## 28 января 2021 - Какой AGI нам нужен: нейросетевой, символьный или гибридный — круглый стол — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/DiYCn0vmvT8/hqdefault.jpg)](https://youtu.be/DiYCn0vmvT8)

Суммаризация семинара:

Семинар посвящен обсуждению подходов к созданию искусственного интеллекта (АГИ), в частности, нейросетевого и символьного. Участники обсуждают преимущества и недостатки каждого подхода, а также гибридные решения, сочетающие в себе лучшие качества обоих.

Основные тематические блоки


1. Нейросетевые технологии и их применение

- Прогресс в области глубокого обучения в последнее десятилетие.
- Примеры успешного применения нейросетей, такие как GPT-3 и трансформерные модели.
- Обсуждение того, что современные нейросетевые модели являются нейросимвольными, используя символьные методы естественного языка.

2. Символьный подход и его значение

- Исторический пример создания программы в уме и последующей записи ее на перфап-карты.
- Объяснимость и интерпретируемость символьных моделей, что важно для понимания и верификации их решений.
- Проблема объяснимости нейросетей и необходимость понимания причин принятия решений.

3. Гибридные нейросимвольные системы

- Обсуждение идеи нейросимвольной интеграции, предложенной Марвином Минским.
- Различие между вертикальной и горизонтальной интеграцией, где вертикальная интеграция подразумевает использование символьных и нейросетевых методов в различных уровнях системы.
- Примеры успешного применения гибридных систем, включая аппроксимацию временных рядов с помощью преобразования Фурье.

4. Ограничения текущих систем и будущее АГИ

- Вопрос о том, сможем ли мы увеличить объем текстовых данных, с которыми работают системы, и сохранить их способность к глубокому пониманию.
- Пример с поисковыми системами, которые становятся "глупее" с увеличением объема обработываемых данных.
- Размышления о том, что система, действительно знающая все, может быть ограничена уровнем массового объема текстов.

5. Критические замечания и возражения

- Комментарии Джуди Пирл о контрафактическом мышлении и способности системы достигать целей без опыта.
- Вопрос о том, сможем ли мы создать систему, которая будет "знать все", но будет делать это на уровне массового объема текстов.

6. Теоретические результаты и анализируемая причина и прогноз

- Обсуждение причинного объяснения и индуктивных законов, полученных в результате обучения и опыта.
- Проблема статистической двусмысленности и необходимость формализации нейронных моделей.

Итог


Семинар показал, что вопрос о том, какой АГИ нам нужен, нейросетевой, символьный или гибридный, остается открытым. Участники обсудили преимущества и недостатки каждого подхода, а также важность объяснимости и интерпретируемости систем. Было подчеркнуто, что создание эффективного и понятного АГИ требует интеграции различных методов и подходов.




S03 [00:00:00]  : И это будет прекрасно. Игорь, спасибо. Так что, можно сказать, у нас сегодня такая разминка перед матчем. Собственно, идея этой разминки родилась спонтанно. Я не буду вдаваться в историю. В общем, спонтанно родилась идея в очередной раз поговорить про того же, кто круче, лыжники или сноубордисты. нейросетевой интеллект или символьный или может быть что-то еще. Алгоритмический интеллект Артур Франц только что в Телеграме предложил. Есть несколько крайних подходов к этой проблеме. Один подход это у нас уже есть GP3, у нас уже есть роберты, диберты и может быть нам просто нужно добавить там еще несколько нулей к количеству параметров, порядку параметров. потом одну очень большую сеть сделать так, чтобы она обучалась другой такой же большой сети, и была еще третья большая сеть, которая бы осуществляла AutoML в подборе гиперпараметров для первых двух сетей, тогда у нас случится магическим образом AGI. Это один крайний подход. Другой крайний подход, что на самом деле у нас действительно есть куча разных способов решать задачу добрым, старым, символьным или, в кавычках, алгоритмическим искусственным интеллектом, строить автоматические системы автопоиска решений, произвольных задач, используя математические методы. Вот. И это другая крайняя сторона. Ну и между этих двух крайних направлений есть бесконечное множество промежуточных точек. И вот где-то в этом пространстве как раз мы сегодня и хотим поговорить. У нас сегодня открывает Сергей Марков, который расскажет, наверное, свое видение с учетом опыта Сбербанка в области именно прежде всего нейросетевых технологий, глубоких сетей, последних достижений в этой области. Потом Евгений Четяев представит позицию Института математики Сибирского отделения наук именно с точки зрения его опыта. Построение систем логиковероятностных и семантических методов. На самом деле в мире три есть задачи такого класса. Три есть системы такого класса. Это система Discovery, Евгений Евгеньевич. Это система NARS, Пиеванга, OpenCock и Бена Керцеля. Соответственно, тут достаточно серьезная разработка, серьезный подход, и будет интересно узнать позицию Евгения Нигеневича. Ну и ваш покорный слуга Антон Колонин, Новосибирский государственный университет и проект E-Agents. Я вот расскажу потом свою позицию, которая называется... Ребята, давайте жить дружно, наверное. Ну, а поможет нам во всем Дмитрий Салихов, Сбербанк. Поэтому я даю слово Дмитрию. 

S04 [00:03:10]  : Я тогда для начала попрошу Сергея Маркова. Наверное, Сергей, есть возможность у вас в канале «22-й век» расшарить ссылку на Zoom, чтобы у нас, может быть, в последний момент побольше народу подошло. Потому что вы ссылочку-то разместили, но ссылку на вашу страницу, а не прямую ссылку на конференцию. И пока Антон, пока Сергей размещает ссылку, немножко о регламенте. То есть у нас трое участников получается. Мы хотим сделать так, у каждого некий доклад вначале в течение минут 20. То есть основные тезисы, позиции относительно этого вопроса. Причем желательно именно в плоскости этого вопроса. То есть не то, что там какой-то обычный доклад, как вы обычно делаете, да, именно с точки зрения, скажем так, противостояния вот этих двух идей, да, то есть нейросимульного подхода против нейросетевого подхода, да, и наоборот. А потом Антон, как сказал, будет нас примерять снова. Потом после вот этих 20 минут, минут 10, сессия вопросов-ответов от телезрителей и потом какая-то общая что-то типа панельной дискуссии. там уже посмотрим как по таймингу пойдет. может быть час, может меньше. и в общем-то вот первое слово Сергею Маркову. 

S05 [00:04:57]  : сейчас буквально еще полминуты. Так, ну вроде опубликовалось. Так, ну что, сейчас я тогда расшарю экран. Я сегодня на самом деле буду говорить о пути к ЭЙДЖАИ через глубокое обучение. На самом деле интересно, что хотя прогресс в области глубокого обучения на слуху последнее десятилетие, но когда на разных ЭЙДЖАИ-тусовках заходят разговоры о том, каким же именно образом на основе технологии глубокого обучения будем делать AJ. Обычно, в общем, как-то добровольцев рассказывать об этом не находятся, все обычно машут рукой и говорят, ну это и так очевидно, интересно, давайте мы об этом не будем говорить, потому что мы же все ML-щики, мы же все все понимаем, поэтому давайте лучше мы поговорим о чем-нибудь там еще. И я сегодня буду не просто в этой теме рассказывать, я немножко хочу понабрасывать на вентилятор в процессе. На самом деле, наверное, первый наброс заключается в том, что то, что мы сегодня понимаем под глубокими моделями и, собственно говоря, традиционно относим к числу моделей конъюнкционистских, на самом деле в чистом виде конъюнкционистскими моделями не являются. Потому что если мы посмотрим на GPT-3, если мы посмотрим на все жирные трансформерные модели современные, то это конечно модели нейросимволи. Почему? вообще говоря, эти модели используют определенные представления естественного языка, которые, разумеется, основаны на символьных методах. Если мы говорим о векторных вложениях, если мы говорим о позицион-энкодинге и так далее, это все, в общем-то, методы, которые глубокое обучение позаимствовало у старого доброго искусственного интеллекта. Точно так же, как и многие другие методы, которые сегодня применяются при обучении таких моделей, они не чисто конъюнкционистские. Важно понимать, что когда мы говорим о какой-то дихотонии, и на самом деле есть два стула, на одном пике точеные, а на другом что-то другое, И нам нужно обязательно сесть на какой-то из этих стульев. На самом деле, возможно, из этих вопросов, из этих вариантов не нужно выбирать никакой. Это, в принципе, такое некоторое упрощение. Но на самом деле, с одной стороны, это действительно так. С другой стороны, мы понимаем, что мы живем в такой эпоху своеобразного конъюнкционистского лета и искусственного интеллекта, потому что уже все-таки прошло как минимум 8 или 9 лет с официально объявленного начала весны. Уже весной называть это как-то, наверное, не совсем последовательно. Я поэтому последние годы говорю обычно о лете. Бросьте, уже никакая не весна, а уже лето, потому что решения на основе глубоких сетей, активно используется во множестве продуктов, во множестве сервисов, которыми каждый из нас каждый день пользуется. И в этом смысле это не похоже на весну конца 50-60-х годов кондиционистскую или на весну искусственного интеллекта 80-х годов, большая часть этих перспективных решений они в общем до продакшен так и не доехали в конечном счете вот поэтому здесь немножко ситуация все другая сегодня и если присмотреться внимательно Ну, очень часто вообще сторонникам кондиционизма предъявляют такую, что ли, претензию, что вот, ну да, вот вы там, дескать, думать головой не хотите, вы просто хотите побольше железа накидать в вашу задачу, да, и оно там само как-то магически решится, сама собой проблема уйдет. Вот. На самом деле, ну, с одной стороны, это действительно выглядит так, когда мы смотрим на какое-нибудь увеличение количества параметров в больших трансформерных моделях. но с другой стороны я бы хотел напомнить, что вообще трансформеру как таковому, как архитектуре нейросетевой ей три годика с половиной. то есть вообще говоря эти модели появились очень недавно и процесс там того, что появление трансформеров, оно открыло возможность масштабировать эффективно глубокие модели за счет эффективного параллелизма, который заложен в основу этой архитектуры. Ну да, это действительно так, но в общем-то Вычислительные мощности, задействуемые моделями, что символьными, что коннекционистскими, они растут и там, и там. Это прогресс объективный, связанный с увеличением вычислительных мощностей, находящихся в распоряжении человечества. А вот в плане архитектур, в плане, так сказать, инноваций, на самом деле глубокое учение вполне может здесь похвастаться множеством инноваций. И если мы посмотрим, допустим, на такую область, как обработка естественного языка, то мы увидим, что с 2003 года у нас произошло фактически четыре смены парадигмы, то есть четыре смены архитектур, лежащих в основе лучших решений в этой области. И если мы начинали с какой-то малоразмерной векторной семантики, обработок бенджо, 2003 года, получили в результате развития этого направления ворк ту век в 2013 году, и в 2013 году джентельменский набор коннекциониста, работающего с естественным языком, это были эластенки плюс какие-нибудь имбединги типа Word2Vec или чего-то еще, то дальше мы видим появление сетей с механизмом внимания и тоже резкое изменение парадигмы. И потом вообще отказ от рекуррентных сетей и переход к трансформерным архитектурам. То есть здесь на самом деле важно понимать, что инновации в области глубокого обучения это инновации в первую очередь алгоритмические, а вовсе не докидывание железа. У нас пресс очень любит подсвечивать количество параметров моделей, потому что архитектура моделей это же что-то такое, что обывателю объяснить очень трудно. Сказать, что мы сделали модель с триллионом параметров, это выглядит круто. Это как в книге Экзюпери «Дом за миллионы долларов». Если мы скажем человеку, дом за миллион долларов, вот тогда взрослый сможет оценить, насколько это действительно хороший дом, а без этого, ну что это за рассказ. Что мы видим с точки зрения движения вообще вперед? Здесь имеет смысл посмотреть на хоть какие-то объективные метрики, которые у нас есть. У нас есть более-менее разработанные системы метрик в решении некоторых задач. Допустим, распознавание изображений, допустим, распознавание речи и много чего еще. Здесь мы можем, воспользовавшись каким-то имеющимся бенчмарком, сравнить результаты разных техник. В плане распознавания опытов мы видим, что с 2013 года у нас идет поступательный рост точности распознавания. особенного замедления здесь мы не наблюдаем. Это процесс постоянного улучшения метрик. Точно так же и в распознавании речи, например, мы видим, как снижается уровень ошибки на всех популярных датасетах, используемых для оценки качества распознавания речи. И опять же, что там, что здесь, человеческий уровень преодолен уже 3-4 года назад. Есть задачи, относящиеся к области слабого искусственного интеллекта, в которых еще не достигнуты уровни, соответствующие человеческим. Например, ответы на вопросы по картинке. но мы видим, что здесь опять же есть поступательное изменение метрик, которое, в общем, наверное, не очень грешно чуть-чуть проэкстраполировать будущее и видеть, что здесь у нас скоро ожидается достижение человеческого уровня, тем более, что я тут не видел пока решений на основе image-трансформера, которые, скорее всего, в этом году будут представлены на очередном соревновании. Я глангую, что там будет, скорее всего, человеческий уровень достигнут. То есть, есть некий поступательный прогресс. С другой стороны, есть Ну, типа, давайте посмотрим, что вот наши железки сегодня представляют в сравнении с человеческим мозгом. Если мы говорим, что мы собираемся делать какую-то конъюнкционистскую модель, которая собирается соревноваться с человеческим мозгом в плане универсальности решаемых задач, то здесь мы что видим? У нас пока нет оборудования, которое бы с человеческим мозгом было сопоставимо. Несмотря на все громкие заявления о триллионах параметров, если мы посчитаем количество параметров в синапсах человеческого мозга, то вывод будет неутешителен для электроники. Окажется, что даже несмотря на колоссальное превосходство в частоте работы, электроники в биток в секунду, мы все равно пока не смогли сделать девайс, который в биток в секунду был бы такой кристалл, сопоставимый с человеческим мозгом. Если брать энергопотребление, там вообще совсем беда. И что это на самом деле для нас значит? Это значит, что мы не можем сейчас пока собрать сетку размером с человеческий мозг, вот абы какую даже, вот даже случайно соединенную, сверчную, трансформер, дальше провести с ним должное количество вычислительных экспериментов, и значит подтвердить или не подтвердить гипотезу, что вот эта вот архитектура, которую мы выбрали, действительно может решать широкий спектр интеллектуальных задач, такой же, как человеческий мозг. Проблема в том, что человек, прежде чем начинает признаки интеллекта проявлять несколько лет, учится в реальной среде. Нам нужно, представьте, сколько вычислительных экспериментов провести с нынешними железками, чтобы что-то сказать определенное. Поэтому здесь нужно понимать, что есть определенные лимиты на сегодняшний день. Они не носят характер физический. Здесь речь не идет о том, что нам лимит Бремермана или лимит Ландауэра мешает. Нет. Здесь ограничения технологические. Мы не можем пока такую же эффективную делать такой же эффективный хардвер, который у нас есть в голове. Хотя в принципе вот симуляции сеток размером с человеческий мозг, попытки таких симуляций были сделаны в свое время, делаются и сейчас, но в 2005 году считается, что это первая была история, когда Евгений Яжекевич собрал сетку сопоставимых количества параметров с человеческим мозгом, то есть квадриллион синапсов. Свою модель импульсных сетей использовал, модели Жюкевича. На одну секунду симуляции нужно было 50 дней расчетов. в кластере, который он использовал, ну вот с 2005 года за прошедшие 16 лет, ну в 1000 раз мы ускорились примерно. как бы это проблему не решает до конца. Здесь во многом еще проблема заключается в том, что бутылочная горлышко фунеймена, те железки, которые у нас есть, не очень хорошо приспособлены к обработке кондиционерских моделей, просто потому что узким местом является шина. Именно поэтому последние 5-10 лет так активно гиганты компьютерного железа исследуют возможность создания нейроморфных устройств, и таких проектов существует очень много. Я в свое время попытался сделать обзор всех нейроморфных проектов, которые в мире существуют, и у меня получилась презентация на 100 с лишним слайдов. То есть, на самом деле, это такая горячая тема, которой все активно занимаются. Но, опять же, даже наиболее продвинутые из этих проектов, типа интеловского проекта Войхи или тех проектов, которые в рамках Human Brain Project разрабатываются, там довольно интересный, хороший прогресс по ним, но они не случатся прямо завтра. Здесь тоже надо понимать, движение есть, но магии немедленной ждать не следует. Ну трансформеры, мы о них сегодня коротко сказали, то есть сети полностью построены из механизма внимания, то есть оказалось, что нам не нужна рекуррентная часть сети, мы вполне можем рассматривать последовательность токенов просто как длинную последовательность и использовать как позиционное кодирование, чтобы эффективно распараллелить вычисления в такой сети. Вот три года модели, сейчас огромное количество ее разновидностей появилось. Это небольшая доля строительных блоков, кирпичиков, трансформерных сетей, которые не удалось на один слайд впихнуть. На самом деле их еще больше. Скорее всего, еще можно на четыре умножить. модификации этой архитектуры, то есть к вопросу о том, закидываем ли мы железом или все-таки что-то другое. На самом деле нет, то есть основной поиск в среде глубокого обучения — это поиск новых, более совершенных архитектур. Но GPT-3, модель, про которую много говорила пресса, 175 миллиардов параметров у самого большого ее варианта, Действительно были очень красивые демонстрации показаны. Что здесь, в принципе, интересного можно сказать, помимо того, что вы все, наверное, хорошо знаете. GPT-3 это модель, которая не только теоретический интерес представляет. Скажем так, большое количество задач прикладных исследуется с точки зрения возможности применения для их решения таких моделей. Мы говорили, что 175 миллиардов параметров – это страшно много и чудовищно. Хинтон пошутил, что главный ответ на Главный вопрос вселенной. Нужно 4,398 триллиона параметров. Казалось бы, год назад мы все удивлялись сетке со 175 миллиардами параметров. И тут нас в начале января Google обрадовал тем, они обучили энкодер-декодерную архитектуру новую, которая называется SwitchTransformer, в которой внезапно больше триллиона параметров. Здесь, конечно, есть некоторая хитрость. Сетка на самом деле представляет собой такой экспертный ансамбль, Но тем не менее, если говорить о числе параметров, вот, пожалуйста, вам трансформер, который больше, чем в 10 раз больше, чем самая большая версия. Точнее, не в 10, но сильно больше, чем GPT-3. И вот тут встает вопрос, что генеративные текстовые модели умеют одну простую вещь сделать. Следующий токен в последовательности умеют предсказывать по предыдущим. И что нам с того? какое отношение это имеет к AGI, какое это отношение имеет к какому-то прорыву, но на самом деле оказывается, что здесь дьявол вкроется в том, что огромное количество задач можно свести к задачу предсказания следующего токена. То есть, на самом деле, подавляющим большинством, наверное, все задачи обработки естественного языка можно представить в таком виде, что на самом деле нам нужно просто предсказать следующий токен в последовательности. А научиться предсказывать следующий токен последовательности можно на основе обучения без учителя, то есть взяв огромное количество текстов, накопленных человечеством. А человечество накопило сейчас содержательных текстов уже под 30 терабайт. 30 терабайт текстов – это очень круто. в таком огромном массиве данных, грубо говоря, на слепке всего интернета, обучить модель, предсказывающую следующий текстовый токен. И внезапно оказывается, что дальше множество задач можно представить в текстовом виде и поехали. В этом смысле тут хочется напомнить об идее, которая в основе теста Тьюринга лежит, что почему задача у Тьюринга тоже приобрела такой текстовый формат. Просто потому что Человеческий язык, естественно, это язык, на котором можно сформулировать условия любой эффективно вычислимой задачи. Так или иначе, это символьная система, которая эквивалентна, не знаю, лямбда-исчислению рекурсивно-транзитивным грамматиком к линии, не суть важно. Если у нас есть возможность использовать естественный язык, это значит, что при помощи этого естественного языка мы, в принципе, можем любую интеллектуальную задачу и ее условия сформулировать. И, соответственно, исходя из этого, мы поставим задачу, как вот игра в имитацию, И будем в ходе этой игры в имитацию давать участникам ее разные интеллектуальные задачи и смотреть, как они их решают. Если окажется, что машина столь же эффективна эти интеллектуальные задачи решает, как их решает человек, то, как говорил Дидро, если я встречу попугая, который в высшей степени разумно будет отвечать на все мои вопросы, то я буду обязан признать за им наличие интеллекта. Но на самом деле интересно, что современные трансформерные модели, они вполне могут работать и, допустим, с визуальными абстракциями. То есть вот это вот сведение интеллектуальной задачи в текстовую форму, оно на самом деле, это не просто какой-то такой формальный трюк. То есть вот мы видим, как модель появившаяся 5 января 2021 года под названием дальняя, она эффективно комбинирует визуальные и текстовые данные, то есть генерирует картинку по ее текстовому описанию. Вы подаете на выходе, получаете картинку. Интересно, что архитектурно эта модель ничто иное, как GPTP. то есть там чуть-чуть модифицирована матрица внимания для токенов, при помощи которых описывается изображение. Но в целом да, то есть архитектурная GT3 версия, причем с 13 миллиардами параметров, то есть не самый большой вариант GT3. И мы видим, что такая модель способна довольно сложные Абстракции постигать и связывать визуальные признаки с текстами. Вот, пожалуйста, нарисую иллюстрацию с изображением ребенка-дайкона в пачке, выгуливающего собачку. Что здесь модель поняла? Она поняла слово иллюстрация, то есть поняла, что она хочет картинку нарисованную. в стиле иллюстрации. Она смогла из редьки сделать ребенка, прицепить к нему какую-то балетную пачку, собачку, поводок. То есть все вот эти вещи. Оказалось, что такая достаточно сложная абстракция такой модели вполне по зубам. Или, например, смотрите, справа витрина магазина с написанным на ней словом OpenAI. Обратите внимание, модель научилась писать текст буквами. Она поняла, что эти символы OpenAI имеют соответствующие визуальные изображения. Ну и в общем это еще только первый подход к снаряду. Надо сказать, что тут еще все впереди. Мы вот сейчас аналог этой модели делаем у себя, но мы конечно сразу покушаемся и на модель потолще. И насчет архитектур мы вот думаем, что может быть как раз идея свитч-трансформера здесь вполне можно подружиться с этой задачкой. Это имеет определенные последствия для прикладных задач. Почему это важно? Потому что если мы получаем какой-то прикладной результат от применения таких моделей, это значит, что будут выделяться ресурсы на это направление. Здесь глубокое обучение, оно как кандидат на пути в AJ, оно хорошо тем, вы можете всегда бизнесу, политикам, государству показать промежуточные достижения и сказать, а вот смотрите, мы сделали умный фотосток, который для дизайнеров генерирует картинки по тексту, вот реальные деньги, давайте мы дальше эти деньги вложим в развитие еще более крутых, глубоких моделей. Здесь, на самом деле, я думаю, что мы в ближайшие годы увидим довольно много плодов развития этих моделей. различные новые сервисы с каким-то кастомным контентом. И, в принципе, ускорение прототипирования при создании сервисов. Эти модели довольно хорошо работают с программным кодом, не только с естественными языками, с искусственными тоже. Довольно хорошие результаты получены в решении символьных задач. Оказывается, что модели глубокого обучения вполне себе могут в символьную логику. Это довольно интересный результат. Он показывает, что здесь возможно расширить область применения такого рода систем. Ну, и на самом деле последний слайд у меня. Я тут хотел несколько накидать таких, может быть, вопросов для дискуссии. То есть, с одной стороны, мы видим некий поступательный прогресс, который в области глубокого обучения происходит. И, значит, это, безусловно, плюс. не видим каких-то, я не знаю, фундаментальных ограничений, в которые бы мы уперлись. То есть вот у нас не стоит проблема таким образом, что вот у нас есть какая-то задача, которую мы никак не можем решить, и у нас сколько бы мы ни бились, там метрики не улучшаются. Нет, такого глубокого обучения нет. Поэтому это, в принципе, большое преимущество этого направления. Но есть, естественно, и определенные вызовы. Первый вызов заключается в том, что эволюции, чтобы решить эту задачу коннекционистским методом, потребовалось довольно много вычислительных ресурсов. У нас миллионы лет мозг эволюционировал. оно и в принципе живые существа эволюционировали там еще больше. И что это значит? Это значит, что природа, она провела много-много симуляционных экспериментов, в результате которых мы получили то, что получили, то есть какие-то архитектуры мозга, которые позволяют ему развить универсальный интеллект. Ну а что нам-то делать? То есть у нас этих миллионов лет нет и наши вычислительные эксперименты, они даже если мы сделаем очень быстрые машины, ну все равно, значит, довольно трудно с природой притягаться в этом плане. То есть нам на самом деле для того, чтобы повторять путь природы, нам придется еще видимо симулировать среду, в которой будет обучение происходить. Ну или использовать естественную среду для обучения, но тут беда, потому что это медленно очень. То есть у нас есть определенные проблемы связаны с тем, что у нас, в отличие от эволюции, нету такого длительного периода времени и такого количества материала, которое у нее было. То есть нам нужно каким-то образом пробежать вот эту дорогу, которую эволюция пробежала за много-много лет, пробежать ее буквально за Но первое – это бионика. А давайте начнем с нуля, давайте подглядим где-нибудь у специалистов по канектонике. Научились же мозг нарезать 40-нанометровыми слоями? Научились. Научились автоматически пихать сканирующий микроскоп? Научились. Научились те срезы, которые пересветили восстанавливать при помощи искусственных нейронов? Ну тоже вроде научились. Научились потом из этих 2D срезов 3D коньяктом строить? Ну да, научились, закрашивающие нейронные сети появились. Ну теперь там вопрос, а можем мы там веса синапсов еще разглядеть на этих срезах? Ну, оказывается, что тоже, наверное, можем, потому что вроде как толщина дендритных шеек сильно коррелирует с эффективностью синапса. Поэтому, значит, если мы так поднатужимся, то мы, наверное, сможем в какой-то момент реверс-инженирить настоящий мозг и дальше в нашей глубокой модели его тропологию связей воспроизвести. И, значит, мы, по крайней мере, начнем тогда не с нуля, как эволюции пришлось это делать, а мы начнем с какого-то близкого к оптимуму состояния. Но может быть это зря все, потому что все-таки человеческий мозг и эволюция через который он прошел, она предъявляла к нему некоторые требования, которые нам совсем не обязательно выдерживать. Вот, например, одно из требований, что, не знаю, от удара сапогом по лицу у вас не должна память сбрасываться. Эволюционно это важно для мозга. Для той машины, которую мы делаем, это неважно. Она может быть гораздо более хрупкой, чем мозг, но если нам отмена вот этого ограничения позволит, например, не знаю, в тысячу раз ускорить вычислительные процессы, то почему бы и нет. Нам не надо, когда повторять ту дорогу, которую эволюция прошла, мы сами какой-нибудь боисовский оптимизатор прикрутим, или как-то еще каким-то оптимизационным процессом найдем архитектуру, которая будет лучше, чем человеческий мозг для решения наших задач. Поэтому здесь это интересно. На самом деле для развилки хорошего ответа на этот вопрос нет. То есть в принципе можем допустить, что скорее первая дорога правильная или скорее вторая дорога правильная. И разные исследовательские команды в мире идут по этим путям параллельно. Вот более-менее все, наверное, что я хотел сказать, но наверняка сейчас куча вопросов возникнет. Когда уже в ходе ответов, в ходе дискуссий. 

S04 [00:36:29]  : Спасибо, Сергей. Да, вопрос возник. Пока один. Вы говорили про изучение мозга в том смысле, что давайте его разрежем и посмотрим на конъюнктом, и может быть тогда поймем какие-то законы функциональные, как он, собственно, выполняет все эти функции. Вот из этого зала есть вопрос, а как же мы будем сканировать законы обучения, то есть, собственно, динамику его. 

S05 [00:37:01]  : Это мы знаем хорошо. СТДП, это, слава богу, 94-й год работы Малину. То есть, со времен Хебба, в 49-м году появилась хеббовская парадигма, fire together, wire together. Потом там работы на доплизе вот эти вот 60-70-е годы, когда антихебовские нашли механизм, который fire out of sync, lose your link. Ну и потом вот в работе Малину в 94-м году было показано, что в изолированной культуре нейронов, значит, вот этот алгоритм STDP, он работает. То есть действительно, если импульсы Присинаптические и постсинаптические синхронизированы в рамках некого промежутка времени, то эффективность синапса усиливается, а если в рассинхроне они приходят, то ослабляются. Потом активно и маркером это дело использовал в своих моделях. Там, грубо говоря, некое понимание есть, но тут просто проблема ведь в чем? Ну, там вопрос, эта модель, она достаточно полна для того, чтобы, ну, типа, итоговая сетка училась так же хорошо, как мозг или нет, да, потому что там нюансы какие-то могут выплывать, как вот там эта работа 2015 года про распространение сигналов через астроциты в реальном ткани, да, вот, или какие-то еще вещи, но в целом, в целом, Что сейчас хорошо понятно, это то, что STDP работает, и то, что при правильном подборе параметров STDP работает примерно так же эффективно, как backpropagation, это тоже как бы понятно. И то, что на моделях небольших, на моделях нервной ткани, мы там наблюдаем, что действительно работает вот так. То есть что у нас модель, которая показывает временную динамику изменения эффективности синапса, ну то есть вот то что лтп лтд да вот это все мы вроде довольно точно знаем как работает как описывается и у нас есть модели какие-то не знаю там более сложные модели, которые ионные транспорты моделируют. Если мы хотим это смоделировать еще более точно, чем просто LTP и LTD, то при помощи STDP мы можем моделировать популяции ионных каналов. И для этого у нас тоже есть довольно хорошие гибридные стокастические системы. То есть, мне кажется, вы понимаете, проблема не в том, что мы не знаем, как эти алгоритмы работают. Я думаю, что у нас много версий о том, как это работает, и эти версии более-менее согласуются с экспериментальными данными. Но у нас, как всегда, проблема, как это было в Нобелевской лекции Адриана сказано, Прогресс нейрофизиологии всегда был прогрессом измеряющих приборов. Здесь вопрос, а насколько точно нам надо симулировать то, что происходит в биологической сети, чтобы на выходе получить те же психические феномены. Вот вопрос в этом. Мы этого не знаем, пока мы не проведем крупномасштабных экспериментов. А на тех экспериментах, которые нам сейчас доступны, оно все воспроизводится. Никто же не может подписаться кровью и сказать, что когда мы это отмасштабируем до размеров 86 миллиардов нейронов, у нас это будет так же эффективно работать. Может быть, нет. Поэтому, наверное, вот так дела сейчас обстоят. 

S04 [00:40:51]  : Хорошо. Еще маленький вопросик, больше философский, чем технический. статью читал, название не помню, к сожалению, там вкратце о том, что большие языковые модели, ну и не только языковые модели, вообще вот эти все большие модели, которые сейчас бороздят просторы, не понимая ничего, тем не менее решают разные человеческие задачи, а некоторые даже на уровне человека и выше. Потом автор экстраполирует эту мысль таким образом, что для решения любых задач понимание не так уж и требуется. И экстенсивное развитие технологии в итоге покорит космос и наступит гегемония машин, которые могут все, не понимая ничего. Как вы считаете, насколько этот принцип жизнеспособен и насколько мы действительно можем высокие фронтиры покорить таким образом? 

S05 [00:41:47]  : Но для начала тут естественно непонятно, что такое понимание, какой мы смысл вкладываем в этот термин, потому что он очень многозначный. Есть целое большое направление, которое называется Explainable AI, в рамках которого мы пытаемся так называемые объяснимые модели построить. Что значит, что мы объяснили модель? у кого-то из исследователей, я, к сожалению, сейчас не помню точно, но было хорошее выражение о том, что человеческое понимание, человеческое, так сказать, сознательное понимание чего-то, у этого ограничен объем. Один челобай называется. Как нам уместить какую-то там модель в этот один челобай понимания, который у человека есть в голове? значит проблема в чем заключается что как только у нас возникает модель которая сложная достаточно ну как бы и возможность построить здесь эффективно объясняемую объяснимую модель она может быть двумя путями задача может быть решена первое первый путь давайте мы попробуем нашу модель каким-то образом в неё внести некоторые ограничения, которые сделают её более понимаемой. Например, какая-нибудь регуляризация для интерпретабельности. Есть такая работа, так и называется, Regularization for Interpretability. И там люди говорят, а вот давайте мы в нейронку добавим регуляционные члены, тогда нейронка, которая выучится, она будет больше похожа на дерево решений, и мы ее тогда сможем объяснять. Но на самом деле, если мы рассматриваем передачу знаний от людей к людям, Это ведь не значит, что вы передали свои знания другому человеку, это не значит, что вы веса своих синаптических связей перенесли в голову другого человека. Это, скорее всего, значит совсем другое. Скорее всего, значит, что вы с другим человеком смогли выровнять некое множество признаков, которые для вас являются общезначными. Вам в этом помогает язык естественный. и вообще общая, так сказать, общественная практика, которая у нас там, тут бедно, единая. И благодаря этому мы можем, опираясь на вот эти общедоступные абстракции, общедоступные признаки, выстроить какую-то модель маленькую. Она опирается на то, что вот, я не знаю, мы человеку объясняем, а человек не видел никогда но он знает, что такое жёлтый цвет, чёрный, что такое кошка, и что такое маленький, и что такое большой. И мы ему говорим, значит, тигр – это такая большая кошка с чёрными и жёлтыми полосками. То есть мы как бы, получается, оттолкнулись от общезначимых для нас понятий, и таким образом обошлись минимумом каких-то минимальной модели. Почему? Потому что она опирается на то же множество признаков, которые нам известны. Ну и в принципе, что можно сделать с нейронками? С нейронками можно делать то же самое. У нас, слава богу, сейчас есть синхронные датасеты с картинками, с текстом. можно заставить нейронки опираться на те признаки, которые судя по тем данным можно таким образом получать объяснимые модели там, где нам это важно. 

S04 [00:45:45]  : К сожалению, нужно следовать регламенту. У нас есть следующие спикеры. Давайте эту тему продолжим на общей панели, которая будет после выступления всех. Сейчас, пожалуйста, Евгений Евгеньевич Витяев с докладом. Сейчас мы послушаем сторону нейросимволистов. Или, может быть, как-то по-другому. 

S03 [00:46:40]  : Презентацию видно мою? Да-да, Евгений Евгеньевич, видно. 

S01 [00:46:44]  : Да-да, хорошо. Ну, после такого доклада по поводу нейронных сетей сложно как бы переходить сразу к символическому искусственному интеллекту. Но я попробую подойти с трех альтернативных сторон. Значит, первая альтернативная сторона, что вот как раз в ходе доклада я покажу, что можно создать логику вероятности модель нейрона, причем нейроны именно, которая будет объяснима. Что это означает? Что если мы, например, взяли, такими нейронами обучили компьютер играть в Go, и он, так сказать, начинает выигрывать. Но вот как вот в той игре, где в Go компьютер выиграл, там пытались понять, а как он на таком-то, там, в 27-м, что ли, году, никак не могли понять, почему он сделал такой код. Так вот, если, так сказать, нейроны будут логикой вероятностной, можно будет от компьютера взять внимательно, посмотреть, как он принял это решение, проанализировать код рассуждений и опыт его, и понять действительно, почему он это сделал. Более того, если, так сказать, там положим, система управляет истребителем еще что-то, и она делает какие-то ошибки, можно опять же вообще безафиксировать, проанализировать, как это все происходит, и в таких ответственных областях, как медицина, военные приложения, финансы, пытаться корректировать и анализировать работу. такой логикой вероятности нейронной сети и тем самым ее доводить до тюма. Это первый аргумент, такой логикой вероятности нейронной модели я приведу. Второй аргумент состоит в том, что на самом деле, на основании той архитектуры, о которой я сейчас буду рассказывать, она моделирует в том числе теорию функциональных систем, то есть она моделирует физиологическую теорию работы мозга. Более того, сейчас идет доклад, сейчас идет конференция в институте физиологии, и там собрались все физиологи-ведущие, в этом институте имени Анокина. И там делается доклад о формализации теории функциональных систем. Я там в том числе сделал доклад о том, что можно формализовывать не только теорию функциональных систем, а как не то, на основании логико-вероятностных моделей нейронов. То есть можно моделировать мозг в том понимании, как это в настоящее время есть. Ну и, наконец, третья сторона, или третий аргумент. Значит, это известные, так сказать, ограничения нейронных сетей. Во-первых, он черный ящик, но это понятно, он, так сказать, не в состоянии объяснить, что делает. Во-вторых, он обладает слабой способностью к генерализации. А, так сказать, логико-вероятностные понятия и символные понятия, они создают сразу, так сказать, свое обучение в рамках довольно общий культур зрения. Кроме того, нейронные сети очень точно адаптируются к конкретным каких-то элементам. А нейросимвельные все-таки так иначе, в силу их общности они не могут очень точно отслеживать отдельные линии, отдельные элементы. Кроме того, нейронные сети не могут использовать априорный опыт, который имеет некоторые предметы новости, накопленные экспертами и еще чем-то. А это, вообще-то говоря, может быть очень важно, может быть очень уникально, и, так сказать, может быть та информация, которую с помощью обучения даже и не возьмешь. Пятое. С помощью логико-вероятностного обучения можно обучаться одновременно нескольким родам. Есть множество родов, они обмениваются между собой опытом в виде правил. Это может быть коллективное и довольно быстрое обучение. Пятое. Нейронные сети невероятны относительно допустимых преобразований шкал. Если мы данные перепишем в другие единицы измерения, мы можем получить другой результат. Шестое. На основании логики вероятностного подхода можно сформулировать довольно общий подход к ADI, а именно решение задачи в достаточно общем виде. Об этом я тоже буду говорить. И, имея в виду эти аргументы, тут уже как бы ваш суд, это лучше или хуже, но в любом случае соревноваться, по крайней мере, в той совокупности результатов, которые сейчас получаются в нейронных сетях, сейчас сложно, потому что некоторые из вещей, которые будут рассказывать, они на уровне, по крайней мере, некоторого рода эксперимента. Но какие-то программы и теоретические результаты уже имеется. Ну и вот теперь, если перейти к теоретическим результатам, потому что та схема, о которой я буду рассказывать, она теоретически очень точно выверена. Именно поэтому она дает те свойства, о которых я рассказывал. А именно, анализируем причину и прогноз. анализируем с самой общей точки зрения, но в результате этого анализа мы перейдем к конкретной формальной модели нейрона. То есть мы получим нечто конкретное. Начнем с самых общих рассуждений. А именно, что такое предсказание? Нам нужно уметь предсказывать. Причинное отношение означает предсказуемость в том смысле, что если полностью предыдущая ситуация известна, события могут быть предсказаны, если будут даны все относящиеся к событию факты и законы. То есть это как мы можем предсказывать и схемы предсказания. Существует две модели предсказания. дедуктивно-аномологическое и индуктивно-статистическое, когда в причинном отношении используются, соответственно, детерминированные или статистические законы. Но нас интересует, прежде всего, причинное объяснение, основанное на индуктивных законах, полученных в результате обучения и опыта. Однако для таких законов возникает проблема, например, статистическая двусмысленность. Есть еще одна проблема о том, что в процессе логического вывода вероятности могут падать, и в результате мы получим оценку предсказания, так сказать, нулевой вероятности или там от нуля до сколько, но это, так сказать, это проблема, которая обсуждается вам как конференции Project, то есть синтез логики вероятности. Это тоже нерешенная проблема. И, с моей точки зрения, она не может быть община. Здесь надо либо делать приоритет у логики, либо у вероятности. Для систем, основанных на обучении, надо делать приоритет на вероятности. И, значит, проблема со статистикой двусмысленности. Если мы будем анализировать медиа, то мы можем быстро вывести такое правило, если философ, то он не миллионер, если держатель приисков, то он миллионер. А для одного из известных философов, который имеет прииски, мы получим противоречие. Это требование еще философии науки Гемпель чуть ли не сто лет назад сформулировал требования максимальной специфичности для статистических правил, чтобы они не приводили к противоречиям. Но формально я его приводить не буду. Содержательно оно означает, что правила должны содержать максимум личной информации, что само по себе требование достаточно естественное. И тогда те правила, которые я приводил, нужно переформулировать в более точные, максимально специфические правила в следующем образом. Если философ не держатель приисков, то он еще более вероятно не миллионер. А если держатель приисков не философ, то еще более вероятно, что он миллионер. Эти два правила уже не противоречат друг другу, и мы не сможем вывести противоречивые предсказания. Но на самом деле эта проблема, хотя Гемпель была сформулирована довольно точно, она не была решена. А нам ее удалось решить. Мы определили максимально специфические причинные связи, из которых противоречия не выводятся. Тут есть статья ниже, где это есть. Но и на самом деле, чтобы уже перейти к формальной модели нейрона, нам нужно уже формально определить эти максимально специфические правила. Они определяются симметрически и вероятностно выводом. Это вывод нелогичный. То есть я говорил, для того чтобы решить проблему синтеза логики вероятности, если мы обращаем на вероятность, то мы не следуем логике. И делается это таким образом. Семантический вариант настоевает это, такая последовательность правил. Если это правило ЦИИ, то следующее правило ЦИИ плюс первое содержит более длинную посылку. Каждое из правил удовлетворяет требованию вероятностной причинности в смысле Cartwright. Это звучит так, что если у нас условная вероятность правила такая, то она всегда строго больше условной вероятности этого правила, если мы в этом правиле что-то уберем. Это означает, что каждое условие в правиле значимо для прогноза. Кроме того, мы когда строим такую последовательность правил, мы их постоянно усиливаем, мы расширяем посылку, то есть мы добавляем новые условия, но всегда с таким требованием, чтобы у нас условная вероятность росла. То есть новые сведения или новые признаки нам должны строго увеличивать вероятность прогноза. В этом случае мы получаем некий симметрический вероятностный вывод. Уже видно, что он похож на нейрон. И в этом случае мы доказываем теорему, что индуктивно-статистический вывод, использующий только максимально специфические правила, не противоречит А максимально специфические правила – это правила, которые находятся в самом конце каждого вывода, то есть они максимально точны, и кроме того имеют максимальную вероятность среди тех, которые есть. И отсюда мы получаем формально модель нейрона, удовлетворяющий правила Хебба. На самом деле, еще Маккало и Кепиц, они формулировали свои нейроны на основе правил Хебба. Но мне кажется, они это сделали на основе суммации, они сделали это приблизительно. Есть специальная работа Петра Кузьмича и Анохина, которые говорят о том, что биологический смысл процедуры суммации не имеет. Но другой вариант, такой же в модели нейрона, который тоже обнаруживает условные связи, но делает это принципиально точно, поскольку она обнаруживает максимально специфические причинные связи, такая модель нейрона действует таким образом. что если у нее есть рецептивное поле, на которое она отвечает безусловно, и отвечает на стимулы ЖЭ, а если мы на каком-то из дендритов нашли некоторые стимулы, появление которых нам значимо увеличивает вероятность прогноза ЖЭ, то мы осуществляем некоторую, обнаруживаем некоторую причинную связь на уровне нейрона, Если обнаруживаются еще какие-то дополнительные стимулы, еще более увеличивающие эту вероятность, мы их добавляем к правилу, то есть мы в каком-то смысле осуществляем семантический вероятностный вывод, то есть мы ищем всю информацию, которая нам необходима для прогноза нашего стимула G. Если нейрон будет обучаться таким образом на всех своих гендритах, он в этом случае будет получать максимально специфические правила, которые, кроме того, утверждают такому условию, известный это физиологический факт, нейрон быстрее всего срабатывает на высоковероятные правила. которыми как раз и являются максимально специфические правила, потому что они имеют как раз максимальную вероятность и предсказывают без противоречий. Поэтому нейрон быстрее всего на максимально специфические правила как раз и отвечает. Так вот, мы проводим некоторые эксперименты, пытаясь заменить стандарты в нейронных сетях нашими нейронами, чтобы получить более точный результат. Я не буду здесь приводить анализ из экспериментов сравнения с сетями Хопфилда, где мы показываем, что, по крайней мере, на тех данных, на которых мы это читаем, вот сети Хопфилда не справляются, а наша система справляется с соответствующей задачей. Но теперь можно перейти к неровному уровню, к общей постановке AGI. AGI говорит о том, что нам нужно решать достаточно широкий круг задач. Это такие задачи, в которых мы можем достигать нужные нам цели, учитывая определенные риски. Но эта постановка задачи на самом деле является, можно показать, что она является частным случаем функциональных систем, о которых я буду рассказывать далее. Но мы в нашем логико-вероятностном подходе сформируем еще более вообще постановку. То есть мы считаем, что все, что можно осмысленно сформулировать в качестве задачи, это все может быть сформулировано в логике вариаций терминов, применительно к некоторой предметной области и эффективно решено. Значит, более точно. Задача определяется таким образом. Задача определена в том и только в том случае, если в ее формулировке присутствует. Указания предметной области, к которой относится задача. Знания предметной области зафиксированы в видеомодели, включая описание сигнатуры и структуры языка предметной области. Антология, понятное дело. Факты знания записаны в терминах антологии, то есть знания, которые у нас имеются, в том числе экспертные. На какой запрос вопрос, сформулированный в задаче, относящийся к предметной области, мы хотим получить ответ. Кроме того, для этого должен быть определен критерий удовлетворения запроса, то есть в каком случае можно считать, что ответ на запрос получен, потому что в противном случае этот запрос не будет иметь смысла, потому что любой ответ может считаться ответом. Если нет критерия получения ответа, то у нас нет задачи. Кроме того, вывод ответа на запрос и тем самым его предсказание осуществляется дедуктивно-аномалогическим или индуктивно-стратегическим выводом, основанным на максимально специфических правилах, о которых я только что говорил. И поскольку в индуктивном как и дедуктивно-номологический вывод. В этом случае у нас обе схемы вывода работают одновременно и одинаково. Они равноправно предсказывают нам возможность вывода и возможность решения задачи. Кроме того, надо учитывать, в каком контексте следует искать ответ на запрос. То есть, что мы ожидаем от результата, каковы его последствия и что делать, если ответ будет отрицательным. Кроме того, задачный подход считается, что назначением искусственной интеллекции является автоматизация решения задач, понимая автоматизацию в самом широком смысле. Кроме того, запросы решения должны формулировать в исполнимой спецификации, то есть мало того, что мы должны сформулировать задачи, мы ее должны в этих терминах, причем таким точным образом, чтобы сама спецификация давала нам алгоритм ее решения, чтобы это решение было эффективно. Теоретические основы вот этого подхода, они приведены здесь, так сказать, в нижних работах, но это не все работы, которые к этому относятся. А теперь покажем, что кроме того, что мы можем решать очень широкий класс задач, достаточно широкий, фактически, это весь класс задач, которые имеют смысл. Если мы задачу можем сформулировать осмысленно, она сразу попадет в наш термин. А теперь покажем, что мозг на самом деле в его натуральном виде То есть в том виде, как он исследовал физиологически в одной из ведущих физиологических школ, а именно школы Петра Кузьмича Анохина. Это, так сказать, еще с 30-х годов прошлого столетия эта школа развивалась, и она является ведущей, одной из ведущих до сих пор. Так вот, в соответствии с этой теорией, ее можно переформировать как таким образом, что мозг, он тоже решает задачу в нашем смысле. И поэтому наша формулировка решения задач является более общей по отношению к действию мозга. Действие мозга и его физиологические механизмы являются частным случаем решения задач. Более точно это звучит таким образом. Любое решение задач мозгом – это целенаправленное поведение и удовлетворение потребностей. И любой поведенческий акт, он имеет следующую архитектуру. Первое – это эфферентный синтез, который включает мотивационное возбуждение, которое ставит цель в целенаправленном поведении и возникает в связи с потребностью память. Мотивационное возбуждение извлекает из памяти также все последовательности действия, которые приводили к цели по удовлетворению потребности. Обстановочная и пусковая эфферентация. которые говорят о том, в какой обстановке мы можем действительно достичь цели. После извлечения мотивационного возбуждения без памяти нашего прошлого опыта по удовлетворению этой потребности происходит принятие решения, а именно выбор из всех этих способов одного, который имеет максимальную вероятность, После этого, после того, как мы выбрали один способ достижения цели, у нас формируется план действий. Вместе с формулировкой планов действий, как это следует в соответствии с формулировкой задачи, но мы формулировали это как формулировка задачи, а физиологически это проверяется специальным рецепторным аппаратом. То есть, как только сформулирован план действий, возникает акцептор результатов действия, который будет прослеживать достижения каждого промежуточного результата и фиксировать это особыми рецепторами. То есть, есть особые рецепторы, которые проверяют достижение цели. То есть, мозг, у мозга для этого есть свои рецепторы. Ну и, наконец, эффекторы механизмов функциональных систем, которые говорят о том, что если план действий нам привел к удовлетворению потребностей, то этот план действий и те правила, которые сработали, у нас подкрепляются. Например, их вероятность увеличивается. Если в какой-то момент мы не достигли какой-то цели, то соответствующее правило, которое не достигло цели, будет нужным образом наказываться. Кроме того, можно объяснить работу теории функциональных систем. с помощью тех самых формальных моделей нейронов, о которых я только что говорил. Объясняется это на основании, прежде всего, высказывания самого Анохина, который открыл следующее в своих исследованиях. Речь идет о коллатеральных ответвлениях пирамидного тракта. отводящих ко многим нейронам копии тех референтных посылок, которые выходят на пирамидный тракт. То есть это импульсы на некоторые действия руками или ногами. Таким образом, момент принятия решений, начало выхода рабочих эфириентных возбуждений, начало действия из мозга сопровождается формированием обширного комплекса возбуждений, акцентуя результаты действий, которые будут проверять достижение каждого этапа, то есть, который соответствует критериям достижения каждой цели и по цели, состоящего из эфириентных признаков будущего результата. и формируется функциональная система на основании причинных связей и тоже формальной модели нейрона следующим образом. Если у нас возникла мотивация, то есть возникла некоторая потребность, то в этом случае, я положу методом ошибок, мы осуществили некоторые действия. В соответствии с высказыванием Анохина, копия этого возбуждения идет в проекционные зоны, одновременно осуществляется действие, и в проекционных зонах всегда найдется нейрон, который получит как сигнал о том, что было действие, так и о его результатах. Сформируется условная связь, что после такого-то действия будет такой-то результат. Он изменит обстановку, если после этого мы сделаем следующее действие, то снова копия пойдет в проекционной зоне, а результат действия во внешнем мире будет уловлен некоторым другим нейроном, на котором тоже вернутся условные связи. Если это приведет к достижению результата, то эта последовательность действия будет закреплена и занесена в память. И что в этом случае получается дальше у нас? Таким образом, некоторая первичная функциональная система сформирована. Если в следующий раз возникает мотивационное возбуждение, оно уже по внутреннему отору причинных связей, еще до начала всяких действий, начинает прогнозировать, что мы достигаем цели. И в этом случае могут быть приняты решения именно о таком способе достижения цели. Если план у нас будет соответствовать этому способу достижения цели, то у нас тогда этим мотивационным возбуждением активируются вот эти нейроны, которые будут уже ожидать соответствующие результаты во внешнем мире, и тогда план действий запустится на выполнение. Это схема работы функциональной системы, которая объясняется на основе причинных связей. Здесь можно показать, но, может быть, даже это не нужно делать более подробно, а, так сказать, это на самом деле достаточно очевидно, что вот эта схема функциональных систем, она является частным случаем понятия задачи. То есть модель предметной области, в этом случае модель внешнего мира, которая получается в результате обучения, в которой существует целенаправленное поведение. Запрос ко внешнему миру – это потребность, которое надо удовлетворить, оно может быть обучаться некоторым предикатам. Решением задачи является объект ситуации, воспринимаемый в некоторой совокупности аффирентных раздражений, которые делают этот предикат истиной, то есть удовлетворит потребность, то есть это есть в этом случае критерий решения задачи. И принятие решения осуществляется выбором конкретного плана действий, на основании общей имеющейся опытной модели внешнего мира, по достижению ситуации А, делающей предикаты истины. Кроме того, задача может разбиваться на подзадачах в соответствии с иерархией результатов, что дает иерархию запросов и иерархию ожидаемых результатов, акцепта результатов действия. Более точно та схема, которую только что рассказал, приблизительно активная, в точности тех самых максимально специфических правил. Она выглядит уже более развертата. Но я не буду здесь подробно рассказывать. Внизу есть работа, где это есть подробно. Просто приведу примеры, которые покажут, что эта схема работает точно и эффективно. А именно, мы проводили много разных компьютерных примеров по применению теории функциональных степеней моделирования различных аниматов и организмов. Но наиболее показательный пример следующий. Вот мы взяли нематоду, то есть электронный организм, который замоделирует нематоду и сделанную Пальяновым институтом системы информатики, вложили в нее нашу систему управления и попросили обучиться своим собственным движениям. Так вот, нематода сначала делает где-то 100-150 случайных движений, и потом находит свое собственное движение, причем оно оказывается совершенно естественным для ее естественных движений. То есть, нематоде не надо специально обучаться своим собственным движениям. Ей достаточно методом проб и ошибок его просто нащупать. Ну и еще пример компьютерного моделирования, когда у нас имеется рой, а именно совокупность мышей. В этом случае они могут обучиться поедать сыр. Поскольку здесь справа находятся правила, по которым они обучаются принимать решения, они могут обмениваться опытом, что они делают в нейронной сети. И в этом случае, в совокупности, довольно быстро обучаться этой цепной дате на основании той или иной схемы функциональной системы. Мы проверяли, сравнивая с некоторыми другими методами, ресурсом, пленником, эта система работает быстрее. Ну и вот, собственно, все. Вот что я хотел сказать. Но я выношу на общую дискуссию сравнение того, что я рассказал, с нейронными сетями. Но, конечно, я заранее должен предупредить, что это все компьютерные эксперименты. Есть программа, есть теория. Конечно, до тех впечатляющих результатов, которые достигли нейронной сети, здесь еще далеко, но перспектива очень хорошая. Спасибо за внимание. 

S04 [01:11:45]  : Спасибо, Евгений. Хорошо, Костя, промыли кондиционистскому подходу и нейросетям в частности. Я вопрос задам с позиции прокурора наоборот. У вас была красивая схема, где в виртуальной среде мыши сыр едят. И, собственно, давайте расширим ее мысленно. Посадим туда кота. в виде какого-то набора пикселов, который будет представлять кота и скажем мышам, что теперь бойтесь кота, когда увидите его разворачивайтесь и бегите. Какая вот с точки зрения нейросимвельной парадигмы есть возможность, чтобы они этого кота как-то узнали, если они, собственно, если это просто пикселы. Говоря широко, символ граундинг. 

S01 [01:12:34]  : Для этого достаточно, чтобы они как-то распознавали. У нас есть другие эксперименты, в которых есть признаки о том, что это препятствие, это еда или еще что-то. У них должен быть предикат, они должны распознать, что это. Но здесь тогда Возникает такой интересный вопрос. Если кот встретил мышь, она тут же съедает, то есть у нее нет возможности сформировать опыт. Это, конечно, одна ситуация. А если он все-таки ее куснет и будет предназначать, что ей будет больно, она убежит. Она это запомнит и научится быстро. То есть, в тех экспериментах, которые мы делали по поеданию еды, аниматы научаются достаточно быстро. То есть, они начинают обучаться в единичных случаях, а потом свой опыт обущают. 

S04 [01:13:32]  : Понял, спасибо. Вопросов таких основных больше нет. То, что есть, давайте на потом. И тогда Антон, пожалуйста. 

S03 [01:13:44]  : хорошо коллеги спасибо я попытаюсь значит немножечко начать издалека вот и попытаться поговорить о том что мы хотим сделать что-то и для этого чего-то нам нужны какие-то алгоритмы да то есть давайте будем говорить о вычислительных алгоритмах и Дальше будем говорить о том, какие алгоритмы хорошие, какие плохие, как они решают задачу. И вот если говорить об алгоритмах, то вот я на самом деле по образованию геофизик и с бигдатой в геофизике работали 30 лет назад, когда еще не было слова машинного обучения, слово искусственный интеллект не было известно, но было известно слово большие данные. В геофизике большие данные Это были самые большие данные, которые были где-либо в индустрии. Больше, чем в космических программах, больше, чем в любых моделированиях погоды и расчетах атомных реакций, больше всего данных было в геофизике. И операция свёртки, которая на самом деле легла в основу революции глубоких нейронных сетей, она использовалась каждый день. Одномерная свёртка, двухмерная свёртка. И вот те картинки, которые заполонили соответствующие сегменты сети в связи с первыми достижениями в области сверточных нейронных сетей, это помните, когда, значит, Google научился распознавать собак, морды собак, и куча было картинок, где вот кругом морды собак, то есть там офис, и везде в офисе там, так сказать, в каждом углу офиса морды собак, или там, значит, лес, и везде каждое дерево, каждый лист – это морда собаки, да? Что это такое? Это на самом деле просто результат применения операции двухмерной свёртки, где оператор свёртки является фильтром обнаружения морды собаки. То есть, в геофизике такой метод свёртки использовался для того, чтобы строить операторы свёрток, рассчитанные на поиске определенного вида аномалий. Только вот там мы искали аномалии, а здесь с помощью свёртки на многоуровневой сверке обнаруживаются те или иные объекты, на которые сети настроены. А настраиваются сети просто таким образом, что мы на различные объекты настраиваем в результате обучения различные операторы сверки. То есть мы имеем образцы, Определяем, какие операторы для свёртки нам нужны для того, чтобы определять яйные образцы для кошек. Один оператор для собак, другой оператор для людей. Третий оператор. И применяем эти операторы свёртки. Смотрим, где у нас возникает большая корреляция. На самом деле можно говорить о нейронных сетях, а можно говорить о применении оператора свертки для выявления аномалий с точки зрения теории обработки сигналов. С другой стороны, если мы вернемся, перенесемся немножечко в 20-й век, его начало, и поговорим о Data Science, то опять-таки есть много статей и работ, которые показывают, что если мы решаем задачу Data Science, что такое на самом деле задача Data Science с точки зрения того, к чему мы ее можем свести, или задачи искусственного интеллекта, или задачи AI. Сергей сказал очень интересную вещь, что все можно свести к предсказанию. Но если все можно свести к предсказанию, то на самом деле любое предсказание можно свести к аппроксимации. То есть если у нас есть какой-то поток данных, какое-то множество данных, и мы можем это множество данных аппроксимировать какой-то функцией, то автоматически, если эти данные являются некоторой последовательностью во времени, и мы умеем аппроксимировать функцию любой размерности на временном ряду, то мы автоматически можем делать любые предсказания, поскольку у нас функция аппроксимирована. В t плюс 1 мы можем рассчитать значение этой функции. Соответственно, задача аппроксимации решается большим количеством способов. Есть исследования, которые показывают, что мы берем некоторый набор данных и применяем к нему различные методы. Логистическую регрессию, нейронные сети, аппроксимацию через ряды Фурье или полиномами. И выясняется, что для широкого класса задач проценты или accuracy или f-measure, связанные с тем, какой метод аппроксимации мы возьмем, влияют меньше, чем качество и объем данных. Грубо говоря, заменим логистическую регрессию на нейросеть, улучшим на 5 или 10 процентов, а возьмем более качественные, более объемные данные и там и там улучшим на 15 процентов. хочется все-таки говорить о том какие алгоритмы нам нужны для решения какого класса задач при этом опять-таки можно вспомнить что можно поговорить о том что определенные вот алгоритмические подходы они для широких классов задачи являются эквивалентными но опять-таки приведут как пример Из области не только геофизики, с которой я много лет проработал, но и медицине, пресловутая везде использующаяся сейчас сейсмическая томография. И она и в геофизике томографии, и в медицине томография, когда мы можем по множеству измерений на поверхности какого-то объекта восстановить его глубинную структуру. Вот здесь тоже есть большой набор методов, с помощью которых это можно делать. Какие-то методы более эффективны, какие-то менее эффективны. Есть методы, которые используют пресловутую свертку, обратную свертку, которая пространство измерения отображает на функцию, которую мы измеряем. А можно это решать методом, похожим на обратное распространение ошибки, когда мы подбираем структуру объекта примерно таким образом, каким мы подбираем сейчас коэффициенты связи нейронной сети для того, чтобы выходы этой нейронной сети удовлетворяли тем входам, которые мы подаем. То же самое, там это называется обратная проекция с коррекцией, здесь называется обратное распространение ошибки. Ну и, наконец, когда мы говорим о прикладных задачах, то вот пример, который я рассказывал, точнее, Бен Герцель рассказывал на AI Journey уже в позапрошлом году. Когда мы строили систему обучения без учителя на больших объемах, на неразмеченных корпусах, Мы обнаружили, что если, к примеру, использовать BERT, то с помощью BERT мы можем увеличить accuracy на 1% или на 2%, но для этого потребуется месяц обучения этого BERT на серьезном серверном оборудовании. строить модель на основе простого вычисления простой взаимной информации на биграмах, то мы на самом деле уменьшим точность на один процент, но это будет считаться за 12 или 20 часов на всем корпусе. Переходя, так сказать, Еще один момент. Я извиняюсь, я без презентации. На самом деле у меня слайды есть, но просто поскольку регламент поджимает, я потом кину ссылку на доклад как раз по нейросимвельной интеграции или по строению гибридных нейросимвельных систем, который я рассказывал на как это называется, на архипелаге НТИ. А вот сейчас я попытаюсь все-таки устно прокомментировать. Интересно, что если мы говорим опять-таки по алгоритмах решения задач, если мы возьмем, допустим, такую задачу, как аппроксимация временных рядов, допустим, с помощью преобразования Фурье, то мы знаем такую вещь, что можно на самом деле временной ряд перевести, превратить в спектр с помощью обычного преобразования Фурье, вычислив свертку этого временного ряда синусоидами различной частоты, И значение свертки с каждой из частот даст нам значение спектра для соответствующей частоты. А можно применить обратное преобразование Фурье. Что делает быстрое преобразование Фурье? Что делает быстрое преобразование Фурье? За счет многослойной архитектуры Она позволяет за один проход, не вычисляя множество сверток, отображать множество значений на временной последовательности, на множество значений амплитуд частот по всему спектру. То есть на самом деле мы начинаем от значений сигналов и собирая эти значения, складывая их и перемножая по различным уровням пирамиды, преобраза бабочки, преобразования фурье, мы постепенно переходим в спектральную область. На самом деле это преобразование по сути, с точки зрения решительной архитектуры, устроено примерно так же, как устроено многослойная нейронная сеть. Я это к чему говорю? Это я вот теперь подвожу к некоторой практике, к тем экспериментам по reinforcement learning, которыми я занимался в конце прошлого года. Про сами эксперименты, результаты я буду рассказывать как раз на OpenTox через неделю. Но я вот сейчас заострюсь на некоторых моментах. Какую задачу мы пытаемся решить? Давайте я переключусь к слайдам. Вот какую задачу мы там пытаемся решить. Вот у нас есть задача, которая выглядит примерно вот так. Всем, наверное, знакома эта история. Это пресловутый Atari Breakout. Нам нужно научиться играть, грубо говоря, в пинг-понг, когда самими собой отбивать падающий сверху мячик и умудряться делать так, чтобы этот мячик или шарик попадал в верхний ряд. Задача заключалась в том, чтобы попытаться посмотреть, а можем ли мы с помощью вот тех методов, про которые рассказывал Евгений Евгеньевич в предыдущей секции, в предыдущем блоке, решить вот такую задачу. То есть, можем ли мы, описав предикатами некоторую задачу. Вот у нас есть шарик, вот у нас есть ракетка, вот мы описываем предикатами координаты шарика, мы описываем предикатами координаты ракетки, и вот можем ли мы в пространстве этих предикатов решить задачу reinforced learning и научиться играть в пинг-понг. Оказалось, можем. То есть оказалось, что если у нас задача поставлена в терминах предметной области или онтологии, где есть шарик, понятие да, есть понятие ракетка, есть понятие право, есть понятие лево, Вот если у нас есть такая онтология и поставленная человеком задача агенту, он в рамках этой онтологии может научиться отбивать ракетку и получать больше счастья от того, что он отбивает мячик и не расстраивается, если мячик этот не будет отбиваться. Но тут совершенно справедливо можно заметить. Извините, но ведь тут-то мы задачу ставим. Какое разве это достижение научиться решать задачу, которую поставил человек? Хорошо мы говорим, а давайте мы опишем задачу агенту в терминах онтологии, где задача не поставлена. где элементами онтологии являются не ракетка, не шарик, а пикселы, расположенные на экране. То есть заменим нижний ряд, где расположена ракетка, просто некоторым облаком пикселов, и пространство, где движется шарик, тоже некоторым облаком пикселов, уже матрицей пикселов. То есть, на самом деле, нижний ряд пикселов будет представлять собой шарик, а точнее положение ракетки, где пиксел там ракетка, где нет пиксела, где пиксел не горит, там ракетки нету. Ну и то же самое с шариком. Там где есть пиксел в этом поле, там шарик, где пиксел выключен, там шарика нет. И вот это про такую антологию, если это можно назвать антологией, дадим на вход агенту. Выясняется, что точно тот же самый алгоритм, но в другом пространстве предикатов, в другой вот такой, так сказать, смешной онтологии, точно так же решается задача, причем та же самая скорость обучения. То есть ничего не меняется, меняются только вычислительные затраты, потому что тут у нас гораздо больше информации и тяжелее эту информацию перерабатывать. А дальше возникает интересная ситуация. Ситуация заключается в том, что мы берем и переключаем решение задач на реальное поле, переключаемся на решение задачи в виде когда у нас пикселов гораздо больше, когда у нас нету ракеток, когда у нас нету шариков, когда у нас наверху какой-то мусор, какие-то пикселы, которые соответствуют непонятно чему, что вроде как вообще никакого отношения не имеют, и нам надо как-то с этим быть. И когда мы начинаем эту задачу разбирать, мы на самом деле понимаем, что нам нужно две вещи, по большому счету. Во-первых, нам нужна на самом деле задача технического зрения, которая позволит нам просто тупо снизить вычислительные затраты. То есть на самом деле для того, чтобы обсчитывать такой большой объем данных и успевать делать предсказания с теми вычислительными ресурсами, которые у нас есть, нам нужно понизить размерность этой задачи в идеале для того, чтобы у нас был один пиксел соответствующий шарику, один пиксел соответствующей ракетки, а в конечном итоге преобразование, значит, к Вот такому редуцированному представлению, где у нас один пиксел на шарик, один пиксел на ракетку – это что называется one-hot encoding, когда у нас в том или ином значении вектора есть значение только по одной из координат. Это первое, что нам нужно. Второе, что нам нужно, нам нужно уметь эффективно вычислять близость между различными контекстами. То есть мы должны понимать, что если у нас шарик двигался, допустим, с левого верхнего угла в правый нижний, и мы его успешно отбили, то когда шарик двигается примерно в том же направлении, но по другой траектории, Мы не знаем этого контекста, мы никогда не были в нём, потому что у нас был другой контекст, у нас были другие пикселы. Но, тем не менее, мы должны понимать, что это похожая ситуация, и в этой похожей ситуации мы должны двигаться похожим образом. Так вот, как раз возвращаясь к статье, которую тут позавчера и вчера активно обсуждали про зрение, как устроено зрение у плодовой мушки и как его симулировать. Мы приходим к тому, что на самом деле нейронная сеть или алгоритм, соответствующий вот той нейронной сети, которая описана в этой работе, он является просто очень эффективным с вычислительной точки зрения аппроксиматором, который занимается выявлением похожих контекстов. Что такое нейронная сеть в данном случае? Нейронная сеть может выступать как эффективный аппроксиматор, когда мы работаем с данными большой размерности. Нам нужно выделять конечное число, небольшое число похожих ситуаций на большом объеме исходных данных. и второе что нам нужно это нам нужна система которая позволит понизить размерность вплоть до того что мы сможем выделить конечное число объектов и работать с ними уже как символами потому что после того как мы сказали что у нас на экране есть только шарик и только ракетка, мы работаем дальше с ними и мы можем эффективно их обсчитывать, аппроксимировать их координаты и применять методы алгоритмической аппроксимации, которые являются гораздо более дешевыми и гораздо более эффективными, чем попытка с помощью свёртки находить знакомые ситуации. Соответственно, гипотеза, которую я хочу сказать, и идея, которая мне нравится, эта идея на самом деле не новая. Я тут перехожу обратно к слайдам. Эта идея была высказана товарищем Марвином Минским. что на самом деле у нас мышление и когнитивные процессы, они у нас являются иерархическими, на самом деле не иерархическими, а хитерархическими, потому что у нас есть хитерархия, у нас один и тот же, так сказать, поток, одни и те же, так сказать, когнитивные процессы, которые происходят на нижнем уровне, они могут относиться к различным когнитивным процессам на верхних уровнях. То есть, грубо говоря, одни и те же изображения, которые мы видим глазами, они могут соотноситься с разными сферами предметной… разными сферами деятельности, разными объектами, разными задачами. То есть я могу видеть одними и теми же глазами, одновременно могу видеть и лес за окном, и компьютерную презентацию на экране и относиться к ним по-разному. Но на верхнем уровне у нас всегда все-таки в той или иной степени происходит мышление символьное, хотя бы потому, что мы в конечном итоге соединяем логические последовательности и мыслим в терминах логических последовательностей, в терминах тех программ, которые мы должны выполнить или как мы должны совершить. Причем на самом деле это связано не только с тем, что мы должны объяснять схемы своего поведения, или программы, которые должны выполнять совместно другим людям. Это связано в том числе и с тем, что некоторые задачи, они просто в силу своей сложности и многосвязности не могут выполняться интуитивно. Представим себе, что нам нужно написать компьютерную программу. Можем ли мы написать компьютерную программу, нейронной сетью, не прибегая к понятиям if-then-else. Когда мы пишем if-then-else, мы понимаем, что у нас есть условие и есть операция, которая выполняется как результат выполнения этого условия. Мы все-таки строим некоторые логические связи и оперируем в терминах этих логических связей. Более того, мы вынуждены, совершая эти действия, в явном виде символизировать этот процесс, выписывая эту программу на бумагу. И на самом деле, даже если мы не выписываем эту программу на бумаге, а у меня есть хороший пример, у меня есть один знакомый, который в свое время, отправившись на службу в армию, получил задание из своего института, где он работал, срочно оказалось нужно написать программу, для решения задачи, которую мог решить только он. А это был, значит, там какой-то 80 какой-то год, никакого имейла тогда не было, мобильных телефонов не было, человек был в армии, но вот в институте нужно было написать задачу для программы на фортране, для задачи, которую мог решить только он. Он, стоя ночью в карауле, написал эту программу в уме, Вот, потом придя с караула, он записал эту программу на фартера, а не на бумаге, вот, значит, отправил это по почте в институт, и в институте эту программу перебили на перфап-карты, запустили, программа заработала. Вот, так сказать, процесс был символьный, процесс был логический, процесс был связан с оформлением некоторых логических схем в виде того, что вот товарищ Минский называет narrative stories, и соединяющие между собой несколько трансфреймс, а уже дальше, значит, на нижних уровнях они могут быть действительно представлены распределенными распределенными представлениями или Distributed Representations. Что я хотел сказать, что да, нейронные сети в том или ином виде являются эффективными алгоритмическими решениями. вот с одной стороны с другой стороны объяснимость она необходима по той причине что сказал Евгений Евгеньевич то есть у нас часто есть задачи когда ну без объяснимости нельзя да ну мы не можем там грубо говоря когда сбили не тот самолет не можем не можем решить проблему избегать сбивания другого самолета тем, что просто начнем лихорадочно искать какие-то данные, которые мы должны скормить для нейросети, которая управляет ракетным комплексом. То есть мы должны понимать, почему было принято решение сбивать этот самолет, что нужно исправить для того, чтобы этот самолет не сбивать, и верифицировать, что правила, которые эта нейронная сеть восприняла в результате корректировки, они исключают возможность повторного сбивания этого самолета. то есть это необходимо вот и это не только потому что ну и ну вот да то есть объяснение в ряде задач необходимо ну такая сбивчивая сбитая концовка но в общем наверное будем считать это вот таким комментарием спасибо спасибо 

S04 [01:36:40]  : Плавно переходим тогда к общей дискуссии, панельной. Коллеги, пишите вопросы в чат, пожалуйста, пока я позадаю сам. Собственно, первый вопрос будет ко всем участникам дискуссии, и я даже предлагаю ответ на этот вопрос делать обязательным, как вступление к докладам. которые в нашей тусовке делают, потому что, во-первых, это проясняет позицию спикера максимально подробно, во-вторых, уменьшает количество вопросов от слушателей. Вопрос простой. Что такое AGI? То есть я прошу сейчас каждого дать определение свое по возможности избегать абстрактных терминов и больше прибегать к примерам из земной жизни, как-то робот, собирающий кубик Рубика, это узкий AI, а робот, собирающий мебель из IKEA по неизвестной заранее схеме, это уже AGI. Или нейросеть, пишущая поэму, это узкий AI, а AI, пишущий научную статью в коллаборации с коллегами, людьми, да, это уже AGI. Вот как-то в таком стиле, пожалуйста, кто хочет сказать. 

S03 [01:38:04]  : Давайте я скажу, я не успел микрофон отключить. В моем понимании четкой границы между AGI и не AGI нет. Она начинается с того момента, когда некоторая система может решать задачи которым она не была заранее обучена. То есть, если у нас есть система, которая была обучена или сконструирована решать задачу А, а ей потом говорят, а теперь решай задачу Б, если эта система эту задачу может решить, то уже можно сказать, что она, так сказать, чуть-чуть, как минимум чуть-чуть AGI. Дальше у нас могут быть разные нюансы, связанные с тем, что насколько задача B отличается от задачи A. Может быть, она не очень отличается. Вот если она не очень отличается, если задач таких B немного, то есть, грубо говоря, если система может решать задачи B и C, которые где-то походят на задачу A, У нас получается то, что Бен Гёрцель называет Narrow AGI, да? А если система решает любые задачи D, E, F, G, S, вплоть до X, где они не имеют никакого отношения к задаче A, то мы имеем вообще, безусловно сказать, совершенно универсальный, бесконечно универсальный искусственный интеллект. Поэтому вот первое, это, значит, границы, насколько он General, они плавные, да? Вот, то есть генерализация и она может быть большая, может быть маленькая, это с одной стороны, но главным является то, что действительно система должна иметь возможность решать задачи, для которых она не была приспособлена. Вот как, так сказать, в моем предыдущем докладе человек, который был приспособлен для того, чтобы бегать за животными, может научиться танцевать танцы, а потом может научиться кататься на горных лыжах и на кайтах, и даже на сноуборде, хотя как бы эволюционно он был для этого не предназначен. 

S01 [01:40:02]  : Можно я отвечу? Я имею в виду способность решать достаточно широкий вопрос. круг задач. Но в этом случае как раз задачный подход является достаточно широким. То есть если мы можем осмысленно сформулировать задачу, что мы хотим, и при этом обязательно мы должны задать критерии. Если мы это хотим, то как определить, мы это достигли или нет, это необходимые условия этой формулировки. Кроме того, задача решается в некоторой предметной области, и это описывается в некоторой онтологии. Так сказать, те вариации задачи, которые есть в этом определении, это как бы необходимый набор условий для того, чтобы смысленно что-то делать. Вот ширина круга задач или ее узлость, она на самом деле определяется тем, что если мы берем очень широкий круг задач, то в этом случае эти спецификации, они будут неэффективны. То есть алгоритм будет очень сложный для эффективного решения этих задач. И у нас есть специально отдельные результаты, где можно доказать, что вот такой-то класс задач решается за полиномиальное время, а вот такой-то там положим с помощью дельта-ноль формы. То есть есть еще некая классификация языков спецификаций, которая решает более узкий или более широкий круг задач. Единственное, что я хотел бы добавить, что на самом деле сейчас выпускаются из внимания так называемые киберфизические системы. Киберфизические, это значит, например, есть большое производство, в них есть датчики. Все-таки датчики, их можно считать сенсорами, Они могут, так сказать, либо непосредственно измерять некоторые физические величины, либо могут использоваться небольшие нейронные сети для того, чтобы что-то дополнительно посчитать. Но в целом, так сказать, это вот некоторая система управления, которая может контролировать, например, в режиме онлайн, как это делается, например, в теории функциональных систем, в режиме онлайн контролировать производство, причем с соблюдением его эффективности. На самом деле более общая задача – это киберфизические системы. И мне кажется, их почему-то не формулировали, но самая общая задача EGI – это киберфизические системы, основанные на задачном подходе. 

S04 [01:42:21]  : Спасибо. Сергей, есть что сказать по этому поводу? 

S05 [01:42:24]  : На самом деле довольно трудно тут что-то добавить. Но все-таки определение все-таки уже более-менее устоялось. Это система искусственного интеллекта, которая способна решать широкий круг интеллектуальных задач. Понятно, что универсальность здесь понятие количественное. и поэтому можно говорить о разной степени универсальности той или иной системы. Но здесь понятно, что у нас есть эталоны для человеческий интеллект, и в целом все наши терминологические пляски вокруг понятия искусственного интеллекта и различных его разновидностей – это, по сути дела, Неблагодарное занятие, потому что у нас есть один как бы бесспорный прецедент, на основе которого мы пытаемся выстроить какое-то множество, и множество это можно достаточно произвольно выстраивать. То есть можно построить какое-то очень узкое определение, которое будет таким образом сконструировано, что кроме человеческого интеллекта ничего под ним не подойдет. взять какое-то очень широкое определение и, соответственно, у нас там и мухи, и котлеты, и все попадет туда же, в этот же класс. Поэтому здесь, допустим, и основатели этого направления в лице с Юрингом и отчасти на карте, которая тоже была близок к Юрингу в своих взглядах, они к этому подходили больше функционально. устраивать функциональные тесты и показывать, что система эквивалентна. Вообще, сама идея теста Тьюринга очень хорошо вложится в общую канву его исследований в 1930-е годы и исследований других математиков, которые занимались проблемой эффективно. Определение того, что такое эффективно вычислимая задача. В 20-е годы или раньше математически говорили эффективно вычислимая задача, подразумевая такую задачу, которую человек может за конечное время решить, обладая бесконечным количеством бумаги и карандашей. Как формально определить эффективно вычислимую задачу? исследования Гёделя, они пробудили к жизни вот эту гонку среди математиков в 30-е годы, когда Чорч предложил лямбда-исчисление, его ученик Линни показал, что лямбда-исчисление не свободна от ограничений Гёделя, потому что дело не только в теории типов, как думал Чорч, рекурсивно-транситивной грамматики к линии, потом машина Тьюринга, потом в 1938 году было показано, что эти все определения взаимно эквивалентны. И, собственно, принцип слабой эквивалентности или тюринг эквивалентности, как мы называем, когда мы говорим, что две машины эквивалентны, если машина A может симулировать работу машины B, машина B может симулировать работу машины A. И в этом смысле в основу теста тюринга положен тот же самый принцип, принцип слабой эквивалентности системы человеческому интеллекту. И здесь я боюсь, что какой-то более хороший критерий, мы можем пытаться усложнять определение, добавлять к нему какие-то еще дополнительные формальные критерии, но я боюсь, что радикально улучшить ничего не получится. И нужно, наверное, ограничиться тем, что мы говорим о универсальной системе, способной решать широкий спектр интеллектуальных задач. а уже там в конкретных испытаниях ориентироваться на процедуры, похожие на процедуры, предложенные Кириллом. 

S04 [01:46:13]  : Спасибо. Я, конечно, попросил как можно меньше абстракции, но минимальная абстракция будет у меня на выступление OpenTalks. Приходите, это еще одна реклама для Игоря. И тем не менее, значит, Олег Варламов спрашивает, у него даже два вопроса здесь. Можно ли заниматься искусственным интеллектом, не рассматривая, как устроены нейроны? Как пример, самолеты крыльями не машут, но летают лучше птиц. И тут же как бы с противоположной точки зрения, или без предикатов, а только на продукциях, если то, можно ли заниматься и это скорее всего вопрос к представительным нейросимвольным стороны. 

S03 [01:47:00]  : Можно я попробую ответить, поскольку я уже начал отвечать в этом самом в чате. Значит, смотрите, вот как раз тезис моего заказа, то что я говорил, что мы можем попытаться начать решать, строить искусственный интеллект, не прибегая к нейронным сетям, Но в какой-то момент мы обнаруживаем, что в некотором случае нам приходится изобрести алгоритм, который окажется в нейронной сети. Вот, например, если нам нужно на задачах, требующих зрения, машинного зрения, например, игр в Atari, на OpenGM. Если нам нужно определять близость контекстов, то лучше, чем нейронная сеть с точки зрения чисто вычислительной эффективности. Но я не знаю, что это может сделать. Вот это первый ответ. Ответ на первый вопрос. А второй ответ на вопрос из той же области. Вот смотрите, что такое reinforcement learning в простейшем представлении. В простейшем представлении reinforcement learning позволяет научить систему узнавая конкретную ситуацию, конкретный контекст, в котором система научилась, предпринимать некоторые действия. Таким образом, модель reinforcement learning, которая находится внутри сети в том или ином виде, Содержание модели для любой задачи Reformed Learning это именно система правил. Если у меня пресловутый шарик находится в центре и движется в левый нижний угол, мне нужно двинуть ракетку в левый нижний угол. Если вы с помощью ваших продукций можете описать задачи любой из игр, которые представлены на OpenGem.ai или в какой-то другой области. Например, если вы можете задачу, которую решает BERT или GPT-3 в предсказании последовательности, если вы можете написать продукцию, если первое слово шумел, второе слово широко, третье слово брянский, то нужно добавить слово лес. То есть, если вы можете это описать в своей продукции, то, конечно, вы можете с помощью продукционной логики решать эту задачу. Попробуйте. Попробуйте перебить, сделать то же самое, что делают BERT и GPT-3 с помощью продукционной логики. Вдруг получится. И будет более эффективно, и жрать меньше ресурсов. 

S04 [01:49:30]  : Спасибо. Владимир Смолин, судя по всему, опять нейросимволистом. Вопрос. Хотелось бы послушать про процедуру выделения новых понятий для символьной сети агенты AGI в незнакомой ситуации. Это, видимо, вот если, Евгений, взять ваших мышек и поместить их в Super Mario, чтобы они вместо сыра начали прыгать через препятствия. Как адаптироваться будет? Ну, не обязательно вам вопрос, тем не менее. 

S01 [01:49:59]  : Но они адаптироваться могут как? То есть вот у них есть какие-то правила. Они, положим, в одном месте обучились. Они будут пытаться их применять. Но правила же, они очень быстро, так сказать, будут модифицироваться. То есть адаптация будет проходить достаточно быстро. Где-то это правило правильно сработает, где-то нет. Вот они тут же будут корректироваться автоматом. То есть вот то определение нейронов, которые мы используем, Оно делает так, что правило автоматическое, лишние свойства будут удаляться, новые добавляться. То есть оно адаптируется достаточно быстро. Я не знаю, насколько это будет сравнимо с нейронными сетями, но для правил, я думаю, это будет достаточно быстро. 

S04 [01:50:44]  : Спасибо. Ну тогда хорошо, я тогда задам вопрос от себя. Вопрос прежде всего конъюнкционистам, но, наверное, и миросимволистам тоже. Вот недавно читал, перечитывал Гарри Маркуса, вашего однофамильца, его статью «Deep Learning Critical Appraisal» и в качестве одного из примеров слабости нейросети и там приводится невозможность интеграции априорных знаний в модели deep learning ну и вообще другие архитектурные тоже это все является нерешенной задачей к примеру знаете есть виртуальные среды и там агенты учатся совершать целевые действия вот например есть шарик который нужно бросить совершают какие-то действия при падении. и нужно научиться правильно выбирать его позицию, чтобы при падении он совершил нужное действие. среда такая fire. таким образом вроде бы он учится гравитации, импульсу и другим вещам из физики и здравого смысла. теперь нам нужно эти знания допустим перенести в языковую модель. так чтобы мы задали вопрос в стиле винограда шарик подлетел, стукнулся в потолок, потом он упал. он, это шарик или потолок? каким образом возможно в принципе осуществлять такой трансфер? вообще возможно ли? какие есть подходы? 

S05 [01:52:20]  : мне кажется, что очень многие претензии, которые предъявляются к кондиционистским моделям, в основном они проистекают из незнания конъекционистских исследований на эту тему. И вот в этом плане, кстати, дискуссия Гарри Маркса с Бенджио, она показательна. Я советую, мы, кстати, транскрипт, по-моему, публиковали на 22 веке в свое время, и перевод на русский язык. Здесь штука в том, что всякие разные мультимодальные задачи, они в глубоком обучении исследуются хорошо. выравнивания фичей, относящихся к разным модальностям. Но это задача, которую там активно и неплохо решают еще с 2014-го, с 2015-го года в рамках мультимодальных кондиционерских моделей. Вот сегодня я показывал пример той же самой модели в Дали, которая, как мы видим, достаточно абстрактное понятие, способное с конкретными визуальными фичами связывать. вот и здесь мне кажется что некая такое есть момент стука в открытую дверь вот как кстати вот и насчет объяснимости тоже существует много работ по объяснимым коннекционистским моделям и по интерпретации коннекционистских моделей начиная там от визуализации, активации сверточных ядр, чтобы выявить, на какие конкретно визуальные признаки реагирует сеть, заканчивая всякими более хитрыми штуками, типа когда используют модель, предназначенную для перевода, для того чтобы перевести фичи из сверточной сети на рассматривают это как некий язык, с которого мы выполняем перевод на естественный язык человеческий, и решают это так же, как задачу машинного перевода. То есть, на самом деле, здесь идей и наработок в этом направлении довольно много. То есть, нужно смотреть конкретно, какая задача, и наверняка под нее найдется какое-нибудь исследование конъюнкционистское, эту задачу решал, но и дальше нужно смотреть, насколько хорошо. Здесь мне кажется, что если есть какие-то модели, которые работают лучше, чем конъюнкционистские, а такие на самом деле задачи есть, в которых конъюнкционистские модели пока работают хуже, чем символические. Но количество таких задач довольно быстро сокращается. Еще два года назад кто-нибудь мог сказать, что какой-нибудь вывод теоремы не может делать нейронная сеть. Сегодня мы видим, что может. Ничего плохого с ней не происходит. Поэтому, мне кажется, тут проблемы нет. И вот у меня призыв, наверное, такой к тем, кто развивает какие-то альтернативные подходы к конъюнкционистскому. Но я-то тоже, опять же, меня как-то принято представлять каким-то таким конъюнкционистом. Я хочу сказать, что большей частью своей жизни я работал с символьными методами. И мой самый большой хобби-проект – это шахматная программа SmartInk, которая вполне себе, так сказать, GoFi. Нужно просто пробовать решать задачи. Слава богу, сейчас разработано много наборов тестов, то есть и на Intel, пожалуйста, Superglue, каком-нибудь Russian Superglue, там хорошие наборы тестов, большие. Давайте пробовать альтернативные модели нейронкам, смотреть, сравнить по метрикам. Казалось бы, чего проще, если есть какие-то альтернативы хорошие. изучать и сравнивать с тем, что есть на каких-то активных тестах. 

S04 [01:56:33]  : Так, коллеги, пишите вопросы. 

S03 [01:56:38]  : Я задам вопрос Сергею Маркову. Сергей, а вот такой вот вопрос. С вашей точки зрения. Все мы помним такой успех символьного искусственного интеллекта IBM Watson. Победа в игру. геопарди, которая была построена на N-Gram. Вот как вы полагаете, если использовать ту же самую технологию IBM Watson на N-граммах, которая использовалась для Geopardy, и накормить его таким же объемом данных, которые мы накормили BERT и GPT-3, и дать ему те же самые вычислительные мощности, которые есть у GPT-3 и которые использовались для Берта, смог бы, насколько бы соревновательным были бы предсказания IBM Watson? 

S05 [01:57:46]  : Да и не были бы соревновательными. Есть же куча бенчмарков, есть соревнования языковых моделей. То есть начиная от N3 банк и заканчивая много чем еще. Долгое время использовали гранные модели, всякие скрытые марковские модели и так далее. Но когда появились современные нейронки, там конечно в топе не осталось этих моделей. Это хорошо известно, что н-граммные модели не тягаются с нейронками на таких вот задачах. Но тут еще штука в том, что Вот опять же, если вы посмотрите на GT3, это вроде как коннекционистская модель, но реально-то за ней стоит токенизатор. Токенизатор, модель символьная. Причем в современном GT3, если вы посмотрите какие токенизаторы используются, это BVPE токенизатор. он на самом деле строит такой квази-оптимальный алфавит токенов для описания гигантских текстов в последовательности. Это сам по себе довольно интересный алгоритм, и от качества токенизации довольно сильно зависит потом результат коннекционистской модели, которая работает с этими токенами. Поэтому, допустим, сейчас многие исследования в плане увеличения метрик каких-то точности трансформерных моделей, это в том числе исследование более продвинутых текинизаторов. И там вот самое раздолье символьным методам. И на самом деле жалко, что мне кажется, что можно было бы туда привлечь больше внимания исследователей, тем более тех, кто символьным подходом занимается, потому что там есть куда применить достижения символьных методов. Поэтому здесь, конечно, если мы говорим про энграмы, в 2003 году, когда Бенджио начинал делать свою векторную семантику, На самом деле сетка прогнозировала не слово, а она прогнозировала разницу между прогнозом н-граммной модели и типа ground truth. То есть он как бы делал сразу нейросимвольную модель, то есть у нее была н-граммная модель, а над ней надстройка была, которая уточняла ее прогноз. но сейчас уже так не делают, потому что смысла нет и нейронка сама может быть точнее гораздо. но начиналось все с такого подхода. поэтому там на самом деле никакого противоречия особого нет. а так вот зайдите в любые есть лидерборды по языкового моделирования. И там вот очень хорошо видно, какая мощность у N-граммных моделей, даже очень большие. То есть, пожалуйста, там N-граммы, где N равно 7, есть N равно 9, то есть там люди делают... Ну, как бы у них проблема в том, что они довольно быстро начинают именно запоминать и типа хуже обобщаются, да, то есть оказывается, что у них точность растет на трейне, но она на тесте падает, да, нейронка, она лучшими обобщающими обладает способностями, чем инграммная модель. 

S04 [02:01:23]  : Спасибо. Евгений Бабарыкин хотел голосом спросить. Евгений? 

S01 [02:01:39]  : Его микрофон выключил. 

S04 [02:01:44]  : Евгений, справитесь с микрофоном или можно пока следующего спросить? 

S03 [02:01:50]  : Он пишет, что у него нет микрофона, а там вопрос еще Алексе Сергею Маркову. Мозг родившегося ребенка уже имеет все связи или ребенок выстраивает их с чистого листа? 

S04 [02:02:03]  : Ну да, я вопрос увидел, просто он странный немножко. 

S05 [02:02:06]  : Ну, понимаете как, конечно, все связи он содержать не может, просто это арифметически, да, это еще Норберт Виннер писал, что вот смотрите, информации столько нет в геноме, чтобы закодировать все там синаптические связи. Поэтому нет, конечно, все связи нет, более того, Мы знаем, что в процессе жизни человека происходит до какого-то времени увеличение количества синаптических связей, а потом начинается активный синаптический прунинг, и у взрослого человека меньше синаптических связей, чем у ребенка оказывается. Формирование связей в мозге — это, в общем, тоже процесс такой вполне себе управляемой кондициацией долговременной, то есть прорастание дендритных шипиков. Оно происходит под влиянием мозга. Изначально, можно так сказать, крупномасштабная архитектура мозга генетически обусловлена. Ну там, структура крупномасштабная мозги, что у нас вот такие есть отделы мозга, вот такие-то там крупные проводящие пути существуют, вот такие-то клетки, такие-то белки экспрессируются, ну и так далее. Отдельный элемент крупной архитектуры, они наследуются. Что касается всех там связей по отдельности, то, конечно, это уже происходит при активном взаимодействии со средой. Поэтому вот, не знаю уж насколько я ответил на этот вопрос. 

S01 [02:03:41]  : В теории функциональных систем это специально исследовано. То есть, например, лосенок, который только что родился, у него нет никакого опыта, но у него есть четыре стимула, которые он стремится достичь. Первое – это встать в вертикальную позу, и у него есть специальный рецептор, который фиксирует, что он эту цель достиг в результате случайных своих колебаний и действий. Второе – это следование за матерью. Еще один целевой параметр – следование за матерью. Третий целевой параметр – это найти сосок. Четвертый – сосание. То есть у него нет опыта, но у него есть четыре целевых параметра, которые он достигает методом пропущения. Он может это сделать в силу своего строения. 

S04 [02:04:28]  : Сергей Терехов хотел спросить. 

S03 [02:04:30]  : Можно я еще чуть-чуть добавлю к этому вопросу. Если мы возьмем систему решения задач, типа той, про которую я рассказывал, или то, что есть на OpenGMI для игр отариевских, Эти задачи в основном состоят из двух уровней. Когнитивная архитектура для решения этих задач состоит из машинного зрения на входе и системы принятия решений для Reinforced Learning на выходе. Так вот, у детей и у людей система зрения и связи на входе, которые занимаются зрением, то есть те механизмы, которые позволяют распознавать движущиеся объекты и определять их координаты, на основе которых уже ребенок учится эти шарики ловить, хватать и бросать. Эти все связи в зрительном тракте, они уже есть от рождения. И уже используя вот эти низкоуровневые связи, данные от рождения ребенок учатся высокоуровневым функциям. 

S04 [02:05:48]  : Все, Сергей, теперь точно Ваша очередь. 

S02 [02:05:52]  : спасибо большое очень было здорово слышать меня да будем докладчиком ну антон вы тоже так ласчик но я беду к фиг и 

S04 [02:06:19]  : со связью там произошел сбой. Виктор Казаринов спрашивает. А, нет, вот уже Сергей включился обратно. 

S02 [02:06:33]  : Прошу прощения. Вот какой вопрос у меня разный, к разному докладчику. Поскольку Евгений Евгеньевич только что отвечал, я вот тогда, с вашего позволения, Сергею задам вопрос сначала первый. Сергей, вот такой вопрос. Вы говорите, что вот не видно пока каких-то ограничений и как бы вот не видно, что они там возникнут. Но вы на самом деле неявно назвали такое одно ограничение. Это те самые 300 терабайт текста, которые мы сейчас имеем. И маловероятно, что мы осмысленно его как-то существенно за какое-то время увеличим. Вот вопрос вот какой. Известно на примере, например, поисковых систем там Яндекса и других. мере того, как эти системы начали все больше и больше охватывать тематики, все больше и больше пользователей, они начали глупеть. То есть сейчас в поисковой системе получить профессиональный ответ на какой-то принципиальный вопрос очень трудно. Все время будет выдаваться вам реферат на уровне шестиклассника. То есть из-за того, что объем информации, которую они собирают, включает в себя вот тот огромный хвост, так сказать, шестиклассника, они начинают мыслить на уровне вот этого самого шестиклассника. Не придет ли вот эта вся тенденция к тому, что система действительно будет все знать, но будет все знать на уровне вот того массового объема текстов, который на самом деле, так сказать, вот этот самый шестиклассник. Пока вы размышляете, я тогда вот Евгению Евгеньевичу тоже задам вопрос, чтобы он тоже мог размышлять, когда вы будете отвечать. Вам вопрос вот какой. Вот уже упоминался Гарри Маркус и в команде, которая там участвует потом в обсуждениях и потом было замечательно организовано Маркусом в новогоднее время там совещание. Там участвует такой замечательный человек, один из старейших таких классиков Джуди Пирл. Джуди Перл, наверное, вам известный человек, который много-много занимался вопросами вот каузальных, так сказать, мышлений системы и так далее. Вот его возражения, его комментарии, вернее, он мягко говорит, его комментарии, они вот какие. Есть контрафактическое мышление. То есть, когда вы мыслите, а что было бы, вот при условии, что сейчас у меня есть то, что сейчас есть, правила описывают то, что я сейчас знаю, вероятности поставлены вот в этой фактической, фатологической ситуации, а теперь у меня есть контрафактическая, мыслительная, параллельная вселенная, та, которая не существует, той, которой не было, и я в этой параллельной системе делаю контрафактическое рассуждение. Вот проблема в том, что в том контрафактном, контрафактическом состоянии у меня нет никаких вероятностей. У меня там чисто мыслительная такая деятельность. Как ваша схема может в этом случае справляться с этим контрафактическим мышлением? Я сразу скажу спасибо, потому что, значит, за ответы, которые, надеюсь, будут очень содержательными и интересными. Спасибо. 

S01 [02:09:23]  : Да, но дело в том, что вот в понятии задачи там используется и вероятность нового ИК. и дедуктивная логика. Поэтому такие высказывания можно мыслить или делать некоторые предположения, и потом из этих предположений делать какие-то выводы. То есть мы можем перебирать предположения, но это уже используется не вероятность, а конечно же используется чисто дедуктивная логика. 

S04 [02:09:57]  : Вторая часть вопроса была у Сергея Маркова. 

S05 [02:10:01]  : На самом деле я, во-первых, не согласен с каким-то углублением. Скажем так, обычно поисковая система довольно быстро подстраивается под релевантность тех или иных ответов для вас конкретно. То есть вот я сейчас, если в гугле что-нибудь ищу, я как раз вижу, что он находит гораздо лучшие результаты, чем там 5 лет назад или 10. Конкретно то, что мне нужно, он находит. То есть он уже знает, какие источники я считаю, так сказать, более качественными. И поэтому их в ранжировке мне выше ставят. То есть в этом плане как раз технологии машинного обучения, они в какой-то мере являются нашим спасительным кругом в условиях экспоненциально растущих объемов информации, которые человечество вполне себе генерирует. Скорость роста — это довольно интересный момент. темпы роста объемов информации, которые человечество накапливает, они экспоненциальны. То есть, по крайней мере, последние 10 лет тренд таков. А, конечно, ограничение в количестве данных оно есть, это верно, но, с другой стороны, никто нам не запрещает использовать всякие разные кибридные подходы с генерацией данных и получением сигнала обратной связи. Опять же, то есть вот что мы видим, например, в случае GPT-3. GPT-3 видела там много всего разного, а ISO сам шиб. то есть она там и художественную литературу читала, и читала какие-то там несерьезные сайты, соцсети и всякую разную чепуху. Но как бы вы ей даете затравку, если эта затравка написана там научным языком, строгим, то она в том же стиле вам продолжает. 

S02 [02:12:04]  : Она на уровне журналиста, она отвечает мне на уровне журналиста, понимаете, не на уровне ученого, а на уровне журналиста. 

S05 [02:12:11]  : Это разные вещи. Как определить уровень ученого, уровень журналиста? 

S02 [02:12:16]  : Уж поверьте, могу. 

S05 [02:12:19]  : Ох, не знаю. Разные бывают ученые, разные бывают журналисты. Понятно, что GT3 это не универсальный искусственный интеллект, не надо здесь, как говорится, строить иллюзии, но тем не менее я к тому, что эта модель довольно хорошо внутри своей структуры кластеризовала те источники, которые она видела. В этом плане она хорошо умеет стилизовать генерацию текста под специфику того или иного источника, и в этом смысле Есть надежда, что мы, управляя стилем генерации, сможем получать те результаты, которые нам будут нужны. Модель это может делать. Модели будущего будут еще более сильны. Здесь в какой-то момент будем вынуждены прибегать либо к аугментациям каким-то, старый испытанный способ, который в глубоком обучении используется, вносить такие, трансформировать определенным образом данные обучающие выборки, чтобы увеличить количество. Будем использовать reinforcement, то есть будем выпускать такие модели, что называется, в свободное плавание и собирать обратную связь по результатам взаимодействия с другими агентами. Плюс человечество дальше продолжает генерировать тексты. Вот три источника, три составных части расширения этого горизонта, они вот такие. 

S04 [02:14:08]  : Спасибо. Борис Новиков спрашивает Евгения Веттяева. Для прогресса нужно уточнить постановку задач. Нужно различать интеллект и сознание. Интеллект работает внутри заданной модели, а сознание создает и использует модели реальности для взаимодействия с ней. Так что желательно создавать? ИИ или ИИС? 

S01 [02:14:29]  : На самом деле и то, и другое. Фактически речь идет о том, что ИИ – это узкий искусственный интеллект, который в состоянии внутри решать вполне определенные задачи, настроившись на нее. Но сознание предполагает решение задачи на основе некоторой модели мира. Не всякий искусственный интеллект способен создавать такую модель мира. То есть, для этого нужна еще определенная техника, что мы сначала создаем модель мира, а потом внутри нее решаем задачи. Но такие методы тоже есть, в частности, эта формализация, которую я предлагаю, она может создавать себе модель мира. Борис Новик, видимо, не согласен. Можно ответить? 

S00 [02:15:20]  : Можно? Можно, можно. Я убежден, что сознание связано с телом, с организмом и работает для его блага. Вне заданной заранее модели. Кроме одной, что нужно выживать и оставить потомство. То есть общебиологическое. А все остальное сознание – часть психики, психика – это часть функций организма, нацеленная на вот эти две цели. И никакой заданной заранее модели, то есть когда сказано, чем можно пренебречь, а чем нельзя пренебречь, а это главное свойство любой модели, что выделяется нечто существенное, а всем остальным можно пренебречь. Сознание, создавая модели, выделяет, чем можно пренебречь, а чем нельзя. А когда модель задана, то уже почти всем пренебрегли, оставили очень немного существенного. И благодаря этому с моделью можно работать на предсказаниях. А с досконечно сложной реальностью на предсказаниях работать нельзя. 

S01 [02:16:34]  : Я не совсем понял, но то, что сознание связано с телом, это очевидно предполагается. Сознание создает образ мира, но когда оно решает совершенно конкретную задачу, оно ориентируется и организуется вниманием. Вот почему, в частности, Анохин говорит, сознание различает разум и сознание. Разум – это весь опыт, который мы имеем, а сознание для решения конкретной задачи, оно выбирает определенный фокус, определенную цель и организует, так сказать, необходимую информацию для решения вот этой конкретной задачи, это организуется внимание. 

S00 [02:17:18]  : Задача возникает в конце цепочки, а сначала возникает потребности тела и модели, в языке которых ставится задача и определяются критерии. То есть, чтобы поставить задачу, нужна модель. Поэтому у меня был вопрос. Ваша теория относится только к математическим задачам или к задачам поведения субъекта, человека или агента в реальности? 

S01 [02:17:50]  : Дело в том, что теория функциональных систем в точности решает эту задачу. А математическую модель функциональных систем я очень коротко показал. 

S00 [02:18:00]  : Которую задачу решает теория функциональных систем? 

S01 [02:18:05]  : Не понял, что? 

S00 [02:18:06]  : Какую задачу решает теория функциональных систем? 

S01 [02:18:10]  : Потребность – это есть задача для организма. И эта задача удовлетворения потребностей как раз организм решает. 

S00 [02:18:18]  : Вот ведущий, господин Колонин сказал, что у него будет доклад. Ребята, давайте жить дружно. Это задача? Или сделать хороший прогноз погоды, это задача? 

S01 [02:18:32]  : Хорошая прогнозовая задача, но должны быть критерии. Вот, когда мы решим, если мы будем говорить То ли будет, то ли дождик, то ли снег, то ли будет, то ли нет. Это не задача, потому что у нее нет критерий. 

S00 [02:18:43]  : В жизни нет четких критерий. Хороший – это значит лучше, чем мы получали вчера. То есть вероятность прогноза по осадкам, скажем, была 50%, стала 80%. Сегодня это хорошее решение. А завтра – это плохое. Завтра уже нужно 90%. Поэтому нет такого соотношения задачи и решений, как ключа к этой задаче. В жизни задачи не ставятся один раз навсегда, они динамические. 

S01 [02:19:19]  : Нет, если нет критерий, то задача просто бессмысленна. Потому что если нет критерий, можно считать, что она уже решена. 

S00 [02:19:27]  : Это в математике бессмысленно. сделать доказательство теоремы, если нет критерия доказал или не доказал. А в жизни мы всегда живем в таких условиях, что мы делаем что-то удовлетворительно, а не единственно правильным способом. 

S01 [02:19:49]  : А что значит удовлетворительно? Это в конце концов тоже должно быть определено. Нет, это не определено, это эмоция. Это должно быть определено. Вот у человека есть такая, так сказать, потребность новизны. Потребность новизны – это тоже очевидная потребность человека. И он всегда точно определяет, он ее удовлетворил, то есть он получил что-то новое или нет. Даже наиболее общих, так сказать, потребностей всегда есть критерий. 

S00 [02:20:14]  : Нет, если он получил что-то новое, это не значит, что он решил задачу и что у него пропала потребность новизны. У него она осталась. Какую бы новизну он не получил, он все равно хочет ее получать дальше. 

S01 [02:20:28]  : У него есть определенные критерии ее получения. Это физиологический факт. 

S00 [02:20:34]  : Он получает новизну или нет? Есть критерии. Но он не удовлетворяет эту потребность до конца. Он всегда удовлетворяет эту потребность так же, как и любую другую частичку. 

S04 [02:20:45]  : Коллеги, прошу прощения, давайте предлагаю такие споры все-таки в текстовом формате в нашем чатике. 

S03 [02:20:51]  : На самом деле, можно мне вклиниться, еще раз попытаться всех помирить и заодно еще задать один, мне кажется, важный вопрос Сергею Маркову. 

S04 [02:21:02]  : Да, я хотел примерить. 

S03 [02:21:05]  : Покажу один слайд, который попытаюсь, если не подвести итог, то свою версию итога. Вот видно мой экран. Вот на этом слайде, который многие некоторые уже видели, я его просто еще раз прокомментирую, есть результаты опроса, который я собирал в трех сообществах. AGI Russia в Телеграме, AGI Russia в Фейсбуке и AGI группа англоязычная. Вот, и там, так сказать, вопрос, грубо говоря, ставился так, что вот какой нам нужен IGI, то есть вопрос на самом деле в повестке сегодняшнего разговора. Значит, либо нам нужно много глубоких нейронных сетей, это вот первая позиция, ну и на самом деле не очень много респондентов высказались в пользу этого решения. Значит, вторая позиция, которая собрала наибольший фидбэк, это построение не булевской, а вероятности или нечёткой логики на графах и предикатах, то есть, в конечном итоге, символьный подход, но с нечёткой или вероятностью логикой в том сообществе, в котором Это бы обсуждалось, казалось, наибольшее число респондентов высказались. А вот третью позицию занял на самом деле гибридный подход, пресловутый нейросимвольный подход. Кстати, я его тоже поправлю. Тут в какой-то момент попытались поделить на когнитивистов и нейросимволистов. На самом деле, когнитивисты с одной стороны, символисты с другой, а нейросимволисты посерединке. И вот этот heterarchical neurosymbolic integration – это как раз та идея, за которую топил товарищ Марвин Минский, и про которую, на самом деле, в неявном виде говорит Дэниел Хенниман со своей идеей концепции двух видов мышления, что на самом деле человек обладает двумя видами мышления. и двумя способами обучения. Быстрым мышлением, интуитивным мышлением, которое требует долгой и мучительной тренировки на большом объеме данных или на большом количестве жизненного опыта, это вот что называется один режим мышления. Вот он здесь справа. Думаем быстро, научимся медленно. Но если чему-то научились в результате долгого обучения, то в этом решение происходит мгновенно и интуитивно. Это соответствует когнитивистскому или нейросетевому решению задач. А с левой стороны здесь другой подход. Когда у нас с одной стороны есть возможность быстрого обучения, Точнее, извиняюсь, это наверху. Не можем объяснить, но действуем быстро, это внизу. А вверху у нас как раз симульные процессы, когда мы медленно думаем, а если мы сделаем так, а потом сделаем так, то что у нас в итоге получится. И пока мы вот эту цепочку все простроили, нас уже съели или там стукнули по голове. Потому что мы не успели быстро отреагировать. Но с другой стороны, когда мы один раз эту цепочку восприняли, она у нас уже в том виде, в котором мы ее восприняли, она у нас уже стакане велось в памяти нам объяснили один раз как машину заводить вот мы ее теперь всегда в этой последовательности заводим нам не нужно машину заводить 20 раз для того чтобы понять что сначала нужно там тормоз нажать и только потом значит сцепление переключать точнее на драйв переключать Это то, что я называю вертикальная нейросимвольная интеграция, и большинство как бы высказались, респондентов, за нее. Но я теперь хочу, чтобы задать важный, мне кажется, вопрос Сергею Маркову. который уже сегодня звучал, я просто пытаюсь сделать фокус. Вот другой пример. То, что называется горизонтальная нейросимвельная интеграция, которую мы пытались применять в своем подходе по самообучению естественным языкам, когда предполагается, что у нас может быть с правой стороны… Это так, это для зрения, вот для языков. Когда с правой стороны у нас есть нейросеть, которую мы можем научить, чему-то, натаскав ее на большом корпусе данных. А с левой стороны у нас на самом деле есть граф. В данном случае это формальная грамматика в представлении Lingrammer. И есть понимание, что можно вообразить некоторый процесс, и некоторую версию этого процесса мы в том числе реализовывали, когда мы можем извлечь, перевести те весовые коэффициенты, которые нейронная сеть выучила, мы можем перевести эти знания в некоторую формальную грамматику, в антологии, которые описывают данную предметную область. А дальше возникает вопрос, а можем ли мы также формальное знание которое у нас есть перевести обратно в нейросеть и вот здесь вопрос да то есть вот он который был как нам значит ранее полученные имеющиеся знания в предметной области загнать нейросеть но один ответ я вижу простой да то есть если у вас есть какие-то знания в какой-то предметной области формальная да то нужно сгенерить большое число прецедентов в терминах данной предметной области с учетом этих экспертных знаний и натаскать нейронную сеть на открытых, сгенеренных знаниях. Но это, наверное, не очень правильный ответ. Сергей, вот вы видите, вы говорили, что нейронных сетей, они на самом деле современные, они на самом деле в большой степени символьные. Вот как можно современные нейронные сети уже существующие экспертные знания в виде антологии, формальных правил, грамматик, экспертных систем. Как можно эти знания туда загрузить? У вас есть понимание? 

S05 [02:27:07]  : Понятно, что самое простое решение в лог, то есть это генерация прецедентов на основе известных правил. Но здесь Возможно, здесь и другие подходы. Это, например, создание каких-то явных символных констрейнтов между некоторыми активациями внутри сети. истории про то, что вообще ваши эти представления, которые вы говорите экспертными знаниями, их точно нельзя представить в дифференцируемой форме? То есть, грубо говоря, высказывание на символе логики в конечном счете-то можно любому высказыванию на символной логике подобрать эквивалентную ему нейронную сеть. И вообще говоря, процедура такой конверсии, она достаточно тривиальна. И есть исследования, когда, например, ну не знаю, модель строят изначально как лес случайных деревьев какой-нибудь, да, а после этого этот лес случайных деревьев заменяют эквивалентной ему нейронной сетью и доучивают его при помощи там какого-то градиентного спуска, да, то есть на самом деле здесь, ну вот такое решение вполне возможно, но есть исследования, темы я правда там не не суперспециалисты конкретно в этом направлении, но есть такой подход тоже и его тоже люди исследуют. 

S04 [02:28:49]  : Виктор Казаринов спрашивает. Глубокие сети похожи на онтологии. На каком уровне пики гиперплоскости можно сравнить с отдельными понятиями? Кто-нибудь делал такое? На каждом уровне пики гиперплоскости можно сравнить с отдельными понятиями. 

S05 [02:29:08]  : Кто-то делал такое сравнение? Есть очень хорошее исследование, когда активации в сверточных сетях сопоставляются отдельно на словарных текстовых описаниях картины. И это, в принципе, работает неплохо. То есть, оказывается, что в обученной нейронной сети большой, причем неважно, супервайзит или ансупервайзит способом, можно дальше найти аналогию между активациями внутри этой сети и какими-то понятиями естественного языка. К вопросу, кстати, об объяснимости моделей. причем есть много способов как это делать. есть так называемые колонки активации, когда берут нейронную сеть и смотрят какие какие активируются нейроны в каждом из сверточных слоев, из них такой вектор строят, и дальше нам нужно этот вектор сопоставить с вектором какого-нибудь верта, который учился на текстах. Вот такой есть подход. Поэтому, конечно, есть способы, как найти в обученной нейронной сети те самые понятия, те самые абстракции, которые мы используем. которые используют люди, и это как раз один из, наверное, наиболее популярных подходов к созданию объяснимых традиционистских моделей. В принципе, очень часто повторяют эту историю про черный ящик, нейронные сети – это черный ящик. На самом деле за последние 10 лет было столько способов просвечивания этого ящика создано разнообразным, что Мне кажется, сейчас уже не вполне правомерно говорить о черноте этого ящика. 

S03 [02:31:11]  : я добавлю от себя вот значит кто что мы все сергей сказал вот надеть просто сейчас уже времени нет мы уже перебрали регламент поэтому я не буду показывать слайда вот я кинул ссылочку на слайды в начале доклада и на свой доклад на видео вот как раз ровно то про что сейчас говорит сергей на тех слайдах которые я показывал перед этим ровно там это и объясняется да то есть там вот справа и слева как раз нарисована Одни и те же понятия, как они раскладываются на разных слоях нейронной сети и как они раскладываются на онтологии, представленной графом. И показано, что эти представления эквивалентны, только в нейронной сети мы имеем просто весовые коэффициенты. между какими-то искусственными нейронами, а на графе у нас есть конкретные лейблы для каждой вершины и есть понимание того, какие логические выражения их объединяют. 

S04 [02:32:15]  : Так, ну что, мы тогда все, да, Антон? Судя по всему, да, у нас уже как раз два с половиной часа обычно. Да, слайды, я думаю, будут и, конечно, запись будет потом выложена, как обычно. Всем участникам спасибо, всем слушателям спасибо за вопросы. Было интересно. Голосуйте. Через доклад было интереснее. Через смс. Это шутка. Ну, собственно, все тогда. 

S03 [02:32:45]  : Всем спасибо. Спасибо. Спасибо большое. Всем до свидания. До встречи на OpenTalks.ai. 

S01 [02:32:53]  : До свидания. Всем спасибо. 

S03 [02:32:55]  : До свидания. 








https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
