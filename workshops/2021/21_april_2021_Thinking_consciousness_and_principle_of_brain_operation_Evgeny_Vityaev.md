## 21 апреля - Мышление, сознание и принцип работы мозга - Евгений Витяев — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/NjoO7ytwqc8/hqdefault.jpg)](https://youtu.be/NjoO7ytwqc8)

Суммаризация семинара:

Семинар посвящен дискуссии и обсуждению текущих исследований в области искусственного интеллекта, когнитивных наук и нейробиологии. В частности, участники семинара рассматривали вопросы, связанные с моделями мышления, сознания и принципами работы мозга.

Докладчики представили различные подходы к моделированию когнитивных процессов, включая формализацию теории функциональных систем и разработку новых моделей нейрона. Особое внимание было уделено проблеме доэтерирования (превышения границы обучения), когда система не может точно доэтерировать до конца из-за большого количества объектов и признаков. В этом контексте было обсуждено необходимость гибкости в решениях частных задач и сложность аналитического решения динамических цепей движений.

Диалог между участниками семинара также затрагивал вопросы обобщения и дифференциации, а также их применения в классификации и прогнозировании. Примером может служить классификация птиц, где не все птицы умеют летать и видеть гнезда на деревьях, что требует выделения отдельных классов с учетом важных признаков.

В ходе обсуждения были подняты вопросы о сознании и подсознании, включая взаимодействие индивидуальных и коллективных когнитивных систем. Участники семинара обсуждали, в какой мере сознание может быть представлено как взаимодействие систем и какие механизмы используются для формирования целенаправленного поведения.

Также были затронуты технические аспекты, связанные с хранением информации и проблемой переполнения памяти. Участники обсуждали, насколько возможно хранить всю информацию и как решается проблема в контексте функционирования мозга.

В заключение, семинар подчеркивал значимость междисциплинарного подхода в исследованиях когнитивных наук и искусственного интеллекта с учетом последних разработок и открытий в области нейробиологии.







S03 [00:00:06]  : Запустилось? Да. Коллеги, всем добрый вечер. Сегодня у нас в гостях Евгений Евгеньевич Витяев снова. И он нам расскажет про мышление, сознание и принципы работы мозга, согласно тем работам, которые он ведет в последнее время. Евгений Евгеньевич, пожалуйста. 

S01 [00:00:29]  : Да, ну вот сейчас на самом деле ведется параллельный семинар, который открылся Самсоновичем. Вот перспективные и ключевые направления и так далее. Поэтому я понимаю, что сейчас народу немножко меньше. Тем не менее, доклад начнем и продолжим. Доклад мышления, сознания и принципы работы мозга. Он посвящен как раз вот этим проблемам. И я хотел его начать с понятия когнитона, потому что на самом деле я расскажу не только о сознании мышления и принципах мозга, но еще и параллельно получится и формализация когнитона. Так вот, когнитом, как рассказывает Константин Владимирович Чанокин, это гиперсетевая модель мозга. И это скрыто от нашего непосредственного восприятия проявляющейся в феноменологии и поведении когнитивная реальность. И как, в общем-то, Константин Владимирович правильно и довольно точно описывает, что он представляет собой совокупность кубов двух типов. когов обобщающих представления теории функциональных систем и когов феноменального опыта. И вот как раз это позволяет более точно и более концентрированно как раз получить формализацию всех этих понятий. Так вот, оказывается, что Их формализация может быть осуществлена на основе всего лишь одного и простейшего принципа. И, собственно, в докладе это и будет показано. Что мозг обнаруживает всевозможные причинные связи во внешнем мире и делает всевозможные выводы по ним. Формализуя этот принцип, нам удастся получить формализация всех упомянутых понятий. Так вот, как это можно сделать и как это вообще можно получить? Еще на конференции в Светлогорске Константин Владимирович Анохин говорил, что проблема не в том, что существующая нейрофизиологическая теория, Используемые в них координационные подходы просто не могут дать ответ на вопрос о природе разума и субъективного опыта. Для этого нужна нередукционистская фундаментальная теория. То есть формализации работы мозга и его принципах новые эксперименты не помогут, нужна другая, не редукционистка в фундаментальной теории, причем такая, которая находится вне, она как бы должна находиться между реальностью и нейробиологией, то есть она должна описывать некоторые, так сказать, вот разум и сознание, они должны описываться некоторой самостоятельной, промежуточной, не сводимой физиологическим, нейробиологическим и другим процессам понятия. Это должна быть своя самостоятельная теория, которая как раз, описав которую, мы только и сможем понять на самом деле, как функционирует мозг и какие связи с этим проходят как раз биологические, нейробиологические и другие процессы. На самом деле еще Тегберг в своей книжке наша математическая вселенная. А Тегмарк, он друг Танони, который тоже занимается сознанием. Тегмарк писал в книжке «Наша математическая вселенная». Он там начинает от квантовой механики до вселенной, и в промежутке он останавливается на гуглировании сознания. Так он пишет, что В поисках фундаментальной природы реальности должна быть первошуточная теория, описывающая взаимосвязь мозга с реальностью. То есть у нас есть внешняя реальность, которая описывается физическими законами. У нас есть когнитивные процессы. внутренняя реальность, так называемая. И должна быть еще промежуточная реальность, которая с одной стороны стыкуется с физикой, а с другой стороны она стыкуется с когнитивными процессами и описывает их. И вот, собственно, когда после конференции еще в Светлогорске я подошел к Константину Владимировичу Анатольевичу и спросил, что вы действительно говорите о некоторой промежуточной теории, которая надо построить, которая должна быть построена. В своем докладе в этом плане он предлагал теорию гиперсетей в качестве такой промышленной теории. Он сказал, что да, конечно, что речь идет о том, чтобы именно такими теориями построить. Так вот попробуем такую теорию построить на основании того принципа, о котором я сказал. что мозг обнаруживает всевозможные причины связи и осуществляет всевозможные выводы по ним. Еще тогда я спросил Константину Владимировичу, получается, что промежуточная теория, о которой говорил Петр Кузьмич Анохин, а именно, сложилась одна универсальная закономерность приспособления организмов к внешним условиям, которые в дальнейшем бурно развивались на протяжении всей эволюции живого мира. В высшей степени быстрое отражение медленно развертывающихся событий внешнего мира. То есть это такая информационная теория, которая описывает процессы отражения внешнего мира и процессы прогноза внешнего мира. В общем-то, по крайней мере, Константин Владимирович не возражал против этого. Так вот, начнем построение такой теории на основании того принципа, который я только что сформулировал. Поэтому, во-первых, эта информационная теория должна описывать предвосхищение событий внешнего мира. нейрофизиологические, физиологические, психологические теории должны описывать, как они обеспечивают те или иные информационные процессы отражения предвосхищения реальности. И в частности, на примере теории функциональных стен я в точности это и покажу. Кроме того, если бы внешний мир был случайным, то никакое предвосхищение было бы невозможно. Но наш мир хорошо структурирован, и в нем есть как минимум причинность. И именно эту причинность мы будем использовать. Для эффективного предвосхищения реальности МОД должен эволюционно сформировать такие нейрофизиологические механизмы, которые бы автоматически улавливали, использовали и причины связи, и структуру внешнего мира, которые отражаются в причинной связи для осуществления прогноза событий. И такие структуры внешнего мира и даже законы внешнего мира, в которых причинность участвует, мы сейчас и рассмотрим, и которые тоже, как покажем, улавливаются и описываются среди когнитивных механизмов. Так вот, информационная теория отражения основана на законах и структурах внешнего мира. и описывать одновременно как структуры реальности, так и нейрофизиологические и другие механизмы, которые обеспечивают отражение этой структуры. Так вот, начнем с анализа как раз высказывания Петра Кузьмича Анохина о причинности и предвосхищении событий внешнего мира. Хотя это утверждение достаточно общее, но мы сейчас достаточно быстро, точным математическим анализом Тут же получим некоторые достаточно конкретные результаты. Обратимся к философии науки. Причина сводится к предсказанию и объяснению. Причинное отношение означает предсказуемость. В том смысле, что если полная и предыдущая ситуация известна, события могут быть предсказаны, если будут даны все относящиеся к событию факты и законы природы. Таким образом, причинное отношение сводится к выводу предсказания. из имеющихся фактов и законов. Такие предсказания можно получать индуктивно-номологическими, индуктивно-статистическими выводами, поскольку нас интересует, прежде всего, обучение в том числе человека, это заведомо уже индуктивно-статистические выводы и прогнозы. Но для них, оказывается, существуют так называемые проблемы, которые нужно решить, чтобы двигаться дальше. Например, проблема статистической двусмысленности. Простейший пример такой. Если философ не миллионер, если философ, то он не миллионер, а если он держатель приисков, если человек держатель приисков, то он миллионер. Для известного философа, ученики которого, собственно, примеры придумали, вот он, оказывается, имеет прииски, и на нем мы получим противоречие. Так вот, этот вопрос статистической двусмысленности исследовал еще Гемпель, и он сформулировал некоторые неформальные требования максимальной специфичности, которые, если говорить неформально, оно означает, что нужно использовать максимумеющиеся информации, чтобы избегать противоречия. Я не буду давать здесь точной формулировки этого требования, но скажу, какой вывод из этого следует. Максимум использования информации стоит в следующем. Если философ не держатель приисков, то еще более вероятно, что он не миллионер. А если держатель приисков и не философ, то еще более вероятно, что он миллионер. То есть если у нас есть дополнительная информация, которую мы можем подсоединить к нашему условию, таким образом увеличить его вероятность, сделать его более точным, то в этом случае мы можем избежать противоречия. Вот эти два утверждения уже совместно неприменимы, поэтому мы противоречия по этим утверждениям не получим. Хотя эти проблемы исследовали достаточно давно Гемпелем, но философами так и не был получен результат. и такая формализация максимальной специфичности, для которой можно было бы строго доказать математически, что из соответствующих максимально специфических правил противоречия не выводится. Нами это было сделано совместно с Сергеем Одинцовым, докторами института математики. Такая формализация статистической двусмысленности, для которой можно доказать, что противоречия в этом случае не возникает. То есть это первый теоретический результат, который следует из анализа, из точного анализа прогноза и причинности, а из него следует следующий, так сказать, результат, который сразу доходит до нейрофизиологических следствий, а именно. Можно выдвинуть такую схему, формальную модель нейрона, которая на самом деле обладает довольно естественными свойствами. Самое главное, она обладает свойствами обнаружения причинных связей на уровне нейрона. Она удовлетворяет правилу HERBAT, хорошо известную, которая удовлетворяет многие другие формальные модели нейрона. Но эту модель нейрона мы устроили таким образом, чтобы она обнаружила как раз максимально специфические правила. Если на вход дендрита поступают сигналы положим A1 и A2, и их поступление увеличивает безусловную вероятность возбуждения нейрона, то в этом случае образуется условная связь на уровне нейрона. Если найдутся еще какие-то сигналы, добавление и учет которых еще более увеличивает вероятность правильного прогноза возбуждения нейрона, то они также у нас добавляются к этому условию. То есть условие наращивается до тех пор, пока оно в состоянии учесть всю информацию, которая поступает на нейрон, и при этом позволяет максимально точно предсказывать его возбуждение. Такие правила и такие свойства, которые будет обнаруживать нейрон, они в этом случае будут удовлетворять требованиям максимальной специфичности. Вот это вот такая формальная модель нейрона, она была опубликована в статье, которая здесь ниже. Так что мы пришли уже сразу в некоторые формальные модели нейрона, которые в состоянии обеспечивать то самое обнаружение причинных связей, причем нужных нам причинных связей. из которых как раз мы собираемся объяснить все остальные механизмы. Но действительно ли реальные нейроны удовлетворяют вот этим условиям? Я, так сказать, обращался, ну, во-первых, на конференции об этом рассказывал, во-вторых, я спрашивал, опять же, Константин Владимирович Анокин, можно ли эту гипотезу проверить на реальном нейроне? Но чтобы проверить, для этого надо подвести четыре электрода, причем к разным местам гетерита и к соме. Но как мне объяснили, это будет смертельный номер для самого нейрона, поэтому пока что такая проверка невозможна. Но мы будем использовать эту формальную модель нейрона, поскольку она нам позволит объяснить большинство остальных эффектов. Перейдем к следующему закону внешнего мира, а именно естественной классификации, как закон строения внешнего мира. Но для этого надо, прежде всего, уметь ее отличать от искусственной классификации. Искусственная классификация основывается на одном или нескольких признаках и формирует классы в соответствии с наличием этих признаков. Но если рассмотреть классы животных и растений, рассматриваемые в естественной классификации, то они отличаются потенциально бесконечно множеством признаков. Джон Стюарт Милль, он первый, который более-менее детально описывал понятие естественной классификации, и сформулировал такое свойство, что это такая классификация, которая объединяет объекты в группу, относительно которых можно сделать наибольшее число общих предложений. И она основывается на таких свойствах, которые служат причинами многих других. Тут сразу же возникает причинность. На самом деле, в естественной классификации известны еще объекты в природе. Они порождаются некоторыми генетическими причинами, то есть они имеют определенный генезис строения. А генезис строения объясняется тем, что у нас всего принципы физического детерминизма, есть некоторые физические процессы, есть некоторые его начальные условия. В соответствии с этими начальными условиями и законами данного процесса мы получаем некоторые конечные, так сказать, продукты, объекты, минералы и еще что-то, которые получаются по этим законам, то есть являются генетическими. И в этом случае, как правило, и хотя генезис, он получил всего их некоторых внутренних свойств, то вот эти внешние свойства являются причинами внутренних. И внешние свойства, они взаимосвязаны между собой по этим причинам. Так вот, как выяснили естествоиспытатели, например, в Иткоске, чем больше существенных признаков схода сравнимые предметы, тем вероятнее их одинаковость в других отношениях, то есть в других причинных свойствах. Смирнов писал, тактиламическая проблема заключается в медикации. От бесконечно большого числа признаков нам нужно перейти к ограниченному количеству, которое заменил бы все остальные. То есть в естественной классификации, там копытные, рогатые, млекопитающие, можно найти некоторые такие индикаторные признаки, которые будут определять некоторые объекты класса. Но в этом случае из этих индикаторных признаков мы можем предсказать и определить все остальные признаки как раз по причинным связям, которые мы для этих объектов естественной классы можем наблюдать. И легко посчитать, что в этом случае когда у нас объект описывается потенциально бесконечным множеством свойств, которые достаточно сильно группируются относительно других свойств объектов, принадлежащих тому или иному классу, то у нас в этом случае из индикаторных свойств, которых может быть немного, Мы можем предсказать все остальные свойства. Поскольку индикаторами можно выбирать различные свойства, то, соответственно, и для них тоже есть закономерности, предсказывающие остальные свойства. Легко посчитать и прикинуть, что в этом случае наблюдается для взаимосвязи признаков естественных классов такой закон внешнего мира, то есть закон строения естественных объектов. то естественный класс содержит потенциально бесконечные множество признаков, которые могут быть описаны небольшим количеством индикаторных признаков, причин, определяющих все остальные признаки. Количество закономерностей, по которым эти признаки взаимосвязаны, оно экспоненциальное относительно количества признаков. То есть у нас имеется огромная информационная избыточность. Посмотрим, как это проявляется дальше и как это используется при восприятии объектов внешнего мира с точки зрения когнитивных наук. То есть, это свойство у нас описывает объекты внешнего мира. То есть, это описание внешнего мира и законы его строения через причинные связи. Здесь уже, как этот же закон отражается уже с точки зрения когнитивных, для наук. Так в когнитивных науках обнаружено понятие, так называемое естественное понятие. Как писала Леонор Рош, она сформулировала принципы категоризации естественной понятия. Это, например, такой принцип – структурированность воспринимаемого мира. Воспринимаемый мир – мнение структурированное, множество равновероятно встречающихся атрибутов. Наоборот, объекты материального мира воспринимаются как обладающие высококоррелированной структурой. Комбинации того, что мы воспринимаем как атрибуты, не встречаются равномерно. Некоторые пары, тройки и т.д. высоковероятны, другие редки, другие логически или эмпирически не встречаются. Поэтому непосредственно воспринимаемые объекты являются информационно богатыми связками, наблюдаемыми свойствами. которые создают категоризацию. Эта теория получила название прототипической теории категорий, потому что эти связки формируют некоторые прототипы объектов классов. Их категории тогда могут рассматриваться в терминах этих чистых случаев, прототипов, если воспринимающий обращает внимание на координационные структуры воспринимаемых атрибутов. В дальнейшем было обнаружено, тоже в коллективных науках, что необходимо учитывать еще также теоретические причинные знания. Например, люди не только знают, что птицы умеют летать, ведут гнезда на деревьях и имеют крылья, но также и то, что птицы ведут гнезда на деревьях, потому что могут летать и летать, потому что имеют крылья. Отсюда возникла теория причинных моделей Боба Рехтера, в соответствии с которой атрибуты причинной связи между атрибутами присутствуют одновременно. То есть те самые закономерности, которые описывают объекты и взаимосвязь свойств объектов естественной классификации, отражаясь уже в виде причинных связей, то есть вот на этой картинке, у нас есть некоторые объекты внешнего мира. Лодка, машина и причал. Если мы обнаружим у этих генетических объектов, которые получены в результате некоторого генеза своего производства, причина и взаимосвязь между ее признаками, которые описывают эти объекты. Эта причина и взаимосвязь улавливаются соответствующими нейронами или улавливаются некоторыми когнитивными структурами. Мы будем считать, что нейронами, но они считают, что некоторыми так называемыми механизмами и так далее. причинные связи, они уже образуют так называемые причинные модели, то есть они своими причинными связями взаимопредсказывают признаки. То есть здесь вот эти признаки сами взаимопредсказывают себя. В этом клеточном ансамбле или в клеточном ансамбле Хэбба если нейроны удовлетворяют правил Хэмпа. Эти нейроны своим возбуждением взаимоподдерживают себя и образуют высококоррелированные структуры взаимовозбуждающихся нейронов. В теории причинных моделей отношение объекта к категории основывается уже не на множестве признаков, не были застепа признаков, как в большинстве бендов классификации. а на основании сходства порождающего причину механизма, то есть той самой корреляционной структуры. На самом деле это корреляционная структура, если уже вдаваться далее в математические методы машинного обучения, то можно показать, что хотя для метода машинного обучения имеет место так называемое проклятие размерности. Если мы построим метод обнаружения классов по экспоненциальному числу причинных связей, то с увеличением числа этих причинных связей точность распознавания и статистическая значимость этого распознавания будет экспоненциально расти. Поэтому наличие такого количества связей, оно как раз позволяет довольно точно идентифицировать объекты внешнего мира, в отличие от методов классификации, которые в настоящее время существуют. Ну и также то, что у нас уже теперь с точки зрения когнитивных наук, уже с точки зрения нейрофизиологических процессов, как теперь отражаются у нас вот эти причинные связи уже, так сказать, в нейробиологических процессах. Вот к этому имеют прямое отношение Танони, Гули Танони, который является одним из ведущих зарубежных специалистов по теории сознания. И он эту ситуацию описывает несколько другим способом, хотя точно так же, на основании причинных связей. Он вводит понятие так называемой интегрированной информации. Все, что нам нужно знать, это как много информации генерируется системой по отношению к информации, генерируемой ее отдельными частями. Это и составляет некоторую интегрированную информацию. Вот здесь на картинке есть причинный связь, определяющий взаимосвязь между вот этими элементами. Так вот, если мы возьмем такое максимальное разделение и определим с помощью энтропии всей системы, А потом определим энтропию и отдельных частей и определим такую условную энтропию, то есть энтропию всей системы в целом, проходящей в нейтральном состоянии Х1 по отношению к энтропии отдельных частей, то в этом случае мы обнаружим, что у нас эта энтропия падает, и есть определенная информация, которая соответствует тому, как вот эта система организует и связывает между собой вот эти части по причинным связям. Танони занимается как раз, он нейробиолог, Он работает в клинике, он занимается в том числе гомотозными больными, которые находятся в коме. И ему важно знать, и, собственно, эта теория возникла из его наблюдений, в каком случае все-таки такой больной реагирует на что-то во внешнем мире. И элементы сознания, которые проявляются, это какие те самые элементы сознания, на которые он в состоянии реагировать. Так вот это и есть как раз те, так сказать, взаимосвязи, в которых образуется максимум интегрированной информации. Мы дадим этому несколько другую интерпретацию. Оно не пишет, что на самом деле в нервной системе вот эти системы можно разбить на комплексы. Потому что некоторые системы формируют комплексы, когда переходя в состояние S1 с ненулевой интегрированной информацией, не найдется подножка с устрого большей информацией. То есть у нас есть вот этот комплекс, если он имеет некоторую интегрируемую информацию, и нет подмножества, здесь нельзя выбрать подмножество, имеющего больше информации. То есть, убирая любую часть, мы понижаем информацию. Вот это и есть комплексы. И с его точки зрения, то, что мы воспринимаем из внешнего мира, можно разбить на комплексы. Но это, на самом деле, в точности то, что получается, если мы будем разбивать восприятие внешнего мира в соответствии с естественными понятиями и разбивать их в соответствии с тем, что мы воспринимаем естественные объекты. Но дело в том, что вот оно нет, на самом деле, внешнего мира. Поэтому он определяет свою теорию как некоторую феноменологию. Но дело в том, что в нашей интерпретации мы будем считать, что вот эти комплексы, это есть в точности те комплексы, которые обнаруживаются и фиксируются теми причинными связями, которые связывают между собой элементы нервной ткани. Они не говорят, что это нейроны, это некоторые более общие случаи, это некоторые элементы нервной ткани, но в нашем случае это нейрон. Отсюда можно сделать такой вывод, что если рассматривать тот вид когов, которые соответствуют клеточным ансамблям в рамках когнитома, то они формализуются некоторым единым образом. То есть можно построить единую формализацию, которая будет приведена дальше, для естественной классификации, естественных понятий и интегрированной информации одновременно. Опять же, мы вернемся к нашему постулату. Мы предполагаем, что мозг осуществляет всевозможные выводы по обнаруженным причинам связи, отражая высококорреливную структуру объектов внешнего мира. Когда мы воспринимаем с помощью причинных связей, насколько видим структурные внешние меры, эти причинные и сильные связи зацикливаются сами на себя в процессе вывода. То есть, отражая тот же самый естественный объект по причинной связи, у нас причинные зависимости между признаками сами зацикливаются сами на себя. Образуются, так сказать, циклические причинные связи. С точки зрения нейронов, Это фактически получается резонанс взаимовозбуждений, который взаимопредсказывает свойства воспринимаемого объекта. Или резонанс, который отражает восприятие некоторого понятия во внешнем мире. Этот резонанс автоматически формирует клеточные ассамбли. одновременно возбуденных нейронов, которые порождают причинные модели, и они будут в этом случае являться причинными моделями, а эти причинные модели автоматически формируют прототипы объектов классов, как те самые индикаторные, совокупность индикаторных признаков, которые нам характеризуют объекты соответствующего класса. Таким образом, в соответствии с нашим принципом, то есть в соответствии с нашим принципом, мы объясняем формирование клеточных ансамблей. Таким образом, мозг осуществляет всевозможные выводы по причинным связям, обнаруживает таким образом на естественных объектах причинные модели на объектах, которые образуют некоторые естественные классы. И вот математическая модель, которая в состоянии описать вот эти технические взаимосвязанные причинные связи, это наша оригинальная разработка, это вероятностные формальные понятия, которые являются точным обобщением существующих в анализе формальных понятий, обыкновенных формальных понятий. Коротко я о них скажу, но на самом деле очень коротко. Так вот, на самом деле, то, о чем я рассказал, в теории когнитома Константин Владимирович предлагает описывать как гиперсимплекс гиперсети, а фактически он обладает практически тем же самым свойствами. Рассмотрим внимательно. Гиперсеть является кандидатом к математическим формализмам для описания организации высшей функции мозга. Гиперсетия состоит из геометрических структур, известных как радиационные симплексы или гиперсимплексы. Основание гиперсимплекса содержит множество элементов одного уровня, а вершина образуется описанием их отношений, приобретает интегральные свойства, делающие его элементы сети более высокого уровня, которые фактически отражают уже некоторую целостность, целостность, которая отражает некоторые естественные объекты внешнего мира. Поэтому, если на нижнем уровне гиперсимплекса мы имеем отдельные свойства, то есть самые собаки, то, организуясь в некоторый комплекс по талони, или в некоторую причинную модель в соответствии с взаимопредсказывающими причинными связями, которые в процессе вывода зацикливаются, мы получаем, так сказать, вот этот самый гиперсимплекс, который отражает нам некоторые внешние естественные объекты. Но математику я постараюсь более-менее пропустить, только несколько слов. Вот здесь я дано стандартное определение анализа формальной понятия. Формальное понятие, если грубо, то это может стать некоторым синдромом. То есть комплекс признаков, общий для некоторых рассматриваемых случаев. Если такое описательное определение формального понятия, то это такая пара A и B, где A – это множество объектов B, это множество признаков, которые описывают эти объекты, но удовлетворяющие следующему свойству. A – это множество всех объектов, имеющих все признаки из B, а B – это множество всех признаков из M, которые есть у всех объектов из A. То есть есть определенная довольно точная связь между признаками и объектами, которые они описывают. Но дело в том, что анализ формальных понятий обнаруживает эти формальные понятия точно. Анализ формальных понятий не работает в условиях шумов. Если в данных получаются шумы, то решетка формальных понятий, она экспоненциально растет И это и фактически рассыпается, то есть она не дает возможность обнаруживать формальное понятие в условиях наличия шумов. Как раз Джон Стюарт Милль писал, что естественная группа определяется признаками, однако при этом принимается в умениании не только признаки, и вот здесь он описывает примерно, как и в анализе формальных понятий. Безусловно, общие для всех, получаемшие группу предметов, Вот первая часть определения не в точности соответствует формальному понятию, но далее она требует большее. Но вся совокупность тех признаков, из которых все встречаются в большинстве этих предметов, большинство во всех, то есть нужно от точного определения перейти к вариаторному определению. Но дело в том, что это до сих пор так никто и не сделал, в силу такого простого свойства, что зацикливающиеся на себя причинные связи только тогда не будут приводить к противоречиям, когда решена проблема статистической двусмысленности. То есть доказана та самая тюрема, о которой я говорил в начале. Она математически нетривиальная. которые доказаны вот в этой работе. И только при этом условии причинные связи не будут противоречиться, не будут входить в противоречие в процессе вывода и будут зацикливаться сами на себя без противоречия, формирует в результате некоторые вероятности формально понятия, которые есть тот самый, так сказать, синдром, но уже с учетом, так сказать, возможных отклонений и возможных причинных связей. но это определение пропущу, есть соответствующие работы, которые внизу. Так вот проиллюстрируем формирование этих вероятностных формалей, понятие на простейшем примере. Возьмем цифры индекса, закодируем их соответствующим образом и обнаружим на них всевозможные причинные связи, которые верны на всех цифрах. Причинной связи не отделяют цифры сами от себя, и не отделяют цифры друг от друга. Например, легко проверить, что имеет место такая причинная связь. Если есть вот эта палочка, то есть вот эта. Если есть вот эта, то есть вот эта. Если есть вот эта, то есть вот эта. И эта закономерность верна на всех цифрах. Вот эта вот палочка, если есть, то есть вот эта. Это на самом деле верно для семерки и для двойки. Но каким же образом мы умудряемся воспринимать весь мир со всем его богатством на основании только причинных связей? Так вот, оказывается, это может делаться только тогда, когда причины связи зацикливаются, отражая некоторый целостный объект во внешнем мире. образуя в результате такую причинную модель, в которой причины связи зацикливаются сами на себя, и тогда они автоматически выделяют во внешнем мире некоторый целостный объект. И только так идет отражение внешнего мира и той иерархии естественных классов, которые есть во внешнем мире через зацикливание причинных связей. Поэтому, опять же, для такого зацикления достаточно нашего одного только принципа, что мозг обнаруживает все причины связи, делает всевозможные выводы по ним, которые в данном случае зацикливаются. То есть здесь вот причины связи, из этого признака следует это, а вот этот признак, Дальше вот из этого признака следует вот этот. А из вот этого признака следует вот этот. А этот признак и отрицание этого следует вот этот. То есть они зацикливаются сами на себя без противоречий, формируя некоторую фигуру. То есть это рисунок получен программой. которая обнаруживает вероятностные формально понятия. Она ищет все возможные, зацикливающиеся на себя причинные смерти. В точных серверах это так называемые все неподвижные точки предсказания. Когда он обнаружит все неподвижные точки предсказания, они в точности обнаживают все цифры. То есть причинные связи не в состоянии идентифицировать объекты внешнего мира. Но когда они зацикливаются, они начинают идентифицировать объекты внешнего мира в соответствии с естественной классификацией. Но вероятность формального понятия состояния делает больше, что и делает на самом деле мозг. А именно, в более общем случае, он обнаруживает контексты восприятия, которые являются необходимым элементом сознания. Например, мы можем попросить тот же самый алгоритм обнаружить все причины связи только на цифрах. Потом взять и попросить, это будут одни причины связи. Потом взять и попросить алгоритма угнаровать причинные связи только на буквах. Он найдет в точности эти все причинные связи, причем в соответствии с формальной моделью нейрон, он будет в каждую причинную связь добавлять максимум информации, чтобы такое распознавание было точно и однозначно. Но теперь возникает вопрос, а если мы теперь возьмем и цифры, и буквы? Понятное дело, что и теперь объединим причины связи и тех, и других. Они уже начнут работать у нас с возможными уже противоречиями, потому что у нас причины связи цифр настроены на цифры, причины связи букв настроены на буквы, а закономерностей настроенных на всем месте у нас нет. Но если опять же попросить теперь алгоритм обнаружит всевозможные причины связи уже на всей этой совокупности, он подправит и уточнит эти закономерности в соответствии с той формальной моделью, которая у нас была, добавит к ним дополнительные некоторые свойства, что теперь опять же вот этими уточненными закономерностями уже и цифры, и буквы одновременно будут опредсказываться точно, без противоречий. Вот это как раз и объясняет формирование контекста. Зачем мозг пытается всегда обнаружить и принимать решение в определенном контексте? Потому что в этом контексте предсказания получаются наиболее точные. И как раз одна из функций сознания – это функция разрешения противоречия. Об этом, в частности, тоже много писал Аллахпердов. Например, в книжке «Сознание как парадокс». Мы воспринимаем реальность. Мы ее воспринимаем некоторой ситуацией. Если мы на нее смотрим с точки зрения их имеющихся у нас закономерностей и правил, мы, как правило, обнаруживаем, что у нас есть некоторая нестыковка в том, что мы видим. Мы в этом случае фокусируем наше сознание, конкретно на этой ситуации. Мы выделяем некоторые контексты. В этом контексте мы выделяем закономерности, которые именно это множество объектов описывает. Это множество закономерностей уточняется. Сейчас даже в области анализа языка есть специальные лингвистические модели, в которых при определении контекста пересчитываются варианты. То есть в современных методах уже такой механизм работает. То есть мы пересчитываем, уточняем эти закономерности в точности для данного контекста. И тогда мы получаем то и точное решение. Поэтому мозгу для формирования контекста это необходимое условие для того, чтобы принимать решения точные и однозначные. И именно функция сознания и состоит в непрерывном разрешении противоречий, когда мы воспринимаем мир, переходя из одной ситуации в другую. Это есть специальная функция сознания, никакая другая. Никакая другая когнитивная функция эту проблему не решает. Это именно функция сознания, разрешение противоречить. Вот это легко представить еще следующим образом. Мне, например, очень нравится следующая цитата Лагвиненко из книжки Гибсона «Экологические подходы к зрительному восприятию». Мне, так сказать, посчастливилось работать вместе с Лагвиненко, который бывший завод лаборатории восприятия Московского университета, но мы с ним работали в Англии по проектам. Так вот, он писал, первое знакомство с теорией восприятия производит обескураживающие впечатления. Прежде всего, ошеломляет обильный теорий, их эклектическая пестрота, полная несовместимость. Тех, кого достанет терпение разобраться в этом чудовищном, заботном нагромождении идеи, подходов, направлений и так далее, осчитает еще один свой порез. Оказывается, что никакой теории восприятия нет и никогда не было. Более или менее удачные идеи были. но не было ни одной достаточно развитой теории. Ну дальше он пишет Логвиненко. Но если в этой области работать, то есть он сам непосредственно в этой области работает, то после этого обнаруживается интуитивное понимание, что каждая из этих теорий, она как некоторая грань, которая смотрит на объект исследования в своей системе понятий. со своей точки зрения, с точки зрения своего взгляда на реальность. Она описывает предметы восприятия некоторым одним образом, другая теория с точки зрения другой грани некоторым другим образом, третья теория третьим образом. Но мы понимаем, когда мы знаем весь этот алмаз, что на самом деле он описывает просто разных сторон одну и ту же реальность. Так вот, сознание действует точно так же. Сознание – это как раз алмаз, который в состоянии смотреть на нашу реальность с совершенно разных точек зрения, переходя из одной точки зрения в другую. И поэтому функция сознания как раз есть как бы восприятие всего мира в целом. но восприятие в целом противоречиво, и нам надо всегда определять ту грань, ту точку зрения, тот взгляд, с точки зрения которого мы в данный момент смотрим на мир, и тогда мы можем принимать решения и выводы не противоречиво. Перейдем теперь к когнитивным группам следующего вида, именно к функциональным системам. А в теориях функциональных систем она тоже может быть описана на основании обнужения причинных связей. А тех причинных связей, которые обнужены, еще только измечены. Вот это цитата из его работы. Речь идет о коллатеральных итудеях отведения пирамидного тракта, отводящих ко многим нейронокопий тех офферентных посылок, которые выходят на пирамидный тракт. Хотя можно в момент принятия решения и начала выхода рабочих и аффирентных возбуждений и начала действий мозга сопровождаются формирование обширного комплекса возбуждений, акцепта результатов действия, состоящего из аффирентных признаков будущего результата. То есть, проиллюстрируем это на этой схеме. Пусть у нас возникло некоторое мотивационное возбуждение. Это мотивационное возбуждение, предположим, сначала мы не знаем, как достичь результата. Активировала некоторый пирамидный нейрон, который активирует какие-то мышцы и осуществляет действия во внешнем мире. Так вот, в соответствии с высказыванием Петра Кузьмича, от него обязательно идет ответвление в проекционную зону мозга. А здесь всегда найдется нейрон, который одновременно уловит результат полученного действия, что в нынешнем мире изменилось, и тот результат, который к этому привел. На этом нейроне образуется причинная связь, что после такого-то действия мы получим такой-то результат. Если мы осуществим еще следующее такое-то действие вслед за этим, то некоторый другой нейрон уловит, что после такого-то действия будет такой-то результат. Если мы в результате достигли цель и удовлетворили данную потребность, которая сняла мотивационное возбуждение, то мотивационное возбуждение снимет нам это возбуждение, а достижение результата санкционирующей афферентацией занесет в память ту последовательность действий, которая привела к достижению результата. Тогда в следующий раз, когда вам возникло мотивационное возбуждение, мы уже лежим на диване. По вот этим причинным связям сразу прогнозируем. Если мы сделаем такое-то действие, мы получим такой-то результат. А если потом сделаем такое-то действие, то получим результат и достигнем цели. Мы в этом случае, еще лежа на диване, сразу прогнозируем достижение цели. Это последовательность действий. Возможно, мы можем точно так же, так сказать, лежа на диване, посмотреть еще некоторый другой способ достижения цели. в соответствии с теорией фундаментальных схем, примем решение о определенном способе достижения цели, например, такой последовательности действий, то мы одновременно активируем вот эти нейроны, которые составляют акцепторы результатов действий, которые будут ожидать, что после таких-то действий придет такой-то результат, после таких-то действий придет такой-то результат, и эти причинные связи сработают. На самом деле, на вот этой схеме все элементы теории функциональных систем, они здесь показаны. Но самое главное, что здесь показано, что обнаружение причинных связей организации целенаправленного поведения может быть достаточно точно описано. Мы использовали вот эту схему, некоторый расширенный ее вариант, с помощью уже обнаружения максимально специфических причинных связей. То есть здесь уже точные формальные модели тех самых максимально специфических причинных связей. И фактически реализуя ту предыдущую модель, можно организовать такую работу в функционале с тем, которая достигает результата. Я об этом несколько раз рассказывал. Это есть в других местах, я не буду подробно это рассказывать, просто приведу конкретный компьютерный пример. То есть мы моделировали с помощью этой схемы функциональных систем достаточно эффективную работу некоторых аниматов и роботов. Таких работ достаточно много, это работа моей и Александра Демина, который это все делал. И, например, один из экспериментальных результатов, который мы получили, это мы, в частности, промоделировали некоторый, в настоящее время, единственный живой организм, который достаточно точно промоделирован электронно, то есть для него есть довольно точная электронная модель, это аниматона. Мы позаимствовали электронную модель нематоды в институте системы информатики. Ее разработал Пальянов, нынче он директор этого института. И вложили в нее нашу систему управления в соответствии с проведенной схемой. И оказывается, что вот эта модель, так, Так, она не запустилась. Так вот эта вот модель, она сначала падает, потом начинает делать некоторые такие случайные движения, но где-то после 100-150 случайных движений она обнаруживает свой естественный способ движения, то есть в итоге оказывается не нужна генетическая программа движения, она может просто методом пропаршивок в соответствии с нашей схемой обучения обнаружить свое естественное движение. Поэтому эта, так сказать, схема, она рабочая. Но эту схему необходимо немножко, так сказать, усложнить и расширить для ее большей эффективности. В схеме функциональных систем явно не участвуют эмоции, но здесь есть подкрепление. Но подкрепление может быть сделано более тонким и более эффективным, если учесть эмоции. Мы здесь добавим к теории функциональных систем информационную теорию эмоций Симонова. Симонов писал, что в сумме результатов собственных опытов и данной литературы мы пришли к выводу о том, что эмоции есть отражение мозга человека и животных, какой-либо актуальной потребности, которая достигается целенаправленным поведением, ее качество и величины, и вероятность и возможность ее удовлетворения. Эмоции – это необходимый критерий выбора между различными способами достижения цели, учитывающие вероятность достижения цели, сложность и трудоемкость, а также санкционирующую афферентацию от удовлетворения потребностей. Поэтому, когда принимается решение о том, какой же способ достижения цели выбрать, он уже делается на основании эмоций. и той вероятности, с которой мы прогнозируем способ достижения цели. В теории функциональных систем это прогноз, так сказать, ожидаемого будущего. Но эмоции учитывают еще и вероятность достижения цели. Мы можем, так сказать, пытаться достичь синицу в руках или желудка в небе с разной вероятностью, испытывая при этом разные эмоции. В искусственном интеллекте вот такой учет цели и ее вероятности на самом деле формализуется функция полезности, то есть есть такой математический аппарат. С физиологической точки зрения принятие решения осуществляется уже переключающей функции эмоции, о которой писал Симак. И тогда схема функциональных систем, она немного усложняется. То есть если у нас есть функциональная система верхнего уровня, в которой есть акцептор результата в действии принятия решений, и предположим, что это достижение целей осуществляется после того, как мы последовательно выполним и достигнем цели четырьмя последовательными функциональными системами, когда у нас действие разбиться на четыре стадии, И тогда мы планируем последовательное достижение цели через достижение четырех последовательных целей. От достижения каждой цели мы получим, так сказать, ее вероятность достижения цели. Эта вероятность поступает уже, оценивается эмоциями, которые одновременно учитывают вероятность. То, что мы ту афферентацию, которая содержится в подкреплении и мотивации, и тогда по этой эмоции мы можем принять решение, а какой же нам цель в этом случае достигать. И принятие решения уже осуществляется с учетом эмоций. И после этого, уже после принятия решения, функциональность тем последовательно начинает выполняться. Здесь имеет смысл дополнительно обратить внимание на то, что каждый раз, когда работает функциональная система, она осуществляет действие во внешнем мире. Из внешнего мира идет сигнал, который воспринимается соответствующим нейроном. которые фиксируют и действие, и результат из внешнего мира. И если этот результат совпадает с тем, что мы ожидаем, у нас в этом случае функциональная система достигает некоторый результат и передается в управление следующей функциональной системой. Но в этом случае у нас на самом деле вот эти коги функциональных систем, они работают таким образом, что они имеют постоянный и непрерывный контакт с реальностью. На самом деле... существует так называемый континуум поведения, когда у нас рассматривается не одиночное достижение цели, а непрерывное и последовательное целевое действие, когда мы последовательно приближаем цель. В этом континууме поведения коги функциональных систем, они всегда непосредственно, имеет непосредственный контакт с реальностью. И происходит так называемая, так сказать, создается нервно-динамическая ткань, как она еще иногда называется. Когда у нас, так сказать, осуществляется действие, получается результат тут же проверяется с тем, что получено. И вот внешний мир ткнется таким образом в точном соответствии с тем, с той моделью, которая развертывается в процессе целенаправленной деятельности. То есть, вот эти причинные связи в когах функциональных систем организованы таким образом, что они непрерывно проверяют реальность, непрерывно с ней взаимодействуют и проверяют эффект от этого взаимодействия, сшивается такая ткань действий. На самом деле, в вероятностных формальных понятиях тоже происходит непрерывный контакт с реальностью, потому что когда вероятностно-формальные понятия, когда мы воспринимаем цифру 6, зацикливающуюся сами на себе причинными связями, мы на самом деле зрительно, когда смотрим по этим причинным связям и этим признакам, мы всегда не просто прогнозируем этот признак по вот этой закономерности, но и мы обязательно проверяем, а приходящий признак действительно этот. То есть контроль, проверка прогнозируемого признака и проверяемого признака тоже непрерывно осуществляется. Это очень хорошо описано в книжке Улиха Найсера, как циклический цикл восприятия. Поэтому здесь вероятность формальными понятиями также описывается. То есть этими когами также описывается непрерывное взаимодействие с реальностью, но через что. У нас есть информационная модель, которая работает сама по себе, она работает по прогнозу, по причинным связям. У нас есть реальность, в которой есть объекты, с которыми происходит взаимодействие. И у нас есть когнитивный процесс, а именно обнаруженные причинные связи в нервных клетках, которые с помощью когов, клеточных ансамблей, осуществляют контакт с реальностью одним образом, а в кого-функциональных системах осуществляют контакт с реальностью другим образом. тесный контакт с реальностью. Но это еще не все. На самом деле есть еще один достаточно тонкий механизм, без которого на самом деле создание эффективных роботов невозможно. Если посмотреть внимательно на то, что делает Boston Dynamics на BigDogs, Легко заметить, что их постоянно толкают. Им постоянно варьируют и искажают. Вот у него есть один прогноз, его толкнули. Прогноз не осуществился. Его предсказание не сбылось. Ему надо непрерывно, постоянно корректировать свои действия. Так вот, принципиальное отличие тех роботов, которые могут разрабатываться виртуально без взаимодействия с реальностью. И те, которыми, как в Boston Dynamics, которые пущены в реальность и в которые возможны разные искажения, так вот между ними есть принципиальная разница, которая Бернштейном описывается следующим образом через необходимость сенсорных коррекций. Это необходимый элемент роботов, которые реально работают во внешнем мире, а не виртуальные, которые, так сказать, работают в компьютере. Бернштейн пишет о том, что при большом числе степеней свободы практически невозможно рассчитать движение сложной кинематической системы, например, руки. Если каждой степени свободы руки и пальца пианиста, сидящего за инструментом, даст погрешность всего в один градус, то суммируясь, эти погрешности могут дать отклонение кончика пальца на 5-6 сантиметров. Хотя по отдельным заведениям, например, в пальцах фаланга, составляющая погрешность не превысит 0,05 сантиметра. То есть вызовут промахивание на целую терцию. Еще более существенное осложнение имеет динамические осложнения. Сложно-кинематические цепи, и каждая звена обладает известной тяжелой инертной массой. Всякая сила, возникшая в одном из звеньев, тотчас же вызывает целую систему реактивных и отраженных сил, передающихся на остальные звенья. Это взаимное взъединение звеньев друг на друга во всех мысленных сочетаниях создает, в общем, в общей совокупности огромное количество силы их взаимодействия, совершенно необозримой, математически представляющей непределимые трудности для аналитического решения, то есть для аналитического вычисления на компьютере. Эти реактивные силы наслаиваются на те силы, которые находятся в распоряжении организма для управления движением системы, и на внешние силы, подвластные ему всегда лишь в большей или меньшей степени, и делает общую динамическую картину движения цепей территориально осложненной, огромно практически непредсказуемой из-за крайней механической запутанности. То есть в некоторых случаях, как в своих работах Бернштейна анализировал болотобойца на заводах, они его снимали на пленку и анализировали, то Бернштайн делает вывод, что из принципа сенсорной коррекции следует, что планировать последовательные действия заранее невозможно. Это что означает? Что мы поставили некоторую цель, ударить молотом некоторым определенным образом. Но мы это рассчитали, но Ударили не точно. Он немножко сошел, так сказать, сдвинулся. Так в этом случае необходимо будет потом... То есть мы цель не достигли, мы отклонились от нее. Но чтобы достигать следующую цель... То есть мы можем планировать достижение цели, фиксируя их точно. Но когда мы реально ее достигаем, мы отклоняемся. И необходимо в моменте отклонения вводить сенсорные коррекции, которые к следующей цели, которую мы планируем точно. с учетом этих сезонов и коллекций, мы сможем достичь. Поэтому вот в этой схеме функциональных систем мы можем точно планировать достижение результата, но при каждом конкретном действии, которое осуществляется с некоторой ошибкой, мы обязаны еще вводить некоторые коррекции на возможные отклонения и более того учиться в них. И без такого обучения, на самом деле, хороших роботов типа BigDog не построишь. Более того, это переводит саму схему обучения и саму схему планирования в совершенно другое рассмотрение, а именно, Когда мы движем пальцем к определенному месту, это тоже психологические исследования, мы сначала, его движение несколько распущено, не точно. При приближении к конечной точке он не уточняется. То есть в процессе движения само уточнение и коррекция делается непрерывно во времени. И в этом случае сама работа организуются не так, что им надо вычислить и заранее спланализировать все последовательные действия, а нам достаточно просто следить за тем, что происходит, и непрерывно корректировать способ достижения цели. То есть это совершенно другой способ организации действий. Нам не надо их просчитывать надолго, нам надо просто иметь плотную обратную связь о результате каждого действия. И кроме того, Бернштейн обнаружил так называемые уровни организации движений, то есть некоторых ИРАх организации движений. Он обнаружил, что реально у человека есть уровень организации движений B, которого нет, это организация движений тела, уровень организации пространственного поля C, это пространственные действия, Уровень организации движений действий D – это имеющий определенную цель действий. И он, например, приводил такой пример, что скрипач… Чем он отличается от пианиста? Скрипач приезжал скрипку к телу, и это у него, получается, единство с телом, и он организует свои действия на уровне движений B. совместную с телом. Это согласованное действие мышц. Пионист ударяет по клавишам, при этом может прыгать, ерзать на стуле и так далее, но у него организация движений пространственная. И эти уровни организации движений, они имеют некоторую, так сказать, иерархию. Здесь я не привожу эту иерархию, но здесь надо иметь в виду, что сама иерархия, вот эта иерархия функциональных систем, как они осуществляют действия, она может выстраиваться иерархически. То есть функциональные системы Они свою работу устраивают иерархически. Для того, чтобы достичь целей, нужно достичь вот этих по цели. Достижение этих по цели обращается к запросу к невылежащим функциональным системе. Эти функциональные системы могут обращаться к невылежащим. функциональной системы. То есть здесь на самом деле, так сказать, может развертываться иерархия функциональной системы. Как это математически делается, это есть в отдельной работе, которую можно найти у меня на сайте. То есть это все на самом деле описано. Ну и подведем некоторый итог. По строению информационной системы которая организует, то есть это отдельно самостоятельная теория, математическая, находящая между реальностью и когнитивными процессами, но она устроена таким образом. С одной стороны, она опирается на законы внешнего мира, на причинность, на физический детерминизм, на высококорреливную структуру признаков естественных классов. то есть на строение внешнего мира. Это информационная теория, она с помощью вероятностных формальных понятий и причинных связей, она обнаруживает естественные классы, обнаруживает структуру внешнего мира. С помощью функциональных систем по внутреннему контуру прогнозирует достижение цели и организует достижение цели чисто информационными процессами с помощью прогноза по внутреннему контуру работы мозга, который осуществляется путем прогноза по причинной связи последовательности действий. И на самом деле на уровне самого мозга У нас причейные связи обнаруживаются нейронами. Клеточные ансамбли, а это как раз коги клеточных ансамблей, они нам призваны обнаруживать как раз вероятностные формальные понятия, отражать естественные классы объектов внешнего мира. Сознание интегрированной информации, она как раз описывает высококорреливную структуру, высококорреливная структура. хотя это выставляется чуть-чуть другой формулой, но она обязательно имеет высокую интеграцию информации. И сознание как целое, оно описывается тоже вариантно-формально понятием как целым, а у Леонтия оно описывается как образ мира. И образ мира – это есть непрерывное действие Сознание, когда оно отражает внешний мир, рассматривает конкретную ситуацию и в определенном контексте осуществляет либо целенаправленное ее поведение, либо решение вполне определенной задачи. Ну и, наконец, это, так сказать, сознание. и инклавенционная модель работы мозга, но теперь мышление. Это у нас, так сказать, такая архитектура, которая отражает сознание и все те внутренние механизмы, то множество причинных связей, которые обнаруживались, как они организованы. Организованы некоторые, так сказать, клеточные ансамбли, структуры функциональной системы. Но как они работают конкретно в процессе мышления? И процесс мышления, это уже есть некоторый, так сказать, вполне определенный процесс, который использует вот эти структуры, но использует в точном соответствии, так сказать, это можно отдельно показать, было отдельное доклад, где можно показать, мозг и теория функциональных систем. Это физиологическая система, решение мозгом задачи, задачи уже с точки зрения информационной системы по достижению определенного результата и удовлетворению потребностей. И мышление уже по решению задач действует таким образом, что у нас есть некоторая модель внешнего мира, отражаемая, например, иерархии вероятностных формальных понятий. У нас есть некоторая потребность, которая обращается к этому разуму или к этой имеющейся иерархии знаний, как, так сказать, определенную потребность, которую можно обозначить некоторым предикатом. Решение ищется как поиск ответа на запрос в этой модели внешнего мира, который может быть некоторым, так сказать, объектом или ситуацией, которая сделает это в кардикатной стене, то есть, которая осуществит достижение цели. Принятие решения в этом случае осуществляется с учетом эмоций, либо на основании имеющегося опыта, который будет извлечен из памяти. в соответствии с обнаруженными причинными связями, которые мы выстроим таким образом, что они нам будут прогнозировать достижение цели. Или семантический моделирование, осуществляя прогноз достижение цели с учетом модели предметной области, которая будет говорить, что это ожидаемое будущее по такому-то плану, такой модели функциональной системы будет достигнута. И когда это все прокручивается, то мы получаем решение задачи и достижение цели. Но в этом случае Можно показать, что эта схема, как информационная схема, может быть обобщена, но решение задач достаточно в общем мире, вплоть до схемы некоторого общеискусственного интеллекта. Но это был на эту тему, так сказать, отдельный доклад. Но все необходимые элементы мышления, они, так сказать, в этой схеме задействованы. И все эти элементы мышления, опирается на вот эту информационную модель, на тот, так сказать, то совокупность причинных связей, которые отражены в процессе обучения в разуме, то есть в той полной совокупности наших знаний. И осуществляет решение задач и достижение цели. На этом все. Спасибо за внимание. Вот здесь на веб-сайте есть довольно много статей, в том числе те, которые были проведены по моделированию аниматов, по прогнозированию, по предсказанию и по другим направлениям. Спасибо. 

S03 [01:12:08]  : Евгений Иванович, спасибо. Сразу по поводу материалов и ссылок. Тут вопрос из Telegram написали. Вопрос докладчику. Я не помню, где читал, что на основе ваших работ была создана архитектура искусственной нейронной сети с вероятностными нейронами или вероятностными связями между нейронами, как я понял, вашим студентам. Где об этом можно почитать? Есть ли работы в открытом доступе? Я скинул ссылку на ваш сайт, но Иван пишет, что нет, там не нашел, к сожалению. Эта работа должна быть совсем новой за последние несколько лет. Задайте, пожалуйста, вопрос. 

S01 [01:12:50]  : Да, я могу указать такую работу. на основании вот этой формальной модели нейрона, мы как раз, так сказать, и задались вопросом, а как промоделировать то самое глубокое обучение? Потому что если мы промоделируем глубокое обучение на основании нашего формальной модели нейрона, которая объяснима и прозрачна, в отличие от нейронных сетей и глубокого обучения, то мы в этом случае получим глубоко прозрачное, объяснимое и глубокое обучение. противовес тому глубокому обучению, которое есть. Вот мой бывший аспирант Мартынович, он в этом случае нашел, так сказать, такую статью, в которой было осуществлено глубокое обучение на основании по анализу текстов. И такую статью, и сравнение с медно-глубокого обучения, который анализировали текст, нами проделан, такая статья есть. Я могу, вот если я закрою демонстрацию экрана, то я могу потом показать, получаю в чат сброшу. Сейчас, секунду. Я сейчас прямо ее найду, эту статью. Вот. сброшу ссылку. Сейчас, секунду. Так. 

S03 [01:14:54]  : Про баллистик формал концепт визнегейшн с Мартиновичем статья или другая? 

S01 [01:14:59]  : Прозрачно-глубокое обучение на основе вероятности формального понятия в задаче глубокого обучения. Сейчас я прям ссылку сброшу. на подэй файл. 

S03 [01:15:25]  : Хорошо. Итак, следующий вопрос. Сергей, может быть, сегодня мы вопросов немного пока, поэтому вот пойдём, идём с конца, где несколько человек буквально обозначились. Сергей, пожалуйста. 

S02 [01:15:41]  : я смысле да да да да да да а потом я по привычке жду пока спасибо огромное за сообщение очень как бы комплексно опять получилось но смысле вот многие вещи в одном месте это очень хорошо у меня на самом деле только один вопрос и вопрос корридорный технический Вы упоминали в какой-то момент, когда вы переходите к вероятностям, что вам требуется что-то типа понятия типа большинство. Большинство объектов обладает большинством свойств, а также свойства, которыми обладает большинство объектов в обе стороны. Это фактически некое частотное определение вероятности. Поэтому оно хорошо, когда множество всех объектов и всех свойств перед глазами, оно вот известно. Но тогда понятно, что такое большинство из того, что мне известно. Например, буквы. Вот у меня буквы есть. Если большинство из букв обладает черточкой горизонтальной, то понятно. Вот и черточек конечное число, и букв конечное число, и все перед глазами. А вот как это происходит в общем случае, Как можно говорить о большинстве среди чего-то, что вот это чего-то не определено? Потому что какие объекты мне включить в потенциальный список? Вот я смотрю, стоят деревья. Вот листья мне включать или нет? Если я включу, слишком много будет объектов. Если, так сказать, я их не включу, тогда, так сказать, мало будет объектов и так далее. И то же самое касается признаков. То есть как система будет поступать в случае, даже не система, а как дать определение корректное, если изначально непонятно из какого множества надо большинство выбирать. Спасибо большое еще раз. 

S01 [01:17:31]  : Да, ну на самом деле, конечно, вот этот алгоритм, он работает так, когда у нас объекты все есть, признаки все есть. На самом деле, все то же самое можно несложно переделать в интерактивное обучение, когда мы по тактам обучаемся. Я по тактам обучаюсь, мы на самом деле статистику мы непрерывно накапливаем, она у нас хранится. Если мы подошли и вот зашли в лес, только зашли, но у нас есть статистика набранная относительно разных деревьев, относительно разных листьев, и когда мы их интерактивно воспринимаем, мы их тут же распознаем и относим к определенному классу. тут работает несколько другой алгоритм. То есть, есть отдельный алгоритм, он опять же у нас описан, когда на основании вероятностных формальных понятий пришел новый объект, и мы как-то смотрим, он относится к этому вероятностному формальному понятию или нет. То есть, есть определенный алгоритм с определенными оценками, который тут же относит его к определенному классу. Если он никуда не относится, такое тоже может быть, он начинает считать его уникальным объектом и относительно него свою статистику начинает собирать. Поэтому это все происходит итеративно, когда мы попали в некоторую конкретную ситуацию, мы, конечно, сначала, опять же, с точки зрения контекста, мы воспринимаем широко. Но если у нас есть вполне определенные задачи, и нам, например, надо там где-то пройти, а мы то толком не видим, где-то что-то застранено, где-то там что-то не так, или там какие-то препятствия, то мы уже когда концентрируемся, мы более точно уже определяем те и классифицируем те объекты, с которыми нам придется иметь дело, Более точно уже соотносим те понятия, которые нам надо для них, собственно, применить. тем самым фокусируется контекст, а как только фокусируется контекст, соответственно, фокусируются и извлекаются те закономерности, которые более точно относятся к этому контексту. Здесь, я думаю, самая непонятная вот какая вещь. Она имеет место как раз этого символа фонализирования. что есть так называемая функция эмоций, когда мы попадаем в новую ситуацию неожиданную, вот, и у нас происходит регресс закономерности, то есть регресс, то есть вот у нас есть некоторая среда, мы к ней привыкли, мы ее очень хорошо знаем, у нас очень точные правила, которые прогнозируют в ней поведение. но мы попали в новую совершенно неожиданную ситуацию, которая нам не знакома. В этом случае происходит реверс закономерности, то есть тонкие закономерности, они уходит на второй план, потому что у них есть в посылке дополнительные свойства, которые в этой новой обстановке просто неприменимы. Но дело в том, что мозг хранит все закономерности, и простые, и более сложные, и более точные. Он хранит всю иерархию закономерностей со всеми возможными условиями. И когда у нас ситуация новая и необычная, то извлекаются из памяти те простые правила, те простые закономерности, которые в данном случае применимы. То же самое имеет место относительно контекста. Вот мы сначала смотрим широко, мы используем разные закономерности, но могут возникнуть некоторые противоречия, некоторые неясности. Мы начинаем обращать внимание на разные не стыкующиеся между собой элементы. Но вот нам надо уже что-то делать конкретно, мы смотрим на ситуации более конкретно. Как только мы сконцентрируемся на более конкретно, мы у нас уже извлекаете те закономерности более точные, которые работают в этой более конкретной ситуации. то есть автоматически идет перестройка самих закономерностей, или как это делается в некоторых современных обучениях, идет автоматический пересчет вероятности, которые годятся в этой ситуации. 

S02 [01:21:50]  : Все-таки вот смотрите, то есть получается, что есть какой-то дополнительный механизм, который отсекает те объекты, которые я сейчас не буду учитывать. Чтобы обновить мне какую-то вероятность, мне надо иметь объекты, которые меня интересуют каким-то образом, и то, что можно назвать всеми объектами. И тогда их отношения между собой, это и есть то самое большинство. Мне нужно иметь и числитель, и знаменатель. Числителям понятно, это то, на чем я сейчас сконцентрировался. А как мне ограничить знаменатель? означает ли это, что мозг всегда работает исключительно с дискретным набором этих понятий? просто он не способен одновременно очень много набрать понятий, и они автоматически усекаются до того какого-то узкого конуса, с которым я сейчас работаю. Это еще один механизм такой, отсечение второстепенных несущественных признаков. Правильно я понимаю? 

S01 [01:22:43]  : Да-да-да, это есть еще один механизм, но я о нем совершенно ничего не рассказывал. Дело в том, что он исследовал еще в зрительной карьере. Когда анализировали зрительную кору и стимулы анализировали, коры обнаружили, что, вообще-то говоря, обездвиживали глаза, обездвиживали восприятие и показывали разные стимулы. И смотрели, какие нейроны реагируют на какие стимулы. Так они обнаружили, что, вообще-то говоря, много нейронов, которые обнаружили достаточно общие стимулы. Квадраты, круги, еще что-то, палочки и так далее. Но оказывается, что Если мы возьмем эти общие стимулы, но одновременное возбуждение этих нейронов, а если мы возьмем пересечение этих кругов, а пересечение кругов будет все более точно, все более точно, может свестись вообще к отдельной точке. То есть признаки более общие, они могут фильтроваться, группироваться, формирует очень точное описание. И вот такая фильтрация или настройка признаков, это то есть отдельный механизм, который настраивается на существующий реальность. 

S02 [01:23:51]  : Понятно. Спасибо большое, Геннадий Ильич. Можно еще раз, раз Антон сказал, что вроде мало вопросов. Я вот еще хотел терминологически тоже уточнить. когда вы используете термин причинно-следственная связь, но не всякая связь является причинно-следственной у вас, наверное, да? То есть, если я правильно так понял из контекста рассказа, это такая направленная связь, то есть это любая связь со стрелкой, которая имеет направление, вот такую вы бы называете причинно-следственную связь, да? 

S01 [01:24:21]  : Да, здесь надо более точно, конечно, говорить, но более точно это означает следующее. Вообще-то говоря, физические причины, это не физические причины связи, это, так называемые, вероятностные причины связи. В частности, это определение максимально специфических причинных связей, вероятностных, оно удовлетворяет определению Cartwright, вероятностной причинности относительно произвольного баграма. Но дело в том, что хотя мы обнаруживаем на объектах тех, которые мы смотрим, то есть когда мы обнаружим некоторый класс и дифференцируем некоторые животных по определенному классу, на самом деле, как говорят естественные испытатели, разрезать и посмотреть внутри для более точного отнесения, но мы же не можем их разрезать. Мы определяем их отношение к классу по внешним признакам. Внешние признаки, они статистически зависимы между собой. Но, когда мы начинаем в процессе нашего восприятия, как это происходит в цикле восприятия Найсера, когда мы начинаем зрительно, сначала мы видим одни признаки, Потом прогнозируем другие. Мы переводим взгляд на то, что мы спрогнозировали. Мы начинаем это разносить по времени. Вот здесь у нас появляются уже настоящие физические причины. То есть мы видели при одни признаки, переведи взгляд, мы спрогнозили, что должно быть вот это, перевели взгляд, определили, да, это, перевели взгляд, да, это. То есть когда мы уже развертываем это в деятельности, в нейродинамические ткани деятельности, реализуются уже как физические причины. 

S02 [01:26:00]  : Но все-таки вот тут хочется терминологически понимать более точно. Вот то, что в результате получается, это некоторое успокоение мозга. То есть мозг успокоился в том смысле, что он уверен, что он очень точно распознал объект. Но это же еще не означает, что то, к чему сошлись эти связи, является истинными физическими связями, потому что среди них там могут быть и какие-то вторичные связи, корреляции, которые не являются причинными и так далее. То есть это именно в том смысле, что работа такого итерационного поиска заканчивается, когда заканчивается желание ее продолжать. 

S01 [01:26:36]  : Когда мы все причины связи замкнулись, когда происходит восприятие, восприятие не сразу. Как говорит Найсер, должно пройти цикл восприятия. Оно должно пройти от частного к целому, а потом замкнуться от целого к частному. 

S02 [01:26:55]  : когда мы поймем, что все, что мы предсказали, оно все правильно сошлось, то есть у нас опять бабки подбиты, то значит... Ну да, для индивидуального восприятия это достаточно, там проблемы могут быть, если вы такое описание захотите кому-то передать вербальным, но это другая задача. Все, спасибо огромное, Евгений Евгеньевич, я извиняюсь, затянул беседу. Спасибо большое еще раз. 

S03 [01:27:21]  : Спасибо, Евгений. Не могу не удержаться, Сергей, по вашему вопросу прокомментируя, что если нам не хватает чего-то для замыкания полной картины и успокоения, чтобы можно было дальше не думать, мы можем допридумать что-нибудь такое, что замкнет картину и позволит нам успокоиться. 

S02 [01:27:37]  : Хотя на самом деле... Антон, после этого это назвать причинными связями. Прощаю ваше внимание. И даже это кому-то транслировать в качестве теории. 

S03 [01:27:48]  : У которого не будет этой части. Поэтому не согласится. У меня вопрос технический, Евгений Евгеньевич. Вы в какой-то момент сказали про хранить всю информацию. Как быть с проблемой переполнения памяти? Мы действительно можем все хранить? Или это была просто фигура речи? 

S01 [01:28:09]  : Дело в том, что все хранится внутри нейрона. Он же, когда обнаруживает эти причинные связи, они все внутри нейрона. Другое дело, что происходит так называемая дифференциация стимулов. То есть, сами эти причинные связи внутри нейрона, они дифференцируются, становятся более точными, но они там и хранятся, то есть, никакого переполнения нигде не происходит. 

S03 [01:28:33]  : ну то есть практически это что означает что мы вот все что мы видим мы все запоминаем и ничего не забываем, и количество информации с каждой секундой жизни у нас увеличивается, которую мы помним. 

S01 [01:28:47]  : Да-да-да, вот мы и проводили такие эксперименты. Дело в том, что для стандартных нейронов имеет место эффект забывания, когда они обучили чего-то одному, потом начинают много передавать других объектов другого класса, они первые забывают. Но это нейрон основан на сумасшедшем. Наши нервы ничего не забывают. Они просто дифференцируются, и все. 

S03 [01:29:14]  : Борис, я вижу, вы киваете головой, но у вас очень много вопросов, поэтому я вас со всеми вашими вопросами в конец отодвину. И чуть-чуть еще продвинусь со своей стороны, Евгений Евгеньевич, а тогда у меня следующий вопрос. Вот там у меня у самого есть куча примеров. Я думаю, если тут есть товарищи, которые с нейросетями занимаются, они тоже могут примеры привести, которые говорят, что на самом деле много информации в большинстве случаев вредно, потому что если мы используем максимум информации для предсказания чего-то, то мы скорее всего будем, что называется, оверфитить. некий свой прошлый опыт хотя на самом деле новый опыт он никогда не будет точности совпадать вот и поэтому на самом деле надо при предсказании принятие решения использовать все-таки не всю информацию а только наиболее значимую информацию вот и тогда мы будем сказать не обязательно предсказывать будущее точно Но в большей числе случаев мы не будем придумывать несуществующих вещей, которые мы видели в прошлом и которые не соответствуют будущему. Часто бывает необходимо все-таки что-то забыть или что-то отбросить при использовании предпредсказаний для того, чтобы получить более устойчивый прогноз. Это называется сильная генерализация. 

S01 [01:30:39]  : Дело в том, что это в нейронных сетях такая каша. Дело в том, что вот те нейроны, которые обнаруживают причинные связи, они их и обнаруживают так. Вот причинная связь дифференцируется, что для более точного предсказания можно включить еще этот признак, этот, этот и этот. Но когда у нас вот эта причинная связь образуется, ее вероятность увеличивается, А нейрон обладает таким важным свойством. В первую очередь и быстрее всего срабатывают максимально вероятные причинные связи. То есть как раз те связи, которые точны. Поэтому остальные связи, которые там масса их много, и не точных, и не точно относящиеся к нашей обстановке, они просто не будут активированы. Потому что сработают те точные, которые максимально используют имеющуюся в данный момент информацию, и сработают по вероятности даже быстрее по времени. 

S03 [01:31:36]  : Скажите, пожалуйста, Евгений Евгеньевич, уже более чисто практический вопрос. Насколько я знаю... Это уже вопрос реализации, вопрос кода, а не теории. У Пейванга, насколько я помню, есть такой механизм, когда он запускает логический вывод, и в силу того, как у него там все устроено, В первую очередь логический вывод осуществляется как раз по тем связям, которые более вероятны. Таким образом, естественным путем получается, что если мы даем на решение задачи ограниченное время, то для того, чтобы отвлекаться там и учитывать всякую ерунду, просто вычислительных ресурсов не хватает. И в итоге сработают самые сильные признаки, самые значимые признаки. В силу принципа тяжести, в первую очередь, мы принимаем наиболее вероятное решение. Как у вас в вашей системе это устроено? 

S01 [01:32:36]  : Точно так же. Прежде всего, срабатывает максимально вероятный которые в то же время, в моем определении, они одновременно максимально точные, то есть они используют максимальную информацию одновременно, они и есть максимально вероятные, но дополнительно еще проводится контроль, но это же не с помощью отдельных правил, а это с помощью вероятности формальной понятия, они не должны противоречить друг друга. Но дело в том, что даже самые отдельные правила, когда они обнаруживаются на основании такой максимальной специфичности, они, как правило, отбираются достаточно четко. Вот мы когда анализировали финансовые религии, мы там есть закономерность, которые купить и которые продать. В данный момент можно и купить и продать. Но всегда там могут срабатывать тысячи закономерностей за одно. и там одно, два, три будет быть против. То есть они на самом деле оказываются достаточно специфичными сами по себе. То есть когда мы берем, когда правильно обучается максимально вероятным правилам, то они сами по себе достаточно точно срабатывают. 

S03 [01:33:50]  : Спасибо. Еще один практический вопрос. Евгений Евгеньевич, вот эта история про теорию функциональных систем и подкрепление той последовательности, которая привела к желаемому результату. Я в прошлом и уже даже в позапрошлом году как раз делал работу на примере пинг-понга, который представлял на OpenTox и на AGI. И там все это прекрасно действительно работает. Но есть одна проблема с определением границ последовательности. Начиная с какого момента считать ту последовательность, которая привела к желаемому результату. Потому что если мы последовательность возьмем слишком длинную, то мы запомним всякую ерунду, которая не имеет отношения. Если мы возьмем слишком короткую, то опять-таки мы не будем учитывать какие-то важные шаги, которые были в начале, и тоже будем выучивать непонятно что. Как быть, с вашей точки зрения, с определением границ последовательности? 

S01 [01:34:53]  : Вот в том-то и дело, что здесь как раз есть совершенно четкие критерии, которые как раз и определяет в каком случае эта закономерность, это правило добавляет новые условия в свою посылку, то есть новые условия. Оно добавляет его в том и только в том случае, если его добавление, то есть вот этого дополнительного шага или этого дополнительного действия по нашей предыстории значимо увеличивает вероятность достижения цели. Если это не так, мы его не учитываем, мы не используем. 

S03 [01:35:28]  : Окей, спасибо. И последний вопрос, который, по-моему, от меня и от Бориса одновременно до того, как мы перейдем к вопросам Бориса, про естественную классификацию. Понятно, что у нас там может быть естественная классификация букв, но как быть, например, с нулем, который он же О? Вот, например, ноль в классификации букв – это одно, а в классификации цифр – это другое. То есть, правильно ли я понимаю, что одни и те же объекты могут входить в разные системы естественной квалификации, которые как раз задаются контекстом? То есть, разные контексты разной системы естественной классификации. 

S01 [01:36:11]  : Да, они могут входить. Более того, эта естественная классификация – она генератическая. То есть вот эти самые буквы, они, например, имеют кружки внизу или кружки вверху, девятка или шестерка. Так вот, поскольку… Как действует принцип построения вот этих вот вероятностных формальных понятий? То, что взаимопредсказывается само по себе, и зацикливается, то это может быть некоторый самостоятельный класс. То есть, например, вот у шестерки, и не только у шестерки есть, вот у шестерки вот у этой, вот у восьмерки есть такой кружок. Вот как только обнаружил вот такой вот отдельный элемент, на котором признаки зацикливаются сами на себя, а продолжение, возможно, разное. то в этом случае оно зацикливалось, и вот этот кружок тоже будет отдельным вероятностью формального понятия. Но он будет входить вот в это более целостное вероятность формального понятия. То есть так называемая иерархия вторичных признаков, она также будет автоматически обнаруживаться по той простой причине, что каждый вторичный признак, как элемент, может входить в разные объекты, а поскольку он может входить в разные объекты, то с него, с этого признака нельзя спрогнозировать, что вокруг, потому что это окружение может быть разное. Поэтому причины связи сами на себя будут зацикливаться на самостоятельных таких статистических единицах, и они тоже будут являться некоторыми элементарными и вероятностными формальными понятиями. 

S03 [01:37:54]  : А как быть, это вот уже пошли вопросы Бориса, с различными почерками написания букв и цифр. Ну, например, вот даже если взять то, что сейчас на экране, единичка может быть с косой палочкой, а может быть просто, как в американстве пишут, вертикальная палка. Четверка может быть с кочергой, а может быть с треугольником вверху. Ну и так далее. Семерка тоже может быть с перечеркнутой палкой. Не говоря уже про почерки. Как вот с этим быть тогда? 

S01 [01:38:26]  : Ну, здесь есть два механизма. Один механизм – это, так сказать, обобщение, поскольку вот здесь у нас есть вот эта четверка, а у нас еще вот такая четверка, вот такая четверка, вот такая четверка, вот такая четверка. Вот те вариации, которые… программа сама обнаружит, что те вариации, которые незначимы для ее обнаружения, а значат, например, находение вот здесь черты и вот здесь черты, они не будут включаться в правило. То есть одновременно, если есть вариации в цифрах, то там, где эти вариации несущественны для распознавания, они перестанут входить в правило. То есть будут находиться более общие правила. Если они будут позволять, будем они точно. прогнозировать эту цифру. Но и одновременно, одновременно, то есть это процессы в обе стороны, одновременно будут находиться закономерности, есть определенные заколючки, но которые как элемент значим, значим, это в каком смысле, что он не является случайной эклякцией, случайным каким-то отклонением, а он встречается в других местах, то есть он является значимым элементом. В этом случае, как значимо или нет, если он будет позволять более точно прогнозировать или относить к классу ту или иную цифру, он будет включен в закономерности. То есть есть одновременно два процесса – дифференциация и обобщение. И каждый раз распознавание будет происходить на основании либо общих правил, либо более дифференцированных, смотря какие будут применимы к данному конкретному объекту и в каком контексте. 

S03 [01:40:09]  : А с этой точки зрения про птиц, вот есть птицы, вот есть классификация животных, но вот есть птицы, но не все птицы умеют летать и видеть гнезда на деревьях. Как вот с этим быть тогда? 

S01 [01:40:25]  : Ну, понятное дело, что не все птицы умеют летать. Отдельно будет класс, где только птицы, которые видят гнезда на деревьях. Потому что видеть гнезда на деревьях, это будет один из важных признаков этих птиц. Поэтому это будет отдельный самостоятельный класс. Но если есть птицы, которые не летают и не унесут на деревья, то есть у них будет признак, который не предсказывается, или более того, предсказывается отрицание этого признака, исходя из другого класса, то это будет другой класс. Потому что здесь надо иметь в виду, я об этом не сказал, что обнаруживается закономерность, как предсказывающие наличие того или иного признака. так и предсказывающие, что в этой тройке не может быть, например, такой горизонтальной линии или вот такой. То есть одновременно предсказывается, что здесь не должно быть. Поэтому, если мы воспринимаем одну цифру, мы вытормаживаем остальные. То есть, еще процесс идет и в гипермарше. 

S03 [01:41:28]  : А я правильно понимаю, что, давая ко всему, у нас эти классификации не обязательно иерархические? То есть, у нас на самом деле могут быть, что называется, хитерархии, где, к примеру, белки или тяги могут быть одновременно и млекопитающими, и летающими, а страусы могут быть одновременно и птицами, и нелетающими? 

S01 [01:41:51]  : Иерархия не строго как дерево, а это решетка. 

S03 [01:41:57]  : Хорошо, спасибо. Дальше вопрос от Бориса. Есть ли в вашей теории место подсознанию? 

S01 [01:42:09]  : Подсознание – это как раз тот самый разум, то есть та самая масса информации, которая накоплена в течение всей жизни. Константин Владимирович относит это к разуму. То есть, как он иногда рисует, что здесь айсберг. То, что мы реально сейчас ощущаем, то, что мы реально осознаем, реально действуем, это некоторая верхушка. А то много всего накопленного опыта, всех знаний, которые у нас вообще есть и которые в данный момент могут быть неприменимы к данной ситуации или не полуактивны, то они находятся в рамках разума, но не активны. Подсознание, конечно же, есть. 

S03 [01:42:49]  : Спасибо. Еще есть вопрос от Бориса. Есть ли связь этого подхода с работой Джуди Перл, Дана Маккензи в The Book of Why – The New Science of Cause and Effect? 

S01 [01:43:03]  : Такой взаимосвязи нет по одной простой причине, что Джудия Первого ограничился байсовскими сетями, которые не допускают сигналов, поскольку это позволяет более-менее точно рассчитывать вероятность. В системе, где причины связи зациклены сами на себя, он такой случай в принципе не рассматривает. 

S03 [01:43:29]  : Спасибо. Следующий вопрос Бориса. Откуда и как возникает деление признаков на существенные и несущественные? 

S01 [01:43:38]  : Те, которые включены в закономерности, они существенные. Более того, эта существенность проявляется специально в статистическом критерии или с определенной значимостью. Так что это не просто существенность, а еще существенность с определенной значимостью. 

S03 [01:43:54]  : Спасибо. Следую последний вопрос Бориса. Если идти с конца к началу, откуда нейрон знает вероятности и факторы? Знает в кавычках. 

S01 [01:44:05]  : Нет, вероятности он, конечно, не знает. То есть, теоретически мы описываем через вероятности. А нейрон работает с той статистикой, с той частотной вероятностью, которая к нему приходит. Он подсчитывает те случаи, которые были, какие признаки были, в каком сочетании были, когда была правильная реакция, когда не была правильная реакция. Он работает с частотной вероятностью. Но теорема доказывается относительно любой вероятности. 

S03 [01:44:35]  : Спасибо. Так, последний вопрос от Бориса. Кроме вероятности исхода нужно учитывать его вес, важность для агента. Да, кстати, вот к вопросу о пиванге. У него пиванга, кроме вероятности составной, там, truth and confidence, у него еще есть impotence, это важность. 

S01 [01:44:54]  : Да, но дело в том, что да, вот здесь вот и вероятность сама по себе. Вот. Она может быть одинаковой, то есть если мы 100% получите 2 из 2 и 100 из 100, будет одна и та же самая вероятность. Так вот дело в том, что значимость признака и включение его в условия, она определяется не по вероятности. Хотя мы смотрим, что вот он у нас увеличил вероятность, но увеличение вероятности может быть и чисто случайно. Такой признак, который по чисто случайным обстоятельствам оказалось, что чуть-чуть увеличивает вероятность. Но мы учитываем этот признак только в том случае, когда он не просто случайно увеличивает вероятность, а статистически значимо поувеличивает вероятность. То есть это проверяется специальным критерием анализа таблиц сопряженности. 

S03 [01:45:50]  : Хорошо. Борис, пожалуйста. 

S04 [01:45:54]  : Спасибо. Здравствуйте. Сначала я хотел бы уточнить последний вопрос. Речь идет о значимости для агента. Он может разбить чашку с вероятностью 5% или умереть с вероятностью 5%. Это совсем разные вещи. 

S01 [01:46:15]  : Да, это учитывается. Аппарат эмоций, он строго учитывает, как значимость достигаемого результата, так еще и вероятность этого. 

S04 [01:46:23]  : А где слова «прозначимость»? В каком месте слова «прозначимость»? 

S01 [01:46:28]  : Не, ну дело в том, что потребности, да, не было явно своей прозначимости, но она была, сейчас я скажу где, она была довольно вскользь, вот, у Симонова. 

S03 [01:46:47]  : Это потребность, да? То есть, потребность – это как раз прозначимость, да, Евгений? Потребность, она имеет разную значимость. 

S01 [01:46:54]  : Потребность имеет разную значимость. Вот потребность и ее качество и величины. То есть, она может быть разной, разной значимости, разной силы. 

S04 [01:47:07]  : Спасибо. Спасибо. Хорошо. 

S03 [01:47:10]  : Спасибо. 

S04 [01:47:11]  : Сергей, пожалуйста. 

S03 [01:47:14]  : Давайте комментарии чуть позже. У Сергея есть еще вопрос. Зачем нужны две разные половины мозга? 

S02 [01:47:20]  : Сергей, поясните. У меня вот такой вопрос. Доводилось в 90-х годах работать с замечательным физиологом Ниной Валерьяной Вольф в Новосибирске в Институте клинической медицины и нейрофизиологии. У нее была замечательная теория о межполушарной асимметрии и ее важности. И в частности она говорила о том, что вот у женщин межполушарная асимметрия устроена не так как у мужчин. Женщины раньше недосформированный аттрактор в правом полушарии передают в левое для дальнейшего анализа. А мужчины, они, так сказать, итерируют его там, пока он там не сойдется там и так далее. Поэтому иногда мужики тупят, а женщины интуитивно сразу, так сказать, как бы действуют. У меня такая была теория. Но вот у меня возникает такой вопрос. Если в вашем построении, Евгений Евгеньевич, такое место, как бы Но принятие решений в условиях, когда еще не сошлась вот эта вот поисковая система. То есть она еще не, так сказать, не сформулировалась, потому что это может быть долго. Чисто эволюционно. Может так получиться, что когда много признаков, много объектов, то просто очень долго решается задача, и мозг должен иметь механизм отказаться от дальнейших, стараться искать. Но я вот с какой-то точностью считаю, что это вот такой-то объект и начинают действовать, и так далее. то есть существует, он не дожидается вот этого, так сказать, ответа, образа результата действия, а завершает эту вот поисковую программу по осмыслению, по распознаванию раньше. И вот в этой связи нет здесь необходимости. Откуда взялись все-таки левая, правая полушария? Нет ли здесь разницы между ними и функциями, вот именно с точки зрения того, что одно обязательно итерирует для точности, а второе интуитивно бросает итерацию и уже начинает там действовать? Вот можете тут что-то прокомментировать? 

S01 [01:49:10]  : Да, значит здесь несколько ответов. 

S02 [01:49:13]  : Понятное дело, что… Ну и вопросов было несколько. 

S01 [01:49:19]  : Да, значит понятное дело, что… Вот когда у нас пришел, так сказать, вот объект не полностью определенный, это как-то плохо определенный, в каких-то дырках или в каких-то штрихах или еще что-то. Понятное дело, что какие-то закономерности сработали, какие-то нет, что-то неприменимо. У нас, так сказать, некоторые частичные знания, получается, об объектах. Но в этом случае вот даже для... Тут вот я опустил, опять же, мы проводили эксперименты по... формированию вот таких образов цифр в условиях, когда эти цифры с пропусками, там у них нет определенных данных, и волей-неволей они должны доопределяться. Но они могут доопределяться, чтобы цикл замкнулся, либо есть еще, в любом случае это все делается на основании вполне определенного критерия согласованности взаимопредсказания этих причинных связей. То есть есть определенные критерии. Он тоже, так сказать, шиноновский. Он, так сказать, отличен от шиноновской меры энтропии Танони. Танони хотел, на самом деле, в точности это вычислить. Но мы его используем для того, чтобы правильно, так сказать, найти наилучшее соответствие, наименее логически противоречащее тому, что наблюдается. То есть мера нестыковки причинных связей. Вот есть такой дополнительный критерий. Кстати, Танони меня пригласил напечатать в журнале «Энтропия» ту меру, которая у меня. Но я написал полный вариант статьи про сознание. Он говорит, мне философия не нужна, мне нужна формула. Есть такая формула, есть такая. По поводу права него, здесь тоже отдельный разговор, потому что на самом деле в области уже как бы таких практических вещей есть графы знаний, которые как бы логические или символы интеллекта, и нейронной сети, которая как бы образная и правополушарная интеллекта. Постоянно идет вопрос о том, как сделать некоторый симбиоз. И вот на самом деле эта проблема симбиоза довольно сложная. И сейчас это одна из наиболее актуальных тем в области искусственной интеллекта и Data Science. Как интегрировать нейронные сети и графы знаний. Мы, в частности, в рамках компании Huawei такого рода проекты рассматривали. Это не тривиальная и серьезная проблема, которая будет решаться. С точки зрения взаимосвязи нейронных сетей как образных понятий, И графов знаний как логические системы. На самом деле, вот есть имбидинги графов знаний в нейронной сети. Это один способ интеграции графов знаний в нейронных сетей. 

S02 [01:52:26]  : Евгений Евгеньевич, интеграция – да, это уже постфактум. Я-то хочу понять, почему эволюционно потребовалось, почему оказалось выгодно. иметь два разных таких типа, там какой-то нечеткий там мутный ассоциативный и более такой жесткий формальный, как вот мы сейчас это понимаем. 

S01 [01:52:45]  : А эволюционная это вот из-за чего возникает, потому что в нейронной сети сейчас о чем упирается, вот есть экспоненциальный рост сложности обучения нейронной сети, когда начинает обучаться переводы или еще что-то, там возникает огромная сложность обучения нейронных сетей. Но это почему? Потому что нейронная сеть, для того чтобы ей правильно распознавать структуру текста или структуру сложных каких-то объектов и правильно ее распознавать в этой иерархии, она должна иметь большую и очень множество уровней, большую и лучшую сложность. Вот верхние уровни как раз, которые, так сказать, призваны соединять между собой разные части, их лучше делать логикой вариантов на графуме. То есть, как бы, структуру объектов лучше улавливать графом, а, так сказать, отдельный элемент объекта лучше улавливать нейронными сетями, в частности, Вот мы же усваиваем еще некоторые понятия, которые мы обучаемся в процессе обучения. Язык. Язык сразу ухватывает очень, вообще-то говоря, некоторые довольно общие образы, которым нейронная сеть сама на автомате будет учиться таким абстрактным понятием достаточно долго. Авграф знаний ее вложил, просоциировал нужным образом с элементами нейронной сети, и она работает. Поэтому это такое разделение, но в правильном смысле и эффективно. 

S02 [01:54:20]  : То есть правильно я понимаю, что нужно иметь возможность не доэтерировать до конца при очень большом количестве объектов и признаков, но не четко выделенным, не четко определенным и плохо сформулированными вероятностями, с одной стороны. А с другой стороны, надо иметь возможность в частном случае как-то очень прецизно, точно решать какую-то частную задачу, где уже там сужено количество признаков и сужено количество объектов. там уже надо это сказать точно решать и поскольку надо и то и то то еще там до появления там буквы так далее пока читать не научились и не было никаких языков уже была вот это функциональная симметрия. Наверное вот такие соображения. 

S01 [01:55:00]  : Спасибо большое. 

S02 [01:55:03]  : Спасибо. 

S03 [01:55:08]  : Коллеги, спасибо. Так, есть рука. У нас кончились вопросы. Давайте комментарии. Борис, пожалуйста. 

S04 [01:55:18]  : Во-первых, я хочу поблагодарить докладчика за интересный доклад и Сергея Терехова за интересный вопрос. Он мне очень понравился. Наблюдая за работами господина Витяева, У меня сложилось такое впечатление, что они очень хороши для моделирования работы интеллекта. То есть, когда зафиксирована какая-то общая генеральная модель, и внутри неё сделаны уже постановки задач, которые надо решать. И вот как решать задачи в рамках определенной модели, вот здесь эти работы очень хороши. Но это определенный класс моделей, а не реальность. Вначале говорилось о разных реальностях. Скажем, о реальностях мозга. Так вот, модели... Для лечения эпилепсии, для конструирования компьютеров, нейронных сетей или программ совершенно разные нужны для медицины и для компьютеров. И на разных уровнях, если эпилепсию лечат сими электрошоком, то компьютеры там действительно ниже нейрона, наверное, идти не надо. Если зафиксирована глобальная модель, например, пиксели на экране, разнообразные множества пикселей на экране, то к ним и ставится задача классификации этих множеств на подмножества. Тогда применимы примерно эти подходы. А если у нас есть реальность физическая, то эти непонятные для выживания агента, человека или агента, какие в этом контексте признаки существенные, а какие несущественные, то эти подходы для построения моделей психики и сознания, мне кажется, не годятся. Они годятся для моделирования работы интеллекта. Спасибо. 

S01 [01:57:41]  : Ну, ответить можно, да? 

S03 [01:57:44]  : Пожалуйста, конечно. 

S01 [01:57:46]  : Ну, на самом деле, вот то, что я рассказываю про задачный подход, там действительно предполагается заданная модель и заданная металлология. Но это в рамках задачного подхода. Когда же я рассматриваю уже модель работы мозга так, как вот здесь в докладе, Мне не нужно предположение о том, что какая-то антология мне дана. Мне достаточно, что есть какой-то набор, может быть даже очень большой, стимулов, которые мы воспринимаем. Этого мне достаточно. Из этих наборов стимул я сам автоматически сформирую, с помощью вероятностных формальных понятий, иерархию сущностей, Вот, иерархия естественных классов, иерархия вторичных признаков. Автоматом будет определено, что существенно, что нет. И будет выстроена некоторая такая иерархия вероятностных формальных понятий, отражающая модели внешнего мира. То есть, модель будет построена автоматически. 

S04 [01:58:49]  : Модели для чего? в пустыне Калакарии или для профессора в МГУ? 

S01 [01:58:57]  : В модели для любого когнитивного процесса. Я же тут описывал, например, целенаправленное поведение любого когнитивного процесса. 

S03 [01:59:10]  : Хорошо. Спасибо. Сейчас еще есть вопрос с комментарием от Ильгизара Талипова. Предложена концепция универсального всевидящегося фиксирующего мозга и причинности, находящейся исключительно во внешней реальности. Причинность, связанная с различиями степени развития образованности мозга у разных людей, в вашей теории отрицается или не рассматривается? А также, как это выглядит для мозга животных? Они тоже все фиксируют? 

S01 [01:59:42]  : Ну, фиксируют, конечно, фиксируют. Более того, что особо интересно, фиксируют и могут по-разному. Вот, например, есть люди, которые учились читать, например, есть, которых учили в школе по буквам, по складам, вот, у них в этом случае возникает такое обучение, что они, есть внутренний процесс внутреннего проговаривания, после этого они воспринимают слова. А если и тогда причины связи и процесс осознания текста, он включает, в том числе, проговаривание слов. А есть люди, которые обучались словам, так сказать, как некоторым паттернам, зрительным образом. У них в этом случае возникает скорочтение, но не только скорочтение. Они в этом случае у них иначе образуются и организуются даже умственные процессы. Они по-разному мыслят. И это все следствие того, как человек обучается, как обнаруживаются причинные связи. 

S03 [02:00:43]  : Спасибо. Так, еще есть рука у Владимира Смолина. Владимир, пожалуйста. 

S00 [02:00:51]  : Так, меня слышно. 

S03 [02:00:52]  : Да-да-да, здравствуйте. 

S00 [02:00:53]  : Даже видно. Ну, очень приятно, конечно, слушать всех серьезных профессионалов, которые, конечно, каждый про себя считает, что он лучше всех знает, как на самом деле. Вот. Ну и вот Борис Новиков, он, конечно, говорит, что задачный подход – это все, что как бы то, что человек там не может задавать… В смысле, не надо, чтобы искусственный интеллект задавал понятие, потому что это человек будет задавать. А если он будет задавать искусственный интеллект, то как мы будем его управлять, таким нам искусственный интеллект и не нужен. Это тоже подход к решению задачи. Но вот у докладчика говорится о том, что можно для любой задачи построить. Но там видится другая проблема. Слово «сложность» в докладе, сколько бы серьезно ни прозвучало. Проблема всех гуманитариев в том, что им сложно посчитать, Досюда мы можем, как сказать, разделить какие-то вещи и набрать достаточно статистики, а потом нет. То есть, если мы рассчитываем, что мы что-то будем наблюдать, и нам всегда хватит памяти, чтобы запомнить разные состояния, ну, в общем, это слабое место в том, что нам сегодня рассказывалось. мы все-таки скатимся к задачному подходу, когда понятие выделяется, как предлагает Борис Новиков «человек», а уже остальное с этими понятиями можно оперировать, либо все-таки из доклада осталось непонятно, а как, кто будет составлять графы, потому что мир он никогда не повторяется, все у нас каждый раз сложно, и вот эта надежда, что мы разные для произвольного потока сигналов из него все выделим, на изначально заданном наборе символов. Это, на мой взгляд, наивное представление. 

S01 [02:02:36]  : Дело в том, что я не говорю про интуицию, про такой когнитивный процесс, но и хорошо известно, что на самом деле интуиция и некий только подсознательный процесс, который в то же время одновременно все-таки запоминает и фиксирует некоторые важные, но элементарные какие-то свойства. То есть, например, был такой эксперимент, что брали глаза от девушек и немножко их ретушировали, то есть увеличили зрачки. И предъявили парням фотографии девушек с ретушированными зрачками и не ретушированными зрачками. И спрашивали, какая красивше. Большинство из них сказало, что красивше там, где расширенные зрачки. Но никто не в состоянии был сказать почему. То есть, это свойство, хотя оно интуитивно было понятно, и более того, оно совершенно очевидно. Вот эта схема, о которой я рассказывал, она будет уловлена соответствующим героном, который на входе эту информацию выделяет. То есть, уловит тот стимул, который связан, так сказать, с ощущением красоты, который есть. Если такой стимул есть и ощущение красоты есть, такая условная связь будет найдена. Но это будет уже в рамках, так сказать, интуитивного ощущения. Поэтому, на самом деле, все такие тонкие вещи, они тоже всегда обнаруживаются. Более того, их обнаружение можно пустить по этим же схемам, о которых я рассказывал. 

S00 [02:04:08]  : поэтому интуиция здесь тоже участвует ну вот как бы все эти на самом деле легенды про левое правое полушария то есть если вы знаете не всех людей даже сердце слева есть бывает справа поэтому собственно кто кто как пекин полушария думает это такая непроверенная гипотеза на самом деле. И, собственно, о том, что левое там символиное, а правое, как сказать, ассоциативное, это тоже такая очень скользкая гипотеза. Как и в целом предположение, что мышление – это, собственно, логика. Это как бы вот та сказка, на которой мы живем. Вот. Ну и вот как бы вот это вот большое, много причин для невзаимопонимания, они, собственно, ну, собственно, сложны для дальнейшего обсуждения. То есть у нас совершенно разные взгляды. 

S01 [02:04:48]  : С этим я совершенно согласен, потому что есть люди, которые по-разному думают. Есть люди, которые думают образно, есть люди, которые думают логически, причем настолько логически, что те, кто думают образно, вообще не понимают, как это вообще возможно. Опять же, я не об этом. Это тоже неизвестно. 

S02 [02:05:07]  : Владимир, я-то тоже согласен, потому что я и с самого начала сказал, что это гипотеза. это гипотетические построения, которые пытаются объяснить феномен интуиции, женской интуиции. 

S00 [02:05:18]  : ну, как вы понимаете, это чисто воды мифы. ну, конечно, это же феноменологический уровень. Скарпетта Мандерсона и братьев Гримм, они замечательные в жизни, и нельзя сказать, что они совсем никакого отношения к жизни не имеют. они, конечно, имеют отношения, но очень косвенные. 

S02 [02:05:33]  : Володь, ну конечно, это феноменология. Ну понятно, это феноменологический уровень, но он тоже в науке присутствует. Если мы не можем сейчас на самом нижнем уровне логическом разобраться, максимотическом полностью ответить на вопрос, мы прибегаем к феноменологии. Ну что делать? 

S00 [02:05:49]  : Нет, понимаете, проблема как раз в том, что уже давно там выявлено, что, собственно, логика не может объяснить все проблемы, и когда у нас появляются новые проблемы, мы, собственно, находим какие-то изменения в логике, чтобы эти проблемы тоже решались. И проблема не в том, как использовать логику, а как строить новую логику для новых наблюдений. 

S02 [02:06:08]  : люди за свое место под солнцем борются конечно люди борются собственно вот из доклада о том как это будет делать искусственный интеллект в общем за и за это особо пока не будет но нет но вот я тут хотел бы немножко защитить докладчика вот какой часть дело в том что действительно немножко создается впечатление что имеет место такой сад эдема то есть мы должны туда сначала попасть каким-то образом и А дальше строится довольно стройная и понятная теория, которая, вернее, многогранная, из многих аспектов состоящая, но все-таки некая теория, к которой можно относиться как к теории. А дальше возникает такой вопрос. А вот этот переход от реальной жизни в сады демо мы должны на нем зацикливаться сейчас. Если мы сейчас не знаем, как туда перепрыгнуть, то давайте остановимся и будем пытаться искать. Вот есть позиция такая у ученых, что иногда можно и перепрыгнуть на какое-то время через непонятную какую-то нам, так сказать, речку с тем, чтобы представить себя, что будет, если мы окажемся на другом берегу. Вот я считаю, что такого типа исследования тоже имеет место, потому что они полезны. Но они, по крайней мере, готовят нас к этому перепрыгиванию. 

S00 [02:07:17]  : Я совершенно не против того, что бумага все стерпит. И несмотря на то, что даже какие-то исследования не имеют никакого отношения к жизни, все равно там может быть что-то интересное и полезное для жизни. 

S02 [02:07:29]  : – Володь, вы очень категоричный. 

S00 [02:07:31]  : – Я не категоричный. Я говорю, что я не спорю, я говорю, что, наверное, это полезно. 

S03 [02:07:36]  : – Коллеги, не мешайте Владимиру объясниться, что он утвердится в том, что он не согласен. 

S02 [02:07:42]  : – Все, услышали, услышали. 

S03 [02:07:43]  : – Владимир не согласен. Все услышали, что Владимир не согласен. Давайте еще вопрос от Бориса Новикова. А как быть одновременно конкурирующими целями агента? 

S01 [02:07:57]  : Дело в том, что на самом деле эта схема очень легко распространяется на случай, когда у агента несколько потребностей одновременно. Конечно, у человека есть так называемый принцип доминанта, и он в конце концов концентрируется на чем-то одном. Но на самом деле это не обязательно. Очень легко ту же самую функцию полезности в соответствии с той же самой информационной теорией Симонова представить таким образом, что агент будет учитывать максимальную полезность, которую одновременно будет включать, что он, например, будет достичь сразу нескольких целей одновременно, или сначала одну, потом с минимальными затратами тут же другую. Это все легко устраивается в эту систему и в соответствующую функцию полезности. 

S03 [02:08:46]  : А ещё тогда уж там был комментарий от Бориса в какой-то момент, что сознание – это не про одного агента, а про взаимодействие между разными агентами. То есть, поясните, Евгений Евгеньевич, это просто у Бориса своя версия, понятие интерпретации, что такое сознание. И если это так, то как взаимоотношения с агентами соотносятся, вписываются в то, что вы рассказываете? 

S01 [02:09:21]  : Взаимодействие агентов, беседы людей или какое-то их общение, в данном случае это отдельная тема, которую я не рассматриваю. Это отдельная тема. Но я рассматриваю понятие сознания, когда есть один индивид, он обучается целенаправленно действовать в некоторой среде. 

S03 [02:09:43]  : То есть, в вашей формулировке сознания взаимодействие не обязательно совершенно? 

S01 [02:09:50]  : То есть, есть среда? Да, это отдельная тема, но не обязательно. 

S03 [02:09:55]  : Я тогда уж прокомментирую для Бориса, что у нас есть работа совместная с Евгением Евгеньевичем про коллективное сознание, где на самом деле функциональная система сообщества составляется из функциональных систем членов сообщества. Имеет место и на самом деле и поведение одного отдельного агента тоже может описываться как некоторые иерархии функциональных систем. То есть есть разные функциональные системы в том же самом агенте, которые отвечают за различные его сферы и цели деятельности. И тут как бы все выстраивается. Борис, пожалуйста. Борис, Вас не слышно. 

S04 [02:10:42]  : С моей точки зрения теория функциональных систем это хорошая модель, но далеко не единственная и не вся мебельщина. И с точки зрения этой теории обучение у человека или у агента идет психика. Обучается психика, а не сознание. И в психике есть неосознанные процессы, которые тоже обучаются. Был вопрос про подсознание. И для хорошего моделирования целесообразно различать осознанные процессы или сознание и неосознанные процессы психики как подсознание. 

S01 [02:11:25]  : Ну, это можно различать, но мне это не потребовалось. 

S04 [02:11:29]  : Поэтому эта модель ограничивается только осознанными ситуациями. 

S01 [02:11:35]  : Нет, нет, нет, ни в коем случае. Ни в коем случае. Она включает весь разум. 

S04 [02:11:43]  : Можно два слова. Когда вы различаете цифры, вы подумаете, что вся реальность вашей модели в этот момент – это картина. Озвуки, вес, тепло и так далее не учитывается. А это тоже важнейшие факторы для агента. Только в данной конкретной модели и в данной конкретной задаче они несущественны. И это определено заранее, когда вы различаете цифры. А когда вы не в реальности, то вы не знаете. Достаточно вам визуальной информации, или надо еще флуховую. И небольшой ответ Сергею Терехову. Образное мышление нужно реагировать быстро. Если обезьяна услышала звук, то она должна либо замереть, либо бежать, либо напасть. Ей некогда. строить логические модели и решать, какое из этих решений будет оптимальным. И нужно это сделать быстро. И это делается вот по гипотезе, как сказал Владимир Смолин, образными моделями правополошарными. А когда нужно изготавливать лодку, тут можно подумать, как это делать и научиться у других и так далее. И это уже более или менее левополусадная работа, пока не надо колотить конкретно камнем или молотком или чем-то еще, где тоже подключается трава. 

S02 [02:13:20]  : Спасибо. Это да, Борис. Я, конечно, согласен с этим комментарием. Это понятная вещь. Вопрос возникает, когда между ними начинается взаимодействие. какой момент конкуренция между полушариями вот опять-таки в этом гипотетическом предположении приводит к тому что можно или нужно отказаться от ассоциативного насчет анализа который не точно уже видно что он не ведет к ответу переключиться на логический или наоборот то есть но вот вы привели пример когда доминанта есть точно известно что надо бежать спасаться и тогда ассоциации либо точно известно что надо заниматься таскать там уравнением фрид горьба второго рода тогда это как бы там логика понятно А вот нет реального места, это когда они между собой начинают синтетически взаимодействовать, передавая друг другу информацию. И вот тут возникает вот этот вот собственный вопрос. А вот в чистых случаях, конечно, вы абсолютно правы. 

S04 [02:14:12]  : Про это есть хорошая книжка Мегдала о поисках научной истины. Там это подробно рассмотрено. 

S02 [02:14:20]  : Как рождаются физические теории. 

S04 [02:14:22]  : Да, как рождаются физические теории. 

S02 [02:14:24]  : Да, да, да. Понятно, да. 

S03 [02:14:30]  : Хорошо. Коллеги, какие-то еще есть вопросы или комментарии? Я думаю, тогда мы поблагодарим Евгения Евгеньевича за доклад, за информацию. Коллеги, всем спасибо за вопросы. И до новых встреч, Евгений Евгеньевич. Спасибо большое. Да, Вам спасибо. Всем до свидания. 

S01 [02:15:02]  : До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
