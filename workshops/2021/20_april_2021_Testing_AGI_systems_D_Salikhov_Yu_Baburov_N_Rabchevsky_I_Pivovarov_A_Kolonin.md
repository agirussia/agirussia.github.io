## 20 апреля 2021 - Тестирование систем AGI — Д.Салихов, Ю.Бабуров, Н.Рабчевский, И.Пивоваров, А.Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/_-KGSMdvPW4/hqdefault.jpg)](https://youtu.be/_-KGSMdvPW4)

Суммаризация семинара:

Семинар посвящён тестированию систем искусственного интеллекта (AGI). Участники обсуждали различные подходы к тестированию, включая самопредсказуемость и самообучение. Особое внимание было уделено проблемам, связанным с насыпанием тестовых условий и их соответствием реальности.

Тема 1: Самопредсказуемость и самообучение

- Ключевые тезисы:
  - Самопредсказуемость как способность системы предвидеть свои собственные действия.
  - Самообучение как процесс улучшения системы на основе предыдущих опытов.
  - Проблемы тестирования систем, способных к самоподкреплению.
- Вывод: Тестирование систем, способных к самоподкреплению, требует новых подходов, отличных от традиционных тестов общего интеллекта.

Тема 2: Реальные и потенциальные среды

- Ключевые тезисы:
  - Различение между реальными и потенциально реальными средами.
  - Реальная среда включает в себя взаимодействие человека и робота в реальных условиях.
  - Потенциально реальная среда — это моделирование реальных условий в программном обеспечении.
- Вывод: Важно понимать, как реальные и потенциально реальные среды влияют на тестирование систем AGI.

Тема 3: Тесты и соревнования

- Ключевые тезисы:
  - Тесты и соревнования являются разными подходами к оценке систем AGI.
  - Тестирование машин включает проверку их возможностей в различных условиях.
  - Соревнования, такие как гонки на автомобильной дорожке, отражают специфические навыки и не всегда соответствуют общему интеллекту.
- Вывод: Необходимо различать тестирование и соревнования, так как они служат разным целям и отражают разные аспекты интеллекта.

Тема 4: Генеральность AGI и критерии обучения

- Ключевые тезисы:
  - Генеральность AGI определяется широтой покрытия векторного пространства.
  - Обучение агента на нескольких играх и последующее обучение на новой игре в ускоренном темпе.
  - Различие между брутфорсом и настоящим интеллектом в решении задач.
- Вывод: Важно учитывать скорость и разнообразие задач при оценке обучаемости и интеллектуальности систем.

Итог

Семинар подчеркнул сложность тестирования систем AGI и необходимость разработки новых методов и критериев для оценки их способностей. Участники обсудили различные подходы, включая самопредсказуемость, самообучение, и критерии обучения, подчеркивая важность понимания реальных и потенциально реальных сред для тестирования.




S03 [00:00:00]  : Трансляция началась. Да, коллеги, добрый вечер. Трансляция началась, так что, Дима, пожалуйста, тебе слово. 

S06 [00:00:22]  : Да, сегодня у нас... Да, всем привет. Семинар сегодня про тестирование. Моя такая, можно сказать, чуть ли не основная тема, которой я занимаюсь в AGI, кроме, собственно, разработки AGI. Вот. И почему тестирование важно? Вот сейчас сразу после меня будет Игорь Филоваров рассказывать, почему это не важно и почему это неприменимо. Но в целом, Вот почему, я считаю. Это еще более важно, чем традиционная система тестирования для моделей узкого интеллекта, вот эти так называемые ML-бенчмарки. Почему? Потому что сам по себе AGI – это такая эфемерная штуковина, которую никто не понимает, что это такое, как ее делать. вот ситуация. какой-нибудь Иван Кулибин приходит к нам и говорит, я сделал AGI. но показать, что он делает, я вам не покажу. вы все равно не понимаете, как это устроено. вы не знаете, что такое AGI. поэтому вы, собственно, ничего не проверите. поэтому вы можете просто не проверить, что это AGI. дайте мне денег. чтобы так не происходило, нужны какие-то стандарты. стандарты, с которыми, ну, какое-то определенное большинство согласится. Вот. Тогда, собственно, люди не будут тратить время на разработку не пойми чего и на обсуждение каких-то там ежиков в тумане. Вот. И таким стандартом как раз должны выступать тесты. То есть сделал AGI, пройди тест. Лучше несколько. но это если все было так просто. вот есть сложности определенные в отличие от ML-бенчмарок. первая сложность в том, что мы не можем измерять интеллект напрямую никак. какие бы там методики не придумали, тем не менее, мы можем только измерить решение задачи интеллектуальной. вот и вся наша отрасль, вернее развитие, показывает, что даже если у нас есть какая-то задача, мы не можем точно сказать, что ее можно решить именно интеллектом, интеллектуальными усилиями, не применяя эвристики и хакер. Классическая история пуш-кахматы, сами знаете, как это все развивалось. И вторая сложность — это автоматизация, т.е. тестирование без человека. Очень сложно проверять интеллект машины, которая сама интеллектом не обладает. Тот же самый тест Юринга, если его правильно провести, то вполне себе это тест NGI. но его никак не получается автоматизировать, пока у нас нет полноценного интеллекта. Но все-таки, несмотря на все эти сложности, люди как-то исхитряются и придумывают хорошие тесты, которые и автоматизированы, и те, которые, собственно, проходят первые критерии сложности, то есть которыми нельзя подобрать евреистики, но, в всяком случае, пока не набрали. Ну, например, я говорил про abstracted prism challenge всем известных. Ну вот, вкратце, это вот то, о чем вообще тестирование, зачем оно нужно. И давайте послушаем Игоря Кивоварова, который нам расскажет свою точку зрения. 

S05 [00:04:06]  : Спасибо. Я, во-первых, хотел совсем разгромный выступить критикой, но потом, когда я почитал текст Николая Рабчевского, я понял, что термин «тестирование» нуждается в уточнении. я бы, во-первых, предложил разделить это обсуждение на две части. есть тесты, а есть то, что я бы назвал некая среда, в которой эта модель проявляется, этот AGI в принципе работает. в этом плане, например, какой-нибудь kaggle или вот какой-то leaderboard это тестирование, а например там условно openai gene, где набор как бы рейльных игр но я не отношу к тесту, я это отношу скорее к среде, в которой эта модель учится и проявляется. и при таком разделении, я абсолютно согласен с Николаем Воробьевским заранее, я видел его текст, что среда абсолютно необходима, потому что нам нужно, чтобы в чем-то эта модель работала, развивалась и проявляла себя. а вот тест, на мой взгляд, был бессмыслен. тест в понимании, например, как тест Тьюринга. в частности, он бессмыслен по двум причинам. во-первых, на примере вот этого теста Тьюринга… сегодня была очень хорошая статья я могу сбросить ссылку сейчас не помню интервью там с каким-то человеком по компьютер безопасности он там Русские являются потому хорошими хакерами, потому что… Что такое хакер? Хакер – это человек, который смотрит на какую-то ситуацию и видит то, чего не видят другие, пытается найти изъяны, пытается найти как бы как система… Там работает, где ее изъяны, где ее можно сломать. И тезис в том, что мы, например, русские, мы по жизни, живя в Советском Союзе и в России, очень часто живем против системы и все время видим, как ее где можно сломать. И в этом смысле, ну, хакеров просто много там среди русских. И в данном случае тест Тьюринга, например, выступил именно такой историей, на которую многие смотрели исключительно на то, как ее можно сломать и обойти. То есть как только мы ставим тест и задачу пройти тест, тут же... Люди бросаются не делать этот самый IGI, не делать этот интеллект, а ищут способы, как обойти тест, как его решить. И как ты это ни сделай, все равно сама задача теста всегда будет вот такая. это первая причина. то есть первая причина, почему тесты бесполезны, именно потому, что они подменяют собой главную задачу, и люди начинают думать, как тест решить, а не как построить систему. а второе, почему тесты бесполезны, потому как мы опираемся во многом на на свой опыт, естественно. Мы все учились и все учились в школе, в университете, сдавали какие-то тесты, зачеты, экзамены и прочее. Для нас это привычный формат. Ты чему-то научился, сдаешь некий тест. Я уже опущу, что я там был частично троечником, никогда не гнался за оценками, но я хотел бы отметить, что вот эти задачи эти экзамены и тесты зачеты этот тест на объем знаний усвоенных который в школе мы сдаем или в университете но это никогда не тест на интеллект мы как бы преподаватель никогда когда к нему приходит человек и сдавать да он никогда не сомневается в наличие у него интеллект это подразумевается то есть мы как бы априори считаем что мы так сказать общаемся с там с интеллектуальным существом это не надо доказывать а доказывается как бы знает или не знает некоторое количество знаний а тут мы хотим тест на как бы наличие интеллекта и я бы так сказал мягко что я вообще не знаю в человечестве но как бы ни одного такого теста который там который бы был направлен на то, чтобы выявить, есть ли интеллект у собеседника или нет. Ну, как-то, ну, правда, вот тестируют, пытаются это сделать, но я не уверен. В этом плане я думаю, что, конечно, среды точно нужны, но упираться в тестирование, ну, мне кажется, бессмысленно. Скорее, я вот согласен тоже с Николаем, с одним из его тезисов, просто глядя на то как эта система перформит в разных задачах и как она как бы обучившись на каких-то одних задачах там применяет это не эти знания, а как она, обучившись на других задачах, работает в других задачах, я бы так сказал. Хотя это тоже, наверное, в своем роде является тестированием. В общем, у меня критика… Я бы сказал так. если кто-то предложил бы какую-то комплексную систему из нескольких разных пунктов, которые бы в сумме закрывали понимание, то я бы с этим согласился. отчасти мы немножко об этом то ли на прошлом, то ли на позапрошлом семинаре говорили. я, собственно, высказывался по поводу MVP. примерно то, что я высказал, что должна быть система, которая просто работает в разных областях и решает там разные задачи. но она претендует на то, чтобы быть ij. вот, собственно, такая позиция. 

S06 [00:10:38]  : спасибо, Игорь. но я сразу немного возражу. это был первый пункт. бесполезность... ну, вообще, как таковых тестов, попыток тестирования. и почему, да? почему ты считаешь, что бесполезно? потому что люди сразу придумывают хаки в ристике и, собственно, просто гонятся за метрикой. с этим поспорить нельзя тут, собственно. Человеческая натура такова. Если у нас есть задача, ее нужно решить, во что бы то ни стало. Но тесты все-таки полезны, несмотря на то, что все эти побочные эффекты происходят. Почему полезны? Вот возьмем тот же самый Obstructive Reasoning Challenge. Что там происходило? приходили люди, которые, собственно, притаскивали весь багаж знаний и технологий, которыми они привыкли решать задачи узкого интеллекта, и, собственно, давай пробовать, да, потому что вроде бы там какое-то зрение присутствует, какие-то там небольшие данные, да, какая-то обучающая выборка хоть и сверхмала и так далее, вот. И когда они видели, что это все не работает, вот, они сильно удивлялись. происходил большой слом шаблона. это нам понятно, что эти штуки будут не работать, но для основной массы ресерчеров, которые считают, что они делают искусственный интеллект настоящим, это было настоящим сюрпризом. они думали, что все задачи так или иначе подвластны вот этим методом, который уже есть. и все лишь дело в масштабировании. дайте нам больше данных, больше вычислительных мощностей, и мы решим вообще все что угодно. тут хоба вроде бы такой простейший тест, такой элементарный, который решает дети от 7 лет. я проверял на своих. вот. и все, значит, у них там были очень большие такие инсайты и прочее, что да, ребята, оказывается, есть такие вещи. ARC, в частности, и тесты подобные, в общем, они пока служат лишь вот таким вот моментом поворота сознания людей. для того, чтобы они начали, ну, там, не знаю, один из ста людей, да, все-таки заинтересуются, а как же по-настоящему можно решить эту задачу. То есть не просто плюнет и скажет, ну, не работает ML, ладно. Вот. И как раз эти тесты, мне кажется, являются вот таким драйвером для того, чтобы именно вот, ну, во-первых, для того, чтобы люди понимали, что AGI – это все-таки отдельно от ML, а во-вторых, чтобы они в это вкатывались. Собственно, вот. 

S05 [00:13:33]  : ну да, но тест как таковой, сейчас как это сказать, например, ты, допустим, выкатываешь свой лидерборд и говоришь, вот там лидерборд для AGI, допустим, у меня есть архитектура какая-то, которая там у меня есть, я вот смотрю на этот тест, я понимаю, что мне, например, для того, чтобы участвовать в этом тесте, мне нужно какой-то API к ней написать, разобраться в том, как устроен лидерборд, скачать эту выборку, как-то с ней поработать. На это уйдет какое-то время, ресурсы. Это некий вопрос, нужен ли в такой формате, будут ли люди тесты проходить. Скорее, я бы сказал, что для AGI я бы видел, что более правильным форматом являются не тесты, а то, что называется челленджи. это известная американская контора, они регулярно объявляют такие челленджи, вот например один из последних челленджей был аватар так называемый, значит, сделать там робота, который там в совместности с человеком, ну неважно, не будет. Смысл в том, что это типа конкурса скорее, но не тесты с жесткими критериями, а как бы вот там челлендж делать что-то. Ну вот если терминами тестов, то был какой-то тест, что там вот робот должен зайти в какой-то произвольный дом и налить чашку кофе, да? не помню, ты рассказывал про него там на одном из семинаров. можно назвать это тестом или нет, я не знаю, но вот это такой челлендж скорее. кофетест. да, кофетест. но это челлендж, это не тест в чистом виде. его разные люди могут решить по-разному, разными архитектурами. и он очень как бы свободно сформулирован. ну может быть в такой форме это пригодно. окей, i'm done. 

S06 [00:15:35]  : в целом соглашусь, что есть некая градация между тестами и челленджами. вот я то, о чем я буду рассказывать, скорее относится к последней категории. но все-таки как бы не совсем понятно где где что где другое так ладно антон пожалуйста микрофон антон микрофон 

S01 [00:16:00]  : ага спасибо так сейчас значит давайте я тогда так я хочу сделать чтобы мог шарить экран показать несколько картинок так вот но я их покажу чуть позже в общем значит к вопросам 

S03 [00:16:17]  : Переходя к вопросу, можно ли надежно выявить, что перед нами AGI? Для этого нужно определиться, что такое AGI. Соответственно, исходя из того определения AGI, которое я использую, это достижение сложных целей в сложных средах, используя ограниченные ресурсы, при том сложных сред может быть много. Соответственно, если мы сможем создать такие тесты, которые будут удовлетворять данному определению и верифицировать решение задачи в рамках данного определения, то мы можем Это надежно выявить. Каковы критерии надежного теста AGI? Соответственно, нам нужны критерии множества сред, сложности сред, достижения целей в этих средах. И эти среды должны иметь возможность создавать условия ограниченности ресурсов. ну например да то есть давайте я перейду к примерам то есть к примеру вот если говорить мы берем за основу системы типа опыта прости ты вроде хотел экран расшарить я экран расшарить чуть позже пока ну я могу сразу расшарить чтобы как бы контекст был по экранам давай так screen Соответственно, как я вижу идеальную среду для тестирования. Сразу отнесусь к тому, что вы с Игорем обсуждали, что нам нужны не столько челленджи, сколько тесты. Челлендж – это одно, а тесты – это другое. А я бы вот за это зацепился и сказал, что если мы можем челленджи оформить в виде тестов, то есть если мы можем автоматизировать процесс прохождения энного количества тестов, и оценки результатов прохождения, фу, исполнения некоторого количества челленджей, исполнения и качество исполнения, прохождения этих челленджей в качестве тестов, да, и собирать, грубо говоря, если бы у нас был фреймворк, в рамках которого мы можем систему по кругу гонять через задачки OpenAI Gym и по каждой задачке собирать некоторые метрики, формализованное исполнение этих тестов, а потом собирать все это в единый дэшборд в рамках лидерборда, то мы автоматически получили бы вот это. То есть, на самом деле, лидерборд – это применение лидерборда, в рамках которого исполняется одна конкретная Система AGI – это на самом деле тест-харнес, который на выходе дает степень прохождения теста на AGI от нуля до единицы или от нуля до ста процентов. Это с одной стороны. С другой стороны, это как мы можем верифицировать количество разных сред. И, соответственно, чем больше у нас вот этих челленджей затолкано в эту среду, тем в большей степени мы можем верифицировать AGI-ность. Дальше. Среды должны быть сложные. Здесь немножко сложнее. Нам нужно формализовать параметры сложности. Что такое сложность? Это что? Это число измерений в пространстве, в котором фигурирует агент, или это количество модальностей, в той среде, в которой он оперирует. Или это разрешение экрана или цифрового сигнала в каждый из этих сред. То есть, на самом деле, нужно как-то формализовать сложность по нескольким параметрам, где у нас есть модальность, где есть количество модальностей, где есть количество параметров, количество, может быть, объектов, количество разрешения. скорость обновления информации. Соответственно, надо как-то прометровать сложность. И вот у нас получается второе измерение. То есть, по одной оси мы откладываем количество сред, и качество прохождения тестов в этих средах. По другой оси мы откладываем сложность, каждый из этих отдельно взятых сред. Но у нас еще есть ограниченность в ресурсах. Вот. Тогда у нас получается третья ось. Соответственно, по третьей оси мы откладываем ресурсы. Сколько, допустим, процентов ЦПУ съедает агент на заданном типе оборудования. Или с какой скоростью агент научается играть в пинг-понг до того момента, когда он перестает проигрывать. сколько он тратит, сколько проходит эпоху. Или по-другому. У нас критерием теста заявляется, что мы даем агенту 100 эпох на то, чтобы научиться играть в пинг-понг или 5000 эпох. Если он не научился за 5000 эпох, то он тест провалил. И дальше мы можем эту планку поднимать. Соответственно, по параметрам ресурсов, по параметрам количество сред и по параметрам сложности этих сред, мы можем создать некоторое трехмерное пространство, где мы можем оценивать либо прохождение, не прохождение теста, или выполнение того или иного челленджа. Где под челленджем, я сейчас пока не говорю, то есть, что такое челлендж, это вообще отдельная история, мы про нее чуть позже скажем. Мы вот каким-то образом формулируем челлендж, И в трехмерной шкале собираем информацию о том, как он эти разные челленджи, насколько быстро, насколько эффективно и насколько сложно эти челленджи проходят. Так, дальше. Значит, соответственно, следующий вопрос. Какие среды теста сейчас отвечают критериям из P2? Соответственно, в каком-то смысле, если мы присовокупим человека, который собирает, прогоняет некоторую систему через множество соответствующих челленджей и собирает эти результаты. То вот OpenAI Gym в купе с оператором, который прогоняет эту систему через OpenAI Gym, можно считать, что он является вот таким прототипом этой среды. Какую систему тестирования вы предлагаете? Но я предлагаю либо то, что я сейчас описал, но это надо делать. Хотя в своей собственной работе я использую немножко другой подход. Мой подход заключается, который у меня родился несколько раньше, чем я столкнулся с OpenAI Gym. Он заключается в следующем, что мы создаем между агентом и внешним миром некоторый интерфейс. Причем это символьный интерфейс. Символьный интерфейс – это, на самом деле, возможность агента общаться с внешним миром через некоторое множество символов, которое заранее не определено. То есть, мы создаем, скажем так, некоторый язык. без словаря, где есть только, скажем так, знаки припинания, пунктуации, с помощью которых мы можем создавать некоторые структуры. И с помощью этого языка мы этому агенту на вход передаем некоторые сигналы о том, что происходит в этой среде, а он на эти изменения в среде, соответственно, какими-то сигналами реагирует. То есть все, что То есть у нас получается, в случае OpenAI Gym, нашему агенту передается параметр Environment и Feedback, а агент должен на это отреагировать некоторым choice, некоторым набором из числа предложенных действий. А здесь, получается, на вход мы продаем просто поток символов, и на выход тоже ожидаем поток символов. Это было сделано для того, чтобы мы в рамках этого потока символов в том числе могли задавать не какие-то абстрактные переменные или состояния среды, а выражения на некотором языке, либо естественном языке, либо на некотором синтетическом языке. И в своей системе EIGEN, собственно, Все общение системы происходит на таком вот символьном языке, в который в том числе вписывается как естественный человеческий язык, как частный случай, так и некоторый редуцированный или упрощенный, или контролируемый язык, который у меня называется Яйджинс лэнгвич, и он содержит некоторые базовый набор символов, который позволяет создать в рамках некоторой фундаментальной онтологии любую онтологию в любой предметной области, с помощью которых можно как раз создавать различные среды. Получается, для того, чтобы начать тестировать агента в какой-то новой среде, мы, используя фундаментальную онтологию, загружаем ему параметры той среды, структуру той среды, в которой он будет работать, а дальше мы уже Начинаем ИКТМО загружать событиями в этой среде, и он в терминах антологии этой среды может на это как-то реагировать. Еще покажу сразу пару примеров. Вот, например, как это выглядит. Да, давайте, прежде чем как это выглядит, еще важным моментом тестирования является в дополнение к рабочему определению EGI, где у нас есть разные среды, множество сред, богатство сред и ограниченность ресурсов. Важно еще понятие обучения, то есть понятие того, что агент должен учиться. То есть мы должны верифицировать не только наличие или отсутствие какого-либо интеллекта, а мы должны еще верифицировать способность этот интеллект обретать. И вот здесь как раз возникает необходимость реализации концепции так называемого baby-turing-теста, идея которой заключается в чём? То есть, на сегодняшний день я ни разу нигде не видел формализации этого baby-turing-теста, поэтому я рассказываю сейчас как бы своё видение. Но Барбара Порти – это замечательная женщина. Дай бог ей долгого здоровья. Она продолжает жить и трудиться на сегодняшний день. Но, тем не менее, это было давно, когда она эту концепцию предложила. И концепция примерно следующая. Что давайте мы создадим некоторый черный ящик, который не умеет вообще ничего. И начнем с ним взаимодействовать. И по мере того, как мы с ним взаимодействуем, давайте будем смотреть, как он меняет свое поведение. И мы должны убедиться в том, что по мере того, как он получает от нас какую-то информацию, обратную связь, какие-то факты, какие-то события, может быть он как-то сам воздействует на нас, а мы отвечаем ему своими реакциями, в результате этого он меняет свое поведение, оно все более и более и более умное. И на самом деле здесь происходит вот такая смычка концепции baby-turing-теста с той парадигмой обучения, о которой мы говорили с Игорем Пивоваром несколько раз за последнее время. Это вот пресловутый curriculum learning. Когда с одной стороны мы должны реализовать этот самый curriculum learning, чтобы болванка пустая, которую мы получаем в начале Процесс обучения по мере обучения могла выполнять все более сложные когнитивные функции, или строить все более и более сложные выражения, как показано на этом примере, или понимать все более и более сложные выражения. А с другой стороны, мы должны создать какой-то тестовый фреймворк, который будет позволять контролировать, что вот у нас есть черный ящик, мы у него потыкались вначале, он говорит какую-то лубуду. Мы с ним чуть-чуть поработали. Теперь проверяем, перестал лабуду говорить, уже как-то нормально реагирует. Ну и грубо говоря, мы можем, например, симулировать таким образом процесс обучения ребенка, некоторого виртуального ребенка, начиная от программы детского сада, дальше программы первого класса, программы второго класса и так далее, верифицировать, сможем ли мы этот черный ящик с полного нуля дорастить до какого-то там уровня, я не знаю, студента третьего курса, к примеру. Но на сегодняшний день это работает в рамках моей Development Framework. Я вообще большой любитель тест-дривен-девелопмент и считаю, что вообще все нужно делать тест-дривен-девелопмент, в том числе AI тоже, с моей точки зрения, можно делать тест-дривен-девелопмент. Там единственная проблема, что если у нас есть некоторые рандомные системы, основанные на рандомном поведении, то для тестов приходится, что называется, фиксировать рендемсид для тестов. То есть тест должен предполагать определенный фиксированный рендемсид. про это можно поспорить но вот тем не менее так это сейчас работает ну вот пример того как собственно вот то что мы видим это просто выхлоп юнит тестов которые выполняется в рамках каждого билда да вот когда делается какая-то фича вначале пишется скрипт на вот таком вот контролируемом языке, который является некоторой редуцированной версией английского. Когда появляется любая фича, то она протаскивается через некоторую онтологию, в рамках которой эта фича работает. После чего мы убеждаемся, что если мы загружаем эту онтологию в агента, обучаем его работе с этой онтологией, после чего в результате взаимодействия с учителем он обретает возможность реагировать таким образом, как учитель ожидает. Вот здесь очень простой пример. Мы спрашиваем, что такое персона. Он говорит, что такого понятия, как персона, нет. Мы говорим, что есть такое понятие, как персона. Он говорит, окей. Мы говорим, что у персоны есть первое и последнее имя. Спрашиваем его, что есть у персоны. Он нам уже отвечает, что у нее есть имя и фамилия. Теперь мы говорим, что... Есть такая персона, которую зовут Алан Тьюринг. Он говорит, окей, мы спрашиваем, он начинает нам про это рассказывать, и начинаем постепенно его накручивать, наполнять его среду различными знаниями. Здесь простая функция создания классов и создания экземпляров классов, но все более сложные функции, они, собственно, валидируются примерно таким же образом. Так, значит, я уже дальше должен закругляться. Значит, если наша цель сделать прототип AGI, помогут ли сделать тесты? Ну, поскольку мы делаем технологию, если мы инженеры, то в рамках инженерии мы должны сделать некоторую среду разработки. Среда разработки должна предусматривать верифицируемость наших результатов. То есть, если мы работаем по задачному подходу, то у нас должен быть акцептор результата действия, то есть мы ставим задачу сделать AGI, соответственно у нас должны быть критерии, которые нам позволят верифицировать, что мы этот AGI достигли. Если мы пишем код, то у нас должны быть юнит-тесты, у нас должны быть интеграционные тесты, чтобы не получилось так, как Игорь жаловался в прошлый раз, что в какой-то момент Значит, он что-то там улучшил, после чего у него система вообще перестала учиться. Если бы было регрессионное тестирование на возможность учиться-учиться, вот в тот момент, когда все сломалось, бы зафейлился билд, и можно было бы в нужный момент откатиться на предыдущий коммит и понять, что ты сломал. Как с помощью тестов в среду отличить прототип AGI от очередной технологии Neural AGI? Два способа. С одной стороны, верифицировать, создать фреймворк, который будет верифицировать процесс обучения от нулевого уровня до некоторого другого уровня. Вот это не гарантирует читерство, потому что читер может создать такую систему, которая будет читить процесс обучения, то есть в начале обучения она будет говорить ничего не знаю, хотя на самом деле все знает, а потом постепенно будет говорить, что нет, я вот все-таки чему-то научилась, хотя она уже научилась этому давно, ну и тоже можно подделать. Но можно пойти по следующему пути. Можно сделать возможность вообще обучать систему работе в новых средах. То есть, если у нас система имеет возможность воссоздания моделей тех миров, которые вообще отсутствуют заранее, которых вообще трудно вообразить. То есть, если мы можем взять какую-то отдельную совершенно среду или отдельное операционное пространство новое, и это произвольное операционное пространство с помощью средств описания операционных пространств самого фреймворка загрузить в эту систему, и убедиться в том, что в новом операционном пространстве, в произвольном, оно способно обучаться и решать новые задачи этого операционного пространства, то, видимо, можно отличить подделку, потому что система, которая заточена на определенный набор операционных пространств, она не сможет решать задачи в произвольном операционном пространстве. Когда я говорил, я подумал, что можно еще подумать о том, что вообще рандомно генерить операционное пространство, и критерии решения задачи в этих рандомных операционных пространствах, которые неизвестны даже заранее испытателю. Как количественно измерять процессы AGI? Я это уже сказал. В трехмерном пространстве, чем больше разных сред, чем более среды эти сложные, и чем быстрее решаются задачи в этом трехмерном пространстве, и чем меньше потребляется ресурсов, тем количественно прогресс к AGI больше. Насколько универсальный может быть средотест? У нас General AI по тому определению, которое я использую, где нет критерия того, что такое General Enough, чем больше сред и тем более универсальная среда. Насколько универсальна может быть сама среда и тест? Чем различнее, тем разнообразнее, тем лучше. Среда, ну вот с моей точки зрения, среда должна иметь возможность описывать вообще любые среды. Среда тестирования должна описывать любые операционные среды. Вот как, например, OpenGM. В OpenGM на входе есть набор параметров, которые описывают среду. На выходе, точнее, на выходе и наоборот на входе, смотря с какой позиции мы смотрим, набор набор действий. На самом деле нужно усложнить, потому что действий может быть много. То есть у нас как действий может быть много, одновременно сделано, так и параметров на входе агента может быть много. То есть нужно описание входов-выходов, которые используются OpenAI Gym несколько усложнить. чтобы можно было комбинировать различные actions. Не придется ли делать среды тесты под конкретные парадигмы архитектуры? С моей точки зрения нет. То есть, если вот говорю, просто положить, что у среды есть возможность подать на вход агенту n параметров, А получить от агента M параметров, где каждый из M параметров имеет K различных возможных состояний, то вот абсолютно универсальная среда. Все, спасибо. 

S06 [00:36:19]  : Антон, спасибо. Мы с тобой еще на OpenTalks, вроде, да? я зацепился за этот пример. ты любишь этот самый, как называется, пинг-понг. и вот сейчас ты снова про него вспомнил. и, соответственно, у меня такой вопрос возник. вот ты говорил, если стандартный сеттинг подразумевает, что нам дается неограниченное количество ресурсов временного на обучение, соответственно, всякие сото-решения как-то справляются условно за 100 тысяч тайм-фреймов, хорошо обучаются эту игру, и ты говоришь, что если мы это количество как-то сократим, то таким образом мы где-то наступает этот порог, когда это уже превращается в EGI-тест из простого reinforcement learning. Как думаешь, если мы сократим этот порог со 100 тысяч, допустим, до 5000 таймфреймов, не превратится ли это в совершенно невозможную, нерешаемую задачу, с учетом того, что у нас такого агента нет таких прайеров на входе? 

S03 [00:37:27]  : Ну смотри, здесь как бы много. Во-первых, просто сокращение скорости обучения ничего не говорит, потому что мы можем здесь сделать систему, которая будет очень быстро обучаться в пинг-понг, но не сможет обучиться игре в шахматы. Поэтому все-таки скорость обучения – это всего-навсего один из параметров. Это во-первых. Во-вторых, у нас же мера айдиайности, с моей точки зрения, она же не абсолютная. Если никакой из агентов, существующих в мире или в сообществе, не способны обучиться за тысячу эпох, Ну, значит, надо брать и пытаться, а может быть, кто-то может за 10 тысяч эпох научиться. А если выяснилось, что там два агента обучаются за 10 тысяч эпох, только один за 9 тысяч, а другой за 5, ну, вот очевидно, значит, тот, который за 5 тысяч эпох обучается, тот круче. чем тот, который за девять тысяч эпох обучается. Вот. А если этот, который за пять тысяч эпох обучается, после того, как он за пять тысяч эпох обучился, он может там футбол научиться играть за одну тысячу эпох, а тот другой, который за девять тысяч эпох научился, ему опять по девять тысяч эпох потребуется для того, чтобы футбол научиться играть. Ну тогда вот понятно, кто победитель. 

S06 [00:38:51]  : как ты относишься к тому же джиму, только немножко с другого угла если на него смотреть. вот допустим слышал про агент 57 DeepMind, который выкатывал недавно. там фишка в том, что один агент на одной сети получается умеет играть, научается играть в 57 этапе игр лучше человека в каждой. но что если мы допустим возьмем и обучим его условно 10 играм. а одиннадцатую игру, скажем так, научись в нее играть не за сто тысяч итераций, а за тысячу всего. то есть ты же по идее понял основные принципы игры. ты понял, что есть площадка какая-то, на ней есть какие-то объекты, которые тебя угрожают и так далее. то есть будет ли вот такой подход как раз к критериям того, что агент действительно обучается. 

S03 [00:39:51]  : Мне кажется, это уже начинаются детали. Но вот смотри, есть люди-универсалы, которые могут и баню срубить, и на машине лихо водят, и могут шахматы сыграть, но нигде не достигают больших высот. А есть там гениальные математики, которые кашу себе не могут сварить. Носок не могут заштопать, но, вообще-то, там доказывают безумные какие-то теоремы. Можно ли сказать, кто из них более интеллектуален или нет? Наверное, тот, который может все, но плохо. Тогда, получается, он более general intelligent, чем гениальный математик. Но ведь это же условно. Мне кажется, тут уже начинаются детали. Здесь уже, получается, важен подход. А в рамках подхода уже можно брать и говорить, какое из наших трех измерений более важное. То есть, если нам более важна сложность задачи, то мы будем искать, и не так важно разнообразие этих задач, мы будем искать гениальных математиков. А если нам не важна сложность каждой отдельной задачи, но важно, чтобы задач будет много, Но тогда мы будем искать таких универсальных мастеров на все руки. 

S06 [00:41:07]  : Ну, вообще, я имел в виду вообще не то, чтобы померить два интеллекта, сравнить их уровнями, а вообще отделить некий брутфорс, который сейчас живет и царствует в решении Джип-задач от настоящего интеллекта. Ну, ладно. 

S03 [00:41:24]  : Дима, вот короткий ответ. Во-первых, скорость, а во-вторых, разнообразие. Ну а в-третьих, да, в-третьих, да, то, что ты говоришь на самом деле правильно, да, я с тобой согласен, но вот я, так сказать, пока не пред... да, значит, вот это ты говоришь правильно, но я пока вот не придумал, как это формализовать. Наверное, это тоже можно как-то формализовать. Это важное дополнение, да, согласен. 

S06 [00:41:50]  : Хорошо. Так, сейчас я... поскольку пропустил сейчас увидел что должен был после игре я вот юра извини тогда сейчас я скажу свою часть так для этого я расширю экран а то наверное ты должен разрешить мне да да так я уже должен так видно всем чего это что я показываю да я хочу рассказать про real это Robot Open-Ended Autonomous Learning Competition. Такая очень камерная вещь, я бы сказал, на которую я случайно практически наткнулся пару недель назад, когда начал думать про материал к этому семинару. руки дошли разобраться детально только вот сегодня, поэтому я буквально подготовил три слайдика. сейчас с Америком покажу, собственно, самую главную страницу этого соревнования. и ссылку потом выложу в чат общий. кому интересно, потом посмотрят. если что, это такая платформа aicrowd.com, на которой можно костить всякие челленджи. Типа такой кегл на минималках. Давайте более подробно расскажу, что это такое. Real – это соревнование виртуальных роботов по всем правилам. То есть организаторы предоставляют и виртуальную среду, и систему правил. Робот на входе, у него есть, как это называется, данные от датчиков своих сенсоров, вот этой руки, которую он оперировал, там семь суставов, и, соответственно, он видит, в каком положении находится внутренний сустав. И также видит камера сверху под каким-то углом, снимает текущее состояние дел. Вот у него, соответственно, стол, да, как платформа, на которой он чего-то делает. А как он может действовать? Он, соответственно, изменяет углы вот таких суставов, и рука таким образом совершает какие-то действия, в том числе суставы пальцев, захватного механизма. То есть, как видно на рисунке, он может захватывать предметы, отпускать их, может их сдвигать и так далее. В общем, полноценная такая рука. Такие тестовые задания. Стол, на котором лежит несколько предметов. Тестовое задание заключается в том, что показывают ему эталонную картинку, то есть как предметы должны быть в итоге расположены. И они отличаются по категориям сложности. Первая категория – это расположить предметы на плоскости, просто там на каком-то большом расстоянии, так, чтобы они в поле зрения не пересекались, эти предметы, именно на плоскости стола. Видите, там стол, он как бы на две части разделен, основная плоскость и полочка. Вторая сложность – это расположить как на плоскости стола, так и на полочке. Это считается типа 2,5D задание. и третья сложность это уже полноценно 3d это когда предметы могут стоять и на полочке и на столе и кроме того могут быть друг на дружке расположен кубик на нем там какой-нибудь цилиндр там и чтобы это все не падал Основное отличие от OpenAI GEM в том, что агенту не предоставляется никакого вознаграждения в процессе обучения. То есть это не reinforcement learning в полноценном смысле слова. Все архитектуры deep reinforcement здесь просто не работают. И почему это важно? Мне кажется, что принцип намного более релевантный для обучения именно AGI-агента. потому что, как вы знаете, если у инженера есть конкретная задача, он эту задачу знает, он будет применять все возможные юристики, хаки, чтобы решить именно эту задачу, а не сделать там какой-то более общий интеллект, к чему мы стремимся. В соревнованиях проходят два этапа. Первый скрытый этап – это там, где задание неизвестно. обучение ограничено временным ресурсом на 15 миллионов таймфреймов. То есть каждый таймфрейм – это одно элементарное движение, или когда предмет падает, или когда он какое-то простейшее движение делает рукой. Ну и следующий этап – открытый, когда задание уже известно, и там дается всего 10 тысяч таймфреймов. Предполагается, что за 10 тысяч таймфреймов, когда у тебя уже есть картинка идеального результата, ты обучиться никак уже... тебе не хватит такого таймфрейма, да, и вот здесь вот как раз срабатывает этот подпорок на обучение, про который мы говорили только что, подпорок на объем времени, который тебе дается, и без этого скрытого этапа ты как бы никак не можешь выполнить это задание. Как, собственно... ну да, во-первых, вопрос. Если так немножко задуматься, то если мы знаем задание, хотя бы в общих чертах, мы же знаем, что это будет какая-то картинка с каким-то расположением предметов, мы теоретически в ходе же можем задать внутреннюю функцию вознаграждения. вознаграждение за то, что рука возьмет предмет и с одного места переместит на другое. и поскольку это противоречит смыслу и духу всего соревнования, для этого в правилах там есть прямо раздел, называется spirit of the rules, в котором сказано, что нельзя делать никаких скоринговых функций. прямо так. то есть обычно знаете, да, что если какое-то соревнование объявляется, в принципе, вообще пофиг, как ты его делаешь. вот хоть что делай, да, внутри. здесь принципиальная отличие в том, что ты должен сделать это все по вот этому определенному правилу, да, то есть ты должен выложить, во-первых, код открытый, видимо, какие-то ревьюеры там сидят и проверяют, что ты не используешь никаких вот этих вот deep reinforcement learning штучек традиционных. И, соответственно, только если это все проходит ревью, тогда твое решение допускается. Мне кажется, это еще одна принципиальная причина. Как предлагается решать? Поскольку особо-то нет никаких архитектур таких вот для относительно нового этого направления, Вот четыре работы перечислены, в которых так или иначе затрагиваются вот эти вот, ну, во-первых, агент должен сам для себя ставить цели. Это вот в первой работе обсуждается. Потом вторая работа я вообще не смотрел. Это что-то для этих самых, для таких рук, видимо. И вот третья работа, самая интересная, она как раз про то, как нам эксплорацию двигать при отсутствии конкретной задачи. И здесь предполагается из названия, что любопытство — это self-supervised prediction. любопытство это способность предвидеть чего сейчас произойдет если я сделаю какое-то вот движение на то есть возьму я рукой подвину там влево допустим да там слева был кубик кубик сдвинется на и вот если я предвижу это вот как бы желание предсказать то изменение, которое произойдет, это и есть любопытство. спорная концепция, но почему бы и нет? и это соревнование было проведено уже в прошлом году. что получилось на выходе? вот видно, что результаты более чем скромные. из трех участников, которых было всего, подались два, прошли отбор. и результат у них тоже не очень впечатляющий. вот эти скоры, они, как бы, понятно, что ни о чем не говорят, но я посмотрел сложную формулу для расчета всего этого. там, если, допустим, три предмета нужно расположить, то максимальный скор за такое задание три. а вот, собственно, задание все они как раз о трех предметах. то есть можете представить, ну, прикинуть, что если наивысший скор это 0.2, сильно есть куда развиваться. Вот, собственно, такой краткий обзор. Вам всем надо подумать о том, что вот есть такое альтернативное направление. Я дальше хочу поразбираться в том, как конкретно ребята решали это дело. потому что сейчас они все свои ноутбуки зачистили, все свои коды, которые они были обязаны вкладывать, все убрали, никакие ссылки не работают. я, видимо, буду всем письма писать, покажу, что мне интересно. как будут катиться интересные вещи, я вам скажу. вот, это, собственно, все, что я хотел сказать. так, нажать на паузу. как выключается демонстрация? Так, Антон, давай. 

S03 [00:51:30]  : Да, Дим, значит, я хочу с одной стороны полностью поддержать. Более того, мы это обсуждали именно вот этот вот подход и с Олегом Серебренниковым несколько раз в частных разговорах и, по-моему, даже вот на одном из В неплановых семинарах с Николаем Воробчевским на воскреснике мы тоже обсуждали эту историю. Это проходило под соусом самоподкрепления. Что делать, как подкрепляться, если не дают подкрепления. И обсуждали различные способы самоподкрепления. И одно из самоподкреплений, как выяснилось, это как раз самопредсказуемость. Я действительно двигаю руку и должен сам себя подкреплять за то, что, двигая руку, я вижу двигающуюся руку, например. Это с одной стороны. С другой стороны, мне кажется, это движение в правильном направлении, но это конкретный тест на самоподкрепление. То есть, это тест не на AGI, а на способность навыка самоподкрепления для того, чтобы потом, с учетом навыков, полученных за счет самоподкрепления, решать задачи на подкрепление с прохождением конкретных тестов. И если я даже правильно понимаю, там подкреплений уже никакого нет, там просто нужно либо проходишь, либо не проходишь тест. Я так понял из твоего рассказа. 

S06 [00:53:00]  : Подкрепление там не дается никогда, даже на тестовой стадии. 

S03 [00:53:04]  : А, ну вот, то есть да. Да, а в реальности нет этого. Да, в реальной жизни это же не так. То есть, это получается, во-первых, очень узкая среда, во-вторых, очень узкий навык. То есть, это очень полезный, очень интересный тест на способности самоподкрепления исследовательских навыков, про которые недавно очередной раз Сергей Карелов сделал пост, я его везде репостил. Но к AGI это в целом отношение имеет очень частичное. 

S06 [00:53:34]  : да, согласен. это не столько про AGI, сколько про новую парадигму self supervised learning, которую я тоже люблю и считаю светом в конце тоннеля, я бы сказал. так, если больше к моему выступлению нет вопросов, то Юра, пожалуйста, 

S09 [00:53:58]  : Всем привет, спасибо, Дима. Как раз вопрос, который я несколько дней назад задавал в группе AGI Russia, что действительно ли вы хотите убивать вашу тварюшку каждый раз, когда она не проходит какую-то задачу и создавать новую, это как раз вопрос тоже про самоподкрепление, про любопытство на подумок. потому что у традиционного reinforcement learning с этим проблемы. и я тоже вас призываю всех над этим подумать, потому что мы же не убиваем человека каждый раз, когда он не решает задачу и не берем нового. иначе бы эти люди ничему не учились просто. ну ладно, это было на подумать. но еще тоже остальное все будет тоже скорее немножко наподумать. давайте я сейчас попробую прошарить экран и посмотрим получится. вот так. давайте поговорим все-таки про буквы AGI. про что мы вообще говорим. и оттуда как раз перейдем к тесту. Для начала давайте задумаемся, где здесь интеллект у нас? Являются ли задачи, которые муравей решают, интеллектуальными? Или мышь, или обезьяна, или человек? Есть соблазн все эти задачи назвать интеллектуальными. Соответственно, измерять качество на всех задачах интеллекта. но тогда вот давайте подумаем, чайник тоже какие-то задачи решает? чайник тоже что ли интеллект? а он именно решает задачу выключиться тогда, когда вода горячая. он эту задачу очень хорошо решает. неужели вы считаете его интеллектом? также и муравей какие-то задачи решает. он не решает все задачи, он решает какие-то конкретные задачи, их можно перечислить. в общем, в каком-то месте надо сделать здесь раздел и считать, что задачи уровнем ниже не являются интеллектуальными, а задачи выше являются интеллектуальными. я предлагаю все же считать интеллектуальными задачами задачи, которые решает человек и только человек. но не решают существа менее разумными. А все, что ниже, называть разумным поведением. В английском, как вы знаете, есть два разных слова – smart и intelligent. Intelligent как раз применяется именно для чего-то разумного, а smart – это просто умный, что-то сообразительное. Даже не умный, да. другое слово. соответственно, думать все-таки про протестирование интеллекта в интеллекте искусственном, а не протестирование всех свойств. ну и, конечно, в случае сверхинтеллекта у нас еще будут задачи для тестирования, но мы пока даже не знаем, какие. хорошо, пойдем дальше. про другую букву. поговорим теперь про букву G. Она говорит про то, что искусственный интеллект должен быть универсальным или общим, или должен генерализоваться. Что это значит? Представим разные задачи, как вектора в пространстве. они в разном направлении, разные задачи направлены. похожие задачи как-то чуть ближе друг другу, непохожие как-то чуть дальше. значит, по сути, если мы хотим протестировать какой-то интеллект, понять его уровень, нам надо все эти задачи у него спросить, потом посчитать какое-то среднее. про метрики у этих задач мы чуть ниже поговорим. каким-то образом это все дело измерить. проблема в том, что задач очень много. не теряя общности, мы можем эти задачи рассматривать, что они на круге. задач все равно очень много, даже на круге. и очень долго и сложно составлять тесты. люди мучаются, составляют окружение разное, кой-как 60 разных игр. разных по типу на атаре взяли или там составляют окружение, которое по сути одна большая задача. вопрос в том, можем ли мы тестировать на одной задаче или нам нужно 10 задач или 100 или 1000 брать. и вот смотрите, ведем понятие proxy задач. proxy task. Если задача близка для другой задачи, то мы можем оценить качество работы на одной задаче через качество на второй задаче. И выясняется, что качество решения задач коррелирует. Мы знаем группы коррелирующих задач друг к другу, а если не знаем, то можем их померить. И они примерно для разных интеллектов. ну похоже как. таким образом мы можем все свести к проверке этих только proxy задач, как-то сгруппировав их по хвостерам. при этом, конечно же, 10 или 100 или 1000 задач нам придется проверить, и каждую задачу придется несколько раз протестировать, чтобы точнее была оценка по метрике, но все равно это не тестирование миллиона и миллиарда разных задач. Более того, есть гипотеза, и она, в общем-то, подтверждается пока что на практике текущими узкими интеллектами и текущим прогрессом в области широкого искусственного интеллекта, что чем интеллектуальнее система, тем больше корреляции между задачами, которые немножко дальше друг от друга стоят, чем совсем рядом. То есть получается, что эти квестера получают со временем все больше. И по тестированию качества на мы даже понимаем на соседнем кластере, как оно примерно будет себя вести. таким образом, получается, чем умнее интеллект, тем меньше разных типов задач ему нужно давать, чем оценить уровень интеллекта. примерно это подтверждается и на человеке, но теперь попробуем про букву а в hai поговорить. давайте я вам зачитаю текст, а вы попробуйте понять, про какой тип систем я говорю. Системы в разговоре проявляют раздражительность, а у них отсутствует интерес к окружающим. Они не умеют общаться с другими. Скорость усвоения знаний таких систем резко снижена. Они не умеют правильно действовать ни по словесной инструкции, ни даже по подражанию и образцу. Демонстрируют лишь ситуативное понимание речи. Для усвоения способов ориентировки в окружающем мире, для наделения и фиксирования ярко обозначенных свойств простейших отношений между предметами, для понимания важности того или иного действия, ему требуется гораздо больше вариативных повторений, чем для других интеллектов. Без специального обучения отмечают существенное недоразвитие специфических видов деятельности, характерных для других систем. Понятно, про кого я говорю. Это описание умственной отставки детей. То есть ровно те свойства, которые демонстрирует сейчас система искусственного интеллекта, включая раздражительность и то, что они очень резко начинают внезапно материться в ответ на обычный вопрос просто так, потому что запомнили неправильно какую-то реплику, как демонстрировали нам чат-боты от Майкрософта и другой еще компании. Как медленная скорость обучения, то есть все тесты, которые характерны для человека, они опять же неплохо измеряют свойства самого интеллекта в целом, что искусственного, что естественного. и теперь немножко подробнее поговорим еще про тесты. получается, что не нужно никаких специальных тестов и мы можем использовать обычные тесты, которые мы можем предложить человеку. например, человеку, который устраивается к нам на работу. или мы, если устраиваемся на работу. наливать кофе гостям, водить машину, играть в шахматы, пеленать ребенка, отвечать на вопросы клиентов по определенной теме. вы можете придумать, как бы вы тестировали такого человека. мы бы измеряли качество выполнения задачи, решил, не решил, дали налить кофе трем гостям, одному налил, еще одному не налил, чашка была нестандартной формы, третьему не налил, кончился, потому что кофе новый он заваривать не умеет, не разобрался с кофемашиной. вот вам тест для искусственного интеллекта в чистом виде. также вы можете учитывать время выполнения задач. можете учитывать, что если задача требует обучения, то вначале производится обучение, значит обучаем в работе с кофемашиной, даем обучающий материал и инструкцию кофемашину. вот все, давай через час наливаешь кофе гостям. все, это тесты для искусственного интеллекта. да, они действительно хорошо работают. не нужно изобретать что-то другое новое, и эти тесты прекрасно применяются уже. и в некоторых областях уже роботы уже заменяют человека. в других областях не так хорошо, но вот это и есть движение к общему искусственному интеллекту, ничего тут придумать больше не надо. согласны со мной или нет? 

S03 [01:04:27]  : уже нужно реагировать. 

S06 [01:04:32]  : ты, Антон, прошел тест интеллект, потому что понял, что нужно реагировать. слушай, Юр, у меня двоякое впечатление. вроде бы правильные вещи, но хочется немножко приземлить. ты говоришь про разлитие кофе по чашкам. как, собственно, нам бы виртуальную среду делать с кофемашиной, с чашками, со столом? 

S09 [01:05:00]  : это не так сложно сделать. более того, компании это уже делают. недавно nvidia на презентации, сколько месяц назад, в конце апреля, говорила, что они полностью смоделировали какой-то там завод компании, где там машины какие-то что ли производят, ну в смысле автомобили, полностью там со всем освещением, там со всем прочим, чтобы учить роботов на нем собирать эти машины, наверное. 

S06 [01:05:34]  : ну подожди, но все-таки ты говоришь... пожалуйста, виртуальное окружение. самоторные навыки, о том, чтобы кофе не разлить, или о том, что, допустим, ты разливаешь кофе всем, кто сидит, а один из них показывает знаком, что ему кофе не нужно, словно чашку переворачивает, а тот ему тоже наливает. он должен реагировать на какие-то более сложные знаки. 

S09 [01:05:58]  : как раз это я и объяснял по середке, что чем умнее интеллект, тем больше он захватывает для своих навыков, для своей задач, навыков из другой сферы. да, действительно, умный человек обратит внимание на то, что чашка перевернута и кофе туда наливать не надо. а глупый будет материться о том, что ему не дают выполнять свою работу по наливанию кофе. 

S06 [01:06:24]  : а тесты nvidia включают такие высокоуровневые проверки, о которых ты сейчас говоришь? 

S09 [01:06:30]  : если мы говорим про окружение, это одно. окружение может быть каким угодно. если мы говорим про конкретные проверки, это другое. проверки тоже могут быть какими угодно. главное, чтобы были какие-то кластера задач. и вот эти кластера задач отражают способности искусственного интеллекта. Да, мы можем тестировать на каждую мелочь, но интеллектуальное поведение складывается со временем из того, что в каждую задачу начинает включаться каждая другая задача, по сути. и более сложные тесты на одну задачу, они требуют... хорошо представим, что требуется решить квадратное уравнение для того, чтобы налить в правильную кружку. потому что перед кружкой написано задание налить только в кружку, где правильный ответ... какую-нибудь математическую задачу решить надо. и после этого определить, нужно наливать в кружку чай или нет. То же самое происходит с текстовыми навыками. То же самое демонстрирует OpenAI с текстовыми навыками. Да, у них iPod объединился с яблоком. Яблоко с этикеткой iPod стало сравнимо с iPod. Это как раз обобщение, которое нужно для того, чтобы решать сложные задачи. У них объединились вместе текстовое представление понятия и графическое представление. И получается, что мы можем одновременно системе давать и текстовые задачи, и графические задачи. И система одновременно учится и тому, и другому, и сможет графически решить текстовую задачу и наоборот. то есть все идет к тому, что по мере увеличения интеллекта она начинает захватывать все эти навыки. это естественный процесс, тут ничего не надо для этого особо делать. 

S06 [01:08:45]  : ты, видимо, про клипов сейчас говоришь, которые учат совместные представления. но тут вопрос в том, как ему задачи подавать. потому что если ты ему просто скажешь сделай выводы о том, нужно наливать кофе в чашку или нет, он, конечно, тебя не поймет. а если ты ему будешь в явном виде запрограммируешь условия этой задачи, то это уже будет не интеллект, а решалка. 

S09 [01:09:10]  : да, тут много еще вопросов, конечно, но во всяком случае с тестами, я думаю, более-менее определенность есть. какие тесты нужны и сколько их нужно. И какие тесты, как они позволят отличить. 

S06 [01:09:24]  : Антон что-то хотел сказать. Юрий. 

S03 [01:09:30]  : Да, я хотел сказать, что, во-первых, респект за подачу. Игорь Пиваров тоже уже высказал, что прекрасное решение подачи материала, во-первых. Но проблема в двух вещах. Во-первых, в первую очередь обосновывается необходимость тестирования Human Level Intelligence, а не General Intelligence. То есть, рассуждение о том, что такое буква I к General Intelligence никакого отношения не имеет. Речь идет исключительно о том, что называется HLAI. Human Level Artificial Intelligence. Соответственно, дальше из этой посылки делается переход к третьей части, где говорится, что нам нужно всего-навсего создавать привычные для человека среды и давать возможность обучению и решению задач в этих средах, верифицировать возможность решения задач в этих средах. Но это мимо, потому что сама установка была не на AGI, а на HLAI. Это с одной стороны. Сейчас я закончу. Это с одной стороны. С другой стороны, про то, что было в середине с векторами. Я полностью согласен. Кстати, это отсылка к тому, что мы с Димой говорили. Если агент научился решать какую-то другую задачу, то то, что он потом быстро научится решать другую задачу, что это является указанием на его интеллект, Это не обязательно так, потому что это будет зависеть от того, насколько эти задачи далеко находятся друг от друга в том векторном пространстве, которое Юрий показывает. Поэтому степень генеральности этого AGI будет определяться тем, насколько широко, а не насколько плотно покрыто все это векторное пространство. Ну вот, собственно, вот мои комментарии. 

S09 [01:11:40]  : То есть вы не считаете, что по мере увеличения уровня искусственного интеллекта human level GI и AGI сравнивают друг с другом, опять же, по той же самой причине, которую я обозначил. 

S03 [01:11:59]  : Все зависит от определения. По тому определению, которое я использую, human level AI где-то находится на середине. Начиная от муравья, то есть на самом деле, с точки зрения GI, эта лестница посередине не оканчивается, то есть она идет дальше вправо. То есть, GI должен иметь возможность научаться… Да, совершенно верно. И, так сказать, дальше и пошли дальше. То есть, мы должны создать среду, где можно постепенно усложнять среды, в том числе, которая… Конкретную назову цифру. Вот известно, что человек может оперировать с задачами, которые требуют эффективно работать с задачами, где в фокусе внимания находится не больше семи объектов. То есть, если мы начнем создавать среды для успешного решения задач, в которых потребуется иметь в фокусе внимания одновременно 8, 9, 20, 45 объектов, то человек ни одного из этих тестов не пройдет. А фреймворк, если будет создавать, генерировать такие среды, он в состоянии будет верифицировать прохождение этого теста системами, которые в состоянии будут оперировать в таких условиях и превышать уровень интеллекта человека. значит это вот как бы критическая часть а практическая часть на самом деле вот то что я в своем проекте делаю оно на самом деле близко вот потому что сказать я как бы вот у меня проект все-таки такой не мать и не то чтобы сразу и джей сделать а сделать что-то полезное для людей и поэтому тех агентов которых я делаю они предназначены для общения в тех антологиях для работы в тех антологиях в которых человек работает и поэтому да и поэтому вот общение с ними на естественном языке в привычных человеку антологиях поэтому как бы с точки зрения вот неру и джай да то есть если мы ставим задачу на неру и джай и делаем нерру AGI как human level нерру AGI, то тогда вот это то, чем занимаюсь я и тем, что, мне кажется, предлагает Юрий. 

S06 [01:14:14]  : Спасибо, Игорь, хотел спросить. 

S05 [01:14:21]  : Да, ну спросить и рассказать. Антон почти правильно сформулировал мои соображения, но я как бы чуть просто еще их ужесточу. С одной стороны, я тоже плюс один к подаче материала. Она прекрасно совершенно про эти буквы. Но мне кажется, Юрий, вы сами себе противоречите. В первой части вы там. Неважно, согласен я с этим определением интеллекта, а то, что ниже разумное поведение, это сейчас не сильно важно, но если согласиться с этим, что интеллект лишь здесь, в поведении человека. в последней части где вы говорили про тесты но как бы там нет интеллекта условно дать кофе там трем людям извините я обезьяна может и там там ну то есть какие-то простые тесты здесь вполне может сделать не обязательно человек Я как раз не увидел в вашем последней части протесты чего-то на тестирование именно интеллекта. А то, что вы говорите, когда мы принимаем человека на работу, я когда принимаю человека на работу, я с ним разговариваю. интеллект я обычно там чувствую вот в разговоре но но это не связано с какими-то тесты для другого скорее для того понять он может выполнять эту работу или нет грубо говоря там Кофе разносить действительно по времени, наверное, можно, прочее. Но если бы у меня была возможность обезьяну нанять за там смешные деньги кофе разносить, ну, может, я бы нанял обезьяну без интеллекта, но она бы прекрасно кофе разносила. Я не исключаю, что она будет лучше. Вот, собственно, вопрос в этом. Не считаете ли вы, что это противоречие в этих тестах ваших с интеллектом? 

S09 [01:16:25]  : да, это правильный, конечно, правильный вопрос, но вот вопрос, что где-то провести вот эту грань все же надо, то есть может действительно, может ее провести на уровне обезьяны, или даже частично на уровне мыши, но не на уровне муравья, но ее провести надо, иначе мы не сможем отличить узкий интеллект от общего интеллекта малой мощности, скажем так. например мы не сможем не сможем тамагочи муравья отличить от обычного муравья. ok, с этим согласен. Поэтому давайте все же… то есть я бы в группе тоже какую-то границу все же провел, предложил бы провести. Ну, не важно, мне не так важно, что это будет. Да, будем ли мы говорить про мышление текстовый интеллект, продвинутый социальный интеллект или там… Вот здесь простой социальный интеллект, простые навыки, работы с манипуляторами. Или мы будем говорить здесь про решение простых логических задач в графической форме. с которыми мыши справляются. будем говорить про муравья, которые умеют считать. если ему повернуть надо в одну сторону, выяснили, что он до 12 поворотов может запомнить. получается, он считает до 12. если повороты в разные стороны, то все же меньше. 3-4 поворота может запомнить. в одну сторону может запомнить, что ему надо 8 раз повернуть. тоже какой-то интеллект. но вот где-то ограничиться здесь надо все же, чтобы не рассматривать уже, не говорить, что вот мы сделали искусственным муравьям и сделали общий искусственный интеллект. вот в чем состоит проблема. и вот где-то эта граница, вот она проходит. с какого-то уровня мы уже искусственный интеллект называем общим, потому что задач становится много. 

S05 [01:18:28]  : Все-таки, наверное, с уровня человека и дальше, потому что все-таки мы же говорим про широкий круг интеллектуальных задач. В этом плане Александр Балдачев, он много раз про это говорил в чате и писал про то, что он определяет интеллект как способность оперировать некоторыми абстрактными понятиями. И в этом плане действительно делают обезьяны или муравей. 

S09 [01:18:50]  : Собаки, обезьяны умеют это делать. Собака, которую научили печатать на клавиатуре, смогла высказать конструкцию про то, что у нее межлап застряло занозы словами, что чужой больно лапа. тоже манипулирование абстрактными понятиями, извините меня. да, логично. то есть какой-то уровень, наверное, млекопитающих все же это будет. но какой-то уровень все же должен быть, чтобы муравья сюда, наверное, все же не причислять. хотя он и считать немножко умеет. но и компьютер у нас считать умеет. компьютер и искусственный интеллект теперь уже сам по себе. 

S06 [01:19:43]  : Хорошо. Пока больше вроде бы такая параллельная дискуссия идет. Александр Булгачев, давайте. 

S04 [01:19:55]  : Добрый день, господа. Большое спасибо всем, кто выстался, особенно Юрию, поскольку он ближе всего выстался к моим каким-то ощущениям. И не было произнесено ключевое слово, слово мышления. Да, действительно, есть такое понятие, как мышление, и оно не только у млекопитающих свойственно мышления, а даже птицам вороновые. То есть, когда ворона берет щепочку и достает из бутылки червя, Это мышление. Она начинает действие, когда еще нет его результата. Они не реагируют на какое-то активное изменение среды, а продумывают этот шаг в себе, в голове. У нее есть понятие «червяк», есть понятие «бутылка», есть понятие «щепочка». Она ищет эту «щепочку» нужной длины. Понятия длины есть, соединяет их вместе и совершает действия. Это элементарное мышление. Здесь даже не нужно говорить о каких-то абстрактных понятиях, просто понятия. Есть просто понятие «бутылка, щепочка, червяк». И когда обезьяну обучают языку жестов, она тоже проявляет некое мышление. Она сначала строит цепочку понятий, называя, не называя их какими-то словами, и выражает некое конечное понятие каким-то жестом, которое однозначно не вытекает из предыдущих данных вещей, которые она наблюдала. И поэтому вот эту желтенькую полосочку, скорее всего, нужно назвать мышлением. И тесты на мышление, они действительно тесты на мышление. И тут можно сильно очень помочь Юрию Варгументов вспомнить слепо-глухонемых, с которыми Лельенков проводил эксперименты. То есть, когда человек, он не умеет ни кофе разливать, ни сам себя обслуживать, ничего не умеет. Он слепо-глухонемой, но они заканчивали институты. слепоглухо-немые. То есть они выдержали бы тесты на решение математических задач. И для того, чтобы выявить интеллект, нет необходимости вообще никаких операций со средой. Вообще никаких операций со средой. Давайте так, чтобы не спорить с терминологией, чтобы выявить мышление, для того, чтобы выявить наличие мышления, не нужно никаких операций со средой. Вообще не нужна никакая среда. Нужен текст, И обработка этого текста. Нужна речь, текст в виде письменного, текст в виде устного и ответы на вопросы. Здесь, конечно, куча вопросов, потому что мы даже у своего соседа не можем выявить признаки мышления, можем отказать в этом. Поэтому тоже неоднозначно. У человека неоднозначно выявить уровень мышления. Но в принципе, есть ли мышление или нет, довольно просто отличить. Кстати, здесь нужно различать мышление предметное и мышление беспредметное. То есть вот ворона осуществляет предметное мышление, а эти предметы есть перед ней, и она, не совершая операции с ними, совершает у себя внутри операции с понятиями, под которые подпадают эти предметы. Но если математик сидит у себя в кабинете или физик-теоретик сидит у себя в кабинете, он оперирует понятиями беспредметными, без предметов. И это есть основной критерий мышления, то есть умение оперировать понятиями, строить цепочки понятий. Здесь не обязательно речь о логике. Это не логика. Это может быть совершенно некий ассоциативный. Но в любом случае человеку сообщается некий пул понятий исходно, и он выдает совершенно отличный, не следующий однозначный из этого пула другие понятия. Пишет какой-то другой текст, отвечает на какие-то вопросы. И это можно вполне тестировать, и здесь нет никаких особых проблем, как правильно говорил Юрий, что это обычные проблемы на тестировании человеческого мышления. Но здесь опять стоит вопрос с терминологией. Скажет Антон, я придерживаюсь понятия интеллекта вот так вот шире. Ну да, пускай. Это неважно. Просто нужно различать тесты на что? Тесты на адаптивность. Да, можно тест на адаптивность. Тест на обучаемость? Да, можно тест на обучаемость. Можно тест на мышление? Да, можно тест на мышление. Тест на предметное мышление, когда перед тобой эти предметы имеются, и ты должен как-то, умея их сначала оценить, а потом совершить действие с этими предметами. Или на тест на непредметное мышление. И, кстати, вот если мы говорим о нашем языке человеческом, то человек, который способен совершать деятельность без предметного мышления, не обращаясь к предметам, мы и называем интеллектуалами. Интеллектуальная профессия – это человек, который сидит за столом, кусает карандаш и решает проблемы без обращения к предметам. Дворник – не интеллектуальная профессия. Водитель – не интеллектуальная профессия. Интеллектуальными профессиями в языке и в русском, и в английском мы считаем именно тех людей, которые совершают беспредметное мышление, можно сказать, теоретическое мышление, предметное мышление и теоретическое мышление. 

S06 [01:25:15]  : Александр, спасибо. Я вам возражу, но вы, пожалуйста, не отвечайте, потому что иначе у нас дождались уже докладчики. Вот вы говорили про текст и текст только на подход. Но смотрите, вот у нас очень много бенчмарк. Бенчмарк типа superglue, где используются очень изощренные такие текстовые задания, с которыми справится только, не знаю, человек. начиная со старших классов, может быть, даже в институте. И тем не менее, они совершенно никак не относятся к тестам общего интеллекта, поскольку обычные deep learning модели, в принципе, с какой-то успешностью справляются. Подумайте пока все остальные. 

S04 [01:25:58]  : Только два слова я отвечу. Достаточно только текста. Достаточно текста. Но может быть и не текст. То есть то, что показывают глухослепонемые, показывают, что достаточно текста для выявления мышления. Но не обязательно текст. Можно и другие. 

S06 [01:26:17]  : Я к тому, что, в принципе, текстовые задания-то можно сделать как критерии общего. А вот вопрос в том, какие дополнительные формы. То есть, мне кажется, что просто от каких-то стандартных вопросов-ответов тут явно будет нововазовка. Какая-то более хитрая система изощрённая должна быть. Это вот как бы вам надо подумать. Так, всё, давайте переключаемся на следующего спикера. Это у нас будет Николай Робчевский, пожалуйста. 

S02 [01:26:45]  : Да. Ну, прежде чем вернуться к собственной теме, сегодняшнего собрания, я немножко скажу по поводу того, что Юрий Бабуров говорил. Дело в том, что при том, что наличие градации – это правильный подход, практическая проблема заключается в том, что часто пытаются реализовать Вот самый верхний четвертый квадратик, не реализовав три нижних, заменяя их какими-то костылями или хардкод заглушками. И при этом становится непонятно, что именно тестируется. Все вместе или только вот верхний кусочек? Ну, а по поводу сегодняшней темы я не буду повторять то, что я уже писал там по поводу ответов на вопросы, а скажу, так сказать, то, о чем как-то особо никто не говорил, как мне кажется. Ну, во-первых, Тесты и соревнования – это всё-таки несколько разные вещи. Вот если вернуться к давно известным сферам, где всё устоялось и выработались некие подходы, скажем, тестирование самолётов или тестирование автомобилей, Там были, наверное, проще, поскольку, в общем, большинству известны. Есть конкурсы, в котором, ну, то есть гонки разного рода. Гонки на автомобильной дорожке, на стадионной дорожке, гонки по Формуле-1, гонки по Сахаре. А есть тесты, которые проводят, когда появляется какая-то новая машина, и её хотят сопоставить с другими. И это совершенно разные вещи. То есть, когда происходит тест, тестирование машины, то это означает, что один или несколько человек берут эту машину и пытаются делать с ней разные вещи для того чтобы выяснить пределы ее возможностей на скоростной трассе выяснить максимально возможную скорость на территории там на полигоне с со сложной местностью выяснить, что она может преодолевать, какие камни, какую глубину грязи, какой глубины брод и так далее. А в городе определить, насколько она экономична в режиме, когда нужно непрерывно останавливаться и разгоняться. И в этом смысле Тестирование вот того, что претендует на роль AGI, как мне кажется, если это реальное тестирование, оно должно быть по виду похоже на тестирование машин, а не на конкурс на то, куда первый приедет или, так сказать, еще какие-то, может быть, много факторное, но тем не менее соревнование, потому что именно определение того, какие предельные возможности имеет система, оно играет крутивую роль. Ну, скажем, мы прекрасно понимаем, что человек, скажем, может научиться плавать, ездить на велосипеде, Потом поехать на пару лет в Антарктиду на станцию, где нет ни велосипеда, ни бассейна для плавания. А повернувшись назад, без всякого обучения, совершенно спокойно, так сказать, вернет себе возможность ездить и плавать. То есть, никакое последующее обучение, в общем-то, не убивает полученных раньше знаний. Это один из примеров того, что нужно ловить для того, чтобы отличить реальный AGI от пускай сложного, но тем не менее адаптивного уровня интеллекта. То есть по адаптивным я в данном случае имею в виду, что есть некое фиксированное количество параметров, и обучение или тренировка сводится к тому, что каким-то способом находятся значения этих параметров, которые позволяют решать некую задачу хорошо. Потом появляется другая задача или изменяется ситуация, и становится ясно, что параметр нужно изменить, и тем самым убить возможность решать ту задачу, которую решали раньше. Это, так сказать, адаптивный уровень. А реальный интеллект – это как бы вот следующая ступенька, и есть возможность найти различия, если а – отказаться от конкурса в пользу реального тестирования, дать возможность тому, кто тестирует, менять условия. Если это пинг-понг, поменять размер поля, вместо одного противника поставить два. Если это другие вещи, мышка в лабиринте, искать сыр. Каждый раз в новую задачу ставить новый лабиринт, а потом вместо лабиринта поставить пустое место, в котором есть некие препятствия. Формально это тоже лабиринт, но другого типа, и посмотреть, как она будет справляться с этой задачей. То есть дать возможность вот… Игорь Пивоваров говорил о том, что хакеры в тех случаях, когда есть задача, как раз конкурсного типа, ищут возможность обойти сложности, найти способ легкого решения, так сказать, вот этой четко поставленной единственной задачи. А тестирование, правильная, которая позволит определить, есть ли AJ или нет. Это обратная ситуация, когда мы хакеру даем возможность менять условия задачи с тем, чтобы найти вот те пределы, которые и определяют, собственно, уровень интеллекта этой системы. Ну и, пожалуй, у меня всё. Тут много полезного уже было высказано раньше. 

S06 [01:34:53]  : Спасибо. Я бы только всё-таки... Соревнования, ВИЭС, отдельное тестирование. Вот в Abstractive Reasoning Challenge он в такую категорию относится. Там тоже, по сути, вроде бы тестирование, потому что были задачи на... абстрактное мышление, и мы тестировали эту способность. И был тот критерий, про который говорили, что там хакер в виде подбрасывания совершенно неожиданных задач, собственно, выявлял эту способность, но при этом при всем это было соревнование, поскольку там можно было... количество набрать разное количество баллов и сравниться между собой вот это это куда относится ваше понимание николай микрофон микрофон микрофон 

S02 [01:36:01]  : В смысле соревнований тут ситуация ещё такая. Они всегда носят более или менее субъективный характер. В каком плане? Разные задачи имеют некий достаточно произвольно назначенный вес. Поэтому в том, что очки считаются, но считать их можно по-разному, результаты, соответственно, тоже могут быть очень разные. Особенно если возникает ситуация такая, когда есть две системы, одна из которых одну задачу может решить, но не может вторую, а другая система, наоборот, решает вторую, а не первую. кто из них будет победителем определяется ровно тем, так сказать, коэффициентами между двумя этими задачами. То есть соревнования не всегда информативны в этом плане. То есть я не говорю, что они не имеют никакого смысла. Безусловно, они имеют смысл. Но вот тестирование, так сказать, по своей полноте и смыслу, оно полезно именно вот в таком варианте, как я описал. При этом ведь, когда систему разрабатывает кто-то, он для себя тесты обязательно делает, потому что иначе как он убедится о том, что получается. Так вот, Давайте свою систему вместе со своими тестами, которые могут демонстрировать ее способности, хакерам, которые могут менять условия и выяснять, что она может, а чего не может. Если выяснится, что она может хорошо, значит вы победили. 

S06 [01:37:58]  : Согласен. 

S02 [01:38:02]  : Ещё один момент, который я упустил и хотел сказать. Это всё-таки близость задач к той сфере, в которой мы будем использовать это. То есть, если мы хотим сделать систему, которая, скажем, применима в сельском хозяйстве, а пытаемся тестировать её на играх в «Атаре». В общем, это вряд ли… С одной стороны, имеет смысл, а с другой стороны, вряд ли оно убедит потенциальных пользователей и инвесторов в том, что, в общем, всё хорошо и можно приступать к работе. У меня всё. 

S06 [01:38:50]  : Хорошо. Юра, давай один вопрос. 

S09 [01:38:53]  : Да, Виколок, вопрос к вам. А если система умеет адаптироваться к разным полям в пинг-понге, хорошо, но кроме пинг-понга ничего не умеет делать, это AGI? Потому что другая эта плоскость или нет? 

S02 [01:39:08]  : Нет, конечно. То есть, всё-таки, опять-таки, пинг-понг, смотря какой пинг-понг. Вот есть пинг-понг дискретный, а есть пинг-понг, то ли в Японии, то ли в Корее. В Корее, наверное, сделали пинг-понг реальный. То есть и робот с телекамерами, играет в пинг-понг на реальном бою. Вот если сделать систему, которая будет и в «Атаре» более или менее хорошо играть, и в такой ситуации, то я буду склонен считать, что, в общем, какой-то, может быть, не очень сильный, но, тем не менее, Эйджай имеет место. 

S09 [01:40:03]  : Может проще напрямую измерить его способности для других задач AGI, вместо того, чтобы просто назвать, потому что на основе его адаптируемости в рамках одной задачи, называть его AGI. 

S02 [01:40:19]  : Ну, адаптируемость нужно на чем-то показывать. 

S09 [01:40:25]  : Но вот я и предлагаю кластера задач. То есть, конечно же, это не значит, что задача будет одна в каждой области. Конечно, если это текстовая задача, то это не будет там задача всегда одна и та же, правильно? Какие-то условия модифицируются. Также и задача на действие, тоже какие-то условия модифицируются. 

S02 [01:40:44]  : Но хватит ли одной задачи? Да, но сама возможность... адаптироваться к разным задачам еще не гарантирует признание в качестве AGI, как мне кажется. То есть сами эти задачи должны быть, во-первых, достаточно сложными, а во-вторых, Она должна демонстрировать возможность адаптироваться к одной задаче, не теряя способности делать другие. Если адаптация к одной задаче убивает способность решать другую задачу, то это, безусловно, не AGI. 

S06 [01:41:33]  : Хорошо, я думаю, что... мы все-таки все время немножко скатывается можно максим максим смотрите давайте давайте все-таки не смотрите по определенному какому-то там это вопросы более я понимаю я хочу все-таки чтобы это уже когда после алекса гура вы спросите отдельно хорошо начнем просто выбиваемся из следования спикер а сейчас максим вам собственно вот слово то есть как бы расскажите вашу. 

S08 [01:42:12]  : Мне не удалось сейчас, как бы я на планшете подключился, вывести на экран, то есть я писал вопросы, ответы на вопросы, в общем готов их прокомментировать, но если только без экрана, то есть у меня в принципе они есть. То есть 

S06 [01:42:36]  : я попробую их на фейсбуке открыть и расширить. 

S08 [01:42:42]  : я могу прокомментировать, может даже начать с Николы, потому что как раз в принципе у меня противоречий с ним нет принципиальных. я так ему в принципе и написал. может быть сначала его вопрос. то есть он прокомментирует и 

S06 [01:43:04]  : давайте я сейчас расшарю. вы говорите, что давайте сделаем диалог. у нас все-таки формат такой, что вы просто рассказываете, потом вопросы, а потом уже в конце всего диалог. вот сейчас я вам прям открою ваш пост. это оно ведь? Максим? да-да-да. 20 минут. ну, крутите тут его, наверное, поможете? давайте, куда? 

S08 [01:43:37]  : ну, пока не надо, с самого начала, в принципе. 

S06 [01:43:41]  : вот с самого начала. 

S08 [01:43:43]  : нет, это вот до начала. ну, можно ли надежно выявить, что перед нами AGI? то есть, мое мнение, я написал да. я так понимаю, здесь комментарий не требовалось. почему не? то есть, они дальше будут. каковы критерии надежного теста. в принципе имеет смысл все это читать? 

S06 [01:44:08]  : смотрите, Максим, предполагается, что это все мы уже прочитали и знаем. если хотите что-то добавить, это какие-то дополнительные мысли, которые поясняют. например, вы говорите да, а можно тоже, в принципе, сказать, что почему. Многие не согласны. 

S08 [01:44:30]  : Давайте тогда по очереди. Каковы критерии? Указание топологического места для рассматривания среды. У меня принципиально здесь ниже, в общем, написано, что я среду, которую в вопросах рассматривается, детализировал, то есть рассматривается программная среда, рассматривается агентная среда. Этого недостаточно, потому что так же это сейчас звучало у всех контекстом выступающих, что они называли это либо реальной средой, вот Микола в том числе называл реальной или там какая-то естественная среда или еще как-то по-другому. Я не понимаю, честно говоря, почему люди системно отделяют, не хотят понимать, что это одна и та же среда, что программная среда, что среда из теории систем, то есть среда, в которой работает это приложение, этот агент. Это одна среда. Это надо рассматривать как одну среду. Если мы хотим что-то тестировать, как какой-то фреймворк тестировать, ну понятно протестировали фреймворк. Если мы хотим тестировать агента, которого применяют люди, надо тестировать всю систему, всю среду. Среда, в которой люди, среда, в которой агент. Это все среда одна. То есть понятно, что это разная среда в деталях. Еще раз повторюсь, первая это среда агентная, вторая среда это, я назвал это здесь у себя в описании, среда истории систем. То есть агент свое поведение, его поведение зависит от той среды, в которой он находится. То есть я здесь ничего не сочиняю, в принципе можно это как бы просто в википедии прочитать определения, то есть я слышал, как идет постоянный диалог о каких-то определениях, или в терминах, мне совсем не хотелось в эту область заходить. Речь о том, что среды две, которые условно объединены в одну. И вот если рассматривать тестирование узкого, или узкого TMI, то да, понятно, это тестирование в какой-то программной среде. Если рассматривать какой-то HDI-вдохновленный, HDI-ориентированный какой-то продукт, идею, то тогда нам необходимо видеть пользователей, нам видеть туда, куда повешен этот на какую прикладную область, что это используется, это тоже среда. ну давайте назовем это область, я не знаю, или как угодно, регион. от перестановки слов суть не изменится. это та же самая среда, в которой оперирует этот программный агент. это принципиально. не знаю, смог ли я объяснить. Критерии надежного теста. Указание топологического места для рассматриваемой среды теста на топологической карте сред. Проще говоря, первый критерий – это представление топологической карты сред. Здесь уже у меня вложено, что топологическая карта содержит все среды, и программные, и назовем их TS из теории системы среды. Второй пункт. представление принципа управления процессом перемещения на топологической карте сред. да, это два сложных таких... по-хорошему этот вопрос можно было, может быть, в самом конце на него отвечать. то есть здесь речь идет о принципе управления, то есть перемещение по средам. оно происходит по какому принципу? то есть что перемещает агента, что перемещает я не знаю, оператора, что перемещает. Есть какое-то управление, то есть чем-то руководствуется то, что перемещается из одной среды в другую, из программной в теорию системы, из одной программы в другую программу. По какому принципу, почему он будет перемещаться? Вот этот пункт написан здесь во втором пункте, что описание принципа управления – это есть критерий, который наличие которого предполагает оценку надежности применения надежного теста. 

S06 [01:49:08]  : всем прошу прощения, раз уж мы в режиме дискуссии, я думаю у всех вопрос назрел. вы говорили про среду функциональной теории системы или просто теории системы. как вы себя представляете? что это за суда такая? в ней правила. как и вообще создать такую среду? я просто впервые слышу такое сочетание как среда для теории систем. как? 

S08 [01:49:34]  : я как бы не буду гадать ничего. я специально, чтобы свое представление не усложнять, я просто взял и воспользовался википедией. я никого не хочу ни в чем здесь Вот если сейчас открыть ее и посмотреть агентные среды, среды, в которых работают программные агенты, там будет указано, что эти среды предполагают, что поведение агента зависит от среды, которая называется, определяется той самой средой, которая определяется теорией систем. Это за уши притянутая с Википедии терминология. Если русским языком проще говоря, то есть агент, который в программном, программный агент, который работает, кто-то писал, для чего-то он работает, кто-то его применял. Вот этот кто-то, вот это вторая среда, которую я назвал теорией системы. Вот, например, человек, вы, я. Тот, кто создает, разработчик, разрабатывающий этого агента, эту программу. Этот разработчик собой представляет эту его целеполагания, все, что его окружает и представляет ту самую систему, он находится в этой системе. Если вот обратиться к ответам на вопросы, которые писал Никола, я в принципе ему как раз этот самый вопрос и задавал. Сейчас, секунду, я прямо найду этот вопрос. он в своих ответах, если внимательно посмотреть, использует такие среды. кстати, вопросов вы не задали, обратите внимание. сложная среда, где изменчивость... Несколько активных объектов одновременно. Реальная среда, потенциальная реальная среда, целевая среда, тестовая среда, универсальная среда, операционная среда, сфера применения, потенциальная. Вот это все столько сред и ни у кого вопросов не возникло. У меня вообще взрыв сознания возник, когда я увидел столько сред, каждую среду. Что он имеет в виду? тестовую среду всегда переименовывают. это не претензия, ни в коем случае. я как раз уточнял, но, к сожалению, вы не прочитали, либо, может быть, позже ответите. то есть, если столько сред описано в ответе, то вот эти все среды – это все среды агентно-ориентированного подхода или это какие-то еще другие среды, то есть сфера применения, но это, наверное, он имеет в виду не агент. сфера применения, наверное, называется та самая среда, по которой вы спрашивали, она называется умикола. я ответил на ваш вопрос? 

S06 [01:52:47]  : Дмитрий? Пожалуй, да. Я читаю ваши все ответы и немножко потерялся. Хорошо, Максим, давайте еще минут пять. Мне, если честно, очень сложно воспринимать, поскольку вы оперируете на очень абстрактном уровне, который мне, как инженеру, просто нужно приземлять. Мне нужен конкретный символ grounding. проблема передо мной стоит. хорошо, давайте. продолжайте. 

S08 [01:53:24]  : если не сложно, откройте тогда мои вопросы к Николе, потому что так получается, что я правда не вижу принципиальных расхождений. может быть, будет более понятно вам, вот если вот это приземление необходимо будет, то там оно как раз есть. то есть ответы на вопросы Миколы откройте в фейсбуке, и там есть. вот оно? да, можно это открыть, да. не фейсбуковое, а просто открыть comments. да-да-да, вот я в принципе здесь у него задаю вопрос, что здесь у него множество, он использует термин среды, и задаю ему вопрос, что в агентно-ориентированной среде, которая через поведение агента напрямую связана со средами, вот это сложно понять. я не могу уловить этот момент. в принципе вся связка вот здесь. все приземление происходит вот в этом приложении. агентно-ориентированная среда, которая через поведение агента напрямую связана со средами теории системы. непонятно, что здесь написано. 

S09 [01:54:35]  : можно вас спросить, к чему вы вообще это говорите? к чему вот это привязывается, про среды? а можно тестировать агента в разных средах. вот этот пойнт вы хотите высказать, что можно тестировать агента в разных средах? 

S08 [01:54:50]  : нет. вы в контексте содержательного, по содержанию коммента, на что вы обратили внимание? 

S06 [01:54:59]  : Максим, например, c – потенциально реальная среда. что такое потенциально реальная среда? я вообще не представляю. это Николай писал. 

S08 [01:55:06]  : Нет, это я не знаю, это я у него спрашиваю. Вот это все у него в ответе. Вот этот список, это все он в ответе пишет. Он пишет, я ему пишу в ваших ответах на вопрос, вы указываете среды из них применения, и вот этот список. A, B, C до I. Я ему задаю вопрос. Если вы это все рассматриваете вот так, то 

S06 [01:55:32]  : Николай, к вам за помощью обращаюсь. Вы понимаете, что Максим сейчас от вас хочет? 

S02 [01:55:38]  : Ну, реально, с моей точки зрения, есть два класса сред, дискретная и континуальная. 

S08 [01:55:49]  : Ну да, вы это говорили, здесь не об этом вопрос. 

S02 [01:55:53]  : А дальше есть просто, так сказать, момент использования. а что такое реально? 

S08 [01:55:59]  : вот вы сказали сейчас реально. это другая среда? 

S02 [01:56:03]  : это если я пришел в walmart и ездит Робот, который следит за порядком и заполнением… То есть реальная среда – это вы и робот в Уолморте. 

S08 [01:56:14]  : Я правильно понимаю? 

S02 [01:56:15]  : Не только я и робот, а еще и куча других людей. 

S08 [01:56:18]  : И куча других людей. Вот это я и называю средами теории системы. Микола, куча других людей, Уолморт и робот. 

S02 [01:56:28]  : А когда я в процессе конкурса моделирую эту систему программно, то это потенциально реальная среда. 

S08 [01:56:49]  : это понятно. Микола, здесь я как бы не хочу цепляться к вопросу, к терминам, но здесь вопрос был у Дмитрия и у Юрия, что здесь имеется ввиду под реальное, то есть что я имею ввиду, что среда теории системы. вот сейчас Микола ее описал. у него есть программа, в которой запрограммирован робот, которую он велит в Walmart, и есть он, волмарте и видит этого робота и все остальные люди. вот это две системы, одна и вторая. Дмитрий, вы понимаете? Юрий? 

S09 [01:57:29]  : я понимаю, но я не понимаю к чему. то есть, что вы хотите сказать тем, что... ну вот разделили вы среды. есть виртуальный мир, есть рядный мир. а к чему вот это идет? ну понятно как бы что надо тестировать разных средах. 

S08 [01:57:52]  : ну вы сейчас сами-то себя слышите. есть реальная система, есть реальный мир, надо тестировать в разных средах. вот это же невозможно понять. Вы сейчас реальными средами назвали или просто средами? Или ничего не назвали? 

S06 [01:58:05]  : Давайте не перепалки, а просто смотрите. Нет, это не перепалки. Ваш поискование пока выглядит как недосказанное предложение, которое половину забрали. продолжить. 

S08 [01:58:18]  : скажите мысль до конца, пожалуйста. да-да, немножко сдвиньте выше этот фейсбучный коммент. сюда? еще выше? нет-нет, обратно, ниже получается. ниже? так. немного назад. 

S06 [01:58:37]  : еще выше. так. 

S08 [01:58:43]  : где про среды заканчивается, и вот в ответах на вопрос вы оказываете объекты. То есть здесь Микола говорит про объекты в тех самых средах, которые программные среды. И вот при описании агентно-ориентированной среды используется объект, объектно-ориентированного программирования. Если путем рассмотрения поведения агента использовать объектно-ориентированного программирования объекта к средам, то есть к теории систем, то есть к этим реальным средам описывать вот этим объектом программирования, то весь процесс управления перехода от этой среды к другой среде придется описывать через вот этого объекта. Программирование. Через объектно-ориентированное программирование придется описывать реальные системы через этот объект. То есть, что придется описывать? Придется описывать субъекта. Субъекта описывать через объект. Миколу придется описывать через объект, который пришел в Walmart. Всех остальных. Ну, уже, наверное, вы слышите, что субъекта придется описывать через объект. Я думаю, что апологеты событийно-ориентированного программирования здесь утеряться, потому что придется описывать события через объекты. Микола задает вопрос о параметрах, он не задает вопрос, он говорит о параметрах, о параметрических требованиях, которые являются важными для тестирования сред. параметры – это и есть те самые субъекты, это и есть тот самый, кто принимает решение. что такое параметр? параметр обладает субъективными условиями, то есть те же самые субъекты – это и есть параметры. то есть речь идет о том, что в этом комменте, но если вы не читали, я в принципе специально это выкладывал, наверное, это все будет сложно восприниматься. Понимаю, если информация не заходит, я готов не продолжать, то есть мучить мозг. 

S09 [02:01:05]  : Максим, можно попросить вас попробовать слов 10-20, мысль одну законченную сформулировать. о том, что вы говорите. ну я не вижу никакой проблемы. ну описали мы объектно-ориентированным программированием людей. ну и что, во всех играх так делают. в чем проблема-то? описали. ну не идеальные получились, но это же моделирование. в чем проблема-то? то есть я пока не понимаю, к чему вы вообще идете. вот пока что термины говорят, что у вас в голове не складываются, но у меня все складывается в голове. я не вижу противоречий. 

S08 [02:01:48]  : вы читали ответы на вопросы? 

S09 [02:01:54]  : нет, я не читал ответы на вопросы и не очень понимаю, почему я должен был это сделать. 

S06 [02:02:01]  : Коллеги, извините, что я встреваю. 

S03 [02:02:03]  : Мне кажется, это мучает всех участников и тех, кто будет смотреть это видео, теми вопросами, которых, может быть, никто никогда не читал. 

S09 [02:02:13]  : Я бы прочитал, я бы все равно ничего не понял. Я до сих пор ничего не понимаю по этим комментариям. 

S08 [02:02:21]  : но я думаю, что если задать вопросы, если я готов содержательно ответить на любые вопросы, которые я в принципе для этого и писал. если Юрий не понимает, для чего читать, Ну, я же не могу на пальцах за 5 минут на голосе... Коллеги, давайте будем обсуждать то, что многие просто не просчитали. 

S03 [02:02:40]  : То есть, если это не озвучено, то как... У нас же семинары не по поводу обсуждения того, что кто-то где-то когда-то написал. У нас каждый здесь имел возможность высказаться. Ну, если... 

S08 [02:02:54]  : ну хорошо, конструктив в чем? это вопрос про то, как говорил Смолин, то есть в чем конструктив вот этого всего действия? 

S09 [02:03:05]  : потому что у нас тема есть. 

S03 [02:03:10]  : Дим, давай все-таки не будем обсуждать протокол, а вернемся к теме. 

S06 [02:03:18]  : Тема у нас называется тестирование новых горизонтов. Следующий у нас Алекс Бур, если он еще здесь. Алло, здравствуйте, слышно? Алекс Бур здесь. Да, да, слышно. 

S10 [02:03:33]  : Добрый день, господа. Сейчас, сейчас, секундочку. В общем, система тестов, конечно, нужна, система тестов должна. Если мы можем заглядывать под капот, а именно анализировать алгоритмы, тогда нам проще будет понимать АГИИ, не АГИИ. Это первый момент. Второй момент. При построении АГИИ мы всегда должны протягивать цепочку от неинтеллектуального к суперинтеллектуальному, от неживого к живому, от... не моделирующих к моделирующему. Поэтому если ответить на вопрос, что такое мышление, я отвечаю, мышление – это процесс порождения использования моделей и ничего более, а интеллект – это способность к моделированию, то тогда получается, что в некоторой степени интеллектуально, и бактерии, и муравьишки, и так далее, и так далее выше. Просто степени интеллектуальности разные. Все это моделирующие системы. И в наличии получается такая цепочка. Это означает, что это очень сложный объект, многопараметрический. Как и любой сложный объект, требуется, соответственно, Отродить все его свойства требуется большая система тестов. Не три измерения, а адаптация по времени и еще что-то, а множественная система тестов. И, конечно, систему тестов нужно учитывать от того, какие алгоритмы и на какой живой. на местной базе или не на местной электротранзисторной базе. Это все происходит. Понятно, что Вингу-10 на процессор 20-летней давности не загрузишь. Аналогично с муравьями, с примитивными организмами и так далее. Таким образом получается, что уровень интеллекта должен определяться всеобъемлющей системой тестов по иерархии усложнений цепочки моделирования. То есть от образования условных рефлексов и тестов фетологов до тестов психологов, психиатров, в том числе и тесты на IQ и иные, которые мы сочтем нужны. То есть это обычное построение шкалы, метрология, теория измерений, тестируем всю иерархию сложного объекта. Таким образом, могут муравьи или несколько клеточных животных получить одни баллы, Там более сложные животные, другие баллы и так далее. Параметры сложной системы, естественно, измеряет система метрик. Далее окончательные баллы – это свертка, это система метрик. Ну, свертка может быть любая. Различие же между узким и общим интеллектом будет не в самом уровне, а в том, каким именно алгоритм решает ставленная задача, независимо от уровня задачи. Например, калькулятор. Складывает или инженерный калькулятор, есть программируемый или не программируемый, и так далее. Таким именно алгоритмом решается та или иная задача. и состоит интеллектуальность. Либо специализированные взяли дифуры и научили согнать манипулятор, руку и так далее. Либо общий алгоритм, который, как здесь упоминалось, умеет решать многие задачи. Это вот в целом. Я сейчас в чат запущу цепочку. Я вот эту цепочку давал неоднократно в чате. ну, в общем, чате о гей. Ну, чтобы не повторять ее вслух. Вот посмотрите, вот эта вот вся цепочка, по большому счету, каждый вот этот уровень должен быть обложен системой текстов. И это будут свои уровни общего искусственного интеллекта. Некоторые примитивные в связи с тем, что у них примитивные алгоритмы и примитивная исполнительность, то есть элементная база, которую исполняют, либо это будет более Продвинутая база и более продвинутый алгоритм. Понятно, на более продвинутой базе больше памяти, быстродействие, коммутирование вычислений, может быть более сложный алгоритм для исполнения. И опять, эти алгоритмы не должны быть специализированы. Поэтому нужна система тестов всегда. Ну, собственно говоря, ну и еще, наверное, вот один момент скажу, было совсем недолго. Я в Facebook, сейчас я сюда, собственно, запущу тоже в чат. Давным-давно писал, не знаешь правила игры. Ты не знаешь ставки в игре, ты не знаешь цель игры и так далее. И проходим. Это вот основное. Есть, собственно говоря, любой искусственный интеллект, по идее, подключаем по универсальному... Это не шутка, вот это вот все. Да, оно в шуточной форме. Подключаем по USB, например, к универсальному какому-то разъему. Непонятно, к чему. Он не знает, сколько у него манипуляторов, сколько у него сенсоров. должен с телом разобраться, как и с любым, с любой внешней средой. Для любого, для искусственного интеллекта любое тело – это внешняя среда. Ну, собственно говоря, наверное, и все. 

S06 [02:09:56]  : Вопросы, может быть? Юра задает вопросы, я вторю ему, в общем-то, да, действительно, когда у нас рефлексы, это все очень просто, но это точно не AGI. А где-то у нас начинается AGI, когда сложные когнитивные задачи начинаются. Где водораздел? 

S10 [02:10:16]  : Ну да, вот в этом я назвал этот водораздел. Водораздел в том, как вырабатывается условный рефлекс. Если это жесткое правило заложено, это значит не AGI. Если это не жесткое, алгоритм выработки условных рефлексов – это уже edge rise соответствующего уровня. Ну, пример какой? Ну, по-моему, тут понятно или нет? Еще что-то требуется? 

S03 [02:10:47]  : По-моему, не всем понятно. По-моему, вот как раз здесь есть проблема того, когда люди говорят, что где начинает CGI, тут как раз возникает ситуация, что непонятно. То есть, что такое вообще? Где мы говорим сложное, а где несложное? Где сложное поведение, а где простое? Какой есть формальный критерий? Я пока не вижу формального критерия для того, чтобы сказать, где начинается сложное и где кончается простое. 

S10 [02:11:19]  : Это должна быть только система тестов. Ни один критерий не сможет охватить всю область. Система тестов, даже на выработку условного рефлекса. Условный рефлекс, скажем... Сейчас, секундочку. Определение произвольных закономерностей наподобие памяти последовательности Серебряникова, то есть мы вычленяем цепочки причинно-следственных связей. Если это достаточно общий алгоритм, то да, это AGI, по выработке условных рефлексов. Ну а так конкретнее, конечно, это надо долгий разговор. 

S09 [02:12:10]  : моделирующая пчела – это AGI? 

S10 [02:12:13]  : Да. В моем понимании, начиная с бактерий, это все AGI. Может быть, даже и вирус. И тут ситуация следующая. Это из общей, скажем так, теории, практики, оптимизации. Каков критерий, такова и классификация. И, соответственно, на границе классов всегда будет дребезг, неустойчивая классификация. Это нормально, это обычно. 

S09 [02:12:44]  : Правильно ли я тогда понимаю, что искусственный интеллект, общий искусственный интеллект уже создан? Ведь у нас есть reinforced learning алгоритмы, которые ровно не знают правила игры, не знают вставки в игры, не знают цель игры и так далее. 

S10 [02:12:58]  : Да, это примитивные искусственные интеллекты, да. Примитивные общие искусственные интеллекты. Ну вот, например, я давал там Starfish, там не помню, чего университета, там неоднократно тоже, да, там звездочку учится ходить, там четырехпалое, по-моему. У нее одну лапку отрывает, она перестраивает. Ну, что-то наподобие страуса и так далее. Или наподобие мышек Витяева. Да, это общий искусственный интеллект, да. Вот очень хороший пример мышки Витяева и сыр. Это общий искусственный интеллект. Он примитивный, но это общий искусственный интеллект. потому что они могут вырабатывать в произвольной среде условные рефлексы. То есть, общий алгоритм, общий. Все. 

S06 [02:14:01]  : Подождите, вот вы сказали хорошее слово «общий», а, собственно, в той парадигме, которую вы здесь предлагаете, общность как бы не проверяется. Здесь проверяется скорее то, что с абсолютно пустого состояния, он разбирается во всём. Обычные условия для джима, всем известная среда. Обобщение-то как проверить? 

S10 [02:14:25]  : Только с системой тестов. Ни один тест никогда не проверит. Если мы не можем заглянуть под капот, посмотреть сам алгоритм, каким образом он действует, то только с системой тестов. 

S06 [02:14:41]  : Подождите, вы сами себе противоречили. Говорите, что тесты не проверить, а систему тестов проверить. 

S10 [02:14:46]  : Ну да, и в любом случае остается какая-то вероятность ошибочной идентификации. Не вижу здесь противоречий. То есть, да, система тестов, которая разные свойства, ну, допустим, условный рефлекс. Да, разные тесты на общность выработки условных рефлексов. Ну, а именно, например, реакция на пинг-понг, реакция на другую игру ата, реакция на шахматы и так далее. Реакция на сыр, реакция еще на что-то. Так же, как правильно говорил Николай Рабченко. 

S06 [02:15:30]  : Хорошо. 

S10 [02:15:31]  : Ну, в общем-то, я тут не сказал ничего супер такого, я просто утверждаю, что это должна быть всегда система ответствий. Поскольку сложная среда, мы должны многие параметры отследить. А если мы не можем заглянуть внутрь, то мы, так же как и проверка правильности программ, требуется система ответствий. 

S03 [02:16:06]  : Я очень коротко дополню, что вот с одной стороны Олег Колтунов совершенно правильно просит не останавливаться на обсуждении правильной терминологии, да, и я не предлагаю обсуждать терминологию, но надо понимать в какой парадигме, в какой терминологии, в каком определении AGI работает какой спикер. Вот если я правильно понимаю, мы с Алексом Буром отталкиваемся от понимания, что AGI это сложная среда, сложные цели и разные среды, да? Соответственно, что значит разные, что значит сложные, да? Вот две, два параметра в среде и две цели одновременные и две разные среды – это достаточно сложно или нет? 

S10 [02:17:02]  : Ну, если ко мне вопрос, то… Соответственно… 

S03 [02:17:06]  : Сейчас, секундочку, я закончу. Соответственно, формально, если следовать тому рабочему определению, от которого я, например, отталкиваюсь, если количество параметров больше, чем 2, то это уже минимально сложная среда. А Юрий Бабуров не готов это принимать, потому что то определение AGI, которое он нам дал в своём докладе – это не AGI. С моей точки зрения, это HLI. Соответственно, с точки зрения HLI ни муравей, ни пчела, ни даже мышь не могут рассматривать AGI, потому что они не соответствуют его определению. Поэтому здесь спорить между участниками, исповедующими различные определения EGI, наверное, не очень осмысленно. Можно только принимать это с точки зрения. Все, спасибо. 

S10 [02:18:05]  : Я по поводу сложности, может быть, скажу. Вообще говоря, как и любое понятие, сложность очень по-разному можно определить. Вот так же, как AXE, сложность определяют как минимальные длинные описания. ну, во-первых, и хотя бы можно, за какое время это все производится, добавить как минимум метрику. А кроме того, вообще сложность и штука сложная. И ее, например, вот на графах есть цикломатическая метрика. диспломатическое число графа, то есть в зависимости от ребер, вершин, от количества, как они связаны, все то же самое можно и к нейросеткам применить или в какой-то модификации. Число связи умножить, входит, столько выходит, что-нибудь сложить, умножить и так далее. Метрик может быть множество. Все, спасибо. 

S06 [02:19:10]  : традиционно ждем если появится желающий так а вот так даже так а где он олег олег олег серебряников да насколько я помню видимо он не дождался своей очереди Тогда Владимир, пожалуйста. 

S00 [02:19:41]  : Меня слышно? Да. Отлично. Ну, я постараюсь краться, чтобы мне было как-то возможно понять, к чему я клоню. Не то чтобы совсем это никто не разделяет как способности и навыки системы, но как-то их не особо стремятся разделить. То есть каждый из нас, скажем так, родился в достаточно цивилизованном обществе. Если бы такой же, наши же родители жили бы где-нибудь на острове в Тихом океане, и мы не получили никакого образования, не были связаны с цивилизацией, всех вот этих наших интеллектуальных свойств мы бы не проявляли. Это, надеюсь, всем понятно. Ну и известный там случай, когда там ребенок вырастал в джунглях, он там... Ну и в целом, как бы, не только, значит, интеллектуалы появлялись в развитых обществах, но и даже олимпийские чемпионы, как бы, это показатели развития страны, то есть, вот, казалось бы, быстро бегать, но там не надо никакого интеллекта, а все равно странные с низким уровнем развития, они быстрых бегунов не производят. тьюринг-бэби-тест или бэби-тьюринг-тест, как хотите, его как-то надо разделять на две вещи. То есть, если вы кошку там будете обучать как человека, ну, вряд ли вы там получите, как бы сказать, ну, то есть, даже если бы она жила там не 20, а 50 лет кошка, все равно бы, вряд ли бы вам удалось ее обучить. То есть, нужно, во-первых, чтобы, значит, вот эта ваша система обладала некоторыми способностями, а во-вторых, чтобы ее можно было, значит, разным вещам обучить. Это как бы первое. Ну и, значит, если говорить о том, к чему ее можно обучить и какие тесты могут быть тесты, как известно, общественно-историческая практика является характеристикой, то есть каким-то одним тестом вы, конечно, не определите. Но, значит, если брать, как сказать, более общим, если признают субъектом права на уровне человека, то это как бы будет, по крайней мере, human level. искусственный интеллект, а, соответственно, если будет чуть-чуть получше соображать, ну, видимо, уже будет немножко выше. Хотя я так подозреваю, что эта граница будет достаточно быстро пройдена. Хотя, значит, Эгберт предложил там еще более такой формальный критерий, что если, собственно, сильный искусственный интеллект сможет себя самоусовершенствовать и получать лучше, хотя в этом критерии тоже есть некоторые червоточины в том смысле, что в каком смысле оценивать, вот он там сделал себе какие-то изменения, а стал ли он от этого лучше. То есть если он там суперинтеллект, мы может быть не можем понять, что он стал лучше, а он, как он суперинтеллект, понимает, что он стал лучше. А если мы там можем понять, что он стал лучше, то, наверное, это не очень суперинтеллект, поскольку это значит, наверное, человеческий уровень интеллекта, поэтому там, конечно, как сказать... Тервоточно во всех этих определениях много, но еще одно важное соображение, наверное, высказать о том, что мы живем на представлениях, которые вырабатывались тысячелетиями, о том, что мы обладаем безграничными интеллектуальными возможностями, которые у нас либо Богом, либо еще чем-то заложены матушкой природой. На самом деле наши возможности у всех очень ограничены. Мы работаем в достаточно узкой всеобласти, решаем достаточно узкие задачи, и если бы нас лишить взаимодействия с другим обществом, то, естественно, никаких серьезных задач мы никогда не решим. Как с тем примером, если бы мы родились где-то на острове и не были связаны с цивилизацией, мы бы даже и вопросов бы таких не ставили, а уж не говоря о том, чтобы их решать. И, соответственно, представление о том, что мы сейчас какие-то коэффициенты наших алгоритмов поменяем и создадим сильный искусственный интеллект, но они, по меньшей мере, наивны. То есть я много раз рассказывал о том, что надо улучшать аппроксимацию преобразований, лионеризацию, проводить декомпозицию и много еще чего делать, чтобы эти способности были уровня хотя бы хорошего искусства, ну пусть сильного искусства интеллекта. Вот. Ну и, собственно, второе, это, собственно, смотреть способности, а насколько широко есть возможности для обучения. Вот. Вот, собственно, про эти разделения и про то, что каким-то одним тестом, конечно, это, значит, не... пробьешь, а это должно быть результат деятельности общества в развитии. Завершая, скажу, что попытки создать очень сильный искусственный интеллект, многие признают, что это опасно, потому что слишком мощные умственные способности для человеческого общества могут быть опасны, поэтому этот агентский подход как бы более, скажем так, соответствует человеческой цивилизации, когда каждый человек имеет ограниченные возможности и общество может контролировать каждого отдельного человека, хотя как бы есть и выверты, значит, в истории, когда там как бы диктаторы начинают контролировать общество, вот, но все-таки, значит, сказать, когда все-таки возможности каждого диктатора собственно ограничены, то, тем не менее, значит, общество как-то с этим справляется, вот это развитие идет. Ну и там еще есть ряд причин, почему, собственно, вот эти агенты не должны быть очень-очень сильны и, собственно, сохраняться должна конкуренция, там много другое, но это как бы не совсем по теме. Вот, вот, собственно, как бы о чем хотелось сказать, по-моему, раньше не особо, по крайней мере, четко было сформулировано. Спасибо. 

S06 [02:25:06]  : Владимир, спасибо. Кто еще вопросы спикерам или сам что-то хочет сказать? Так, две минуты. Да, пожалуй, давайте. 

S07 [02:25:20]  : Добрый день. Нормально слышно? 

S06 [02:25:22]  : Да. 

S07 [02:25:24]  : Да, я тоже хотел бы сказать по поводу тестирования. Начну я с того, что полезность нашего условного IG в первую очередь заключается в предсказании. Сейчас нет ничего сложного в том, чтобы запомнить какие-то нужные данные и для них запомнить какой-то нужный аутпут. Сложность наступает, когда наши входные данные как-то немного изменились. Наш мозг может быстро отсеять ненужные данные. Если, например, листок стал менее зеленым, он у нас все равно остался как листок. Но для компьютера такие мелкие изменения могут быть значительными, так как для этих новых данных у него может не быть информации, а какой должен быть выход для этих новых данных. И мы начинаем вводить какие-то метрики, которые определяют какой-то близость данных, математические функции и тому подобное. С одной стороны, у нас есть комбинаторный взрыв со всеми возможными вариантами, где мы должны заполнить все возможные input и соответствующие output, а с другой стороны, у нас есть жестко закодированные метрики. И с моей стороны, IG должен динамически уметь перестраиваться и подстраиваться под эти метрики. Но сейчас не об этом, сейчас о тестах. Если мы будем строить какие-то тесты, то в любом случае мы будем вводить какие-то метрики, делать какие-то алгоритмы, которые в себе уже будут заключать какую-то определенность, которую нельзя будет нарушить, которую наш компьютер не сможет нарушить. И в любом случае мы будем приходить к каким-то специализированным решениям, которые будут лучше, чем обученные. Если мы будем делать такие тесты и для них IG, то мы в какой-то момент наткнемся на то, что IG будет хорошо работать именно для этих тестов, так как мы сами разрабатываем решения, человек, разрабатывая решения, он будет отбрасывать какие-то метрики, какие-то данные, которые будут показывать плохие результаты. И иногда он будет делать это ошибочно. И вывод такой, что если мы и должны делать эти тесты, тестировать IG, то только на тех данных и на тех средах, с которыми сама IG и мы сами никогда не сталкивались, не видели. И только когда наш условный IG сможет как-то работать и перестраиваться под эти данные, под эти новые метрики без нашего вмешательства, то тогда можно и говорить, что мы уже в какой-то момент идем в правильном направлении. В общем, 3-2 минуты. Спасибо. 

S06 [02:27:47]  : Ну, в целом, да, согласен. Юра, давай вопрос. 

S09 [02:27:53]  : Вопрос такой, а не может ли достаточно сложная задача быть использована вместо того, чтобы использовать, проверять способности именно к экстраполяции, к решению новых задач? Потому что, ну вот не знаю, если кто-то решит великую теорему Фирма, он для меня будет умным, даже если он ничего другого делать не умеет. то есть это значит, что у него достаточно развитый какой-то математический аппарат и вообще, наверное, умеет много чего делать. 

S07 [02:28:23]  : да, мы тут тогда говорим о том, что теорема-фирма работает для каких-то данных. то есть это какой-то математический алгоритм. извините, я не знаю, надо вспомнить, что такое теорема-фирма. Немного неконтекстно, но смысл в том, что мы подаем какие-то данные и мы получаем какой-то выход. Мы не можем теорему фирмы применить для абсолютно всего нашего обзора количество данных. То есть мы должны быть в каком-то, можно сказать, нужном контексте. Мы должны знать, что для этих данных мы должны... Смысл в том, что наши какие-то математические функции, математические решения, они работают для какого-то набора данных. Это хорошо, но для какого-то набора данных они могут не работать. Но когда мы, грубо говоря, закладываем какие-то теоремы в наш IG, в наш компьютер, то это уже наше предсказание, наша гипотеза о том, что вот эта теорема должна работать для всего. И если мы делаем это предсказание правильно, если мы действительно нашли теорему всего и правильно это делает, то AI здесь не нужен, он должен и так уже правильно считать все данные. Если мы берем какую-то, например, задачу, какие-то задачи смоделировать того, чего нет, то есть то, что сейчас делают в фильмах, спецэффекты, То есть тут проблем нет, они это делают. Другое дело в том, сколько времени для этого надо, потому что они просчитывают очень большое количество данных. Когда мы делаем какую-то другую задачу, мы хотим, чтобы эти данные не просчитывались, то мы откидываем какую-то часть данных. И тогда, откидывая какую-то часть данных, мы точно не можем знать, правильно ли откидывая вот эту часть данных, Правильно ли наша новая математическая функция будет работать для новых данных? В одном случае нам надо очень много ресурсов и времени, чтобы прочитать все возможные варианты. Учитывая какие-то молекулярные особенности и структуры организма, мы откидываем очень большую часть данных и работаем с какими-то главными факторами. Проблема в том, что когда мы знаем, какие эти главные факторы, И мы их закладываем. Проблема насыпает, когда эти наши главные факторы не соответствуют действительности, когда мы получаем результаты, которые плохие, учитывая то, что мы заложили. И тогда наш условный IG должен перестраиваться, исходя из тех новых данных, которые он получил. 

S06 [02:31:16]  : Я хочу Юрию возразить. терминах data science, у тестов подобных докажи теоремы Ферма или Пон Каре очень хороший precision, но очень низкий recall, потому что очень много систем общего интеллекта, его не пройдут, как, не знаю, 8 миллиардов людей, которые тем не менее обладают общим интеллектом. Тогда тест хороший. 

S09 [02:31:50]  : если мы говорим про эти прокси-задачи, то мне кажется, что есть способ более сложной задачи – проксировать более простые задачи. и таким образом свести, ну, немножко упростить жизнь. Вместо того, чтобы проверять, действительно придумывать каждый раз новую какую-то уникальную задачу, которую никто из разработчиков не видел, и проверять, решают ли все интеллекты эту задачу. Просто если решил очень сложную задачу, значит, более простые решают. 

S07 [02:32:20]  : Ну, я как бы пытался сказать о том, что для любой задачи, если нам известны все ее возможные решения, мы можем просто как то, что называется overfitting, просто подгонять на эти решения, просто их запомнить. Ну, и в жизни это тоже присутствует. Человек может тоже просто зазубрить материал. Эту нормальную на экзаменах трудно проверить. Хорошим показателем будет предсказание, когда данные немного изменились, каким-то таким способом, чтобы человек или машина смогла правильно сказать, какой результат для этих немного измененных данных. 

S09 [02:33:00]  : Смотрите, необязательно менять задачу. чтобы не было overheating. Можно просто увеличить количество данных. Например, вы можете запомнить то, как один человек разговаривает, но как говорит какое-то одно слово, распознавать это слово. Но вот система распознавания речи, когда ее тестируют на 100 часах, на 1000 часах, невозможно уже это запомнить, никакой нейросети. И это уже проверка интеллекта, без всякого out of domain тестирования и экстраполяции. 

S07 [02:33:32]  : Еще раз вы говорите о том, что нейросеть, которая там работает условно 300 часов, она не запоминает, а делает какое-то хорошее обобщение? Да. Ну, это обобщение строится на тех математических функциях, которые закладываются в нейросеть. То есть она, условно говоря, ищет какие-то правильные математические коэффициенты для входных данных, ищет для них такие правильные веса в нескольких слоях, чтобы они соответствовали всем тем данным, которые приходят. 

S09 [02:34:02]  : У человека в голове нейроны, они то же самое делают. 

S07 [02:34:05]  : Да, и это вроде бы неплохо, но тут у нас есть несколько bottlenecks, такие, как мы плохо должны... Я согласен, что нейросетки, они там есть. какие-то идеи, которые хорошо работают, но у них есть также проблемы, с которыми мы тоже должны работать. И нейросети сейчас эти проблемы не решают. 

S09 [02:34:36]  : Мы можем таким образом, просто количеством. Вместо того, чтобы каждый раз новую задачу просто старая задача увеличить количество данных, пинг-понг с разными размерами поля, с очень разными, проверять. таким образом получить то, что система не сможет все запомнить. таким образом проблема запоминания решится же тоже. 

S06 [02:35:04]  : я просто немного потерялся какую сторону мы идем какой вопрос мы то есть вы утверждаете когда можно это продолжить в текстовом виде согласен в чатике пообсуждать вот вроде бы уже все так обсудили более-менее и думаю что можно разбегаться если есть какие-то прям точно такие интересные моменты. кто хочет сказать, то давайте. если нет, то спасибо всем. общий вывод такой, что тесты нужны. тесты всякие важны, но какие конкретно соревнования, челленджи, тесты и так далее. тут мы все разошлись, как обычно и бывает. это хорошо. спасибо. и до свидания. 

S03 [02:35:59]  : Всем счастливо. Спасибо. 













https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
