## 8 июля 2021 - NARS — система неаксиоматического логического вывода, докладчик — Юрий Колонин - Семинар AGI
[![Watch the video](https://img.youtube.com/vi/PKz7_7SaJIs/hqdefault.jpg)](https://https://youtu.be/PKz7_7SaJIs)


Суммаризация семинара:

Тематика семинара касалась системы неаксиоматического логического вывода NARS. Система NARS представлена как одна из старейших когнитивных архитектур невероятностной логики, которая не любит называть свою область "вероятностной логикой" и предпочитает термин "неаксиоматическая логика".

Суть: Основные идеи семинара подразумевают использование системы NARS для решения задач, связанных с необходимостью работы с неопределенностями и недостаточностью знаний. Система позволяет обрабатывать информацию, учитывая историю событий и динамику их изменения во времени. 

Детали: НАРС включает в себя механизмы, позволяющие обрабатывать утверждения с учетом их временных рамок и истории получения. Утверждения в системе NARS хранят информацию о времени и условиях получения, а также о родителях, которые их породили. Это позволяет системе учитывать сложные механизмы, такие как обобщение во времени, этернализация и другие.

Результаты: Семинар подчеркивает экономичность и параметризуемость системы NARS, что позволяет ей работать с ограничением оперативной памяти в 1 мегабайт, делая все возможное в рамках этих ограничений. Однако, в контексте разработки общего искусственного интеллекта (GIA), система представляется как узкоспециализированная и не масштабируемая в различные направления и задачи. Семинар не исключает возможность применения подходов NARS в узкоспециализированных задачах, таких как распознавание документов.


S04 [00:02:13]  : Антон, если мы уже в эфире и ты уже пишешь, ты сделай общую вводную, чтобы мы не… Да, коллеги, вот сегодня мы начинаем серию лекций или семинаров, точнее, предложенных Игорем Пивоваровым, посвященных… где каждый семинар предлагается посвятить разбору какой-либо когнитивной архитектуры. Начинаем с Нарса, который является одной из старейших систем, если это правильно сказать, невероятностной логики. Пейванг не любит слово «вероятностная логика», потому что под «вероятностной логикой» заразумеваются вполне определенные вещи. Он это называет неаксиматической логикой и собственно сегодня рассказ будет про это. Ну а дальше в зависимости от желающих можем разбирать другие когнитивные архитектуры. Про Джеффа Хокинса может быть Юрий Бабуров нам или Дмитрий Салихов расскажет. Потом может быть Потапов нам снова придет и про Опенкок расскажет. Ну и дальше посмотрим. 

S06 [00:03:19]  : Ну отлично. А сегодня у нас Юрий Колонин будет рассказывать про нас. Замечательно. Так, коллеги, я всех тоже приветствую. Всем добрый вечер. Я буду модерировать сегодняшнюю встречу и прошу Юрия Колонина расшаривать экран и приступать к рассказу. У нас сегодня час времени примерно планируется на рассказ. Юрий, в принципе, готов на какие-то вопросы в процессе. Если у вас есть в процессе вопросы докладчику, я прошу ясно писать в чате. У нас в чате обычно такой трэш творится, и переписка друг с другом это нормально, это хорошо. Если у вас есть вопросы прямо к докладчику, пишите прямо вопрос. И в зависимости от вопроса мы его там прям будем по месту вставлять или он останется в конце на общие вопросы. Все, Юрий, вам слово. 

S13 [00:04:16]  : Да, коллеги, всем еще раз добрый вечер. Как меня уже представили, меня зовут Юрий Колонин. И сегодня я рассказываю про когнитивную архитектуру NARS. Это действительно, как уже подметили, одна из старейших когнитивных архитектур, при этом достаточно необычная. Очень многие вещи, которые я подмечал по ходу ее разбора и изучения, Я не видел больше нигде, поэтому, наверное, в конце было бы интересно устроить небольшое обсуждение. В первую очередь, мне интересно мнение людей, которые сами разрабатывают архитектуры. Было бы интересно услышать по двум вопросам. Во-первых, какие вещи, о которых будет по ходу рассказа, имеют параллель в каких-то там других архитектурах, которые вы разрабатываете или просто видели, и, наоборот, интересно услышать, какие вещи из доклада покажутся необычными, уникальными и которые, в принципе, могут иметь перспективу при использовании где-то еще. То есть, может быть, там что-то можно перенести в другую архитектуру. Вот это, наверное, было бы интересно услышать в первую очередь. Ну и вопросы в чат во время доклада, голосом после доклада тоже приветствуются, буду рад ответить. Собственно, если говорить про саму архитектуру, это действительно очень старая разработка. Первые статьи по неаксиоматической логике и основам НАРСа, они уходят еще в 90-е годы, возможно, есть и раньше. Как вообще я стал это все изучать? Я вообще занимаюсь другой коллективной архитектурой. Мы с моим научным руководителем Евгением Евгеньевичем Летяевым, который сейчас присутствует на встрече, вообще занимаемся теорией функциональных систем. Это другая архитектура. В прошлом году мы делали доклад по ней на конференцию AJI 2020. Там мы взяли премию за лучшую когнитивную архитектуру, после чего Пей Ванг, главный редактор журнала Journal of Artificial Intelligence, предложил нам опубликовать расширенную статью. По совместительству он является отцом-основателем NARS и очень давно в сообществе международном, очень давно занимается искусственным интеллектом. И так возникла идея в целом провести анализ именно теории функциональных систем и НАРСа посмотреть, чем эти архитектуры, что у них есть общего, что разного, чем они могут, в принципе, друг другу помочь, потому что такое сравнение, оно может помочь обеим архитектурам в развитии, какие-то вещи можно подметить. И это стало темой моей бакалаврской работы, которую я успешно защитил. И сейчас, поскольку мне по ходу процесса пришлось очень сильно разобраться в NARS, возникла идея, чтобы я про него, собственно, рассказал. И вот мы здесь. Собственно, NARS расшифровывается как Non-Axiomatic Reasoning System. Это не аксиоматическая система рассуждений или вывода. Эта когнитивная архитектура основана на правилах. Один из достаточно популярных типов когнитивных архитектур не аксиоматическая. Тут значит, что никакое из никакое знание, никакое утверждение, высказывание система не воспринимает как аксиому. Тут уместно упомянуть про такую дистинкцию, как state-based и statement-based подходы. Это, опять же, терминология, используемая пейвангом. Там идея в том, что state-based подход, то есть основанный на состоянии, он про то, что агент или система всегда хранит в памяти некое состояние среды, то есть законы, по которым среда изменяется, правила, которые она считает истинными, и в зависимости от этого совершает действия. В оппозицию этому идет statement-based подход, который завязан на то, что все, что есть у системы, это высказывания о мире, которые по ходу ее жизненного цикла подвергаются каким-то изменениям и переоценке. И с точки зрения пейванга, statement-based подход очень сильно хорош тем, что он избавляет от так называемой frame problem. Это проблема того, что чтобы пользоваться аксиомами АМИР, их надо найти. А тут аксиом нет, все берется из опыта и любая даже самая уплотненная в знаниях агента любая информация, она может быть переосмыслена и отвергнута в какой-то момент. Вот эти четыре буквы, которые вы видите сейчас на экране, это такое некое абстрактное рассуждение, которое лежит глубоко-глубоко в основе НАРСа. Это так называемая assumption of insufficient knowledge and resources или предположение о недостаточности знаний и ресурсов. Это именно некая такая максима. Ее смысл в том, что к вопросу об определении интеллекта, вот с точки зрения Пейванга на этот вопрос, в том, что интеллект это способность достигать целей в условиях недостаточных ресурсов, ограниченных ресурсов и недостаточного знания. При этом ресурсы здесь понимаются в широком смысле, как какие-то абстрактные ценности, которыми агент владеет в среде, так и просто вычислительные ресурсы. Поэтому вот эта цитата из книги «Неаксиматическая логика» — три требования, которые предъявляет к интеллектуальной системе, чтобы она претендовала на звание интеллектуальной, они следующие. Это ограниченность, это чтобы система могла работать именно в ограниченных ресурсах, в частности скорость процессора и память на диске. Это работа в реальном времени, то есть система должна всегда уметь работать с задачами, которые появляются в любой момент ее жизненного цикла. Ну, как, собственно, живые сущности. И открытость, универсальность – это о том, что система должна уметь решать любые задачи, покуда они могут быть изложены в понятном системе языке. Собственно, для описания, как внутренний язык NARS, был разработан специальный формальный язык NARSIS, на нем осуществляется ввод в систему, и ее внутренние все вычисления могут быть изложены на нем же. в частности, на экране это уже такой небольшой псевдо-нарсизм. Собственно, неаксиоматическая логика, которая лежит в основе НАРСа, то есть Пейванг все время говорит, что НАРС разделен на две части, и есть сама логика неаксиоматическая, и есть система контроля, и вот что, дескать, неаксиоматическая логика уже и вглубь и вширь разработана, а систему контроля мы пока делаем. В связи с этим я до начала упоминал, что сейчас как-то немножко скудно с работающими демками. Я думаю, это связано с тем, что как раз система контроля пока допиливается. Так вот, о некотематической логике. Это некая вариация на тему классической логики с достаточно сильно от нее отличающейся, даже от нечеткой. Терм, можно начать с термов, они определены, собственно, идея примерно та же, как в классической формальной логике. Есть некие атомарные термы, например, кошка, ворона, дверь и так далее и тому подобное. И из атомарных термов конструируются термы составные, которые объединяются друг с другом при помощи некоторых связок, в частности, копул. То есть вот, например, пример составного терма. Его можно прочитать, как кошки являются животными, и между ними вы видите такую стрелочку. Это так называемая копула наследование inheritance, то есть как бы как про подклассы. вот это такой достаточно упрощенный ультрированный пример. в реальной жизни это все выглядит примерно вот так. это пример из документации Нарса с гитхаба. тут можно увидеть, если это прочитать по-простому, то будет примерно так, что Если ключ находится в зоне доступа, то есть если ключ где-то в зоне предела досягаемости и осуществляется операция поднять ключ, то, вот это другая копула, то ключ окажется взятым. Такое вот нехитрое умозаключение. Эта копула называется копулой предиктивной импликации. Вот она же, это тоже табличка из книги. Смысл ее в том, что если она связывает события А и Б, то это значит, что наступление события А с необходимостью увлечет наступление события Б. Ну, то есть обычная причинно-следственная связь. Есть также копула ретроспективной импликации, она наоборот про то, что если наступило событие Б, значит перед ним с необходимостью было событие А и так далее, тому подобное. Все эти вещи, они достаточно интуитивно понятны, если пытаться чуть-чуть в них въехать. Это все задокументировано и имеет некие программные аналоги в реализациях NARS. Значение истинности — это не менее интересная тема. Вот я собрал такую картинку, что можно по-профански при разработке архитектуры сделать значение истинности у высказываний 0 и 1. Можно чуть-чуть исхитриться сделать их на отрезке от 0 до 1, как в нечеткой логике. NARS делает еще круче. У него значения истины двумерные, и каждое значение находится на отрезке от 0 до 1. что вот эта пара, первое значение в ней называется частотой frequency, а второе – уверенностью, confidence. Смысл в чем? Первое – это примерно вот эта же штука, это то, на какую меру утверждение система считает правдой, А Confidence, если совсем упрощать, это то, насколько система уверена в значении частоты. На примерах, наверное, будет понятнее. Если у нас есть утверждение, что кошки пушистые, то есть все кошки являются пушистыми со значением 1 и 0.9, смысл примерно в том, что Весь жизненный опыт агента показывал ему только пушистых кошек, и этот жизненный опыт достаточно большой, потому что система достаточно сильно в этом уверена. Если мы рассмотрим аналогичное высказывание с значением уверенности 0.5, это просто-напросто покажет, что кошки все были пушистые, но их было меньше на жизненном пути. Высказывание, например, собаки дружелюбные с значением частоты 0.5, с значением уверенности 0.9 будет значить, что примерно, что агент встречал в своей жизни много собак и где-то половина из них кусались, половина нет. Поэтому значение, оно такое, серединка на половинку. Кто-то кусается, кто-то нет, бог его разберет. А вот это утверждение можно распарсить, как вы уже, я думаю, понимаете, просто-напросто, что собака была где-то одна, и она кусалась. Поэтому значение уверенности в том, что собаки дружелюбные – ноль. Уверенность – это маленькое. То есть, если вслед за этим будет встречено агентом несколько подряд дружелюбных собак, оно достаточно быстро изменится. По сути, на практике, чем больше уверенность утверждения, тем меньше новый опыт будет отклонять значение частоты в любую сторону. Смысл уверенности на практике в этом. Вообще, в реальном мире значения утверждений поступают либо на вход, вот это вот так выглядит стандартное значение, потому что по большей части, когда разработчики Нарса рассказывают о нем, они его позиционируют именно как систему рассуждения и ответов на вопросы, несмотря на то, что эта теория должна уметь и целенаправленные действия совершать и так далее. То есть либо это значение подается на входе, его можно задать самому, либо оно будет присвоено по умолчанию, либо оно может быть получено в ходе вывода, потому что, забегая вперед, в целом суть работы NARS в том, чтобы взять две предпосылки, и по различным правилам вывода получить из них что-то третье, четвертое, пятое и так далее. И в зависимости от значения истинности родителей будет значение истинности у потомка. Во всех этих вычислениях используется такое понятие, как расширенные булевые функции. Pivank его тоже позиционирует как оригинальную разработку. Не знаю, насколько это правда. смысл их в том, что это функции, у которых все аргументы определены на отрезке 0.1 и значение тоже находится на отрезке 0.1. Мы недавно в чате рассуждали насчет различных функций, кто читал, тот помнит. Вот, в частности, очень интересно здесь сформулировано «или». То есть, «не» и «и», они достаточно такие тривиальные. То есть, это то, как это, в принципе, оно и представляется. А «или» вот достаточно интересно. Я с таким впервые сталкивался, когда разбирал. Собственно, в NARSIS есть три основных типа предложений. Вообще четыре, но четвертый практически не проработан. Это частный случай третьего. Один мы сейчас как раз разбирали, это суждение, это то, как хранятся знания о мире в системе, это именно то, что можно назвать высказыванием в логике. Кошки являются животными, котята являются кошками и так далее. дверь открыта, ну вы поняли, они помечаются точкой и у них есть вот это значение истинности, о котором мы сейчас говорили. Вопроса нет значения истинности, вопрос описывает кусок информации, которого у системы на данный момент нет, но который ей зачем-то нужен. Либо там извне поступил вопрос, на который надо ответить, либо это нужно для какого-то внутреннего вывода системы. Есть два типа вопроса, селективный, то есть выборочный и оценочный. Селективный ставится так, то есть это вопрос, грубо говоря, что является кошкой, и тогда система среди вот таких высказываний ищет то, у которого значение истинности по какой-то метрике будет оптимальным. И ответом на вопрос, собственно, будет вот, например, вот такое высказывание. Оценочный вопрос, он представляет из себя законченное высказывание, которому нужно, исходя из внутренних знаний системы, присвоить значение истинности. То есть найти что-то соответствующее со значением истинности, и чем больше будет значения уверенности, тем лучше этот ответ будет подходить. И, наконец, есть цель. Она описывает некое желаемое состояние, некое событие, которое агент хочет достичь. У него вместо значения истинности значение желаемости. Оно архитектурно устроено так же, это два циферки от нуля до единицы. В принципе, Пей Ванг в книге это объясняет так, что значение желаемости можно представить как значение истинности, утверждение о том, что из этого события следует событие D, а D — это некая абстрактная сущность, она никак не зафиксирована физически в коде. Это некое виртуальное желаемое состояние. Можно это смотреть как на дезюнкцию всех целей. Дезюнкцию, конюнкцию. При этом, по факту, если разбирать код, оказывается, что это не так важно. Важность цели присваивается также либо на входе, либо выводится, если это какая-то подцель, которая обнаруживается по ходу. Вот, про высказывание, про предложение языка, в общем, рассказал. 

S06 [00:21:17]  : Сейчас надо будет рассказать про… Юрий, пока вы далеко не убежали, тут был вопрос. То есть, уверенность агента всегда базируется только на количестве его опыта, да? У него нет другой меры измерения как-то уверенности? 

S13 [00:21:32]  : в первую очередь она базируется на том, что вошло в систему. То есть, еще раз, значение по умолчанию, оно, если это человек вводит в систему, то по умолчанию присваивается такое значение, либо его можно задать вручную. По факту, сейчас я объясню, По факту, каждое утверждение такого вида в системе может появляться больше, чем один раз и в разное время с разными значениями истинности. И если система обнаруживает, что у нее есть два одинаковых значения в ходе вывода, она их по правилу ревизии объединяет, у них повышается уверенность. Сейчас я могу немножко даже забежать вперед. 

S06 [00:22:14]  : Ну, то есть, другими словами, например, если человек ввел там, что все кошки пушистые, а потом система увидела лысую кошку, то она не будет подходить к первому утверждению как абсолютной данности, а просто их, ну, грубо говоря, средне взвесит, и для нее... у нее нет авторитетов. Я к тому, что опыт, количество штук встречаемости объектов Это главный критерий, а не какие-либо авторитеты или там, я не знаю, источник абсолютно истинный. 

S13 [00:22:44]  : Очень хорошо сформулированный вопрос. В утверждение, в каждое утверждение за счет вот этого двумерного значения заложено то, что можно назвать мерой уверенности. И если система встретила, например, два утверждения с одинаковой уверенностью, одно из которых говорит а, а другое не а, то есть одно говорит кошки пушистые, другое говорит кошки лысые, а уверенность у обоих одинаковая. Тогда результатом ревизии будет 0.5 и еще более увеличенное значение уверенности. Если же человек ввел знание как очень уверенное, а потом система встретила одну лысую кошку, то есть один кейс, то значение будет уменьшено, то есть с единички вниз. Но в силу того, что у введенного, например, было confidence 0.9, а у случайно встреченного факта, если я правильно помню, 0.45 там получается, то оно отклонится не так сильно. Вот. То есть все зависит и от количества, и от качества evidence. 

S06 [00:23:54]  : Спасибо, едем дальше. 

S13 [00:23:56]  : Ответ понятен, я надеюсь? 

S06 [00:23:58]  : Да. 

S13 [00:23:59]  : Ага. Вот. Так, теперь сейчас про то, как данные хранятся в системе, потом только можно будет рассказать про общую архитектуру. Мешок, так называемый, по-английски bag, это структура данных, которую Пейванг тоже говорит как про авторскую, хотя это вот из тех вещей, которые, когда читаешь, думаешь, что, ну, а почему не я придумал? То есть, ну, идея в целом звучит очень логично. Наверное, я подозреваю, что кто-то еще ее делал. Суть в чем, что это некое неупорядоченное множество, ну, то есть вот как в математическом смысле set, которое поддерживает три операции. Это операция... а, множество ограничено по количеству предметов в нем. Это операция положить в него, добавить какой-то объект. Это операция достать конкретный объект из мешка. И третья операция, самая важная, это достать некоторый объект. Идея в чем? Что у каждого объекта в мешке есть так называемое значение приоритета. Это чиселка тоже от нуля до единицы. И, грубо говоря, если у нас есть в мешке два предмета, и у одного из них значение приоритета в три раза больше, чем у другого, то вероятность достать – это вероятностная операция – у первого предмета будет в три раза больше, чем у второго. То есть сколько бы там предметов ни лежало, у каждого есть значение приоритета, и вероятность случайным образом достать один из них пропорционально значению приоритета. Это очень важная структура. На ней, в принципе, в Нарсе основано практически все. У каждого кусочка информации в системе практически есть так называемое значение бюджета. Оно состоит уже из трех величин от нуля до единички. Это приоритет, долговечность и качество. Priority, durability, quality. И каждый раз, когда вот этот кусочек информации оказывается в работе, его значение, то есть когда его, например, достали, вернули, достали, вернули, каждый раз это значение обновляется, происходит процесс, который можно назвать забыванием. И значение p, которое имеется, пересчитывается по такой формуле, то есть оно умножается на d, так как d меньше единички, p тоже уменьшается. Если оно не достигло нижнего значения, за которое отвечает качество, а если p уже равно q, то оно не забывается меньше, чем какое-то значение его важности. Нужно ли говорить, что именно p является тем самым приоритетом? Собственно, в соответствии со значением P предметы хранятся в мешке по порядку. Да, важный момент насчет мешка. Если в мешок кладется вещь, а в нем уже в нем уже достигнуто максимальное количество предметов, то удаляется предмет с наименьшим приоритетом. То есть это в целом можно провести аналогию с мозгом, что самые слабые, самые тонкие и редко используемые нейронные связи в какой-то момент умирают. Это, казалось бы, небольшая деталь, но на ней практически вся система стоит. вот теперь мы наконец подобрались к архитектуре сейчас будет наверное самое страшное потом вроде должно быть чуть попроще вот это понятие концепции это то из чего состоит архитектура одна концепция составляет соответствует одному терму то есть вот, например, схема, вот это вот, это все концепции, то есть есть концепция животная, концепция птицы является животным, концепция птица и так далее. Каждому терму, для каждого терма, который поступает в систему, заводится концепцию, но при этом концепции хранятся в мешке, то есть главная структура данных NARSI это один большой мешок с концепциями. могут существовать термы, которые ссылаются на уже забытые концепции, потому что, как и любой мешок, он подчиняется вот этому закону удаления наименьшего. Но в целом каждый концепт он снабжен одним и ровно одним термом. Что есть в концепте? В нем есть мешок ссылок на так называемые задачи. Это, в принципе, тоже ссылки на концепты. Вот здесь эти ссылки показаны красным на схеме. Например, на task, на задачу, ворон является птицей, ссылаются концепты ворон, птица. Ворон является птицей. Это одноименный концепт. Есть ссылки на термы. Это ссылки, которые связывают концепции между собой. Вот у меня тут была схема. То есть вот у нас мешок с концепциями, и они связаны между собой как раз тасклинками и термлинками. При этом термлинки двунаправленные. то есть концепт, например, вороны и птицы связан с концептом вороны, а концепт вороны связан с концептом вороны и птицы. Также в концепте присутствует таблица убеждений, это сводный список тех утверждений. Сводный список появлений вот этого терма в системе, одноименного. Как я уже сказал, один терм может присутствовать в системе в нескольких вариантах. Это сводный список с разными значениями истинности и с тем, когда это появилось. И есть таблица целей. Это тоже список, когда этот концепт в результате вывода оказывался целью этого события. Как вы понимаете, если речь идет про атомарный терм, например, животное, то у него нет ни таблицы убеждений, ни таблицы целей, потому что у нас нет высказывания «животное» в системе. Это атомарный терм. Да, вот еще раз, так это примерно все выглядит. Собственно, в чем заключается рабочий цикл системы? Это, если по-разному считать, это 5 или 6 шагов. Суть в чем? Первый шаг – эта система вероятностно достает из мешка концепций одну из концепций, Как вы поняли, у них тоже есть свое значение приоритета, у каждой. Система достает из мешка концепцию, потом из мешков с тасклинками и термлинками по очереди достаются тасклинк, то есть ссылка на задачу, и термлинк, ссылка на терм. и то и другое в целом, в некотором роде ссылка на концепцию. Таким образом, у нас получаются две предпосылки для вывода, после чего к ним применяются правила вывода, те, которые можно применить к этим концептам. Там идет большой поиск по дереву. Я уже говорил, что около 200 правил переванг насчитывает в актуальных версиях. То есть, в зависимости от того, что из себя представляют концепции, которые являются предпосылками, применяются возможные правила. И в зависимости от того, всем возможным результатам, которые получаются при этом выводе, присваиваются значения истинности, значения бюджета и так далее. То есть, они отсеиваются по качеству. И те из них, которые проходят некоторую планку, которые оказывается система считает достаточно ценными, они заносятся на обработку. после чего системе остается только положить предпосылки, которые были взяты из мешков, обратно в мешки. То есть вернуть тасклинг в мешок, вернуть термлинг в мешок и вернуть в мешок концепцию. При этом происходит тот шаг, о котором я говорил, что если мешок уже переполнен к этому моменту, то что-то из него выбрасывается. А те задачи, то есть те результаты вывода, которые попали в буфер, обрабатываются. Там происходит В зависимости от типа высказывания они обрабатываются по-разному. Если речь идет про суждение, то оно преобразуется в убеждения, в те самые beliefs, которые находятся в таблицах. Ему тоже заводится свой концепт, свое значение истинности. Если это вопрос, система сразу пытается на него ответить в каком-либо варианте, находит какой-то лучший ответ и его заносит. Если это цель, система оценивает, стоит ли ее достигать прямо сейчас. Если да, то она принимается в работу как одна из целей, потому что NARS вообще допускает возможность обработки многих целей одновременно. именно целей, как неких событий, которые он пытается достичь. Так, через архитектуру пробежали. Вот это слайд из моего диплома. Тут описано, это нам менее интересно, но конкретно целенаправленное поведение в NARS как некое решение практических задач. Вот тут я могу попытаться его рассказать. Это запись на таком псевдонарсизе, достаточно упрощенная. В общем, как это примерно работает. Давайте допустим, что у системы есть цель Ж. То есть система хочет достичь некой цели Ж. Также у системы есть знание о том, что, совершая действие А, можно достичь цели Ж. то есть с каким-то значением уверенности вот это соответствует одному успешному опыту. Система в общем допускает, что действие А может привести к результату Ж. Если мы берем вот эти две предпосылки, то да, я сразу говорю, что этот вывод достаточно условный в том плане, что мы вручную скармливаем предпосылки каждый раз. Как вы уже поняли, в общем случае это происходит вероятностно, то есть это всего лишь один из возможных выводов. В общем, если у нас есть цель «Ж» и знание о том, что действие «А» достигает цели «Ж», система может из этого… Если при таких двух предпосылках система сначала задает вопрос, достигнут ли «Ж» на данный момент, это связано как раз с тем, что система может достигать нескольких целей одновременно и, может быть, делая что-то другое, она случайно оказалась в ситуации, когда «Ж» уже достигнут. Нет смысла прилагать крепкого усилия. Если же вопрос задан и из своих знаний система извлекает, что цель G на данный момент не достигнута, то из этих двух предпосылок делается следующий вывод. У нас есть цель G, действие A поможет нам ее достичь. Значит, что? Значит, наша цель — совершить действие A. Вот это значение, оно получено при помощи правила дедукции. вот по таким формулам, то есть частота пересчитывается в зависимости от частоты родителей и уверенность пересчитывается в зависимости от f1, f2, c1, c2 тоже у родителей. Это вот из этих чиселок получаются вот эти. Так вот, когда система приняла в работу, что ее новой целью является совершить действие А, Поскольку действие А является операцией, а операция – это такое событие, которое система может по щелчку пальцев сделать реальностью, то есть поднять руку, открыть дверь и так далее. Поскольку это является операцией, система сразу его выполняет. И как только система его выполнила, она, ну, если я поднял руку, я знаю, что моя рука поднята. Соответственно, система принимает совершенные события в момент времени как некую данность. То есть это становится высказыванием. Не целью АУЖа, а высказыванием. у нас есть, то есть мы получили, в общем, у нас есть совершенное действие А, у нас есть также совершенное действие, то есть знание о том, что Действие A влечет в достижение цели G, поэтому система на основе этих двух предпосылок делает вывод о том, что если событие A влечет в наступление G, и событие A совершено, значит, наверное, G тоже совершено. таким образом вот это, то есть система не получила знания из внешнего мира еще о том, что уже достигнуто, но она уже это прогнозирует. то есть эта функция прогноза, она здесь реализована таким образом. 

S06 [00:36:54]  : но прогнозируется с низкой вероятностью 0,4. да, с низкой уверенностью. да, все верно. 

S13 [00:37:02]  : Вот это как раз про то, про что я говорил, про то, что одно и то же событие может существовать в нескольких экземплярах с разными временными штампами. Это событие G, которое, предположим, поступило из внешнего мира, то есть система совершила действие, начала слушать реальность и узнала, да, G достигнуто. И у нас совпадает, и у нас вот это значение, это вот это вот, которое было получено благодаря прогнозу. Система обнаруживает, что у нее есть два дубля с непересекающимся, как это называется, evidence set, то есть доказательной базой, после чего по правилу ревизии, вот тут формула, она как раз про то, чтобы объединять два утверждения. Система получает из этих двух значений, из этих двух утверждений новое утверждение с более высоким значением уверенности. Тут понятно. Вот сейчас интересный шаг, на котором я скажу чуть позже, чуть подробнее. Система совершила действие А в один момент времени. Чуть позже система получила знание о том, что достигнуто Ж. что наступило событие G, то есть если говорить в терминах события, наступило событие A, наступило событие G. Если два таких события поступили как премиссы, как предпосылки, что делает система? Система говорит, ага, событие A вызывает событие G, и все. это типичная индукция, то есть с точки зрения индукции после значит следствие, и тут благоразумно пейванг учел, что сколь высокими не были уверенности двух предпосылок, индукция это такой достаточно слабый логический вывод, поэтому тут уверенность падает. в соответствии вот с этой формулой. то есть частота понятна, а тут у нас через конъюнкцию. вот. и, соответственно, у нас было знание, что иза следует же. мы получили такое же индуктивное знание, что иза следует же. они по правилу все той же самой ревизии объединяются вот таким образом. тут значение уверенности немножко подрастает. Глядя на этот вывод, что можно заметить? Во-первых, как я уже сказал, в нем опущен момент о том, что всегда это вероятность, и вот такой строгий, четкий и последовательный логический вывод будет, ну, как минимум, не подряд в системе, скорее всего, поскольку все операции выполняются плюс-минус за константное время. Это очень сильная сторона системы на самом деле. Она вся построена на экономичности. Наверное, шанс того, что то есть в одну секунду будет исполняться много-много таких одинаковых тактов и в каком-то варианте подобный вывод будет произведен, наверное, этот шанс есть. Но, опять же, все зависит от ряда параметров. Ну, то, что система может преследовать одновременно несколько целей, это я уже говорил. И тут момент такой, что одна цель порождает там подцели в разных вариантах. Опять же, человек может что-то ввести. Опять же, как задачи система рассматривает, в том числе какие-то просто высказывания, из которых можно произвести высказывания, произвести другие высказывания. Вот тут есть момент, что любой концепт практически системой рассматривается как задача. То есть, если это просто высказывание, если у него высокий приоритет, высокое значение бюджета, система рассматривает его как ага, это важно, надо посмотреть, какой логический вывод из этого высказывания можно сделать, соответственно, если сопоставить его с другими. То есть, чем больше таких целей, тем больше система может распыляться. и не преследовать одну и ту же цель постоянно и уверенно, как это сделано в той же теории функциональных систем. И самый значимый момент, один большой подводный камень – это то, что причинно-следственные связи формируются в системе практически всегда именно индуктивно. Для того, чтобы система поняла, что событие A влечет в наступление G, ей нужно один раз на это натолкнуться, второй раз натолкнуться, произвести ревизию, третий раз натолкнуться, произвести ревизию. То есть тут очень плохо с целенаправленностью. Тем более, если мы рассуждаем о том, что в потенции это может стать каким-то AGI, то у AGI на вход будет выступать одновременно огромный поток разных событий, то есть то, что можно назвать событиями. И очень большой шанс, что система будет постоянно связывать два неважных события, например, вот то, что я сегодня вам докладываю, у меня за окном едет трактор. Причинно-следственной связи нет, но NARS бы вполне легко вывел. И чем больше этот поток, тем сложнее будет в нем вычленять действительно существующие вещи, действительно существующие причинно-следственные связи без какой-то предпосылки. Для сравнения объясню, что в теории функциональных систем, если обнаружена какая-то закономерность, то дальнейшие действия всегда идет от того, что мы берем это правило, в котором уже есть какая-то минимальная уверенность, пробуем его на зубок. Мы его применяем и смотрим, изменил какой результат. Если он совпадает с ожиданием, оценка правила увеличивается. Если не совпадает, то она штрафуется. Если правило оказывается непригодным, оно умирает в какой-то момент. Здесь же нет такого понятия, как проверка гипотезы. Здесь это работает так, что один раз совершил, обнаружил причинно-следственную связь, жди пока совершится еще раз. Если будет поставлена эта цель, будет обнаружено самое статистическое, вот это устойчивое правило, но его еще надо таким долгим образом как-то обнаружить. И вот эта вещь, она очень заставляет думать, сомневаться вообще в том, насколько она расприменима именно в каких-то реальных задачах, впрочем, а какая когнитивная архитектура на данный момент готова к реальным задачам. Вот, у меня на этом по основной части доклада все. Я буду рад ответить на какие-то вопросы или обсудить. 

S14 [00:43:25]  : Спасибо. 

S06 [00:43:28]  : Спасибо огромное, Юрий, но как-то мне кажется немножко не хватает чего-то, ну хотя бы, допустим, на примере какой-нибудь демы или своими словами расскажите, ну какие вот там применения, ну хотя бы какие демы есть этой системы, что она делает полезного? 

S13 [00:43:53]  : Что она делает полезного, я бы знал. Я могу сейчас легким движением руки заползти на YouTube. Там есть полторы демки. В частности, сейчас они показывали предсказательную модель, которая, как бы, должна в теории изображать... мы рассматриваем там... демка в том, что есть модель пешеходного перехода, там, автопешеходного, и по ней ходят агенты, и NARS учится предсказывать, где какой человек в какой момент окажется. 

S12 [00:44:28]  : сейчас я попробую найти. 

S13 [00:44:31]  : то есть вот это в принципе один из наиболее наглядных результатов на данный момент из того, что есть, то есть вот есть модель пешеходного перехода, вот по ней вмечутся точки, и вот полупрозрачные, то есть точечки, снабженные цифрами, полупрозрачными, показано, как система думает, где они будут находиться в момент времени. То есть сначала это какая-то хаотичная оценка, а потом оно начинает уже вот более-менее консистентно предсказывать. Не идеально тоже, но в целом, ну, похоже на правду. Меня очень огорчило то, что на гитхабе у них в одном из списков есть, в списках демок есть то, что, ну, то, как Нарс проходит Марио, вот классическую игру, но ни видео, ничего я не смог найти, и сейчас у них эта демка указана как деплокейтед. 

S14 [00:45:38]  : И вот это меня очень огорчило. 

S13 [00:45:39]  : Ну, и в Pong он играет, кстати, да. 

S06 [00:45:41]  : Указано как что? 

S13 [00:45:43]  : Ну, устаревшее, неактуальное. Ссылок на видео нет, ни на что нет. 

S06 [00:45:48]  : в данном случае вот это видео которое вы сейчас показываете грубо говоря, там положение агентов, все конвертируются в некие утверждения для этой системы NARS. 

S13 [00:45:59]  : Это не агенты, это, ну то есть, агент, все-таки давайте придерживаться терминологии, NARS, его задача в том, чтобы оценивать кружочки. Вот, а кружочки это, ну, просто какие-то скриптовые. 

S06 [00:46:10]  : Ну, хорошо, какие-то скриптовые кружочки, но они не зависят от этого NARS никак. Да-да-да. Он получает на вход условно координаты там этих кружочков, по их траектории мобы и позиции там скорости этих кружочков для него являются входными утверждениями и он на базе истории таких утверждений пытается делать как бы суждение о том что дальше предпримет этот кружочек то есть куда какая его там координата и скорость будет дальше вот такая я это понял именно так но это понятно с точки зрения вот такого применения этого наш сюда это наверное вполне возможно и понятно но кто-то должен эти кружочки у него на входе идет как бы очень чистый вход То есть это уже, как бы это сказать, оцифрованная качественная информация. Не картинка, а просто, как бы, координаты, даже еще не координаты, а просто переведенные, я так понимаю, уже в языке его суждений. То есть кто-то это должен был сделать. 

S13 [00:47:21]  : я предполагаю, что да, вон там слева идут логи, собственно, но это грешок, который есть, в принципе, плюс-минус у всех систем. 

S06 [00:47:30]  : Ну, это не грешок, это как бы особенность, которая сильно ограничивает ее применимость. Хорошо, окей, ну, по крайней мере, одно демо понятно. В Mario он тоже играл, да? 

S14 [00:47:46]  : Говорят, играл, никто не видел. 

S09 [00:47:49]  : Ну, я не знаю, может быть всем понятно. Какая это оценка? Насколько хорошо он делает? Какие-то кружечки бегают туда-сюда. Можем ли мы понять, хорошо это или плохо? 

S14 [00:48:02]  : Это большой вопрос. 

S09 [00:48:06]  : Вот и у меня такое впечатление. 

S13 [00:48:09]  : Собственно, есть такой момент, что у меня изначально с задачей дипломной работы мы планировали провести какой-то эксперимент по сравнению той же самой теории функциональной системы Нарса, но просто к моменту завершения работ с Нарсом столкнулись с тем, что придумать какой-то эксперимент, который будет когерентен обеим системам, в котором еще и метрика будет успеха нормальная, чтобы там еще и ввод-вывод был адекватный, но это очень проблематично. Как минимум, много ручной работы. Есть планы все-таки это сделать, попытаться, особенно при содействии американско-китайских коллег, но этот вопрос, который задали, он действительно очень актуальный. 

S06 [00:48:58]  : Да, вопрос хороший, правда. Так, давайте у нас есть несколько вопросов в чате, давайте их попробуем, а потом посмотрим, куда дальше. вырулиться. По поводу связи между количеством опыта и уверенностью мы спрашивали. Сергей Терехов спрашивает, уверенность, которая у утверждений есть, 0.9 или 0.5, это уверенность системы или уверенность поставщика данных? 

S13 [00:49:30]  : Ответ – да. Если поставщик данных подает эти данные в таком виде, то есть человек, учитель, то система принимает это на веру. Но аналогичная оценка, как вы видели в процессе разного вывода, она может получаться… Давайте я сейчас верну презентацию. Она может и естественным путем получаться, то есть система выводит в зависимости от родительских утверждений какие-то дочерние утверждения, и у них эти значения по-разному скачут. Ну, соответственно, еще раз говорю, что если мы берем некое значение по умолчанию, то оно равно 1.09. по задумке архитектора. 

S06 [00:50:15]  : Да, понятно. Но в каком-то смысле это получается такая очень по-человечески система. Человек ведь тоже также оценивает исходя из своего входящего опыта. Если он видел только белых лебедей, он склонен думать, что все лебеди белые. Пока не увидит черного, он будет уверен, что все лебеди белые. Чем больше он их видел, тем больше он будет в этом уверен. Это, в общем, похоже очень на человеческую логику. 

S13 [00:50:39]  : Ничто человеческое системе не чуждо. Кстати, по поводу человечности я, наверное, добавлю. Такая интересная сторона НАРСа в том, что разработчики не педалируют то, что должен быть в итоге какой-то там супер НАРС 1.0, который будет объявлен золотым стандартом. Есть множество параметров системных, которые могут варьироваться от системы к системе и, как это сам формулирует Иван в книгах, что Система, в зависимости от настройки ряда параметров, может обладать некой личностью. Она будет либо более открыта к новым знаниям, либо, наоборот, более консервативна в своих убеждениях. И в зависимости от этого она может больше или меньше подходить под разные задачи. Опять же, в своих «Розово-голубых мечтах» Эпи Иванг описывает Большое количество НАРС-агентов, которые могут взаимодействовать друг с другом, обмениваться опытом, имея при этом разные личности и, соответственно, решая разные задачи. Такая мысль тоже есть. Это про человечность. 

S06 [00:51:43]  : Отлично. Дальше. Был вопрос по поводу концепта. То, что вы описывали, концепт термы. Концепт это некий автомат над термом или скорее оператор? 

S13 [00:52:02]  : концепт — это структура данных, которая, я боюсь соврать, ну в условиях, которая имеет некое соответствие, то есть каждому концепту соответствует ровно один терм, при этом существуют термы без концепта. 

S06 [00:52:24]  : У меня ощущение такое, что НАРС все-таки является как бы автоматом над этими терминами. Он как бы исполняет, как система как бы исполняет эти термы, подтягивает и концепции точнее исполняет. 

S13 [00:52:39]  : Он исполняет, еще раз, он берет за один шаг он берет по два концепта как предпосылки, и из них порождает некие новые утверждения, которые тоже при успешном прохождении отбора становятся концептами. Постоянно появляются новые концепты, исчезают концепты, и вывод производится на их основе. 

S06 [00:53:03]  : в этом смысле реактивен. то есть, если, грубо говоря, у него закончились там цели в мешке, то он просто молчит и ждет там чего-то нового. 

S13 [00:53:13]  : они не могут закончиться, потому что inference, он работает по принципу лучшее, что есть, берем. то есть, если есть два концепта, если есть в нем минимум два концепта, то все это уже не остановить. что кролики занимают весь весь свободный вот этот загон и самые жизнеспособные порождают новых кроликов. 

S06 [00:53:35]  : понятно то есть как какую бы глупость не сказать системе она будет думать про нее вечно. 

S13 [00:53:41]  : если они там хоть как-то минимально связаны между собой то есть там есть общий терм например. 

S06 [00:53:47]  : две глупости. 

S13 [00:53:49]  : если хотя бы два кролика способные к размножению есть то все. 

S06 [00:53:53]  : ясно но был вопрос как в нас вести терм некоторые кошки пушистые можно сейчас я ну это терм некоторые кошки пушистые это терм все кошки пушистые с низким значением ну вот я так примерно ответил в чате да Евгений Бабариков спрашивает, глядя на эту формальную грамматику, можно ли назвать НАРС предметно-ориентированным языком? 

S14 [00:54:24]  : Что такое предметно-ориентированное? 

S06 [00:54:35]  : Это, видимо, исправление. 

S14 [00:54:38]  : Ну, предположить, что да. Я просто не знаком с определением, особенно с конкретным. Можно пояснить в чате либо голосом. 

S06 [00:54:52]  : Евгений, пояснишь голосом, если ты здесь? Видимо, не здесь. Ну ладно. У Сергея Терехова вопрос в чате. Такое эмпирическое тестирование правил не является качественным отличием от усиления ассоциации корреляции. Это не то что вопрос, а скорее комментарий. 

S14 [00:55:20]  : Знать бы, что такое усиление ассоциации, каким определением пользуется Сергей. 

S06 [00:55:23]  : Я тоже не очень понял. 

S14 [00:55:25]  : Может нет разницы. 

S10 [00:55:28]  : Я могу уточнить, если дадите вопрос. 

S06 [00:55:30]  : Да, Сергей. 

S10 [00:55:31]  : Ну, смотрите, вы фактически что делаете? Вы применяете какое-то A, потом что-то в системе происходит, и вдруг почему-то оказалось G. Это G там оказалось по тысяче разных причин, которые могут быть не связаны с A. Но вы, тем не менее, с каким-то маленьким уровнем эту ассоциацию назначаете. И дальше вот эти ассоциации есть. Те, которые из них сохраняются, еще раз потом появилось G, когда появилось A, они, так сказать, немножко усиливаются. Теперь вы говорите, что это на самом деле слабость системы, а вот в системе, в ТФС теорию, там более глубокая проверка. Но там глубокая проверка, она все равно на самом деле глубокая лишь до определенной степени. То есть просто пока вы не смогли опровергнуть того, что факт ассоциативный, а не причинно-следственный, это все равно конечная-конечная вещь. То есть обе системы имеют просто... одна более слабая, а другая более сильный механизм усиления ассоциаций, который, как известно, пагубный, потому что именно он и приводит к тому, что там реальная система искусственного интеллекта не работает. 

S13 [00:56:32]  : Спасибо. Я понял мысль, но начнем с того, что причинно-следственных связей в принципе не существует и опровергнуть их в принципе невозможно. 

S10 [00:56:43]  : Это мнение, утверждение или теорема, что это? 

S13 [00:56:48]  : это система понятий, которой я пользуюсь. Чем мне больше нравится теория функциональных систем, это то, что там вот такие закономерности. Не знаю, кто знаком, наверное, в курсе, что как это все работает. Там сначала агент совершает при отсутствии опыта просто какой-то набор случайных действий. обнаруживает какие-то, ну, нарабатывает себе какую-то историю, после чего вот такого рода правила, они обнаруживаются и на основе анализа всей истории и выявляются на основе статистики. Там используется точный тест Фишера из Матстата. И, то есть, как бы причина-следственная связь, она все еще не доказана, но 

S10 [00:57:38]  : некое статистическое утверждение некий критерий показывает что она не просто не доказано у нее нет шансов в рамках такой системы быть доказано вот это очень принципиально понимаете у нее нету даже потенции в конце концов превратиться под причину следственную связь вы можете ассоциативную связь это ассоциативная связь а небо гроза гроза и молния вы можете усиливать до одурения и можете даже сделать какую-то систему, которая будет работать с этими ассоциативными связями, но у них нет шанса превратиться в логические связи, то есть сложную задачу вы решить таким образом не сможете. Там у меня дальше есть следующий вопрос, касающийся глубины возможных обсуждений. 

S06 [00:58:17]  : Это верно, Сергей, но у меня такое ощущение, что этот НАРС, он скорее как экспертная система работает с некой вероятностью и просто действительно, но то, что correlation does not mean causation, этого он как бы не понимает. А тогда, Игорь, что мы от нее можем взять? 

S10 [00:58:35]  : Мы ее только как в музей можем поместить. Можно докладчику вставить. 

S13 [00:58:41]  : Насчет correlation causation все правильно. Добавлю, что NARS, как экспертная система, как правило на конференциях его так и преподносят. Про часть с целенаправленным поведением куда более скромно обычно говорят. Но я возвращаю вас к началу доклада, что PayWang осознанно выбирает именно statement-based подход, в котором нет каких-то четких логических связей, потому что как только мы берем state-based подход, где есть некая система, в которой работают какие-то аксиомы, то есть реальный мир с какими-то законами, возникает вопрос, а как, ну то есть возникает проблема фрейма, а как эти аксиомы определить, как их набор составить. и на этом как бы тоже можно увязнуть не меньше, чем на разнице между correlation и causation. 

S14 [00:59:28]  : вот, спасибо. 

S06 [00:59:30]  : ну окей ну давайте считать что систему иметь такие плюсы и минусы это просто не спасибо большое извините вынужден бежать Юрий огромное спасибо за доклад я прошу прощения. 

S13 [00:59:39]  : Спасибо за интересную полемику. 

S06 [00:59:42]  : Так вот есть комментарий у Игоря он поднял руку давайте короткий комментарий. 

S08 [00:59:50]  : Ну минутки на две. Я бы хотел немного покритиковать вероятностные структуры со своей колокольни. Я считаю, что вероятностные структуры и характеристики – это способ работы с уже выявленными неопределенностями в наших входных данных. Но это не значит, что наши данные, с которыми мы работаем, являются неопределёнными. То есть в презентации было такое хорошее сочетание как insufficient knowledge. Недостаточные знания вытекают из реального мира, и в некоторой мере это и мотивирует нас получать больше знаний. Но это не означает, что в нашем реальном мире этих данных недостаточно. Когда мы работаем с предоставленными данными и датасетами, то скорее всего у них уже неопределенности нет как таковой. Неопределенность у них может быть только если у нас есть абсолютно идентичные инпуты и у них разные аутпуты, что опять же для большинства датасетов не так. Неопределенность в реальном мире возникает лишь в случае упрощения данных. В презентации там были показаны иерархии разного типа, ворон – это птица и тому подобное. И этому приписываем какую-то вероятную характеристику. Если переложить это на реальные данные, то мы видим некоторых птиц разного вида, у которых там может быть разный цвет, разный размер крыльев и тому подобное. Есть какие-то общие характеристики, и поэтому мы этим общим характеристикам приписываем ярлык птицы. Но это не означает, что эти характеристики, которые мы упростили для создания ярлыка птицы, не существуют. И это также не означает, что характеристики могут с некоторой вероятностью соответствовать птице. Это просто означает, что характеристики, которые мы упростили, не важны нам для создания и описания птицы. Но когда нам эти характеристики становятся важными для принятия какого-то решения, то мы обращаемся обратно к нашей входной информации, например, к фотографии птицы, и уже смотрим на те данные, которые говорят нам, какая именно эта птица. То есть как таковых вероятностных характеристик в наших входных данных нет. И нет как таковых неопределенностей. Но они могут появиться, когда мы эти данные упрощаем или, к примеру, когда этих данных попросту нет. Например, фотография взята с плохого ракурса. И тогда нам определенность говорит, скорее всего, о том, что нам надо получить больше данных, так как для текущих данных мы можем дать лишь вероятностную характеристику, потому что раньше мы встречались с какими-то неопределенностями, которые давали нам и один откут, и другой. ну и опять же, если мы эти данные получить больше не можем, то это окей. если этих данных нет, то мы можем так работать с неопределенностями. но закладывать изначально эту архитектуру, с моей стороны, это не окей, потому что тогда она будет пытаться увеличивать вероятность, а не пытаться находить реальную закономерность. Юрий? 

S14 [01:02:34]  : Спасибо. 

S13 [01:02:35]  : Я очень боялся, что в конце вопрос будет, потому что высокий темп, большая сложность. Но я отдельные мысли уловил, ну то есть общее совсем направление уловил. Будет интересно над этим подумать. Но на данный момент у меня нет ощущения, что в случае плохих данных, условно говоря, NARS придет к Мне кажется, что он не будет нагонять что-то, увеличивать вероятность оценки своих утверждений. Наверное, если они были плохенькие, они плохенькие и будут. Теория функциональных систем, в свою очередь, там это работает так, что если вообще ничего не проходит тест Фишера, то система просто продолжает ориентировочную исследовательскую реакцию и ищет. Продолжает искать, пока не находит какие-то действительно результативные вещи, правила и так далее. 

S14 [01:03:36]  : И в целом, в частности с житировочной исторической реакцией у меня есть некоторые мысли, как это все можно улучшить. 

S12 [01:03:42]  : Спасибо. 

S06 [01:03:42]  : Окей, да. Я бы подискутировал с Игорем, потому что мне кажется, что вообще вся наша природа знаний о мире, она вероятна с ним. И у нас нет достоверно стопроцентных знаний, так уж по сути ни о чем. Мы люди, мы привыкли мы привыкли преподносить их как стопроцентное знание, но опять-таки это базируется на нашем опыте, если я скажу, что вот дом стоит и он тут стоит как бы вечно, но на горизонте там 40 лет или там 80 лет окажется, что он там, что его снесли или там что-то, то есть Реально в этом мире все вероятностно. Вопрос длительности процессов и нашего наблюдения за этим процессом и проявления этой вероятностной природы. Мне кажется, что замысел как раз интересный у системы в этом плане. все утверждения сразу считать с некоторой вероятностью и дальше оперировать. Мне кажется, даже наоборот, людям было бы полезно осознавать, что мы на самом деле оперируем не как бы не не утверждением типа 0 1, а на самом деле вероятностными утверждениями, но иногда нам кажется, что они какие-то прям стопроцентные, а нам бы хорошо понимать, что они вот не стопроцентные, у всего есть исключения, всегда есть черные лебеди. 

S08 [01:05:11]  : Ну, Лассен, это в том плане, что мы как бы пришли к этому как способ работы со сложным миром, в котором мы никогда точно не знаем, правильно ли мы выявили закономерность. Если брать обратно тех же лебедей, мы всегда видели белых лебедей, и все, у нас как бы стопроцентная гипотеза, что все лебеди белые, потому что у нас просто нет данных, на основании которых мы можем предполагать другое. Но как только мы увидели черного лебедя, мы не можем говорить, что все лебеди белые. Мы можем говорить, если какой-то человек сказал «я увидел лебедя», мы можем ему сказать «а, ну 99% это белый», потому что как бы Из 100 случаев в 99 мы видели белый, но мы также можем предполагать, что это черный, но это как бы не значит... То есть, если нам эта информация важна, белый этот лебедь или черный для какого-то нашего действия, то мы как бы это обязательно уточним, и мы как бы... 

S06 [01:06:06]  : Верно, Игорь. Проблема в том, что большинство людей не уточняет. Если вы видели всю жизнь белых лебедей, и вам Юрий скажет, а вот есть черные лебеди где-то, вы скажете, да я не верю, не может этого быть. Но большинство людей скажет, не вы, а там. подавляющее большинство, потому что оно не привыкло мысли в терминах вероятности. Ладно, слушайте, мы... Это как бы офф-топик, на самом деле, для Нарсса. Мы же про Нарсс все-таки. Так что давайте мы будем дальше про Нарсс. Вот там я вижу рука у Евгения Евгеньевича. У нас там еще есть несколько вопросов. Вопрос есть, почему до сих пор нет чат-бота на Нарссе? Казалось бы, ну... 

S13 [01:06:45]  : Мне кажется, что если с целенаправленным поведением уже непросто, то тут... Чат-блог же, по сути, на мой взгляд, сейчас просто рассуждаю, что построение речи — это, по сути, большое количество последовательных действий, которые должны быть еще и между собой связаны. когерентно. То есть там, ну, каждый там, не знаю, можно разбить это на сказать слово. Ну, и вот из этих слов надо собрать предложение. Ну, и как бы, учитывая то, что у нас NARS, он в принципе даже... ему сфокусироваться трудно на одной задаче. Мне кажется, что это... не вижу, как это с кондачка можно решить таким образом. Но вопросы, типа, как это... вопрос интересный, интересно будет над ним подумать. 

S06 [01:07:34]  : Так, но вот тут Антон Колонин набросал в чат еще какое-то количество разных примеров, но Виктор Казавинов спрашивает, может быть я прослушал, но на каких именно задачах вы тестировали NARS? 

S14 [01:07:49]  : Я его не тестировал именно в коде. Я по сути сделал только такой анализ извне. Есть планы, но мы пока не реализовывали. 

S06 [01:08:06]  : Окей, тогда можно ограничиться теми примерами, которые здесь в чате есть. От Владимира Смолина вопрос. Есть ли какие-либо оценки соотношений между ростом сложности задач и ростом сложности системы НАРС, их решающей? рост сложности системы чем сложнее задача тем как бы нарастает этот нас как снежный ком все эти там концепты мешки в общем соотношение как любая система экспертная она начинает там ну там экспоненциальный или там квадратичный степень но как-то по отношению к задаче. 

S13 [01:08:47]  : Скажем так, я не очень понял, я могу это переформулировать, то есть я не очень понял именно, что имелось в виду в изначальной формулировке вопроса. Я бы, наверное, задал его так, что Есть ли оценки, которые сравнивают сложность задачи и тот, скажем так, объем НАРСа? Я еще раз акцентирую внимание на том, что НАРС экономичный и параметризуемый, то есть можно его сделать так, чтобы он работал с оперативной памятью 1 мегабайт и делал все, что в рамках него возможно, и можно сделать его с оперативной памятью 1 гигабайт. то есть он пользуется теми ресурсами, которые ему уделяют. И корректный, наверное, вопрос был бы сопоставить сложность задачи и те ресурсы, которые нужны Нарсу для того, чтобы стать эффективным, но, повторюсь, с оценками, с примерами, экспериментами на данный момент, я не думаю, что это будет эффективно. Я думаю, что это будет эффективно. немножко не завезли. 

S06 [01:09:49]  : Ну хорошо. У Терехова был интересный вопрос, но он убежал уже. Какова степень глубины рассуждений? Реальная. Не получается ли так, что цепочка из трех-пяти правил приведет к умолчательному состоянию типа 0.5.0.5? 

S14 [01:10:08]  : 0,5-0,9. 

S06 [01:10:09]  : 0,5-0,5. 

S14 [01:10:09]  : Ну, я имею ввиду, что... Ну, может быть, 0,5-0,9. 

S13 [01:10:15]  : Какова степень глубины рассуждений? 

S06 [01:10:18]  : То есть, другими словами, если мы начинаем наслаивать одни концепты на другие, они начинают друг из друга все выводить, то со временем из-за всей этой пересчитывания математики, грубо говоря, все может свестись к какому-то банальному... Я понял, я понял. 

S13 [01:10:33]  : Это зависит от того, какие правила система берет как предпосылки, то есть есть сильный вывод, есть сильный дедуктивный вывод, который увеличивает истинность и уверенность. Если его нельзя применить, то применяется индукция-абдукция, если они переживают отбор, то они остаются в системе, но их значения оказываются меньше. тут нельзя прогнозировать как-то в одну сторону. то есть слабые уходят, сильные остаются. оказаться с высоким значением уверенности может как единичка, так нолик, так и 0.5, так и 0.7. все зависит от задачи и того, что реальный мир посовывает. 

S06 [01:11:16]  : Ну хорошо. От Александра Талипова очень любопытный вопрос. Мне кажется, сильно выходящий за скоб Нарса. Может ли Нарс рисковать, действовать уверенно в условиях большой неопределенности? 

S13 [01:11:34]  : Мне кажется, что рисковость Нарса можно охарактеризовать словами «слабоумие и отвага», потому что он всегда случайен. И это как раз, это интересный момент, который мне бы, например, было интересно инкорпорировать по приколу, ради интереса, в теорию функциональных систем. Потому что в теории функциональных систем, там, если есть, собственно, система, у которой есть набор правил, она выбирает всегда то правило, у которого наибольшая эффективность на данный момент. Было бы интересно посмотреть, что получится, если заменить вот этот выбор всегда лучшего на вот такой мешковый выбор. ну и весь риск, мне кажется, предопределен этим. ну да, нас рискует иногда, когда случайность ему показывает убирать менее проторенную тропу вместо более проторенной. 

S06 [01:12:23]  : Так вот, у Евгения Евгеньевича поднята рука, но в чате я не зафиксировал, когда это было, так что давайте, Евгений Евгеньевич, если вы готовы, мы вас слушаем. 

S01 [01:12:34]  : Меня слышно, потому что я тут не совсем в нужной форме. Слышно, слышно. Ну, значит, я прежде всего хотел бы сказать, что вот уже не первый раз делаются ссылки на то, что это настоящие причинные связи, а это не настоящие. Я все-таки хотел бы поддержать с точки зрения Игоря, и в частности многих других, и вообще считать, что на самом деле для разработок искусственного интеллекта не может быть исследования настоящих причинных связей. То, что Сергей Терехов сделал ссылку пердзла, но пердзла он разрабатывает, так сказать, Байсевские сети. Байсевские сети предполагают, что человек сам в точности прослеживает эти причинные связи, участие человека. Мы все-таки в разработке системы искусственного интеллекта не предполагаем, что нам человек эти причинные связи все разложит. Давайте предполагать, что человек в этом не участвует. В разработке причинных связей все-таки участвует сама система. Единственным образом, как это может делать, это она может логико-вероятностные причинные связи обнаруживать. Это отдельная тема вероятностных причинных связей, она более-менее разработана, в частности, обнаружение закономерностей, и там и правил могут быть все более точно которые в пределе могут доказать, что они в пределе стремятся к точным знаниям. То есть здесь на самом деле довольно четкая разработанная теория. Поэтому давайте не будем все-таки считать, что мы в какой-то степени претендуем на реальные причины связи. Более того, это совершенно другая тема, не имеющая отношения к самообучающему искусственному интеллекту. Это первое. Второе, конечно, я хотел сказать, что обнаружение взаимосвязи теорий функциональных систем и положим системы НАРС или других систем это важно, потому что теория функциональных систем она за рубежом неизвестна. А на самом деле это довольно сильная, довольно хорошая теория. Я думаю, что данная работа будет продолжена, и какие-то уже совершенно конкретные рекомендации, которые можно взять из теории функциональных систем, примитивные к системам нашим или другим, можно сформулировать и все-таки довести до сведения зарубежной общественности, что это может быть использовано. И, в частности, это может быть проделано в терминах системы NARTS. Это предполагается. То есть, мы все-таки предполагаем довести до ума ту статью, которую нам предложили напечатать P-WANG, и там, я надеюсь, что мы это более-менее все распишем. И, конечно, эксперимент, но здесь действительно сложно проведить более-менее. Дело в том, что очень легко придумать эксперимент с целенаправленным поведением одного агента, где теория функциональных систем сильно выиграет у НАРС. Но это не будет, на самом деле, показателем для сравнения систем. Но система НАРС, точно так же, как это было на этом ДЕМе, она расписывает множество людей, когда идут одновременно. Система, на самом деле, параллельная. Здесь достаточно корректно проводить компьютерное сравнение двух систем сложно. И можно дать совершенно конкретные рекомендации, где мы можем помочь другим системам, В частности, параллельность НАРС может помочь теории функциональных систем. То есть, взаимную поддержку, что на самом деле и требуется для разработок, вот это можно сделать. Ну, собственно, мой комментарий. 

S06 [01:16:35]  : Спасибо огромное. Как раз у вас было очень важное слово, Евгений Евгеньевич, мне кажется, прям прекрасное. В пределе. Что все наши знания, они в пределе являются точными знаниями. Этот предел, мне кажется... Мы сами-то не доходим, как правило, а уж что говорить про систему. Так, меня не слышно было, да? Чуть-чуть. Да, было слышно. Хорошо. Есть вопрос от Сергея Московского. Есть мнение, что вместо 24 аккуратных аристотельских силагизмов НАРС использует только первый, Барбара. 

S13 [01:17:24]  : вообще не так. вообще не так. там и чезаро, и там все нормально. 200 правил, там это все в разных вариантах есть, но полный список он лежит только в коде. 

S14 [01:17:41]  : приводить его не представляется возможным. 

S13 [01:17:44]  : Не, там он не 24, он все, сколько их там, если правильно это все перемножать, короче, все неправильные силогизмы он тоже использует. Это как раз передукты, обдукты и так далее и тому подобное. 

S06 [01:17:55]  : Хорошо. Антон Колонин готов был прокомментировать сам про задачи, видимо, которые решаются с помощью НАРСа. 

S04 [01:18:05]  : Да, Игорь. Первая задача, которую я увидел несколько лет назад, это пресловутый пинг-понг. Собственно, почему я за него и взялся. Потому что вспомнил, что Нарс пинг-понг уже научился играть. 

S06 [01:18:22]  : Вот. Извини, не пинг-понг. Вот тонкий момент. Не то чтобы пинг-понг. Он играет не с противником. Он играет как бы в стеночку, если так можно. 

S04 [01:18:30]  : Игорь, Игорь, там посмотри. Там на видео как раз именно пинг-понг. Хороший противник. Да, посмотри. И там есть целый канал какого-то парня, который к разным задачкам этот самый Нарс применяет. 

S13 [01:18:45]  : Если этот канал называется по Петхам-9 или Петхам-7, то это... 

S04 [01:18:50]  : Нет, это не Патрик. Но там я кинул ссылку, могу потом поделиться. У Патрика там какие-то другие. А вторая задачка, с которой Патрик в прошлом году выкладывал видео, я тоже кинул. Там они прикрутили это все к мобильному телефону с камерой. И там у них робот ездит на колесиках, находит и хватает всякие предметы с помощью Нарса. Это во-вторых. В-третьих, я честно скажу, я с Нарсом 20 лет не занимался. С Пивангом встречаюсь раз в 5 лет на конференциях. Но исходя из того, как я это все понимаю, в Нарсе, как и в системе Discovery, можно решать те задачи, которые можно описать, с одной стороны, с помощью системы связей, которая в эту систему будет загружена. То есть, если мы операционную среду можем описать с помощью вот тех связей наследования и причинно-следственных взаимосвязей, событий, и можем загрузить вот эту предметную область и операционную среду в него, да, и генерировать на вход некоторые экземпляры событий в терминах вот этой вот операционной среды, которая в него уже загрожена, то вот с помощью активности в этом самом мешке он будет реагировать на раздражители в той системе понятий и связей, в которые эти раздражители вписываются. И в этом смысле, для того, чтобы заставить его работать в режиме chat-bota, нужно просто загрузить в него некоторую грамматику, например, в формате один граммар. Ну, собственно, что, собственно, для чего 20 лет назад, грубо говоря, НАРС использовался в системе Бена Герцеля. Что просто мы берем, так сказать, описываем катентологию всего на свете, заталкиваем ее в НАРС, вот, и ее исполняем, и все работает. Насколько это хорошо будет работать? Это вопрос уже... Тут нет Юрия Бабурова, который, наверное, скажет, что это просто все умрет на соответствующем объеме. Не знаю. Это вопрос не ко мне. Но теоретически любые задачи, которые могут быть описаны с помощью системы правил, которые НАРС может использовать для индукции, абдукции с помощью тех силогизмов, которые им предусмотрены, Все эти задачи могут быть теоретически решены. И еще я сразу прокомментирую. Вопрос был у тебя, Игорь, я прокомментирую. эти самые социальные связи, что разных источников, к разным источникам можно относиться с разной степенью доверия. Опять-таки, мне кажется, если бы вопрос Пивангу задали, как с этим быть, он бы сказал очень просто, что вот у нас есть какие-то дефолтные значения для событий, для которых НАРС не знает. что назначать, какую уверенность назначать, какую confidence. 0.45, по-моему, прозвучало. Есть уверенности для тех фактов, которые у него уже есть в системе. Если у него что-то всплывает по приоритету, то он берет конфидент, который у них есть. А та конфидент, которая приходит извне, она на самом деле не обязательно может быть 0.45. То есть мы можем, допустим, приделать некоторый интерфейс, с помощью которого информация, которая будет поступать от Игоря Пивоварова, будет иметь конфидент 0.9, а информация, которая поступает от Васи Пупкина, будет иметь конфидент 0.2. Как это обеспечить? Это вот уже дополнительный вопрос. У нас с Евгением Евгеньевичем отдельная работа на эту тему. Ну вот, некоторый механизм социального инференса для выявления конфиденса. Это вот интересная история, которая, мне кажется, у Нарси встроенной нет. Я не знаю, но попытался ответить со своей точки зрения. 

S13 [01:22:56]  : Я добавлю в пику Юрия Бабурова, которого здесь нет. Мне кажется, что на одних и тех же объемах данных последний, кто умрет, это Нарс как раз. Потому что у него все операции типа плюс-минус константы. Там нет никого, ни поиска по дереву, ничего. 

S06 [01:23:12]  : Ну, хорошо. Вот тут есть очень любопытный вопрос от Виктора Казариного. Зачитываю целиком. Игорь затронул вопрос не только вероятности, но и открытости-закрытости мира. Юрий, как вы считаете, концепты и их связи описывают замкнутый или незамкнутый мир? Если не замкнутый, то концепты могут напоминать расширяемые классы. Все, что неизвестно, нельзя отрицать. Ваше мнение? мое мнение подпишусь под каждым словом открытый закрытый мир это какие-то устоявшиеся определения нет не устаешь но в данной ситуации я понимаю что речь в том что грубо если у нарса там 20 суждений в базе он ими оперирует все остальное для него неизвестно и он новые ниоткуда не возьмет если у него нет плитока новых данных то в каком-то смысле это вот замкнутые замкнутая система утверждения у них будет вариться А вот если у него есть постоянный вток новых каких-то, то он как-то приподоткрыт. 

S13 [01:24:15]  : Ну да, но NARS в целом он описывает, то есть идея NARS она описывается в отвязке от сенсоров, от устройств ввода-вывода, то есть Pivank всегда делает упор на то, что В частности, операции сами по себе не являются частью языка NARS, потому что они завязаны на какие-то периферийные устройства. Тут момент такой, что если мы возьмем NARS и не дадим ему ни глаз, ни рук, ни ног, ни ушек, и, скажем, вот у тебя есть высказывание варить в них, то он действительно ничего нового не выдаст. Но тут момент такой, что он рассчитан на то, что к нему поступает информация, то есть как она может поступать от учителя или от человека, так и это данные сенсоров, которые должны переводиться в язык на российский как раз. И, соответственно, он про открытый мир, если говорить в терминах вопрошающего. Можно уточнить вопрос? Да, конечно. 

S07 [01:25:22]  : Вот я как раз задавал вопрос. Тут немножко по-другому стоит. Если мы имеем единичку, это значит факт существует, допустим, только белые лебеди. Или нолик. Нет белых лебедей. То есть мы в системе работаем с фактами. А класс определяет только класс белых лебедей. И может существовать третья вещь. Нам неизвестно, существуют ли другие типы лебедей. В этом открытость мира и замкнутость мира определяется. То есть все, что неизвестно, мы либо отрицаем, говорим нет, этого нет и никогда не будет. И тогда работаем в минарной системе понятия, в замкнутом мире. А когда у нас мир не замкнутый, это означает, что нам что-то ещё неизвестно. Но мы допускаем, что может что-то добавиться. И это понятие наполнится другим смыслом. Добавится ещё какой-то представитель или подкласс этого класса. этого концепта. Понимаете? 

S13 [01:26:21]  : Вот я об этом. Да. NARS в его философии в основе лежит открытие, открытость как одно из понятий. Он всегда должен быть готов к новым задачам, к новой информации, ко всему вот этому. Опять же, пока это может быть выражено на языке NRC. Момент того, как переводить реальный мир в язык системы – это отдельный вопрос. Опять же, он стоит для всех систем. в том или ином варианте. Но у NARS, по идее, рассчитано на то, чтобы всегда все было рассчитано, чтобы всегда была возможность что-то новое получить. Если говорить конкретно про вашу формулировку про все лебеди белые, принадлежит ли класс лебедей классу белых и так далее, то это, опять же, зависит от того, как сформулировать. То есть можно было бы сформулировать прям на нарсизе выражение со значениями истинности, что лебеди являются подмножеством белых предметов, там 1 0 0 9 и так далее и тому подобное. Все зависит от того, как сформулировать, мне кажется. 

S06 [01:27:27]  : Отлично. Так, есть комментарий у Николая Робчевского. Николай, вы с нами? 

S00 [01:27:35]  : Да. У меня такие комментарии. Главный момент – это то, о чём Юрий Колонин рассказал нам сегодня касательно Нарта. Это не есть архитектура AGI. Это есть архитектура логических выводов, которая может быть встроена в разные архитектуры AGI. И вот когда речь идёт о примере, который Антон Колонин говорил насчёт маленького робота на основе селфона, который смотрит, находит какие-то объекты и складывает их в кучку, то это пример системы, которую использует тот НАРС, Юрий Колонин описал, как элемент действительно простенькой модели AGI. То есть для того, чтобы создавать новые концепты, для того, чтобы преобразовывать сенсорный ввод в то, что может НАРС обрабатывать своей неоксиоматической логикой, нужны другие системы, другие подсистемы, которые, так сказать, в совокупности с системой логического вывода, могут вместе образовать некую систему, которая претендует на AGI знания. Это первый момент. Второй момент. Вот такая не очень явно выписанная схема взаимодействия элементов, внутри самого логического вывода. Вот тот аспект, который Игорь Пивоваров говорил, а что будет, если ничего на входе не происходит, а она там крутится? Чем это закончится? Это зависит очень сильно от размера того, что в нее уже вложено было, И от тех самых настроек, о которых Юрий Колонин упоминал, о том, что их там очень много, и они влияют на это. То есть мы можем получить ситуацию, когда оно сойдется к некому стабильному значению, непонятно какому. А может оказаться, что оно войдет в цикл, в котором все циклически меняется. То есть это... Кстати, вещи, которые аналитически оценить заранее нельзя, а экспериментально, насколько мы можем видеть, оно пока не исследовано. Ну и вот по поводу использования вероятностных оценок и доверительных этих величин. На самом деле, если говорить именно о конкретной AGI-системе, то есть совершенно чёткое разделение между вещами, которые известны практически точно, а именно величины, которые меряются сенсорами, величины, которые, так сказать, поступают как бы сырые на вход, их бессмысленно считать случайными величинами. Потому что, во-первых, они практически не случайные, во-вторых, та невеликая, так сказать, доля случайности, которая есть, это скорее, так сказать, вероятность отказа от чего-то, которую, в общем, этим способом нет смысла учитывать. И есть гипотезы, то есть если мы, исходя из вот тех данных, которые у нас имеются и означают вход, так сказать, измеренные сенсорами и точно известное внутреннее состояние системы, ведь система свое состояние знает точно всегда. мы делаем некий прогноз, который по сути дела является гипотезой. Так вот, для гипотезы есть смысл использовать вероятность, а для остального нет смысла, потому что оно известно. А если неизвестно, то совершенно непонятно, какие так сказать, параметры ему назначить. Потому что если мы назначаем их по умолчанию, то это получается как вот в старом анекдоте, когда спрашивают, а какая вероятность того, что сегодня инопланетяне приезжают? Ну, 50 на 50, да. Есть в этом польза какая-то? Ну, очевидно, что нет. Ну вот у меня все. 

S13 [01:32:58]  : По-последнему, мне кажется, что мы с вами на одной точке зрения. Я просто это вижу так, что в фактах поступающих на вход, условно говоря, у которых то самое 1.09 стандартное значение, в них система особо не сомневается. А все эти метания относятся именно к взаимосвязям, к нахождению их взаимодействий в потоке поступающих фактов окружающего мира. По первым двум вопросам они мне оба симпатичны, оба близки. Я хочу просто отбить как бы такими рассуждениями, что я правильно понял вот по первому моменту, что когда вы сказали, что NARS это не AGI, что ему не хватает, ну чего ему не хватает с вашей точки зрения для того, чтобы называться AGI? Именно вот эта и система ввода-вывода периферии. 

S00 [01:33:51]  : Чего не хватает? Не хватает мотивации, не хватает способа выбора решения из нескольких возможных. Нет, способ есть. Если способ есть, который диктуется не аксиоматической логикой, а не требованиями заказчиками, то это означает, что его нет. 

S13 [01:34:23]  : Если у нас есть цель G и A, B, C варианты, как ее достичь, и система выбирает какой-то наиболее результативный. 

S00 [01:34:31]  : А что значит результативный? Чем определяется результативность? У нас есть способ задать критерии результативности? 

S13 [01:34:41]  : В NARS? Критерии результативности это будет достигнута цель G или нет. Соответственно, продолжая это рассуждение, в NARS это определяется по принципу, какое из утверждений A следует G, B следует G и C следует G, имеет наилучшее значение истинности. Грубо говоря. 

S06 [01:35:04]  : Юрий, давайте я поддержу здесь Николая. Я, конечно, тоже думаю, что НАРС это никакая не система ЭДЖАИ, в первую очередь, потому что... Меня интересно узнать, почему... ЭДЖАИ, мы думаем, что это система, которая будет решать широкий круг задач в условиях большой неопределенности, а НАРС, как минимум, требует формулировки очень точной цели. Знаете, вот как бы здесь вам сказать, вот например, есть такой анекдот, что человеку можно, ну не анекдот, это менеджерский такой анекдот, что человеку можно задачу поставить очень по-разному. И разным людям имеет смысл задачу ставить по-разному. Если у вас есть там, если вы хотите построить мост, то есть класс людей, которым вы можете поставить задачу. Сказать так, нужно построить мост. Вот тебе там бюджет. И дальше ты ничего не делаешь, он его построит. Есть человек, которому нельзя поставить задачу на таком уровне. Ему нужно сказать так, значит тебе нужно там вот построить мост отсюда сюда для этого тебе нужно нанять вот там таких проектировщиков вот этих там и не знаю бригаду взять там грузовики и в конце концов доходит до самого там условно рабочего которому в принципе нельзя поставить задачу кроме как вот бери лопату и как бы выкопай яму вот размером один на один вот начиная отсюда до туда и И G.I., как и человек, как мы предполагаем, все-таки должен уметь эти как бы цели, во-первых, какие-то сам ставить, во-вторых, какие-то их там условно, не то что декомпозировать, а цели могут быть нечеткими. Навс, как я его вижу, Это предельно четко сформулированная вещь, ну как бы вот на уровне вот этого самого рабочего, которому сказали, бери яму, выкопай ее отсюда-досюда. Не вопрос, любой человек выкопает яму. И в этом плане такая система суждений очень-очень понятна. А вот как формализовать цели сложные, в особенности если их даже нельзя четко формализовать, ну условно там, выигры-выборы. в системе нужно выиграть выборы президента. Это множество факторов, которые на это влияют. Эту задачу надо разбивать на отдельные и формализовать невозможно. 

S00 [01:37:24]  : У меня есть пример, который иллюстрирует то, о чем Юрий говорил в ответ мне. Вот простая задача. Мы стоим на балконе второго этажа. Наша задача оказаться на земле. Логично, при помощи НАРСа мы находим два пути. Один это прыгнуть с балкона, а второй это пойти через серию дверей в квартиру, подъезд там и так далее, наружу, выйти наружу. Оба имеют гарантированный выход единицу, но при этом один более опасный, а второй менее опасный. Критерии выбора решения их обычно больше одного. Поэтому сказать, что мы выбираем тот, у которого там некий фиксированный показатель наибольший, он становится тормозом, если мы этот показатель не можем оперативно подменять на одну комбинацию разных критерий, то на другую. Или то на один критерий, то на другой? 

S13 [01:38:56]  : Да, я понимаю, о чем речь. Я бы, наверное, сказал так. Походу того, как я еще полгода назад разбирал NARS, как бы все время была параллельность теории функциональных систем. В теории функциональных систем всякие такие сложные вещи решаются учетом максимальной специфичности и рассмотрением от меньшего к наиболее Учет все большего и большего количества параметров. И когда я это все рассматривал в NARS, сложилось впечатление, что NARS, он как алгоритм Монте-Карло, что всегда есть вероятность, что определенная последовательность логических рассуждений, в теории, она может привести и к рекомпозиции задач, и к нахождению нужных подцелей, и, в общем, так или иначе, смерч в итоге может собрать дом. Но статистически, я сам не знаю, Я сам далеко не апологет NARS, но просто сегодня я его представляю, так уж сложилось. И мне кажется, что на данном этапе ему действительно будет сложно как-то направленно решать сложные задачи, но статистически в целом сама модель вроде как этому не противоречит. При такой вероятности, которая чуть-чуть побольше нуля. 

S06 [01:40:19]  : Отлично. Юрий, прежде чем сдать слово Владимиру Смолину, в чате было какое-то количество обсуждений, все-таки надо их надо их закрыть, по поводу комбинаторного взрыва. Ну то есть, знаете, да, что такое комбинаторный взрыв? Когда у вас есть там некий вилка вариантов, у каждого из этих вариантов есть еще там варианты, еще там варианты, и когда мы начинаем все перебирать, то перебор станет слишком большим. Вот у многих людей, у меня в том числе, тоже ощущение, что НАРС как система такого аксиматического вывода, оперирующая с каким-то набором этих понятий и правил над ними, есть этих суждений или там термов в этих терминах. становится слишком много и выводов из них слишком много то есть если мы начинаем моделировать какую-то реальную задачу там не происходит реального комбинаторного взрыва то есть нет такого что он просто начинает там зависать 

S13 [01:41:20]  : мешок переполнит. а, вот так. и все просто. 

S06 [01:41:27]  : элегантная борьба с комбинаторным взрывом, да. 

S13 [01:41:29]  : конечно. все просто. когда мы берем две предпосылки, на каждом шаге берем две предпосылки, Из них там вот какое-то количество, плюс-минус 10 правил, будут давать какой-то результат. То есть для двух конкретных предпосылок там будет сколько-то результата. Как только мы получили 10 выводов из двух предпосылок разных, Система их все оценивает на жизнеспособность, то есть какой у них бюджет, какое у них значение истинности в зависимости от предков и так далее. Те, которые проходят какой-то минимальный порог, заносятся в систему. Там они сразу конкурируют за место в мешке с этими значениями. Если даже лучшие оказались недостаточно ценными в плане значений истинности и бюджета, то они в мешок просто не вылазят. И таким образом 

S06 [01:42:17]  : вот все мешок мешок не переполняет мешок переполняется и за счет этого ограничений ну любопытно то есть как бы мы снижаем грубо говоря там точности или не знаю количество информации но зато избегаем этого комбинатурного взрыва Любопытно, да. Хорошо, окей. 

S13 [01:42:34]  : Когда все идет от предположения о недостаточности ресурсов, там не попляшешь. 

S06 [01:42:40]  : Окей, у нас две поднятые руки Владимир Смолин и Александр Балдачев. Так, Владимир Смолин. 

S09 [01:42:48]  : Ну, значит, мне видно, слышно. Коротко, пожалуйста. Соглашусь с уже высказанным мнением о том, что это, конечно, не сильный искусственный интеллект, но я хотел бы подтвердить свое мнение тем, что, в принципе, я тут сообщал в сообщество, что вышла в июльском номере такой журнал Communications ICM, от Association of Machine Learning and Communication, что-то такое, вот, и там, значит, статья, собственно, трех мушкетеров глубокого обучения, то есть это Хинтон, Бенджо или Кун, и они как раз рассуждают про, значит, глубокое обучение и искусственный интеллект. Ну, я, как это выводится, не совсем с ними соглашаюсь, но совсем я с ними согласен, что, ну, правда, как бы соговор, что поскольку они занимаются нейросетями, конечно, они это и продвигают. что все-таки главное в искусственном интеллекте, то есть сильно в искусственном интеллекте, это то, что он умеет выделять понятия. Потому что вопрос декомпозиции сложного мира на простые объекты, он очень сильно экономит в его описании. Если мы осуществили хорошую декомпозицию мира, то мы, соответственно, очень сильно сэкономим на описании этого сложного мира. А если мы не умеем это делать, то, соответственно, сложные задачи мы решить никогда не научимся. Ну, то есть мы совсем сложные задачи никогда, и даже умея делать эти композиции, тоже не научимся. Но, по крайней мере, будем, значит, сильно впереди. Раз уж тут вспомнили, значит, вот про комбинатурный взрыв, ну, собственно, такой, как сказать, сложной, конечно, задачей было бы предложить, там, вот этому самому... рассматривать технологии, попробовать сыграть в шахматы или го и сравниться с альфа-го, которые тоже решают ту же самую проблему комбинаторного взрыва. я понимаю, что это некорректная задача. это как вручную, в смысле побегать на скорость с формулы-1, только без колес. и в мешках. И в мешках, да, особенно для НАРС, что характерно. Но, в принципе, мне кажется, что там всё-таки в Альфа-0 немножко элегантнее решается задача комбинаторного взрыва, чем просто ограничением размера мешка. И я со своей стороны, если помните, рассказывал о том, что есть в интеллекте две стороны. С одной стороны, мы рождаемся с некоторыми способностями, а с другой стороны, поскольку мы живем в обществе, то наша цивилизация нам позволяет развить эти способности. И я все эти НАРС отношусь к некоторым цивилизационным навыкам. То есть мы с огнем научились пользоваться, с колесо изобрели, базы данных. И NARS, видимо, тоже такая же, может быть, полезная технология, но это как бы не АГИИ, а некоторые способы, которые, значит, выдумал человек. А, собственно, когда мы разрабатываем сильный искусственный интеллект, то нам нужно делать агента, который может выдумывать такие способы, а не пользоваться ими. Вот, собственно, в чем разница. 

S06 [01:45:50]  : Вот мой комментарий. Спасибо. Сценный комментарий мне еще тоже намысленно вело, что разработка этого НАРСа ценна уже тем, что когда оно сделано, можно посмотреть на него и на его результаты и сказать, что это не АГИИ. Я к тому, что это тоже ведь немаловажно. Можно себе представить, что вот если мы сделаем систему вывода, она будет работать, то, наверное, она будет как человек. Но когда мы сделали и посмотрели на это, то существеннейшим результатом является то, что мы начинаем видеть ограничения этой системы. Юрий, ты сегодня прекрасно нам показал, кстати. Я считаю, что это очень классная история. Так, Александр Балдачёв, вам слово. 

S02 [01:46:32]  : Добрый день, Юрий, большое спасибо. Очень интересно, познавательно. Я вот Владимира Смолина хотел... То есть его мысль, когда он говорил, у нас есть уже колесо, огонь, база тандыр, и я думал, что сейчас он скажет, но сказал другое. Я бы на его месте сказал, а зачем всё это с нуля выдумывать? Зачем голую машину заставлять выдумывать то, что уже известно? То есть есть огромный свод знаний, огромный свод накопленных отношений, которые можно просто загрузить, а не пытаться вероятностно что-то там выискивать, пытаться долго-долго заставить машину, чтобы она какую-то связь между грозой и громом нащупала. Когда ребенку мама показывает, гроза, гром, смотри, и потом еще в школе объяснили. Вот это такой момент. Второй момент касается логики. Никто не затронул, кстати, поэтому я и взял слово. У нас какое-то очень странное наблюдается, особенно в этой сфере войны, но не у всех. То есть какое-то преклонение перед логикой. Мы тут стали обсуждать Барбара, сколько там сил логизмов. А ведь логика по сути своей, она совершенно пуста. Она никогда ничего не дает, она никогда ни к чему не приводит. И если мы берем просто обычную деятельность человека, он никогда не ориентируется на логику, не говоря уже, если о животных. Животные, когда у них запускается функциональная система, он, экипард, ловит, гонится за ланью, он ориентируется на величайшие поведенческие отклонения и все прочее, но там логики нет. Там никогда не делается никакой вывод логический, там совершенно действует на другом принципе. И мы знаем огромное количество свидетельств ученых, когда они делают открытие, то, что Владимир говорит, новые понятия, они никогда не выводятся логически. То есть логический вывод, это нечто вспомогательное с точки зрения оформления знаний. Кстати, опыт, два крупных опыта, это опыт с ЦИКом, создание логической вывода системы глобальной, и опыт Semantic Web, RDFOIL, где тоже была сделана ставка на логический вывод. Ноль, этот логический вывод никому не нужен. Это вывод только на этом уровне, что если ребенок родился, если Маша родила Сашу, то мы логически можем вывести, что Маша стала родственницей Саши, стала мамой Саши. что у неё появились, то есть у Саши появилась мама и появились там тёщи, дедушки, бабушки, всё. Это логический вывод, это всё лексика. То есть вместо того, чтобы говорить, что это мама моей мамы или т.д., мы просто придумали бабушка, слово. То есть весь логический вывод основан на том, нужен ли вот тот, который используется в современных логиках и основан на теории множества, на классической теории множества. Он всего лишь расширяет наш лексический запас, но не добавляет в них знаний никаких. Логика знаний не добавляет, а всего лишь позволяет делать аналитику, анализ и поиск, чтобы нам не искать, найдите мне маму мамы, а мы ищем бабушку. Поэтому очень странно пытаться построить что-то либо адаптивное с одной стороны, то, на что ориентированы теории функциональных систем, и тем более поиск понятий с другой стороны, новых понятий, научные какие-то, на логике. на искусственный интеллект, на общий искусственный интеллект, ориентированный либо на адаптацию к неизвестным каким-то ситуациям, либо на поиск сугубо в понятийном пространстве, в мышлении, то ни там, ни там логика не работает. Ни там, ни там она не нужна. И вероятностная эта логика. Я вот, Игорь, поймаю вас на слово. Дом, мы не знаем, он может там разрушиться. Это вероятно. Дом-то однозначно. Поэтому эта вероятность касается, ну просто… Да он может и взлететь. Да, может и взлететь. Но он касается нашего состояния. Да, кстати, еще один момент очень интересный. Он связан с тем, что с попыткой создать единую систему правды, единую систему истины. А ведь в жизни у нас совершенно не так. У нас каждый человек, когда произносит некое суждение, он его произносит только потому, что он стопроцентно уверен, что оно истинно. Ну редко можно сказать, я не уверен, но когда человек говорит, вот я говорю, я стопроцентно уверен в том, что я говорю истинно для себя. Не вообще. Я бы не стал говорить, если бы не считал, что это истинно. И поэтому множество людей противоположными точками зрениями. Каждый из них считает, что произнесенная фраза является истинной. Поэтому считать вероятности, это можно как бы посадить арбитра которого, который будет посчитать всех по головам, посчитать то, что сказал и посчитать вероятность, сколько вероятно сказали за, сколько против. Но в действии, в деятельности Вот в деятельности, когда человек совершает некое действие. Вот он решил построить мост. он не может исходить из каких-то вероятностных соображений, он окажется неправ. Но для того, чтобы действовать, всегда нужна стопроцентная уверенность. И очень часто бывает, что дело делает человек тот, который уверен. Он потом ошибется, он потом найдет правильное решение. Но если изначально закладывать вероятность, выступность каких-то положений исходных, ты никогда с точки не сдвинешься. И это провальный вариант. 

S06 [01:52:35]  : Но только вы не путаете, Александр, я почти с вами согласен, надо не путать все-таки уровень уверенности и допустимый риск. Я бы сказал, что только глупые люди абсолютно уверены во всем, что они делают. Ну вот честно. Умные уверены. Я, например, уверен всегда в том, что я делаю, но я понимаю вероятность этого события, но для меня есть уровень приемлемого риска. Например, если я там уверен больше, чем условно на 0,8. 

S02 [01:53:05]  : Вы правильно сказали. 

S03 [01:53:06]  : Верно, верно. 

S06 [01:53:11]  : я вам скажу так мир был бы куда лучше если бы люди понимали не стопроцентное как бы не были бы стопроцентно так уверены я вот со многими людьми иногда приходится их когда переубеждать то в первую очередь начинаешь работать именно с тем, чтобы показать человеку, что то, в чем он абсолютно уверен, не является стопроцентным, а является вероятностным. И только когда человек на каких-то примерах это начинает видеть, то у него начинает эта вот картина немножко трещать. Абсолютный стопроцентной уверенности в том, что он делает. Мир был бы куда лучше, если бы люди не генерализовали, не говорили условно все негры быстро бегают, а все там русские пьяницы, а все американцы. Я условно. И вот эта вот уверенность, она ужасно портит нам коммуникации. Лучше уж, вот мне очень в этом смысле Нараса очень нравится. Он изначально вероятностный. Кстати, мне, если я правильно понимаю, Юрий, то невозможно сделать так, чтобы быть уверенным на сто процентов. Ну, это же умножение одного на другое, то есть всегда будет 0, 99, там 9 что-то. 

S13 [01:54:19]  : я могу точно сказать, что flow confidence в системе по идее считается по принципу n делить на n плюс k, где k системный параметр. 

S06 [01:54:28]  : ну да, это круто на самом деле. как говорил Евгений Евгеньевич, в пределе только мы имеем 100% уверенность, но никогда ее не умеем. 

S09 [01:54:44]  : Выгодно отличается от глупого тем, что он всегда во всем сомневается. Впрочем, в том, что это выгодно, я сильно сомневаюсь. 

S13 [01:54:56]  : Я хочу просто добавить к этой полемике, что мысль о том, что только абсолютно уверенные в себе люди всегда всего добиваются, хороша ровно до того момента, пока мы не вспоминаем про ошибку выжившего. 

S02 [01:55:10]  : Нет, это другое. Игорь, я хочу все-таки возразить немножко, потому что одно дело в коммуникации, вы говорите. Это коммуникация. Коммуникация действительно требует обходительности. Всегда говоришь, что по моему мнению, и все прочее. Но когда ты начинаешь делать, действовать, то человек, который постоянно сомневается, он не действует. А мы как бы задачу, которую формулируют создатели этого понимать что-то в среде. Поэтому вот здесь нужно как бы, есть два варианта решить эту проблему. Либо вести по полной субъектности, то есть и каждое суждение приписывать разным агентам, которые могут как-то бороться за какие-то ресурсы, но который победил, тот имеет стопроцентную уверенность и действует. Либо как-то выводить себя в какую-то Мы же начинаем действовать, когда строим модель. 

S06 [01:56:08]  : Александр, посмотрите. Русская пословица «Семь раз отмерь, один отрежь». Она вот как раз про Нарс в каком-то смысле, потому что, грубо говоря, тройкратное повторение увеличивает нашу уверенность. Такое ощущение, что он никогда не отрежет. Заметьте, семь раз. Но прикол в том, что в этой поговорке есть некий ответ на то, что вы говорите. Любой человек должен сомневаться. Рано или поздно приходится действовать, но лучше уж пару-тройку раз отмерить. Конечно, конечно. Не-не, вот здесь есть как бы здесь есть драма-зеро. Я троллю вас немножко, но... Нет, я тоже трогаю, мы заняли противоположную, крайнюю позицию. 

S02 [01:56:46]  : Да-да-да. Там где-то нужно, там действительно нужно расстелить. Я вам первое говорил, не про уверенность, а про истинность. Истинность, она, то есть сказанное выражение, вот идет дождь, я сказал, я вижу идет дождь, оно истинно, само по себе, потому что я произнес. И поэтому выяснять, который показывает нам, что вот то-то произошло, что туча закрыла солнце. Зачем здесь выяснять какие-то вероятности? Нужно пользоваться теми данными и принимать те данные, которые нам поступают, как у животных, как у человека. Мы не можем сомневаться в данности. 

S06 [01:57:26]  : Нужно срочно доставать деньги. Александр, а вы с Декартом знакомы? 

S02 [01:57:30]  : Да, недавно мы с ним тут вот как-то обсуждали тем, я, кстати, не согласен по поводу когета. Я считаю, что без мышления прекрасно можно существовать. 

S13 [01:57:42]  : А что делать, если все наши чувства подменяют? Что тогда? 

S02 [01:57:46]  : ничего не делать. А как животных подменять? Мы действуем в своем мире. Если бы мы задумывались о том, во-первых, я еще с Кантом после этого переговорил, а Кант сказал, что плевать, нам все равно неизвестно, как в этом мире, что существует. Есть только явление, и мы в нем существуем. Поэтому ставить вопрос, а кто там на самом деле, это схемы, и нужно создать эту схему. Кстати, это одна из ошибок Нарста, что он пытается создать одну схему. То есть нужно создавать под разные ситуации множество разных схем, даже противоречий. Я в разных ситуациях, в разных контекстах могу сказать совершенно разные противоположные вещи, потому что я знаю, что это в разных схемах, и это необходимо, и это нужно. Познакомьтесь с историей ЦИК, когда они пытались сделать единую систему, она развалилась. Они не смогли, они 15 лет пытались найти эту единую логику, все развалилось, и это не будет работать никогда. 

S06 [01:58:56]  : Это, кстати, хороший комментарий по поводу разных систем. Александр, вы прекрасно украсили семинар вместе с Декартом и Кантом, просто замечательно. Евгений Евгеньевич поднята рука, я так понимаю, что он тоже хочет в эту дискуссию вступить. 

S01 [01:59:12]  : Евгений Евгеньевич. Меня слышно? Да. Иногда пропадает здесь звук, но, так сказать, Я хотел бы все-таки добавить. В соответствии с теорией функциональных схемы, в принципе, Анохина, человек и мозг – это предсказывающие устройства. Поэтому на все логические схемы вместе с вероятностью надо смотреть не на логику, а на процессы. предсказания, потому что предсказания, физиологический факт отвечает на условные связи, быстрее отвечает на высоковероятные события, то есть это физиологический факт, то есть мозг человека вероятности учитывает, поэтому не надо смотреть на логические исследования, логический формулизм как начинку 

S06 [02:00:11]  : у меня это совсем логику смотреть на как на прогностические вот в марсе такой прогноз тоже такой прогноз есть поэтому это не логические системы это прогностические системы вот мой комитет да суть была понятна да спасибо мне вот интересно кстати на записи потом вот когда запись есть зум же пишет там ну от каждого человека может быть на записи не будет этого провисания звука вот любопытно хоть раз посмотреть у 

S13 [02:00:39]  : на временной отметке сейчас ровно два часа можно будет. 

S06 [02:00:41]  : да, надо будет глянуть. обычно пропаж есть. есть, да. что сейчас вот, ну, сейчас, по счастью, комментарий, в принципе, Евгений Ильич был понятен, и, кстати, я согласен. В этом смысле это не совсем логическая система, это именно система такого вероятностного вывода. 

S13 [02:00:59]  : Ну, конечно, и опять же добавлю, как бы тоже всем известно, что всем известна проблема индукции, как бы про индюка, который живет на ферме, и в течение нескольких лет его каждый день кормят, а потом в один прекрасный день фермент приходит, делает из него суп, как бы, в общем, Вопрос в том, где индюк ошибся, ответов, в принципе, особо не имеет. Любое предсказание, оно всегда не с вероятностью единичка. 

S06 [02:01:23]  : Это правда, да. Так, у Виктора Казариного есть еще, видимо, вопрос или комментарий. Виктор? 

S07 [02:01:30]  : Я могу голосом, да? Я как раз его понял. Я буду с микрофоном, потому что у меня звук пропадает тоже. Я бы хотел 5 копеек ставить в защиту логических подходов, которые я не полностью поддерживаю, но тем не менее. Николай Робчевский и Александр Балачев сказали, что входные данные — это есть факты, но на самом деле входные данные, они бывают первичные, такие как природа, шум ветра и так далее. А есть те, которые несут на себе вторичную информацию. Допустим, изображение чего-то. То есть само изображение — это факт, это истина. Но то, что там изображено, мы можем подвергнуть сомнению. Это фейк какой-то и так далее. Сами же понимаете, да? То есть в этом плане необходимо определяться с доверием к тому, что мы воспринимаем То, что мы анализируем и вырабатываем собственное мнение или пользуемся чужим мнением. Второе замечание. Уверенность, степень уверенности в чём-то, она динамическая на самом деле. Если мы её запишем с той же информацией, которую восприняли, то мы вспомним легко, что тогда мы в это верили больше, а сейчас мы меньше, сейчас мы наоборот противоположно считаем. Этому ничто не мешает, если мы это запишем. Мы не будем это делать константами, как вот сейчас нам в НАРСЕ продемонстрировали, а сделаем такими же данными, как всё остальное. припишем нашу уверенность, наше отношение к этому. Потому что субъект, который искусственный или любая система, она и припишет это значение к данным. И никаких проблем не будет. Это первое. Дальше. Все-таки определенная уверенность нужна именно при принятии конечных решений. Либо если мы всё время чему-то верим, то мы всегда можем совершить какие-то вещи, неправильно принять решения. Система, которая динамически работает, именно сиюминутная, определяет степень своей уверенности, она более адекватно работает. И ещё последнее замечание насчёт защиты логики. У меня работающая система, я уже говорил об этом, которая распознает документы по изображениям. Она полностью основана на аналогическом уровне распознавания, где один раз предъявили документ, она запоминает его и потом уже классифицирует, идентифицирует документы, которые идут с конвейером на вход этой системе. Она пользуется не чистой логикой, а точно так же с этими вероятностями. В конце которой этой системы стоят, находится группа экспертов, которые определяют не только свою степень уверенности, но определяют не только Ну, свою обычную уверенность, о которой сейчас говорили, как своё доверие. Ну, и определяют ложные положительные ошибки и ложные отрицательные ошибки. То есть, можно забраковать то, что действительно правильно, а сверху сказать, что это неверно. И вот такого рода ошибки существуют. Ложно-положительные, ложно-отрицательные еще. Вот я же на что нарвался. Поэтому это все логические системы вполне отрабатывают, хорошо работают на определенных, естественно, ограничениях. И как один из вариантов, систем основ для построения будущего АГИ, Они вполне могут конкурировать с нейросетевыми и другими. Поэтому я не вижу оснований для таких жёстких нападок на данное направление. Поэтому поддерживаю в чём-то этот НАРС. 

S06 [02:05:33]  : Виктор, ну тут не было жестких нападок, строго говоря. Ну окей, Юрий, у вас, да, отвечай. 

S13 [02:05:38]  : Да, я хотел добавить только что. Мы с Виктором, видимо, друг друга недопоняли по поводу NARS. Ответственность, конечно, на мне, что я об этом либо не сказал, либо сказал мельком. NARS, он не приводит одно и то же утверждение в разные моменты времени к общему знаменателю. Каждое утверждение, которое в нем есть, оно хранит информацию о том, когда оно было получено, оно более того, вот об этом я не говорил, что утверждение хранит историю того, на основе чего оно было выведено, то есть либо оно поступило из внешней среды, либо, если оно было получено в результате вывода, то оно хранит информацию об ID родителей, грубо говоря. И вот эти все вещи, они в конечном итоге, там просто еще более сложные механизмы. Если бы я про них рассказывал, мы бы и сейчас не закончили. Они в целом учитываются при выводе. Там есть такое понятие, как обобщение во времени, что так называемая этернализация и так далее и тому подобное. То есть NARS, он учитывает историю некоего события, некую динамику. В разных вариантах это учитывается. Спасибо. 

S06 [02:06:46]  : Но все же, отвечая Виктору в его комментарии, система распознавания документов, безусловно, понятная работающая задача, где может такой подход вполне работать, я совершенно не исключаю, но это совсем не GIA. Мы, все-таки семинар наш и группа обсуждает модели для построения общего искусственного интеллекта. в этом плане система логики она то есть я здесь согласен с владимиром смольным и николай рощевский это просто ну как бы условно узкая такая система для своих задач применимая но и не видно, чтобы она была прямо как-то очень масштабируемая и в разные стороны, чтобы она... Не знаю, это скорее не возражение, а просто такой открытый комментарий. Давайте мы еще кому-нибудь дадим высказаться, кто еще сегодня не говорил. Вот Ильгизар поднял руку. 

S05 [02:07:49]  : Добрый вечер. Я хотел бы усомниться, что вот этот сам принцип, концепция неаксиматичности может привести к получению адекватной модели. Немножко получается продолжение выступления Александра Балдачева и Виктора. Вот то, что в неком мешке равноправно лежат все правила, это получается какая-то аморфная система, которая не имеет архитектуры собственной. Какой-то получается бесперспективный, мне кажется, какой-то тупиковый тупиковая архитектура получается. Все-таки должен быть у системы какая должна быть самоидентификация. Вот был в комментариях то, что не хватает Нарсу. Мне кажется вот самоидентификация. Самоидентификация значит иметь свой Скажем так, мотивацию, свой характер, то, что отличает именно систему целостную, которая может вести свою деятельность, свои знания иметь. Сам принцип неактиматичности, что система не может иметь свои принципы, мне кажется немножко бесперспективным. 

S06 [02:09:32]  : у вас есть два тезиса на самом деле по поводу самоидентификации это я бы сказал вообще как бы вообще нет ни у одного системы пока технической никакой самоидентификации там мотивация это как бы вообще как бы это пока за скобками, а вот по поводу неаксиоматичности и как бы что это бесперспективная архитектура я думаю что Юрий вы откомментируете. 

S13 [02:09:55]  : Я понимаю претензию, вопрос понятен, и все, что я могу ответить, что те свойства, на которые Ильгизар подверг скепсису, мне было бы интересно услышать, почему под это же описание не подходит человеческий мозг, если забыть о количественной химиатрии. 

S05 [02:10:23]  : ну как на каких как бы основаниях можно утверждать что мозг мы не оперируем концептами мне кажется совершенно наоборот допустим вот допустим нарцы мы сажаем в первый класс начинаем учить вот там теоремы, законы, правила, грамматика – всё это концепты и всё это архитектура. А Нарс получается, что он будет всему сомневаться и сказать, что всё допустимо, что прямой угол может быть иногда и непрямым. 

S13 [02:11:12]  : прямой угол. прямой угол может быть непрямым, в логике такого нет. 

S06 [02:11:17]  : но у него же нет аксиом. в евклидовой геометрии прямой угол всегда прямой, но в неевклидовой геометрии не всегда прямой. 

S13 [02:11:28]  : прямой угол не может быть непрямым к силу опоропределения. это может быть неудача, но 2х2 не всегда 4 допустим. 

S05 [02:11:32]  : я просто ровно про то, что мне сложно сказать почему 

S13 [02:11:53]  : как будто бы я уловил претензию в том, что Нарс он какой-то достаточно однородный, что там просто есть одно большое скопление разных штук, которые как-то между собой связаны. Мозг же тоже куча нейронов, которые абы как между собой соединены. 

S06 [02:12:09]  : Знаете, мне кажется, что это спор. Был такой замечательный старый, ну это не анекдот, а такая шутка, когда там пришел ученик к фотографу. как известному мастеру и сказал я хочу у вас учиться фотографии вот у меня вот такой фотоаппарат вот смотрите вот у меня значит такой вот он быстрый там все вот есть вот такой объектив и вот есть вот такой объектив еще есть вот такой штатив еще такая вспышка и вот еще другая вспышка еще такой зонтик по фотографу слушал слушал потом вы хоть одну фотографию свою покажите И вот, понимаете, мне кажется, что имеет смысл обсуждать не технику, а результаты, которые она дает. Мы сейчас обсуждаем, то есть какой смысл говорить там, вот кажется это бесперспективным или кажется перспективным, но если мы увидим хорошие результаты, которые этот НАРС дает, мне кажется, пока результатов мало. Вот увидим хорошие результаты, вопросы отпадут. А так, как бы, ну, теоретически, мне кажется, что да, а мне кажется, что нет. Я бы предложил скорее сконцентрироваться на тех... Вот есть некоторые примеры, там демы, которые были выложены. Желающие могут, наверное, посмотреть эти демки и посмотреть, есть ли там результаты или нет. Так, у нас есть вот редкая прям рука поднята. Александр. редко готов высказаться. давайте мы вас послушаем. только без обсуждений того, что там кто-то ничего не понимает. пожалуйста, без этих комментариев. александр бур. алло, графики. да, слушаю вас. слышно, да? да. 

S11 [02:13:59]  : Здравствуйте. Во-первых, я хотел сказать по поводу нас. Там аксиомы есть. На основании чего-то они делают выводы. Там есть аксиомы, можно все посмотреть. Почему такое название было? Ну, некорректное название. Ну, вот им понравилось. В том смысле, я так понимаю, исторически так сложилось, что не совсем те классические от классической логики названий. Это первый момент. Второй момент. Логика есть много, все знают. Смотрим википедию, там логика сейчас вагон и тележка. Модальные логики там и поехало, и поехало. Раз много логик, какой логикой пользоваться где-либо? Логик много. Еще раз, какая самая правильная? Простой. В той или иной ситуации требуется использовать ту или иную логику. Где-то нечеткую, где-то модальную, где-то там темпоральную, где-то там еще всякие разные. Там непрерывные и поехало. Что это означает? Как обобщить это все? Чем эти все логики? Что-то же их все объединяет? Что объединяет все эти логики? Ответ простой. Есть некие начальные цепочки, символы, правила, начальные аксиомы. И есть правила присоединения следствия, правильно построенные формулы. Мы дополняем, дополняем, дополняем. Это второй момент. То есть, именно так работает и НАРС. То есть, по сути дела, чем ценен в этом плане НАРС? Тем, что это пример того, что Пейванг как раз и эту суть уловил. он делает нужные ему правила и получает полезные для него следствия. Этому ценно. Но такие правила не единственны, таких правил может быть множество. Это второй момент. Третий момент. Что объединяет все эти логики? Это означает, что, по сути дела, это нормальные алгоритмы Маркова. Ну, все знают. Нечто стоит слева, заменяем на любое то, что стоит справа. Набор таких правил – это нормальные алгоритмы Маркова, по сути дела, протологика, мать всех логиков. То есть, когда мы конкретизируем эти правила, то получаем перечень логик, перечень систем вывода, присоединения следствия. математические и моделирование. Вся математика, по сути дела, это отражение, наведенная, индуцированная, символьная система, индуцированная реальностью. Какая нам математика интересна? 2 плюс 2 равно 4. Две авцы зашло, две вышло. 

S06 [02:17:24]  : Александр, вы, по-моему, уже сильно далеко ушли от темы Нарса, но мысли понятны? 

S11 [02:17:31]  : Не вопрос, я могу это закончить. 

S06 [02:17:35]  : Комментарий был как раз по поводу логики в целом. 

S11 [02:17:40]  : Конкретно, почему НАРС полезен на самом деле. Хорошая вещь, но она частная. То есть надо подняться на один уровень выше метамоделирования, и тогда понятно, место НАРСа. То есть вот здесь НАРС то, НАРС сё, а там такая логика. Так вот, это всё индуцировано реальностью, и, соответственно, Мы правильно должны любые логики продуцировать на раз-два. Понадобилась та логика. Мы отметили причину следственных связей. Обычная логика – это отражение причинно-следственных связей, не более того. 

S06 [02:18:19]  : Окей. Спасибо. У меня, знаете, какое вот есть предложение. Юрий начинал с того, что... Юрий проделал большую работу с тем, что он нам рассказывает про НАРС, в котором он разбирался специально. И, Юрий, одной из ваших мотиваций было то, что вы там хотели устроить какую-то дискуссию, еще что-то. от сообщества какой-то фидбэк получить. У меня вопрос к вам. Вы фидбэк этот получили или может быть вы как-нибудь сейчас можете сформулировать там какой-то свой вопрос или там утверждение на которое вы хотели бы получить какую-то обратную связь и может мы не в формате высказываний таких догоняющих догоняющих это можно бесконечно делать а попробуем как-то еще на ваш наоборот ответить если у вас что-то осталось неотвеченным или тем не прозвучало. 

S13 [02:19:18]  : Да, я собственно ровно с одним вопросом пришел. Никто не стал на него отвечать, тем не менее я очень доволен обратной связи, очень доволен в целом дискуссии. Получилось интересно так или иначе. Повторяю то, о чем сказал вначале, хотелось бы чтобы люди, все, но в частности те, кто сам разрабатывает архитектуры, хотелось бы вот про какие-то отдельные механизмы, о которых было сказано в докладе, услышать фидбэк, то есть может быть что-то на что-то либо похоже, с одной стороны похоже из других архитектур, или наоборот что-то уникальное. что может быть кто-то, то есть есть мысли инкорпорировать это в какую-то другую модель. я вот например сказал, что в момент мешка можно было бы в теории интегрировать функциональные системы, посмотреть что получится. вот вот такого формата хотелось бы наверное что-то улучшить. 

S06 [02:20:11]  : так, отлично. коллеги, а есть у кого-нибудь вот такого плана как бы комментарий, ответ Я не вижу… Физическую. 

S08 [02:20:23]  : Можно уточняющий вопрос, чтобы быть уверенным в моих комментариях? Правильно ли я понимаю, что в нас выводили… Когда делается вывод, то мы берем вероятностную оценку от родителя. То есть, грубо говоря, у нас есть какие-то осуждения, мы из них выбрали самое вероятное, а потом, когда мы берем новое вероятное, мы получаем новое осуждение, учитывая предыдущее. 

S13 [02:20:48]  : Да, но я уточню, в зависимости от того, какое правило применяется к предпосылкам, по разным формулам для разных правил считается значение истинности нового утверждения. 

S08 [02:21:02]  : Вопрос, когда наше финальное утверждение является каким-то мерам неправильным? Как мы обновляем нашу информацию? Обновляются только родители или вся иерархия? 

S13 [02:21:13]  : И родители, и дети варятся в одном мешке, и если полученный новый результат оказывается жизнеспособным, он попадает в этот мешок и долго-долго в нем живет. Если результат не жизнеспособен, он в мешок либо не попадает, либо быстро из него его покинет. 

S08 [02:21:29]  : Какой финальный? 

S06 [02:21:31]  : Игорь, подождите. Я сейчас как модератор задал другую линию. Давайте посмотрим на нее. У Юрия все-таки был некий интерес, как у докладчика. Он сделал некоторую работу для нас, для всех. Рассказал нам про этот НАРС, в котором большинство из нас не разбиралось. Давайте попробуем дать ему фидбэк. И если у кого-то есть система, у вас, например, Игорь, есть система, которая похожим образом работает? И что-то можно отзеркалить, например? 

S08 [02:21:58]  : Я бы сказал, да, я чем-то подобным занимаюсь, пробую разные методы. И я почему-то задавал уточняющие вопросы, вот как раз когда оно отустроит по иерархии. То есть я хотел сначала уточнить, как точно она работает, потому что я не до конца понимаю. И мне кажется, в этом может быть ошибка за счет того, как мы берем, грубо говоря, родителей, когда мы выстраиваем все эти иерархии и берем их результаты и потом обновляем. В общем, это как бы большая ветвь, где можно делать это по-разному. Просто хотелось бы уточнить, как именно это делается, чтобы поделиться, грубо говоря, своим опытом. 

S06 [02:22:34]  : А вы как это делаете? У вас как это делается? 

S08 [02:22:37]  : В чем? сказать, ну, тоже высказаться еще по поводу предыдущих комментариев. Вот проблема как раз вот этого комбинаторного взрыва. 

S06 [02:22:46]  : Давайте не по предыдущей, не по предыдущей комментарии. 

S08 [02:22:49]  : Да, так это идет к этому. 

S06 [02:22:50]  : Как вы это делаете? Суть в том, что нам надо 

S08 [02:22:58]  : Посмотреть сначала, когда мы делаем это с вероятностями, мы не можем, грубо говоря, до конца определить. То есть, если мы будем обновлять только родителей, это означает… Суть в том, что мы никогда не можем знать, какое из этих предположений было неверным. Если мы будем пытаться обновлять их все, мы попадаем в комбинаторный взрыв. Поэтому обратно нам нужны какие-то метрики, чтобы определить, как это делать. Если мы будем обновлять только родителей, то это будет неправильно, потому что не только родители могут иметь неправильный результат в этом объединении. 

S13 [02:23:33]  : Да, если я правильно понял вопрос, родителей мы не обновляем, мы их используем для получения детей, при этом родители не удаляются, они по умолчанию возвращаются в мешок. Другое дело, под давлением чрезвычайно продуктивных детей, выживут ли они в мешке на дистанции, но это совсем другая история. Родителей мы не перезаписываем, не удаляем. Они как появились, так они и есть. 

S06 [02:23:58]  : Честно, я вас слушаю, я понимаю, что для людей, которые этим занимаются, это, наверное, интересно, но если не видеть результатов, то непонятно, что лучше. Если бы, например, вы там показали бы, что вот на этой системе видно, что вот так работает, а так не работает, это было бы понятно. 

S08 [02:24:15]  : Можно я просто приведу простой пример? К примеру, когда мы работаем, например, с изображением, это просто как бы пиксели, картинки. Приведем простой пример. Приходят у нас, например, три числа. 10, 5, 15. И выход один. Вопрос в том, какой из этих чисел влияет на наш выход. Типа 10, 5 или 15 или ихняя сумма. И грубо говоря, мы делаем какой-то новый слой, новый вывод. Мы берем ихнюю сумму или любую другую математическую операцию. Если эта математическая операция будет не уникальный хэш, Если мы будем для всех данных брать уникальный хэш, то тогда мы попадаем в тот вариант, где мы не можем делать предсказания, потому что каждые новые данные приводят к каждому уникальному, грубо говоря, выходу. Поэтому мы должны как-то эти данные складывать, чтобы на основании их делать новые предсказания. Если мы делаем какую-то математическую операцию над ними, например, складываем, у нас получается сумма 30. Проблема в том, что эта сумма 30 может получиться для других данных, 10-10-10, 0-0-30 и так далее. Когда мы складываем это в следующий слой, например, сумма 30, и мы будем обновлять как-то в зависимости от данных, то эта 30 в зависимости от наших первых данных может давать и 0, и 1. Здесь может наступать неопределенность. Почему мы получили другой результат? И если этот результат включает все остальные, на одном лишь результатике мы не можем точно сказать, какой из факторов влиял на этот результат. То есть это было или 10, или 5, или 15. И, грубо говоря, это простая математическая проблема, которая как раз от этого, когда делаются системы, отталкивается. Веду я к тому, как это работает. Обновляем ли мы только родители или обновляем ли мы вот так всех детей? И, грубо говоря, как... Просто вероятность на этих моделях, что мне не нравится, что каждый фактор имеет какой-то, грубо говоря, свой вес. И каждый какой-то фактор влияет. Как по мне, в реальном мире есть определенные факторы, которые влияют на определенный результат. Если, например, у нас какой-то фактор 15 в нашей сумме 30 иногда давал 0, а иногда 1, то мы этот фактор просто отбрасываем. Но если, например, фактор 10 всегда в сумме 30, он давал нам всегда правильный результат, то мы учитываем этот фактор как настоящий, на который нужно всегда смотреть, когда мы хотим сделать решение в зависимости от наших партнер-факторов. 

S06 [02:26:42]  : Ну, да, я бы здесь попелемизировал, но не буду. Давайте, если у нас есть еще... Времени уже совсем мало. Да, Николай, вот сейчас вижу руку. Да, давайте. 

S00 [02:26:53]  : Моя короткая, это по поводу альтернативного варианта. Неопределенность ситуации может выражаться не обязательно значениями вероятности и доверия, а может выражаться просто перечнем возможных вариантов. То есть вместо того, чтобы считать, что у нас лебедь является белым с вероятностью 0 там и черным с вероятностью 0,1. Мы говорим, что он может быть либо белым, либо черным. И принимать решение, исходя из того, что возможно и такой, и такой вариант, не оперируя конкретными значениями вероятности. Потому что в большинстве случаев на самом деле нам неважно значение. Мы пристёгиваем ремень безопасности не потому что мы знаем точно вероятность аварии или спасения, а потому что мы знаем, что это полезно. И масса других таких примеров тоже. Кошка ловит мышку независимо от вероятности того, что она ее поймает, когда она голодная, и она ее совершенно не ловит, вне зависимости от вероятности поимки, когда она сытая. То есть вполне возможно я пытаюсь это реализовать. Рациональное принятие решений, которое учитывает разные возможные варианты, но при этом не использует вероятности. Это полезно бывает по одной очень существенно и недооцениваемой обычной причине. Реальные ситуации описываются очень большим числом параметров. Когда мы принимаем решение для этой конкретной ситуации, мы должны, если мы используем вероятности, эти вероятности как-то накопить заранее. Но в силу большого количества параметров у нас появляется большое количество разных ситуаций, для каждой из которых у нас нет статистики. И тем более мы должны принимать решения в ситуациях, в которых мы не были раньше. То есть при полном отсутствии информации. И вот для сложных ситуаций мы будем практически постоянно в этой такой обстановке принимать решения до тех пор, пока мы не выучим environment, если он остается стационарным. Поэтому даже если мы диагностные оценки используем, то мы должны использовать все равно запасной вариант принятия решений в тех случаях, когда у нас информации нет. У меня все. 

S13 [02:30:06]  : Я коротко замечу, что под вашу постановку задачи, которую вы только что описали, это просто тика в тику теория функциональных систем, как она работает. 

S06 [02:30:18]  : Отлично. Нет, Александр, слушайте, мы уже два с половиной часа. 

S02 [02:30:23]  : Я как раз по практической. Прямо ответ. Значит, смотрите, как я решаю вопросы, которые были поставлены. Прежде всего, с вероятностью. Здесь с чем-то сочетается с подходом Микола, что нужно записывать факты. Просто факты, какие есть, которые доступны. То есть в граф записываются все поступающие данные и записываются в том виде, в котором они поступили. И если нужна вычислить вероятность, то можно вычислить ее уже потом. не сразу ее высчитывать, а пройтись по графу, получить данные, в каких ситуациях, в каких контекстах были получены какие факты и разделить работу с данными от аналитики. И второй момент. что принципиально я считаю, это разделение классификации, работу с теорией множества, с различными классами и подклассами от деятельности. То есть Микола тоже правильно говорил, что когда мы действуем, мы никогда не думаем, что заяц это животное, а волк там млекопитающее. Это лишние данные, которые навязаны у нас в логике сразу же. И мы с ними работаем. Они не нужны. То есть нужно слоя, которые работают с деятельностью, отделять от слоя аналитики логики. И этих слоев классификации может быть множество. У нас не может быть одна классификация. Для одного случая одна классификация, другая, третья классификация. И поэтому совмещение всего этого – деятельность, расчет вероятности и расчет логики в один слой – это сильно нагрузочно. И третий пункт. Есть множество областей, в которых работают параллельно разные модели над одинаковыми данными. То есть кто-то слушается Каунта, кто-то Гегеля. У них разные модели, и они работают адекватно по своим представлениям по моделям. Поэтому нужно разделять еще по предметным областям, по кластерам, и даже в одном предметном области можно иметь несколько плохо пересекающихся кластеров. И потом по работе этих кластеров опять же получить новую вероятностную модель, новую статистику, новую аналитику. Не нужно все сваливать в одну корзину. Это подход, который уже работает. Еще один момент. Это субъектность подхода. Каждый факт, который фиксируется, нужно знать, что его фиксирует, какой датчик зафиксировал, какой человек зафиксировал. Нельзя пытаться совместить различные точки зрения. Их нужно все сохранить отдельно. Поэтому каждый факт должен сохраняться со своим субъектом, который его зафиксировал. Игорь, я не отклонился от ответов точных? 

S06 [02:33:25]  : Нет, не отклоняюсь. Мне просто казалось важным, чтобы Юрий какой-то фидбэк получил. 

S02 [02:33:30]  : Да, я бы его дал. Извиняюсь, что не дал сразу. Вернее, дал, но не так четко. 

S06 [02:33:34]  : Отлично, спасибо. Коллеги, у меня предложение заканчивать, потому что времени уже 20.30 по Москве. Я понимаю, что все могли бы еще высказаться, но давайте закончим. Давайте дадим докладчику последнее слово. Доволен он, недоволен этими результатами, фидбэком и прочим. 

S13 [02:34:00]  : Ну, моя статистика как бы из одного выступления на семинаре очень положительная. Мне на фоне предыдущих выступлений моих же все понравилось, которых не было. Не знаю, очень продуктивная дискуссия на самом деле, то есть были точки зрения. Мне понравилось, что есть моменты, которые пока слушаешь, особо непонятно, но при этом какая-то пища на то, чтобы, условно говоря, перед сном подумать, она закладывается. И, возможно, это какие-то вещи, которые будут партиться еще там некоторое время. То есть, ну, правда, фидбэк очень разнообразный, интересный. Я очень рад, что было внимание. Больше всего я рад тому, что я все-таки донес, потому что фокус-группа понимала куда меньше, и вопросы были менее посуществующими, вот я сейчас услышал. Не знаю, я чувствую, что… моя задача выполнена. my job here is done. чем пришел, то донес. этому очень рад. 

S06 [02:35:01]  : со своей стороны тоже могу сказать, что мне кажется, что было понятно, хорошо изложено и достоинством изложения было еще и то, что мы увидели как некие особенности этой системы, так стали понятны ее ограничения, возможные недостатки. Это полезно очень для собственного понимания мира и моделей, какие бывают модели. И в этом плане я лично у себя такую галочку поставил в списке того, что можно было бы сделать, но что я, например, не буду делать. не мое направление, но было интересно. 

S13 [02:35:40]  : Да, тоже добавлю маленькую галочку. Как обычно это бывает, было интересно защищать систему Апологетом, которой я не являюсь. 

S06 [02:35:50]  : Антон, сделаешь финальную ремарку? 

S03 [02:35:55]  : Финальная ремарка. Спасибо докладчику, спасибо модератору, спасибо участникам. до новых встреч. 

S06 [02:36:05]  : всем спасибо. 

S03 [02:36:06]  : всем пока. 







https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
