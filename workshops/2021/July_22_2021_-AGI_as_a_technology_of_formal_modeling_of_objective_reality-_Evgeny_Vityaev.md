## 22 июля 2021 г. - AGI как технология формального моделирования объективной реальности  — Евгений Витяев — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/sKbXEPbaUSk/hqdefault.jpg)](https://youtu.be/sKbXEPbaUSk)


Суммаризация семинара:

Семинар посвящен теме AGI (искусственного общего интеллекта) и технологии формального моделирования объективной реальности. Основной акцент делается на разработке систем, способных к маркетинговому анализу и анализу спроса и предложения, а также на построении графиков распределения цен.

Основные идеи

- Необходимость структурирования данных для маркетингового анализа.
- Важность пересчета одних единиц измерения в другие для анализа цен.
- Проблематика работы с вероятностными данными, содержащими ошибки.
- Пример задачи ритейла, где необходимо отслеживать поступление, наличие товара на полках, продажу и необходимость дополнительной доставки.
- Проблема в определении потребительских корзин из-за множества наименований товаров.

Ключевые концепции

- Система шкалирования и её применимость к большинству физических законов.
- Болезнь на математике, о которой говорится, но подробное описание отсутствует.
- Трейдинг как область, где шкалирование не используется из-за упорства на точках и порядке между ними.
- Логарифмирование экстремального вида физических законов.

Детали

- Использование антологии в задачном подходе для формирования предмета исследования.
- Пример с мотивами ДНК, где обнаружены статистически значимые зависимости между мотивами.
- Применение системы Discovery к финансам, где важен день недели для прогноза.
- Примеры анализа данных из финансового ряда для обнаружения сигналов, похожих на технический анализ.

Результаты и выводы

- Расширение формализации процесса познания до формализации процесса формального моделирования объективной реальности.
- Интеграция моделей мышления и мышления денег в рамках единого формализма.
- Важность предметной области для задания предмета исследования и антологии, которая определяет взгляд на объекты предметной области.




S02 [00:00:03]  : Коллеги, всем добрый вечер. Сегодня у нас снова Евгений Евгеньевич Витяев выступает. Вообще у нас за последние полгода было достаточно много интересных докладов по поводу того, что такое мышление, что такое моделирования. И достаточно интересные мысли были высказаны разными участниками. Мне особенно понравилось то, что рассказывал Александр Балдачев, то, что рассказывал Александр Кабанов. Но, пожалуй, сегодняшний доклад интересен тем, что не только мысли интересны, но и что эти мысли отражены в формальной математической модели. И не только отражены в формальной математической модели, но еще и отражены в большом числе публикаций и определенным числом практических реализаций и практических применений в различных проектах. Поэтому, Евгений Евгеньевич Витяев, пожалуйста, вам слово. 

S01 [00:01:07]  : Да, ну, слышно хорошо? Да-да-да, пожалуйста. Мой доклад называется EJ как технология формального моделирования объективной реальности. Но, по сути дела, этот доклад является продолжением доклада, который здесь ниже написан, математическую модель отражения мозга в реальности. И в этом докладе было рассказано, что мозг путем обнаружения причинных связей и формированием с помощью них клеточных ансамблей отражает естественную классификацию внешнего мира, которая, как я покажу в этом докладе, тоже является некоторым законом внешнего мира. и отражает в виде иерархии естественных понятий. Кроме того, в том же докладе было показано, что отражением причинных связей можно моделировать функциональные системы и таким образом в целом моделировать понятия когнитома. В данном докладе я хочу расширить эту формализацию как технологию формально моделирования объективной реальности, но расширить ее до формализации процесса познания, который по идее также является задачей AGI. На самом деле, еще в одном докладе, а именно задачный подход как логика вероятностной AGI, я рассказывал примерно в одном и то же формализме, немного более широком, чем обнаружение причинных связей, хотя на самом деле это расширение является минимальным. Я рассказывал, как задачный подход в рамках единого формализма на самом деле интегрирует моделирование когнитивных функций и решение задач. Но отдельно в этом докладе я на формализации процесса познания не останавливался. Поэтому в данном докладе я сконцентрируюсь на том, что в рамках опять же задачного подхода и в том числе совместно с моделированием когнитивной функции можно одновременно и формализовать процесс познания. То есть в результате этот доклад сцементирует все предыдущие и даст достаточно такой развернутый процесс формального моделирования объективной реальности. На самом деле, это опубликовано уже Все эти материалы, о которых я буду рассказывать, в основном были опубликованы вот в этой монографии. Извлечение знаний из данных, компьютерное познание и моделирование когнитивных процессов, которые изданы в МГУ. И по ссылке ниже эта монография скачивается, как PDF-файл. Поэтому, если что-то будет непонятно или будет потребоваться какие-то дополнительные материалы, то эту монографию можно скачать и посмотреть. Но для того, чтобы начать спознание реальности, все-таки для этого надо задать некоторую предметную область. Потому что не задав предмет исследования, который задается антологией предметной области, мы не знаем, что мы, собственно, должны познавать. Антология предметной области специфицирует множество рассматриваемых объектов, связи между ними, систему понятия и свойств объектов. В этом случае предмет исследования и антология определяют взгляд или точку зрения, с которой рассматриваются объекты предметной области. Например, человек может рассматривать совершенно различные точки зрения, физиологии, психологии, скелета и так далее. Для осуществления процесса опознания необходимо понимание и интерпретация человеком предметной области и ее онтологии. Это является необходимым условием. Понимание и интерпретация человеком предметной области и ее онтологии дает информацию и знание о предметной области. И как раз является определение в том числе информации для информационных процессов. Поэтому, если мы хотим познавать предмет новости, мы должны понимать и интерпретировать те знания, которые есть о предметной области. Информация о предметной области состоит из восприятия и интерпретации человеком антологии предметной области и ее объектов. В результате интерпретации мы получаем знания предметной области. Знания, опять же, это воспринятая, осознанная информация. Но применительно к данным, это означает, что человек воспринимает в данных ту информацию, которую может проинтерпретировать в системе понятия предметной области. Но оказывается, что уже вот этот пункт, он не всегда выполняется, более того, он даже, как правило, и не требуется, что является на самом деле большой ошибкой, как я покажу. Потому что сами по себе числа, хранящие базу данных, смысла не имеют. В физике для этого специально вводится понятие размерности. 5 метров, 5 литров, 5 килограмм, которое определяет как раз допустимые математические действия с этими величинами. Поэтому на самом деле смысл величин определяется некоторыми шкалами. Например, шкала номинований, она задается на некотором множестве объектов, и есть отношение равенства или отношение эквивалентности двух элементов. И тогда мы объектам присвоим некоторые имена, которые либо совпадают, либо не совпадают. Шкала порядка, в ней на множестве объектов заданы некоторые отношения порядка, которые порядывают эти элементы. Шкала интервалов определена на интервалах AB, например, экспертные близости или похожести объектов AB. Шкала отношений, большинство физических величин измеряется в шкале отношений. Эти шкалы должны быть проинтерпретированы в антологии предметного области, а это означает, что вот эти отношения и операции, они обязаны быть проинтерпретированы в антологии предметного области. Все это довольно детально исследуется в теории измерений, но дело в том, что последняя книжка, которая по теории измерений была переведена в 1976 году. После этого по теории измерений мало что переводится, и причина это тому, что было обнаружено, что методы машинного обучения не инвариантны относительно допустимых преобразований шкал. Что такое допустимые преобразования шкал? У каждой шкалы есть группа допустимых преобразований, которая определяет наш произвол в приписывании числовых значений величинами. Шкалу именования объекта мы можем обозначить как 1, 2, 3, 4, 5, а может быть 3, 4, 5, 6, то есть любыми натуральными числами. Шкала порядка, например, имеет в качестве допустимого прообразования группу монотонных отображений. Это значит, что значение величины мы можем любым монотонным образом изменять, при этом сама шкала не изменится. Физические величины, например, измеряются в шкале отношений. Единственное, с точностью до выбора единицы измерения. Так вот, оказывается, что методы машинного обучения за некоторым исключением, редким исключением, не инвариантны относительно допустимых преобразований шкал. Но как результаты по теории измерения не переводятся, так и опять же, считается, что такой проблемы нет. То, что, например, мы нейронными сетями взяли данные какого-то пациента, посчитали и сказали, что нет, ему надо делать операцию. Потом переписали его, так сказать, давление из одних единиц в другие, температура из одной шкалы в другую, рост в другую единицу и так далее. Преобразовали шкалы, запустили ту же самую уже обученную нейронную сеть, получили другой результат. И это на самом деле верно для большинства методов машинного обучения. На самом деле вот этот дефект как раз и выявляет тот факт, что методы машинного обучения используют в своей работе те понятия и те математические действия операции, которые не интерпретимы, интерпретируемой матологии предметного области. А что это означает? Что те функции, с помощью которых они описывают полученные результаты, аппроксимационные функции регрессии, еще какие-то, так сказать, классы гипотез. Они в этом случае используют некоторые операции, которые неинтерпретимы в антологии предметного области. Это означает, что конечный пользователь, тот же самый врач или агроном, он не в состоянии полученную форму или полученный класс или полученную регрессию проинтерпретировать в своих терминах. Поэтому на самом деле методы машинного обучения, они не обнаруживают знания в том смысле, что знания должны быть интерпретируемы в антологии предмета новости. Но что они на самом деле делают? Они аппроксимируют данные с требуемой точностью. Причем в этом случае не спрашивается, как они это сделали. Но если требуемая точность аппроксимации достаточно, считается, что задача решена. Поэтому в этом случае надо очень хорошо понять, если мы занимаемся Проблемой познания, то методы машинного обучения нам для этого не подходят, с помощью них мы не можем обнаруживать знания в данных, которые бы были интерпретируемы, осмыслены в нашей шкале. В частности, это довольно детально исследуется в теории измерения. Основное условие теории измерения – числовые представления величин определяются алгебрическими свойствами эмпирических отношений операций, определенных на объекты и предмет на области. Вот, например, большинство физических величин является экстенсивными величинами, которые определяются такой следующей алгебрической структурой, где для величин заданы отношения порядка и некоторая эмпирическая операция. Для длин, например, это стуковка двух длин, дающая более длинную длину. Для массы – это совместно взвешивание двух объектов, когда мы получаем объединённую массу. Для скорости – это измерение скорости в двух двигающихся относительно друг друга системы измерения. И распространяя через физические законы вот эту операцию на другие величины, практически все физические величины описывает следующая система – аксиома. Для этих величин, например, для длин, определен слабый порядок. Определена ассоциативность, что стыковать длины можно в разном порядке. Определено то, что если одна длина меньше другой, то при стыковке справа и слева любой другой длины не меняет это отношение порядка. Ну и, наконец, как всегда, в теории измерений нужен некоторый вариант аксиома Архимеда. В данном случае он звучит так, что любых x, y, z, u, если x меньше y, то найдется такое n, которое делает это различение x, y столь большим, что nx плюс z и ny плюс u, все равно это отношение порядка сохраняется. Так вот, в теории измерения делается все корректно и доказываются специальные теоремы, которые показывают, а как мы получаем числовые представления величины. Нам доказывается, например, такая теорема для числового представления экстенсивных величин. Алгебрическая структура. которая является экстенсивной структурой, для нее существует числовое представление в виде сильного гомоморфизма, отображающего множество величин в действительные числа, такое, что для любых двух величин А, Б, а меньше либо равно b, тогда и только когда числовое значение а меньше либо равно числового значения b. Например, мы каждую длину отображаем в то значение, которое измеряется линейкой. Так вот, числовое значение, полученное линейкой на объекте а, меньше либо равно числового значения, получено линейкой на объекте b. А вот эта эмпирическая операция, она переходит в операцию сложения. И в этом случае мы получаем действительно точное понимание. Во-первых, как осуществляется это числовое отображение. Во-вторых, в этой же теории еще показывается, что вот это отображение, оно единственное с точностью до выбора единицы измерения. Оно еще показывает, а каков произвол в построении этого числового представления. И, например, показывает, что для физических величин это шкала отношений. Они единственные с точностью до выбора единицы измерения. Перейдем теперь к закону. Для того, чтобы, так сказать, познавать предметную область, нужно обнаруживать законы. Только опять же, на самом деле, методов машинного обучения нет. Методов, которые обнаружат законы в правильном смысле. Что значит правильный смысл? Что на самом деле методы машинного обучения есть? В направлении scientific discovery, которое, так сказать, вроде как развивается до сих пор, хотя там исследователей не так много, поскольку на самом деле, так или иначе, в этом направлении теорию измерения не используют. Хотя именно теория измерений не даёт настоящее понятие закона. Но, тем не менее, делается вид, что они в каком-то смысле закона обнаруживают. Хотя это ни в коем случае не законы. Я сейчас объясню почему. Считается, что если мы аппроксимируем некоторое множество точек достаточно точно, то мы обнаружили закон. В Scientific Discovery для этого вводится понятие простоты этой функции, чем проще эта функция, тем больше оснований считать это законом, но все это туфта, совершенно не имеющая отношения к настоящему понятию закона. Как же на самом деле закон обнаруживается? Для этого специально в теории измерения разработаны уже системы Аксиом для законов. Одну из систем Аксиом я приведу. Сейчас в теории измерений написан такой фундаментальный термитомник в теории измерений. И как раз в первом томе, достаточно толстом, найдена система аксиома основных физических законов. Так вот, для наиболее простых законов, закона Ньютона, Ома, Гука, как раз и найдена система аксиом, так называемая аддитивно-соединительная структура. Как она выглядит? Пусть мы имеем некоторые функции, например, вот здесь мы аппроксимировали функцию y равно f от xz, которая связывает величины y и x и z. Мы от этих величин x, y, z будем требовать только то, что для величины y интерпретируемы отношения порядка на действительных числах, а для величины x, z только равенство. И вот если для этих величин выполнена следующая система аксиом, которое гласит следующее, что значение функции от xz1 больше либо равно значение функции от xz2 то это будет верно и для любого из четырех, которые можно подставить вместо x. Вот эта довольно длинная аксиома – это аксиома Томпсона, но смысл ее я расскажу дальше. Третья аксиома – это аксиома разрешимости для любых четырех чисел. Если имеют место равенство функции, то это равенство разрешимо относительно любого из четырех аргументов. нет ревиальности этой функции, существует значение, для которого функция имеет различную, ну и опять же определенный вариант аксиома Архимеда, который в данном случае выглядит так, что если у нас есть z1, z2, неравные между собой и на х ограничена последовательность х таких, что x1, z1 равно f x2, z2 и x2 мы теперь подставляем сюда, z1 равно f от x3, z2 и так далее. Здесь у нас x1, x2, x3, x2, x3, x4 и так далее. Это последовательность ограничена. Теория измерения доказывается, что для любой такой функции, которая удовлетворяет вот этой системе аксиом, то есть удовлетворяет систему аксиом аддитивных соединительных структур, существуют взаимооднозначные функции, перешкалирующие величину х, перешкалирующие величину у, а точнее находящие истинные и правильные для них шкалы. И монотонную функцию φ, которая перешкалирует величину у, Такую, что уже перешкалированные величины связаны между собой простой функциональной зависимостью через сумму. y равно x плюс z. Перешкалированные. Это означает, что если, например, мы возьмем вот эту функцию, которая с точки зрения направления Scientific Discovery будет считаться законом, но ничего подобного. Мы возьмем величины x, y, z из этой функции, проверим, приведена ли на нами система Axiom, и если она будет выполнена, мы таким образом перешкалируем величины x, z и y, что у нас она окажется плоской. поверхности. И вот это уже будет закон, а не та туфта, которая, так сказать, рассматривается в направлении scientific discovery. Так вот, оказывается, что методов, которые обнимут в такие достаточно сложные системы аксиом, их не так много. Они исследуются как раз в некоторых других томах по теории измерения, но, так сказать, это множество. Аксиом недостаточно полностью покрыт. В этой же книге, в томе Foundations of Measurements, переводится более сложная система аксиом для так называемых простых полиномов. Но такого рода системы Axiom, не все, но некоторые из них, могут обнаружиться системы Discovery, о которых я уже рассказывал, которые в состоянии обнаруживать такого рода условные зависимости. Так вот, есть еще одна теория, а именно теория физических структур, которая обнаруживает законы, физические в том числе, но не только физические, в точном и правильном смысле. И этот смысл на самом деле согласуется со смыслом теории измерения. Об этом я расскажу немного дальше. Но сначала для того, чтобы показать, каким образом получается это самое функциональное зависимое, чтобы понять сам процесс. А он на самом деле достаточно простой, но нетривиальный. Я как раз расскажу о процедуре шкалирования, одновременного шкалирования x, z, y, так, чтобы у нас получилась как раз простая функциональная зависимость. По оксиоме 4 существуют такие четыре точки, что значение функции в них не равно. То есть значение функции в этой точке, в этой точке не равно. После этого в силу третьего аксиома, если мы возьмем одно значение x и два значения здесь, это x0, x1, у нас найдется вот это значение z1, такое, что функции φ в этой точке будет равна значению функции φ в этой точке. Проведем здесь линию. Далее мы возьмем, мы нашли z1, присвоим ему значение 1. Здесь мы x присвоили значение 1. Здесь на их пересечении мы присвоим вот этой точке значение 2. Опять же по оксиомой разрешимости для этой точки и зная вот эту ось, мы найдем вот эту точку, где значение функции будет равно. Также мы разрешим вот это значение относительно вот этих двух переменных и вот этой переменной. Найдем z2, присвоим ему значение 2. Теперь мы возьмем такую точку z2 x1 и z1 x2. 2 плюс 1 и 1 плюс 2 равно значении 3. То есть в этих точках значение функции тоже должно совпадать. На самом деле это регулируется как раз той самой второй аксиомой, сложной, о которой я пока не говорил, но смысл ее выяснится дальше. В этой аксиоме говорится следующее. Если у нас есть вот такая фигура, вот такая вот фигура значений, то тогда вот эти значения равны между собой. У нас эти значения равны и равны 3. Мы по разрешимости находим здесь значение x3, здесь значение z3, а y присвоим тоже значение 3. Мы тем самым получим, так сказать, процедуру шкалирования, одновременно шкалирования трех величин, которые дает нам как раз закон их Правильно в смысле, когда шкалы измерений, они взаимосогласованы между собой. тогда это есть закон. Но есть еще одна теория, а именно теория физических структур, в которой показано, что все фундаментальные физические законы, кроме статистической физики и физики элементарных частиц, а также входящая в них величина, могут быть выведены из принципа феноменологической симметрии. Вот здесь вот эта книжка, она около тысячи страниц, в которой выводятся основные физические законы и физические эволюции из единого принципа, очень простого, о котором я сейчас сформулирую. Принцип состоит в следующем. Пусть у нас есть некоторое множество m и его элементы i, и некоторое множество n и его элементы α, в произвольной природе. И у нас есть некоторая измерительная процедура, которая в взаимодействии объектов из M и N ставит некоторые числа. Например, для закона Ньютона у нас есть объекты и пружинки. Если мы объектом сожмем пружинку, то она даст ей некоторое ускорение, которое мы можем измерить и замерить некоторым числом. Это число мы обознаем как а и альфа для объекта и пружинки альфа. У нас получится довольно большая матрица, в которой будут всевозможные ускорения, полученные объектами из M, пружинками из N. Что такое принцип феноменологической симметрии? Так вот, на множествах m и n задана физическая структура рамка R-S. Если для произвольных R-S чисел из вот этой матрицы, стоящих на пересечении любых R-строк и любых S-столбцов, связаны функциональность некоторой, неизвестной нам, вид функциональной зависимости не задается. но требуется, чтобы она была равна нулю для каждого выбора r-строк и s-топцов. Так вот, оказывается, можно получить совершенно удивительный результат. Почему он может получаться, я чуть-чуть объясню немножко дальше. А именно, это было получено учеником Кулакова-Михаличенко, он за это получил докторскую степень, что вот это уравнение, в котором функция f не определена, на самом деле имеет ровно четыре решения. И более того, все физические законы, которые я упоминал, они описываются одним из этих решений. А именно, для ранга R равно S равно 2, это, в частности, закон Ньютона Ома Гука, ту систему всема отитийных соединительных структур, которую я приводил, она как раз соответствует вот этому рангу, и можно точно строго доказать, что эти законы, так сказать, взаимно переводятся друг к другу. Так вот в этом случае для рангов R равно S равно 2. А и альфа – это есть и некоторая монотонная функция от x и t и сигма альфа, то есть мы можем построить некоторое числовое представление для величины x, некоторое числовое представление для величины альфа. И минус 1 будет давать нам величину y. Такое, что вот эта самая функция, здесь она равна 0, она будет в данном случае иметь вот такой вид. Для рангов r равно 4, s равно 2 функция имеет более сложный вид, и этот закон порождает уже раз, два, три, четыре величины, которые связаны между собой такой физической зависимостью, для которой та самая функция f Имеет уже вот такой вид. Для ранга r равно s больше либо равно 3, а альфа уже имеет φ минус 1. это обратная функция коллектора монотонных функций, от вот такой суммы, где здесь уже вводятся и могут быть определены, на основании а и альфа могут быть определены целая серия физических величин, которые в совокупности приводят к нулю вот такую функцию. Вот это еще один, второй вид варианта результата для r равно s больше либо 0.3, вот такой вот оператор. Для r равно s плюс 1 больше либо 0.3, мы имеем вот такую функцию, которая приводит к нулю, тождественно равно нулю вот такой определитель. Для r-s больше либо равно 2, кроме случая r-4, s равно 2, физических структур не существует, а φ – строго монотонная аналитическая функция одной переменной. Эта монография на самом деле доступна, то есть она у меня есть, если кого интересует, я могу ее выслать по электронной почте. Так вот, вот эта книжка, она была написана на русском физикам Кулакова. К сожалению, теория физической структуры не очень признана в России. Ей продолжает заниматься Владимиров, зав. лаборатория Московского университета, зав. лаборатория теоретической физики. Он продолжает этим заниматься. Но дело-то в том, что на самом деле это не столько теория физической структуры, Это теория обнаружения законов в некоторых предметах новости, законов вообще, а не только физических структур. И как раз имея эту книгу на руках, которую мне подарил Кулаков, я донес до как раз специалиста по теории измерений, занимающегося как раз этой теорией измерений. Но перед этим я могу проиллюстрировать, как, собственно, физическая структура ранга 2.2 дает ту самую аксиому Томпсона, которая является ключевой в процедуре скалирования. Что значит физическая структура ранг 2-2? Мы имеем произвольные две величины здесь из множества m, произвольные две величины здесь из множества n, и на их пересечении мы возьмем четыре величины. И они связаны всегда одной и той же функцией, которая, так же известно, равна 0. На самом деле, эту функцию можно разрешить относительно одной из переменных. Это функция аналитическая в тех изложениях, которые есть. В этом случае мы возьмем вот эти четыре величины и возьмем еще один квадрат, еще четыре величины, на которых тоже эта самая функция, так же известно, равна 0. Так вот, у нас оказывается, что вот в этом квадрате вот это значение равно этому. этого квадрата. А это значение равно значению этому и этому этого квадрата. То есть все три значения в этом квадрате и в этом квадрате, они совпадают между собой. Поэтому значение функции здесь будет одно и то же. И будет выполнена та самая аксиома Томпсона, которая фигурирует в системе аксиом аддитивных соединительных структурах. На самом деле, мной была доказана строгая теорема, что система максимально-интенсивных структур вытекает из принципа феноменологической симметрии. Поэтому, несмотря на то, что вроде бы как функция совершенно неизвестна, то есть здесь она на нулю, о ней ничего неизвестно, но участвовать в таких вот процедурах скалирования, которые в конце концов дают нам закон, это оказывается возможно. Так вот, эту самую книжку Кулакова мне удалось передать лидерам теории измерений Дункану Льюсу, который как раз является одним из авторов вот этой книги и всего трехтомника этой книги, на конференции в Паде в Италии. Он, так сказать, не последний человек. Он получил национальную медаль науки, врученную президентом Буффоном в 2003 году. Но Дункан Дьюз русский не знает. Но в этой компании, которая там была, по теории измерений, есть Ахтибар Джафаров, который знает русский. Они взяли эту книжку Кулакова, их эта книжка заинтересовала, они между собой ее реферировали, и в конце концов они решили ее перевести на английский. А чтобы перевести ее на английский, нужно было сначала перевести некоторые базовые материалы. по теории физических структур. Но такой базовый материал написали в конце концов мы с Кулаковым и ученик Кулакова-Сименов, который как раз занимался не функциональным решением его уравнений, а алгебрическим решением его уравнений. И в конце концов мы написали статью об алгебрическом определении законов природы. Но, опять же, выясняется, что для алгебрыческого определения законов природы, для этого нет алгоритмов, которые это могут обнаруживать. За исключением некоторых вариантов, которые может обнаруживать система Discovery, о которой я уже рассказывал. Но теперь вернемся к тому, что есть метод машинного обучения, метод Knowledge Discovery и Data Mining. Так вот, оказывается, в методах knowledge discovery и data mining машинное обучение, которое работает с информацией, извлеченной из данных и представленной в виде положим, так сказать, некоторого уже, так сказать, системы типа RDF, которые извлекают именно отношения, имеющие смысл отношения в антологии предметного области, или в UML, где могут представляться информации, извлеченные из предметного области. Так вот, нет метода машинного обучения, который на этой информации работает. Поэтому нами был разработан свой оригинальный, реляционный, или, так сказать, онтологический подход, который во многих местах напечатан, в том числе и по-английски, в котором мы и говорим, что обрабатывать надо, обращаясь не к данным, а к той информации, которую мы извлекаем из данных и интерпретируем в онтологии предмет новости. И это у нас случай первый. Позволяет полностью извлечь, интерпретировать информацию из данных, используя онтологию предмета новости. Кроме того, обнаруживает производные классы гипотез, в терминах извлеченной информации, в том числе и те, которые могут обнаруживать положение решающей деревни, которые могут быть интерпретируемы. Кроме того, обнаружить полное множество знаний в основе изученной информации. Но это отдельные теоретические результаты, о которых я как-то упоминал, что можно сформулировать максимально специфические причинные связи и знания, которые решают проблему статистической двусмысленности, и предсказания по ним непротиворечивы. Можно обнаруживать максимально вероятные условные связи. И для этого можно разрабатывать одну систему Discovery, которая в этом случае а в случае извлечения именно знаний, а не аппроксимации, она аппроксимирует все остальные методы машинного обучения, поскольку она может использовать любую информацию, которую можно извлечь из данных и представить в термоконтологии предметного области, проверять экспертные или другие роды гипотезы, которые можно сформировать в термоконтологии предметного области. и целенаправленно использовать нужную интерпретируемую информацию, и в том числе ее использовать для предсказания. Далее приведу примеры применения системы Discovery, которые никакой другой метод машинного обучения решать не могут, по той простой причине, что ту информацию, которую мы используем, и которую мы взяли как раз у эксперта предметной области, и который сказал, что для решения этой задачи нужно использовать именно эту информацию, а не какую-то другую. Другие методы машинного обучения эту информацию использовать в принципе не могут. Так вот, есть, например, одна участвованная задача, не решенная до сих пор, это анализ регуляторных районов генов и определение этих регуляторных районов генов. Мы пошли к экспертам института цитологии и генетики и спросили, а для решения задачи какую информацию надо использовать? Они говорят дистанцию между сигналами на генетической последовательности, принадлежность интервалов, смена ориентации этих сигналов и повторение этих сигналов. В результате мы сформулировали гипотезы в терминах вот этой онтологии. в виде так называемого комплексного сигнала, где здесь на генетической последовательности могут быть разные либо нуклеотиды, либо некоторые мотивы, либо могут быть сайты связанные или другие, выделенные некоторые элементы генетической последовательности. Они могут находиться между собой на определенном варьировании подробно расстояния, Этот сигнал может рекурсивно уже использоваться в некотором другом сигнале, который может использовать этот сигнал, еще какой-то сигнал, находящийся на каком-то расстоянии между собой. Эти сигналы можно инвертировать, и кроме того, эти сигналы можно повторять, опять же, с некоторым варьируемым элементом повторения. Так вот, система Discovery была обнаружена, положим, это результаты реального счета, обнаружена на мотивах, так называемых 15-буквенных мотивах, которые были обнаружены другой программой и была произведена соответствующая разметка. то есть антологическая разметка и генетическая последовательность этими мотивами. Такой программа обнаружила, что на расстоянии, которое варьируется от 0 до 10, между вот таким мотивом и повторяющимися сигналами с повторением от 2 до 5 раз следующего мотива. Вот примеры некоторых других сигналов. Вот это сигналы, которые обнаружены уже в регуляторном районе гена. Вот это start transcription, это генетическая последовательность. Программа обнаружила, что вот эти мотивы, которые находятся между собой на определенном, варьированном между собой расстоянии, они значимы, статистически значимы, увеличивают вероятность прогноза того, что это есть регуляторный район. Это реальные данные. Также мы попробовали применить это к финансам. И для этого мы снова обратились к некоторой антологии. Мы посмотрели некоторую информацию, статьи и обнаружили, что день недели важен для прогноза. И для программы мы задали такой гипотезы, по дню недели, например, пятница три недели назад, подъем цены до среды две недели назад, потом снова падение до понедельника текущей недели, то после этого должен быть подъем через пять дней. Такие закономерности были обнаружены. Это все было опубликовано потом в книжке Data Mining and Finance, наши эксперименты. Но мы потом перешли к более сложным финансовым экспериментам, а именно мы промоделировали так называемую форму технического анальза. Есть толстые книжки по форму технического анализа, в которых говорится головоплечи, пила или треугольник и так далее, которые говорят, что есть такая-то фигура, то после этого можно сделать некоторый параметр. Мы задали задачу, а что бы нам алгоритмически не обнаружить все эти фигуры? Для этого мы взяли такую информацию из финансового ряда. Пики максимум минимумы и взаимное расположение их между собой с точностью до отношения порядка. Можно ли в этом случае прогнозировать на 5 таймфреймов вперед. Вот, например, сигнал, который был обнаружен. Он похож на сигнал типа пилы, что если был такой минимум, а потом еще раз более сильный минимум, а потом два раза подряд некоторый подъем, то снова будет подъем. В результате программа обнаружила такого рода сигналы, и мы попробовали с помощью этих сигналов прогнозировать некоторые российские акции. В том числе вместе с компанией БКС, которая одна из ведущих в России, мы такие эксперименты проделывали. И некоторые результаты уже реальной работы системы у нас были представлены и некоторые клиенты им пользовались какое-то время, пока был определенный договор. Опять же, в книжке не только финансовой, в этой книжке, которая, вот эта книжка издана по-английски, но финансовые наши эксперименты, они описаны и по-русски тоже вот в этой же монографии. Таким образом, применяя методы обнаружения знаний, то есть систему Discovery. мы в антологии предмета новости можем обнаружить некоторое новость о знании. Кроме того, если вдруг системы Discovery обнаруживают некоторую систему аксиомы теории измерения, то в этом случае мы можем обнаружить закон, именно тот, который мы можем построить с помощью теории измерения. Таким образом, кроме того, мы можем с помощью анализа системы аксиомы проанализировать и найти систему аксиомы исходных величин. что тоже является некоторой задачей. В результате мы можем проанализировать наш предметный область и извеличить в него некоторую совокупность знаний. Вообще говоря, достаточно полные. Об этом есть отдельный теоретический результат, но это отдельный вопрос. В результате, если вернуться теперь к задачному подходу, и погрузить все это рассмотрение в задачный подход. А как я уже рассказывал, в рамках задачного подхода можно моделировать и в том числе и когнитивные функции. Но вернемся к понятию задачи. Задача определена в том и только в том случае, когда ее формировки присутствуют. Указание предметной области. Мы только что об этом говорили. Должна быть указана предметная область и предмет исследования, который задается в виде онтологии этой предметной области, который мог быть зафиксирован в виде модели. И та информация, которая извлекается из данных, тоже может быть записана в виде модели, в частности, в виде эмпирической системы. включая описание сигнатуры, в том числе антологии предметной области, структуру языка описания предметной области, опираясь опять же на антологию предметной области, набор терминов и понятий антологии, исходные данные, Мы в этом случае переписываем в терминах онкологии. Факты и знания, которые мы извлекли с помощью системы DSCiRE, мы тоже записываем в нашу модель и записываем в терминах онкологии. Таким образом, исходная база для дальнейшего оперирования с этими знаниями, она может быть сформирована как раз на основе этого подхода, о котором я только что рассказал. Но при оперировании знаниями нам, естественно, нужно с ними как-то работать, то есть задавать определенные вопросы и обращаться к ними с запросами. В этом случае в рамках задачи определяется запрос или вопрос, который сформулируется в задаче, относящейся к предмету новости, на который мы должны получить ответ. В этом случае ответ получается либо логическим выводом, либо этот ответ может формулироваться в виде некоторой гипотезы к данным, в виде некоторого запроса к системе Discovery, которая может уже пытаться обнаружить это знание в данных. То есть и индуктивно, и дедуктивно. Кроме того, должен быть определенный критерий удовлетворения запроса, то есть было определено, что действительно ли получен ответ на запрос или нет, чтобы был определенный критерий. Кроме того, в каком контексте следует искать ответ на запрос? Какую цель мы проследуем, решая задачу? Что мы ожидаем от полученного результата? Каковы последствия? И что делать, если ответ оказывается отрицательным? Кроме того, если мы ищем с помощью детективного вывода, или мы ищем необходимый нам ответ на запросы в некоторой модели, таких ответов мы можем найти несколько. поиска модели. И тогда нам контекст позволит выделить наиболее приемлемый, наиболее ожидаемый, наиболее лучший или с точки зрения когнитивных, наиболее значимый эмоционально или с точки зрения функций полезности ответ. Кроме того, но это уже отдельная тема, что эта спецификация поиска ответа на запрос должен быть еще осуществлен автоматически. Это делается уже в рамках более широких языков. Такие языки разработаны. Это язык 7 определимости или дельта 0 определимости. И тогда в рамках дельта 0 определимости доказывается теорема, что тогда поиск ответа на запрос будет осуществлен за полиномиальное время. То есть это отдельное исследование о том, как вычислить насложность решения задачи. И теперь вернемся еще к некоторому закону природы. которые на самом деле, как и законы природы, как и функциональные зависимости, опять же делаются совсем не то, что нужно на самом деле. Как и для законов, Настоящий закон обнаружился только в теории изменений, в теории физики, а не в направлении scientific discovery. Так и естественная классификация и систематика как закон. А то, что есть закон, это я сейчас покажу. Тоже для этого, так сказать, особо умедленно нет, за исключением, опять же, того, который мы разрабатываем. По этому поводу на самом деле был очень большой спор. В России, еще в бывшем Советском Союзе было целое направление и естественная классификация, которой возглавлял Кожар Владимир Леонидович. Он был при Госкомитете по науке и технике, поэтому он помогал устраивать конференцию на эту тему. Он выдвинул клич, что надо собрать литературу по естественной оптификации, сформулировать, что это такое, разработать соответствующие методы. Фактически, потом я ему рассказывал свой метод, он оказался единственным, который более-менее это все обнаруживает. Но в конце этого направления было большой съезд, где собирались естественные классификаторы и натуральные классификаторы, которые занимаются классификаторами обычной методной классификации при знакомом пространстве. Так вот, ни та группа людей, ни другая договориться не могли. Те, кто занимается обычным методом классификации, называли тех, кто занимается естественной классификацией методологами, не имеющими своих точных определений методов. А естественная классификация, они говорили, что вы занимаетесь искусственной классификацией, которая к естественной классификации не имеет вообще никакого отношения. И вы никакие законы в настоящем смысле не обнаруживаете. В результате этой конференции договориться так и не смогли, но что такое естественная классификация, все-таки была собрана такая литература, выдержки из тех работ о том, что такое естественная классификация, которая в результате собранной литературы была получена. Значит, это следующее определение. Смирнов. Таксономическая проблема заключается в индикации. От бесконечно большого числа признаков нам нужно перейти к ограниченному их количеству, которое заменило бы все остальные признаки. Вот когда мы строим классификацию естественных видов, копытный, рогатый, млекопитающий, у нас вот эти признаки есть индикаторные. То есть мы выбираем некоторое минимальное количество индикаторных признаков, по которым мы можем определить вид. Рудковский. Чем больше в числе существенных признаков схожие и сравненные предметы, тем вероятнее их одинаковые и в других отношениях. Понятное дело, чем больше, так сказать, признаков, в том числе индикаторных, у нас совпадает для одного и того же объекта, тем вероятнее, что и другие признаки и их значения тоже будут совпадать на этих объектах и, вероятно, принадлежащих одному и тому же классу. Чем больше общего утверждения объекта до этого может сделать классификация, тем наестественнее. Наиболее сильное определение дает любящих. Наиболее совершенной системой является такая, где все признаки объекта определяются положением его в системе. Чем ближе система состоит к этому идеалу, тем она менее искусственна. И естественно, следует называть такую, где количество свойств объекта, поставленных в функциональную связь с его положением в системе, является максимальным. Ниже я как раз и поясню, как получать такие наиболее совершенные естественные классификации. И определение Шрейдера. Это современный исследователь. В многообразии объектов, образующих естественную классификацию, можно обнаружить два типа закономерности. Первое. Закономерности, позволяющие на основании принадлежности объекта к некоторым естественным классам прогнозировать все остальные его свойства, то есть, например, по индикаторам прогнозировать все остальные свойства данного конкретного вида. И правило, показывающее, как деформируются свойства объектов перед переходом к смежным классам, то есть от вида к виду, например. Как получить, определить эту естественную классификацию, которая всем этим определениями удовлетворяет? Для этого сначала определим закономерную модель объекта. Для этого мы возьмем в виде такой модели Omega A – это множество значений всех понятий, признаков и величин, применимых к этому объекту и принимающих на нем определенные значения. ZA – это множество законов, закономерностей антологии, которые позволяют по значениям этих признаков и величин предсказывать их между собой. что если положим есть индикатор и не индикатор, то такие-то признаки примет такие-то значения. И вот эту модель мы обозначим как закономерную модель одного объекта. Можно принять закономерную модель класса объектов, но в этом случае мы возьмем просто-напросто такую модель, в которой у нас во множестве признаков, и свойств, и величин. Стоят только те величины и их значения, которые одинаковы для всех объектов класса. А среди закономерностей возьмем только те закономерности, которые входят в пересечение закономерностей, которые верны для всех объектов. То есть мы возьмем общие закономерности. Пронализируем критерии Смирнова и Рудковского. классы всегда значительно меньше. чем комбинации значений независимых между собой признаков. Для сотни классов может быть не более 7 независимых бинарных признаков, поскольку 2 в 7 равно 128. Если мы будем брать 7 различных комбинаций, 7 индикаторных признаков, то мы получим 128 видов. Это достаточно много, скажем так, средняя задача классификации. Но для ее определения троих всего семь. А признаков, которые могут измеряться на этих объектах, как правило, значительно больше. на порядок или несколько порядков больше. Это означает, что из этих индикаторных признаков мы можем предсказывать на порядок на 2 большее значение других признаков. Вот такого рода закономерности у нас достаточно много. Их число растет экспоненциально по отношению к числу признаков. Теперь попробуем найти признаки, из которых предсказываются все остальные признаки. и составляет в этом случае проблему индикации. Проблема индикации алгебраически означает, что мы ищем порождающую совокупность значений признаков. То есть мы ищем такой набор значений признаков в этой закономерной модели для этого класса. Такие, что по закономерностям из этого класса и по этим значениям индикаторных признаков предсказываются все остальные значения признаков объектов класса. Усложним определение систематика. Систематикой назовем такой набор признаков, уже признаков, а не значений признаков. которые будем называть системы образующие для совокупности классов, такую, что для каждого отдельного класса мы найдем свой набор значений этих индикаторных признаков, который одновременно станет для них порождающим. То есть по вот этому набору значений этих системы, образующих признаков, мы сможем предсказать все остальные значения признаков. И в этом случае задача построения систематики состоит в том, чтобы найти наиболее компактный информативный набор системообразующих признаков, которые в этом случае будут индикаторными. И систематика состоит в том, чтобы представить некоторым образом, например, таблицей изменения значений системообразующих признаков при переходе объектов одного класса к другому. То есть, чтобы получить естественную классификацию, По любящему нам нужно. во множестве объектов, которые разбиты на классы, класс 1, класс 2, класс 3, найти такие признаки среди всех остальных признаков, такие, что их значения, вот эти значения и вот эти признаки, эти значения будут системообразующими для объектов этого класса. По вот этим значениям этих признаков все остальные значения признаков этого класса будут предсказываться. Но для этих же признаков другие значения в другом классе тоже будут системообразующими. И уже по этим другим значениям снова будут предсказываться все объекты класса. А в другом классе эти признаки имеют уже другие значения, и по ним опять же предсказываются все объекты класса. Точно так же и для класса 4. В этом случае мы получаем систематику, которая сжимает информацию без потери. Почему без потери? Потому что она удовлетворяет требования любящего. То есть у нас вот эта вот большая таблица без потери информации схлопывается вот в такую таблицу, где у нас есть только классы, значения системы образующих признаки и их значения для каждого класса. В этом случае по положению объекта в соответствующем классе мы обнаружим его признаки для системы образующих признаков и по этим признакам предсказываем все остальные признаки этого же объекта. Изменение значений системы образующих признаков может уделять некоторому закону, который представляет собой систематику. Этот закон можно представить в виде некоторой закономерной модели, где S – это набор системы образующих признаков, а ZS – это закон систематики. S – это набор системы, образующий признаков, ZS – это, собственно, вот эта таблица. Это то, что дается систематике. Точно так же объясняется и определение Шрейдера, потому что закон S, вот эта таблица, это закон верхнего уровня, который определяется Шрейдером, а законы внутри каждого класса, связывающие между собой значение признаков, это значение первого уровня по определению Шрейдера. Таким образом, мы дали определение естественной классификации, которое этим определением удовлетворяет. Здесь, опять же, определение любящего, оно поясняется. И тогда систематик можно определить как набор, где есть множество систем образующих признаков, их закономерной связи, где есть некоторые таблицы или не обязательно таблицы, там таблицы могут быть треугольные или еще какие-то. И законы для каждого класса, определяющие взаимосвязь между значениями признаков. И задача построения систематики настоит в том, чтобы выбрать наиболее совершенную систему, объясняющую свойства строения объектов простейшим образом. Несмотря на субъективность выбора систематики, и на самом деле есть различные подходы к систематикам, есть разные естествоиспытатели, которые предлагают немножко различные систематики, у которых индикаторы при языке немного отличаются. Но тем не менее, они являются законом периода, потому что они позволяют сжать информацию до такой записи практически без потерь, потому что любые остальные значения восстанавливаются по закономерности. И поэтому такая классификация называется естественной. Искусственная классификация, она определяется так, что мы фиксируем некоторый совершенно конкретный набор значений признаков, и после этого мы разбрасываем объекты в разные классы в соответствии с тем, какие у них вот эти признаки отличаются между собой. То есть мы эту классификацию задаем заранее. а не ищем ее в виде некоторой порождающей системы признаков и в виде законов, связывающих их между собой. Но все эти рассмотрения я проводил в предположении, что разбиение на классы нам известно. Тогда такое построение можно провести. Но естественным испытателям разбиение объектов на классы неизвестно. у них задача принципиально более сложная. Нужно так разбить объекты на классы, чтобы потом построенными по ним закономерностными признаками сходились в некоторую систематику, у которой есть системообразующие признаки и совокупность индикаторных признаков. То есть поэтому вот эта задача обнаружения закона систематики является на порядок более сложной. Я на самом деле затрагивал эту тему, когда рассказывал, так сказать, о танонии. А Танони, когда он описывает, как он формирует так называемые концепты на основании нейронных ансамблей, он описывает это таким образом. Нужно найти с помощью интегрированной информации такую совокупность нейронов, интегрированной информации для которых максимально. Но как он это делает? Он перебирает вот эти, так сказать, связи между собой, добавляя и удаляя, так чтобы, так сказать, они давали, интегрируя информацию. То есть он работает, опять же, в очень сложной ситуации, как естественный испытатель. Ему нужно найти, так сказать, вот эти базовые показатели. На самом деле, как я уже показывал, так сказать, в своей работе необходимо ввести понятие, отправляться не от объекта. а отправляться от закономерностей. Как я показывал, используя вероятностные формальные понятия, отправляться надо не от объектов, а от признаков. То есть надо искать зацикленные между собой системы признаков. Это на порядок проще. И мозг именно использует это более простое решение. Но для этого решения необходимо было доказать то, что было доказано для вероятности формальной понятии, что такие, так сказать, циклические причинные связи, они логически непротиворечивы, то есть они могут действительно зацикливаться без противоречия, а не расползаться, так сказать, по мозгу, предсказывая, так сказать, силу противоречия, совершенно не имеющую отношение к делу. Так вот, на самом деле, для обнаружения естественных классификаций, мы построили алгоритм, который не ищет разбиения объектов на классы, а потом строит эти закономерности и потом ищет закон системы. Это невозможно вычислительно. Точно так же и этанония. Только на небольшие системы он может найти максимумы своей энтеропии. Это вычислительно невозможно. Мозг идет более простым, естественным путем. Они ищут зацикливающиеся причинные связи. Тот алгоритм естественной классификации, который одновременно является алгоритмом поиска естественных понятий, он как раз обнаруживает циклический замкнуть на себя. причинные связи, которые как раз и формируют эти классы. То есть таким образом программа, решающая эту задачу, она выглядит несколько иначе, но я об этом уже как-то немного рассказывал. Ну и, наконец, можно проиллюстрировать определение вероятностных формальных понятий и построение вот этих естественных классов как зацикленных на себя свойств объектов, которые позволяют обнаружить естественный класс в действительности и отразить его в виде уже некоторого естественного понятия. В виде цитаты Смирнова. Смирнов, последователь школы Леонтьева психологии, в своей книге «Психология образа» интегрировал все, что было наработано в школе Леонтьева психологии о том, что такое образ. И одно из наиболее показательных его цитат – предсказание, то есть антиципация. непрерывно во времени сравнивает объект с наличной стимуляцией, является процессом активного движения от образа к внешнему миру, непрерывно во времени процессом проверки и предсказания образа на соответствие стимула внешнего мира. Только если все многочисленные предсказания будут совпадать с реальными стимулами непрерывно во времени и в пространстве стимулов, только тогда есть восприятие, что является аналогом физического гетероиммунизма. То есть, опять же, в отличие от того, что пишет Танони, предсказание в той самой системе взаимосвязанных причинных связей, оно не просто интегрирует некоторую информацию, нет, оно делает гораздо большее. Оно делает на основании причинных связей предсказания всех этих свойств, которые, опять же, зрительной системой непрерывно проверяются на наличии. Это на самом деле очень хорошо описано в книжке Найсера в перцептивном цикле, где мы, так сказать, не только предвосхищаем те стимулы, которые должны находиться в этом объекте циклически, но и одновременно проверять их наличие реально. То есть восприятие непрерывно во времени предсказывает эти стимулы и проверяет их наличие одновременно. На этом все. Надо сказать, что, опять же, в заявлении естественного классификации закон формирования понятия. Опять же, таких алгоритмов нет. Есть только тот алгоритм, который мы предложили, и который, в том числе, может описывать некоторые эффекты сознания. опираясь, опять же, на единственную гипотезу о том, что мозг обнаруживает причинные связи и делает всевозможные выводы по ним. То есть эта гипотеза, она является очень простой и, возможно, базовой для всех живых организмов. Но на основании этой гипотезы можно объяснить, фактически строение когнитома, которое включает формирование естественных понятий в виде клеточных ансамблей и работы функциональных систем. На этом все. Спасибо за внимание. 

S02 [01:05:37]  : Евгений Евгеньевич, спасибо большое. На самом деле для меня было немножко неожиданно. Я сейчас сделаю пару комментариев, если позволите. А потом пойдем по списку вопросов, хотя в основном вопросы, похоже, будут от Виктора Казаринова и от меня. У нас обоих их много. Комментарий первый. Во-первых, с одной стороны, высоконаучный подход. Сделается заявка на построение системы методологии, как автоматизация открытия законов природы. Но при этом я сходу могу обозначить две совершенно банальных практических задачи и решения, которые... Одно из них было буквально на слуху. У нас вообще в этой группе часто обсуждаются темы финансового анализа. И обсуждалась та же тема AGI. Это торговый бот как прототип AGI. Насколько применим искусственный интеллект и машинное обучение или бесполезно что-то делать, нужны только сакральные знания или инсайт. Буквально позавчера был у меня разговор по своему проекту с одним матерым трейдером. Который сказал, что на самом деле на малоликвидных рынках, где маленькая ликвидность и маленький объем продаж, на самом деле важно выявлять не какие-либо законы или какие-то зависимости, а нужно выявлять именно события. То есть, нужно выявлять именно цепочки событий. который Евгений Евгеньевич показывал. То, что он показывал маркеры на уровне генетических последовательностей или определенное чередование определенных подъемов и опусканий цен выше или ниже определенных уровней, например, финансовых рынков. Вот именно вот такие вот паттерны, да, это не фигуры технического анализа, да, это не рыночные индикаторы, которые используются в техническом анализе стандартно трейдерами, а это вот именно выявление таких как бы структурных элементов, что ли, в рыночных данных, которые являются указателями на то, что события будут развиваться по тому и другому сценарию. То есть, если мы видим определенную последовательность событий, которые происходят с ценами, с объемами, с ордерами, в зависимости от того, какой именно рынок мы имеем дело, то вот эта последовательность событий является триггером, допустим, последующего обвала или последующего подъема или, допустим, последующей стабилизации рынка. именно вот выявление вот таких вот паттернов структурных оно как раз является предметом поиска профессиональных трейдеров и собственно вот автоматизация этого процесса наверное вот на финансовых рынках она была бы очень интересно вот а вторая задача она еще банально первое первое большой вопрос 

S01 [01:08:56]  : Если тренер, он действительно совершенно правильно считает, что нужно искать событие, но событие это не любое. Дело в том, что если под событием считать вообще совершенно произвольный участок кривой, то это не будет событие, это будет некоторый факт. Под событие все-таки имеется в виду некоторый выделенный участок, который значимый. А значимый в каком смысле? Это значит, он несколько раз все-таки повторяется. Дело в том, и почему он все-таки говорит, что нужно искать эти события. Потому что рынок меняется, он меняется достаточно быстро. Через три месяца значимо сдвигаются законы мерча, через полгода их вообще надо менять. Дело в том, что поскольку рынок быстро меняется, данных недостаточно для обучения обычными методами мужчинного обучения, в том числе нейронными сетями. Ровно сетями на небольшое количество данных не в состоянии настроиться, а если не настроится, они потом будут обманывать, причем достаточно быстро. Поэтому нейронные сети и другие методы применять нельзя. А вот нашу систему как раз можно применять. Почему? Потому что мы используем для событий очень общую информацию. И вот те самые пики и так далее, вот это как событие, оно может быть найдено несколько раз в последовательности и действительно является событием. То есть отличить событие от несобытия можно только через наличие некоторых таких достаточно общих свойств. которые наша система в состарении выявляет, в отличие от нейронных сетей. Поэтому вашему трейдеру скажите, если у него есть интуиция о том, какой информации, как он смотрит на события, какой он извлекает. Мы с помощью нашей системы можем в точности найти все эти правила, которые включают ту информацию, которую он использует. Мы, к сожалению, трейдера такого хорошего, успешного не нашли, они не даются. 

S02 [01:10:50]  : Евгений Евгеньевич, спасибо, я принял сведения, я этим людям уже рассказывал про ваши работы, но вот в результате нашего с вами сейчас обмена мнений, я, видимо, им еще раз предложу к ним обратиться. Может быть, они сейчас будут более к этому готовы. Второй момент, второе приложение. Которое я тоже не ожидал, но оно достаточно важное. И я вот прям призываю, если вдруг кто-то увидит, как можно вот это приложение реализовать в виде пресловутого AGI MVP, как относится автоматизация открытия законов природы, грубо говоря, про которое сейчас рассказывал Евгений Генчи. Вольно перефразировал. Если кто-то услышит или будет слушать это сейчас, или услышит эту постановку, про которую я буду говорить, то было бы очень интересно обсудить, как можно реализовать именно некоторые MVP, именно некоторый проект, который бы демонстрировал решение этой задачи. Следующая задача. Задача такая. Предположим, у нас есть рынок, где происходит торговля какими-то товарами. Это может быть онлайн торговля, это может быть ритейл, это может быть просто система анализа спроса предложений в интернете. Я с этой задачей сталкивался, когда мы работали на большом аутсорсинговом проекте для здравоохранения Соединенных Штатов, там нужно было делать следующее. У нас есть большое количество накладных, где в этих накладных есть позиции товарные, есть количество товаров по этим позициям, есть единицы измерений и есть цены. И задача заключается в следующем. Задача очень простая. Есть поток таких данных. Позиция, количество, единица измерения, цена. И на основании больших объемов данных нужно понять, у каких позиций есть какие единицы измерения, как одни единицы измерения пересчитываются в другие, И каковы диапазоны цен у каждой позиции в какой-то базовой единице измерения, или в любой единице измерения, с учетом того, что мы одни единицы измерения можем пересчитывать. Это базовая задача. И усложнение этой базовой задачи заключается в том, что у нас, во-первых, каждая позиция может представлять собой некоторый подкласс более широкой позиции. То есть, допустим, в нашем случае было много всяких медицинских катетеров. Но каждый катетер является частным случаем некоторого общего катетера. И в зависимости от свойства этого общего катетера, свойства частных катетеров могли меняться. И, соответственно, меняются цены в зависимости от единицы измерения и количества измерений. Кроме того, у каждой позиции есть различные поставщики, есть различные способы заключения сделок, опт или розница. Учитывая количество измерений, в которых мы вынуждены находить вот эти соответствия, оно возрастает от четырех до примерно семи или восьми. И вот нужно это все структурировать и нужно научиться именно пересчитывать одни единицы в другие и строить графики распределения цен для того, чтобы в конечном итоге осуществлять маркетинговый анализ, анализ спроса предложения, находить наиболее эффективных с точки зрения цена-качество поставщиков. И еще одно усложнение этой задачи заключается в том, что все эти исходные данные являются вероятностными. То есть, каждый раз, когда мы видим некоторое количество цен и единицу измерения позиций, мы должны понимать, что данные были получены с помощью метода. Например, оптического распознавания текстов или они, возможно, были набраны с ошибкой или с опечаткой. Вот что в данных реально есть ошибки и нужно уметь еще и иметь дело с этими ошибками. Ну и когда я занимался этим проектом, там было сначала в качестве постановки ТЗ была написана такая диссертация на 90 страниц. Я вот сейчас как раз листал, когда Евгений Евгеньевич рассказывал. В результате этого 90-страничного ТЗ были сделаны только какие-то жалкие потуги, которые показали, что в лоб задача не решается. И как раз именно решение этой задачи теми методами про которые Евгений Евгеньевич рассказывал, было бы очень интересно. То есть, если вдруг у кого-то есть такая задача или кто-то видит, у кого есть такая задача, то было бы интересно поговорить и попытаться понять, можем ли мы попробовать продемонстрировать решение этой задачи, вот используя те механизмы, про которые Евгений Евгеньевич рассказывал. Вот, собственно, второй комментарий. 

S01 [01:16:14]  : Да, я могу сказать, что мы занимались задачей ритейла, но там все было достаточно четко, то есть товар имеет вполне определенную номенклатуру, вполне определенную цену, и там нужно было, так сказать, только отслеживать, то есть какой товар поступил, есть на полках, он продан, требуется ли его дополнительная доставка, этот товар будет ли через неделю на месте или его раскупят. Но там эти параметры, поскольку это товары совершенно конкретные, там их параметры были фиксированы. Там единственное, что требовалось, это поскольку товаров, как правило, тысячи наименований, то там необходимо было определять или искать так называемые потребительские корзины. То есть автоматически пытаться определять ту или иную корзину на основании того, в каких пакетах или в каких наборах покупатели эти товары покупают. Но вот эта задача поиска потребительских корзин в программе классификации может быть решена. 

S02 [01:17:23]  : Спасибо, Евгений Евгеньевич. В том проекте, о котором я говорил, основная фишка была именно в автоматическом нахождении соответствий между различными единицами измерения, которых может быть много. Одна и та же таблетка может быть, грубо говоря, в коробках по 10 или в пачках по 15. И ещё в различном количестве миллиграммов может быть в каждой таблетке. И на самом деле сама единица измерения в зависимости от категории товаров разбивается на несколько. Сколько, допустим, таблеток, сколько блистеров, сколько таблеток в блистере, сколько блистеров в коробке, сколько таблеток в блистере и сколько миллиграммов в каждой таблетке. То есть, на самом деле, сама даже единица измерения является не одномерной. двух-трехмерный в общем случае. И при том и нужно как бы пытаться понять, как в конечном итоге мы можем высчитать цену на некоторую средненную стандартную коробку со стандартным количеством блистеров со стандартным количеством миллиграммов, чтобы пересчитывать в конечном итоге, если мы не нашли товара в одной упаковке, как нам найти товар по более дешевой цене, но в другой упаковке. Это ладно, это комментарии. Давайте перейдем тогда к вопросам Виктора Казариного. Что такое законы природы, по вашему мнению? Что это за субстанция? Есть время, есть энергия, есть материя. А законы, что это? Они что, обволакивают все остальные субстанции? А себя? Законы природы как-то связаны между собой, иерархически или как-то иначе? И если да, то есть ли какое-то объяснение этому факту? алгебраическое определение законов природы основано на каких-то других законах природы? Если так, то получается, что на основе законов природы для алгебраического поиска должны быть найдены законы природы для алгебраического определения. Иными словами, возникает самозамкнутость. Евгений Евгеньевич, вопрос, может быть, вы, если увидите текст в чате, ну или давайте по порядку, я могу зачитывать. 

S01 [01:19:51]  : Ну, я думаю, что закон периода – это то, так сказать, высказывание, которое записано, понятное дело, в физический термин, то есть оно, так сказать, физически имеет точный физический смысл, который, безусловно, выполняется. Но, по крайней мере, в тех в тех ограничениях и в тех рамках, в которых он работает. Теперь относительно разнообразия. Действительно, вот такого разнообразия законов. Опять же, как это следует из определения Кулакова, там выписаны функционалы для этих законов. И многие известные физические законы под эти функционалы попадают. Но не исключается возможность, что будет обнаружен еще какой-то закон, который попадет в функционал, который раньше не использовался. То есть, такое возможно. То есть, мы можем, так сказать, обновить еще в дальнейшем физики или, может быть, даже в других областях. Дело в том, что, на самом деле, почему это важный вопрос, потому что в других областях, кроме физики, химии, так сказать, ну, там, не знаю, еще, может быть, электроники, точные законы-то даже и не искались. То есть, на самом деле, применение технологии обнаружения законов, она толком, так сказать, еще и не использовалась. Поэтому не исключено, что в некоторых других областях, так сказать, такой же техникой могут быть обнаружены законы, которые, так сказать, в те формулы, которые, так сказать, положим, Кулаков выписывает или в теории измерений, так сказать, они записываются. Этот закон может быть выражен, но до этого он известен не был. Значит, те самые алгебрические определения, что они на самом деле означают? Они означают некоторую строго определенную зависимость, в которой у нас шкала величины и сам закон связаны некоторым достаточно однозначным образом, в которых на самом деле закон и шкала величины связаны достаточно четко, вполне определенными правилами. Если посмотреть внимательнее, если мы одну переменную увеличили в два раза, вторая может уменьшаться или увеличиваться в два раза, то есть между ними есть четкое соответствие, как они могут взаимоизменяться. Я не знаю, ответил я бы на целиком вопрос или нет. 

S02 [01:22:26]  : Виктор, если вы считаете, что вопрос не отвечен, то вы подключаетесь с голосом, а я пока ваш следующий вопрос зачитаю. Как вы считаете, законы природы как-то взаимодействуют между собой без посредства материи, времени, энергии? Чисто законное взаимодействие? 

S01 [01:22:53]  : Но тут надо разделить два варианта. Они, конечно, чисто физически между собой взаимодействуют, и это бесспорно, это физика. Их математическое описание, их, так сказать, математическое выражение. Оно, строго говоря, не обязано взаимодействовать между собой, хотя система всем, они варьируются тоже довольно определенным образом. То есть математически они тоже, так сказать, некоторым образом связаны. Но, строго говоря, эта связь Она... не обязательно в том смысле, что если нет некоторого заведомого постулата, вот у Кулакова есть постулат. Это постулат феноменологической симметрии. Там взаимосвязь, давно, в конце концов, выражается в некоторых функциях, которые от результата измерения соответствуют равновесию. Другое дело, что, так сказать, на основании этой функции получается множество разных законов. Но сам принцип получения закона, он, в общем-то, здесь один и тот же. И в этом смысле, а это связывает и математику тоже. То есть математика в этом случае связывается в виде той самой функции, которая тождественно равна нулю, но у которой есть множество решений. Как Кулаков, например, поясняет суть своей феноменологической симметрии, Вот мы возьмем произвольные три точки на плоскости и соединим их, получим треугольник. Линии, связывающие эти три точки, могут варьироваться произвольно. А теперь возьмем тетраэдр, точку вне плоскости, и соединим ее с тремя точками на плоскости, получим тетраэдр. Все его стороны и длина могут варьироваться достаточно произвольно. Но если мы возьмем одну точку, которая связана с тремяноплоскостями, и вторую точку, которая связана с тремяноплоскостями треугольника, то есть получим два тетраэдра. то тогда уже длина, связывающая между собой вот эти две точки Титрайдера, она уже функционально зависима от всех остальных длин. И на самом деле Кулаков поясняет свой принцип так, что если между взаимоизмеряемыми величинами находится хоть какая-то зависимость, хоть какая-то, то есть хоть какая-то функция, то здесь она на нулю. Мы в этом случае можем найти ее точное выражение, ее точную формулу. И в этом смысле эти формулы математически тоже выводятся некоторыми единообразным образом. Это у Кулакова. В теории измерений там есть система аксиомов для простых полинов, они тоже похожи друг на друга, но единого принципа там нет. Поэтому там могут быть много разных. 

S02 [01:26:08]  : Спасибо. Следующий вопрос от Виктора. Детерминированность и хаос как две крайности. Хаос определяется законами природы. В хаосе тоже обнаружены некие закономерности типа точек бифуркации и так далее. И что первично? Детерминированность или хаос по вашему мнению? 

S01 [01:26:36]  : Ну, хаос он в конце концов, так сказать, может быть не беспредельный, то есть в нем тоже могут обнаружиться закономерности некоторых более высоких уровней. когда этот хаос некоторым образом самоорганизуется. Вот этот более высокий уровень, он может быть некоторым образом записан, если он записывается функционально, то для него можно будет сформулировать некоторые законы. Но это фактически будет закон некоторого высокого уровня по отношению к исходному хаосу. А сам исходный хаос, его полный безграничный объект, Объеме, конечно, для него нет закона. 

S02 [01:27:19]  : Ну и тогда, раз уже про уровни законов зашла речь, следующий вопрос Виктора. Это является ли закон естественной классификации под законом какого-то более общего закона? 

S01 [01:27:34]  : Но фактически оно так и получается, потому что закон естественной классификации, он получается над законами, которые связывают между собой признаки между собой, а связь признаков между собой, она в том числе определяется, дают ли они некоторый синдром, или они все-таки могут достаточно независимо друг от друга существовать. Если мы возьмем, так сказать, опишем объекты случайным набором признаков, там никакой естественной классификации найти нельзя будет. Поэтому естественная классификация сама по себе является законом даже, можно сказать, некоторого третьего уровня. 

S02 [01:28:19]  : Но вопрос был такой, что является закон об естественной классификации под законом какого-то еще более общего закона. То есть, есть ли закон более высокого уровня, чем закон естественной классификации? 

S01 [01:28:35]  : Но это я не знаю, потому что закон естественной классификации, он рассматривается для так называемой феноменологической классификации, когда у нас есть вполне определенная задача. Есть множество объектов, имеющих определенный набор признаков. Эти признаки принимают разные значения на этих объектах. и надо найти какую-то группировку этих объектов. Не исключено, что могут быть поставлены более сложные задачи по поводу интеграции этих объектов. Тот же самый Кулаков, например, для таблицы Менделеева строил свою естественную классификацию, связанную с принципами логической симметрии. Она имела уже треугольный вид. И там, понятное дело, эта естественная классификация была основана не только на индикаторных признаках, она включала в себя более сильные взаимосвязи между элементами. 

S02 [01:29:32]  : Спасибо. Следующий вопрос Виктора. На каких аксиомах или постулатах основано определение любящего? Из чего следует возможность предсказания части признаков из некоторого набора известных признаков? 

S01 [01:29:47]  : У него никаких таких аксиом нет. Он просто говорит, что если мы получаем такую естественную классификацию, то она является в определенном смысле идеальной. То есть это предел построения естественной классификации с его точки зрения. Но никаких аксиом, как ее строить, он не выписывал. 

S02 [01:30:07]  : Спасибо. И последний вопрос Виктора. Естественная классификация – субъективный или объективный процесс? Если субъективный, то может ли тогда она являться законом природы? 

S01 [01:30:22]  : Она является законом природы, потому что она сжимает информацию, то есть это означает, что мы по имеющейся, то есть по сжатой информации можем воспроизвести большое количество, так сказать, всей остальной информации. Но естественная классификация, поскольку они строятся действительно разными людьми, и естествоиспытатели обращают разное внимание на разные признаки, могут быть отчасти, делая это под разным углом зрения, потому что разный угол зрения фактически выделяет некоторые подсистемы признаков. И поэтому один считает такую систему признаков более важной, чем другую, и в этом случае они, естественно, получат немного отличающиеся между собой, так сказать, естественные классификации. Но сам принцип сжатия информации, он в этом случае остается один и тот же. 

S02 [01:31:25]  : Здесь еще на эту тему тоже есть комментарий от Эльгизара Талипова, что упомянутая субъективность выбора систематики заслуживает более серьезного рассмотрения. В презентации совершенно исключен наблюдатель и важность его системы измерений и видения онтологии природы. объекты воспринимаются через то, чем обладает наблюдатель, но не через абстрактное измерение. И, Евгений Евгеньевич, я здесь сразу тоже дополню. Значит, вот в книжке Курпатого промышления, которую я сейчас в вашей подаче считаю, там как раз тоже очень много говорится про то, что каждая вообще система интеллектуальных объектов, которые наблюдают, Агент, пытающийся построить эти модели или обнаружить законы, они сугубо субъективны с точки зрения личного жизненного опыта каждого агента. Как вы это прокомментируете? 

S01 [01:32:29]  : Естественно, тут можно сформулировать. Есть форма мышления абстракции, есть форма мышления синтез, анализы синтез. На самом деле есть такая форма мышления, которая в частности применяется во всяких интеллектуальных играх. Это выбор. поиск другого взгляда на задачу. Задача положим не решается, если рассматривать с такой-то точкой зрения, с такой-то системой понятий. Она может быть решена с совершенно другой точки зрения, если поменять точку зрения на проблему. Так вот, выбор точки зрения и выбор взгляда на проблему – это действительно вещь субъективная, она включает в себя наблюдателя. И это в определенном смысле неотъемлемо, но неотъемлемо от чего? От той онтологии, которую казаховцы выберут. Те рассмотрения, которые я приводил, они приводятся в предположении фиксированной онтологии. Но понятное дело, что на самом деле онтология варьируется от наблюдателя к наблюдателю, в зависимости от того, что мы рассматриваем, что мы считаем важным, а что нет. 

S02 [01:33:42]  : Спасибо. У меня на самом деле будет ещё один вопрос, более практический, про субъективность этих законов. Но сначала есть несколько вопросов более принципиальных. Евгений Евгеньевич, вы можете для понимания сформулировать, как вот та история, о которой вы рассказываете про определение, обнаружение законов, шкал связано с айджиай то есть собственно что вот эта вот история И вот эти принципы дают именно для построения системы общего искусственного интеллекта. 

S01 [01:34:22]  : Дело в том, что общая система искусственного интеллекта должна не только моделировать когнитивные функции, решать интеллектуальные задачи, но в конце концов должна сама уметь осуществлять процесс познания действительности. А для этого необходимо иметь возможность обнаруживать законы, в том числе законы естественной квалификации. Более того, в определенном смысле мозг это уже делает, по крайней мере относительно естественных понятий. 

S02 [01:34:49]  : Я правильно понимаю, что мы можем считать знания, что это, по сути, законы или модели окружающей реальности, которые система AGI должна уметь обнаруживать для того, чтобы применять их в своей повседневной деятельности? 

S01 [01:35:08]  : Да, я считаю, что система AGI должна уметь обнаруживать. Хотя, на самом деле, я не сказал. Дело в том, что так называемый алгоритмический интеллект, он, так сказать, по-моему, мне кажется, можно доказать такую теорему, что алгоритмический интеллект не в состоянии обнаружить закон, где требуется такое перешкалирование величин. которая алгоритмически на самом деле неразрешима. А система, которая обнаруживает закон путем перешкалирования величин с помощью той системы, о которой я рассказывал, шкалирования, которая проводится, это вполне алгоритмическая процедура. Вот такой алгоритмической процедурой можно прошкалировать и получить закон, даже если шкалы нужно перешкалировать, не алгоритмические. А алгоритмический интеллект, если он сразу за исходное возьмет функции f от x, y, он ни за что не найдет. Это будет логаритмически неразрешимая проблема, найти из этой функции fxz тот самый простой вид закона, который является по-настоящему законом. Тут еще можно проводить некоторые теоретические исследования, что может обнаруживать закон, а что нет. 

S02 [01:36:24]  : Евгений Евгеньевич, тогда вот еще вопрос по поводу, возвращаясь к Курпатову. Вы как-то можете привязать вот эти вот законы и шкалы, которые вы обнаруживаете, к интеллектуальным объектам, которыми он оперирует? Я в двух словах скажу, кто этой книжке не знаком, что Курпатов строит свою теорию мышления как способ простой работы и оперирования с интеллектуальными объектами. То есть, все, что мы имеем, это некоторые эрахи интеллектуальных объектов. Человек воспринимает одни интеллектуальные объекты. На основе одних интеллектуальных объектов более низкого уровня он строит интеллектуальные объекты более высокого уровня. На основе интеллектуальных объектов более высокого уровня строят объекты еще более высокого уровня для того, чтобы построить максимально компактную структуру, чтобы ее можно было с одной стороны протискивать через ограниченный размер рабочей памяти, чтобы принимать решения повседневной реальности, а с другой стороны, чтобы минимизировать количество конфликтов которые человек имеет дело, сталкиваясь с событиями в реальной жизни. Ну, не человек, невероятно, существо, да, живое. Для того, чтобы минимизировать количество когнитивных конфликтов, чтобы, так сказать, всё было максимально предсказуемо с одной стороны и требовало минимальное потребление энергии для хранения этой информации и манипуляции и, соответственно, максимальное упрощение, максимальная минимизация количества признаков, которые нужны для того, чтобы идентифицировать тот или иной объект. Вот с этими интеллектуальными объектами как-то вы можете увязать то, про что вы рассказывали? 

S01 [01:38:06]  : Ну, у Карпатова-то есть понятие, уже будет понятие, так сказать, таких величин. Так или иначе, они должны участвовать в восприятии действительности, и они являются интеллектуальными объектами. Другое дело, что он не говорит о шкалах. На самом деле, понятие шкалы, оно фактически говорит о том, что у нас, ну, большинство этого, в частности, физические величины, они аддитивны. А понятие аддитивности очень хорошо и естественно усваивается человеком. Поэтому аддитивные величины воспринимаются как некоторые самостоятельные интеллектуальные объекты со своими свойствами. Ведь даже само восприятие, как оно устроено, раньше восприятие было более плоское, чем трехмерное, проекционное. То есть даже само восприятие пространства у человека, оно осуществляется через освоение так называемой нервно-динамической ткани в процессе человеческой деятельности. среде, то есть через перцепцию и ощупывание внешней среды, но в конце концов оно выстраивается в автоматизм восприятия трехмерного пространства вполне определенным образом. А такие аддитивные величины, как длина масса-скорость, которая имеет такую простую структуру. Там, конечно, в некотором автоматизме все это включается как некоторый интеллектуальный объект вместе со свойством и детальностью. 

S02 [01:39:49]  : Спасибо. Еще два уже более практических вопроса есть. Один я попробую сформулировать в виде утверждения, если сможете вы на него прокомментировать или опровергнуть. Вот есть такое ощущение, что можно вообще все задачи, которые есть в искусственном интеллекте на сегодня, свести к двум классам задач. То есть, это задачи классификации и задачи кластеризации, грубо говоря. И если первую задачу, задачу классификации, мы достаточно хорошо умеем решать самыми различными способами, когда у нас есть уже предопределенные классы задач с назначенными им характеристиками через шаблоны или через передобученные нейросети, тренированные в наборах данных, где классификация дается в качестве разметки. Если задача классификации достаточно хорошо решается в большом числе случаев, то задачу кластеризации или задачу построения этих классов и построения этих характеристик на сегодняшний день мы решать не умеем. А если и умеем, то либо мы ее решаем в варианте переобучивания на системы на недостаточном объеме данных, либо на избыточном объеме данных, который является характеризующим только какой-то узкий набор частных случаев и система узнает вот эти частные случаи совершенно не в тех ситуациях где этих случаев нету либо система просто недообученная и Она вообще не в состоянии распознавать ситуации, которые не получили достаточного числа представлений в обучающей выборке. И, собственно, то, про что вы рассказываете, это, мне кажется, как раз именно про подход к решению задачи кластеризации, когда мы даем возможность, пытаемся построить систему, которая будет сама выявлять вот эти самые классы или кластеры, свойств и характеристик этих классов. которые будут использоваться потом уже просто могут использоваться при решении задач классификации. 

S01 [01:42:27]  : Но не только вот эти задачи, кластеризация, классификация. Конечно, в методах машинного обучения есть и другие задачи. Прогнозы, например, очень важные. Важная задача принятия решений и так далее. Но методы классификации действительно, там есть некоторые критерии качества классификации. И классификация, там важна точность прогноза, то есть раунд-турбин контроль, например. А в кластеризации, поскольку она в определенном смысле субъективна в том плане, что в каждом алгоритме есть свой критерий качества кластеризации. Так вот, этот критерий качества кластеризации задает Собственно, ее смысл. Положим, минимизация среднего расстояния между точками внутри разных групп, или по отношению к их разделению, или минимизация расстояние, если это граф и метод, минимизация расстояний их нахождения и хождения внутри отдельных, так сказать, единиц. То есть, в этом случае, этим критериям качества, собственно, и задается смысл соответствующей кластеризации, но он, опять же, вытекает из соответствующей задачи, то есть, что нужно решить. А вот именно в том смысле, что построение естественной классификации, как и некоторый внутренний закон строения объектов. Он, конечно, не предполагает наличие какого-то внешнего критерия качества. 

S02 [01:44:05]  : Спасибо. И последний мой вопрос – это по поводу опять-таки субъективности. Вот смотрите, есть эксперименты по поводу автоматического формирования грамматик или изучения морфологии слов. которые показывают, что закономерности, которые будут построены, причем закономерности, которые являются объяснимыми, которые описывают грамматики или правила, они очень сильно зависят от того, в каком порядке и каким образом мы будем систему тренированную систему загружать данные. Но я приведу простой пример из своих исследований, что, к примеру, в зависимости от того, каким набором данных мы будем кормить систему, в слове PING она, значит, либо выучит, что ING Это окончание глагола с корнем пи. Слово пинг английское, от слова пинг-понг. Либо она всё-таки поймёт, что пинг – это отдельное слово, а инг, суффикс инг в данном слове отсутствует. То же самое можно говорить о грамматиках и связях на уровне слов. И здесь я хочу сказать, что субъективность Она выражается в том, что действительно, в зависимости от того, в каком порядке мы будем грузить систему данными, у нее могут быть разные естественные классификации. То есть, для кого-то там будет более важно, к примеру, Одно. Для другого будет важно другое. У кого-то будет десять видов снега и два вида песка. У кого-то будет десять видов песка и три вида снега. Или один вид снега. В зависимости от жизненного опыта. как мы можем чисто практически при построении реальных систем можем учитывать вот эту субъективность то есть вот как мы можем решить реально проблему вот нам нужно построить систему правил ну допустим мы строим там торгового бота и нам нужно чтобы этот торговый бот обнаружил вот эти значимые последовательности. Или мы строим систему построения грамматики, и нам нужно, чтобы были выявлены значимые грамматические правила. Допустим, выделены ситуации с переходящими глаголами и непереходящими глаголами. Как добиться того, Чтобы у нас, независимо от того, в каком последовательности мы скармливаем систему данные, то ли мы берем сначала данные за этот год, а потом за предыдущие, или сначала за предыдущие, а потом за этот, чтобы у нас все-таки более-менее объективная и универсальная картина получилась. 

S01 [01:47:06]  : Но здесь опять же, то есть та же самая система Discovery и вообще любой мет машинного обучения, он проходит все данные. Поскольку он проходит все данные, ему все равно в какой последовательности они были накоплены. Но все равно проходит все данные и находит определенную статистику. Это и для грамматики, это еще даже в институте математики разрабатывались методы обнаружения префиксов и окончаний на основании статистического анализа вариации слов в предложении. Но в этом случае на основании определенной статистики с определенным уровнем качество и значимости. Это все проверяется на всех данных, но поскольку там проверяется все данные, неважно какой последовательности они получены. 

S02 [01:47:56]  : А вот то, что вы говорите, это результаты были инвариантных последовательности данных? То есть, понятно, что на всех, но вот результаты, они зависят от того, в какой последовательности эти данные проходятся? 

S01 [01:48:14]  : Нет, они проходятся все, и обнаруживаются все такие зависимости. В смысле, регистрируются все такие отклонения, из которых строится зависимость. И в этом случае неважно, в какой последовательности они были даны. Делается полный анализ. 

S02 [01:48:31]  : этих зависимостей. То есть, в Discovery он инвариантен в последовательности исходных данных, да? 

S01 [01:48:37]  : Да, и на самом деле большинство моиметно-мышленного обучения тоже. Другое дело, что если рассматривается так называемое потактовое обучение. Потактовое обучение – это когда мы данные добавляем по единице, надо варьировать уже поштучно, варьировать нужные правила. 

S02 [01:48:58]  : То есть, тогда система уже будет зависеть от последовательности? 

S01 [01:49:04]  : Ну, конечно, потому что она будет зависеть от того, что мы получили, что каждый раз мы получаем. Потому что каждый раз мы получаем, можно получить одно, можно получить другое. Поскольку количество информации разное, то есть, сама информация разная, то мы можем получить разные программы. 

S02 [01:49:21]  : То есть, в случае, если мы строим систему инкрементального обучения или так называемый lifelong learning, когда пытаемся реализовать систему типа baby turing test, когда система получает знания инкрементально, мы не гарантируем универсальность знаний при разной последовательности поступления одной и той же информации. 

S01 [01:49:50]  : одной и той же информации. То есть, мы все равно, в конце концов, подали одну и ту же информацию. 

S02 [01:49:57]  : Да, грубо говоря, мы системе сначала дали почитать про Винни-Пуха, а потом про Буратино. А другой системе дали сначала почитать про Буратино, а потом про Винни-Пуха. Будет ли в конечном итоге система обладать одним и тем же интеллектуальным багажом, или системы ценностей будут разные в этих двух случаях? 

S01 [01:50:18]  : В условиях, что она будет обучаться по такту. И в том и другом случае она будет обучаться по такту. Да, да, да. Но система Discovery есть вариант, который нейролизован. Ей все равно. Она все равно учтет всю статистику. А поскольку информация одно и та же… Понятно. 

S02 [01:50:39]  : Спасибо. Хорошо. Последний комментарий еще насчет субъективности от Ильгизара Талипова интересный был, что естественная классификация всегда относительно зависит от наблюдателя классификатора. Поэтому было бы правильнее было бы назвать искусственная классификация. Наверное, все-таки не искусственная, а субъективная. Естественная субъективная классификация, да? 

S01 [01:51:03]  : Термин «искусственная классификация» – он забит. Это, так сказать, стандартная классификация, которая получается по фиксированным признакам и значениям. Поэтому это, заведомо, не искусственная классификация. 

S02 [01:51:15]  : Спасибо, Евгений Евгеньевич. Теперь Владимир Смолин имеет поднятую руку и желание высказаться. 

S00 [01:51:26]  : Ну, я не знаю, представляете ли вы мою систему взгляда. Наверное, если представляете, то знаете, что она совершенно другая. Но интересно как бы не то, в чем мы могли бы друг друга критиковать, наверное, с разных сторон, а то, что вы, значит, упомянули Что я хотел бы увидеть позитивное в вашей системе, это то, что вы упомянули систему шкалирования, и что большинство физических законов, которые нам преподавали в школе и даже в институте, если их просто программифировать, то они все приводятся к линейному виду. Это очень удобно, потому что разделяет переменные, шкалирование очень простое. И вот, собственно, у меня по этому поводу к вам вопрос. Почему вы используете некоторую болезнь на математике, которую, ну, в смысле, вы, может быть, меня заинтересуете, чтобы я ее подробнее узнал, потому что из вашего доклада, конечно, я не воспринял, что вы рассказали. Вот. И второе, вот тот пример, который вы приводили про, значит, тренинговую систему, там как-то вот это вот шкалирование у вас никак не проиграло. Как вы его там используете? Или это как бы совершенно несвязанные понятия? 

S01 [01:52:31]  : Относительно трейдинга, там шкалирование явно не используется, но оно там и не нужно, поскольку мы используем только точки и отношение порядка между ними. А поскольку точки выбираются в соответствии с некоторым порядком, там шкалирование не нужно. процедура шкалирования, но ту процедуру, которую я привел, она простым логарифмированием может не взяться. То есть, там могут быть довольно хитрые и довольно сложные преобразования, которые могут в конце концов привести к линейной зависимости, и они, вообще говоря, не очевидны. 

S00 [01:53:19]  : Нет, я не говорю, что все системы, но большинство законов, которые нас учили, они логарифмированы всего экстремальному виду. 

S01 [01:53:27]  : Те, которые мы действительно используем, и поскольку мы их так и используем, они приводятся в экрифмирование. Но если мы берем новые неожиданные данные, тем более, что, например, если мы используем физическую величину вне физической области, там есть совсем другая шкала и другой совсем смысл. И если мы будем уже брать отношение порядки, отношение эквивалентности уже из другой предметной области, не физической, и там проверим систему во всем, что она выполняет. Там, например, в теории принятия решения это часто делается. В теории принятия решения там величины шкалируются, чтобы получать некоторые решающие функции. И там это шкалирование может быть совершенно неожиданным и необязательно географическим. 

S00 [01:54:16]  : Ну, тут я не спорю, что оно может быть не обязательно вагрифмическим. Но не могу сказать, что было понятно ваше объяснение, к сожалению. И, собственно, второй вопрос, что в вашем докладе, кроме названия, выводов, которые вы сделали, никак не прозвучало, что это относится к сильному искусственному интеллекту, который Эдди Путрин это называет. И, собственно, о муске делается и человек. То есть, в принципе, складывается впечатление, что когда в прошлом и позапросном веке была механика, то в голове рисовали шестеренки. Представляли, как шестеренки работают, но иначе как-то муску нельзя было понять. Сейчас научились рисовать семантические системы. Соответственно, вы их туда вкладываете. Но вот эти самые семантические структуры ее может создавать только человек. Ваша система использует эту систему. По крайней мере у меня сложилось из вашего доклада впечатление, что когда уже с человеком созданы понятия, созданы семантические структуры взаимодействия, тогда ваша система может их использовать. С моей точки зрения это, конечно, не сильный источник интеллекта. Он без человека работать не может. Но, может быть, я ошибаюсь. Может быть, вы, соответственно, скажете, как на самом деле. 

S01 [01:55:30]  : Ну, то, что я рассказывал, во-первых, предполагает, что логика вероятности подхода к IGI, это был отдельный доклад, и там уже, так сказать, было действительно реальное описание сильного искусственного интеллекта. Здесь это, по сути дела, добавление к тому докладу, который связан с формализацией процесса познания, в том числе. Поэтому надо иметь ввиду, что сильный искусственный человек понимается в совокупности с теми докладами, которые уже были. 

S00 [01:56:02]  : Все-таки ваша система предполагает, что есть некоторый автоматический, безучастный человек, который выделяет понятия, строит семантические взаимоотношения, просто не вошло в этот доклад. Я правильно вас понимаю? 

S01 [01:56:18]  : Нет, здесь вот как раз все построение и задачный подход, и вот то, что я часто рассказывал, оно начинается с антологии в задачном подходе, это начинается с антологии, антология при предметной области, то есть тот предмет исследования должен быть дан. Предмет исследования, то есть система понятий, как мы воспринимаем наши объекты, которые мы исследуем, что мы с ними делаем, что мы из них измеряем. То есть предмет исследования должен быть дан. Только с этого момента начинается производство познания. Другое дело, что в докладе как раз по формированию понятий, где формирование понятий мозга, самого по себе, то есть как происходит само формирование понятия. Это уже, так сказать, отдельная тема. То есть человек на самом деле может формировать понятия на основании тех же самых вероятностей формальных понятий. Их потом используют в системе понятий, но это уже будет связано тогда, чтобы сформировать некоторые предметы следовательно, там нужна система понятий, не одно понятие. Там предполагается, что осуществлена некоторая естественная классификация объектов предметной области. В рамках этой естественной классификации, естественно, предполагается наблюдатель и некоторая точка зрения, с какой точкой зрения смотрится на объекты. Формируется понятие, а потом уже начинается начинается процесс познания. Хотя формирование самих планет тоже может быть описано формально. 

S00 [01:57:57]  : Правильно я вас понимаю, что все-таки наблюдатель – это человек, или вы можете предложить какие-то другие системы, которые бы заменили человека? 

S01 [01:58:04]  : Нет, наблюдатель – это человек. 

S00 [01:58:06]  : Понял. Спасибо. 

S02 [01:58:12]  : Спасибо. Владимир, у вас все вопросы, да? 

S00 [01:58:15]  : У меня очень много вопросов, но это не соответствует нашим взглядам. 

S02 [01:58:23]  : Хорошо. Николай Робчевский, пожалуйста. 

S03 [01:58:28]  : Добрый день. Спасибо за доклад. У меня несколько моментов. Во-первых, Вот в связи с тем, что для выявления некой зависимости должна существовать функция, которая обращает в нуль набор параметров измеренных, есть вариант отыскания таких функций, соответственно, других результатов. Таким образом, мы формально формируем задачу аппроксимации чего-то набором функций, у которой, так сказать, с использованием ортогонального базиса строим задачу, которая позволяет апроксимировать что угодно, используя измеренные значения в качестве коэффициентов. Такая задача дает нам некую матрицу, для которой мы можем находить собственные вектора и собственные числа. И из этого достаточно ясно выскочит вот та зависимость, которая реально имеет место, если она есть. Это к тому, что можно попытаться сопоставить статистические подходы с таким подходом и посмотреть, что интереснее и что полезнее. Второй момент перекликается с тем, что упоминал Эльгизар Талипов и Антон Канонин, и Смолин, по поводу того, что существенным моментом для определения зависимости является то, какие данные использовать. То есть, если речь идёт об измерениях, то что именно мерять, не только в каких единицах и какие величины, но и в каких местах мерять. Ну, например, Если мы меряем температуру с тем, чтобы определять, есть у нас ковид или нет, то важно знать, где мерять температуру для того, чтобы зависимость имела место. И в познании, так сказать, окружающей местности, среды, интеллектуальной системой, эта фаза, видимо, играет, ну, как минимум, столь же важную роль, как и анализ, собственно, полученных данных. Третий момент заключается в том, что вот то, что мерять, Оно не всегда по своей сути является числами. В нашей, так сказать, континуальной реальности, с чем имеют дело роботы, которые работают в реальной физической среде, факторами являются в значительной степени функции. То есть функции, которые описывают траектории, функции, которые описывают форму объектов, контуры объектов на видимом изображении. И было бы интересно подумать над тем, что и как обрабатывать в тех случаях, когда данными являются реально функции. При том, что в мире в реальности не функции, а какие-то отдельные величины, скажем, координаты неких точек, которые задают нам траекторию. По сути, тем не менее, это не набор изолированных точек, а именно функция, и мы можем мерять сколь угодно густо, потенциально, по крайней мере, и так далее. Но когда речь идет о функциях, то там и отношения между ними, и операции между ними будут, в общем, существовать. видимо, намного сложнее будет. Я об этом рассказываю, потому что я пытаюсь в эту сторону что-то делать, пока у меня нет хороших решений. Ну и последний момент. Это то, что в конечном итоге интеллигентность – это как бы степень хорошести решений. Хорошести решений о действиях. И степень хорошести говорит о том, что последним этапом всегда будет решение некой оптимизационной задачи. И то, что мы знаем в явном виде законы какие-то, не означает автоматически, что нам легко решить эту оптимизационную задачу. Во многих случаях, по-видимому. Решить ее, используя просто те сырые данные, не зная конкретных закономерностей, которые там присутствуют, может оказаться более простой задачей, чем сначала отыскать закономерности, а потом использовать их для решения оптимизационной задачи. Вот у меня все. Спасибо. 

S01 [02:05:29]  : Первое – это то, что можно брать и в матрице находить элементы. Есть такой способ решения задачи, он тоже может дать некоторые функции, но он не предполагает перешкалирование величин. То есть, это другой метод находения функций, но он отличен от того, о котором я рассказал, потому что перешкалирование величины не предполагает. Ну и, конечно же, мы должны знать, что измерять. Если мы не знаем, что измерять, конечно, само измерение отчасти теряет смысл. А вот функции на функциях, это я не знаю. Нужен какой-то особый аппарат, я такого не встречал. И, наконец, относительно задачи оптимизации, она, конечно, всегда есть. Но дело в том, что с точки зрения искусственного интеллекта и даже той же самой теории функциональных тем, информационной теории эмоций Симонова и так далее, окончательное решение, оптимизационное, принимает эмоции. В искусственном интеллекте это называется функция полезности, которая учитывает как прогноз, так и вероятность. Но для того, чтобы сделать прогноз, закономерности нужны, их надо сначала найти, их надо применить, посмотреть с помощью каких закономерностей мы какой результат можем получить. получить и потом уже на основании эмоций выбирать, а нам это надо или нам это не надо, или что нам на самом деле надо. То есть, окончательное решение, конечно, приводится получаться не по закономерности, а по эмоциональным оценкам или функциям полезности. 

S02 [02:07:19]  : Спасибо. Еще вопрос от Ильи. Можете ли Вы, Евгений Евгеньевич, более детально объяснить, как Ваш алгоритм находит связи? А то я немного не понял математику, которую Вы описали. 

S01 [02:07:35]  : Но я могу немножко более подробно. Я об этом рассказывал в докладе «Логовероятностный подход к AGI», который по-русски был. А на самом деле, вот ту самую книжку, которую в самом начале я приводил, и там ссылка, что она скачивается, там в ней все есть. Там, правда, конечно, это надо смотреть, но там все есть. 

S02 [02:08:04]  : Да, логиковероятностный подход к AGI должен быть на нашем YouTube-канале. Если вдруг не найдёте, то можете написать в группу, я уточню. Но там должно быть видео. И ещё есть комментарий от Кент Бур, что теория изменений, шкалирование, метрология – это необходимая и существенная часть CE-AGI. С этим можно согласиться. Хорошо. Коллеги, еще есть какие-то вопросы или комментарии? Нет. Ну, хорошо. Тогда, Евгений Евгеньевич, Вам спасибо большое за доклад. Всем вопрошающим спасибо за вопросы. Комментаторам спасибо за комментарии. и до новых встреч. Всем спасибо. До новых встреч. 

S01 [02:09:00]  : До свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
