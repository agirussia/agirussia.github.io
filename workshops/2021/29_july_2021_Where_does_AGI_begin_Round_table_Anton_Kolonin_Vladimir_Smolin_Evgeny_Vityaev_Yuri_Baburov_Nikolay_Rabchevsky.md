## 29 июля 2021 - С чего начинается AGI? - Круглый стол - Антон Колонин, Владимир Смолин, Евгений Витяев, Юрий Бабуров, Николай Рабчевский  — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/EwbQ_x3ruO0/hqdefault.jpg)](https://youtu.be/EwbQ_x3ruO0)

Суммаризация семинара:

Семинар посвящен обсуждению вопросов, связанных с развитием искусственного общего интеллекта (AGI). Участники обсуждают определения и критерии достижения уровня общего интеллекта, а также минимальные требования для его реализации.

Основные Тезисы:

1. Определение Общего Интеллекта:
   - Спикеры обсуждают недостаточность существующих определений общего интеллекта.
   - Евгений Евгеньевич подчеркивает важность прогноза достижения цели и сенсорной коррекции.
   - Обсуждается необходимость акцепта результата действия и образа результата.

2. Сложность и Эволюционные Ресурсы:
   - Первый вопрос семинара касается согласия с определением общего искусственного интеллекта.
   - Евгений Евгеньевич не согласен с недостаточностью определения, так как оно не учитывает прогноз и акцепт результатов действия.

3. Минимальные Требования для GI и AGI:
   - Третий вопрос семинара касается соотнесения GI и наличие образа акцептора результата действия.
   - Евгений Евгеньевич утверждает, что образ и результат действия для GI необходимы, но недостаточны.

4. Образ Мира и Акцепты Результата Действия:
   - Обсуждается вопрос о наличии образа мира у нейрона и AGI.
   - Евгений Евгеньевич подчеркивает, что у нейрона нет образа мира, и это не обязательно для AGI.

5. Реализация Образа Результата Действия:
   - Спикеры обсуждают, как реализуется образ результата действия на разных уровнях развития GI или AGI.
   - Евгений Евгеньевич говорит о необходимости прогноза достижения цели и сенсорной коррекции.

6. Личное Отношение к Проблеме:
   - Владимир Смолин делится своими успехами в создании минимального AGI.
   - Евгений Евгеньевич рассказывает о двух проектах, в которых применяются элементы AGI.

Вывод:
Семинар показал, что вопросы общего интеллекта остаются открытыми и требуют дальнейшего исследования. Участники обсудили важность прогноза и акцепта результатов действия, а также необходимость реализации образа мира. Были подняты вопросы о минимальных требованиях для достижения уровня общего интеллекта и о личном опыте участников в создании систем с элементами AGI.



S03 [00:00:06]  : Коллеги, добрый вечер всем. У меня вопрос один есть, в первую очередь ко спикерам сегодняшним. Как нам правильнее построить разговор? Есть два варианта. Один вариант – это по кругу вопросов дать возможность высказаться каждому. А второй вариант – это пойти по вопросам и отписать от вопросов. То есть сначала один вопрос проговорить со всеми, потом второй, потом третий, потом четвертый и так далее. Я за первый вариант. 

S05 [00:00:40]  : Что-что? Я за первый вариант, потому что вопросы взаимосвязаны и, как вы правильно говорите, с разных систем взглядов, на них ответы будут сильно различаться. Хорошо. 

S00 [00:00:53]  : Я поддерживаю Владимира Смолина. 

S03 [00:00:56]  : Хорошо. Давайте тогда начнем. Давайте я тогда попытаюсь проинтерпретировать то, как я вижу вопросы, а потом дам слово всем остальным участникам. Итак. Я сейчас открою список вопросов. Первый вопрос простой. Есть определение синтетическое Герцеля, Маркуса, Вонга, что общий интеллект – это способность достигать сложных целей в различных сложных средах. и в условиях ограниченных ресурсов. Соответственно, согласны вы с этим или не согласны. И если вы не согласны, то второй вопрос – это каково ваше определение General Intelligence, Artificial General Intelligence и в том числе Human-Level Artificial Intelligence. Потому что важно это соотносить, потому что в наших дискуссиях часто создается впечатление, что многие под GI подразумевают Human Level Intelligence, а под AGI подразумевают Human Level Artificial Intelligence. В то время как по мнению большинства людей это вещи разные. Поэтому вот здесь вот хотелось бы позицию спикера иметь проясненной по этому второму вопросу. Значит, третий вопрос это, собственно, какое отношение имеет к GI? вообще и AGI, в частности, наличие образа и акцептора результата действия. Ну, а заодно, как вы понимаете, если имеет, то как вы понимаете, или если не имеет, то на основании чего, на основании какой интерпретации и определения образа, акцептора и результата действия делается соответствующее заключение. Значит, следующий, четвертый вопрос, изменяюсь, только сейчас заметил множество опечаток. Значит, суть вопроса в чем? Что вот, хорошо, допустим, мы договорились, у нас есть какое-то определение GI, например, вот то, которое указано в первом пункте. Соответственно, в рамках этого определения, когда мы можем... сложности сред, и определенный уровень ограниченности ресурсов, и определенный уровень сложности целей. И вот если система достигает интеллекта, или если мы имеем в рассмотрении систему, которая на данных уровнях сложности среды, сложности целей и ограниченности ресурсов умеет эти цели достигать, то тогда вот эта система имеет GI. Это вот один вариант. Второй вариант B – это когда мы берем систему, которая ничего не может, но в результате какого-то процесса обучения система может добиться того, что она этот уровень будет достигать. То есть, система может научиться этому уровню с какого-то гораздо более низкого уровня. Это вариант B. Вариант В. Мы не говорим о том, что система должна достигать какого-то уровня. Мы говорим о том, что система должна уметь возможность повышать свой уровень. То есть, В – это про то, что на самом деле система должна продемонстрировать способность учиться. И тогда, если мы имеем возможность верифицировать систему двигаться по кривой обучения с увеличением сложности решаемых задач и достигаемых целей, вот тогда мы говорим, что вот некоторая скорость движения по кривой обучения говорит нам о наличии интеллекта. Ну и, наконец, последнее, G, это самое, так сказать, облегченное, это мы просто верифицируем, что каким-то образом, не знаю пока каким, верифицируем, что у системы есть потенциал возможности такого движения к усложнению своего поведения, определенной или безграничной сложности. И как только мы видим, что мы эту возможность каким-то образом верифицируем, мы успокаиваемся и говорим, что фундаментальную задачу мы решили, а дальше можно заняться чем-то более интересным или начать монетизировать этот проект. Дальше пятый вопрос. Развитие четвертого. Каковы минимальные требования? Где мы говорим, что GI достигнуто и можно получать заявку на Нобелевскую премию? уходить на пенсию. Это если мы говорим про AGI. А если мы говорим про GI, то какие уровни организации материи ему удовлетворяют. То ли это клетка с ногами, которая там бродит по чашечке Петри, как мы видели на видео, на заставке. То ли это попугай который там замки открывает, то ли это все-таки обезьяна, которая там из ящиков пирамиду строит и залезает на них с палкой, то ли это все-таки наш брат-человек. Шестой вопрос. Соответственно, если у нас действительно нужен образ акцепта результата действия, и если спикер определяет определенный уровень развития GI, или AGI, то как на данном уровне, с его точки зрения, реализуется этот образ результата действия, какова его реализация. Ну и последний вопрос, личное отношение к проблеме, то есть, что вы делаете, таковы ваши успехи на данном направлении. На этом я, наверное... Альберт Ефимов к нам не присоединился, да? То есть я не вижу. Хорошо, ну тогда слово... А Евгений Евгеньевич у нас опаздывает. Ну тогда получается, Владимир, слово вам. 

S05 [00:06:39]  : Хорошо, сейчас я тогда запущу. 

S03 [00:06:45]  : Ну и по регламенту у нас получается, наверное, с учетом того, что у нас четыре спикера, наверное, по 20 минут и 10 минут обсуждения, а потом общая дискуссия. 

S05 [00:06:54]  : Очень хорошо. Так, сейчас загрузится. вывести на полный экран. Общая идея состоит в том, что сильный искусственный интеллект это не какие-то действия с данными, а убрать из головы вот того человечка, которому все эти преобразования делают большинство современных систем. То есть, чтобы голова работала сама, не так, что открываешь, а там человечек. Опыты это не подтверждают, но мы все привыкли жить в такой парадигме, что вот мы давайте как-нибудь преобразуем информацию, а потом там человечек, который внутри, он эту информацию поймет. Вот, вот основное отличие, значит, интеллектуальных систем, которые ставятся в кавычки, что они интеллектуальные, от действительно сильного интеллекта в том, что там, значит, нет человечка, и он, значит, преобразует эндоинформацию. Ну и еще некоторые тонкости, о которых я скажу. План моего расклада, я в конце отвечу на вопросы, а сперва несколько предварительных обсуждаю. Дам некоторые определения, которые я уже давал, но попробую повторить. Может быть с какого-то раза их удастся понять. Выделю о том, что есть сингулярные понятия. Стол, стул, которые... Стол и все, без параметров. А можно ему... дать пространство-состояние, пространство-состояние аппроксимировать, как статическое, так и динамическое в виде фазовых портретов, и это будет более интересное в смысле построения модели окружающего мира на описание. расскажу про три важные идеи, которые необходимо бы приступать исследовать, то есть вот та оптимизация градиентным спуском, которая сейчас дала замечательные результаты и там, наверное, стива революции из-за этого произошла, вот, но если добавить еще какие-нибудь глубокие достаточно математические идеи, а именно вот те хотя бы три перечисленных, то это еще приведет к некоторым успехам, на мой взгляд. Вот, ну и, собственно, то, что, собственно, вот, Вопросы между человеческим уровнем и, собственно, сильным искусственным интеллектом, на мой взгляд, это все очень условно, я уже об этом тоже как-то говорил, но, значит, тема есть, я повторюсь, может быть, опять из какого-то... Ну и, собственно, на все вопросы я дам ответ. Да, нет, там, ну и как-то немножко, значит, на основе того, что я изложил. Вот. Ну, собственно, я уже вспоминал, там, Жуковского о том, что, значит, человек полетит, опираясь на силу своих не носило своих мыслей, а носило своего разума. Все было хорошо, но биологический вид находит, что человек не изменялся за последние 40 тысяч лет. Но полетел только 100 лет назад с небольшим. И как он был человеком разумным, так он остался человеком разумным. А развилась цивилизация, развились технологии, науки. какие-то там вот собственно сам Жуковский там придумал преобразование Жуковского значит комплексная вот и это все значит дало возможность развить интеллект и вот разумность и интеллект я собственно хотел бы обратить ваше внимание что их на мой взгляд желательно разделять что это разные вещи что скажем так, вообще мышление, вот как список определений, которые я хочу познакомить и вкратце прокомментировать, что мышление, как многие, значит, соглашаются, что это основано на моделировании тех ситуаций, которые могут походить в реальном мире. И с какой целью мы это делаем? Чтобы сравнить. А вот какая нам ситуация больше нравится, какая там меньше нравится? Можно, конечно, просто помечтать, но все равно вот это подходное сравнение какое-то идет. Сознание основано на том, что мы могли себе представить о том, что происходит в реальном мире, надо как-то соотнести. И вопрос соотнесения текущих действий с тем нашим мыслительным процессом, который есть, он определяет за этим сознание. То есть если мы в сознательном состоянии, наш мыслительный процесс направлен на текущие действия. А если мы в прострации, то можем о чем-то мечтать и не соотноситься с текущими действиями. Разум, на мой взгляд, это в целом способность к развитию интеллекта. То есть, допустим, когда амеба совершает какие-то действия или попугай, как сегодня было, развивает, он какие-то разумные действия совершает, но способностью к развитию своего интеллекта, у него есть, но достаточно низкие. У человека этот разум выше, поскольку у него больше, скажем так, возможностей к развитию интеллекта. То есть любые разумные действия, конечно, могут осуществляться, но степень разума определяется как раз способностью к развитию интеллекта. А, собственно, сам интеллект — это возможность решать задачи, не связанные напрямую с непосредственным во время текущих потребностей. То есть, когда вас спрашивают о том, Обладает ли ваш, допустим, телефон интеллектом? Ну, задайте, вот, согласно этому определению, задайте вопрос. Во-первых, есть ли у телефона какие-то потребности? И вы, конечно, можете найти к нему какие-то потребности, допустим, потребности, там, звонки передавать, еще что-то. Вот. Но, значит, при этом, если он даже это осуществляет, значит, выполнение этих потребностей, то интеллект он все равно не проявляет, поскольку он, значит, осуществляет действия, которые связаны с его непосредственным удовлетворением текущих вот этих потребностей, которые ему только что, значит, дали. Ну и всякие пчелиные рои, муравейник, тем более амеба, которая совершает какие-то действия, естественно, она в этом смысле интеллектом не обладает. А человек, он, опять-таки, не выросший в джунглях или на острове, кроме физиологических потребностей никаких особых ценностей не имеет, он, конечно, тоже интеллект у него слаборазвит. А вот выросший в цивилизации человек, у него цивилизация позволяет развить этот интеллект и, соответственно, ну, надеюсь, что все здесь присутствующие, значит, интеллектом обладают, может быть, в разной степени, но тем не менее. Вот. Ну и, собственно, цивилизация это как бы то, скажем так, условия, которые обеспечивают развитие интеллекта. Поскольку на всей цивилизации нет, то скажем так, что нет возможности не развивать интеллект, не заниматься интеллектуальной деятельностью и, собственно, нет средств для реализации каких-то интеллектуальных результатов. Есть две стороны формирования индивидуального интеллекта. Это биологическая эволюция, которая дала нам какие-то способности, тело, мозги и прочее. А, соответственно, цивилизация дала знания, возможности их реализации, разделение труда и много еще чего тут перечисленное. И интеллект формируется в цивилизации, но нужно обладать способностью. Кошки и собаки тоже живут в нашей цивилизации, но интеллект у них не развивается, поскольку у них способность в этом плане похуже. Вот. Ну и, собственно, если есть эти две стороны, и мы строим агента сильного искусственного интеллекта, то, собственно, что нам более важно? Делать его разумным, в том, чтобы воспроизводить биологию человека, или делать интеллектуальным? То есть, чтобы он воспроизводил успехи цивилизации. То есть, строить какие-то математические структуры, преобразовывать информацию. делать какие-то, значит, решать линейные уравнения или не обязательно линейные. Это, конечно, нужно и полезно, но, на мой взгляд, это не составляет основу агента сильного искусственного интеллекта. Нужно, чтобы этот агент был разумным, то есть обладал сознанием, имел чувства и мог стать субъектом права для восприятия и развития достижений цивилизации. А, собственно, все успехи цивилизации могут распродить промышленные роботы, автоматические линии, информационные системы, какие-нибудь средства поддержки принятия решений, ну и много других автоматических систем, у которых нет ни сознания, ни чувств, и они не являются субъектами права. И центральной частью агентов сильного искусственного интеллекта должно быть формирование понятий. То есть они должны работать не с теми понятиями, которые мы им закладываем, или от Аристотеля к нам пришли, которому Зевс передал эти понятия. А соответственно, чтобы они сами могли формировать эти понятия на основе общений с окружающим миром. И нужно это не для имитации разумных действий или каких-то явлений психики, а для решения проблем сложности описания реального мира. То есть там и вопросы чувств, и вопросы прогнозирования, и сам факт выделения простых понятий. Он связан с тем, что мы сложные понятия аппроксимировать и в пространство состояния не можем, а как быть со сложным миром, который состоит из простых понятий и как из него выделять, это как раз все необходимо не ради имитации каких-то явлений психики, а ради того, чтобы описать этот сложный мир. Понятно, что допустим у нас в комнате кошка, и мы с камерой ее пытаемся снимать с разных ракурсов. Каким бы ракурсом мы ее не поворачивали, не дерево, не танк. не получится. Все равно, значит, будут кошки. Там в каких-то состояниях она может быть похожа на каких-то других животных, может быть еще на что-то она будет похожа, но в целом вот ее, значит, с разных ракурсов она снята и она, значит, образует некоторое, значит, пространство в состоянии полученной вот такой сенсорной системы. Конечно, обработка должна идти не в один этап, должна быть иерархическая обработка, локальных признаков, несколько этапов должна быть визуальной обработки, но это не меняет этого подхода, что если есть какой-то простой объект, стол, стол, кошка или еще что-нибудь, то у них достаточно простое пространство состояния. А если там 20 стульев или 20 кошек, то уже как бы Вместе пространство будет очень разнообразное, поскольку они там могут по-разному располагаться, действия использовать разные, и всего получается очень много. Поэтому выделение простых объектов из воспринимаемого пространства очень экономит описание внешнего пространства. Речь идет не только о статических описаниях, а и о динамических. Есть у каждого объекта так называемый фазовый портрет, когда характеризуется не только текущее состояние, но и скорость изменения этого состояния. Значит, оно может быть одно-двух-трех-четыреххимерное. И, соответственно, это описание позволяет характеризовать данный объект. Вот, ну и собственно о чем я вкратце скажу, о том, что, значит, наверняка его есть картирование, которое позволяет апоксидировать. Сегодня, естественно, мы не будем это обсуждать, но в целом есть некоторая техника, которая позволяет осуществлять моделирование вот этих самых пространствосостояний простых объектов. Вот. Ну и, собственно, зачем нужно это картирование? Если, как я уже сегодня сказал, что есть у нас замечательный успех инверситетовой революции за счет того, что мы применили идею оптимизации параметров на основе градиентного спуска, то если мы еще применим идею локализации данных, которые позволяют осуществлять независимое обучение, то есть когда мы учимся чему-то одному, другое не портится за счет того, что локализовано у нас расположение знаний. Декомпозиция за счет того, что мы компактно описываем простые объекты и вместо произведения объема, которое необходимо для описания набора простых объектов, мы получаем сумму знаний про каждый объект, и это, соответственно, сильно нам экономит знаний. Ну и наконец, если у нас есть карты, то можно выделять оси, что в некотором смысле осуществляет лионеризацию процесса описания, и это тоже очень эффективно для компактности описания внешнего мира. Вот, в принципе, идея картирования состоит в том, что не нужно прогонять информацию по всем десяткам, сотням и тысячам уровней, как это сейчас делается. То есть, в принципе, карта позволяет, значит, сенсоры на карте выделяют определяют то положение центра активности, где мы, собственно, считываем с карты данные, а на выход с этого места идут, собственно, значения активации наших эффекторов, ну и по мере того, также как головка магнитофона смещается вдоль ленты, ну или лента смещается вдоль головки, то же самое, значит, центр активности, двигаясь по карте, считывает какую-то информацию, которая идет на эффекторы, ну и это, собственно, обеспечивает считывание программы действий. То есть это не программа, в смысле каких-то операторов, а это именно некоторая программа музыкальная, которая записана на ленту. И она, собственно, идет считывание, ну, каждых ее конкретных значений. Вот. А верхние уровни нужны, собственно, для того, чтобы не просто воспринимать сенсорную информацию, а ставить какие-то цели. Ну и, соответственно, наоборот, эти цели, в смысле, как сказать, эту же информацию, еще тоже картировать, но уже на более высоких уровнях. То есть, поскольку каждый объект, он имеет, значит, пространство, состояние, есть у них переменные, они могут быть зависимы у разных объектов, или там внутри объекта могут быть какие-то частно есть какие-то общие свойства, можно строить карты этих новых переменных и так может быть несколько уровней иерархии представления. Важным моментом является наличие экрана. Когда мы осуществляем какое-то управление, все знания, которые хранятся на нашем уровне, нам не нужны. Нужна небольшая часть этих знаний. Выделение того, что мы считываем и используем для решения данной задачи. Чтобы строить модели простых объектов, тоже нужно из большого объема информации выделять достаточно узкую часть, построить карты простых объектов, потому что сложные объекты мы просто физически не можем построить карты. Ну и, наконец, очень важный момент стоит в том, что вот здесь есть важно, на этом простом рисунке показывается важное отличие мышления людей от мышления животных. что принцип многоуровневого мышления есть у всех высших животных, неважно, у дельфинов. осьминогов, птиц, кого угодно. Но нет ни у каких животных ни сотен, ни тысяч уровней обработки информации. 5, 10, максимум 15 переключений и вся информация прошла через нервную систему. Это физиологическое ограничение есть у всех животных, в том числе у человека. Но человек выделяется из мира животных, что он обходит это ограничение. Я вам рассказываю, ну и вы друг другу рассказываете не, скажем так, то, что вы конкретно увидели, а уже выводим речью и какими-то графиками, которые в том числе на этих слайдах, какие-то уже абстрактные понятия, и мы их еще раз пропускаем через нашу систему, и такой процесс может происходить неоднократно. И это, собственно, возможность. резко повысить число уровней иерархии обработки информации, оно резко выделяет человека над остальным миром животных и дает эффект, который мы наблюдаем в создании цивилизации. Касательно человеческого уровня интеллекта, давайте начнем с уровней В смысле жизни 1, 2, 0 и 3, 0 по Текборку, которая вот, собственно, картинка из его книги в верхней части, это то, что, собственно, жизнь 1, 0, она может только, значит, выживать и репродуцировать, значит, жизнь 2, 0 к этому добавляет еще возможность подстраивать свое поведение под текущие условия, а жизнь 3, 0, она, значит, позволяет не только, значит, поведение подстраивать, но и, значит, свое потомство улучшать направленно, не так, как у животных, что вот кто-то родился там более удачным, а кто-то неудачным, а кто неудачным, собственно естественно отбор как бы отсеял, а по потомству это хорошее, а можно собственно направленно улучшать свое потомство и вот это вот собственно жизнь 3.0 по тегу, ну так же как жизнь 2.0 она создавалась на основе жизни 1.0, то есть сперва должны были появиться какие-то животные с нервной системой, то есть не нервной системой, а скажем так, с отдельными хотя бы нейронами, чтобы обеспечивать безусловные рефлексы. А когда уже появилось несколько безусловных рефлексов, там можно было объединять и, собственно, начинать дизайн software, который, собственно, обеспечивает улучшение поведения под текущие условия. Вот. Ну, соответственно, появилась когда человеческая цивилизация, то есть как я тут хочу назвать Life 2.0, то есть она, значит, отличается от обычных большинства животных, то есть некоторые животные, там типа бобров, тоже меняют ландшафт, там еще что-то. Вот. Ну, значит, человеческая цивилизация это делает более направленно и более широкие возможности, то есть она не столько сама подстраивается под внешний мир, сколько начинает мир подстраивать под себя. Ну и, собственно, развитие этой идеи состоит в том, что мы вот сейчас разговариваем о том, как бы нам изменить себя, чтобы улучшить наши вот эти, собственно, разумные качества, чтобы мы быстрее развивали цивилизацию. вот и собственно значит вот как бы сказать уровень разумности человека владимир извиняюсь значит просто уже уже почти 20 минут вы говорите и чтобы это было похоже на круглый стол видите вот у меня внизу тут 12 слайдов из 16 

S03 [00:24:21]  : Я понимаю, но просто нам нужно, чтобы вы ответили на вопросы. 

S05 [00:24:25]  : Я очень быстро, на основе того, что я рассказал, отвечу на вопросы. У меня будет отдельный слайд, буквально через один, и я на все 7 вопросов отвечу. Вот, соответственно, вот этот человеческий уровень, он начался, как появилась цивилизация, как вот там взяли палку-копалку, там сделали какое-то кремниевое орудие, уже появился человеческий уровень разумности. И он, естественно, с точки зрения биологов, сохранился. То есть развивалась у нас именно наша цивилизация, которая повышала уровень нашего интеллекта. То есть сейчас мы можем решать квадратичное уравнение, писать стихи, еще что-то делать, сильно оторванное от наших физиологических потребностей. для развития цивилизации. Ну, в принципе, значит, когда появится жизнь 3.0, ну, скажем так, наша разумность от этого не повысится, а уровень интеллекта поднимется, конечно. Ну и, скажем так, цивилизация будет развиваться быстрее, значит, все будет, процессы идти более быстро. Но, значит, вот эта вот грань, когда будет создана жизнь 3.0, она может условно распространяться как-то, что интеллект вот раньше был не очень сильный, а теперь стал сильным. Это очень условная грань, но в принципе, поскольку вот эта все-таки ступень такая заметная, я бы ее предложил как раз считать, что вот, наконец, тогда-то наш интеллект и станет сильным. А пока что он, конечно, тоже ничего, но не очень сильный. Вот. Ну и, собственно, как сказать, вкратце скажу про этот слайд, тут не читайте ничего всего, потом, если кому интересно, я дам, соответственно, всю презентацию. Вот. Что, значит, скорость развития с появлением цивилизации, конечно, сильно возросла, то есть если там виды менялись тысячелетиями, то цивилизация за сто лет могла, особенно последние сотни лет, делать большие шаги и, конечно, скорость очень велика. Соответственно, если появится жизнь 3.0, то скорость еще возрастет, соответственно, будут улучшаться сами субъекты, которые развивают эту цивилизацию. И скорость будет расти еще дальше. Вот как будет принципиальное отличие. Повторяю, что технологической сангурарности, я считаю, не состоится. И, наконец, вопросы, как вы хотели. Согласны ли вы с определением, которое дает Герцель? Нет, я не согласен. Потому что решать сложные задачи могут различные устройства, которые есть сейчас. Но это, конечно, не искусственный интеллект. В том смысле, который разгадал. Но вот про определение сильного искусственного интеллекта и человеческого искусственного интеллекта я дал мысль о том, что в принципе они достаточно условно определяются, можно делать разные соглашения. Я предлагаю гранью между человеческим и сильным искусственным интеллектом ставить создание жизни 3.0. Может быть у кого-то есть более разумные идеи, но я хочу только обратить внимание, что эта грань очень условна. Как вы относитесь к наличию образа акцепта результата действия? На мой взгляд, оно необходимо. Пару слов скажу, почему оно необходимо. Что мы во всех своих интеллектуальных современных системах, нам нужна либо разметка данных, либо какие-то ухищрения, чтобы эта разметка данных как-то все-таки состоялась. Вот, собственно, гениальность там Анохина состоит в том, что он это как бы предвидел, и вот, значит, есть некоторый универсальный подход, который состоит в том, что давайте что-нибудь будем прогнозировать, а нас жизнь научит, правильный ли был наш прогноз или неправильный. Вот, и, собственно, Акцептор 10, это как раз про это. Мы составляем какое-то ожидание, что произойдет. Если наше ожидание правильное, нас жизнь научила, что мы молодцы, если неправильно, ну, соответственно, дала, значит, указание, где мы ошибались. Это необходимая часть сильного интеллекта. Определяется ли сильный интеллект? На мой взгляд не определяется. Вопрос в том, что интеллект это продукт развития цивилизации, а разум это средство стать субъектом цивилизованного общества. И вот эти вопросы из другой плоскости. Можно говорить, что какая-то связь есть, но они из другой плоскости. значит, минимальное требование сильному интеллекту, собственно, развития цивилизации, значит, условно можно говорить, что когда создадим жизнь 3.0, тогда вот он действительно станет сильным, пока он, собственно, не очень сильный, но все равно, значит, сильнее животных, поскольку мы развиваем цивилизацию и у нас, значит, более-менее получается. Вот, значит, на каком выбранном высшем уровне технически и биологически реализуется образ акцептора действия? Вот на том схеме, о которой я говорил, вот, на этом. Вот этот экран, он соответствует как раз акцентуру действия, то есть где-то ожидается, что будет, и на самом деле показывает, что произошло, сравнивается, используется для картирования более высокой характеристики уровень, но единственное отличие в той схеме, которая нарисовала, что таких акцентов в действии не один, а там несколько структур, то есть там может быть 4, 5, 6, в зависимости от того, что мы сделаем, но в целом это необходимая деталь. И, наконец, Каков ваш личный план по созданию минимального АГИИ и какие успехи? Ну, значит, я разрабатываю теорию, ищу, собственно, коллектив, которым АГИИ заинтересуется и, может быть, воспримет какую-то часть идеи, поскольку, ну, надо понимать, что то, о чем я рассказываю, это как бы не план работы для одного человека, там достаточно большой объем работ. Вот, ну, ту теоретическую часть, которую развиваю, может быть, кому-то интересно, но, собственно, я готов сотрудничать по ее развитию, если кому-то это интересно. Вот. Ну и, наконец, в качестве выводов хотелось бы обратить, что вот к той идее оптимизации, которая есть на основе градиентного спуска, хорошо бы еще добавить идеи локализации, декомпозиции и линеризации. На мой взгляд, именно эти идеи и их реализация позволят сильно продвинуться в развитии искусственного интеллекта. Ну, естественно, от того, что удастся лично мне слить какой-то вклад в развитие этих идей, это не так важно. Я думаю, что и без меня это разойдется. Я думаю, что в Китае к 25-му году создадут. Вот. Но, собственно, Развитие этих идей позволит перейти от имитации интеллектуальных действий к решению проблем, описанию сложности внешнего мира. Достичь решения проблем формирования простых понятий и создания на их основе описания сложного мира. Ну и проблема еще существует социальная, поскольку особенно в условиях рыночной экономики исследования хороши, когда они приводят за ближайшие 3-6 месяцев, ну в крайнем случае за 3 года, к каким-то коммерческим успехам. Поскольку я пока что этого обещать не могу, то со стороны менеджеров понимания моей теории, к сожалению, нет. Ну, что делать? Вот, собственно, о чем я хотел рассказать. Если по тому, как я ответил на вопрос, есть какие-то вопросы, я готов, соответственно, дать пояснение. 

S03 [00:30:59]  : Владимир, спасибо. У нас есть пять минут на вопросы. Значит, у меня есть два вопроса, и потом еще есть третий вопрос от Игоря. Значит, первый вопрос. Вот вы сказали про экран. Все ваши ответы мне понятны. Значит, по экрану можете ли вы дать, во-первых, определение экрана компактное, а во-вторых, привести один или два примера реализации экрана на биологическом или физическом уровне? 

S05 [00:31:27]  : хороших примеров я в коротком таком ответе не приведу, но смысл примерно такой, что мы когда составляем карту, в ней можно уровни иерархии это не как у герцога с гетерархиями что можно связывать произвольные уровни получать какие-то новые понятия значит здесь все-таки и иерархия то есть в том смысле что значит карты формируют пространство состоянии значит сенсоров а карты следующего уровня формируют грубо говоря пространство состоянии кат Вот. Но в эти карты, значит, можно, грубо говоря, вводить оси и положение центра активности в эти карты, значит, как переменные, собственно, отображать на экран. Вот. Ну и, собственно, от карт, как бы, еще с этого уровня идет управление в смысле постановки целей. И вот, собственно, вот эта информация, которая отражается на экран, ну, там еще, там есть ряд условий, о которых нужно, как бы, делать отдельный доклад. Но в целом, значит, вот это, значит, средство, во-первых, управления, значит, установкой цели, значит, разных уровней, вплоть до исполнения, как бы, на нижнем уровне. Ну и, кроме того, это средство разделения. То есть, если мы, скажем так, карта нижнего уровня, ей поставлена цель, и она хорошо справляется с тем, что происходит, значит, в управлении, то верхний уровень у нас свободный для мыслительной деятельности. То есть, поскольку они моделируют, значит, какие-то переменные от нижних карт уже более высокого уровня, то в терминах этих переменных можно моделировать развитие различных событий под текущую обстановку, которую мы только что выяснили. Или как-то предполагаемость выяснить. И, соответственно, вот этот экран – это средство разделения. То, что по ткани МАНу системы 1 и системы 2. нижнем уровне экрана всегда быстро реагирует на то что происходит снаружи а собственно какие цели ставится если значит есть возможность промоделировать различные варианты на верхних уровнях это моделирование происходит но и собственно цели значит ставится не сразу на основе моделирования ну или настолько вот предыдущего моделирования если времени уже помоделировать нет вот такой ответ 

S03 [00:33:26]  : Все слова понятны, но все-таки непонятно, как работает акцептор. Но это, видимо, надо отдельно разбираться. Вообще, это самое интересное. Давайте уже отдельно, потому что есть еще два вопроса. Второй вопрос. С одной стороны, вы сказали, что для AGI нужна цивилизация. С другой стороны, вы сказали, что AGI уже через 4 года будет сделан в Китае. Соответственно, вопрос, а какая там цивилизация-то будет? Вы хотите сказать, что в Китае АГИ посадят на существующую цивилизацию? 

S05 [00:34:03]  : Ну, это моё, во-первых, предположение, что сделают в Китае, поскольку там сейчас наилучшие условия. Там хорошее финансирование, большое число людей этим занимаются, ну и есть, скажем так, техническая база для развития. Цивилизация у нас на самом деле общая. Конечно, когда-то была отдельно у древних ацтеков цивилизация и с египетской цивилизацией не пересекались. Сейчас у нас цивилизация общая и она уже есть. Это не то, что будет какая-то новая цивилизация. Неважно, в Китае, в Иране или в Израиле создадут агентов сильного искусственного интеллекта. они все будут так или иначе взаимодействовать с той цивилизацией, в которой мы живем. И если они будут направлены на то, чтобы служить этому обществу, то они будут ее развивать. Хотя могут быть и другие применения, какие-нибудь автономные летальные средства, много чего сейчас предлагается и реализуется. Вот, соответственно, значит, цивилизация, во-первых, она уже есть, она как бы общая, то есть, конечно, везде есть своя национальная специфика, реализация этой, значит, цивилизации и условий, в которых создается сильный искусственный интеллект, значит, в Китае, на мой взгляд, сейчас наиболее благоприятные условия, поэтому я предполагаю, что она будет создана, скорее всего, там. Ну и в целом, поскольку в мире сейчас занимаются уже не сотни тысяч, а миллионы исследователей этими проблемами, то, конечно, подавляющая часть решает какие-то коммерческие проблемы, но в Китае всё-таки, поскольку, повторюсь, занимаются этим очень много... Владимир, можно короткий ответ? 

S03 [00:35:28]  : То есть, цивилизация будет не искусственная, а цивилизация будет использоваться естественная? Правильно? 

S05 [00:35:34]  : Да, цивилизация человеческая, в которой мы живем, она уже есть, она уже там десятки тысяч... На ее основе будет построенный GI. Да, то есть используем тех самых цивилизаций, которые есть на ее основе. 

S03 [00:35:46]  : Спасибо. Третий вопрос от Игоря. Какие проблемы возникают при развитии теории? 

S05 [00:35:55]  : Проблема в том, что мы все говорим о своем высоком интеллекте, но мы к этому определению относимся так косвенно, что мы не развиваем те теории, которые они приносят коммерческим результатам. Когда начинаешь кому-то рассказывать о том, что это теория, а коммерческий результат есть, Пока нет. Есть теоретики, которые занимаются высокоинтеллектуальными вопросами. Ты рассказываешь, что есть такая проблема, давайте попробуем ее решать. Как бы сказать, а мы эти проблемы пока не занимаемся, нам она не интересна. Вот это как бы стандартный ответ. То есть вопрос в том, что вот те проблемы, которые поднимаются, попытаюсь развивать, ну не то чтобы никто их не хочет понимать, все-таки есть у меня там небольшой круг, с кем я могу общаться, но это буквально 2-3 человека. Вот основная проблема. 

S03 [00:36:48]  : Хорошо. Владимир, спасибо. Коллеги, у нас, во-первых, поступила информация от Альберта Ефимова, что он застрял на совещании и не может к нам присоединиться. Но появился Евгений Евгеньевич. Евгений Евгеньевич, вы готовы? 

S02 [00:37:03]  : Да, я готов. Без презентации, правда. Да, тогда вам слава. 

S03 [00:37:07]  : Может быть, я тогда выведу вопросы на экран, чтобы было проще. Пожалуйста. Вот я вывожу вопросы на экран, а заодно результаты голосования. 

S02 [00:37:20]  : Ну, значит, первый вопрос. Согласны ли вы с определением, что общий искусственный интеллект способен достигать сложных целей в сложных средах в условиях эволюционных ресурсов? Я с этим определением не согласен, потому что оно сильно недостаточно, и оно никак не характеризует сильный искусственный интеллект. Первая причина, почему оно недостаточно, здесь нет прогноза и нет акцепта результатов действия. На самом деле, как показывал еще Бернштейн, как бы точно мы не рассчитывали, потому что у нас есть AGI, который точно рассчитывает наши действия. Но Бернштейн показывал, что если система имеет много степеней свободы, например, человек, если он, положим, пианист, при тех степенях свободы, которые есть, в каждой степени свободы делает отклонение только на один градус, то в этом случае пианист ошибется на терции. То есть ни при каких точных прогнозах точно предсказать результат действия невозможно, хотя бы в силу того, что есть хотя бы элементарные ошибки в самой физической системе. Эта участь заранее никак невозможна. Для этого специально будут так называемые сенсорные коррекции. А сенсорным коррекциям нужно научиться. одновременно с прогнозом достижения результата. То есть мы в соответствии с теорией функциональных систем прогнозируем, что мы достигнем такой-то результат, такой-то, такой-то. Мы последовательно их достигаем. Если мы чуть-чуть ошибаемся, мы делаем сензорную коррекцию. И в реальных системах это всегда так. То есть невозможно заранее это все рассчитать. Поэтому это все должно присутствовать и сенсорной коррекцией, и прогноз достижения результата, и проверкой его реального достижения, и проверкой того, насколько мы точно попали или немножко отклонились, и скорректировать это для того, чтобы в конце концов достигать цели. То есть необходимость вот этих элементов совершенно необходима для создания некоторых более-менее реальных систем. Второе, недостаток этого определения, в нем нет образа мира. На самом деле настоящий интеллектуальный прогноз, освоение среды и достижение целей в ней предполагает создание образа мира. Именно образ мира позволяет учиться точно и быстро, самое главное. То есть в более-менее сложной среде чистым обучением на основе проб и ошибок обучиться невозможно. Поэтому на самом деле нужно научиться создавать образ мира. Это известный эксперимент, что если мы ковку запускаем в пустую комнату, Она сначала ее обходит и создает некоторую модель среды, потом она уже начинает что-то в ней делать. То есть создание образа мира или образа среды – это первейшая задача, которая решается организмом. Ну и, наконец, третий недостаток этого определения. Дело в том, что нужно иметь образ мира, нужно иметь сознание, положим, в том же определении, как это определяет Лохвердов. Функция сознания – это разрешение противоречия. Как бы мы образ мира точно не создавали, при восприятии конкретной ситуации будут возникать противоречия в том, как мы воспринимаем. Потому что мы всегда воспринимаем в некоторых контекстах, которые относительно разных признаков могут немножко не соответствовать друг другу. И сознание должно не просто получать образ мира, а постоянно разрешать некоторые противоречия, возникающие в нем, чтобы отражение реальности было в этом образе непротиворечиво. Это основные функции сознания. Это тоже должно быть отражено в определении сильного искусственного интеллекта. В этом определении этого тоже нет. Но мое определение IGI – это на самом деле задачный подход, но который должен включать создание образа мира, но в определенном смысле, хотя я об этом точно не говорил, создание образа мира может быть сделано на слове вероятности формальных понятий, максимальное формальное понятие, которое включает образ мира. То есть, с этой сенсорной коррекцией, на самом деле, тот формализм, который я рассказывал, он тоже включается, хотя я тоже об этом явно не говорил. Все эти элементы, они должны быть. Но определяется ли AGI некоторым уровнем интеллекта системы? Ну, в общем-то, вот этих случаев недостаточно. Минимальные требования к AGI – это создание образа мира. в каком направлении мы двигаемся и какой личный план по созданию AGI. Это задачный подход, который в том числе включает моделирование когнитивного процесса и автоматическое формирование понятий вместо сформированием образа мира. И при этом разрешение противоречия должно делаться на основании сопоставления разных контекстов. Можно предложить определенную технику, о которой я не говорил, но это может быть сделано на основе вероятностных формальных понятий. Контексты можно друг с другом согласовывать, но для этого надо расширять понятие контекста и то множество объектов, на котором происходило обучение. Тогда в силу свойств вероятностных формальных понятий они автоматически будут согласовываться между собой. между собой. Я в точности об этом не рассказывал, но это некоторые теоретические результаты этих формальных понятий. Поэтому то направление к общему искусственному интеллекту на основе задачного подхода и логика вероятности моделирования реальности – это то направление, к которому мы двигаемся. Пока что, с моей точки зрения, оно охватывает, по крайней мере, основные множества интеллектуальной функции. Здесь, опять же, я не рассказываю про мышление, но оно на самом деле описывается. Бывший директор Института психологии Московского, У него была книжка о том, как можно описать мышление через понятие прогноза и о перцепции. Это описание очень точно характеризует, как можно описать мышление через прогноз достижения целей, который включает некоторые комбинации возможных результатов, которые можно получить. То есть комбинации имеющихся опыта вместе с прогнозом возможности достижения результата вот этим опытом. То есть если включить сюда еще элементы мышления, то тогда, в общем-то, как мне кажется, мы получим более-менее полное моделирование когнитивной функции. Но, как я опять же рассказывал в предыдущем докладе, это еще не охватывает формализации процесса познания. Но в нем есть свои задачи, для некоторых из которых методов еще нет. Спасибо. 

S03 [00:45:01]  : Евгений Евгеньевич, спасибо. Вот если можно, хотелось бы уточнить по нескольким вопросам. Во-первых, по поводу третьего вопроса, соотнесение GI и наличие образа акцептора результата действия. То есть, если я правильно понял, по вашему определению, Это, что называется, условие необходимое, но недостаточное. То есть, образ и результат действия для GI нужен, но ему нужна еще масса всего то, что вы перечислили. Модель мира, так сказать, и так далее. Правильно я понимаю, да? 

S02 [00:45:36]  : Да-да-да. То есть, для GI должно быть наличие прогноза достижения цели, то есть, наличие образа результата. А его достижение должно сопровождаться акцентом результатов действий, причем таким, который отслеживает все последовательные этапы действий, которые в соответствии с анарктической теорией являются континуумом поведения. осуществляется прогноз и континуально осуществляется контроль достижения результат. То есть, очевидно, этого нет в определении AGI. 

S03 [00:46:09]  : Хорошо. Тогда переходя к пятому вопросу. Вот в вашем понимании, каковы примеры существующие. Ну, видим, наверное, вот с этой точки зрения искусственного интеллекта примеров тогда, которые бы это реализовывали, если не считать отчасти систему Discovery, нет. Но вот в живой материи какие уровни ее организации удовлетворяют вот этому требованию, наличию модели, построению прогноза, верификации последовательности действий или иерархии действий через акцепторы? 

S02 [00:46:46]  : Минимальной единицей является нейрон. На самом деле теория функциональных систем, в соответствии с теорией Швыркова, как он это описывает, на самом деле можно переформулировать достижение цели, в том числе акцентура результатов и действия, самоорганизацией отдельных нейронов. Для этого нейроны должны быть активны. в активной парадигме. Но это есть работа Швыркова, но из них следует, что отдельный нейрон – это есть элементарная самоорганизующая единица, у которой есть акцептор результата в действии. Более низкие системы этим условиям не удовлетворяют. В экспериментах Швыркова, опять же, было показано, что когда есть акцепторы результатов действия, мы достигаем какой-то промежуточный результат, то те нейроны, которые сигнализируют о достижении этого промежуточного результата, выключаются, то есть их активность просто пропадает. То есть это как раз говорит о том, что эти нейроны не контролируют достижение промежуточных целей, но они не основаны на некоторой обратной связи, в результате которой их возбуждение, оно бы немножко падало, немножко увеличилось, как это делается в системах обратной связи, а оно просто исчезает. То есть оно в точности сигнализирует, что цель достигнута. То есть это не система обратной связи. Поэтому, опять же, есть некоторые условия. Но ДНК, конечно, уже не удовлетворяет. 

S03 [00:48:23]  : Хорошо. Евгений Евгеньевич, если мы берем за единицу нейрон, то каким образом на примере отдельного нейрона Это не на примере, а даже в случае отдельного нейрона, как вы видите реализацию акцептора и результата действия. Вот у нас есть там питательная среда в чашечке Петри, и мы туда помещаем отдельно взятый нейрон, которому там что-то нужно. Я не знаю, по градиенту ему двигаться или я не знаю, какая у него цель. Это отдельный вопрос. Допустим, он предпринимает, как ему нужно достигать этих каких-то целей, строить какие-то прогнозы и осуществлять какие-то действия. Как у него реализуется, на каком уровне у него реализуется акцептор результата действия отдельно взятого нейрона? 

S02 [00:49:13]  : Отдельно взятый нейрон достигает своих целей, кооперируясь с другими нейронами, когда они достигают определенной цели организма, и срабатывает функциональная система, которая удовлетворяет определенную потребность, а удовлетворение этой потребности прогнозируется этим конкретным нейроном, его активностью в совокупности с другими, и оно не просто прогнозирует достижение цели, а прогнозируется одновременно с этим, что после достижения цели он получит некоторое подкрепление. На самом деле это не явно прогнозируется этим отдельным нейроном. То есть он прогнозирует, что при своей активности он потом в дальнейшем получит подкрепление, то есть нужны ему метаболиты. Это он прогнозирует, включая свою активность. 

S03 [00:50:02]  : Евгений Евгеньевич, то, что я услышал, получается, что у отдельно взятого нейрона у него есть подкрепление. Он работает просто под креплением, он охотится за метаболитами. Но в полном виде функциональная система с акцептом результата действия, она строится уже на уровне нейронной системы нервной системы из более чем одного нейрона. 

S02 [00:50:27]  : Да, но акцепторы результатов есть, поскольку этот нейрон включен в целую функциональную систему, но он должен определенным образом сработать, то есть он делает некоторый прогноз, в частности, в определенный момент достижения некоторой цели, Он ожидает, что в процессе достижения функциональной системы он получит вполне определенный сигнал от внешнего мира, в который он должен сработать. То есть он мало того, что прогнозирует достижение цели, он ожидает определенный сигнал к себе от внешнего мира, на который он должен сработать. То есть у него есть определенные входы, на которые он ожидает получения сигнала. То есть, у него есть персональный акцепт результата. 

S03 [00:51:13]  : Евгений Евгеньевич, я услышал, но тогда возникает вопрос, что если у индивидуального нейрона есть способность настраивать свои индивидуальные входы на ожидание какого-то подкрепления и реагировать на ожидание этого, на получение этого подкрепления, означает ли это, что в принципе любая клетка может являться элементарным AGI кирпичиком. Почему обязательно нейрон тогда? 

S02 [00:51:45]  : Нейрон довольно специально устроен, про другие клетки здесь сложно говорить, потому что в них может работать более простая система обратных связей. И там это может быть проще. Нейрон специализирован на такого рода прогнозы и специализирован на получении определенных результатов, после чего он дает мощный спайк и выключается. Он работает определенным образом. Спасибо. 

S03 [00:52:16]  : Спасибо, Евгений Евгеньевич. Последний вопрос. Возвращаясь к обратному определению. Как вы ответите на следующий комментарий? Вот чем мне нравится определение, которое в вопрос вынесено, это тем, что оно легко верифицируется. Что мы можем создать среду определенной сложности, цели определенной сложности. определенный уровень ограниченности ресурсов и смотреть, может ли система решать, существовать в этих условиях или нет. А если мы в качестве критерия говорим о том, что у системы должно быть наличие способности строить прогноз, у нее должно быть сознание, У нее должен быть акцептор результата действия. То есть, если мы перечисляем элементы внутреннего устройства системы, а не функционал... То есть, мы описываем, на самом деле, в качестве требований функционал. Не функционал, а именно реализацию. А в то время как то определение, которое вынесено в вопрос, это больше про функционал. Но мы же не можем... означает ли это, что для того, чтобы понять, удовлетворяет ли система требованиями GI, мы должны разобрать и посмотреть, что у неё внутри. И если, к примеру, выяснится, что она функционал выполняет, как, допустим, вот GPT-3, если GPT-3 в состоянии одурачить человека и ввести его в заблуждение, что он разговаривает с человеком, несмотря на то, что у неё внутри нет сознания, То есть, мы говорим, что это human level intelligence, разговорного интеллекта. А в вашем случае получается, что недостаточно функционала, недостаточно имитации поведения. Нужно, чтобы внутреннее устройство тоже соответствовало определенным критериям. Можете прокомментировать? 

S02 [00:54:05]  : Дело в том, что здесь нужна система, которая включает действия, понятное дело, и протестирует, например, то, что есть у нее сензорная коррекция или нет. Это, на самом деле, достаточно просто, потому что мы берем достаточно сложную систему и в ней нет сензорной коррекции. В этом случае она ошибается раз, ошибается два, потом ее заносит вообще в сторону, и оказывается, что, как и пианист, ошибается на терцию, то есть она не в состоянии выполнить свои функции. Только в том случае, если она в состоянии довольно точно корректировать непрерывно свои действия, только тогда она достигнет цели. В противном случае это просто не будет. И это легко проверяется. 

S03 [00:54:48]  : Спасибо. Еще есть два вопроса от Владимира Смолина. На чем базируется уверенность, что ряд процессов познания еще никем не понят? Я только не понял, по-моему, Евгений Евгеньевич такого не говорил. 

S02 [00:55:03]  : Не то чтобы не понять, но не то говорить. Вот тем, что я рассказывал в прошлый раз об обнаружении законов Перлова в теории функциональных систем. теории физических структур. Но для нее нет алгоритма. Дело в том, что такой алгоритм сами разработчики пытались сделать, но это свелось к сложной системе нелинейных уравнений, которые поручали решить аспирантам. Короче говоря, решить пока это не удалось. Такого алгоритма пока нет. 

S05 [00:55:44]  : Ну, я это к тому, что я говорил о том, что когда говоришь о том, что вот квартира в нем, это можно решить. Но говорят, что мы этим пока не занимаемся, поэтому нам это неинтересно. Вот примерно почему я спросил. 

S02 [00:55:53]  : А, ну, понятно. Ну, то есть, это открытая задача, короче. 

S03 [00:55:59]  : Спасибо, Евгений Евгеньевич. Еще вопрос от Соколова. Вопрос. У нейрона имеется образ мира? Как вы видите образ мира нейрона? У нейрона нет образа мира. Тогда у AGI должен быть образ мира? У AGI должен быть образ мира. Мы же недавно с вами говорили, что нейрон удовлетворяет требованию минимального AGI. 

S02 [00:56:28]  : Нет. Нейрона удовлетворяет требованиям того, что у него есть акценты результатов действия, какой-то прогноз. Но это одно из условий. Создание образа мира – это более сильные требования. И у нее есть свои условия для создания образа мира. 

S03 [00:56:47]  : А можно уточнить, в чем различие между наличием прогнозной модели, которая описывает законы мира на уровне данной онтологии? Допустим, есть некоторая онтология нейрона, в которой он существует, которая описывает его среду с точки зрения тех сенсоров, которые он обладает. И если у него есть прогнозная модель, то почему нельзя сказать, что у него есть очень элементарный образ мира? Что включает в себя образ мира, кроме прогнозной модели? 

S02 [00:57:21]  : Но вот это лучше всего проиллюстрирует на понятии когнитома Анохина, потому что Анохин специально рассказывает о том, что когнитома включает две системы. Первая из них – это клеточная ассамбль, которая в потенциале создает образ мира. И вторая система – это система целенаправленного поведения и теории функциональных систем. Только их совместная интеграция может дать более-менее полное описание и системы действий, и одновременно создание образа мира вместе с организацией действий путем создания нервно-динамической ткани действий, с помощью которой в конце концов описывается образ мира. То есть необходима интеграция этих двух систем для создания образа мира. 

S03 [00:58:11]  : Вот здесь от Алекса Бура есть несколько комментариев по этому поводу. Первый вопрос. Есть ли у логического элемента, состоящего из нескольких транзисторов, акцептор результата действия? Мой ответ – нет. А в некотором смысле есть, как основная функция вытекающая из структуры данной системы. Дальше. У нейрона в некотором смысле есть образ мира. Он сам жестко заложен в структуру нейрона. 

S02 [00:58:41]  : Образ мира в него жестко не заложен, потому что на самом деле нейрон обучается участию в своей функциональной системе. Нейроны, которым задают исходную мотивацию, в них это активно заложено. Но остальные нейроны, которые включаются в обучающую систему и функциональную систему, они заранее не запрограммированы на достижение цели этой функциональной системы. Этому надо обучаться. Чтобы там пойти и поесть, или приготовить пищу, этому надо учиться. И каждый учится по-своему. 

S03 [00:59:17]  : Спасибо. Еще Юрий Бабуров просит прислать ссылку на работы Шваркова. 

S02 [00:59:23]  : Швыркова? Да. В Википедии достаточно задать Швыркова, и он сразу появится. Это очень известный ученый. Швыркова, да? 

S03 [00:59:37]  : Швырков. Спасибо. Коллеги, еще есть вопросы к Евгению Генщу? Спасибо. Вопросов нет. Ну тогда, Евгений Евгеньевич, вам спасибо. Слово дальше предоставляется Юрию Бабурову. 

S01 [01:00:02]  : Всем добрый день. Добрый вечер. Ну, я сегодня все-таки думаю пройдусь как раз по самым простым частям. Спасибо остальным за то, что они затрагивали более детальные какие-то куски и более сложные части, но нам надо хотя бы с основными частями, с самыми простыми частями тоже определиться. Сейчас попробуем включить презентацию. Не получилось. давайте вначале самые простые вопросы затронуть. что такое сильный интеллект? чем он отличается от слабого? обычное определение такое, что сильный интеллект это такой, который сам выбирает свои действия. но дадим роботу или простейшему какому-нибудь существу возможность подкинуть монетку или любую другую возможность, любую детерминизм, и эта система сама начнет выбирать свои действия. То есть, сильность против слабости – это, по сути, не детерминизм системы. Она сама делает, что хочет, а не подчиняется тому человеку, который ее создал. видимо, что это плохой критерий и, наверное, сильный искусственный интеллект не очень хороший. давайте другое слово выберем – общий искусственный интеллект. в этом этот вариант уже интересен. значит, общий интеллект – это такой, который умеет делать много всего, правильно? он умеет и на машинке шить, и песни петь, и корову дать. Каким образом же он возникает? Давайте разберемся. Я для себя сложил разные части интеллекта, которые принципиально разные. В аббревиатуру Волк Давайте разберем ее подробнее. Actionable интеллект – это такой, который способен проявлять навыки, строить и реализовывать планы. В целом любой узкий интеллект на самом деле является actionable, то есть он уже как-то запрограммирован, и он эти действия выполняет. Причем действия могут быть очень сложными. Действия могут включать ответы на вопросы. Мы знаем как раз парадокс китайской комнаты, который в общем-то и описывает вот эту ситуацию. Интеллекта, который нельзя или сложно доучить, но который может при этом ответить практически на любой вопрос. Другая категория для искусственных интеллектов, или настоящих интеллектов или не интеллектов – это способность использовать знания. Знания о мире или знания о задаче, или еще какие-то знания. Существа, собственно, эти знания со временем как-то получают, и отсюда у нас еще один навык – способность эти знания получать. Да, есть существа, которые полагаются на какие-то рефлексы и знания практически не получают. Но при этом вот такими рефлексами они какие-то знания о мире могут использовать. Известно, что людям розовый цвет кажется более безопасным, красный цвет, наоборот, более опасным. Миллион можно привести примеров, когда даже у человека есть какие-то зашитые зашитые правила, но у животных их еще больше, а у насекомых они… насекомые практически из них состоят полностью. Поэтому способность именно использовать знания как что-то, чего не было или как что-то, что приобретается с опытом – это отличительная способность тоже интеллекта. Дальше способность обучаться как раз этим произвольным навыкам, Я здесь отличаю навыки от знаний, потому что навыки – это то, что влияет на способность действовать, а знания влияют на способность рассуждать и принимать планы действия, вообще говоря, придумывать планы действия. То есть, чтобы как-то действовать, нам, в общем-то, нужны какие-то знания о мире, Но эти знания можно не пополнять. В то же время есть какие-то задачи, которые опираются на знаниях. Как видите, эти факторы разные. Нельзя какой-то одной шкалой оценить интеллект, нужно его изучать по этим разным шкалам. про последний навык скажу особо – получать знания из непосредственного опыта. Интеллекты как-то умеют, но только человек умеет получать знания из книг или каких-то более сложных обучающих материалов. Причем в принципе нет обучающих материалов животное воспринять способно. То есть рефлексировка – это как раз способность животных учиться на каких-то обучающих материалах. Но вот если брать книги или там менее структурированные какие-то знания, то вот здесь уже только человек. И теперь давайте еще раз для закрепления, скажем так, пройдемся по тому вначале, кто есть волк, а кто нет, по вот этому списку. Значит, растение, что оно умеет? У него есть какие-то навыки в зачаточном состоянии, что-то оно умеет. Знает ли растение о мире? что самое интересное растения знает Америка, потому что большинство растений запрограммированы на определенные изменения погодных условий, чтобы при этих изменениях погодных условий, измерения температуры и влажности, менять фазы собственного роста и развития. Например, все вы знаете, Широко сказал, кто-то из вас знает, что вымирают бананы, вымирают кофе и какао. Почему они вымирают? Потому что глобальное потепление поменяло на 2 градуса температуру в тех районах, где они живут. Они могут жить только в определенном диапазоне температур. Иначе они неправильно включают собственные фазы развития, и плодов нет вкусных. Поэтому растение о мире что-то знает. Может ли оно узнать больше о мире? Да, может узнать о мире больше, и это как-то влияет на его поведение. Может ли оно знаниями как-то управлять? Наверное, нет. То есть растение все же не волк. Точно так же мы можем пройтись по всем. Я сейчас не буду, конечно же, это делать. У стайных животных, например, есть система знаков, есть система сигналов. Этих сигналов немного, но они способны выучивать эти знаки, способны учиться у других особей какому-то поведению. То есть стайные животные, в принципе, уже приближаются к состоянию волк. Ну а Маугли примерно на уровне стайт животного. Потому что хоть он и человек, но без как раз та и без группы он не все свои навыки проявляет. Более интересным является вопрос, в какой момент появляется общий интеллект. Вот смотрите, растение выполняет одну задачу, оно растет. Знаете, получается, оно не общий интеллект. Правильно, амиоба растет. выполняет одну задачу вроде бы, значит, расти там, собирать еду, как-то размножаться, вроде бы тоже не общественное. Насекомые тоже, в общем-то, выполняют одну запрокрамированную задачу, но тут появляются стайные насекомые типа муравьев, типа пчел, которые демонстрируют разные поведения и могут уже решать интеллектуальные задачи. На уровне животных, например, у нас есть голуби, которых можно научить решать визуальные задачи, задачи распознавания изображений. Как вы знаете, голуби, в принципе, способны распознавать некоторые виды раков не хуже профессиональных рентгенологов. Их даже хотели применить для алгоритмов PageRank в первоапрельской шутке от гугла, чтобы они размечали как-то картинки, ходили по ссылкам и так далее. То есть можно сказать, что с момента голубя у нас уже появляется общий интеллект, потому что голубя уже можно приспособить для решения любой задачи. Это не значит, что голубе эта задача будет нужна в данный момент, но в целом он на это способен. И вот теперь вопрос, возникает у нас ситуация в живой природе, когда особи или виду нужно применить какую-то способность, какую-то особенность поведения, но получается тогда, это животное уже общий интеллект, потому что оно может решать как раз такие нестандартные задачи. Качество решения зависит, конечно, от животного, зависит от интеллекта и так далее. То есть вот эта граница общего интеллекта, вот здесь она плохо заметна. И что самое интересное, если мы попробуем Вернуться теперь к изначальному определению. Общий интеллект – это способность достигать сложных целей в сложных средах, в условиях ограниченных ресурсов. То мы видим, что здесь ровно та же самая проблема в определении, насколько сложной должна быть среда, насколько ограниченной должны быть ресурсы, насколько ограниченное должно быть время, Задача должна быть нестандартной для данного животного или там лида. Поэтому слово «общий» в интеллекте, вообще говоря, оно запутано. Я сказал так, как только появляется управление собственным поведением, вот этот тот самый интерминизм, появляется интеллект, Как только мы начинаем этот интеллект применять для разных задач, интеллект становится общим. И интеллект качественно, пожалуй, все же не отличается у разных видов, искусственный, естественный, но он сильно отличается количественно. Причем настолько, что эти количественные изменения дают качество. Поэтому давайте измерять интеллект численно, применительно к разным задачам. Можно также зафиксировать границы, минимальный уровень интеллекта, который способен уже называться общим. Поэтому в качестве этих задач я как раз и предлагаю использовать эту аббревиатуру как четыре разных вида задач. Потому что когда у нас стоит задача проявлять какие-то навыки, Обычно не требуется обучение до обучения и так далее, максимум какие-то локальные знания. Значит, когда говорится про способность использовать знание, то скорее говорится про какую-то, возможно, задачу, когда знание, опять же, у вас уже есть, вам требуется какие-то рассуждения. Дальше, когда говорится про способность обучаться, ну, вообще говоря, животные не так быстро обучаются. То есть они не могут по щелчку пальцев обучиться. И человек, в общем-то, тоже не может по щелчку пальцев обучиться. Поэтому способность обучаться нужно тоже измерять достаточно сложным способом. какой-то таймер, чтобы у нас был час, или день, или неделя, или год, и давать возможность обучиться. Ну и knowledge acquisition. Здесь тоже нам нужен какой-то критерий. Должны быть какие-то материалы, и нужно измерять, насколько существо приобрело возможность пользоваться этими знаниями потом. то есть вот видите, вот все эти четыре фактора, они все совершенно разные, и все они вроде как свойственный интеллект в разности каждому конкретно. поэтому я вот все же за более конкретное определение вместо одного общего, которое всех только путает. спасибо. 

S03 [01:14:39]  : Юрий, спасибо. Вопрос от Соколова. Почему только использовать знания, а не получать знания? А где строить знания? Или интеллект не строит знания? 

S01 [01:14:58]  : Получать знания – это строить знания. 

S03 [01:15:05]  : Knowledge Acquisition, то есть в Knowledge Acquisition у нас построение знаний. 

S01 [01:15:11]  : Получать знания из непосредственного опыта – это как раз обычно про создание новых знаний. Я бы их не разделял, потому что их, опять же, очень тяжело разделить друг от друга. 

S03 [01:15:24]  : Вопрос от Владимира Смолина. Правильно ли я понимаю, что с точки зрения Юрия разум и интеллект – это синонимы? 

S01 [01:15:35]  : но есть, опять же, очень много определений разума. Я не знаю, какой используете вы, но поэтому не могу сказать. 

S05 [01:15:48]  : Может, да, может, нет. Уточнить вопрос, что обычно все-таки интеллектуальные деятельности понимают способность к каким-то абстрактным преобразованиям, то есть, скажем так, что работа Земле, не знаю, чисто руками, она не рассматривается как особо интеллектуальная, хотя она требует знаний, сложная, тонкая. А интеллектуальная деятельность, особенно высоко интеллектуальная деятельность, она оторвана от непосредственного восприятия реальности. Вот как-то вы относите это разделение на разумную и интеллектуальную? 

S01 [01:16:27]  : Во-первых, опыт группы AGI Russia показал, что все склонны интеллектуальной деятельностью называть совершенно разные вещи. И разумной деятельностью, скажем так, практически любая деятельность человека включает включает в той или иной степени размышления, необходимость к размышлениям, то есть работать сознанием. И при этом практически любая деятельность включает в себя какие-то манипуляции предметами. Тот же ученый пишет ручкой, это манипуляция предметов. 

S05 [01:17:14]  : то есть вы противник системы канемана, у которого есть система 1 и система 2, которые не требуются размышлять, вы считаете, что везде требуются? 

S01 [01:17:23]  : деление в этой схеме есть. как раз если мы делим на навыки и знания, по сути мы как раз противопоставляем систему 1 и систему 2. why is it knowledge acquisition? это про систему 2. actionable e-learning – это именно про систему один. То есть, когда животное просто там играется с какими-то предметами, чему-то научается, при этом не получая знаний о том, как этот предмет называется и какое его место в мире, вообще говоря, это вот знаний таких вот о мире серьезных не возникает, возникают какие-то навыки по большому счету. отличия вот на таком уровне как раз есть. 

S05 [01:18:11]  : ну как бы все это очень легко поддается критике, но наверное не сегодня. 

S01 [01:18:17]  : да, ну вот я говорю, что вот эта система будет пожалуй немножко точнее, но вот безусловно наплывы одного на другое конечно есть, но во всяком случае это разные совершенно направления. то есть они автогональны, пожалуй, друг другу при измерении интеллекта. 

S03 [01:18:44]  : Юрий, спасибо. Вопрос все-таки. Извиняюсь, может быть, я углубился в чтение чата и пропустил, когда вы сказали. Если пропустил, извините и повторите. По поводу акцептора. Соотношение GI и акцептора с одной стороны и с другой стороны на том уровне. Да, это первое. Второе. Вы хорошо сказали про то, что уровни, и какой уровень является минимальным. Соответственно, с вашей точки зрения, с практической точки зрения, какой уровень имеет смысл считать минимальным? Что бы вы выбрали? И чтобы вам казалось бы удобным, либо с теоретической, либо с практической точки зрения. Ну и третий тогда вопрос. Как на данном уровне реализуются пресловутые образы акцептора результата действия? 

S01 [01:19:37]  : Для меня минимальный уровень был бы как раз уровень условного голубя или условной мыши. Это уровень, при котором система начинает решать любые задачи в принципе. просто потому что мозг становится достаточно большим, чтобы и демонстрировать уже возможность как раз к интеллектуальному избирательному поведению. то есть он действует в зависимости от внешних условий и достаточно хорошо достаточно сильно меняет свое поведение в зависимости от внешних условий. растение слабо меняет свое поведение в зависимости от внешних условий. поэтому я бы этот уровень выбрал за минимальный. и вот как раз нейросекину, наверное, пожалуй, сильные нейросети, пожалуй, этот минимальный уровень сейчас демонстрирует мощность. в принципе их можно переучивать. ровно все те же свойства actionable learning и немножко чуть-чуть умеют novice and knowledge acquisition. вот такое вот есть. 

S03 [01:21:00]  : Хорошо. Тогда все-таки вопрос. Акцепторы результата действия, образ результата действия, они есть? Это полезное понятие? 

S01 [01:21:09]  : Они существуют? Для меня это понятие кибернетики, также как обратная связь. И система, работающая на обратной связи. Положительной и отрицательной. Есть много разных видов положительной обратной связи, сложных систем. 

S03 [01:21:29]  : Хорошо. Если мы говорим, где у голубя и где они у мыши, то, наверное, понятно, что примерно там, где на это указывал Анохин. А у сильных нейросетей где они? Можете на примере нейросетевой архитектуры показать, как работают образы акцептора результата действия? 

S01 [01:21:54]  : Архитектуры типа GPT-3, они пытаются демонстрировать что-то типа рассудочной деятельности. старые до этого уже написанные фразы и пытаются продолжить последовательность. то есть это наше предсказание любимое. соответственно в зависимости от предсказания при обучении они страхуются. то есть вот у нас есть целевая функция при обучении. Мы штрафуем за несоответственность силевой функции. При том, для некоторых задач силевую функцию построить легко, нейросети получаются хорошие и демонстрируют навыки очень хорошие. А для других задач с этим проблема. 

S03 [01:22:44]  : Потому что требуется учитель. Это мы их штрафуем. Ну, пожалуйста, друг. 

S01 [01:22:48]  : А где нет? 

S03 [01:22:49]  : А акцепты результата действия где? Где образ результата действия? Где акцепты результата действия? То есть продолжение фразы – это прогноз. 

S01 [01:22:57]  : нет, есть разные архитектуры принципиально, то есть не архитектуры сетей, а архитектуры обучения. а если у нас reinforcement learning, то у нас также штрафует мир. 

S03 [01:23:09]  : Нет, ну а где образ-то? То есть понятно, что мир штрафует. Это просто обучение с подкреплением. Это простейший условный рефлекс по Павлову. Тренируется. А где акцент на это действие? Где у нас образ и где у нас... То есть что-то по Анухину получается, что вот если бы нейронная сеть сначала бы предсказывала фразу а потом бы ожидала, что будет эта фраза получена, подкреплена положительно, а потом бы сравнивала бы результат подкрепления со своим ожиданием, и на этой основе она бы переобучалась, вот тогда бы это было так. Или вы хотите сказать, что это не явно так и есть? 

S01 [01:23:58]  : Что если она... Эту схему называет септифленин и применяется много дней. 

S03 [01:24:04]  : Окей, окей. То есть это то пресловутое самоподкрепление, вы хотите сказать, про которое мы какое-то время назад говорили? 

S01 [01:24:13]  : Ну, если можно, я немножко… Не самое, это подкрепление на обратной связи от мира. 

S05 [01:24:20]  : Если можно, я немножко про защиту нейронных сетей скажу, что, конечно, вот эта тема акцептора действия, она недостаточно развивается в нейронных сетях, но вот все вот эти генеративные сети, которые существуют, в принципе, показывают о том, что нейронные сети вполне хорошо могут прогнозировать и строить какие-то достаточно сложные ситуации и делать их очень похожие на реальность. И сравнивать с реальностью их потом можно. В принципе, эта тема, на мой взгляд, достойная развития, не то чтобы она совсем не развивается, на мой взгляд она развивается недостаточно. Её, конечно, надо интенсивнее развивать. 

S01 [01:24:53]  : Владимир, какие-то общие слова, но на вопрос совершенно не отвечающие. Нет, давайте попробуем… Юрий, можно я уточню вопрос? 

S03 [01:25:02]  : У нас есть еще 5 минут. Где нестыковка? Я понимаю, что у нас нейронные сети очень хорошо могут делать прогноз и очень хорошо могут решать задачи на уровне очень похожем в некоторых случаях. на то, как это решает человек, но я все-таки не вижу формально именно вот этой функциональной системы, именно способности прогнозировать реальность с учетом верификации соответствия реальности данному прогнозу. То есть, да, если система спрогнозировала реальность плохо, она наказывается, она штрафуется, в рамках reinforcement learning она переобучается. Но где здесь функциональная система, где здесь акцептор и образ результата действия? 

S01 [01:26:02]  : Нет, смотрите, все это многократно разбиралось, анализировалось, как нейросети работают. Так же внутри, если у нас нейросеть с вниманием, то сама вот эта часть внимания, она показывает как раз на что образ, как раз результат задается вниманием. То есть где и какого результата ожидать и на что похоже. Какое место на что похоже. То же самое в обычных сетях делается тем же обратным распространением ошибки. Обратное распространение ошибки – это ровно тот же самый метод, которым мы можем узнать, как сеть отреагировала. Потому что штраф — это как раз и есть то, что мы смотрим, в каком месте этот прогноз результата был неправильный, и в этом месте мы его подправляем. То есть в этом месте мы подправляем сеть, что результат в будущем изменится в правильную сторону. 

S03 [01:27:10]  : Это все в одном и том же. Евгений Евгеньевич, если вы слушаете, вы согласны, что обратное распространение можно считать аналогом образа и акцента результатов действия Анухинских? 

S02 [01:27:25]  : Нет, обратное распространение просто корректирует ошибку. Эта коррекция-ошибка – это способ настройки нейронной сети, более точная аппроксимация. Вот и все. Это способ обучения. Больше ничего. 

S01 [01:27:49]  : Результат можно измерить, например, той же функцией ошибки. Будет близость к результату. 

S02 [01:27:56]  : Функции ошибки можно посчитать. Вот, но... Будем ближе. 

S01 [01:28:02]  : по результату, по мнению нейронной сети. А образ – результат. 

S02 [01:28:06]  : Так, минуточку. Вот есть, так сказать, отдельные прекрасные работы. Вот опять же у того же Швыркова, его последователя… Значит, Швырков был зав. лабораторией в Институте психологии московской. Его последователь, то есть преемник, вернее, это Александр. У Александра есть прекрасные лекции, вот так называемые пассивные и активные парадигмы. работа функциональных систем. Так вот, пассивные парадигмы – это рефлексы, это есть как раз некоторые действия и проверки, достигли они результаты или нет. Здесь можно посчитать точность, можно посчитать точность прогноза, но это совсем не то, что активные парадигмы. В рамках активной парадигмы мы сначала делаем прогноз, Фиксируем наши ожидания и последовательность этих ожиданий. Потом последовательно их осуществляем и проверяем на выполнении. То есть у нас есть некоторый образ результата, к которому мы идем. И это совершенно разный парадигм. У него есть прекрасная лекция на эту тему. В YouTube, кстати. 

S03 [01:29:18]  : Спасибо, Евгений Евгеньевич, Юрий. Давайте я еще добавлю на этот же вопрос. 

S01 [01:29:26]  : Смотрите, вот тут недавно в группе спрашивали работу, которая бы показывала, как нейросеть с помощью reinforcement learning, каким-либо другим образом, но может делать вот как раз нацеливаться на что-то. ну то есть когда система делает что-то не в один шаг, а во много шагов. соответственно, вот о чем Евгений Евгеньевич говорит, что система, если будет настраиваться только на один шаг, этот шаг будет ошибочным, хотя бы немножко, то кто-то должен этот результат подправить. то есть эта же система на следующем шаге должна себя подправить, а потом на следующем шаге еще немножко подправить. это все активно изучалось парадигмами рекуррентных нейронных сетей и достаточно давно были получены рекуррентные сети. которые как раз ведут себя подобным образом, которые методом, вот этот метод последовательных приближений реализует, это как раз будет вполне активная как раз парадигма с результатом и так далее. На практике оно не сильно отличимо, не сильно нужно. 

S02 [01:30:50]  : Есть одна принципиальная разница, что такое образ будущего. Это мы не просто делаем прогноз, что вот такими-то действиями мы достигнем такой-то результат, вот с такими-то корректировками и так далее. Мы выбираем образ будущего, то есть мы делаем не один прогноз, который получается, если мы нейронную сеть запустим, мы получим какой-то один прогноз. Нет, мы делаем несколько, множество прогнозов. У нас есть разные способы достижения тела. Мы делаем разные прогнозы и выбираем тот образ будущего, который для нас эмоционально является наиболее приемлемым. Мы на основании различного рода прогноза выбираем и фиксируем то, что мы хотим достичь, только после этого начинаем это достигать. Мы заранее просчитываем множество вариантов действий, а не то, что у нас получится буквально за один раз, даже с корректировками. Образ будущего предполагает выбор из множества различных вариантов будущего, которые мы прогнозируем. 

S01 [01:31:52]  : я сомневаюсь, что у пчелы этот образ будущего это подразумевает. вот как раз за что я не люблю вот эту анохинскую систему, за то, что каждый ее понимает абсолютно по-своему. 

S02 [01:32:06]  : посмотрите определение образа будущего. 

S01 [01:32:09]  : вот нету определения. я искал определение образа будущего, искал, что значит, акцептор и так далее. Кроме общих слов я ничего не нашел. Поэтому каждый это понимает по-своему. 

S03 [01:32:20]  : Да, Евгений Евгеньевич, у нас, кстати, была дискуссия, действительно, по-моему, с Юрием как раз, где тоже искали определение. Определение, не нашли определение. Если вы нам насткнете пальцем, значит, и дадите ссылку, где хорошо расписано у Анохина это определение, то это, может быть, поможет и Юре, и мне, и, может быть, кому-нибудь еще. 

S02 [01:32:42]  : у меня, кстати, есть все классические работы на эту тему. 

S01 [01:32:45]  : Антону больше всего оно поможет, потому что в первую очередь спрашивает нас всех про акцепторы и образы будущего. а для меня, то есть я вижу, что также gpt3 перед тем, как предсказать следующее слово, да, конечно, настроит разные прогнозы. Она внутри строит разные прогнозы разного развития событий, на несколько слов вперед, на несколько даже фраз вперед. потом выдает следующее слово, потом снова строит прогнозы, на основании этих прогнозов выдает следующее слово. Так она действует. 

S02 [01:33:19]  : Есть много совершенно классических работ, которые не мешали бы ссылке эти выставить, может быть даже выставить эти где-то работы для скачивания, потому что большинство... Еще лучше в тезисном виде из них выписать определение. 

S01 [01:33:35]  : что авторы, как эти определения вводят. 

S03 [01:33:40]  : Дальше смотрите. Юрий, на самом деле спасибо. Евгений Евгеньевич, спасибо большое за пояснение. Юрий, спасибо за ответы. 

S01 [01:33:51]  : Я вот последние пять слов еще хотел поговорить, только сейчас, если я их вспомню. Дальше последний момент критики, вот самый последний, про то, что нейросеть выдает один результат. Это опять же не так. Сэмплирование с температурой, даже с дефолтной температурой, позволяет выдавать много результатов. Так же, как и у человека, эмоции в какой-то степени являются способом задать температуру и тот результат, который нам нужен в данной ситуации. 

S02 [01:34:30]  : Но она выдает множество результатов с учетом различных своих собственных различных активных действий, то есть не по различию параметров, которые идут на вход, а по тем различным действиям, которые она делает. Не по входным параметрам, а по действиям. 

S01 [01:34:47]  : вот для этого строят немножко другую систему, когда gpt3 вот это вот. но человек же тоже не за одну долю секунды разные варианты перебирает. 

S02 [01:35:00]  : за одну долю секунды? параллельно? 

S01 [01:35:03]  : вот на самом деле нет. интуитивно человек перебирает лишь ограниченное множество вариантов. если у человека включается перебор вариантов более сложных, то тогда это требует более длительное время и уже другая система, по сути. То есть также человек перебирает какие-то, фиксирует какие-то промежуточные моменты, что-то перебирает. Вот рассудочная деятельность, сознательная, ее можно также эмулировать, но вот если брать нейронки типа ЧПТ-3, то они именно, по сути, это интуитивное действие. Это вот человек, который говорит первой попавшейся, ну не первой попавшейся, но вот наиболее вероятное слово. 

S02 [01:35:43]  : Для мозга понятие перевора бессмысленно, потому что он работает параллельно. 

S01 [01:35:49]  : ну где-то параллельно, где-то последовательно. нет, ну когда шахматист играет в шахматы, он не перебирает миллионы вариантов. он сосредотачивается на каких-то позициях и 

S03 [01:36:02]  : в будущем и перебирает варианты действия. Я предлагаю дать слово следующему докладчику. Если у нас останется время, мы еще поговорим. У меня на самом деле все-таки хочется домучить еще Юры про акцептор в нейросетях. Но у нас еще один короткий вопрос есть от Соколова. Рука поднятая. И потом следующему докладчику нужно уже дать слово. Соколов, я не знаю, это Андрей Александр Соколов или А.Н. Соколов? Вы будете спрашивать что-то? 

S04 [01:36:33]  : Да-да, это А.Н. Александр Соколов. 

S03 [01:36:35]  : Да, добрый день, пожалуйста. 

S04 [01:36:36]  : Да, добрый день. Смотрите, мне кажется, что вот эта последняя сейчас дискуссия очень интересная была в том смысле, что Дошли до того, что давайте мы разберемся, что такое акцептор действия и образ результата действия, как я понимаю. Если не забрасывать эту дискуссию, потому что она сейчас тяжело как бы протекала, а все-таки ее попробовать преодолеть и продолжить, Думаю, что мы можем выйти на постановку вопроса о том, что интеллект вынужден, чтобы ответить на эти вопросы, он вынужден построить некоторые знания для того, чтобы связать образ результата действия с акцептором того действия который он производит то есть мы выйдем как раз вот на эту границу тонкую да которую мы все время упускаем ну или как бы проговаривать все равно как бы уходит от нас о роли знания в интеллектуальный в интеллектуальных действиях вот такой бы комментарий пока Спасибо. 

S03 [01:38:01]  : Хорошо, спасибо. Слово дается Николаю Рабчевскому. Николай, пожалуйста. 

S00 [01:38:07]  : Спасибо. Я постараюсь придерживаться списка вопросов. И начну с того, что с тем определением, которое в пункте 1 я не согласен. Дело в том, что, ну, во-первых, он совершенно неконкретный, потому что что значит сложные цели. Уровень сложности можно поставить очень разный. Во-вторых, как для сложных целей, так и для сложных сред. А что касается ресурсов, то в общем ресурсы, они по определению всегда ограничены. Неограниченных ресурсов не бывает. Поэтому в условиях ограниченных ресурсов это синоним слову с использованием ресурсов, что опять-таки тоже лишено смысла. Тут интересно другой момент. Во-первых, у человека разум – это есть вариант системы управления. Система управления – это система, которая вырабатывает решения, которая исполняется другой частью, не системой управления. То есть есть некие две системы, одна исполнительная, другая принимающая решения. Второй момент заключается в том, что реальный интеллект заключается в том, что работает такой цикл. Мы собираем информацию нужную для принятия решений, эту информацию обрабатываем и обрабатываем решения. Это самый общий принцип, который действует как там у этого попугая или мышки. или в штаб-квартире какой-нибудь партии, которая занимается организацией выборов, или в нашей голове. То есть процесс совершенно принципиально одинаковый. Поэтому, с моей точки зрения, AGI – это, прежде всего, первое, система управления, второе, способность отбирать ту информацию, которая нужна для принятия решений самостоятельно, а не работать по принципу мясорубки. Типа, что засунули, то и получили. Засунули в нее одно, насыпали, получили один результат. Насыпали другой, получили другой. Ничего не насыпали, система стоит. Это не интеллект. Интеллект работает все время, сам ищет информацию, вырабатывает решения и передает в подсистеме, которая выполняет эти решения. И при этом он не требует внешней мотивации. ЖПТ-3 не может ничего делать до тех пор, пока и не подсунут Она не может сама собрать информацию. А мышка может собрать информацию. Она побегает и найдет то, что ей нужно. Если ей хочется пить, она найдет водичку. Если ей хочется есть, она найдет еду. Теперь следующий момент. Дженерал. Что такое дженерал? Вот в английском дженерал это означает общего назначения. Это не означает как бы способность решать совершенно любые задачи. Это означает вот как производстве грузовых автомобилей. Есть шасси. На него можно поставить один мотор, а можно поставить другой. Можно поставить кабину с двумя дверьми, можно с четырьмя. Поставить кузов обычный или самосвальный. А конструкция автомобиля это, кстати, она general, то есть общего назначения, которая в каком-то конкретном случае может быть подстроена под нужды конкретного использования. То есть General говорит о том, что внутренняя структура реализации, то есть набор модулей, из которых мы строим систему AGI, она примерно одна и та же. В автомобиле есть шасси, есть система рулевого управления, есть трансмиссия, есть двигатель. А конкретную модификацию каждого из узла можно выбрать исходя из того, что мы хотим сделать. Но общая схема остается общей для самосвала и для маленькой легковушки. При этом уровень интеллекта. Сложно сказать уровень интеллекта, который можно уже считать действительно интеллектом. В зависимости от приложения, так сказать, мы где хотим, там и поставим. При этом главное вот то, чтобы можно было ожидать от системы то, что она самостоятельно соберет информацию и научится ее использовать, исходя из той миссии, ради которой мы ее создали. То есть, если мы сделали марсоход какой-то, наделили его искусственным интеллектом, то она будет собирать информацию и выполнять ту роль, для которой она выполнена. Путешествовать и находить там то, чего мы от него хотим. То есть наша задача будет снабдить её той системой внутренней мотивации, которая обеспечит деятельность в нужном аспекте. При этом, как это устроено внутри, оно, по идее, не должно отражаться в определении Джейна Розенфельдовича. Поэтому, когда мы говорим, что должен быть акцептор результата, должно ли быть прогнозирование, в определении это не должно присутствовать. И при этом я бы сказал так, что если она действительно является AGI, так у нее наверняка будет в каком-то виде и прогнозирование, и эксцепция результата. Но при этом как это будет выглядеть в конкретной реализации сложно сказать, и, наверное, может быть сделано по-разному. А где находится уровень опять-таки? То есть, с моей точки зрения, можно считать реальным наличие интеллекта Начиная от уровня… Ну, во-первых, требуется, чтобы была нервная система, потому что появление нервной системы – это как раз вот то разделение на две части, одна из которых вырабатывает решение, а другая, которая исполняет. Все, что не имеет нервной системы, оно, безусловно, не является, так сказать, интеллектом. в разумном определении. То есть, на самом деле, можно как угодно договориться. В общем, это соответствует общепринятому пониманию. При этом возникла она при переходе от растений к животным как раз тем, что решение нужно принимать довольно быстро, если ты хочешь движется. У растений есть некая обратная связь, реакция на внешнюю ситуацию, но поскольку у них процессы медленные и они не движутся, то нет необходимости в быстром принятии решений и достаточно каких-то очень медленных процессов. И возможностей исполнения тоже очень мало. диапазон принятия решений возможных, он тоже очень узкий. При появлении нервной системы мы получаем полноценное разделение на систему управления, систему принятия решений и систему исполнения этого дела. Ну и насчет плана. Я пытаюсь как раз разработать вот некий набор модулей, которые позволяют делать относительно простые системы, которые позволяли бы моделировать то, о чем я говорил, то есть самостоятельно собирать. информацию, обрабатывать ее, вырабатывать решения и, так сказать, совершенствовать свое поведение, исходя из внутренних мотивов. В целом, то, что я делаю, оно, в общем, очень похоже на то, о чем рассказывал Евгений Евгеньевич Витяев. При том, что терминология у меня совершенно иная, потому как я к этому пришел, наверное, с достаточно другой стороны. И, наверное, единственным существенным отличием является то, что я пытаюсь это делать без использования вероятностного подхода. на всех уровнях. А вот это заметное отличие существенное, но вот в целом в архитектуре, в логике, в общем, все очень похоже получается. То есть есть планирование, есть сбор информации, есть ее представление в неком виде. И ключевыми аспектами, которые сейчас, как мне кажется, стоят перед разработчиками, является наделить систему способностью работать с информацией из реального мира. То есть, получать информацию о динамических объектах в мире. То есть, если, скажем, робот создается, то обеспечить ему возможность спокойно, никого не задевая, ходить среди движущейся толпы. чего, скажем, роботы не могут делать, потому что нужно отслеживать движение многих объектов одновременно, то есть отслеживать динамические процессы во внешней среде. А просто найти что-то на картинке, Вместо того, чтобы отслеживать процесс во времени, задача радикально более простая. При этом нужно научиться единообразным образом для разных объектов научиться представлять эти знания о динамике внешнего мира. так чтобы это можно было применять на практике и в разных системах. Ну а что получится, посмотрим. В этой части у меня все. Если есть вопросы, я могу пояснять. 

S03 [01:51:36]  : Николай, спасибо. Вопросы есть от Александра Соколова. Во-первых, исполнитель Не обладает нервной системой? 

S00 [01:51:49]  : Нет, конечно. То есть, исполнитель – это все, кроме нервной системы. 

S03 [01:51:58]  : Окей. Что необходимо иметь для получения решения кроме информации на входе? 

S00 [01:52:13]  : Ничего. Система должна сама собрать нужную ей информацию и использовать ее и накопленные раньше знания, а также тот мотив, которым она руководствуется в данный момент, и выработать соответствующее решение. 

S03 [01:52:36]  : И последний вопрос. Как я понял, докладчику-интеллекту необязательно иметь акцептор образ результата и акцепцию собственного действия для получения или принятия решения. Но это странно. 

S00 [01:52:51]  : Ну, я бы сказал так, что не нужно требовать в определении AGI, чтобы присутствовали они. Но при этом, если мы реально AGI создадим, то в каком-то варианте они обязательно будут на самом деле реализованы внутри. 

S03 [01:53:13]  : А можно немного поподробнее про отличие определения картинки и динамику? Как система может определять какой-то процесс в динамике? 

S00 [01:53:21]  : Это от Игоря вопрос. Для этого нужно, во-первых, чтобы система была real-time, чтобы она непрерывно получала информацию от сенсора об окружающей среде. То есть если речь идет о зрительной информации, то мы вместо картинки должны иметь на входе видеокамеру и отслеживать, как меняется ситуация. Причем не просто глядя на вход от камеры, а управляя камерой в том смысле, чтобы направлять ее в нужном направлении, устанавливать нужный зум и так далее. Как делает оператор в системе наблюдения, в секьюрити-системе. Он управляет камерой для того, чтобы найти и следить за наиболее важными моментами. Вот точно так и здесь. Ну а как это описать внутри? Это вот пока что вопрос открытый. 

S03 [01:54:39]  : Спасибо, Александр. У вас рука, я вижу, поднята. Может быть еще? Волосом прокомментируете или спросите. 

S04 [01:54:47]  : Да, спасибо. Большой комментарий. Сначала Николай ответил, что для принятия управленческого решения интеллектом кроме информации на входе ничего не нужно, а потом почему-то добавил. Ну кроме как мотивации и кроме как некоторого опыта и знаний. Получается противоречие. что кроме информации необходимо для принятия решения. Есть предложение о том, что нужен некоторый идеальный образ полученного результата от того, что если этот интеллект совершит какое-то действие. Вы это отрицаете. Относите это к определенному варианту реализации. То есть намекаете на то, что при другом варианте реализации это не нужно. и так далее. так все-таки вы можете сказать что же внутри должно быть заложено интеллекту, чтобы он работал как интеллект? спасибо. 

S00 [01:55:59]  : ну должно быть Первая система, которая позволяет хранить накопленную информацию, причем как о стабильных связях логических между разными понятиями, обнаруженными системой во внешнем мире, так и о последовательности действий и событий, которые происходили в прошлом. Второе – это модуль, который будет прогнозировать результат доступных в данной ситуации действий. Причем прогнозировать не на один шаг, а на много. То есть делаем целое дерево вариантов в зависимости от того, какие действия возможны в данной ситуации. Для каждого из цепочек действий мы оцениваем, исходя из своего прошлого опыта, возможные исходы, которых может быть несколько для каждого из вариантов действий, исходя опять-таки из прошлого опыта. А затем, исходя из того мотива, которым мы в данном случае руководствуемся, мы выбираем то действие первое из цепочки, которое ведет к наиболее приемлемым результатом. А как только мы сделали первый шаг, мы обновляем информацию о текущей ситуации, полученную от центра, и повторяем процесс. То есть такой скользящий режим планирования, когда мы на каждом шаге корректируем ситуацию. При этом каждая новая ситуация может привести к тому, что старый план действий многошаговый будет отброшен, и более того, сама мотивация может измениться. Если кошка пытается ловить мышку, на каком-то шаге обнаруживается собака поблизости, то мотивация от ловли мышки мгновенно сменится на мотивацию спасения от собаки. Вот, я не знаю, ответил ли я на вопрос. 

S04 [01:58:54]  : Ну, ответ получился очень пространный. Я к тому, что можно ли вот из вашего этого большого ответа попробовать выкинуть формулировку интеллекта. Ту, которую вы пользуетесь, когда отвечали на мой вопрос. Как-то жесткой такой формулировки я бы не смог вытащить. Может, вы сможете, не знаю. Интересно получить от вас формулировку того, что вы сейчас сказали. Что такое интеллект, который вы сейчас описали, что он должен делать? 

S00 [01:59:29]  : Я более короткой формулировки не могу сказать. Я писал ту схему, которая, как мне кажется, реализуется. Опять-таки, я упоминал об этом в начале. практически в любых системах принятия решения, вне зависимости от того, является ли это животным, или системой автоматического управления, или коллективной системой управления, которая состоит из множества людей, множественных подразделений и так далее. То есть если мы возьмем вот систему управления, опять-таки я говорил, управление выборами для какой-то партии или управление военной операцией, то там будут подразделения, которые собирают информацию, будут подразделения, которые охранят информацию о прошлых событиях. И будет некое подразделение, которое анализирует вот мгновенную текущую ситуацию, прогнозирует возможные действия и выбирает исходя из этого решения. 

S03 [02:01:04]  : Спасибо. 

S00 [02:01:06]  : Больше мне нечего сказать. 

S03 [02:01:07]  : Хорошо. Николай, спасибо. У нас еще осталось 25 минут. И поскольку у нас не пришел Альберт Ефимов, я попробую сам свою собственную позицию высказать по этим вопросам. Итак, по определению. Я с этим определением согласен, поскольку оно соглашаться с ним, мне кажется, практично. То есть, есть некоторые практические соображения. Во-первых, просто чтобы удобнее было общаться, чем вы занимаетесь, какими вы задачами занимаетесь. Какие задачи вы решаете? Вот мы занимаемся AGI. Что такое AGI? А вот AGI вот это вот. И поскольку есть известные люди, которые придумали термин AGI 20 лет назад, и вот то определение, которое у нас имеется в этих вопросах, это определение, которое эти люди используют, мне кажется, просто с точки зрения упрощения общения проще с этим определением согласиться, чтобы говорить на одном языке, с одной стороны. С другой стороны, это определение, мне кажется, удобно в каком смысле? Что если мы говорим о том, что AGI или интеллект – это просто некоторая степень усложнения формы существования материи, способной к адаптации к внешней среде настолько, что она способна не только адаптироваться к этой среде, но и воздействовать на нее, и оценивать результаты своего воздействия, и прогнозировать результаты своего воздействия с тем, чтобы обучаться Дальше на результатах этого воздействия постепенно усложнять модели, постепенно дальше научаться воздействовать на среду таким образом, что содержание этих моделей транслируется в окружающее пространство и воспринимается другими участниками среды. И получать эту информацию от других участников среды через эту же среду уже не как обратную связь от среды, а какую-то структурированную, символную информацию о знаниях об этой среде, генерируемой другими участниками. Если мы на это дело посмотрим, и часто это возникает в дискуссиях нашей группы с участием Алекса Бура, Артура, Мне кажется, что это определение удобно тем, что позволяет заниматься разработкой инкрементального увеличения сложности. То есть, если мы научаемся делать сначала искусственного муравья, потом искусственную пчелу, потом искусственного искусственную лягушку, потом искусственную мышку, потом искусственного голода. То мы можем, постепенно усложняя задачу, постепенно подниматься на более высокий уровень. С третьей стороны, Вот я совершенно согласен, что для того, чтобы на каком-то уровне сложности, когда у нас сложность среды определяется наличием литературы на различных языках или наличием панели управления пассажирским самолетом или космическим кораблем, И сложность цели заключается в том, что нужно сохранить собственную жизнь и жизнь человечества, а также обеспечить достойное воспитание своим детям. И при этом еще и получить удовольствие от собственной жизни. Если мы достигаем такого уровня сложности как цели, так и среды, то безусловно, без наличия прогнозной модели, без наличия сознания, без наличия акцептора результата действия, без наличия сложной иерархии вот этих вот акцепторов действия в поведении, мы просто не сможем в таких сложных средах общаться. закладывать вот в наличие как бы технических требований, архитектурных требований к AGI, определение AGI, мне кажется это неправильно. То есть мне кажется, что вот как мы когда пишем спецификацию, да, вот есть что называется, функциональное требование или PRD. То есть, это то, что пишет продакт-менеджер. То есть, система должна соответствовать вот таким-то требованиям. А уж то, есть ли у нее внутри сознание или прогнозная модель, или акцепторы результата действия, это уже, что называется, спецификации. Это уже внутренняя техническая документация, архитектура, дизайн, как угодно его можно называть, SRS. Но это не требование к продукту. И с точки зрения софтверной инженерии, то есть, что у вас внутри. То ли у вас внутри BIOS-овские сети, то ли у вас GPT-3, то ли у вас символная логика. Если на заданном железе с заданным респонс тайм система решает свои функциональные задачи, прописанные впереди, или функциональной спецификации, то какая вообще разница, на чем она реализована – на нейросетях или на бейсике написано. И в этом, чисто с прагматической точки зрения, мне правильно С одной стороны, в определении AGI выносить именно функциональную часть. С одной стороны и с другой стороны иметь функциональную часть максимально гибкой, чтобы просто увеличивая сложность среды или увеличивая сложность рисунка. целей или ограничивая систему по ресурсам, мы постепенно могли подниматься все на более и более высокий уровень сложности. А уж то, что по ходу дела нам придется усложнять архитектуру, это понятно, но это не должно быть частью требований. Соответственно, определение мое – оно вот такое, с human level, artificial intelligence. Определение AGI относится таким образом, что HLI – это уровень развития AGI, когда система вынуждена оперировать в тех условиях, в которые оперирует человек. на сегодняшний день или во всех возможных условиях, в которых мы вообразим, человек может функционировать. Как нас относится GI и наличие образа, акцептора и результата действия? Наличие образа, акцептора и результата действия – это одно из условий внутренних, один из обязательных элементов технической архитектуры или биологической архитектуры, системы, способной оперировать в условиях сложных целей, сложных сред. Соответственно, образ результата действия нужен для того, чтобы сформировать цель. То есть, наличие образа результата действия – это наличие образа цели. То есть, если у нас мы не можем сформировать формулировать образ действия, то мы не можем поставить себе цель, мы не можем поставить себе задачу. Если у нас образ результата нашего действия есть, то, соответственно, у нас есть цель, ради которой мы это действие выполняем. Акцептор результата действия – это механизм, который позволяет верифицировать, что мы это действие выполнили. Соответственно, должен быть механический или биологический механизм формирования цели и ожиданий к этой цели, и технический или биологический механизм верификации, что мы эту цель достигнули. То есть, у нас должна быть в терминах задачного подхода, Евгения Евгеньевича, у нас должна быть возможность постановки задачи, и у нас должна быть возможность верификации, что мы эту задачу выполнили. Определяется ли GI некоторым уровнем интеллекта, либо и так далее, и так далее. С моей точки зрения, здесь я, кстати, соглашусь с Юрием Бабуровым. Я, на самом деле, со всеми участниками, если не согласен, то хорошо их понимаю и вижу их позицию. Но вот с моей точки зрения, чисто спрагматической. Безусловно, уровень нужно каким-то образом определять. И, безусловно, нужно говорить об уровнях пресловутого General Intelligence. То есть, можно говорить об уровне General Intelligence, уровня голубя, уровня мышки, уровня обезьянки, уровня человека, уровня Суперчеловека, то есть можно говорить в терминах конкретных задач, да, есть разговорный интеллект, есть социальный интеллект, то есть можно в рамках этого определения уже, так сказать, применительно к конкретным задачам или доменным онтологиям или операционным окружением, то есть уточнять эти задачи именно с точки зрения того, какие у нас цели, какие среды, какие у нас ресурсы. Но при этом система, которая будет верифицировать, что мы этот уровень достигли, должна иметь возможность верифицировать не только заданный в конкретной прикладной задаче уровень, но и способность системы до этого уровня доходить. В практической точке это совершенно, кстати, не обязательно. То есть, если мы говорим об AGI, то на самом деле В моем понимании, в прагматическом, необходимости именно обучения, как я сейчас думаю, нет. Потому что, видите, если нам нужно, к примеру, сделать роботосистему, которую можно использовать как пылесоса, как в качестве умного пылесоса, так в качестве умной газонокосилки, так и в качестве умного сборщика окурков. чтобы он сам адаптивно в условиях разных сред, и на ковру, и на полу, и на песке, и в лесу, и в каменистой пустыне мог убирать мусор и собирать кокурки, адаптируясь к новым средам. в которых он оказывается, нам совершенно не обязательно учить его с нуля. То есть, мы на самом деле можем сэкономить некоторое время, заложив какие-то начальные знания вручную, И дальше дать возможность системе дообучаться. Причем нам даже не обязательно иметь возможность эти знания загружать в символичном виде, чтобы система имитировала процесс обучения так, как учатся люди. То есть, люди же часть опыта получают в качестве интерактивного обучения, взаимодействия со средой, reinforcement learning. А часть обучения они получают в виде дидактических материалов. Нам совершенно не обязательно в ряде прикладных задач, которые, в моем понимании, к прикладным задачам AGI можно относить, как к пресловутой «умный пылесос» или «умный мусоразборщик». Нам необязательно обучать устройство в процедуре самого сбора мусора. Мы можем заложить исходные знания о всех типах мусора, которые в системе нужно собирать. А вот адаптироваться к тому, как собирают мусор в лесу или как собирают мусор на пляже, система уже дальше может. Мы ее можем обучить собирать мусор на песке на пляже, а потом отнести ее в квартиру или на дискотеку, и она все равно должна в новых условиях научиться, что в первую очередь нужно проверять зону туалета. Ну и, соответственно, то, что система должна иметь потенциальную возможность, это, на самом деле, чисто теоретически, наверное, интересно. То есть система все-таки должна решать конкретные поставленные перед ней задачи и иметь возможность дообучаться решению этих задач. Это более важно. Но насколько она хорошо это делает, это уже частное определение AGI для конкретных прикладных задач. Каковы минимальные требования к GI и какие уровни организации материи ему удовлетворяют и почему? Ну вот здесь, с моей точки зрения, формально, если нам нужно, с точки зрения пресловутого определения, если у нас нужно решать задачу многопараметрической оптимизации, И не нужно это делать в условиях ограниченного времени, то есть мы не можем решать задачу полным перебором. А мы должны иметь возможность строить какие-то гипотезы. Если у нас даже нет совершенного знания, мы должны иметь возможность в условиях несовершенного знания делать какие-то, осуществлять какие-то ориентировочные действия. И дальше уже в зависимости от того, подкрепляются ли эти действия средой как успешные или неуспешные, уже уточнять свою модель поведения. Соответственно, если способность ориентировочного действия в условиях различных вариантов и выбора компромиссов между целями различного уровня различной визначимости есть, то это уже есть. И если мы говорим про уровни организации материи, то с моей точки зрения я нахожусь в состоянии колебания. Вот здесь справа есть некоторое голосование. Я, собственно, сначала проголосовал про многоклеточные с нервной системой, и необязательно без центральной нервной системы, примерно исходя из тех же аргументов, которые высказывал Евгений Евгеньевич. То есть, если у нас на самом деле мы можем действительно построить системы с обратной связью на нейронах, если мы можем некоторый нейрон, который задает стимул дать ему возможность, побудив моторный нейрон к какому-то действию, при этом еще и перевести сенсорный нейрон в состоянии некоторого ожидания результата этого действия с тем, чтобы если действие приведет к реакции среды на данный сенсор, подтверждающий состояние ожидания, то мы тем самым запомним, что данное ориентировочное действие было успешным. Как строить такие системы с помощью нейронов, это понятно. Это есть в докладах Евгения Евгеньевича. Здесь у меня вопросов нет. Тут я смело поставил галочку. Значит, про нейрон я был не уверен, но вот опять-таки, исходя из тех соображений, которые Евгений Евгеньевич сегодня про нейрон рассказывал, я эту галочку поставил. Но вот на сегодняшний день я все-таки не уверен, потому что… Ну, окей, хорошо. Я не знаю пока, как нейрон. Переходят в состояние ожидания какого-то результата. Или даже как отдельная клетка. Вроде видео, которое мы смотрели в начале сегодняшнего разговора, там видно, что поведение достаточно сложное. Там были другие видео, как клетки ползали по лабиринтам между другими клетками для того, чтобы поймать какую-то другую. Поведение достаточно сложное. Но я просто, честно говоря, не знаю, у меня нет информации о том, как можно вот этот образ результата и акцепты результата действия там реализовать. Хотя, в общем, мне очевидно, что целей много. С одной стороны, нужно двигаться по градиенту, а с другой стороны, какие нужно... совершать какие-то перемещения своими отростками для того, чтобы это движение осуществлять. То есть, есть основная задача и есть вспомогательные задачи. Опять-таки, нужно же перебирать лапками, точнее, своими отростками в правильном направлении. Нужно это как-то синхронизировать. То есть, движение каждым отростком – это, на самом деле, некоторая подцель и некоторая подзадача. А, соответственно, воздействие на мембрану с разных сторон – это тоже, можно сказать, сложная среда. То есть, среда давит на нашу мембрану с разных сторон. И, соответственно, у нас много параметров в поведении. Но как это происходит на уровне клетки, я на самом деле не знаю. Поэтому уверенности под этой галочкой я здесь не могу. подтвердить. Ну и на шестой вопрос, соответственно, я ответил. Как это делается в нейронах, я понимаю. Как делается на клетках, я понимаю, поэтому не уверен. Ну и личный план по созданию минимального AGI. Здесь у меня два проекта, про которые я рассказывал. Один – это мой собственный проект по созданию персонального ассистента, где некоторое очень примитивное Элементы AGI в такой постановке используются. Соответственно, мне удобно в этой схеме работать еще и потому, что просто, может быть, я это применяю в своем проекте. И второй проект – это проект, про который я тоже рассказывал. Это автоматизация финансовой деятельности. применительно криптофинансам. Буквально несколько дней назад мы залили статью на AGI. Там показано, как в рамках этого определения мы строим простого бота для обеспечения ликвидности на Binance с использованием системы лимитированных ордеров, где такое адаптивное поведение позволяет на паре Bitcoin и доллар США за неделю получать примерно 8% Return of Investment. То есть, в банке 8% годовых, а у нас 8% получается за неделю. Вот такой вот интересный результат. Мы его получили на только одном отрезке экспериментальном, практически в ручном режиме промоделировали на шести днях. Сейчас будем заниматься тем, чтобы проверифицировать этот результат на полугодовых данных на семи основных криптовалютах. Посмотрим, что получится. все, что я хотел сказать. Если какие-то есть вопросы ко мне или другим спикерам, я вижу вопрос от Александра Соколова. Александр, пожалуйста. Александр? 

S04 [02:19:54]  : Да-да-да. Трудно включается микрофон. Хотел отнестись к тому, что сейчас вы сказали. И с самого начала. По поводу практичности определения интеллекта, которое дано. С одной стороны, как я понял, вам нравится практичность этого определения, потому что оно задано как требование к интеллекту. в нем не описывается самофункционирование, какие функции должен выполнять интеллект. но с другой стороны, если наверное такое определение практически для и вы об этом сказали для ну некоторой внешней позиции там менеджеров который заказывает продукты еще кто-то но не для разработчик разработчик разработчику все-таки нужно функциональное сами что какие функции должна выполнять которую надо разработать. поэтому думаю, что поэтому ни один из разработчиков, которые здесь высказывались, не поддержал это определение. а не каждый высказал свое определение и это было определение больше функциональности. и поэтому я у Николы тоже такой провокационный вопрос задал, что там внутри должно быть, что должно исполняться в системе. Ну вот он считает, что интеллект это система принятия управленческих решений. Ну вот так вот он решил и такую систему делать. Ну хорошо, вот ради бога. Он так определился и так понимает себя. Другой понимает по-другому. Ну и так далее. То есть нам никуда не деться от функционального такого описания, что мы понимаем под интеллектом. Одних требований, что это вот некая система, которая там в условиях ограниченных ресурсов, сложных целей, при этом недостаточно. Кстати, у вас, если у вас сейчас задать такой вопрос, вы тоже, скорее всего, когда разрабатывает как разработчик свою систему, скорее всего, вы тоже дадите некое функциональное описание, какие функции исполняет ваш агент. Вот. То есть я к чему? Я к тому, что нам никуда не деться от ответа на вопрос по сущности. самого интеллекта. Мы должны эту сущность как бы ухватить, ее как бы задать и описать. Желательно, чтобы это было не некоторый такой пространный текст, там на 2-3 страниц, а что-то вот такое короткое и емкое. Поэтому когда Никола стал описывать, у него получился большой-большой описатель. Я его спросил, а коротко это можно сказать? Не получается. вот надо как-то извернуться. например вот Евгений Евгеньевич, насколько я понимаю, если я его точно понимаю, он бы так, например, ответил на вопрос о сущности. это интеллект, это система, которая решает задачи. коротко. я бы, например, со своей стороны тоже бы коротко ответил. сейчас я закончу. и отвечаю, что это система, которая умеет строить знания и строить знания. дальше меня можно спросить а для чего она это делать я скажу а для того чтобы порешать задачу то есть тут мы с егей чем можем как бы вот дополнять друг друга но уже функционально примерно прикинуть что мы понимаем вот может быть даже и который делает Микола сюда тоже может быть приписан потому что в системах управления решения конечно без знаний без решения задач она тоже как бы не мыслиться то есть это тоже близко то есть вот если вот эти все позиции немножко попробовать проинтегрировать то может быть сущность того что мы понимаем под интеллектом можно было бы вытащить вот то определение которое вы все время используете оно нас к этому пока никак не продвигает кстати ваш ход на то чтобы зацепить прообраз результата и акцепцию действия вот он больше нас продвигать к тому чтобы ухватить сущность интеллекта я бы вот этот ход поддержал и покопал бы спасибо 

S03 [02:25:00]  : Спасибо. Я прокомментирую и потом еще на вопрос Юрия Бабурова тоже прокомментирую, который он написал в чате. Значит, смотрите. Во-первых, тут мы немножечко попадаем в терминологическую ловушку, как обычно. Что имеется в виду под функциональным описанием? В моем понимании... Функциональным описанием является то, какие функции система решает, а не то, какие функции она в себе содержит. Потому что то, какие функции система решает, это ее внешнее поведение, а то, какие функции она в себе содержит, это внутренняя часть, это те функции, которые есть внутри программы, какие функции заложил программист. а не то, какие экраны она генерирует в результате исполнения этих функций, никакие виджеты или гаджеты для программиста она представляет. Поэтому, если мы говорим, я программист в основном, и есть понятие описания требований функциональных или требований к продукту пользовательских, А есть элементы технической архитектуры или требования, собственно, на разработку. Так вот, то определение, которое мне кажется полезным, несмотря на то, что я программист, это требование именно договориться о том, что система делает, а не как она это делает внутри себя. И вот здесь под «что» мне кажется неправильно закладывать «как», в «что» не нужно вкладывать «как». Потому что есть у меня отдельный доклад и на конференциях это бывает. И здесь у нас тоже есть разное мнение, вы сказали, что «как делать AGI?» То ли делать его на нейросетях, то ли делать его на символьных архитектурах, то ли делать его на нейросимвольных архитектурах – это вопрос открытый. А есть еще Kaneman, у которого есть System 1 и System 2, то тоже нужна какая-то гибридизация. Недавно там была ссылка про гибридный. Как делать? Внутри у нас согласия нет. Но нас все объединяет, что мы хотим делать и, может быть, именно в области что наговориться проще. И в этом плане мне удобнее все-таки про что тоже говорить. И, собственно, про это мы сегодня говорили, потому что мы говорили акцептор. Но разделять, что, как – это про акцептор, и что – это про цели, про решение задач. Кстати, решение задач – это, с моей точки зрения, как раз функциональная часть, потому что можно сказать, а для чего мы решаем эти задачи. Там, кстати, тоже много уровней. Мы хотим, чтобы AGI – это система решения задач. Это, кстати, определение Алексея Потапова, который тоже работает с Герцелем. тоже является одним из лидеров этой истории. Выступал у нас на семинаре. Но можно сказать, что решение задач оно же само по себе ценности не несет. Решение задач нужно постольку, поскольку оно, конечно, в итоге позволяет достигать вот этих вот целей некоторому организму. Это вот один комментарий. Второй комментарий – это Юрия Бабурова, который сказал, что HLA очень непонятно, да ещё и жев себе не содержит. Естественно, HLA очень жев себе не содержит, потому что General – это General. General – это начинается у кого-то от мышки, у кого-то от голубя, а дальше через человека идёт к суперразуму. А у кого-то, вроде меня, оно начинается то ли с нервной системы, то ли вообще с отдельно взятого нейрона. или AGI или GI – это про всю линейку, начиная от какого-то минимального уровня и кончая бесконечностью, а HLI – это конкретный уровень на этой линейке, соответствующий человеку. И здесь, конечно, очень важно. тоже понимать, что HLA – это тоже достаточная условность, это тоже линейка. Потому что есть HLA уровня бомжа под забором, есть HLA уровня маугли, которого забрали из волчьей стаи в 10 лет, а есть HLA маугли, которого забрали из волчьей стаи в возрасте 3 года. А есть и человек, который в волчьей стае пробыл всего несколько дней, его оттуда быстро забрали и он успел превратиться в человека. Вот где у нас настоящий Эйчелай? Есть Эйчелай уровня Эйнштейна, есть Эйчелай уровня меня там есть человек уровня там васи пупкина вот как про какой человек мы говорим и здесь опять-таки важно понимать то и человек это не только про человека а это и про еще и про ту культуру в которую этот человек погружен и некоторое вот информационное поле которое идет в придачу к собственно физическим способностям конкретного индивидуума прилагается то информационное поле или та структура знаний, которая накоплена человечеством и с которой этот человек или сообщество людей могут оперировать. Поэтому я просто попытался уточнить разницу между G, AGI и HLI. У нас уже нужно закругляться, поэтому Владимир, пожалуйста, давайте короткий Вопрос от вас еще. Владимир. 

S05 [02:30:34]  : У меня комментарии, если можно, минут на 3-4-5. Можно? Да-да-да, конечно, давайте. Можно тогда я еще экран продемонстрирую, если это удастся. Вот, то есть, вот мне, конечно, очень нравятся комментарии. Ну вот, во-первых, вот определение, которое вы вынесли в вопрос, оно, конечно, нравится, видимо, Герцелю, поскольку он его написал, и поскольку с ним сотрудничать, конечно, вам проще с ним работать. Но все те, кто сегодня комментировал, в том числе я, сказали, что нет, это не определение. Ну, связано это с тем, что, значит, сложность задач, среда, это все очень размытые понятия, и, как бы сказать, для общения с Герцелем, может быть, это удобно, а для конкретных задач нет. Вот. Собственно, вопросы, которые решались, там, на примерах, там, бананов, голубей и мышек, они тоже интересны, но давайте согласимся, что все-таки Даже уровень мышки к интеллекту имеет очень косвенное отношение. Она решает какие-то задачи, но они не интеллектуальные. Собственно, я сейчас попробую открыть свою эту самую... 

S03 [02:31:47]  : Тегмарка. Владимир, давайте уже, у нас просто мы уже были, если коротко очень, чтобы не делать второй доклад. 

S05 [02:31:55]  : Скажу, значит, не второй доклад, а то, что я пытался ввести какие-то достаточно такие граничные определения и брал за основу Тегмарка. Почему? Потому что у него вот три градации и они достаточно, ну, конечно, не абсолютно четко, но более или менее четко разделяются. вот значит соответственно этим градациях можно строить то что собственно разумом обладает жизнь 2 Интеллектом, собственно, обладает жизнь 2а, которая, собственно, так же, как просто жизнь, являлась основой для построения жизни 2.0, а вот, значит, соответственно, не все элементы жизни 1.0 подходили для построения жизни 2.0. Соответственно, не все элементы жизни 2.0 подходят для построения жизни 3.0. Согласитесь, что ни пчелы, ни бобры никакой жизни 3.0 не построят. Только человеческое общество обладает тем интеллектом, который позволяет построить. Мы, конечно, можем исходить из того, что давайте построим модель лягушки или банана. Они же тоже какую-то разумную деятельность осуществляют. Может быть когда-нибудь мы дадим до человека. Я понимаю, что вы пока этим не занимаетесь, это вам неинтересно, но вопрос на самом деле важный. Тема всё-таки лягушка отличается от человека. Я какие-то короткие ответы давал, и отметить я никаких моделей сегодня не предлагал. Я просто говорил про определение, что из жизни 1-0 получается жизнь 2-0, не из всех элементов из жизни 2-0 может быть получится жизнь 3-0. И вот те свойства, скажем так, разумные, которые есть у некоторых представителей, а в данном случае только у человека, для создания жизни 3.0, вот это и есть, собственно, то, что относится к интеллекту. Может быть, это не единственная хорошая идея. Может быть, есть какие-то идеи лучше. Но я предлагаю вам задуматься о том, что не говорить о том, что давайте решать сложные задачи. Вот Забанан, он решает сложную задачу, давайте эту сложную задачу промоделируем. И в скорости, как говорит Виктор Арцехов, будем эту задачу развивать, и буквально через год-два мы уже все проблемы решим. ну это инвесторам нравится и конечно это значит можно, но все-таки давайте какие-то более вот я попробовал через тегмарк это определить, может быть у вас какие-то другие более интересные подходы появятся, но вот эти вот качественные оценки, что задача сложная, среда интересная, еще что-то, они в общем скользкие и на них ничего хорошего никогда не определить. Вот собственно о чем стоит комментарий. 

S03 [02:34:17]  : Хорошо. Владимир, спасибо. Коллеги, всем спасибо, кто принял участие. И до новых встреч. Всем до свидания. До свидания. 








https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
