## 18 марта 2021 - Swiss Army Knife for AI или ИИ с мультимодальным обучением — Алексей Веснин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/D7GnyMI7dvc/hqdefault.jpg)](https://youtu.be/D7GnyMI7dvc)


Суммаризация семинара:

ТЕМА
- Семинар посвящен развитию искусственного интеллекта (ИИ) и мультимодального обучения, с акцентом на практическое применение.

СУТЬ
- Участникам представлен инновационный подход к созданию ИИ-инструментов, модульных и адаптируемых к конкретным задачам.
- Основные идеи семинара включают в себя разработку системы, способной обучаться и адаптироваться к новым данным без переобучения.
- Особое внимание уделено мультимодальности обучения, позволяющей интегрировать различные типы информации и обучение на основе "открытых моделей".

ДЕТАЛИ
- Принципы мультимодальности и модульности задач и их интеграция в единую систему.
- Использование технологий NLP и распознавания речи для создания голосовой QA-системы.
- Разработка методов интеграции с Википедией и другими источниками знаний для расширения языковой базы и понимания контекста.

РЕЗУЛЬТАТЫ
- Показан пример работы deep speech с системой распознавания речи, без использования Ngram и Language Knowledge Base.
- Демонстрация возможностей интеграции ИИ-систем с бизнес-процессами и создание веб-сервисов через модульное API.






S00 [00:00:01]  : У нас сегодня, может быть, будет не совсем стандартный семинар. На некоторых семинарах мы говорим на достаточно отвлеченных философских уровнях. То есть, сегодня, наверное, будет гораздо все более практический, я надеюсь. Хотя, может быть, не слишком практический для оценителя настоящего AGI. Но посмотрим. Вообще, я Алексея знаю несколько лет как специалиста в области компьютерной безопасности. А недавно обнаружил, что он стал активно заниматься искусственным интеллектом для всех и для каждого. И вдобавок еще с переписыванием знаменитого Ди Павлова с глубоким рефакторингом. И введением туда, насколько я понимаю, понятия мультимодальности. Но я думаю, Алексей более подробно обо всем расскажет. Алексей, тебе слово. 

S01 [00:00:59]  : Да, всем доброго времени суток, меня зовут Алексей Веснин, кто со мной знаком. Я, на самом деле, не просто начал заниматься АИ, я им продолжил заниматься, потому что заниматься им начал еще в 90-х годах в школе. Потом в университете, это была моя базовая, но одна из тем. Потом я делал некоторые только свои разработки и достаточно мало мог этому терять время. Некоторые предыстория библиотеки, чтобы было понятно, откуда она взялась и как она связана, и как она не связана с гипполом. Это просто для большего внимания. Год назад фактически, чуть ли не ровно, мы выходили на один из гипотонов с командой и решили там применить машинное обучение и искусственный свет, в частности, в режиме талого обучения. естественно, для этого Дипалов, который тогда был уже на тренде и заявлял о том, что можно взять и развернуть свою инстанцию буквально за десятки минут и попробовать на нем его сделать. в итоге возникли примеры даже из их мануала, то есть я захожу на сайт, делаю copy-paste, это важный момент, делаю copy-paste примера, выкачиваю последний депаблов и у меня ничего не запускается. Почему это важно, скажу позже. Поэтому я сначала это довел до ума, а потом начал другие свои идеи выкладывать в этот код, и появилась фактически идея Потом мы начали работать еще на некоторых задачах с машинным обучением, и переписки пошли дальше. В итоге получилась вот эта библиотека, в которую я накидывал вопрос из чата сразу. Математики сегодня не будет. то есть какого-то высокого пуска я показывать не буду. Вся математическая статистическая часть с результатами тестов и так далее, это будет в начале месяца, когда я буду показывать новый релиз. Соответственно, в чем на самом деле очень большая проблема огромного количества библиотек? Во-первых, количество. Да, у любой задачи есть два и более различных решения, однако если мы посмотрим сколько сейчас у нас фраймблоков в библиотеках для машинного обучения, которые на самом деле нужны каждому, то есть у меня это спрашивали начиная от студентов колледжа, то есть ребята 16, 17, 18 лет, заканчивая и люди, которые уже за пенсионным возрастом, которые прислали задачи, хотят посмотреть. И вот эти люди как раз будут делать копии паст, им нужен простой инструмент, чтобы они могли работать с логикой, им не приходилось для того, чтобы просто запустить даже банальное обучение нейросети на какие-то свои данные, чтобы им не приходилось осваивать огромное количество программирования, системного администрирования и так далее. И есть еще один момент, который меня окончательно подвел на создание и на публикацию в собственной библиотеке. Он заключается в том, что когда люди учатся, Они изучают один фреймворк, другой, третий. Те, кто сами делал какие-то куски по машинному обучению, наверняка знакомы с Numpy, с MLTK, Space и другими вещами. Это хорошая реализация, но вам нужно вынужденно изучать все ведущие, чтобы просто связывать в единое целое для решения вашей задачи. Хотя вашу задачу вы на самом деле можете переслать довольно просто и графом. Поэтому я и начал делать библиотеку, которую так и назвал. То есть это шикарский нож, на котором, как известно, есть практически все, что нужно. Это не значит, что там нету таких библиотек. Это значит, что эта библиотека фактически дает вам возможность, не влезая в глубины всех вот этих реализаций, всех таких framework, просто заниматься решением своей задачи. Вот для этого она и была сделана. Откуда на название взято? Все было достаточно просто. После того, как мы с ребятами из Диппола созванивались, точно так же в Зуме у них было непосредственно заседание лаборатории, я там тоже рассказывал про библиотеку, и как раз название тогда было уже чисто рабочее. Меня спросили, причем, на самом деле, вопрос мне задавали еще до этого, а почему я просто не сделал pull request? Ну, в опенсорсе, на самом деле, коллаборация – вещь хорошая. То есть, когда кто-то что-то выложил на GitHub, либо в Git, кто-то это усовершенствовал лучше, исправил ошибку, почему бы это не присоединить к оригинальному DeepAuth? чтобы всем стало лучше. Ответ на самом деле достаточно простой. Потому что те нововведения, которые я делаю, они просто сломают депал их архитектурно. То есть он уже не будет депалом. Поэтому это вынесено как отдельное дебрятие. Соответственно, давайте посмотрим основные моменты. Начнем просто с базы. с того, как у нас стоит задача. Это достаточно важный момент. Смотрите. Базовые примеры. Я сейчас дам несколько примеров, чтобы было понятно, о чем я буду говорить далее. Смотрите. Рассмотрим чашку. Видимый экран, да? 

S00 [00:06:46]  : Да, любимая чашка Джеффа Хокинса. Но только у Джеффа Хокинса, по-моему, попроще чашка. У тебя красивее. 

S01 [00:06:53]  : Нет, это обычный, самое обычное. Смотрите, вот уже даже, когда мы смотрим, возникает базовая ассоциация. Но в принципе так, чашку в виде системы компьютерного зрения. То есть она оценивает форму и более-менее оценивает объем. может что-то вытащить из рисунков, но ничего больше. В принципе, у нас это тоже не вызывает каких-то глубоких ассоциаций. Теперь посмотрите сюда. Это тоже чашка, согласны? Тут больше ничего нет. Но уже подсознательно мы можем либо ощутить запах того, что там налито, почувствовать ее вес. Суть в том, что машина никогда не может это сделать сама, автоматически, в том виде, в котором используется современный фреймворк. То есть это две чашки, обычные чашки, но когда их будет смотреть машина, она обе чашки увидит также как первую картину. Когда мы смотрим, Мы видим и понимаем эту чашку совершенно по-другому. То есть задача научить искусственный интеллект не только самому обучаться, но и понимать суть не только визуальных, но и банально текстовых вопросов. Смотрим дальше. Второй кусочек. Это посуда, которая стоит дном вниз. Все видят, да? Это которая дном и вверх. Только маленькая инва, она везде стоит дном вниз, но мы думаем, вот первое впечатление у 99% людей, что на втором фото посуда стоит дном вверх. На самом деле просто поменялось освещение. Вопрос. Как это увидит машина? Машина это будет видеть на самом деле только как фото первое. Почему? Потому что машина будет просто анализировать картинку. А теперь структурно увидим ответ на вот этот момент. Что у нас есть? Это архитектура 90. 5% фреймворков не только DeepPower, в функциональном виде. То есть у нас есть кодные данные, то есть либо база, в частности, SQLite в случае DeepPower, что тоже спорно, либо обычный файл, который мы скармливаем системе, то есть, например, вот эти же фотографии, или какие-то данные из памяти, например, если мы берем скайп. Это вы увидите на куче скетчей Raspberry Pi, которые можно скачать. Это у нас просто преобразуется в выходящие данные, без учета чего-либо, подается в модель и выдается на выход либо в файл, либо в результат в памяти. Либо, если у нас нечто более сложное, как, например, задача машинного чтения, У нас модель может состоять из пайплайна. То есть в одну модель загоняем, например, в ранкер. И, соответственно, ранкер подбирает на основании поданного запроса для сетки, например, BERT обычно используется, статьи, из которых она генерирует ответ. И точно так же выдаем выбор. На самом деле, почему мы, когда смотрели на первую и на вторую пару изображений, почему мы видим по-другому? Эта теория пришла не только из биологии, она была проверена еще до того, как начали изучать высшую нервную деятельность и строение нервной системы. 1000 brains theory – теория тысячи мозгов. На самом деле, даже у червей, я говорю это как биолог, поскольку я биофизик, у там членистоногих, у того же самого таракана, которого вы давите, у него мозг устроен не просто как ганглий, то есть не просто как обычный нервный узел, который, например, предуспечивает нам коленный рефлекс, все мы его помним со школы, он устроен гораздо более сложно. И там на самом деле, Несколько совершенно разных участков. То же самое. Почему перед змеей либо перед лягушкой, если встать, она перестанет вас видеть? Хотя казалось бы, у нее есть визуальный сенсор, правильно? Который вас прямо и явно отсекает. Потому что обработка идет, начиная от зрительного метода. И вот эти все участки, они идут не вот так, pipeline. То есть это не одна модель. и не такой пайплайн, который просто передает данные по цепочке. Это несколько компонент, которые, более того, в жизни организованы. Я сейчас просто набросаю, чтобы было понятно. То есть они организованы не просто вот так. Собираем. Поэтому они организованы вот так. Либо еще более сложно. Понятная идея? Не слишком мелкая. Нормально видно? 

S00 [00:12:31]  : Нормально. 

S01 [00:12:32]  : Вот, я могу просто понимать. Суть. Суть заключается в том, что даже у Де Павлова, хотя у них надо отдать должное, они совершенно правильно сделали описание вот этого пайплайна в отдельном JSON, правда, сам JSON они нормально не использовали, вы не опишите это одним конвейером. Вот такую архитектуру, я думаю, всем понятно, что в терминологии такого конвейера мы не запишем, и фреймворки этого не дают. Поэтому более того, у нас входящие данные могут быть совершенно разные. То есть если мы говорим не только о мультимодальном, хотя все реальные задачи мультимодального обучения требуют и мультимодальный inheritance тоже, в том числе, у нас нет вообще нормальной работы где-то сделанной с данными. То есть здесь, здесь. Это не нужно воспринимать как прямые синаптические связи. В живых системах это может быть еще и гуморальная регуляция. Это, если вдаваться в то, как образуется парень в живых организмах, это отдельный вопрос. Здесь у нас есть входящее данное, вот это входное событие слева направо, здесь происходит событие обработки, но оно транслируется в две точки. И вот эти два узла получают их далеко не синхронно. Я их специально нарисовал не на одной линии. То есть может быть вот так, если здесь распределить еще время. И это нормально. А итоговый узел выдает отсюда сигнал не всегда, когда получит результат от всех данных. как раз штука с двумя картинками, которую мы использовали, с тарелками вверх и вниз. Вот это как раз результат работы 1000 brains theory, которую вы сейчас могли на себе наблюдать в действии. Почему нам кажется, что вдруг оно стоит сверху? Мы же присматриваемся и видим, что оно стоит точно так же, но вниз, правильно? А потому что вот этот сигнал, вот эта обработка более высокоуровневая, запаздывает. А здесь, когда мы обрабатываем тени, наш мозг и наша нервная система их обрабатывают, мы этот сигнал здесь уже получили и вынесли в предварительное суждение. Потом оно уточняется и меняется. Здесь мы не можем организовать это так же. Эта архитектура не дает возможности организовывать подобную платформу и, более того, адекватно работать с данными. Один из кусков, который будет в большом обновлении, я сейчас, соответственно, смотрю. Это модуль работы с дейтесетами. Всем видно? 

S00 [00:15:31]  : Да, видно. 

S01 [00:15:32]  : Видно все, да? Надписи видны или прибавить? 

S00 [00:15:38]  : Мелковато, но видно. 

S01 [00:15:42]  : Вот так лучше? 

S00 [00:15:46]  : Так лучше, но не все влезает. 

S01 [00:15:49]  : Ну да. Я, соответственно, покажу, что здесь за узлы, и потом дальше будем смотреть уже по кускам. Во-первых, на сегодняшний день, как могут нам поступить данные? И на самом деле не только поступить. Когда мы получили данные, правильно их обработали, это замечательно, но нам надо их отдать. Причем отдать в нужном и удобном для других виде. Мы можем получить их по API, по интерфейсу, когда нас как-то вызовут. Мы можем достать их из интернета, то есть нам ничто не мешает скачать там страницу либо PDF-ник и его пропарсить. Сразу говорю для представителей церебральных меньшинств, я всегда делаю оговорку, которые занимаются защитой копирайта. Все, что можно взять и скачать из интернета, имеет открытую лицензию. Если вы хотите защищать ваши данные, не кладите их публично. Если данные лежат публично, все остальное идет лезвие. У нас есть только, соответственно, протоколы их передачи. Если данные без авторизации, без взломов, подборов, паролей, без украденных кук и так далее, если я могу просто взять и открыть, либо скачать это в одну строчку, все, эти данные можно использовать. Естественно, никуда не девается обычный не структурированный файл. Далее, база данных. Почему я здесь не указал? Да, SQLite меня поддерживает. Также в новом релизе будет адаптер для MySQL. PostgreSQL будет, но попозже, потому что я с ним пока особо не работаю. Плюс сейчас огромное количество данных живет в следующих вещах, которые только-только пытаются подружить с системой машинного обучения и очень зря. Во-первых, есть IPFS – Interplanetary File System. Знакомо этот термин или рассказать о нем по-подробному? 

S00 [00:17:57]  : Можно пару слов сказать, чтобы не повисло в воздухе. 

S01 [00:18:00]  : Это распределенная файловая система. Система, когда вы можете хранить данные в нескольких точках и по ее кэш-идентификатору данного по распределенной этой сети вы делаете запрос к любому узлу, Собственно, сама IPFS находит тот узел, где это есть, и вам это дело доставляет. Его можно, соответственно, есть глобальный клоун, есть, можно поднять свой клоун. Зачем нам свой клоун? У нас сейчас достаточно большое количество ноутбуков, планшетов, других мобильных устройств, в которых уже далеко не маленькие хранилища. На самом деле, если их правильно объединить в IPFS, то ваши данные, с которыми вы работаете, и обработку которых вы сможете создавать, используя как раз такой инструмент, вы можете просто брать их у себя. Либо что-то глобальное, которое лежит. Вот как мы с Антоном с тобой говорили в свое время, я спрашивал тебя про один из корпусов, про RuSentiment, который погнали из искра ВКонтакте. Его убрали из открытой скачки в интернете. На самом деле, если это положить в IPFS, то все, это будет доступно всем. И тот, кто работает с этим корпусом, у него абсолютно ничего не будет, если кто-то другой спросит у него кусок этого корпуса, и ему эта система отдаст. Он даже этого не заметит. Но это позволяет всем работать с глобальными данными. Есть ребята Cyber Congress, которые делают систему кибер на космос SDK. У них есть вот такой на EFS базированный граф знаний, то есть распределенный поисковик. Это огромный массив данных и с ними тоже мы не только будем сопрягаться. Сейчас я вышел на Хакато, на Хакатом по космосу, где непосредственно вот это все будет пущено еще в децентрализованном виде. У нас есть физические устройства. Да, почему их отдельно выделил? Потому что под физическим устройством в данном случае понимается камера, понимается аудиосенсор. Их обработку тоже нужно осуществлять правильно, а не оставлять на совести пользователя. Если что, через API, то есть через самый верхний кусочек, можно загнать все. И на самом деле вот это у меня работает тоже через мой API. Но это те адаптеры, которые нужны каждому. И последний, но только по списку, это блокчейн. То есть у него есть распределенный консенсус, у него есть распределенные данные. Это огромная массива данных не только для финансовых каких-то вещей. Есть сервисные специальные блокчейны, откуда вы можете брать огромное количество данных. Плюс, если вы делаете какое-то приложение, вам вовсе не обязательно, как в начале 90-х годов, сразу брать огромный сервер для централизованного хранения, вы можете хранить через тот же IPFS, либо через тот же блокчейн, вы можете хранить нужные данные, распределенные на всех узлах ваших пользователей. И ваши сами сервисные мощности очень сильно оптимизируются, вам это не нужно. Но вот эти четыре вещи, я специально отдельно выделил, Они имеют еще четыре куска, которые, в принципе, игнорируются, я сам не знаю почему, сейчас при создании какого-то софта, либо при создании каких-то решений для машинного обучения. Есть обработчики событий, то есть, например, событие, может быть, там появилась какая-то новая страница в IPFS. Да, в IPFS можно сайты класть распределенные, которые центрально устойчивы. Вы можете это обработать. Из IPFS там можно подписаться через Listener, либо его в IPFS называют subscriber. Там есть Pub-Sub-Interface, Publishing-Subscription, то есть публикация-подписка. Вы можете сказать, что я генерирую определенного типа событий. Например, Википедия может сказать, что она генерирует события создания страниц. Вы можете на него подписаться. И когда на Википедии что-то появилось, вы об этом будете децентрализованно уведомлены и, соответственно, сможете достать эти данные и обучиться на них. И есть в консенсусе и в блокчейне, соответственно, смарт-контракты. Да, они далеко еще не совершенны, но это очень хорошая распределенная логика, которая может отбирать нам данные. И все это генерирует входящий поток, своем формате как вы видите справа у меня слева направо идет соответственно справа это выход точно такой же пул того с чем мы можем взаимодействовать то есть не только то мы подали какие-то входящие данные, мы смогли их достать. То есть идея в том, что, например, если вы работаете с Википедией, то самая первая задача, которую я разбираю по Винтику, это корпус Википедии, который есть и в том же DeepSpeech, а нет, это в DRQ есть, в Deepavlov есть. Но в чем суть? Вам дают просто какой-то там лохматых годов выгрузку, которая там 1,6 миллиона, да, 1,6 миллиона там. Если вы просто возьмете штатную выгрузку Википедии, которая, кстати, задокументирована, как это сделать, я для этого сделал отдельный скрипт, который вы сейчас можете просто запустить, и он вам вытащит последнюю выгрузку Википедии. У вас уже в английской Википедии будет 6,5 миллионов. То есть понимаете разницу. Но пользователь должен иметь возможность это – просто нажать кнопку. а не взять и написать 3-4 страницы кода. Все вот эти форматы должны быть приведены к единому внутреннему знаменателю. Для этого есть узел Data Form Processor, то есть обработчик форматов данных. Мы можем получить картинку, которую мы будем смотреть. Мы из интернета можем получить в добром десятке графических форматов, либо вообще. Это должно быть преобразовано в единый кусток. Точно так же, когда мы все преобразуем, это реализовано. Это то, что я еще просто не положил в экран. Когда мы это все внутри берем, у нас должен быть некоторый уникальный идентификатор. Чтобы мы могли ссылаться на данные, чтобы вот эта архитектура заработала, Почему, когда мы сначала смотрим, мы видим, что это стоит к верху дном, а потом присматриваемся к низу? Как мы должны знать вот на этом этапе, какое решение нужно поменять? Вот просто по идентификатору, образно говоря, идентификатор объекта сцена с тарелками проходит здесь. И мы знаем, что когда здесь уже прошло, ее обработка более быстрая, но здесь приходят корректирующие какие-то веса или сигналы, мы знаем, к чему именно это сопоставить, потому что здесь уже может идти что-то дальше. Это, кстати, примерно так же, но более сложно, работает тот кейс, который рассмотрел сейчас. То есть сначала и там, и там, и мы, машина, видим его по быстрому. Чашка. Да, это чашка. Мы ее определили, мы ее идентифицировали по форме. Все окей. Что дальше? А дальше у нас на более глубокий уровень может идти какая-то форма чашки, а что там налито, и какие-то воспоминания уже об этом. И вот это дальше дополняет. Вот здесь у нас идет наше восприятие чашки. И вот этот вот идентификатор, мы тоже должны получить, то есть не нужно изобретать велосипед, нужно просто правильно реализовать то, как работают живые организмы. Это несколько миллионов лет оплаты, с этим как-то не поспорим. Точно так же с результатом. Когда мы получили результат, то есть это уровень, почему я сказал датасет менеджер, но сейчас говорю результат. Потому что обычно в классических работах по машинному обучению пишется, что dataset – это то, с чего мы стартуем, либо то, с чего мы обрабатываем. Правильно? На самом деле dataset у нас понятие динамическое. Это те данные, которые нам поступают, и те данные, которые мы генерируем на их основании. Посмотрите, как устроена наша память. Мы учим таблицу умножения, мы учим алгебру, геометрию, математику. Мы делаем свои какие-то выводы. И мы их тоже помним точно так же, как таблицу умножения. Хотя таблицу умножения придумали не мы, а какую-то формулу в какой-то задаче применили мы. Но мы помним и то, и то одинаково. Это и есть наш dataset. То есть процесс результата тоже должен зарегистрировать то, что получили, и потом сюда пойдет. Он должен преобразовать это в нужный формат и получить идентификатор результата. Точно так же, для работы с подставлением, я сейчас, когда буду рассказывать про распознавание речи, это вторая задача, с которой, я думаю, тоже как минимум в базовом виде покажу в начале месяца. У нас есть некоторые кэш. То есть некоторая шпаргалка, кратковременная память, это называется в живых организмах, на самом деле реализация разная, названия разные, суть идентичная. И для реализации работы всего как единого фреймворка есть глобальная очередь событий, глобальная очередь объектов данных и глобальная очередь объектов сообщений. Поэтому у нас есть менеджер, который что-то закидывает в эти очереди, что-то из них получает, уведомляет, и наш некоторый внутренний кэш. Вопрос, почему я делаю не в очереди, а через менеджера? Ответ будет несколько попозже. На самом деле, посмотрим еще на второй кусок. Что мы видим в принципе? На рынке сейчас, да и на самом деле не сейчас, есть большие проблемы с видеокартами, с железом, на котором мы можем что-то расширить. Но есть такая замечательная вещь, как sharing. То есть мы можем взять наше железо и запрячь на какую-то распределенную задачу. я остановлю демонстрацию, сразу говорю, все вот эти вот картинки я положу в хаб, то есть это все можно будет скачать, если вы захотите потом это себе куда-то попользовать, там АГПР и лицензии без проблем. какая еще есть проблема? есть проблема в том, что как приходят ребята, например, в том же колледже ко мне приходили, я говорю просто по реальной события. Приходят люди, они хотят учиться. Да, человек покупает себе ноутбук там с неплохой видеокартой, чтобы можно было хоть что-то гонять, потому что процессор и гонять просто нереально, но ему далеко не всегда ее будет хватать. Это раз. Второй случай. У нас есть, например, кто-то там занимается Искусственным интеллектом. У него есть, соответственно, машина с несколькими GPU. Да, говорю сразу, немножко вперед забегая из технических деталей. Библиотека умеет параллельно использовать несколько GPU, причем одновременно NVIDIA и AMD. То есть, если у вас там даже от mining ферм осталось что-то, вы сможете сделать, банально поставить эти GPU либо в несколько материнских клад, чтобы на райзерах не висели, поскольку скорость передачи данных все-таки хромает, и объединить это в единую вычислительную систему. Объединение в единую вычислительную систему тоже на автомате. Вам не придется изучать системное администрирование. Возьмите образ, есть контакт. Вопрос в том, что когда мы вкладываем какую-то инвестицию, в железо в частности, у нас есть не только рабочее время, у нас есть простой. То есть какое-то время, ну, вы, например, спите, да, поставили задачу считаться, а она просчиталась за 4 часа, например, нервная публикация рабочая. Хорошо, но вы спите больше, и система работает, что делать? Это раз. Второе, вы можете просто там уйти на работу, а у вас на машине задача не стоит, она тоже может что-то делать. Либо, наоборот, вам пришла большая задача, и вам бы не хотелось ждать все выходные, чтобы ее обсчитать. Вопрос. Как с этим быть? Выход я здесь нашел. Собственно, вот этот кусочек, его первая часть будет на хакатоне. Хакатон идет до 27 числа хакатом, и я там уже выкладываю этот кусок. Как минимум первую версию. В чем суть? которые находятся на нескольких чайниках. Зачем нам токены? Это не биржевой инструмент, это просто мера учета использования ресурсов. Когда вы хотите свои ресурсы кому-то предоставить, вы получаете за то, что они бессчитали какой-то кусок работы токен, который выставляется там в маркет, внутри работает автоматом, вы выставляете минимум сколько токенов вы за свое железо, за свои ресурсы хотите, кто-то выставляет сколько он готов заплатить за расчет какую-то часть. 

S00 [00:32:02]  : Алексей, я стряну. Наверное, это интересно, но все-таки у нас тема не блокчейн, это экономика. То есть, может быть, все-таки двинуться в сторону ближе к теме, то есть про AGI, про multimodalities. 

S01 [00:32:14]  : А вот я, собственно, и сейчас вам расскажу. Вот это все введение я даю специально развернутое для того, чтобы потом было понятно, как будет работать то, о чем я буду говорить. Соответственно, таким образом вы можете рассчитать что-то быстро, либо свои ресурсы, чтобы они не простаивали, получить за это то же самое. Зачем это нужно? Как я и показывал, у нас есть смарт-контракт по схеме. Суть заключается в том, что смарт-контракт, как и вообще модуль вычислений, может быть автономен. Наш интеллект автономен, скажите, вот ваш интеллект, он же внутри нас, правильно, это отдельная сущность. Точно так же мы можем создавать не просто каких-то там голосовых помощников, торговых роботов, мы можем создавать отдельные анализирующие сущности. Но как их сделать отдельными? Как их сделать самодостаточными? Вот именно для этого не только вот этот токен, а это еще и система распределения изделана. То есть, чтобы мы могли создавать что-то действительно автономное, а не работающее только на каком-то отдельном центральном сервере. Более того, при мультипликации на несколько контейнеров растет мощность, То есть система сможет анализировать, например, вы хотите сделать, работая, например, с фотографией. Вы можете сделать просто как обрабатывать фотографию и не просто обрабатывать фотографии в параллельном потоке, хоть тысяча через эту систему, но и потом дальше их анализировать. И для этого у вас есть рабочий инструмент. Соответственно, Как это влияет на то, как мы видим, классические задачи. Сейчас я покажу, собственно, задачу speech recognition. Распознавание речи – это STT, speech-to-text. Разная формулировка, суть задачи одна. Сейчас я включу экран. Видно экран, да? 

S00 [00:34:29]  : Да, видно. 

S01 [00:34:30]  : Отлично. Посмотрим классический и предлагаемый мной, который я, собственно, реализую, подход для решения этой задачи. Что есть SR? Вначале мы что-то говорим. У нас у многих есть умные колонки, либо кто-то писал даже для них что-то. У нас идет ADC, аналоговый цифровой преобразователь. Мы аналоговый голос преобразуем в цифровую форму. Потом мы производим обработку на Digital Signal Processor, на процессоре обработки сигналов для того, чтобы убрать шумы, нормализовать и преобразовать в каком-то внутреннем формате. Это, что в классическом понятии, что в моем предложении, одно и то же. Тут из песни слова не выкинешь и, более того, ничего не добавишь. Потом идет токенизация. Для тех, кто работает с машинным чтением, с текстами, не путайте. Токенизация в тексте. Она другая, т.е. когда у нас есть текст, мы его разбиваем на токены. Когда у нас есть звук, мы его разбиваем на слова, т.е. независимо от языка, я сейчас говорю о европейских языках, у иероглифических там немножко по-другому, но я не буду даваться. Будем говорить о европейских. Мы разбиваем на какие-то слова, и потом мы еще детектим окончание предложения, то есть вопросительные интонации, воспитательные, либо просто, когда мы договариваем предложение, мы так или иначе неосознанно делаем несколько больших пауз. Все это кладется на pronounce model, то бишь модель произношения. Когда мы тренируем тот же deep speech, я его очень люблю за то, что он модульный, И действительно из него можно как из конструктора лего делать что угодно. Главное, чтобы руки оттуда росли, откуда надо. Мы после того, как берем Pronounce Model, когда мы тренируем его на голос, мы тренируем вот именно вот эту модель, ну и немножко покинайся голосами. И потом оттуда мы получаем текст. То есть понятно, как это работает в общем случае. Понимание есть. Как работает классическая задача распознавания речи? Если кто-то пробовал, раз вопросов нет, значит пробовал. Если кто-то пробовал системы, начиная от голосовых ассистентов, там ту же серии, что угодно. Как часто даже такие системы неправильно распознают то, что мы говорим не просто вот таким дикарским тоном, голосом, когда мы говорим четко, размеренно, медленно. А когда мы говорим так, как мы говорим, качественное распознавание резко падает, если оно вообще можно назвать качественным. Это уже зависит от системы. Что делаю я? Я использую несколько токенайзеров. Зачем? Несколько токенизаторов после цифровой обработки сигнала. Я использую разные масштабирования по времени. То есть, когда мы что-то говорим, можете записать даже чей-то разговор, либо свой разговор с кем-то, а потом на любом анализаторе посмотреть, как у нас будут интервалы между словами, и самое главное, когда мы употребляем одни и те же слова, ну, там, предлоги, союзы, частицы, например, там, посмотрите, мы произносим одно и то же слово, если разговор долгий, за достаточно долгое время, с разными длительностями. Это зависит от контекста и так далее. Вот для вот этого узла, для классического, то есть почему тот же deep speech, те, кто начинают работать с распознаванием речи, и другие еще ругают, да потому что, когда человек говорит как человек, вот этот узел токенайзера может неправильно распознавать слова и, соответственно, выставлять там акценты для того, чтобы загонять это в модель произношения. Если мы сделаем… почему я изобразил четыре? Четыре покинайзера, в моем случае, я эти цифры тоже покажу, когда буду показывать уже в начале месяца проекта. Четыре покинайзера очень хорошо поднимают качество распознавания. То есть здесь у нас идет нативно, то есть один к одному, а вот здесь идет некоторое замедление. Естественно, каждый из этих покинайзеров, подается в модель произношения, и мы получаем несколько вариантов слова. А вот здесь начинается интересное. То есть вот здесь слева, да, вот в этом вот кусочке, у нас находится задача STT. А вот здесь находится задача работы с языком. И на самом деле именно так, в биологическом плане, это и работает. Почему мы когда спрашиваем, что-то не расслышал и так далее, у нас вот здесь вот на уровне спеллчекера, то есть контроля произношений, или мы когда услышали новое слово, почему мы, зависая, почему всегда нужно прояснять слова? Если мы что-то изучаем, первое, что мы делаем, мы обязаны поработать с терминологическим словарем. Как только вот здесь у нас происходит зависание, либо вот здесь, все, у нас там фокус внимания, потому что подсознательно в мозге включается параллельный поток понять, что это такое. Здесь мы нормализуем из каждой из версий. то слово, то есть вот этот голосовой токен, который мы получили. Казалось бы, текст уже идёт здесь. Да, идёт. Но когда мы его берём, векторизуем, обычная векторизация, я использую хрящевичный векторизатор, мы получаем обычную хорошую пуллинграмму. А дальше мы можем применить наше знание о языке, фактически анализ фраз, как я это делаю. То есть мы читаем, учим систему отвечать на текстовые вопросы. Хорошо. Но раз мы это читаем в каком-то эталонном, то есть мы читаем словари, художественную литературу системы, мы же знаем, как устроен язык. Мы знаем, какие слова вместе употребляться. И здесь, через англиомизацию, мы можем с этих характеризаторов Фактически выцепить фразу, даже если мы ее особо не расслышали, так же работает на самом деле человеческое восприятие. Мы выцепляем фразу, либо несколько фраз, и выдаем ее сюда. И качество распознавания на том же дипспиче, я не трогал код самого дипспича, но в этом нет необходимости, он хорошо написан. Качество возрастает диаметрально. Кстати, все слышали про NLP, которое не Natural Language Processing, а не релингвистическое программирование. Вот так вот оно и работает. То есть здесь, когда мы слышим что-то в прямую, на самом деле в параллельных каналах мы вот из этой базы, это у нас не Language Knowledge Base, то есть не база знания языка, а некоторые наши воспоминания, опыт и так далее. они достаются вот в этих параллельных потоках и тоже идут сюда. Хотя это идет на подсознательном либо не до конца осознаваемом углу. Вот так это и работает. То есть, чтобы реализовать подобную систему, почему я здесь и сделал три отдельные очереди. И для распределенных вещей. То есть, когда у вас, например, две материнские платы, в каждой по четыре видеокарты. Казалось бы, зачем? Взяли одну материнскую плату, засунули туда восемь через райзер. Нет, не для всех задача подойдет, потому что скорость обмена данными с видеокарты при этом совершенно другая. И так может быть лучше. Либо если нам нужно добавить распределенно через тот же блокчейновый кворум, либо через какой-то субкворум, то есть какого-то приватного IPFS, ресурсов, нам нужны именно очереди асинхронные. То есть, когда система устроена так, вам не нужно ломать голову, когда вы будете что-то обучать. Вот здесь не хватило ресурсов, надо, например, один, два, три, четыре, а может еще десять организаторов. Ну, недостаточно пока, например, вот здесь у нас данных. Пожалуйста. Система сама это смасштабирует. Вот для чего это и делалось. О вот этой архитектуре понятно, как идет обработка или объяснить? Чати я пока вопросов не вижу. 

S00 [00:43:27]  : Алексей, у меня возник вопрос на самом деле про то, что, раз уж ты переспросил, по поводу того, что распознаются плохо слова. А ты не думал на ту тему, что, во-первых, любое распознавание всегда идёт в контексте, и на самом деле разрешение амнимии часто происходит в результате того, что просто мы знаем, какие похожие слова друг на друга в данном контексте являются более правильными. Это первое. Это вот здесь. Вот. Где? 

S01 [00:44:05]  : Вот, language knowledge base, то есть база знаний о языке через N-граммы. Совершенно верно. 

S00 [00:44:14]  : Это уже в конце. 

S01 [00:44:16]  : Да. Здесь задача, смотри, здесь задача распознать слово не в плане его смысла, либо во фразе. Вот здесь мы уже переходим к фразам. Вот это идет дальше. Наша задача получить с голосового ввода, вот отсюда, да, с АЦП, получить текст того, что вы сказали. 

S00 [00:44:43]  : Это уже идёт дальше. На самом деле, я неправильно сказал, видимо, слово амонемия. Дело вот в чём, смотри. Я просто тоже занимался распознаванием текста, и когда экспериментировал с тем же самым буглом, я во многих случаях Просто мне не удавалось его заставить перенести какое-то слово, правильно не перевести, а точнее распознать, несмотря на то, что я очень тщательно проговаривал. Вот, ну у меня как бы английский не идеальный, да, вот, хотя и достаточно хороший, но он упорно распознавал слова, которые по звуку похожи. Но в данном контексте совершенно неуместно. То есть, если бы я был человеком, то я бы, на самом деле, ожидал, что я буду слушать те слова, которые... То есть, если есть два похожих слова, и система не понимает, какое точное слово сейчас должно прозвучать, система, на самом деле, смотрит на контекст, и в этом контексте она правильно угадывает, какое слово мы распознаем. И, собственно, вот это то, что делают всякие BERT и GPT-3 с помощью механизма Attention на самом деле. Я про это спрашивал. 

S01 [00:45:56]  : Вот это здесь будет, справа дальше. То есть, вот эти четыре потока, которые здесь нарисованы, они дальше не идут. То есть, вот здесь мы просто распознали слова более-менее. А дальше здесь как раз мы смотрим на контекст, и можем дальше производить этот анализ. Просто здесь у нас не будет нерасслышанных слов. Если твое слово есть в системе, то есть мы его знаем, мы с ним хоть раз где-то встречались, Для него векторайзер сможет найти уже существующий хэш, и так или иначе оно будет здесь. То есть в один из этих потоков оно попадет с очень большой долей вероятности. Чтобы оно возросло на количество потоков, нужно увеличивать. там ГПТ, они идут дальше. То есть если мы смотрим, например, голосового ассистента задачу, которая отвечает на вопросы, то вот здесь дальше это попадает, вот эти потоки попадают на обработку уже самого ассистента. Здесь мы обработали голос. Мы не отбрасываем эти потоки. Плюс то, о чем ты рассказываешь, возможно их система была еще не обучена на этот контекст. То есть у них вот здесь не было нужной связи. 

S00 [00:48:03]  : Алло. Алло, да. Здесь, да? 

S01 [00:48:05]  : Да, да. Понятная идея? 

S00 [00:48:07]  : Да, да, окей, хорошо. Давай двигаться дальше. 

S01 [00:48:11]  : Так, а какой у тебя другой вопрос был? Вот этот вопрос и был. Понятно, как в этой архитектуре он будет решен? 

S00 [00:48:26]  : Окей, да. 

S01 [00:48:28]  : То есть, что мы вешаем дальше, если смотреть? Как раз по твоему вопросу, твоей задаче смотреть. Вот это только ввод. Это точка ввода, которая находится вот здесь. Она идет на уровень API, интерфейса. Дальше она попадает в очереди. Как реализуется вот эта живая система? Как ее реализовать? чтобы она работала так же. И самое главное, чтобы мы могли описать ее так же. Почему и теми же пайплайнами, как либо здесь, либо вот здесь, мы это не можем описать. Потому что у нас нет вот этого узла. То есть вот этот build pool, мы подаем данные сюда, на вход. Что идет дальше? У нас идут результаты. результаты отсюда, результаты отсюда, а также, на самом деле, еще сопоставляются результаты отсюда. Я экспериментировал с большими базами текстов, это пока показывать не буду, потому что очень фыра. но в принципе, в принципе, у меня удалось машину научить, выучить новое слово, то есть понять, что оно значит. суть в том, что если, например, тот же GPT-3, смотрите по моделям, Сбербанк выложили даже свою модель в доступ открытый. Попробуйте с ней просто неразвернутыми вопросами пообщаться, чтобы она продолжала текст. Текст будет очень нередко не в попад, хотя обучали действительно много. Вот если мы опять же применим 1000 Brands Theory и будем оценивать Тексты на выходе с нескольких GPT-3, предположим. Я с GPT-3 не работаю, я люблю открытые модели. Эксперименты базовые у меня есть на GPT-2. Здесь их стоит несколько. Потом в конечном итоге мы пополняем, во-первых, баланс векторов и также немножко корректируем спеллчеки. То есть мы можем выучивать новые слова. Откуда я это беру? Я это беру следующим образом. Вот у меня здесь следующее. Этот модуль в принципе работает, но пока релиз у меня будет другого. Значит, смотрите, мы берем... Релиз этого будет, я думаю, ближе к 8. Мы берем там слово... Пусть это будет слово A, тогда. Пусть это будет слово B. Это, соответственно, слово C. Это у нас, вот если смотреть на вот этот викторизатор, это у нас будут 3 токена, то есть это 1 грамма, это 2 грамма. Я беру и делаю точно так же, но делаю маленький нюанс. Сейчас я другим цветом помечу, чтобы было ясно. А вот здесь будет немножко другое. Я бы оставил специально. Это другой язык. То есть, вот это русский, а это английский. Вот эти два словосочетания имеют тот же самый смысл, но на разных языках. Здесь у меня есть определенная базис из той же Википедии. И здесь у меня есть базис из Википедии и из других непосредственно источников. Что я делаю дальше? Я, во-первых, вижу и научил машину это видеть. То, что, например, слово «был» у нас сказал «заимствовал». Ну, таких слов достаточно много. Мы вычисляем при этом заимствованные слова. Во-вторых, эти слова разные, но здесь у нас есть смысл. И я объединяю вот как раз то, о чем ты говоришь, какие слова могут быть, какие словосочетания могут быть. Это на коррекцию вот здесь. То есть я вот этот блок, анализ фраз, на самом деле дуплицирую столько раз, сколько у меня найдется вот таких составлений. Зачем? Это очень хорошо позволяет распознавать, например, терминологию. Берем российский, нормально написанный на русском языке, технический текст, например, по интернет-маркетингу. Если мы сопоставим в графе то, что интернет-маркетинг, вот они, вот здесь будет, соответственно, AB и тоже AB, потому что Это оба заимствованные слова. Например, поисковое продвижение, поисковый маркетинг. Это будет поисковый маркетинг, то есть маркетинг-маркетинг у нас будет здесь. Здесь, соответственно, будет поисковый, здесь будет, соответственно, слой сёрки. Мы можем объединить эти базы непосредственно и распознавать, этот текст из контекста, не теряя контекст русского языка. Но мы сможем понимать какие-то новые слова, которых вот здесь еще нет. И научиться этому на лету. Это также позволяет системе. Также при обучении вот эти графы, эти графы можно будет, их на самом деле можно дергать через вот эту интерфейс. То есть, если вы создаете, вы можете делать это публично, как те же ребята из Кибера, можете делать у себя это приватно в IPFS и при этом из своего инстанса нормально совершенно адресовать. Вы можете вот эти вот все ваши знания системы дергать из любого куска ваших задач, не одной задачи, а нескольких задач. То есть у вас появляется единый инструмент, единый интерфейс для того, чтобы обучение шло не просто этимодально. То есть где-то, например, вы, предположим, анализируете, не знаю, анализируете литературный текст, да? Вот как ты сказал, там, любимая чашка кого-то из писателей, я понял, вот. А где-то мы начали решать новую задачу, и мы начали решать задачу распознавания образа. Естественно, куда мы это встроили? Мы встроили в мобильное приложение и ходим с ним покемонов. А почему бы нам при этом, классифицируя что-то на фотографии, не спросить наш предыдущий опыт из той же литературы, чтобы понять, а что мы здесь можем видеть? Мы же так думаем, это логично. Но опять же, вот эта архитектура классическая вам этого не даст. У вас вот этот кусочек будет другой. И это все ваши исходящие данные. И они от исходящих данных предыдущего попытки, они изолированы. Единый интерфейс, когда вы можете следующую задачу, как мы в жизни, собственно, сами и делаем, и более того, как делают это все живые организмы, мы решаем это, исходя из своего прошлого опыта. Причем это делают не только многоклеточные, но и одноклеточные организмы, которые способны к обучению. Да, такие есть. Они тоже это учитывают. То есть не важна реализация, важен принцип, если он настолько широко распространен. И вот здесь как раз подобные сопоставления и возможность эти сопоставления хранить, в том числе распределённые, этой возможности, в принципе, тоже нет. Я думаю, что это поднимет обучение совершенно на другой уровень. На самом деле, хотелось бы услышать про ваши задачи, и если нет чего-то экзотического, то, может быть, летом вы уже сами сможете это применять. Причем самое главное, для этого вам нужно в принципе знать базовый питом. Визуальный билдер типа вот такого, то есть как я вот сейчас рисую, чтобы можно было бы так составить из компонентов систему. Такая идея у меня есть, но разрабатывать его пока просто нет времени. Так что пока мы будем без этого компонента, но со временем он будет. Так, ну тогда сейчас давайте отвечим на вопросы, которые там были. 

S00 [00:58:22]  : Да, на самом деле, Алексей, последние два вопроса ровно такие. У нас с Виктором Казариным, похоже, одни и те же вопросы. 

S01 [00:58:38]  : Градиент освещения дает точную информацию. Это как раз о том, почему я говорил, что если вы стоите при директиве, она перестанет вас видеть. Потому что предобработка изображения у нас тоже. Не нужно думать, что человек венец творения. Нет, это такое же животное, которое никто не освобождал от исполнения законов природы и естественного отбора. И то, что он их не исполняет, уже очень хорошо вышло ему боком. В частности, мы так получили болезнь цивилизации и заспамленный генофор. У нас тоже есть то, что есть у лягушек, в зрительном нерве, такая же предобработка. Это не градиент. Градиент как раз дает эту информацию. Просто вот это первое звено – это предобработка. Понятная идея. Также, кстати, работают и иллюзионисты. Они используют вот эти особенности предобработки, чтобы сразу в мозг пролетел сигнал, который будет давать иллюзию. Почему на некоторых людей вот эти все шоу-иллюзионисты не действуют? Это, кстати, совершенно нормально. Потому что у них скорость вот именно обработки визуальной выше дополнительной обработки, я имею в виду. И шумовой сигнал, то есть вести человек в заблудении, не получается. Какая связь? Объясню. Суть в том, что архитектура системы, архитектура сети, там не только одна сеть, в том-то и все дело. У нас, если мы посмотрим, можете посмотреть даже не в каких-то научных статах, а в гугле, посмотрите, срез нервного окончания, срез крышка спинного мозга, срез самого спинного мозга, срез подолговатого мозга, срез головного мозга какого-нибудь из отдела. Это все нервные ткани и роглеи, но они совершенно разные структуры. В том-то все и дело, что должно быть несколько сетей. Вот у нас с вами, у нас огромное количество сетей. И есть подсистемы, которые раньше наука ошибочно читала, ну тоже рудиментарными, не работающими, типа той же юнитической системы. Еще как работает. Это несколько разных систем, то есть не обязательно это одна сеть. И вот чтобы между этими блоками не терять контекст обработки, поскольку все очереди асинхронные, как вы видели на примере этих фотографий, очереди асинхронные, и чтобы не терять контекст обработки, вот нам и нужны для этого непосредственно гииды. Далее, праволицензию. Патенты публикуются, верно. Правообладатели не теряют своих прав на то, что они не публиковали. Классическая история была. Ребята из какого-то автосайта анализировали. У людей начали вылетать движки. Причем открывают, в движке просто каша, не пой, ничего, машина. Что случилось? И эксплуатируют нормально. Дилер отказывается на гарантию менять, потому что пошло, пошло, пошло. В чем было дело? Они спросили о формулах. В частности, катализаторах. Только LiquiMole, производитель, дал катализатор и раскрыл формулу, патентованную ребятам, чтобы они просто смогли подтвердить, что действительно такое бывает от катализатора. Все остальные не дали. Вторая история. Один из ребят купил на аукционе камень, но он оказался грязным. Он взял его, помыл стиральным порошком, чтобы красиво было смотреть, и открыл новый минерал. Смотрит, да, действительно, такого состава нет, но смотрит, там соли, одно из органических кислородов, которые в принципе в минералах не встречаются. но она встречается в непосредственно синтетических помощи средств, в частности стиральных порошков. То есть он фактически обработал его. Спросили у производителя порошка, поскольку там была уже экспертиза для продажи и так далее этого образца. Эта история гуглится в интернете, то есть это не придумано. Производитель отказался вообще раскрывать, что входит в его порошок детально, как это работает. Когда его спросили, у вас такая кислота есть, они сказали, да, есть. Они сказали, больше ничего. Все, что публикуется, оно бесплатно. Если вы хотите обладать на что-то правами, держите это в секрете. Тогда вы сможете продавать право это использовать. Если вы что-то выложили, то все. Создатели трансформера GPT, они не выложили GPT-3 в открытый доступ, И я их прекрасно понимаю, причем они именно по этой причине, как раз по нашему вопросу, они его и не выгружили. Потому что они сказали, да, у нас есть платная опишка. Эти деньги пойдут на дальнейшие исследования и помогут нам развивать наш проект. имеет право. У меня библиотека тоже на AGPL. То есть, хотите учиться там, либо что-то делать открыто, да, пожалуйста. Если это хотите коммерциализировать и так далее, да, давайте договоримся лицензионным спрашиванием. Потому что повторять историю с Ай Павловым, который мне, когда я все узнал, ну, мне, честно говоря, не хочется. Вот. То есть, это не антикопирование. Это отсутствие копиоризма. То есть, есть плагиоризм, когда мы просто берем что-то, копипастим и над этим идем. А есть копиоризм, либо, как ее называют, копиростией, когда вы просто вот за насвистывание мелодии в душе вы должны заплатить ее правообладателю. Давайте не будем заниматься здесь пиаризмом. 

S00 [01:04:38]  : У тебя все-таки то, что ты рассказываешь, это у тебя какая лицензия? 

S01 [01:04:44]  : Это абсолютно открытая. 

S00 [01:04:46]  : То есть у тебя какая конкретная лицензия? 

S01 [01:04:49]  : Ты имеешь в виду на библиотеку на саму, на код? 

S00 [01:04:51]  : Да. 

S01 [01:04:52]  : Код Alpherge BL3. Код полностью открыт, соответственно, совершенно свободен для использования в обучающих, некоммерческих целях и так далее. Если кто-то из этого захочет сделать SAS, например, как Ай Павлов сделал из Дик Павлова, нет, это не получится. Без моего лицензионного разрешения. А если хотите применять это в продукты, берите и применяйте. 

S00 [01:05:20]  : То есть это типа MIT? 

S01 [01:05:23]  : Несколько более жестко в плане коммерциализации. Чтобы в том числе не повторить историю Айпаумова. 

S00 [01:05:32]  : Ну а несколько более жестко можешь двух словах сказать? Какие там расстычения? 

S01 [01:05:39]  : Там смотри, по сравнению с MIT я сейчас тебе такую корреляцию сходу не скажу. 

S00 [01:05:46]  : В MIT лицензия такая, там можно все кроме убора, убирания копирайта. То есть ты можешь менять, можешь строить коммерческие приложения, но ты обязательно должен сохранять исходный копирайт. 

S01 [01:06:03]  : А, нет, копирайт там, естественно, ты указываешь того, что твое, указываешь твое, и сама лицензия сохраняется, то есть выходит под этим тоже должно быть на GPL. Вот, и если ты хочешь это встроить, например, в какую-нибудь компьютерную программу, ну там, например, в мобильное приложение, да, пожалуйста, свободно. Вот, если хочешь делать из этого там Вот именно сервис типа СААСа, да? Как тот же IPAO. Вот тут да, тут нет. Без моего лицензии. То есть это можно заключить лицензионное соглашение, вот, а так нет. В MIT это можно. То есть медлицензии я могу там из проблем взять это, сделать СААС. Как бы без разрешения правообладателя. Вот. У IFRT нельзя. 

S00 [01:07:01]  : Окей, давай посмотрим, какие у нас еще там вопросы есть по правам вопросов. 

S01 [01:07:05]  : Да, я сейчас дальше иду по этому, по чату. Любой интерпретатор-компилятор – автономная отдельная анализирующая сущность. Значит, там используется компилятор, интерпретаторов я не использую. И, честно говоря, я не планирую. Вам никто не мешает их прикрутить, если они вам нужны. Я использую, в принципе, Python. И немножко забегая вперед, поскольку это первый кусок гиперсферы, там будет еще и для smart contracts и для всего остального, там будет PHP 7. Это все, в принципе, языки, которые в байт-код компилируются. так или иначе Python создает PySE, PHP создает свой байт-код, его можно, в принципе, при желании выгрузить, но да, в эти контейнеры можно будет загружать распределенные, которые в том числе и через блокчейн синхронизируются, в них можно будет загружать свой код, но не байт-код, то есть того же, как в эфире, но если об этом был вопрос, отдельная сущность, которая закрыта, нет, она открыта Там будет возможность обсчитывать приватные данные с сохранением и приватности, и открытости. Это я расскажу отдельно. Это будет осенью показываться, потому что SOM и другие на этом тоже запнулись. У меня, похоже, решение получилось. И это будет отдельный совершенно рассказ, потому что там очень много будет как раз математических моментов. Парсеры по API можете вязать любые. GUID, естественно, реализуется через те или иные хэш-функции. В Linux, собственно, GUID реализуется также через функции. Есть libguid, если говорить по Linux, и ее аналоги. И они встраиваются в том числе и в гидро-Linux, никаких проблем. То есть это все одно и то же. Да, я о таких именно и говорю. Почему там отдельно стоит GATE? Потому что он все-таки должен быть глобал. То есть по системе он будет синхронизирован, чтобы у нас ни у кого не получилось двух одинаковых идентификаторов. В этой системе можно учитывать обратные связи от более поздних этапов. вот на speech recognition вот этот базовый кусок proof-of-concept у меня есть. я не скажу, что у меня есть альфа. есть proof-of-concept. когда будет это расписываться дальше, когда буду это расписывать, да, посмотрим. Естественно, есть система. Почему я перевел именно в такой сразу контекст очередей и контекст распределения просто из коробки, то есть она у вас сама создает считающий факт, чуть ли не кластер, и почему она еще умеет гулять через блокчейн. Вы не должны быть связаны этим, тем, на чем вы работаете. Смотрите, есть студент, да, Что он потянет? Он потянет нормальную карту для математического обсчета. Ну, она стоит где-то полтора миллиона рублей. Конечно, нет таких денег в большинстве случаев. Даже, более того, ноутбук с какой-то мощной игровой видеокартой. Навряд ли. Но он может взять этот токен, и когда изучает непосредственно свою задачу, Вот просто с этого ноутбука, хоть с нетбука, там за 10 тысяч рублей, не все сейчас богаты, он может точно так же полноценно эту задачу распределять. И все связи, все связи прописываются в дефиниции задачи, она модульная. То есть там можно будет и веб-сервис задавать, интеграция с бизнесом тоже есть. Вы можете учитывать любую связь. какую вам угодно. Некоторые связи, которые я рассматриваю, я их напишу. И более того, покажу, наверное, даже будет по этому отдельное видео делать, и вот такой же эфир, потому что Zoom я себе пока еще не брал, но я чувствую, скоро будет надо, где объясню, как я это строю. Вы сможете построить и учет своих типов связи через API. API как раз сделано универсальным. Вы захотите, можете использовать НЛТК, например, там либо с цепью вот просто нарратив на уровне этих трейдеров. Не хотите, вы просто хотите описать задачу. Оно само подтянет и попользует так, как уже есть. То есть тут опять же выбор у вас совершенно свободный. И как в том... чем вы обрабатываете каждый этап, так и то, как ваши этапы между собой связаны. Вот это, говорю, совершенно четко. Так, насчет системы. Она выучила смысл слова, она поняла его контекст, то есть, что это значит. Естественно, это не настолько умная система получилась, которая сразу понимает его как человек. Но она поняла, к чему оно относится и относительно, что оно означает. Вот это здесь как раз отдельно я прорабатываю, выкачиваю, сейчас называется тоже, что можно совершенно свободно скачать. Я достаю толковый словарик. Причем как общие, так и терминологические. Общие репозитории в виде IPFS уже есть. Вы можете класть это все в открытый доступ. Вы можете сделать из нескольких своих устройств, сразу тоже оговорюсь, это делается. Вам не нужно будет настраивать IPFS. В программу у меня это внесено, вы просто сможете сказать. Вы сможете создать свой личный репозиторий, например, для вашего домашнего компьютера, вашего ноутбука и вашего мобильного телефона. У них будет возможность вот эти данные, которые есть у вас либо там, либо там, либо там, и это будут только ваши данные. Например, какие-то ваши очень пикантные приватные фото. вы сможете их обрабатывать системой просто через них. Финальный релиз, но до финального релиза еще как декалец Сатурна. Следующий релиз, вот кусок, который будет, сейчас там лежит степишка, она объясняет через другие, в том числе, это я использую. Это то, как на самом деле работает метод прояснения в образовании. То есть, когда вы учите ребенка, вы ему сразу не объясните многие математические вещи, хотя это элементарно. Вы просто показываете, самую базовую терминологию проясняете. Когда вот терминология идет, вот дальше человек начинает уже понимать. Фактически это контекст. но опять же тут очень очень сыро это proof of concept то есть в какие-то моменты здесь я как только доделаю и выложу в релиз действительно уже с запуском токена в боевой в том числе среде распределение полностью вот тогда смогу заняться за это потому что ну мне еще нужно другими делами заниматься и в одну персону пока на это времени хочется но в сутках только 24 часа. Я понимаю, это жуткая недокомплектация, но так есть. Релиз будет, он идет поэтапный. То, что сейчас лежит там, это CTP, это Community Technical Review. То есть до альфа-версии, если смотреть, до конца года, я думаю, альфа-версия будет хорошая. Может быть, даже с этим визуальным гилдом. Насчет визуального билдера, чтобы можно было так составлять, у меня есть идея скрестить его с Python в плане iPad ноутбука. Может быть, кто-то видел, если кто-то с Python работает, знаете. Дедлайн пока особо не стоит. Вопрос в том, что это зависит, ребята, к сожалению, только от наличия моего свободного времени. я все-таки смог сделать себе подарок на последнее рождение, просто огромное количество проектов отрубил и опять занялся в том числе и исследованиями в этой штуке и написанием всего этого, чтобы можно было выкладывать. я в начале года это зарелизил. к рождеству это CTP сделал и так далее. все зависит только от свободного времени. Когда конкретно, сказать не могу. Вот где не знаю, ребят, врать не буду. Окей, так, у кого еще какие вопросы? 

S00 [01:16:22]  : Там вопрос еще где-то был в начале про какой инструмент вы используете, редактор? 

S01 [01:16:29]  : Так, редактор. 

S00 [01:16:31]  : Где картинки рисовал, ну как бы технический такой вопрос. 

S01 [01:16:35]  : А, Ycat. Это опенсорсная утилита, очень хорошая штука. Вот он так называется, он гуглится, скачивается бесплатно. Кстати, в принципе, если уж говорить о компонентах и мультимодальности, сейчас еще есть, но, правда, я его пока туда не релижу, есть связка с OpenCV. Это библиотека машинного зрения. 

S00 [01:17:06]  : Хорошо. Коллеги, есть еще какие-то вопросы у кого-то? Вопросов нет. Тогда, Алексей, спасибо тебе за информацию. 

S01 [01:17:22]  : Ребят, вам спасибо. Демо-дэй, я думаю, будем делать в начале апреля, как раз когда релиз будет. Там 100% будет полностью показана задача работы с корпусом Википедии и вообще как в него свое что-то добавлять. И не переобучать это, как у Димпавлова, а дообучать. Это я тоже покажу. И, возможно, уже покажу базовую версию вот этого deep speech с speech recognition, который я сделал. Но там пока будет без ngram, то есть вот этого блока language-knowledge-base, я его вряд ли успею доделать до этого момента. Это будет фактически некоторый такой голосовой QA-систем, разобранный по винтикам. 

S00 [01:18:09]  : Хорошо. Коллеги, всем спасибо. Алексей, спасибо. И успехов. До свидания. 

S01 [01:18:16]  : Спасибо. Пока-пока. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
