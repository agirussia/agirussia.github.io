## 13 мая 2021 - МVP для AGI — что это? Эпизод 1 — В.Артюхов, О.Серебренников, И.Пивоваров, А.Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/IJSsD59_K2c/hqdefault.jpg)](https://youtu.be/IJSsD59_K2c)

Суммаризация семинара:

Семинар посвящен обсуждению MVP (минимально жизнеспособный продукт) для AGI (искусственного общего интеллекта). Участники обсуждают рабочее определение AGI и работают в рамках канонического определения общего искусственного интеллекта.

Тематические блоки:

1. Определение AGI и MVP
   - Участники семинара работают в рамках определения AGI.
   - Обсуждается важность конструктивной дискуссии с учетом рабочего определения.
   - Просьба спикеров указать на свои определения AGI, отличные от рабочего.
   - Критика существующих проектов с позиции других определений AGI не уместна в рамках семинара.

2. Проекты и представления
   - На семинаре представлено четыре проекта, а также запасной пятый проект.
   - Каждому проекту отведено по 30 минут: 5-10 минут на представление и 20-25 минут на обсуждение.
   - Просьба задавать вопросы и комментарии компактно, чтобы все успели высказаться.
   - Обмен мнениями ведется в телеграме, а не в общей группе.

3. Обсуждение MVP и AGI
   - MVP для AGI не обязательно будет привлекать инвесторов.
   - Основной результат семинара - формирование команд для разработки проектов.
   - Возможность найти партнеров и коллабораторов в рамках проектов.
   - Некоторые участники сомневаются в возможности найти инвесторов благодаря семинару.

4. Технологии и продукты
   - Различие между технологией и продуктом: технология - это способ построения модели, обучения и получения результата, в то время как продукт - это конечный результат, который может включать в себя технологии.
   - Важность формализации архитектуры и акцептора результата действия.

5. Обсуждение итераций обучения
   - Возможность обучения на основе подкрепления (reinforcement learning) и ее различия от дословного перевода.
   - Важность понимания того, как обучение происходит на основе ошибок, а не только на основе жизни.
   - Обсуждение концепции curriculum learning и ее потенциальной роли в AGI.

6. Комментарии и вопросы
   - Вопросы по поводу работы в команде и архитектуры модели.
   - Комментарии по поводу универсальности представлений и их роли в AGI.
   - Вопросы по поводу экономической эффективности обучения роботов и сравнения с программированием.

7. Примеры и аналогии
   - Аналогия с обучением мышей и их способностью рассказывать о находках.
   - Работа группы Александра Панова с роботами в виртуальных и реальных средах.

Заключение:
Семинар показал разнообразие мнений и подходов к AGI, а также важность формализации и понимания процессов обучения. Участники обсудили не только технологические аспекты, но и экономическую эффективность и возможности применения AGI в реальных проектах.




S07 [00:00:18]  : Да, коллеги, всем добрый вечер. Давайте начнем калякать о наших скорбных делах. И хотелось бы сказать небольшое вводное слово прежде всего. Прежде всего хотелось бы предположить, что хотя мы будем говорить о MVP, или о том, что мы называем MVP, но на самом деле это совсем не MVP, как многие высказали в Телеграме. На самом деле я не уверен, что мы реально в результате этого разговора найдем инвесторов, потому что я не уверен, что здесь у нас в группе присутствует много инвесторов, и что много инвесторов посмотрит нашу передачу. Тем не менее, мне кажется, что наибольшая польза от этого разговора будет, если мы не столько инвестора найдем, сколько найдем друг друга в плане того, что мы сможем сформировать, возможно, по каким-то проектам, которые будут сегодня или в следующий раз обсуждаться, сможем по ним сформировать какие-то команды, добровольно объединившиеся, потому что при всем разнообразии мнений, позиций, подходов и навыков и возможностей из тех тысяч человек, которые в группе, я думаю, Единую команду собрать невозможно, но, как уже говорилось несколько раз на предыдущих семинарах и обсуждалось в группах, может быть, удастся кому-то найти себе партнеров и коллабораторов в разработке тех или иных проектов. И вот мне кажется, что если это произойдет, то это будет основной полезный результат нашего сегодняшнего разговора. Значит, это один. Ну, а если вдруг кто-то еще и благодаря этому семинару найдет себе инвестора каким-то чудом, то это будет вообще сказка. Но в это с трудом верится. Тем не менее. Значит, второе, на что хотелось бы обратить внимание. Мой экран сейчас всем видно? Я надеюсь, что видно. Хотелось бы обратить внимание, что мы сейчас на этом семинаре работаем в рамках этого определения, так сказать, рабочего определения или канонического определения общего искусственного интеллекта. я к чему это говорю что у многих людей есть неприятие этого определения у многих есть свои определения вот но чтобы дискуссия была конструктивной сегодня мы вот работаем вот в этих вот рамках то есть если у кого-то из спикеров основных вот которые будут представлять сегодня проекты есть Своё определение, отличное от этого, просьба на это указать, а если кто-то захочет покритиковать существующие проекты с позицией своего определение отличного от того, которое мы видим сейчас на экране, то, наверное, это не очень уместно, потому что вот мы сегодня работаем в этих рамках, вот, и в других каких-то рамках можно поработать в рамках какого-то другого определения. Ну, даже если что-то очень важное нужно сказать, отталкиваясь от своих частных определений, Вот то, просьба на это указать, что вот я не согласен с главным определением у меня, вот с данным определением у меня есть свое, и вот с позиции этого своего определения я, значит, задаю вопрос или делаю комментарий. Второй момент. У нас сегодня четыре проекта. Есть пятый запасной. Не знаю, дойдем мы до него или нет. Но даже если у нас четыре проекта, все равно на каждый проект получается по 30 минут. Соответственно, представляющий проект человек может потратить минут 5-10 на его представление по тем вопросам, которые были обозначены. И соответственно оставшиеся 25-20 минут на обсуждение вопросы, комментарии. Просьба задавать вопросы и комментарии очень компактно, чтобы это не было развернутой оппозиции, а чтобы были именно вопросы или замечания, чтобы все успели высказаться. Если время будет оставаться, то можно будет кому-то дать желающим развернутой оппозиции высказывать. И в связи с этим просьба, чтобы понимать, кто хочет что сказать, использовать группу в зуме прежде всего для записи на очередь, а обмен мнениями друг с другом вести в телеграмме, а не в общей группе. 

S08 [00:04:40]  : Антон, извини, пожалуйста, а мне казалось, что сегодня семинар посвящен MVP, то есть концепции, что такое должен быть MVP. И я как бы там, ну, согласился поговорить про то, что такое MVP, но никакой проект представлять я лично... Хорошо, хорошо, концепции, то есть проект, концепция MVP, да, окей. 

S07 [00:05:03]  : Хорошо. Окей, да. Я называю это проектом. MVP предполагает, что мы обсуждаем какой-то гипотетический проект, в рамках которого будет делаться некоторое гипотетическое MVP. Так можно интерпретировать мои слова. Вопросы, которые хотелось бы обсудить сегодня, были заданы. Они здесь есть на экране, я их зачитывать не буду. Значит, еще что хотелось бы важное сказать. Мне кажется, ну, опять-таки, это может быть моя позиция, что вот у того, что мы можем условно назвать MVP, может быть как минимум две составляющих. Одна – это вот пресловутая болванка. Мне кажется, замечательное определение, которое вот возникло у Алексея Тарасова, что вот Это некоторая болванка, которая может чему-то научиться в результате взаимодействия со средой. В зависимости от того, какая среда, она этому может научиться. Главное, чтобы болванка была обучаема. Но дело в том, что кроме болванки для того, чтобы она чему-то научилась, нужна обязательно среда. То есть говорить о том, что мы делаем такую прекрасную болванку, которая научится чему угодно, мне кажется, невозможно, не говоря о том, в какой среде или в каком наборе сред эта болванка будет чему-то обучаться. А если мы начнем говорить о болванке отдельно и о среде отдельно, тогда возникает еще, возможно, третья компонента, Это о том, как эта болванка связана со средой. Например, если мы говорим про человека живого, то болванка – это его мозг, среда – это естественная среда обитания человека, а соединение человека с этой болванки со средой – это сенсомоторная инфраструктура человеческого организма, которая этого гомункула сосвязывает с окружающей реальностью. Эту позицию было бы интересно, если бы представляющие проекты или MVP как-то к этому отнеслись. Следующий момент, который тоже бы хотелось обозначить. Каноническое определение, которое здесь мы видим, оно подразумевает достижение целей. Но вот если мы посмотрим те проекты, которые будут сегодня представляться, то не у всех из этих проектов, мне кажется, в явном виде будет достижение цели. То есть, например, в той архитектуре, про которую я в свое время рассказывал, есть модуль предсказания, есть модуль принятия решений, есть модуль сжатия информации. Ну вот, например, один из проектов, который будет сегодня представляться, в нем в основном фокус есть на предсказании, насколько я понимаю. А принятие решений там как такового нету, и сжатие информации я тоже не уверен, что там есть. Вот поэтому вот возможно этот проект не очень в полном объеме подходит к определению AGI, но опять-таки я вот Рассчитываю на то, что человек, который представляет этот проект, он про это скажет. Ну и последнее тоже, значит, хотелось бы сказать, что в рамках разговора у нас возможно попадание в терминологические ловушки. Мы в них попадали на некоторых предыдущих семинарах, говоря о том, что такое reinforcement learning. что такое Supervised Learning, что такое Unsupervised Learning. Вот здесь вот хотелось бы обозначить края вот этих вот ловушек. Во-первых, Reinforced Learning можно рассматривать с двух точек зрения. С одной точки зрения это дословный перевод – это обучение на основе самоподкрепления или на основе подкрепления. То есть это парадигма обучение, когда нечто или некто или что-то взаимодействует с чем-то и в результате того, что он от этого чего-то получает, он обучается. Вот на самом деле 20 лет назад, даже уже 22 года назад, еще до того появился как термин reinforcement learning, у нас с Беном Герцелем в проекте WebMind было понятие Experiential Learning. То есть вот у нас там, так сказать, одно из мейнстримных направлений называлось Experiential Learning. Это вот как раз тот самый AGI, который должен был в взаимодействии с окружающей средой, с определенным эссенциомоторным фреймворком, должен был обучаться взаимодействию с этой средой, достижению определенных целей с минимизированием потребления ресурсов. В существующей парадигме это сейчас чаще называется Reinforcement Learning, но многие почему-то воспринимают Reinforcement Learning как некоторый набор алгоритмов машинного обучения, которые решают задачи Reinforcement Learning, используя, например, Q-Learning или Deep Q-Learning. И вот это семейство алгоритмов машинного обучения ассоциируется с Reinforcement Learning, и поэтому у некоторых людей негативная реакция есть. вот и вторая значит терминологическая ловушка это насчет supervised learning то есть вот что такое supervised learning есть как бы такая интерпретация supervised learning это что вот если у нас есть supervisor то тогда у нас это supervised learning. То есть если учитель читает лекцию ученику в школе – это supervised learning. Если ученик сам выполняет задание, а учитель ему потом ставит оценки и показывает, где ошибки сделаны – это тоже вроде как supervised learning. Но, с другой стороны, в каких-то случаях у нас ошибки расставляет учитель, а в каких-то случаях у нас ошибки расставляет жизнь. То есть, на самом деле, с точки зрения взаимодействия объекта обучения со средой обучения, supervised learning, так сказать, во взаимодействии с учителем – это unsupervised learning или это experiential learning или это reinforcement learning во взаимодействии с средой. А можно раз говорить об supervised learning в более, так сказать, каноническом смысле. Supervised learning – это обучение на размеченных корпусах. То есть, если у нас есть разметка, И мы на основе этой разметки учимся. Это и формируем свои модели на основе каких-то размеченных корпусов, фотографий, текстов или чего угодно. Это supervised learning. А если разметки нет, и мы решаем чистым виде задачу кластеризации, то это unsupervised learning. Соответственно, если мы здесь будем говорить что-то плохое или что-то хорошее про reinforcement learning, experiential learning, supervised learning, unsupervised learning, то просьба в двух словах уточнять, что же именно под этой разновидностью леарнинга вы имеете в виду. Ну вот, собственно, мое введение на этом окончилось. Я с удовольствием представляю слово Виктору Ратюхову. Я надеюсь, он к нам уже присоединился к этому моменту. Виктор, пожалуйста. 

S03 [00:12:07]  : Время я запросил. Как слышно меня? 

S07 [00:12:11]  : Хорошо. 

S03 [00:12:14]  : Так, сейчас я экран. Экран мой видно? Итого, я недавно начал проект Аджифа. Это Аджи для всех. И, соответственно, потихоньку пишу код для него, который публикую в GitHub. И, соответственно, для этого проекта я придумал несколько задач, которые вполне себе реализуемы. И вот как раз общие требования к этим задачам. Аджифа после обучения должен уметь решать задачи разного типа. Тут правило одно – движок один, решаемых задач много. Чем больше универсальности, тем больше аджи. То есть это такое правило достаточно общее, которое позволяет сильно не отклоняться по пути к созданию общего интеллекта. Задачи должны быть решаемыми за ограниченные сроки бюджета. То есть те задачи, которые я буду использовать для тестирования Аджифа, они должны быть достаточно простыми изначально, но при этом Каждая задача должна иметь сценарий дальнейшего развития и усложнения. То есть начиная тестирование движка с простой задачи, задача постепенно должна усложняться и этот движок должен суметь развиться вместе с задачей так, чтобы даже на более сложных уровнях движок тоже справлялся с более сложными задачами. В этом как бы смысл формулировок дальнейших. Задача, которую мы здесь рассмотрим, называется условно мышь в лабиринте. Самый простой сценарий работы этой задачи будет выглядеть примерно так. Мы рисуем двухмерный лабиринт, вид сверху. куда-нибудь в этот лабиринт кладется кусочек сыра и система отжифа должна научиться перемещать условную мышь по лабиринту мышь тоже двумерная то есть она двумерном пространстве существует пытаясь найти сыр как можно быстрее Система должна уметь запоминать уже известные маршруты, на их основе создавать новые с целью найти СР быстрее. То есть тут должно быть проверено свойство GIF по использованию уже накопленных знаний в базе данных. таким образом, чтобы она эти знания могла использовать для ускорения поиска. То есть чем больше знаний, тем быстрее задача должна решаться, даже в неизвестных лабиринтах. Самая простая конструкция мыши, с которой можно начать. Мышь смотрит на лабиринт двумя глазами, то есть простое стереозрение, но в 2D. Видит стены и проходы между стенами. За счет наличия двух глаз может оценить расстояние до стен до прохода. То есть это простейший вариант стереозрения, когда мы можем в такой простой модели оценить расстояние до препятствий. У мыши также есть датчики столкновения со стенами, которые должны помочь в обучении. То есть, чтобы мышь через некоторое время поняла, что есть стены и сквозь них нельзя пройти, у нее должны, соответственно, быть датчики столкновения со стенами. Сыр, образ требуемого результата, это будет сыр, условный сыр, также должен распознаваться глазами, как и стены, то есть сыр мышь должна увидеть, но при этом, так как у нее в конструкцию мыши заложен этот образ, то она должна понять, что это есть еда, и фактически это и будет конечная цель. То есть это конечный образ, требуемый результат, который передается мыши вместе с архитектурой ее конструкции. То есть это то, что передается по наследству. Ожидаемый результат от решения задачи после нескольких итераций обучения с учителем мышь должна научиться, понимать, что есть сыр. Для этого она должна как минимум один раз дойти до этого сыра и понять, что она знает, что это есть сыр, и, соответственно, это ее цель. То есть хотя бы раз она цель должна достичь, чтобы понять, что это то, к чему она стремится. Должна научиться уклоняться от столкновения со стенами, в этом ей должны помочь датчики столкновения. Должна быстро находить сыр в знакомом лабиринте и находить сыр в незнакомом лабиринте. То есть мы кладем сыр в разные места, меняем схему лабиринта, и задача по-прежнему должна решаться в любом варианте. Развитие этой задачи будет происходить в сторону постепенного усложнения сцены. Сначала будет простой 2D-лабиринт, потом трехмерный лабиринт. Затем можно будет усложнять саму конструкцию мыши, то есть это будет уже не 2D-мышь, а некая машинка на колесах, на гусеницах, может быть даже шагающая. Затем помехи в сцене, чтобы усложнить работу алгоритмом распознавания препятствия. И затем это все то же самое можно перенести уже на железного робота в реальном лабиринте с реальными помехами и так далее. То есть эта задача в несколько итераций может очень сильно усложниться вплоть до реальных сцен. И ответы на вопросы, которые предложил Антон. Как проект относится к АДЖИ? В основе лежит универсальный open source движок АДЖИФа, который сейчас находится в разработке. Те, кто уже смотрел предыдущие презентации, я подробно об этом проекте рассказывал. Почему инвестор захочет вложиться в такой MVP? Потому что это универсальный алгоритм, способный к обучению развитию перспектив и будет требовать меньшей трудозатраты по сравнению с узкоспециализированными алгоритмами. На текущий момент множество алгоритмов, которые относятся к категории искусственного интеллекта, они требуют по-прежнему высоких трудозатрат, например, для того, чтобы обучить нейросеть. предполагается, что более универсальные алгоритмы смогут требовать меньше затрат и за счет этого они станут экономически более выгодными. Что уже сделано, какая есть интеллектуальная собственность, какова ее защита, сколько затрачено на проект в долларах. Проект Adjif находится в разработке, то есть есть архитектура, есть концепция, понятно, что и как там делать, там просто идет процесс разработки кода. и выкладывается в Open Source для того, чтобы к этому проекту впоследствии мог кто-то присоединиться и, соответственно, помочь ускорить его развитие. Есть ли команды и что за команды? Команды пока нет, потому что нет желающих в этом проекте участвовать по непонятным причинам пока. может быть сложный может быть еще что-то какие ресурсы нужны, если нужны деньги, то сколько и на что они будут потрачены. Пока ничего не нужно для этого проекта, то есть если будут желающие, то, соответственно, это может помочь ускорить развитие проекта, но вот на данном этапе не вижу пока смысла каких-то больших вложений в этот проект, потому что это но, скажем так, в реальности пока мало применимо, потому что та же самая задача решается более простым способом, специализированным, и, соответственно, проще написать пока программу, которая все это будет делать, чем развить универсальный алгоритм. Ну вот, пожалуй, все то, что касается конкретно этой задачи. Можете задавать вопросы. 

S07 [00:21:18]  : Виктор, спасибо. Тут уже вопросы поступили. На самом деле, первый вопрос поступил у меня. Я извиняюсь, что его не записал, но я его задам все-таки. Я думаю, успеем. Остальные вопросы тоже. Вот смотрите. Приведу конкретный пример. Есть работы, где человек пытается с помощью reinforcement learning адаптивно на основе deep learning научить этого торгового бота торговать на бирже. И успехи заключаются в том, что этот торговый бот научается еле-еле сводить концы с концами, выработав те стратегии, которые, в общем, давным-давно известны трейдерам, достаточно понятные примитивные вещи известные, что нужно там закрывать сделки и закрывать их при определенных изменениях цены. В результате большого количества затраченного машинного времени бот научается это делать достаточно посредственно. Вопрос, если мы хотим делать какую-то искусственную мышь, которая будет или искусственного робота, который будет находить сыр или потерпевших людей, потерпевших бедствия и спас, чтобы их спасти. Не проще ли закодировать уже известные принципы, как Boston Dynamics кодирует двигательную активность в своих роботах. Вместо того, чтобы долго и мучительно обучать их, постепенно отодвигая сыр на все более и более дальнее расстояние. Вот в чем смысл именно такого инкрементального постепенного обучения с длительной кривой обучения? 

S03 [00:23:05]  : Смысл тут скорее всего не в длительном обучении, а в развитии задач. То есть тут как раз у меня идея в том, что задача должна в первую очередь развиваться в сторону усложнения. И когда задача развьется до реального мира, то она уже будет практически применима. То есть вот этот алгоритм, который способен ориентироваться в лабиринте, он фактически необходим уже прямо сейчас. То есть практически всем роботам, которые скоро, видимо, появятся уже на улицах. И в ближайшие года 2-3 они начнут постепенно появляться, а лет через 10 это станет уже нашей привычной реальностью, как мобильный телефон. И, соответственно, такой более универсальный алгоритм, более экономически выгодные, потому что когда роботов будут миллионы, соответственно, программистов на всех просто не хватит. Сейчас программистов вообще просто катастрофический дефицит. Я в свою компанию, например, не могу найти хороших программистов за разумную стоимость. потому что те программисты, которых я могу найти, они задачами не справляются. И, соответственно, будет через несколько лет все то же самое, только еще хуже. То есть специализированные алгоритмы будет некому писать. Но нет столько людей, которые могут это сделать. А универсальный алгоритм, он, соответственно, будет требовать более низкой квалификации на его развитие. И, соответственно, можно подготовить большое количество людей, которые его просто-напросто обучат по специальной методике и фактически получат правильного робота, который будет нормально себя чувствовать в окружении людей. 

S07 [00:25:03]  : Хорошо, спасибо. Следующий вопрос от Максима Вишневского. Он, видимо, не был на Вашем предыдущем докладе и поэтому задает вопрос, при чем здесь AGI. Те, кто знают Ваши работы, наверное, это более понятно. Можете пояснить, в чем суть Вашего проекта с точки зрения AGI? 

S03 [00:25:26]  : J это общий интеллект, то есть некая абстракция, которая пока еще непонятно, что это такое в деталях, но при этом все понимают, что нужно в эту сторону двигаться. поэтому я в это понятие вкладываю максимальную универсальность. то есть если у нас какой-то алгоритм максимально универсальный, то человек, он универсальное существо, он может решать разные типы задач, если его обучить. точно так же универсальный алгоритм должен без какой-то радикальной пределки решать разные задачи. Соответственно, чем больше задач он может решить посредством его обучения либо до обучения, тем более он будет универсальный, тем ближе он будет к аджи. И это, соответственно, мое понимание, оно не противоречит вот этому базовому правилу, которое было изначально на первом слайде. 

S07 [00:26:30]  : Спасибо. Следующий вопрос от Евгения Бабарыкина. Где здесь MVP? То есть, что именно является MVP? А я бы это еще по-другому... Значит, можно я сейчас чуть-чуть попробую уточнить этот вопрос? Потому что, что такое MVP, тоже, в общем, отдельная дискуссия была. Вот, тем не менее. Значит, посмотрите. Вот мы говорим, что есть некоторый проект, у которого будет какой-то результат. Да? Ну и, видимо, на основании того, будет ли этот результат достигнут или нет, будет работать акцептор результата действия. То есть, у нас получилось или нет. Соответственно, если речь идет о MVP, это, видимо, некоторая минимальная ценность, которую можно получить в результате развития этого проекта. И вот в чем, собственно, вы видите минимальную ценность, которую можно продемонстрировать, минимальная функциональность на основании достижения, которое можно будет сказать, что проект удался. И усилия тех людей, которые в него вложились или которые к нему присоединились, потрачены не напрасно. 

S03 [00:27:35]  : Но здесь, чтобы понять ответ на этот вопрос, нужно просто немножко знать предысторию, чем я занимался все это время. То есть вот Аджифа это, скажем так, достаточно проработанный проект, потому что это для меня лично устаревшая архитектура, то есть она уже давным-давно Я ее просто не реализовал в коде, но ее понимание я разработал давным-давно, много лет назад. И то, чем я сейчас занимаюсь, это уже следующий шаг после Аджифа. И, соответственно, здесь ценность какая будет. Если Аджифа будет реализован, в полном объеме, то это позволит решать очень многие задачи в области общего искусственного интеллекта, ну или не только в этой области, а вообще в области искусственного интеллекта. То есть там куча задач по распознаванию может успешно решаться, могут успешно решаться задачи по управлению роботами и целый другой, ну в общем очень большой список задач можно будет решить, если этот движок будет разработан до конца. И в качестве тестовых задач, просто мышь в лабиринте – это одна из простых задач, которая позволит проверить, как unit test, работает код, либо не работает, и насколько хорошо он работает. То есть требования по быстродействию там тоже достаточно оптимистичный, потому что он будет работать достаточно близко к реальному времени, либо вообще в реальном времени. Скорее всего, в реальном времени. Судя по самодостаточному интеллекту, в принципе, это можно достичь. а это уже по сравнению с текущими нейросетями это большой выигрыш в производительности и, соответственно, экономический эффект достаточно большой должен быть, потому что не придется покупать дорогостоящее железо, можно использовать обычные телефоны, обычные мобильные процессоры для того, чтобы создать какой-нибудь мощного робота, который полнофункциональный. Может доставку пиццы делать, открывать двери в подъезде, нажимать на кнопки в лифте и так далее. 

S07 [00:30:13]  : Ну а минимальный функционал вот этой мыши предполагается в виртуальной среде, то есть в той же Unity, да? 

S03 [00:30:21]  : Среда может быть даже еще более простая. То есть я же предлагаю начинать с самого простого 2D лабиринта. Но в принципе можно делать в любом игровом движке. То есть там тот же самый Unity позволяет делать и 2D-сцены, и 3D-сцены. То есть если сделать 2D-сцену в Unity, то точно так же потом можно её будет переключить в 3D-режим и уже в 3D-сцене работать. То есть там трудозатраты на переход в 3D минимальны. 

S07 [00:30:55]  : Спасибо. Ещё у Виктора есть вопрос. Насколько не очень понятно всё-таки по команде и по затратам. Я так понял, в команде есть один человек – это Вы. А по затратам, то, что Вы нам рассказывали в прошлые разы, насколько я понимаю, на чём основана концепция этого проекта. Есть понимание, сколько Вы вложили в это уже человека месяцев своего высококвалифицированного труда. с чего мы начинаем этот проект? 

S03 [00:31:28]  : ну это трудно вообще оценить, то есть архитектуру аджифа, скажем так, стоимость разработки аджифа это наверное лет 20 высококвалифицированного труда а сам код, который я туда постепенно выкладываю, ну это он к копейке по сравнению с этим стоит, потому что В принципе, я уже понимаю, как это все будет выглядеть. 

S07 [00:31:55]  : Основное это ноу-хау. Хорошо. Вот здесь вот еще Бадулин Николай рекомендует вам ознакомиться с компанией Pubcof Robotics и посмотреть какую-то учебную платформу. для технического зрения. Присоединяюсь к вопросу. У Игоря Пивоварова был вопрос, в чем здесь AGI. Игорь, вы удовлетворены объяснениями или хотите еще больше получить? 

S08 [00:32:32]  : я прошу прощения, я так и не доехал, пока мне не очень удобно говорить, но, в принципе, глобально тезис, что нет, я не понимаю, честно, в чем G.I. Но я могу даже сказать так, мышь живая, которая в лабиринте ищет сыр, но, безусловно, не обладает A.G.I. в нашем понимании, даже в том определении, Антона, который предавал в начале на первом слайде. решение широкого кругозадач в любых условиях адаптироваться и так далее. Даже в этом определении я не вижу, в чем здесь, честно говоря, тженность. 

S07 [00:33:08]  : Виктор, прокомментируйте. 

S03 [00:33:13]  : Тут нужно просто немножко разделять архитектуру проекта Adjif, которая в чистом виде является AGI, и задачи, которые могут быть решены при помощи этого проекта. То есть задачи, они могут быть на разном уровне сложности. И предполагается, что через некоторое время можно будет сами задачи доразвивать до максимально сложных, которые уже будут очевидно вписываться. высокого уровня. То есть там сама архитектура, она позволяет развитие до максимума. Соответственно, если задачи точно так же усложнять и постепенно как бы доводить до задач, например, не просто мышь в лабиринте, а, соответственно, уже операции, например, с кубиками, с буквами, со звуками и так далее. И, соответственно, вот это все можно доразвивать до самых сложных задач, в том числе, которые только люди могут решать. Вопрос только во времени. Сколько это времени займет развить сложную задачу? 

S07 [00:34:38]  : Спасибо. Два вопроса еще здесь. Игорь Пивоваров спрашивает, в чем суть модели? Дерево решений или что-то еще? И Дмитрий Салихов спрашивает, что посмотрел репозиторий, но там только заглушка. Соответственно, какая архитектура будет в основе обучения и когда она появится в коде? 

S03 [00:34:59]  : У меня же там лежит презентация, которую я две недели назад подробно рассказывал про нее. На эти вопросы, наверное, лучшим ответом будет просмотр семинара двухнедельной давности. 

S07 [00:35:16]  : Присоединяюсь. Да, Дмитрий, там Виктор достаточно подробно рассказывал. Единственное, Виктор, у меня, как и у Виктора Казаринова, возник вопрос все-таки формализации того, как вы описываете вот это дерево результатов и как работает ваш акцептор результата действия. То есть, несмотря на то, что там очень сложная математика, было бы интересно все равно на нее посмотреть. чтобы это не звучало голословно для некоторых дотошных товарищей, вроде нас с Виктором. 

S03 [00:35:45]  : Я думаю, что через какое-то время там появится код, который это все реализует, и можно будет в коде все посмотреть, все подробности. 

S07 [00:35:55]  : Так, теперь вот еще Бадулин Николай здесь кидает ссылки про разные беспилотники, которые, наверное, очень заинтересованы были бы в решении подобной задачи. Только вот у меня здесь очень серьезный комментарий. Я не думаю, что имеют какую-то ценность беспилотники, которые будут самообучаться вождению по городу тем методом, которые предлагает Виктор. Давя пешеходов, получая за это какие-то отрицательные подкрепления, получая положительные подкрепления, если ни один пешеход не задавлен, я думаю это не очень и вот как вопрос об экономической эффективности вот я как бы сомневаюсь что экономическая эффективность обучения робота вот таким вот образом данных на их ошибках она будет обязательно выше чем просто запрограммировать этого робота с учетом известного рельефа, с учетом известной структуры лабиринтов или городов, по которым будут эти машины перемещаться. Даже при всем недостатке программистов может быть дешевле один раз запрограммировать, чем иметь небольшой командой программистов, чем иметь кучу народа, которая будет этих роботов тренировать. Даже если одного робота натренировали, а его потом память перезагрузили в других роботов. Прокомментируйте, Виктор. Николай, давай Виктор ответит, потом вы. 

S03 [00:37:39]  : Здесь ответ достаточно простой лежит на поверхности потому что современные методы обучения они сначала происходят в виртуальной среде и потом уже обученная железка она переводится в реальный мир и какие-то уже Ну, фактически, если мы автопилот какой-то обучим в виртуальном городе, то в реальном городе он уже будет полностью обучен, ему там добучаться может и не потребуется. 

S07 [00:38:15]  : Согласен. Николай, пожалуйста. 

S04 [00:38:20]  : Николай? Да, я поясню, почему именно зимний город я упомянул. Там не надо давить пешеходов, это некий полигон. Под Дмитровым, если ты знаешь, там на МИП построили специализированную площадку. Так же, как под Саратором, сейчас создана для тестирования беспилотных систем. Соответственно, там ставится задача, которую команды со всей страны, это ГАЗ, это питерские ребята, ну там участвовало в этом конкурсе порядка 20 команд. И если, может быть, не решить всю задачу в целом, но можно поучаствовать в работе этой, Да, там определенные затраты, но это, как правило, пиар для региона, поэтому регионы это выделяют. У нас вот Томский кластер выделял деньги на участие этой команды. Она ничего там особого не получила, но благодаря тому, что она познакомилась со специалистами ГАЗа, КАМАЗа и других команд, которые в том числе выиграли, возможности трудоустройства резко увеличились, возможности коллаборации. Ну и если тебя пригласят как специалиста в ту команду, которая выиграет 200 миллионов рублей, ну ты получишь капитализацию. Спасибо. 

S07 [00:39:39]  : Спасибо. Еще есть комментарий от Николая Робчевского, актуальный, что у Патрика Хаммера, это основной разработчик проекта NARS, у него есть работающий прототип на основе смартфона, который уже делает то, что Виктор Артюхов собирается делать. Николай, у меня вам встречный вопрос. Вот я видел последнее видимо Патрика, но что-то там я не увидел езды по лабиринту. Он уже по лабиринту ездит? 

S02 [00:40:11]  : Ну, он, может быть, по лабиринту не ездит, но он исследует местность вокруг себя, прежде чем найти предметы там. Исследовать местность – это, в общем, примерно то же самое, что исследовать лабиринт. То есть я не вижу принципиальной разницы. Но главное тут не столько детали, сколько, как мне кажется, то, что это задача, которая сама по себе не может продемонстрировать никакого преимущества перед какими-то проектами, которые уже реализованы. У меня больше нет комментариев. 

S07 [00:41:02]  : Спасибо. У меня еще маленький комментарий у Евгения Витяева. в группе, к которой Евгений Евгеньевич сегодня еще подсоединится, возможно, в конце, есть решение задачи по обучению мыши в двумерном лабиринте по поиску сыра. Правда, там не лабиринт, там открытое пространство, но там мышь тоже учится находить сыр, причем она еще умеет рассказывать о своих находках окружающим мышам. Таким образом, все сообщества мышей коллективно учатся находить сыр быстрее. А во-вторых, в похожий парадигме на настоящих роботах в виртуальных и реальных средах работает группа Александра Панова, который делал у нас доклад на семинаре. В прошлом году есть запись этого семинара, и он там про это рассказывает. Если вам интересно, тоже можете с этим ознакомиться. Коллеги, еще есть к Виктору вопросы? Вот Максим Вишневский задает вопрос, почему Спикер называет архитектуру проект архитектурой AGI? Вот я этот вопрос не очень понял. Два раза на него отвечали. Вы, Максим, можете пояснить свой вопрос? В чем суть вопроса? Хорошо, давайте тогда двигаться дальше. Виктор, спасибо большое. Игорь Пивоваров, ты уже приехал? 

S08 [00:42:42]  : Нет, ты знаешь, к сожалению, еще не приехал. Если можно, мне еще через минут 20-30. 

S07 [00:42:47]  : Хорошо, тогда сейчас придется сделать следующее. У нас Олег Серебренников не явился по уважительной, я считаю, причине. Поэтому я попытаюсь про него рассказать. Подробности проекта рассказывать смысла нет, потому что проект память последовательностей Олег рассказывал. И я попытаюсь очень компактно рассказать перспективу с точки зрения своих вопросов. С моей точки зрения проект Олега Серебренникова «Память последовательностей». Виктор, можете убрать скриншеринг, чтобы он не отвлекал? Виктор, можно скриншеринг убрать? я вроде выключил нет да почему-то он стоит по-прежнему Хорошо, тем не менее, проект Олега Серебренникова посвящен одной конкретной части того, что в моем понимании можно считать архитектурой AGI. То есть AGI должен, с одной стороны, достигать целей, с другой стороны, он должен делать это эффективно, но для того, чтобы достигать целей, он должен находить способы достижения этих целей. А для того, чтобы находить способы достижения этих целей, он должен обладать предиктивной способностью. То есть, он должен иметь возможность предсказывать будущее как в зависимости от того ситуационного контекста, в котором этот агент находится, то есть мы наблюдаем изменения среды и должны понимать, иметь возможность предсказать, а куда эта среда движется дальше, что произойдет там в следующую минуту или в следующие сутки, с одной стороны. С другой стороны, мы должны иметь возможность предсказывать то, как на изменения среды повлияют наши действия. То есть, если я пну мяч, то что произойдет? У меня отвалится нога, или мяч полетит в ту сторону, куда я его пну, или произойдет что-то совсем другое, неожиданное. иметь возможность предсказывать, как на среду воздействуют мои собственные действия. С третьей стороны, я должен иметь возможность предсказывать то, как изменения в среде повлияют на какие-то мои целевые функции. Как, допустим, температура на улице повлияет на мою способность сохранять жизнеспособное состояние, и не умереть от ожлаждения. Таким образом, есть параметры самого агента, которыми он управляет, есть параметры среды, которую он воспринимает, и есть еще параметры агента, которые являются параметрами не среды, а его собственного я, который, собственно, связан напрямую с его целевыми функциями. Утолить чувство голода, утолить чувство жажды, утолить необходимость оставления потомства. Так вот, проект Олега Серебренникова «Память последовательности» в моем понимании сфокусирован на одну конкретную задачу – это предсказание. И в этом смысле он относится к AGI как некоторая часть AGI. Это вот ответ на первый вопрос. Почему инвестор захочет его вложиться? Попробую ответить за Олега. Надеюсь, я не сильно ошибусь. Для того, чтобы инвестору продемонстрировать какую-то ценность, ему нужно показать эту ценность в сравнении с какой-то ценностью про которые ему уже известно. То есть, если вы хотите получить деньги на дальнейшую разработку, вам нужно сказать, чем вы лучше конкурентов. Поскольку у нас в AGI конкурентов нет, в общем случае, поскольку никто не знает, что такое AGI, наверное, никто не знает, какие в AGI могут быть конкуренты. Постольку нам нечего предъявить в качестве конкурентов. Но у такой маленькой составной части, как предсказание, построение предсказательных моделей или предсказание последовательности каких-то действий, здесь достаточно. Есть хороший пример. Это пресловутый Мертв. или более пресловутый GPT, который умеет предсказывать последовательности. То есть, вы можете в него вбить последовательность слов, а он их будет прекрасно продолжать. Соответственно, если вы будете туда вбивать вместо слов какие-то другие объекты, имеющие функцию, являющиеся функцией времени, или меняющие свои состояния, или свой набор в зависимости от функции времени, вы будете предсказывать события, которые должны по идее следовать после этих последовательств. При этом известно огромное количество задач и огромное количество бенчмарков, которые достигают, решаются и достигаются с помощью BERT и GPT-3. Собственно, 50% всех публикаций, которые идут на сегодняшний день в машинленинге и, наверное, 90% всех публикаций, которые идут в НЛП, они в той или иной степени основаны либо на Берте, либо на ЖПТ-3. И при этом все прекрасно знают, что для этого нужны чудовищные вычлительные мощности. Я не помню, говорила я или нет, в какой-то момент, что задача, которая простыми средствами с не очень высоким качеством решается за час или за сутки простыми методами попарной взаимной информации на БЕРТЕ с чуть-чуть более высоким качеством считается за полтора месяца. Соответственно, если мы получаем решение, которое достигает ту же самую точность БЕРТ и ЖПТ-3, но с гораздо меньшими вычислительными ресурсами, За гораздо меньшее время, за гораздо меньшее деньги, за гораздо меньшим энергопотреблением мы вообще делаем революцию, потому что это дешевое решение. Можем действительно втыкать в мобильные телефоны, в микросхемы, в умные часы. И у нас вся мощность Берта иже ПТ-3 оказывается на кончике булавки. Тем более, что проект Олега предполагает именно аппаратную реализацию тех алгоритмов, которые он предлагает. Это вот почему инвестор захочет в него вложиться. Что уже сделано в деньгах я не знаю, но поданы заявки на патенты США. Вот один или два, я не знаю, как минимум одна заявка на патент есть, а подготовка заявки на американский патент это достаточно серьёзная работа, тем более что у Олега есть опыт прохождения и получения американских патентов и продажи их. крупным американским компаниям. Я бы сказал компаниям топ-5. Соответственно здесь очень есть большая интеллектуальная собственность в плане самой процедуры подготовки этих патентов как минимум. И прохождение вот этой патентной процедуры на западе. Ну и есть сам этот патент, который вот этот алгоритмический подход именно эффективного предсказания последовательности по сути решает. Если команда, я так понимаю на сегодняшний день это один Олег и ему как раз команда нужна и что нужно каких ресурсов, про это Олег писал в своем сообщении в группе, что ему нужен на каких-то либо партнерских, либо каких-то вменяемых финансовых условиях программист, который закодирует вот этот вот самый MVP, где MVP будет как раз предсказание последовательности, например, на тех же задачах, на которых достигает своих показателей BERT и GPT-3. Вот, собственно, все, что я попытался сказать за Олега. Если он вдруг пришел, он может меня поправить. Но я вижу, что он не пришел, поэтому я смотрю вопросы. Так, вопросы. Так, значит, вот, Виктор, ну, мне прочитать или вы прокомментируете голосом? Так, тогда зачитываю Виктора. Все так, да не совсем так. Я вам скажу, чем круты трансформеры. Они легко масштабируются на любые сферы и до обучения стоят дорого, но не супер. Ну, 50 тысяч рублей, ну, 100 тысяч рублей. Точность высокая. Но главное, что вам не надо делать отдельную разработку, которая стоит для каждой отрасли 300 тысяч рублей, 50 тысяч рублей, 3 миллиона и прочее. Суммы растут и скачут вверх очень быстро. Так что эта ваша архитектура должна быть масштабируемой. Ну, безусловно. То есть то, что архитектура должна быть масштабируемой, в этом никто не сомневается. И вопрос только в том, что она должна быть дешевой. Так, вопрос Игоря Пивоварова. В чем MVP у Олега? Насколько я понимаю, MVP у Олега заключаются в том, что мы получаем решение программное, как минимум. которая решает ряд задач, которые известно, что решает Берд. Например, те же самые предсказания последовательностей. То, на чем лучше всего заработал Берт, это просто продолжение последовательности по литературным корпусам. Но будет это делать с гораздо меньшими вычлительными ресурсами. То есть, грубо говоря, для тренировки на большом корпусе потребуется не полтора месяца, как у нас потребовалось, допустим, на Гутенберг-Чилдерне. а там, не знаю, хотя бы неделя или может быть сутки. То есть, это превышение именно вычислительной производительности, существенное превышение вычислительной производительности при сохранении качества бенчмарков в сравнении с GPT-3 и Burton. 

S08 [00:53:50]  : Это не МВП, ты говоришь про технологию, а МВП в чем? 

S07 [00:53:54]  : МВП? Опять-таки, мы тогда приходим к дискуссии о том, что такое МВП. Я понимаю МВП как некоторое решение, которое можно сказать, что вот оно есть, вот оно дает некоторую ценность, вот дайте мне денег, я сделаю еще круче. Я это так понимаю. Может быть, я не прав. вот и здесь как раз вот этой ценностью будет то что у нас есть аппаратная программное либо аппаратное решение Кстати, если вдруг кого-то это здесь заинтересует, Олег ищет... Николай, я вижу вашу руку. Олег, насколько я понимаю, ищет не только программистов, которые запрограммируют его систему, его алгоритмы и покажут их эффективность на тех же задачах, на которых показывается его эффективность. Олег также ищет тех, кто реализует это в железе. И на аппаратной реализации покажет то же самое, но уже в железе. Так, вопрос от Игоря. Так, есть готовая алгоритмическая часть, но она еще не реализована ни на каком языке программирования. Да, Игорь, вот ровно так и есть. То есть, есть не то, что алгоритмическая часть, есть патент. Ну, то есть, как минимум заявка на патент. И нужно эту алгоритмическую часть реализовать на каком-то языке программирования и прогнать ее на каких-то бенчмарках типа бертовых. Теперь, пожалуйста, Николай, ваша рука, а потом у Дмитрия вопрос будет. Так, Николай, вас не слышно. 

S02 [00:55:46]  : Да, по поводу этого проекта. Тут надо четко понимать один момент. Дело не в том, что пока это не реализовано программно. Дело в том, что когда мы реализуем это программно, совершенно не очевидно, что результат будет таким, как он ожидается. То есть, не очевидно то, что система сможет делать то, чего декларировано. То есть, на самом деле, это проект эксперимента, а не проект... имплементации чего-то, работоспособность чего-то доказана. 

S07 [00:56:45]  : Николай, спасибо. Я тут сейчас легко переобуюсь в воздухе и перепрыгну на другую сторону. На самом деле у меня тоже есть такие сомнения. И я помню эти сомнения Юрия Бабурова высказывал после обсуждения, после представления проекта Олега. А у Юрия Бабурова есть достаточно хорошее познание как раз именно в той области, на которую данный проект ориентирован. То есть, именно на превышение производительности пресловутого Берта. Теперь комментарий от Дмитрия Сайхова. Фишка Берта не в том, что он предсказывает последовательность, а в том, что он образует хорошее универсальное представление предложений, на базе которых решается куча НЛП задач. Как с этим у Олега с представлениями? Дмитрий, с одной стороны, я с вами не совсем соглашусь, потому что наш опыт использования Берта показал, что ничего хорошего он не делает. И никаких представлений полезных он нет. Потому что на тех имбедингах, которые он выучил, в течение нескольких месяцев мучений, мы с коллегами из Singularity.net смогли улучшить наши результаты полученные на гораздо более простых и гораздо более дешевых методах ну там я не помню то ли на пол процента то ли на один процент причем сказать вот там где-то от сорока шести процентов до сорока семи там или что-то в этом духе то есть ну не очень это все серьезно серьезно оказалось вот с одной стороны с другой стороны с универсальностью представлений как у Олега вот мне пока тоже не очевидно вот кстати значит тоже вот комментарий для Олега если он это будет смотреть записи значит я у него хотя проект называется иерархическая память последовательности вот то что касается памяти последовательности я увидел но иерархической составляющей. Я не увидел их, как я понял из комментариев Олега. Иерархическую чаще всего предстоит дорабатывать, причем не только программно, но и фундаментально. Игорь Пивоваров готов высказаться. Игорь, пожалуйста. 

S08 [00:59:07]  : Да, спасибо. Антон, сегодня у меня личный семинар в неожиданном формате. Я подумал, что я и не поеду, а просто в парк тут зашел, из парка поразговариваю, благо интернет хороший. Я вообще на этот семинар подписывался с тем, чтобы поговорить вообще про то, что такое MVP для AGI. я хочу сейчас три копейки вставить, пока еще не про свой проект, а вообще с размышлением, о чем мы говорим. Есть понятие технологии и есть понятие продукта. Допустим, BERT или память последовательности или дерево решений – это то, что мы называем технологией. некий способ построить модель, обучать ее и получать от нее результат. мы можем предполагать, что он там в то или ином применении будет хорошо работать, но заранее мы этого не знаем. в этом смысле память последовательности, которую Олег предлагает, это даже не технология, это идея технологии. но я знаю, что модель Шубского, которую мы там двигаем, она очень похожа. я якобы подробно не читал патенты и не сравнивал, но они, видимо, очень похожи с концепцией Олега Серебренникова. и это тоже в некотором смысле запоминание последовательностей. и я могу сказать, что что она давно запрограммирована. проблема там как раз не в запоминании последовательности, а в предсказывании новых последовательностей, на которые эта модель оказалась рассчитана хуже. поэтому совершенно не очевидно. я знаю достоверно, что когда будет реализован память последовательности в коде, она не выполнит то, что потому что мы с этим столкнулись уже два года назад. Она очень похожа. Но я сейчас не об этом. Технология – это одна из частей. Продукт – это когда мы берем технологию и заворачиваем ее в нечто, чем могут пользоваться другие люди. Например, одно из очевидных применений продуктовых для существующих моделей типа GPT-3 и BERT – это чат-бот. у нас есть чат-бот, мы хотим, чтобы он отвечал человеку. мы все знаем уровень продуктовости этой истории, что качество продукта пока низкое. в том смысле, что мы не видели пока ни одного бота, который бы отвечал нормально. но тем не менее, как продукт эта вещь некая понятная. и если посмотреть на продукт... что такое продукт чат-бот? это некая модель машинного обучения. во-первых, над ней некая API, которая скармливает тексты, а еще над ней некая API, допустим, к мессенджеру, к телеграмму, к чему угодно, которая позволяет подключать эту модель к мессенджеру, возможно, до обучателя каких-то тех, и так далее. В этом смысле продуктом является уже подключение, допустим, к мессенджеру. Но еще до этого можно было бы с этой моделью сделать MVP. Это минимальный размер. продукт минимального размера с очень существенными функциями, но уже демонстрирующий достаточную функциональность, чтобы поверить, что из этого можно сделать нормальный продукт. В случае Берта, допустим, это будет сам Берт у которого просто можно в текстовой строке вводить ему предложение, а он будет давать ответ без подключения к чат-боту, к чему угодно. Это еще технология, но она уже видно, что она будет работать как чат-бот. А, например, если мы скажем, давайте мы на базе BERT сделаем игру в Atari. я скажу нет, это пока еще, здесь нет MVP. Есть технология, а вы покажите, что она будет работать вот в таком продукте, как игра в Atari. И для MVP нужно будет ну хотя бы подцепить этого Берта хотя бы к какой-то одной игре в Atari и показать, что она хотя бы в одной игре, ну там, как-то прогрессирует, что не очевидно. Технология – это одно, а будет ли она жить в форме определенного продукта – это другое. поэтому вот что я видел сейчас первых двух как бы докладах нашего семинара первый докладчик на самом деле у него нет технологии у него продукт я до сих пор не понимаю технологии зато я вижу продукт страус которого значит там телеграмме показывают это как раз образец продукта когда как бы там ну, мне до конца не понятно, как устроен, значит, там, движок, но зато виден некий продукт. ценности этого продукта для меня, например, непонятно, поэтому, ну, я там прохожу мимо обычно, ну, страус, ну, что там делает. он делает нечто, что для меня не является MVP. мышь с сыром и лучший с точки зрения MVP, но это точно не MVP для AGI. это MVP для какой-то, ну там, я не знаю, для студенческой работы, которая человек занимается машленингом, допустим. ему хочется показать, что он достаточно освоил, я не знаю, что-то, куленинг, какие-то нейросетки, неважно что. у него есть алгоритм, но это точно не MVP для AGI. вот я здесь как бы меня этот семинар привлек как какой мысли а что является вообще mvp для и джей что может быть представимся что кто-то из нас сделал действительно там нет технологии вот например евгений генщитеев и есть технологии вот этих как бы символьного эти мыши сыром. Является ли это достаточным MVP, который бы показывал, что эта технология пригодна или, скажем так, перспективна, что на базе ее можно построить и джайв? Судя по всему, не является. Иначе бы, если являлась, то уже давно было бы сильно больше интереса к этой истории. Поэтому, во-первых, я предлагаю ясно разделить технологию MEP, технологию продуктов, понять, что сперва нужно представить некую технологию в нашем сообществе, мне кажется, для того, чтобы люди с тобой 

S07 [01:06:18]  : Игорь, по-моему, тебе надо отключить видео. Игорь, попробуй отключить видео. 

S08 [01:06:25]  : Игорь. Игорь, попробуй отключить видео. Как-то... Игорь. Представляю какую-то технологию того, что ты... делаешь в чем как бы в чем технологии а потом уже сказать ну и там а да извини извините да я слышу слышу я видимо далеко зашел а 

S07 [01:07:02]  : да я вернулся я вернулся вот мы тебя слушаем но лучше тебя да я возвращаюсь обратно сейчас да тебя сейчас слышно но видео лучше не включай сейчас слышно слышно слышно вот я я выключил видео и ну собственно я собственно я все 

S08 [01:07:23]  : и главное, нужно обсудить, что является вот этим самым MVP, который бы убедил людей, что некая модель, которая у тебя есть в руках или там у группы людей есть в руках, что она действительно способна претендовать на то, чтобы это был AGI. Мышь с сыром нет, не способна. 

S07 [01:07:51]  : Хорошо, Игорь, спасибо. Я на самом деле, с одной стороны, с тобой согласен, с другой стороны, я вот, например, не уверен, что Страус, для меня даже Страус не является MVP. И для меня даже память последовательности, играющая в Atari, не является MVP, потому что, с моей точки зрения, ценности от страуса, бродящего по Unity, никакой нет. То есть, в моем понимании, ценность именно MVP, как в классическом понимании MVP, когда это ценность для конечного потребителя, какого-то гипотетического потребителя, это если бы этот страус, к примеру, являл собой некоторый плагин, для, допустим, вставления в виртуальные миры, которые манипулярируются по определенным схемам. MVP давал бы определенное увеличение прибыльности онлайн-игр. К примеру, если бы мышь могла бы, действительно, как Виктор сказал, что его технология обучения роботов позволит сэкономить на программистах при обучении этих самых роботов. То есть, на самом деле, именно с точки зрения конкретной ценности для бизнеса, для инвестора, у мыши ценностей больше, чем у страуса. Поэтому тут еще вопрос о том, что является MVP. Это с одной точки зрения. Игорь, ты долго говорил, тебя никто не перебивал, давай я тоже договорю. С другой стороны, в моем понимании, можно сказать, вольная интерпретация MVP это некоторая демонстрация, действительно должна быть некоторая демонстрация технологии, где ценность будет в самой технологии. То есть, в моем понимании, в широком понимании VP, мы должны показать, что есть технология, которая позволит создать продукты, которые уже будут давать какую-то реальную ценность конкретным гипотетическим потребителям. То есть, с одной стороны, действительно есть два разных понимания MVP, условный MVP и технологический. реальный MVP бизнесовый, но граница между ними достаточно условная, как вот показывает пример наш с тобой, что я считаю Strauss не MVP, а мышь MVP, а ты наоборот. 

S08 [01:10:48]  : Антон, ну вообще-то термин MVP это очень конкретная определенная вещь в стартаперских кругах, как бы стартап на инвестиционных кругах. стартап должен продемонстрировать не технологию, а некий продукт, который ну там, за который условно, с которым можно пойти к пользователю и понять, пользователь готов за это платить денег или нет. В этом плане MVP предельно сформулированная вещь. Другой вопрос, когда мы говорим про MVP в применении к AGI. AGI это другая история, но мы просто используем этот термин как бы сами для себя, хотя это некорректно, мы должны это понимать, что это некорректно. Но вот смотри, я с тобой могу согласиться, что, например, мышь с сыром, как MVP, если позиционировать это не как AGI, а как, допустим, тип модели машинного обучения, которые способны управлять любыми роботами на складах, как это Виктор Носков написал, и они там будут условно доставлять любые товары. я бы тогда модель усложнил. модель не должна искать сыр, а условно, допустим, у тебя должны возникать в этом лабиринте лабиринт постоянен, а в нем возникает, например, в одном месте посылка, а в другом месте точка назначения. и модель должна постоянно Брать посылку, доносить его в место назначения и, скажем, минимизировать общее время. За какое-то время доставить максимум посылок, например. Тогда это может являться MVP для складского робота. Вполне себе. Для продукта складского робота. Но не для AGI. Я здесь не вижу опять-таки AGI. Это пока MVP. А что касается Strauss, то он вообще неубедительный как MVP. Допустим, я мог бы себе представить следующий вариант. Например, ты абсолютно правильно говоришь по поводу имплементации в виртуальных мирах. Давай себе представим, что это некая модель, которая может управлять движением, научиться и управлять движением любого существа. заранее неизвестно какого но вот в виртуальном мире условно люди создали игрушку и вместо того чтобы прописывать таким скриптами движение всех своих там существ этой игрушки они берут модель значит виктора и подсоединяет и она каждым этим существом за какое-то время учится сама управлять и дальше после этого они просто все там существует на базе управления вот этой модели когда мы понимаем что а это не только страус б это ну как бы движение в широком смысле и там какие-то абстрактные движения, ну как-то тогда это MBP будет для вот таких существ в животном мире. Неплохо, хотя опять-таки ЭДЖАИ, но я не очень понимаю в чем здесь ЭДЖАИ пока. ЭДЖАИ это решение широкого круга задач. Должны быть разные задачи. 

S07 [01:13:51]  : Хорошо. Игорь, я предлагаю нам сейчас вернуться в регламент. У нас закончилось время, отведенное на Олега Серебренникова. И итог данной дискуссии, я считаю, очень хорошо подвел Дмитрий Салихов своим комментарием, что мы не можем применять классическую трактовку MVP в этом случае. Вот, а сейчас я все-таки предлагаю вернуться к плану. Значит, Игорь, ты готов, так сказать, показать мастер-класс вот на том вопросе, на той теме, которую ты обозначил? 

S08 [01:14:25]  : Ну, насчет мастер-класса не знаю. Я-то в этот семинар, видишь, и шел как раз для того, чтобы поговорить про то, что такое… что может быть… Я могу просто высказать свою точку зрения. 

S07 [01:14:38]  : Ну вот смотри, ты предложил тему, я не помню, как сейчас уже звучит, универсальной системы, которая учится обучаться широкому кругу задач. 

S08 [01:14:50]  : Я, в принципе, с тобой согласился, но сделал немножко шире обобщение. 

S07 [01:14:57]  : сказать, вот именно структурировано вот по той сетке. 

S08 [01:15:01]  : давай попробуй тогда. я считаю, тезис первый, технология или модель, кусок кода или модель машинообучения, претендующая на то, чтобы вырасти в UJI, должна в первую очередь продемонстрировать возможность решения разного типа задач, но не перестраивая при этом критическим образом саму модель. И в этом плане сегодняшние модели, которые мы знаем, они заточены конкретно либо под текст, либо под компьютерное зрение, либо предпредиктивная аналитика. у них, допустим, трансформеры архитектурные есть и там и там, но, тем не менее, они заточены. В этом плане я рассматриваю нашу модель с Шумским, что это некая архитектура, которая потенциально способна решать широкий круг задач. Опять-таки, до конца неизвестно какой, пока мы все не попробуем, но достаточно большой. И в первую очередь потому, что ты говорил про модель Олега Серебряникова, что она способна анализировать происходящее и предсказывать, что будет дальше. И это тезис первый. Технология должна претендовать на решение широкого круга задач. подпункт к тезису первому. может быть, при этом она может обладать какими-то дополнительными бенефитами по отношению к нейросетям. например, быть более производительной, работать в реальном времени, есть меньше памяти и чего-то такое. хотя это мое мнение с точки зрения, вот если я шел бы к инвесторам с этим, это второе. это второстепенная вещь. с этим как с первым идти нельзя. грубо говоря, сделать то же самое, что делает берт, но там в реальном времени неинтересно. берт уже есть, он уже делает. все, точка. инвестировать никто не будет. поэтому это тот пункт. но главный пункт должен быть такой. модель должна решать широких задач. второй момент, второй пункт важный. нам этот тезис первый надо на чем-то продемонстрировать. и вот это как раз и является то, что мы условно называем MVP. то есть показать не настоящие GI во всем его мощи, а на каком-то классе задач показать, что эта модель учится и как-то их решает. достаточно, чтобы инвестор поверил, там инвестор или там широкий группа инвесторов, поверили в то, что действительно эта технология работоспособна, что технология работоспособна, а продукта еще пока не будет. И я для такой задачи пока для себя увидел, да, и тезис третий. Идеально бы это сделать на таком фреймворке, который будет являться общедоступным. в том смысле, что людям не нужно будет сомневаться в самом типе теста. я в этом смысле для себя, для второго-третьего пункта выбрал пока вот этот Open AI Gym, потому что это набор игр на Reinforcement Learning, разных игр, в которых мы не говорим прямо системе что нужно делать она не получает прямо информацию о том что происходит она как бы должна это как-то сама там извлекать из сложного потока событий и значит там как-то сама научиться но но прямо сказать что вот именно что именно на набор и рельных игр это является да, это MVP для, в моем понимании, минимальное для AGI, с которым я точно могу пойти к инвестору и отстаивать позицию, что да, это оно. но моя формулировка была просто чуть шире. если будет другой фреймворк, который позволяет решать широкий круг разных задач, но без больших затрат на подключение, типа OpenIG, потому что, насколько я помню, у фейсбука есть любопытный фреймворк. я просил Дмитрия Стрихова про него рассказать, но он очень коротко по нему на конференции рассказал. фреймворк, который позволяет агенту решать задачи в физическом мире. там прям сформулирован некий физический закон. разные, типа бросание предметов, попасть куда-то, или система блоков, или трамплин. какие-то, я сейчас не помню. fire.ai. да, наверное, fire.ai. вот, скажем, может быть, этот фрейворк тоже пригоден для вот я сейчас воюю с этим openai gym и пытаюсь с ним добиться. но могу еще поделиться своими последними соображениями по поводу опять-таки бипишности этой истории. кто-то, по-моему, Антон, даже ты говорил, не помню, кто-то в нашем семинаре говорил о Сергей Терехов говорил прекрасную фразу, которую ему сказал Виталий Львович Дунин-Барковский после одного из его докладов как раз про мышки лабиринте. Они тоже моделировали крысу в лабиринте. И Дунин-Барковский, это было много лет назад, ему сказал, что вы не понимаете, что крыса 90 процентов этой задачи уже умела решить, живая крыса, уже умеет решать до лабиринта. а в данном конкретном лабиринте она как бы условно доучивает недостающие 5-10% этого конкретного лабиринта, а все остальные навыки у нее уже были. А мы берем свои модели и как бы с нуля их учим в этом лабиринте. В этом плане мои последние размышления как раз о том, что человек, человеческое существо, которое пока для нас является вершиной мысли, точно не учится с полного нуля в абсолютно враждебной среде, которая все время стремится ему навредить, как это, допустим, делает моя модель сейчас в играх OpenAI Gym. Человек учится постепенно в очень дружелюбной среде, с родителями, которые постепенно помогают ему освоить сначала одни навыки, потом другие, потом третьи. то, что вот концепция curriculum learning, которая называется, мы это обсуждали вот два-три семинара назад. и в этом плане я бы сказал, что я пока не вижу ни одной среды, то есть если бы мы себе представили, что в OpenAI Gym было бы добавлено нечто для для изи старта, для более простого начала, для того чтобы какие-то вещи делать сперва попроще, а потом посложнее, то вот это возможно было бы совсем правильным фреймворком для иджайных моделей. потому что я бы сказал так, у нас пока нет ни одного доказательства, так сказать существование что что мы можем построить модели джайну не по пути которым там развивается человек потому что единственный интеллект как мы знаем это человечество человек учится вот как бы постепенно и вот над этим надо на самом деле подумать как как должна быть такая как должен быть такой и устроена со совместным усилием вот собственно все что я 

S07 [01:23:13]  : Игорь, спасибо. А можно для полноты, я на самом деле хочу чуть-чуть добавлю к тому, что ты сказал, но вот все-таки вопросы. Я правильно понимаю, что вы с Сергеем сейчас работаете вдвоем или у вас есть какая-то команда, которая этим занимается? 

S08 [01:23:34]  : у нас смотри мы Сергеем оба такие в общем я бы сказал так мы регулярно общаемся обмениваемся мыслями что получается что не получается и в этом плане обогащаем там продвижение но архитектура которую я делаю Сергея кажется слишком сложной и а он делает более простой вариант архитектуры, который объективно является проще. На мой взгляд, он не лишит всех прав. Я пояснил. Это память последовательности. Помните, у Олега это память последовательности. условно говоря, есть некий агент, который анализирует входящий поток данных и пытается сказать, что будет дальше. в модели Сергея таких агентов много, они все работают одновременно и иерархически. но в его классической модели это все происходит синхронно, как бы тактами. а в моей модели, которую я делаю, это все асинхронно и параллельно. каждый агент вообще никак не зависит от всех остальных, ничего не знает об их существовании и никак с ними не синхронизируется, а просто живет сам по себе. то, как, собственно, я думаю, происходит и в мозгу. я не думаю, что там есть какие-то единые импульсы, синхронизирующие все колонки, каждая колонка существует сама по себе, у меня есть вход-выход, она как бы генерирует. это на порядок сложнее, потому что там возникает куча всяких промежуточных сложностей. что касается команды, у нас есть человек, который помогает Сергею, есть двое даже, которые помогают. просто мне самому как программисту проще писать чем чем ставить задачу на поставку задачи уходит много мы видели наш семинар этот и ответы на него все понимают что коммуникация с программистом это время к сожалению, там много времени тратится на коммуникацию, все равно делает не всегда так, как нужно. это объективно. поэтому я почитаю проектировать сам до какого-то момента, когда эта модель не задышит достаточно, чтобы можно было ее переписать начисто в хорошем виде. пока я могу сказать, что вот у меня пока ситуация следующая. у меня лично Вот помните, я показывал на конференции вот эту модель. Она учится достаточно прилично, достаточно быстро доходит до примерно равных позиций с компьютером, и у меня компьютер дохнет на этом. Потому что структура памяти хранения, которую я использовал, некая красивая программистская идея, но она решительно рушит всю память. когда этот маркер размером станется 30 гиг, мой компьютер на этом ломается. а когда я попробовал переписать ее, чтобы она была незатратна по памяти, то я что-то потерял в ней. как раз вот и она теперь у меня там 20 тысяч игр играет, но она перестала учиться с такой... она учится, но она перестала так эффективно действовать. Вот это мои результаты последнего полугода. Я поэтому нахожусь в размышлениях, что я там, где я что там. С водой выплеснул ребенка, в общем, обидно. 

S07 [01:27:18]  : Ну и вам, как я понимаю, в этой ситуации ничего от сообщества и от инвесторов не нужно? 

S08 [01:27:27]  : То есть его самодостаточно? Не совсем. Этот кусочек технологии, который мы делаем, это часть большого проекта, который мы скоро хотим сообществу предложить. Например, Singularity.net. Singularity.net – это идея большого фреймворка, для которого то, что, собственно, сделал сам Бен Герцель, стало, ну там, кусочком этого большого фейерверка. Я, кстати, не знаю, как он развивает сейчас, сингулярить или нет, но, надеюсь, развивается. Что робот София, что, значит, там этот Atom, ну тогда еще не было Atom Space, потом был OpenCock, они стали, как бы, кусками этой большой экосистемы. нацелена которая претендует на то что в ней возникнет и джай я скептичен в этом смысле я не думаю что-то возникнет и джай по построению что это не произойдет но но как бы но мы шумским хотим предложить готовим сейчас вот эту тоже некую как бы модель системы целый большой который наш наш технологии станет кусочком некоторым этой общей системы и там точно будет это будет приложение для всех но оно будет просто мы хотим у вас там может быть не знаю может надо быстрее его обсуждать или там с большим кругом обсуждать в общем Мы не хотим обсуждать, я лично в частности, не хочу обсуждать в сыром виде, а хочу, чтобы оно было как-то более-менее сверстным. 

S07 [01:29:11]  : Спасибо. Мне кажется, Игорь достаточно полно ответил на все вопросы. Есть несколько комментариев у меня, у Олега Серебренникова и у Николая Рыбчевского, но у меня комментарии маленькие. Во-первых, кроме вот этого фейсбучного фриворка у OpenAI Gym есть еще Майнкрафт популярный в этом плане. А Майнкрафт на твой взгляд является MVP для AGI? 

S08 [01:29:38]  : В той же мере, в которой и OpenAI Gym. То есть это тоже виртуальная среда. 

S07 [01:29:53]  : Достаточно богатая, то есть это богатая среда, в которой можно учиться. 

S08 [01:30:00]  : если мы учим агента, который в майнкрафте, условно, побеждает, то это достаточный MVP с точки зрения IGI, да? 

S07 [01:30:07]  : ну вот нет, с точки зрения вот той позиции, которую ты обозначил и которую я полностью поддерживаю, то есть мы можем, так сказать, сделать это... можно делать на самом деле две команды, да, то есть можно делать команда, которая вот эту вот болванку будет побеждать этой болванкой в OpenAI Gym, а другая команда будет этой болванкой побеждать в Майнкрафте, а третья команда будет этой же болванкой побеждать в этом самом фейсбучном фреймворке, не помню его название. Ну, к примеру. То есть это примерно равнозначные вещи. 

S08 [01:30:40]  : Да-да, ну, пожалуй, я согласен, да. В Майнкрафте там же задачи каждый раз разные, там разные конфигурации, и в этом смысле они не однотипные. Ну, пожалуй, да. 

S07 [01:30:54]  : Второй комментарий, значит, относится к критике вот этого идеи, которая высказывалась в Телеграме, значит, там бы прозвучала критика, что это все не серьезно, потому что там нету мультимодальности. Так вот, я хочу возразить, что на самом деле мультимодальность может быть логическая, а мультимодальность может быть физическая. То есть, никто не мешает создать некоторую среду, в которой часть входа, которая физически будет одномодальная, то есть вся информация будет попадать на вход по одному каналу, но часть один, так сказать, фрейм этой информации будет, условно говоря, визуальный, другой будет, условно говоря, аудиальный. 

S08 [01:31:39]  : Или так верно? Верно. Слушай, а где нет мультимодальности? Критика чего? Нет, в Телеграме. В Телеграме вот тот подход. 

S07 [01:31:46]  : Критика чего? OpenEngine. То есть подход, основанный на OpenEngine, критиковался, потому что там все одномодальное. 

S08 [01:31:54]  : там ведь есть просто некоторый поток данных, не идентифицированный. я про это и говорю. да, да, мозг ведь тоже, ну как там критики говорят, что мозг это он сидит в темной коробке, в которой вообще нету никаких модальностей, есть просто входные, так сказать, сигналы и выходные. все, вот то же самое и здесь. OpenAI Gym в этом смысле такая вот просто какой-то поток сигналов откуда он взялся мы не знаем но откуда-то 

S07 [01:32:22]  : И последний комментарий насчет курикум-лёнинга. Мне кажется, Дима Салихов, если нас слышит, то это очень интересная тема. У нас как раз следующий семинар будет посвящен тестированию EGI. И в моем понимании как раз формализация вот этого курикум-лёнинга – это по сути будет формализация и прохождение бейби-тюринг-теста. Вот я надеюсь на следующем семинаре очередной раз рассказать, что такое baby-turing-тесты, как я его понимаю. Было бы очень хорошо, если бы Альберт Ефимов там тоже появился и рассказал бы свое видение этого. У него как раз защита диссертации на близкую тему. Но сейчас такого нет. Сейчас нет тестов нормальных, тем более стандартных, которые позволяют именно валидировать то, что вот некоторый субъект, начиная с какого-то нулевого уровня, постепенно улучшает свои способности в результате постепенного усложнения задачи. Примерно в том ключе, кстати, как Виктор рассказывал, когда мы постепенно отодвигаем сыр и убеждаемся, что мышь, значит, находит сыр каждый раз быстрее. Но это был мой последний комментарий. Олег Серебренников, пожалуйста. 

S06 [01:33:38]  : Добрый день. Я коротко тоже попытаюсь высказаться. Во-первых, Пивоваров сейчас упоминал, что повторение Берта не имеет никакого значения для МВП. Я бы здесь хотел вот что сказать. С одной стороны, это верно, но это в той же степени верно для начала. Для начала в той же степени верно, как решать задачки Open GM AI. То есть, ну решили вы, ну и многие решают. Вот. Есть отличия, правда, то есть вот умение решать задачек в Open GM AI, его монетизировать, наверное, как-то можно, но я вот сразу не вижу как. Наверное, вы знаете лучше. А задачу BERT, если ее делать на лету без большого комплекса компьютеров и не в сети, то есть не в облаке, а на локальном устройстве, допустим, с маленьким чипом, применение огромное количество может быть то есть эта штука она монетизируется потому что масштабность меняется всего этого дела и если у вас производительность вашей машинки позволяет вот из огромного там не знаю множество компьютеров группировки компьютеров вместо группировки компьютеров иметь маленький тип, то это принципиально меняет потребительскую ценность того, что вы предлагаете. Вместе с тем можно воспринимать повторение задачи BERT так же, как воспринимаем повторение задачи Open Gym AI, на которой мы тренируемся. Это первое. Второе. Поскольку я тут свое слово, к сожалению, пропустил, в этом моя вина, безусловно, но я тут, может быть, пару минут, тем не менее, займу. Моя модель, она математическая, то есть для всех, кто математики, сведущ, причем это линейная алгебра, по сути, то есть там не сверхматематика никакая, там уровень чуть ли не школы. Они все могут разобраться. Более того, из этой математики следует очень простая вещь. Во-первых, объектами могут быть любые объекты. Это могут быть фичи картинки, это могут быть слова текста, это могут быть фонемы звука, что угодно еще. Это моя машинка. Она просто берет на входе некие объекты, которые были распознаны существующими технологиями. Это могут быть или ансамбли, или последовательности объектов. И на основе этого она строит два множества объектов. Первый – это иерархию смыслов она строит в виде векторов. которые могут быть частью более больших векторов, вот в чем иерархия. И вторая она строит вектора прогнозов, а именно, как будет развиваться последовательность, то есть вероятное развитие последовательности, вот такой вектор. Он выражен тоже в тех же самых единицах, то есть в единицах объектов и, стало быть, тоже представляет из себя тоже вектор. То есть два типа векторов. Возвращаясь к тому, что сказал Игорь Пивоваров относительно Берта, еще раз с ним соглашусь, что будь то Open GM AI, будь то BERT, будь то еще, что-то, на чем мы тестируем машину. Говоря об AGI, нужно понятно объяснить, а что, собственно, такого вы видите, ну тот, кто представляет MVP, что он видит AGI в том, что он делает. Потому что, конечно, при том, что есть большая ценность, к примеру, в упаковке BERT в маленький чип, со спичечную головку. В этом безусловная ценность есть. Но если у этого чипа еще и есть некие свойства, которые присущи AGI, мы можем спорить или не спорить о том, что присущи, но предположим, мы сошлись в чем-то и мы говорим, что да, это действительно свойство AGI. Допустим, мультимодальность, о чем я сказал. или объяснимость и предсказуемость работы машинки, как в моем случае. Причем видно, что и прогнозы мы вектора строим, и иерархию смыслов тоже вектора мы строим. Если согласиться, что это IGI вещь, то, безусловно, у нас появляется с вами что? Есть некий MVP, который продемонстрировал присущие естественному интеллекту характеристики, в частности потребления по потреблению энергии и скорости вычислений. строительство прогнозов при создании прогнозов и при этом эта штука может быть мультимодальной и при этом она может еще что-то еще что-то а на первом этапе мы можем упаковать берд в спичечную головку вот собственно что с моей точки зрения должно убедить инвестора каким я тоже многократно бывал я был в шкуре инвестора и я бы думал именно так Я должен, а, заработать, но мне нужна перспектива. То есть я не откажусь от того, чтобы заработать в ближайшие 3-5 лет, безусловно. То есть я хочу вложиться и выйти, иметь возможность выйти, если что-то будет идти не так. Но с другой стороны, если есть огромные перспективы, получить единорога. Слушайте, ребята, безусловно, я на эту штуку подпишусь. Теперь о моем MVP. Мой MVP – это математика, которую сделать достаточно просто. Более того, сейчас я знаю, как ее сделать на полносвязных сетях. Тоже очень просто можно сделать. Сейчас я упаковываю эту историю. Собственно, трудоемкость этого небольшая, и я даже предлагал оплатить, если есть энтузиасты этого дела, я готов даже оплатить этот MVP для этих энтузиастов из нашей тусовки. Вот, собственно, с чем я пришел. Трудоемкость, как я думаю, в пределах месяца. Ну, наверное, все. 

S08 [01:40:03]  : Олег, а можно вопрос? Олег, а как вы будете показывать? Вот, предположим, вы написали свою модель, написали код, собрали команду. Вот у вас написана модель. Я пока не понимаю, в чем MVP. Математика реализована в коде, а MVP это нечто, что должно продемонстрировать, что эта модель выполняет задачи. На чем вы это будете показывать? 

S06 [01:40:32]  : Если у нас есть с вами код, предположим, мы выполнили математику, упаковали в код, вот этот код при определенной конфигурации будет повторять результаты, позволит повторять функциональность Берта, условно, он трансформер. И мы можем посмотреть, сравнить, допустим, вот у нас есть трансформер, и он потребляет сколько-то энергии. Здесь мы смотрим сколько. Мы можем посчитать, в частности, сколько, если мы увеличим точность предсказания до Бертовской, условно говоря, сколько он будет жрать в этом случае энергии. Дальше второй вопрос. На этой модели мы тоже можем показать, что, ребята, вот эту штуку можно упаковать вот в такой чип такого размера. Вот если это можно показать, две эти вещи, то, собственно, мы и доказали теорему, что в течение 3-5 лет при том, что мы не полные придурки, мы можем дать продукт, Который может, может, золотой дождь не золотой, но он по меньшей мере и цвет даст. Это первая история. Дальше нужно убедить, что это часть AGI. Об этом я говорил, но это более такая история, которая не про деньги, она про представление об AGI и о консенсусе в такого рода представлении. Ответил? 

S08 [01:41:57]  : Олег, я целиком согласен с вашей первой частью. Я понимаю, что MVP... вы слышали, я считаю, что это немножко спорно, но допустим, я согласен с тем, что BERT, воспроизведение функциональности BERT это вполне себе MVP и для какого-то круга задачи это вполне монетизируемая вещь, но BERT не является AGI, нисколько в моем понимании, прям вот ровно не является AGI, поэтому я не понимаю, как вот это MVP, чем оно продемонстрирует, что эта модель способна, что из нее способна вырасти GI. я специально разделил эти две вещи. 

S06 [01:42:38]  : я сказал, что есть BERT, который в той же степени хороший, как и Open GM AI, в отличие от Open GM AI, BERT позволяет при условиях, о которых я напомнил, значит, что это маленький чип, что это без облака, что он позволяет отжать денежки с рынка. Вот это разница между BERT, как способом доказать концепцию, и OpenGM AI, тоже способом доказать концепцию. Вот между ними и ровно эта разница. Что один способ доказать концепцию, он монетизируемый, а второй, я не знаю, как вы монетизируете, может быть, вы знаете, но я не представляю. И вот разница в этом. Но вот дальше, когда вы переходите к AGI, я это специально убрал в сторону и сказал, что А вот про AGI нужно говорить про мультимодальность. общность подходов, потому что я это могу доказать даже, что там общность подхода есть. Она прям вот правильная. Но для этого нужно, чтобы у того, кто слушает, было немного времени, полчаса – час. Вот и все. 

S07 [01:43:52]  : Спасибо. Николай, пожалуйста, вам слово. 

S02 [01:44:00]  : У меня по поводу того, о чём говорил Игорь Пивоваров, два момента. Первый – это когда мы говорим о использовании уже готового какого-то тестового инвайормента типа OpenGEM, то тут нужно понимать, что Если кто-то продемонстрировал свои возможности на Open Gym, то это не потому, что это хороший способ для всех, а потому что это хороший способ для того, кто смог там что-то продемонстрировать. То есть реально идеальным вариантом было бы продемонстрировать свои возможности на таком тесте, который другие выполнить не могут. А поскольку другие выполнить не могут, то и такого готового теста естественно нет. То есть идеальным вариантом было бы сделать свой тестовый environment, на котором Предлагаемые решения работали бы, а альтернативные известные другие не работали бы. Это сложнее, но мне кажется, что это гораздо более перспективный вариант. Ну и второй момент, это вот по поводу мультимодальности. Дело в том, что есть так сказать, понятие активного Active Sensing, которое означает то, что из очень-очень большого доступного потока и внешнего информации мы выбираем то, что нам полезно. И эта процедура одна из особенностей AGI, так сказать, по моему мнению. А когда мы приходим к тестовым environment типа OpenG или другим подобным, игровым там и так далее, то нам скармливают не очень большой поток информации, из которого, в общем-то, выбирать то, что нам нужно, не выглядит мультимодальностью. достаточно близким к тому, что делает человек. Поэтому мне кажется, что особенно в тех случаях, когда речь идет о визуальном внешней информации, все-таки мультимодальность лучше бы продемонстрировать на каких-то других примерах. Но это как бы что первое, что второе – это как-то благие пожелания. Как может получиться – это другой вопрос. Ну вот у меня всё. 

S07 [01:47:17]  : Спасибо, Николай. Так, и мы передаём слово следующему докладчику, то есть мне. Я про подробности своего проекта рассказывать не буду, потому что я про него рассказывал на одном из предыдущих семинаров. Сфокусируюсь на тех вопросах, которые были заявлены. Какое отношение пресловутый персональный ассистент или персональный референт имеет к AGI? И какое отношение конкретно мой персональный агент, или персональный референт, или персональный ассистент имеет EGI. Я в начале сегодняшнего разговора говорил о том, что EGI, пресловутый MVP, или нечто, что мы хотим продемонстрировать инвестору как некоторую минимальную ценность, может состоять из двух частей. Это, собственно, болванка. которую мы в широком наборе сред или в одной достаточно богатой среде чему-то учим. И, с другой стороны, это среда, которая как-то эту болванку облекает и направляет в неё какой-то поток информации, на который она учится реагировать. Так вот, мой проект посвящен в первую очередь созданию именно такой среды, для того, чтобы в рамках этой среды развивать вот эту самую болванку. У меня на сегодняшний день нету. У меня есть различные проекты. Проект, который я докладывал, показывал на OpenTalks, я с Пинфонгом. Проект Unsupervised Language Learning, которым я занимался в Singularity, нет. Это отдельная история, которую можно будет на следующем семинаре обсудить. Это вот как бы некоторые составные части вот этой вот болванки, связанные с одной стороны с обучением на ошибках, с другой стороны со структуризацией не структурированной информации. Но вот проект персонального ассистента, он основан именно на чем? В моем сегодняшнем видении, что мы Мы создаем некоторого агента, который в состоянии, с одной стороны, создавать вот эти потоки информации, богатую сенсорную среду некоторого будущего агента, который будет решать конкретные задачи конкретного пользователя по сбору информации, по поиску информации, по мониторингу интересующей информации, по фильтрации того контента, который приходит к пользователю со стороны и того контента, который исходит от человека наружу. С тем, чтобы в рамках этой среды на основе каких-то достаточно простых функций, реализованных не методами AGI, а какими-то более простыми методами показать с одной стороны ценность вот такого вот ассистента, а с другой стороны, постепенно усложняя и совершенствуя его начинку по различным направлениям с точки зрения структурирования информации, с точки зрения обучения на ошибках, постепенно двигаться в сторону ИЖА. То есть как бы у нас оболочка, которую мы предоставляем пользоваться, она сохраняется. Среда она сохраняется. Мы на основе какой-то простой действующей модели демонстрируем вот эту вот ценность для с одной стороны потенциального пользователя, с другой стороны для инвестора или партнера, с которым мы этот проект развиваем. И вот в рамках этой среды, в рамках этого набора функционала мы дальше совершенствуем качество исполнения этих функций, возможность самообучения, возможность построения более глубоких и более точных моделей. И тем самым ответ на вопрос, почему инвестор должен вложиться в эту модель, ответ такой, потому что мы действительно выполняем конкретные бизнес функции, конкретные бизнес задачи, которые могут стоять у большого числа людей. Что на сегодняшний день есть? На сегодняшний день есть проект с открытым кодом. который на MIT лицензии написанный, который с одной стороны позволяет мониторить потоки информации из примерно полутора десятков разных источников, включая социальные сети, RSS-фиды, HTML-страницы, мессенджеры и блокчейны. С другой стороны, он может выстраивать графы отношений между участниками этих коммуникаций, графы отношений между объектами, выявляемые в их текстах, определять сентимент положительно-отрицательный и мега-отрицательный в виде ненормативной лексики соответствующих оборотов. в соответствующих текстах. Он в состоянии мониторить информацию, формировать отчеты, структурированные отчеты по той информации, которая проходит по этим каналам за указанные промежутки времени, и давать человеку оповещение о определенных событиях, которые происходят в окружающей его среде. Команда на сегодняшний день в большей части состоит из одного меня, если не считать того, что иногда мне чуть-чуть помогают по конкретным вопросам эти студенты. Ну и ресурсы, которые требуются. С одной стороны, мне требуются контрибьюторы, которые готовы присоединиться к этому проекту и на условиях опенсорса. Использование этого проекта как опенсорса в своих проектах будут мне его помогать развивать. И сейчас, в частности, у меня один Американский студент работает и занимается как раз проблемой языкового интерфейса. И, с другой стороны, я ищу потенциального бизнес-партнера, который поможет именно тот функционал, который я предлагаю, и вот эту идею, которую я рассказал, донести до конкретного инвестора, который будет в это вложиться. Вот, собственно, все. Если есть вопросы, то... Алло. Так, я почему-то ничего не слышу. 

S02 [01:54:27]  : Ну, Антона слышно. 

S07 [01:54:29]  : Да. Все, да, хорошо. Вопросов нету. Соответственно, если вопросов нету, 

S01 [01:54:36]  : Алло. Да. Да, Виктор. У меня есть вопрос. Вот я уже опубликовал ссылочку на своего версию системы преобразования текста на различных языках до 14 языков в антологический граф антологии. Вот мой сервис там ссылку давал. в принципе ведь это же какой-то элемент который может оставаться с вашей системы. 

S07 [01:55:11]  : наверное да. наверное может быть. 

S01 [01:55:16]  : вот почему вы как-то это не упустили. я же давно над этим писал в телеграмме. 

S07 [01:55:24]  : Ну, если вы готовы свой проект строить в тот фреймворк, который у меня есть, то как бы welcome, что называется. То есть у меня код открыт, и если вы готовы свой проект строить в мою инфраструктуру, то двумя руками за. 

S01 [01:55:43]  : У меня большая часть тоже открытая. Она основывается на испанском фреймворке. Университета Каталонии, который именно речевой синтаксический анализатор. А моя часть это то, что степь космотологии идет верхнего уровня, который я все время отлдычу. И, соответственно, дальше мы можем, я могу пристегивать туда планировщики, которые принимают решения. Сейчас сделан анализ того, что может человек сообщить, и преобразование его в граф антологии. Это значит, что мы более глубоко начинаем понимать, что выразил пользователь. А дальше мы можем сделать вторую основную часть, а именно принять решение, поиск решения необходимого пользователю в соответствии с теми требованиями, которые вы сейчас только озвучили. Но он может это делать как раз на основе этой же онтологии, то есть более глубокого понимания контекстов общих задач. Вот такое моё предложение. 

S07 [01:57:01]  : Хорошо, я предлагаю нам с вами, чтобы не отвлекать всех, мы можем в рабочем порядке обменяться с ссылками на проекты. Я не помню ссылку на ваш проект в гитхабе, вы можете кинуть ее мне, я вам кину свой и посмотрим, где и как мы можем спрятаться. Спасибо. Так, ещё вопрос от Бадулина Николая. Николай, вопрос стандартный. Почему этот проект нужно развивать? Это ко мне вопрос? Я его не совсем понял. 

S04 [01:57:33]  : Если можно, я разверну. 

S07 [01:57:35]  : А, да, тогда, пожалуйста. 

S04 [01:57:37]  : Хотя у нас две минуты осталось, насколько я понимаю. 

S07 [01:57:40]  : Нет, у нас ещё 15 минут. 

S04 [01:57:42]  : Ну, постараюсь кратко. Дело в том, что у тебя нарисованы сетевые социальные сети. Их размерность E равно mc квадрат. Ну, peer-to-peer сети, у них размерность π в квадрате с коэффициентом m. По-разному люди понимают их, но это коэффициент общения. Вот я тебе, допустим, позвоню, ты возьмёшь трубку. А если мне кто-то звонит с неизвестного номера, возможно, я и не возьму. То есть вот эта перкаляция от единицы до нуля. Это и есть весовой коэффициент коммуникации. Но проблема вся в том, что энергия, которая появляется в такого рода взаимодействии, как наш семинар, она отрицательная. в сумме, потому что это просто коммуникации, которые приводят к некому осознанию, знанию каждого из конкретных коммуникаторов. Они теряют энергию, они теряют время, возможно, деньги. Но если ты посмотришь закон Мура, он же описывает как раз Google-системы, Яндекс-системы информационного типа. Это же не социальные коммуникации. Помнишь радио в советские годы? «По заявкам радиослушателя Иванова транслируем музыку». Это одноранговая информационная сеть. Там ответ, будет или нет, неизвестно. Пишите в «Спортлото», как говорили некоторые юмористы. Поэтому коммуникационный профиль там, энергетический профиль, Это E равно mc квадрат. Закон Мура. Закон сжатия. Вся информация в Гугле сжимается по закону E в степени t. Это разные типы сжатия. как ты умудряешься их соединять, сетевые профили и информационные профили. Потому что информационные профили дают тебе информацию, то есть ты сжимаешь данные и обезличиваешь их. А сетевой профиль совсем про другое. Он про управление социумом, политикой, Трампа избирать, Путина выявлять преступников, наркоманов и прочих киберпреступников, как в Казани было. Если бы через сетевые технологии выявили бы этого придурка, который пошёл убивать людей, школьников в Казани, тебе бы памятник поставили. У нас Евгений Гарин ровно этим занимается. Знаешь, наверное, Женю Гарина. Поэтому вопрос-то в этом. Потому что это два принципиально разных математических агрегационных состояния. Как ты умудряешься их сплачивать? 

S07 [02:00:35]  : Не, ну пока плохо, но как-то умудряюсь, скажем так. Но это опять-таки вопрос не про МВП, то есть если бы вот я вот сейчас вот тогда перейду к вопросам, я попробую ответить на твой вопрос ответами на другие вопросы. 

S04 [02:00:51]  : Ты можешь мне ответить, когда я приеду в Новосибирск. Хорошо, хорошо. 

S07 [02:00:57]  : Разверну то я тебе отвечу, когда мы увидимся в Новосибирске, а я сейчас попытаюсь тебе кратко ответить вот ответами на другие вопросы. Игорь Пивоваров пишет, что персональный референт – это не MVP, а полноценный продукт. Если бы Игорь был полноценным продуктом в части анализа социальных связей и взаимоотношений, если бы он решал ту задачу, которую сейчас обозначил Николай. Но поскольку он эту задачу пока решает не так хорошо, как обозначил Николай, то это не больше, чем MVP. Это вот один момент. Второй момент. Олег Култунов пишет, у Антона уже есть МВП и айдженты. Насколько это AGI вопрос открытый? Совершенно верно. Я уже сказал в начале, что мой проект относятся к AGI постольку, поскольку он предполагает в первую очередь оболочку той самой болванки, где AGI будет в болванке. Оболочка как бы есть, а дальше оболванку надо выращивать. У болванки там только какие-то зародыши. По определенным требованиям. По анализу неструктурированных объемов информации и текстов на естественном языке. И анализ социальных связей. Но это нужно совершенствовать. И именно поэтому, с точки зрения AGI, это не более чем MVP. То есть, мы показываем некоторые функции, которые мог бы выполнять AGI, но пока он их выполняет плохо. А когда он будет их выполнять хорошо, то это будет уже полноценный продукт. Так, теперь, Николай, мне пришло на ум, что твой продукт как МВП – это сжатие модели проведения сделок и голосования в блокчейн-системах. Но если мы возьмем социальную составляющую, то да, это как бы отдельная тема про… Не совсем так. Что-что? 

S04 [02:03:09]  : Нет, ты не совсем правильно меня понял. Антология сети – это триангуляционный сферический граф. Антология информационных сетей – это сотка. Это когда у тебя один узел с тремя контактируют, а онтология треангуляционного сетевого графа – это все коммуницируют со всем. И это главная проблема блокчейна при проведении сделок, потому что ты вынужден изменять данные во всей структуре вот этой матрицы, а комбинаторное число там гигантское. 

S07 [02:03:43]  : – Там есть хэш-графы, есть датчики. 

S04 [02:03:45]  : – Я понимаю. Ты с 12-го уровня улитки инноваций переходишь на 11-й и получаешь энергетически гораздо более простую модель принятия решений. Консенсус только по шести узлам, которые с тобой рядом контактируют. 

S07 [02:04:04]  : Это как раз суть репутационной системы, которая одна и составляет. Давай мы сейчас отдельно поговорим. У нас есть темы для разговора. Спасибо Николай Зах. Хорошие, подводящие вопросы. Слово Дмитрию Салихову, пожалуйста. Евгений Евгеньевич, потом вы… Коллеги, меня слышно? Да. 

S05 [02:04:31]  : Отлично. Вот у меня Игорь Пивоваров очень интересную тему затронул о том, что… А что такое, собственно, MVP в случае AGI вообще? Насколько сочетаются эти два слова между собой? Ну, во всяком случае, из его объяснения я не совсем понял все-таки, какой образ имеет в голове Игорь. Но все поняли, что это непростая какая-то штука, и надо бы это все дело осмыслить. И вот, собственно, мои пять копеек. Я как бы задумался. пока все говорили, и подумал о том, какие, собственно, могут быть наброски направлений. Давайте попробуем подумать вообще о первых принципах, чего мы хотим добиться в конечном итоге, создавая наши архитектуры. Понятно, мы хотим добиться AGI. Соответственно, если мы, допустим, берем AGI как конечную степень эволюции, последнюю фазу, если у нас это нечто уже присутствует в рабочем состоянии, то нам никакие MVP не нужны, никакие инвесторы не нужны. Мы можем сразу, собственно, прийти на рынок, устроить дизрапт большой и, собственно, перевернуть все индустрии. условно, если у нас есть какой-нибудь искусственный программист или искусственный бухгалтер, тут все понятно. Но достичь этого довольно-таки сложно. Идем фазу назад, предыдущая фаза. Как мне кажется, она должна называться даже не MVP, а прототип EGI. И именно на этой фазе, собственно, самые большие инвестиционные сделки-то и происходили. Вот так вот задумался. Тот же самый DeepMind поднял сколько-то там сотен миллионов. Потом еще недавно была у нас OpenAI, насколько я знаю, от Microsoft миллиард поднял. По-моему, GoodAI есть такая чешская контора, они тоже явно подняли денег. не совсем понятно на чём, потому что как такового именно прототипа я у них не увидел, хотя какие-то идейки там расписаны. Ну так вот, что такое прототип? На мой взгляд, прототип — это демонстрация некого маленького чуда, то есть показания такого результата, который раньше был вообще не достижим ничем, никак. что было DeepMind, они смогли поиграть в Atari игры. То есть до этого, конечно, были какие-то попытки, но они все были настолько слабы и настолько невыразительны, что это была просто хохма какая-то. А DeepMind пришел и сделал это, как говорится, human level и выше. И, собственно, чем Hasabis удивил Пейджи, например, убедился в том, что это прорывная технология, она ведет к AGI, к общему интеллекту, и, собственно, в итоге сделал эту сделку. OpenAI тоже показала некое чудо в виде GPT, которое стало генерировать а-ля смыслные тексты. Сейчас мы уже понимаем, что это, конечно, не AGI, хотя некоторые все еще какие-то, может быть, надежды питают на это, но тем не менее, все эти кейсы – это было показано некое маленькое чудо. Я считаю, что это некая такая стадия прототипа, которая уже довольно-таки легко и просто продается. Но если мы не можем достигнуть этой стадии, какими-то такими маленькими скромными силами. Вспомните, что у DeepMind, что у OpenAI были все-таки значительные ресурсы. Это были компании, а не какие-то там индивидуальные разработчики. У них там была какая-то длинная история перед этим, большой багаж, большой багаж академического бэкграунда и так далее. Так вот, если… еще фазу назад попробовать, то мне кажется, как раз это и есть MVP AGI. То есть это тогда получается еще не чудо, но некая демонстрация результата, который может быть, ну, скажем, достижим другими средствами. Допустим, мышь, которая ходит по лабиринту, да, это можно действительно сделать там с помощью Relic, классического, можно там какими-то еще технологиями, но если мы продемонстрируем технологию, которая имеет какой-то ноу-хау внутри, допустим, то есть мы достигаем какого-то интересного результата, но при этом совершенно каким-то нестандартным путем. Как я так понимаю, что у Виктора как раз это и есть. внутри его парадигмы, тогда это можно считать каким-то типа MVP. И потенциально это можно продать. Для этого, конечно, нужно, мне кажется, прежде всего обладать каким-то, не знаю, умением продавать просто. То есть технология сама за себя уже не говорит. А если ты обладаешь умением продаж, и у тебя есть там какой-то знакомый круг инвесторов, то, наверное, шансы на успех повышаются. Ну, собственно, вот это мои соображения того, что такое мог бы быть MVP. 

S07 [02:10:14]  : Дима, спасибо. У меня два очень коротких комментария. Во-первых, я предлагаю ввести в обиход понятие NVM – Minimum Viable Miracle, или Минимально Достижимое Чудо. Спасибо тебе за эту идею. Видимо, это правильная идея, потому что я еще приведу один пример, дополнение к твоим примерам. Есть еще компания Vicarious Systems, достаточно широко известная в узких кругах. которую возглавляет человек индийского происхождения по фамилии Джордж, забыл, как его зовут, который бывший первый главный ученый у Джеффа Хокинса. Но потом он у Джеффа Хокинса отделился и основал Vicarious Systems, и у них минимум Viable Miracle была демонстрация распознавания капчи. То есть, они сделали чудо, они добились каких-то бешеных, достигли прорыва в качестве распознавания разнообразных капч. Что само по себе продуктом не является, но является именно демонстрацией торжества технологии. Спасибо, Евгений Евгеньевич. Вы хотели высказаться. Так, Евгений Евгеньевич. Евгений Евгеньевич. Так, Евгений Евгеньевич, видимо, отошел. Ну, тогда Виктор Носков. Вы готовы высказаться? 

S09 [02:12:06]  : здравствуйте. а уже слышно? да, слышно. так, ну я не знаю, я очень коротко. мне кажется, я уже говорил на одном из семинаров про hacking face. есть такая компания. правда, здесь, к сожалению, нельзя увидеть фидбэк. я не знаю, знают ли большинство людей про hacking face или нет, но это топ-компания, которая работает по принципу open source, и она входила в списки топ-компаний, которые получили наибольшее количество лайков звездочек на гитхабе, там 46 тысяч лайков. что они делают? они оледеняют в себе множество трансформеров. этих трансформеров у них уже более 30, может быть уже 40 штук разнообразных архитектур, в том числе gpt-подобные, berta-подобные, там есть bart, там есть t5, то есть там есть многие такие слова, которые большинство людей не слышали, в основном все слышали про berta и gpt-3. но есть и другие, которые скейлятся на другие downstream задачи, downstream таски намного лучше, чем gpt. почему они так делают? почему они лучше работают? там есть фишки с энкодером-декодером, там есть смеси в барте, там лучшее взято и от gpt и от берта. такая вот есть модель. что это дает? в конечном итоге это дает, допустим, на архитектуре барта вы можете построить вопросно-ответную систему, которая как эксперт, экспертно, очень круто отвечает на очень сложные вопросы. Как отвечает эксперт на вопрос? Он отвечает, он дает некий короткий ответ, затем он подкрепляющий ответ со ссылками на какие-то фактические научные данные. Такой ответ все уважают, все говорят, что такой ответ является очень крутым. трансформеры, которые объединяют в себе лучшие качества других известных архитектур, можно получать очень крутые результаты. а что делает эта компания? почему она получила 40 миллионов долларов в раунде b? а год назад, в 2020 году, она получила 15 миллионов долларов, причем аги здесь вообще никакого нет. в чем фишка? она делает disruption с точки зрения простоты использования вот этих трансформеров. очень разные архитектуры. я бы сказал, что она дает некий инструмент разработчикам, программистам библиотека на бетоне. Она дает им инструмент, который позволяет намного легче и быстрее создавать различные продукты. То есть это в каком-то смысле, можно сказать, натянуто, наверное, но это инструмент, который в будущем станет способом платформы или вспомогательным фреймворком, который позволит разработать AGI системы. То есть АГИ внутри нет, там есть трансформеры, там есть большое количество вспомогательных вещей, токенизаторы есть и прочие-прочие вещи. Вы сейчас говорите, что там штука, которая строит энтологию. То есть там есть вот эти все многие-многие элементы. недавно туда добавили трансформеры, которые позволяют объединять мультимодальность. то есть они объединяют и текст, и изображение, анализ. и что делаем мы? в частности, я. у меня есть такая мысль, что можно делать такую же платформу, типа HackingFace, но ее демократизировать. Демократизировать, то есть делать интерфейсы простыми. Почему? Потому что HackingFace и многие другие, Databricks есть еще компания, тоже там много миллиардов стоит уже. Есть множество компаний, которые для разработчиков предоставляют различные фреймворки, однако обычные люди не способны ими пользоваться. Если сделать disruption вот в этой части, то есть заточить интерфейсы, сделать их очень простыми под базовые задачи, то что вам это дает? Вам это дает приток людей и приток данных от них, датасетов. Мы думаем, что мы сможем сделать вот это в каком плане? Если мы привлечем большое количество людей, которые смогут обучать внутри этой системы, естественно, платя за мощности, абонентскую плату и так далее, то мы привлечем большое количество датасетов, мы привлечем в том числе разработчиков, там будет часть неумеющие, то есть обычные люди, часть будет разработчики. Что они будут делать? Они будут делать эксперименты и смешивать модели, то есть они будут экспериментировать с архитектурами. И вот то, что я написал в фейсбуке, если кто-то видел, я написал, что для меня AGI, в плане анализа текста, Это такая штуковина, которая бы делала эмуляцию эмоций или саморефлексии. Я систем саморефлексии не видел ни одной. Таких систем нет вообще. Можно на старых технологиях сделать эту систему и тем самым, мы говорили здесь, что нам нужен proof of concept. То есть на старой системе можно сделать proof of concept, если привлечь большое количество людей, которые которым не надо платить. Они нам будут платить, а не мы им, за то, что они проведут эксперименты и, используя наши интерфейсы, достаточно простые, будут выкладывать эти модели. Какие-то они не будут выкладывать, какие-то будут. Но много будет моделей за счет демократизации в открытом доступе. Получается, это инструмент, который позволяет приблизить AGI с точки зрения инфраструктуры. И, возможно, тогда произойдет какой-то фазовый переход. Я думаю, он не сам, естественно, произойдет. То есть, само собой, что-либо не возникнет. Пока что здесь нет чего-то генетического, то есть такого развития. Но с точки зрения инвестиций, вообще должно заходить. То есть инвесторам вот такая штука должна заходить. Спасибо. 

S07 [02:18:21]  : Спасибо, Виктор. Евгений Евгеньевич, вы с нами? Да, я с вами. 

S10 [02:18:26]  : Пожалуйста. Ну, я уже как-то рассказывал, что я поручил студенту взять какую-то нейронную сеть и попробовать так промоделировать ее, чтобы получил слой ковероятности на нейронной сети. На самом деле я понимаю, что происходит в нейронной сети. Они являются очень хорошим аппроксиматором. И в пределе, когда они хорошо обучаются, они на самом деле находят максимально специфические вероятностные логические правила, которые теоретически максимально точны. Поэтому я могу провести более-менее параллель. максимально специфичными точными логиковероятностными правилами самой нейронной сети. Поэтому я предложил один из вариантов, как можно переделывать обычную нейронную сеть в логиковероятностную объяснимую нейронную сеть. И такой эксперимент я предложил провести моему студенту Владиславу. Дегтяреву, он такой эксперимент провел и получил действительно объяснимую нейронную сеть, работающую не хуже, чем нейронная сеть и, более того, другие аналогичные методы. То есть, он провел довольно полное сравнение и получил довольно хороший результат, в том числе и объяснимый результат. Вот теперь спрашивается, является ли это МВП или нет? На самом деле нет. С этого эксперимента только начинается на самом деле работа, потому что для того, чтобы получить МВП, для этого нужно создать некоторую технологию, то есть нужно создать такую технологию, что мы приходим к некоторому некоторую компанию, которая работает в нейронной сеть, прогнозирует, не знаю, выраженность или еще что-нибудь. Мы берем эту нейронную сеть, их нейронную сеть, берем те данные, на которых они обучились, берем ее себе, обучаемся, делаем логкие вероятности на нейронную сеть. Показано, что она работает ничуть не хуже, но в том числе объяснимо. Отдаем и вставляем туда, где она у них работает, свою логику вероятности нейронной сети, вместе с некоторым интерфейсом, который позволяет анализировать, что там происходит. Если она где-то дает сбои, то посмотреть, по каким правилам, на каких данных это правило получено, почему оно не совсем точное. понятной технологии, довольно точного анализа, как правило, как правило работает, что в совокупности происходит. Так вот, если разработать уже такую технологию замены существующей гендерной сети на выводе вероятностной, с не меньшей точностью, но с большей объяснимостью, вот это уже будет MVP. И его уже можно будет масштабировать по нейронным сетям с разными слоями, разного рода и так далее. С этого момента начинается масштабирование. Но сама монетизация и результат начинаются с этого, но для этого требуется довольно серьезная работа в создании такой технологии. Поэтому я, опять же, с точки зрения тех ученых, которые работают со студентами, тут нужен обязательно некоторый промежуточный этап, чтобы от экспериментов, интересных идей, тем не менее, получать MVP. Вот мой комментарий. 

S07 [02:21:49]  : Евгений Евгеньевич, спасибо. Владимир. Меня слышно? 

S00 [02:21:57]  : Да, да. Отлично. Ну, значит, я пока тут обсуждался, почитал, что такое MVP, потому что я не любитель ходить по бизнес-семинарам, для меня, в общем, это не новое. Но, конечно, я так понимаю, что большинство из нас тоже не ходят по этим семинарам, что все-таки это какой-то простой продукт, который позволяет вместо сложного продукта выяснить свойства, как сказать, что хочет потребитель от нас. Ну и то, что сегодня обсуждалось, конечно, к МВП имеет очень подственное отношение. Обсуждалось сегодня, на самом деле, вот у меня сложилось впечатление, что каждый из выступавших имеет некоторую идею, которую он верит, что она гениальная. Если ее развить, то есть приходите ко мне, работайте, моя идея разовьется, а почему бы ей не сделать прорыв? Никто из выступавших, особенно первый доклад показательный, никаких доказательств того, что эта идея гениальная, не дал. Просто говорит, ну а что где-нибудь гениальная? Будет гениальная, давайте разобьем. Безусловно, если он окажется прав, А совсем этого нельзя исключить. Другое дело, что он доказательств никаких не дает, но совсем исключить же нельзя. Вот. То, конечно, можно будет создавать и MVP продукты на основе некоторого гениального результата и, соответственно, и полные продукты, потом создавать и сильно искусственно, интеллектно в результате создать. Вот. Но, значит, прежде чем, как бы сказать, вот создавать MVP, нужно иметь действительно некоторую технологию, которая лучше других. Тогда на ее основе, может быть, построен некоторый МВП-продукт, на котором мы изучим, что, собственно, нужно потребителю от нашей хорошей технологии, которая лучше других. И, собственно, все выступавшие говорят о том, что давайте разовьем мою технологию, тогда вам покажут, какая она гениальна. Но вот этот этап, он, к сожалению, ни мной, ни с кем не спрашиваю, он непреодолён. И мы как бы в этом смысле, ну, не то чтобы все в одинаковых условиях, кто-то там больше занимается, у кого-то лучше, у кого-то хуже, но вот, к сожалению, значит... как, кстати, State of the Art, ну, в общем, мало кто в этом списке из нас находится, насколько я понимаю. Вот. Второй вопрос, что, значит, для IG мы все-таки далеко, то есть создавать MVP-продукт для IG, даже если у нас будет такая гениальная технология и кто-то из нас ее создаст, это достаточно сложно, потому что, значит, как бы сказать, Много есть разных аспектов создания сильного искусственного интеллекта. Основной наш недостаток, в том числе меня, состоит в том, что каждый предполагает, что его знания позволят решить все проблемы. То есть я про себя понимаю, что это не так. Но в душе, конечно, сидит такая вера, что есть же там глубокое понимание, которое там многолетним трудом создавалось. Но при этом есть же на основе этого понимания стоит в том, что один человек не может охватить все проблемы. Что если работать одному и пытаться решить все проблемы, то это совершенно безнадежный подход. Считает, что вот одна идея, неважно там моя, Виктора, Антона или кто-то еще, она решит все проблемы, ну в общем это некоторый волюнтаризм. Этого наверняка не будет. Проблема в том, что нужно все-таки попробовать отказаться от этой веры, что каждый из нас обладает абсолютным решением, которое решит все проблемы, а попытаться все-таки друг с другом обсуждать, на какие специализированные решения наши идеи могут быть направлены. МВП, конечно, пока эти специализированные решения не окажутся лучше других, все равно не получится. Нужно, чтобы оно было или дешевле, или производительнее, или лучше аппроксимацию давало, или какую-то масштабируемость давало бешеную. Тогда, конечно, вот эта технология, она себя проявит, ее можно будет продать, там будет ли это MVP, это нужно обсуждать, но вот это решение, его уже можно будет монетизировать. Хотя сейчас вот таким решением все-таки являются нейросети, и то, кто занимается их моделированием и компьютеризацией, собственно, к продажам наиболее близок. Опять, кто говорит о том, что это идеальный аппроксиматор, ну, видимо, он не совсем понимает, как работают на ресете. Аппроксиматор это очень плохой, так как паровые машины были очень плохими двигателями, но они работали. И на ресете также очень плохой аппроксиматор, но он работает. И это позволяет решать много разных задач уже сейчас. В принципе, можно их улучшать, делать еще, но как бы до MVP с новыми идеями пока что мы очень далеки. И важно, о чем я пытаюсь много раз говорить, понимать, что при движении КАГИ нужно понимать, что основная проблема — это сложность мира. То есть задачи-то разбиваются на очень простые. Улучшение аппроксимации, лионеризация, декомпозиция, иерархическая организация — вот эти проблемы надо решать. И чтобы в них реально продвигаться, и чтобы польза была не отрицательная от нашего общения, а положительная, нужно пытаться все-таки разделяться на решение вот этих проблем. И каждый, чтобы для себя попытался решить, в каких задачах он себя чувствует сильнее. Обсуждение некоторым кругом людей позволит там выделиться каким-то лидером, и в конкуренции всегда идет какой-то прогресс к решению задач. А если каждый будет сидеть со своей собственной идеей и ждать, что к нему подключатся те, кто оценит его глубокую гениальность, которую он пока никак не продемонстрировал, то, в общем, вот, как бы сказать, будет такое обсуждение, как сегодня. В принципе, я тоже много чего интересного для себя узнал, и другие, надеюсь, что-то узнали. Не хочу сказать, что оно совсем бесполезно. Оно полезное, но оно малоконструктивное. То есть нового мы, конечно, узнаем, общение все равно что-то приносит, вот. Но, значит, чтобы были, как бы сказать, коммерческие результаты, нужно чтобы мы, во-первых, усилили, сформировали специализацию, то есть не пытались решать по отдельности каждую всю проблему очень сложную в одиночку, а формировали какие-то группы по интересам и обсуждали какие-то узкие специализации. Ну, а второе, это, собственно, на основе конкуренции внутри этих групп все-таки попытаться показывать, что вот данная технология, которая там может быть таким путем выработана, что она, собственно, не когда-то в дальнейшем покажет, а уже сейчас дает какой-то результат, но вот тогда это, собственно, будет некоторым коммерческим продуктом, которое как MVP или каким-то другим путем, собственно, можно продавать. Вот, наверное, все в основном, что я хотел сказать. 

S07 [02:28:57]  : Владимир, большое спасибо. 

S00 [02:28:59]  : Я попытаюсь закончить на более позитивной ноте с отсылкой на замечательную мысль Дмитрия Салихова о том, что нужно не только верить в чудеса, 

S07 [02:29:22]  : как поется в песне, но им нужно делать чудеса. И, собственно, с точки зрения задачного подхода и теории функциональных систем, видимо, для наших акцепторов результата действия, образом результата этого действия является достижение некоторого чуда. Ну и в этом плане, мне кажется, все-таки обсуждение было полезное, потому что мне кажется, что мы обсуждали, в каком направлении нужно двигаться и какое именно чудо надо делать. И мне, например, было очень полезно получить некоторое понимание того, что, например, с Игорем Пивоваровым у нас примерно одно. понимание того, какого рода чудо должно возникнуть. И мы на самом деле этот разговор продолжим, то есть про то, как тестировать AGI мы будем говорить на следующем семинаре с Дмитрием Салиховым. И у нас направлений, в области которых делать чудеса, Еще, по-моему, штук 15 осталось, даже если сократить. Близкие темы тоже штук 5. Поэтому, видимо, на одном из очередных семинаров, может быть, даже через семинар мы еще пообсуждаем альтернативное направление для чудес. Коллеги, всем спасибо! Было очень интересно. До новой встречи! 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
