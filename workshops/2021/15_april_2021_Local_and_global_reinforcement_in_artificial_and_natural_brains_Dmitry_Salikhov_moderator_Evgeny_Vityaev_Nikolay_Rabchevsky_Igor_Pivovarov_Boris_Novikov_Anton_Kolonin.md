## 15 апреля 2021 - Локальное и глобальное подкрепление в искусственных и естественных мозгах — Дмитрий Салихов (модератор), Евгений Витяев, Николай Рабчевский, Игорь Пивоваров, Борис Новиков, Антон Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/0BFd8EjLyYk/hqdefault.jpg)](https://youtu.be/0BFd8EjLyYk)

Суммаризация семинара:

Семинар посвящён теме локального и глобального подкрепления в искусственных системах обучения. Основная идея заключается в том, что для эффективного обучения искусственных систем необходимо правильно настроить механизмы подкрепления, которые стимулируют систему к достижению определённых целей.

Теория функциональных систем:
Евгений Витяев представил модель, в которой мотивация системы выступает в роли запроса к блоку афферентного синтеза и принятия решений. Мотивационное возбуждение извлекается из памяти и проигрывается в виде различных способов достижения цели. Система анализирует возможные решения и, на основе вероятности достижения цели, выбирает оптимальный путь. Важной частью является интеграция теории функциональных систем и информационной теории эмоций Симонова.

Обсуждение проблем:
Участники обсуждали конкретные проблемы подкрепления, подчёркивая важность решения сложностей в этой области, а не сосредоточения на терминологии. Были высказаны замечания по поводу того, что в дискуссии преобладало обсуждение терминов, в то время как необходимо было быть более конкретными в решении проблем.

Исторический контекст:
Сергей, занимавшийся искусственными задачами с подкреплением 20 лет, отметил, что задачи, стоявшие 20 лет назад, касались нейродинамического программирования автономных агентов. Он подчеркнул, что задача управления коллективом участников, не понимающих управляющий сигнал учителя, сводилась к задаче design of reward, где необходимо было манипулировать агентами для достижения нужных результатов.

Архитектуры и реинфорсмент:
Николай, выступающий идеологическим противником реинфорсмента, представил архитектуру, в которой использовалась ассоциативное обучение для прогнозирования результатов действий и выбора оптимального действия на основе критериев полезности.

Цели и желания:
Евгений Витяев объяснил, что цель в его архитектуре может быть любым желанием, например, желанием новизны. Критерии удовлетворения желания позволяют системе достигать цели.

Общая теория создания и интеллект:
Борис Новиков обсудил общую теорию создания и роль интеллекта в сознании, подчеркнув, что интеллект должен быть встроен в картину мира и способен определять, что возможно и что нет.

Выводы и итоги:
Семинар показал, что вопросы подкрепления и обучения искусственных систем остаются открытыми и требуют дальнейшего изучения. Участники обсудили различные подходы и архитектуры, подчёркивая важность понимания механизмов подкрепления и их влияния на обучение.




S01 [00:00:02]  : И убеждаемся, что все у нас заработало. Да. Лайфскрин у нас заработал. Соответственно предлагаю начать наше сегодняшнее заседание Клуба любителей AGI. Я тогда расшариваю экран, возьму небольшое вступительное слово, обозначу повестку и вопросы, заодно выскажусь по теме, а потом передаю слово Дмитрию Салихову, чтобы он провёл сегодняшнее мероприятие. Итак, возникла идея поговорить о том, что я назвал, может быть не очень корректно, но назвал локальным и глобальным подкреплением. О чем здесь идет речь? Речь идет о том, что на самом деле в книжке у Марвина Минского называется Global and Local Reward. где он рассуждает о том, что если мы строим искусственный интеллект или изучаем естественный интеллект, то есть там Минский же пишет не обязательно про искусственный интеллект, Минский пытается понять природу интеллекта вообще, где искусственный интеллект это частный случай, вот и рассматривает его с точки зрения многоагентной парадигмы, где мы мозг можем, или сознание, или разум, или интеллект можем рассматривать как взаимодействие независимых агентов, каждый из которых решают задачу на своем уровне компетентности. Если мы, например, рассмотрим такую многоагентную систему в организации, где у нас есть менеджер, который занимается координацией на высоком уровне, есть руководители компании, Под ним есть менеджеры, которые в своих областях компетенции решают какие-то задачи, у менеджеров есть подчиненные, которые делают что-то в конечном итоге, то у нас часто возникают задачи, когда нужно распределить работу. То есть у нас менеджер верхнего или руководитель верхнего уровня выдает какую-то задачу, его как-то понимают менеджеры среднего уровня и дальше ставят задачу своим подчиненным. И типичной ситуацией является, когда подчиненный выполняет, например, задачу очень хорошо с точки зрения менеджера среднего уровня, но задача поставлена неверно. То есть, менеджер среднего уровня мог неправильно понять задачу, которую ему поставил руководитель верхнего уровня. И тогда возникает интересная ситуация, что после того, как исполнитель выполнил правильную задачу, получив понятные ему указания от менеджера среднего уровня, в итоге задачи, поставленные высшим руководством, не выполнены. В итоге компания или организация получает негативный эффект, например. И в этой ситуации возникает дилемма. Что нужно делать с тем рабочим, который выполнил задачу среднего менеджера? Нужно ли нам поощрять этого рабочего или нет? С точки зрения локального подкрепления его нужно поощрить, потому что он выполнил задачу в соответствии с тем, как она была поставлена временно и четко. Либо руководитель, либо менеджер среднего уровня, которые либо плохо сформировали задачу, либо плохо ее поняли, они должны быть наказаны, потому что они не смогли правильно донести то, что нужно делать внизу. Это концепция локального. подкрепления, а есть понимание командной ответственности. Когда мы рассматриваем их всех как команду, если в целом команда отработала неправильно, то нужно наказывать всю команду, в том числе даже тех исполнителей, которые отработали верно. Ну вот так вот примерно Марвин Минский рассуждает на тему того, что он называет ревард. Но когда мы переводим слово ревард на русский, это переводится как награда. А ведь не обязательно же подкрепление может быть положительным. Оно может быть и отрицательным. И поэтому я в заглавии семинара вынес тему именно фидбэк, когда речь идет все-таки о подкрепление или обратной связи, которая может быть как положительная, так и отрицательная. Но если в системе есть много элементов, то в случае того, когда мы говорим о локальном подкреплении или локальной обратной связи, мы говорим о том, что два компонента внутри системы Или ограниченное число компонентов внутри системы решают какую-то задачу, ставят между собой, один ставит задачу другому, а другой выполняет. И они подкрепляют внутри своего внутреннего контура, командного или управляющего, подкрепляют один другого. Это мы называем локальным подкреплением или локальной обратной связью. А глобальное подкрепление или глобальная обратная связь – это когда мы рассматриваем всю систему в целом и подкрепляем ее в целом. Причем в данном случае мы можем даже не обязательно говорить про множество агентов. Мы можем говорить про одного агента. но который выполняет одну многошаговую задачу и здесь тоже возникает похожая проблема и вот в ссылках которые я кидал значит как раз дискуссии в telegram там как раз эти определения про global and local Ревард и Global and Local Feedback в немножко разных словах, но примерно одинаково разъясняются. То есть, на самом деле мы можем подкреплять по каждому отдельному шагу, если каждый следующий шаг у нас успешно выполнен. то мы подкрепляем результат каждого правильно сделанного шага. Но если каждый правильно сделанный шаг в итоге нас ведет к неверной цели, то это локальное подкрепление ни к чему не приведет. И тогда надо подкреплять не каждый отдельно правильно сделанный шаг, а общее достижение общей цели. И в этой ситуации, если мы можем сформировать механизм, когда мы подкрепляем всю последовательность шагов, которая привела к нужному результату, то нам каждый отдельный шаг подкреплять не нужно, потому что каждый отдельный, какой-то из отдельных шагов на самом деле может быть ошибочный, а может быть даже какой-то из отдельных шагов будет ошибочный, но тем не менее все равно результат будет полезный. Ну и вот, собственно, вопросы теперь, которые возникли в процессе подготовки обсуждения. Один из вопросов, который добавили в конце, то есть в начале его не было, но он мне показался важным. То есть, вообще, когда мы говорим о эволюции с точки зрения кибернетической перспективы, и когда мы говорим об определении AGI, когда у нас вообще появляется AGI? То есть, можно ли считать кошку, обладающую в какой-то небольшой степени AGI, а можно ли считать клетку, обладающую в какой-то совсем мизерной степени AGI? Вот. И если мы вот с этой позиции пытаемся смотреть, то возникает вопрос, а вообще что такое феномен подкрепления? На каком этапе появляется подкрепление? И вот там в конце последний вопрос будет от Михаила Вишневского. Если я его правильно понял, то вообще следует рассматривать подкрепление как феномен Не только индивидуальный характерный для интеллекта человеческого уровня, а и вообще социальный феномен, что подкрепление на самом деле определяется социо-культурными факторами. Если Максим здесь, может быть он эту тему раскроет, свой вопрос. в обсуждении более конкретно. Итак, когда вообще на этапе эволюции живой и неживой материи мы можем начинать говорить про это подкрепление? Первый вопрос, который хотелось бы, ответы на которые хотелось бы услышать. Дальше. Какие виды подкрепления есть? Какие из них важны? Какие вторичные? Ну вот здесь я грубо попытался задать сетку. Что у нас подкрепление может быть либо локальное, условно, когда оно между двумя агентами, или двумя шагами, в одной последовательности шагов, или в одной исполнительной многоагентной схеме. Возникает, если это между двумя агентами, это абсолютно локально. Если награждается в целом последовательность шагов или вся компания мультиагентная, вся система мультиагентная, это глобально. Но, очевидно, могут быть какие-то промежуточные формы. Дальше. Есть положительное подкрепление, есть отрицательное. Есть метод кнута, есть метод пряника. Какие нужны, какие важны, какие вторичны, какие нам нужно использовать при создании искусственного интеллекта, какие нет. Ну и опять-таки дальше возникает вопрос, как эти виды подкрепления могут реализовываться в кибернетических системах искусственных и как они работают на уровне живой материи. Соответственно, следующий вопрос, что если… Третий. Нужно ли… Так, а мой экран видно или нет? Что-то говорю, говорю. Соответственно, третий вопрос. Если мы понимаем, какие виды подкрепления есть в живой материи, нужно ли нам, идя по пути нейроморфного моделирования, воспроизводить те же методы подкрепления в системах искусственного интеллекта? А следующий вопрос. Вот пресловутое глобальное подкрепление, про которое я говорю. Нужно ли оно вообще или нет? Насколько я понимаю, все системы обучения с подкреплением типа Deep Cullioning, они работают на сегодняшний день по схеме глобального подкрепления. То есть, мы в алгоритме Cullioning постепенно распространяем подкрепление от последнего шага к предыдущим шагам. И именно поэтому Q-Learning происходит достаточно медленно, потому что нам нужно очень много повторений, чтобы подкрепление, полученное при достижении цели, дошло до начальной цепочки шагов. А в том алгоритме, который я рассказывал на OpenTox, там как раз наоборот, там чисто глобальное подкрепление, потому что я подкрепляю только ту последовательность действий, которая привела в конечном итоге к результату, но возникает проблема, когда у нас подкрепление оказывается слишком далеко, очень трудно, очень долго уходит на то, чтобы выявить эту магическую ситуацию. Хотя как только она выявлена, сразу же становится все хорошо. Нужно ли комбинировать положительное или отрицательное подкрепление? Философская проблема дрессировщиков и родителей. Нужно ли и кнутом, и пряником воспитывать, или только кнутом, или только пряником? Или на разных этапах воспитательного и образовательного процесса нужно использовать кнуты и пряники, или использовать их в какой-то пропорции? Ну или в зависимости от ситуации. Какие-то ситуации достаточно пряников, какие-то нужно и вкнуто дело пускать. Шестой вопрос – backpropagation. Соответственно, является ли у нас backpropagation адекватным подкреплением, или это вот такой костыль, который только всё портит, потому что ничего лучше его не придумали. Соответственно, можем ли мы без него обойтись, или всё равно в каких-то случаях его можно и нужно использовать. Просто, может быть, нужно его как-то делать правильнее и придумывать что-то ещё. Вопрос, собственно, как раз на злобу дня. Что делать, когда нам нужно учить сложные поведенческие схемы и когда поведение, подкрепление возникает в конце? То есть мы, например, учимся играть в пресловутый пинг-понг. И выигрываем мы не тогда, когда... То есть подкрепление получается не в момент отбития шарика, а только в тот момент, когда мы выиграли игру. А пока мы первую игру не выиграли, мы вообще не знаем, отбитие шарика, оно приводит к поражению или проигрышу. Ну представьте себе, что мы научимся играть в шашки, Вот, не зная того, значит, нужно нам рубить или поддаваться. Вот, и узнаем об итогах игры только когда нам сказали, играли ли мы в поддавки или в шашки. Вот, обучиться, наверное, будет достаточно трудно. То есть, все-таки, наверное, если мы хотим научиться играть либо в поддавки, либо в шашки, надо заранее говорить, играем ли мы в поддавки, либо в шашки, и наказывать или награждать за удачно съеденную или подставленную шашку. Дальше вот то голосование, которое было организовано в фейсбуке, Олег Култунов его в русскую группу тоже недавно перенес. Какие мы можем придумывать фокусы для того, чтобы обучаться на тех реальных жизненных ситуациях. когда обучение наступает поздно, когда мы не можем от окружающей среды получить подкрепление в последний момент. То есть нужно ли нам придумывать какие-то методы, которые нам будут позволять самоподкрепляться, то есть нам или системе, которую мы делаем. самоподкрепляться по ходу того, как она пытается найти нужное решение. Например, с Олегом Серебряником мы много этот вопрос обсуждали. Там был такой дискурс у нас, что если мы учимся играть в пинг-понг, то прежде чем мы начнем пытаться отбивать мяч ракеткой, нам вообще нужно бы научиться управлять ракеткой. Мы должны для начала хотя бы научиться тому, что движение руки вправо приводит к движению ракетки вправо, а движение руки влево приводит к движению ракетки влево. А для этого нам нужно забыть про шарик, смотреть только на ракетку, и пытаться коррелировать то, как наша моторика связывается с тем, что мы получаем от наших органов зрения на предмет их взаимообусловленности. И тогда получается, что если мы увеличиваем предсказуемость нашего поведения одновременно с модификацией этого поведения и модификацией наших предсказующих моделей, то есть, если мы Подбираем такую модель мира и такие движения, такие действия в отношении этого мира, что любое наше действие приводит к беспредсказуемым последствиям. То есть, если мы сформировали такую модель, что движение руки влево предсказывает движение ракетки влево, на движение в руки вправо, она предсказывает движение ракетки вправо, то мы уже построили некоторую предсказуемую модель реальности и некоторые способы поведения в этой реальности. То есть мы уже умеем изменять окружающую реальность в виде вот этой вот ракетки, которую мы держим в руке. И после этого мы уже можем обратить внимание на шарик и пытаться Уже зная то, как обращаться с ракеткой, попытаться теперь еще и изменять поведение шарика за счет отражения от ракетки. А уже когда мы научимся отбивать шарик, мы уже можем попытаться играть на счет. Собственно, как и... учат детей в пинг-понг. Ну и последний вопрос. Вот здесь вот задан вопрос, как я его понял. Внизу написано, как его сформулировал в фейсбуке Максим Вишневский. Если я правильно понял, мысль заключалась в том, что на самом деле Явление подкрепления у человека и животных – это не чисто физиологический феномен, то есть бессмысленно говорить о нем с точки зрения того, что у нас там происходит с нейронами или с медиаторами, а нужно всё-таки рассматривать культурно-социальный контекст, какие задачи мы решаем. Для чего мы их решаем? Какие цели мы ставим? Как эти цели вообще вписываются в жизненную траекторию человека и социума? Ну и когда я над этим размышлял, у меня вообще возникли интересные вопросы, которые уже выходят за рамки дискуссии. Я заканчиваю. Что вообще можно ли ставить вопрос о том, что то, что мы называем AGI, вообще не способна возникнуть у автономного живого существа, даже обладающего высшей нервной системой, будь то обезьяна, животное, слон, кит, дельфин или даже человек. То есть, можем ли мы вообще сказать, что мальчик Маугли, который вырос в лесу один и не может потом уже научиться говорить, можем ли мы говорить, что этот мальчик не только говорить не может научиться после того, как он потерял возможность адаптации в обществе, будучи оторван от этого общества на ранних годах своей жизни, можем ли мы говорить, что он вообще никакой высокоуровня когнитивной активности не может обучиться, и, соответственно, интеллектом он вообще не обладает? То есть, можем ли мы в этом смысле говорить, что интеллект уровня AGI, то есть, уровня который позволяет обучаться высокоуровневым задачам и разным задачам и эффективно оптимизировать свое взаимодействие с окружающей средой. Можем мы говорить, что эта возможность появляется не в момент рождения человека или примата, а только в тот момент, когда этот примат или этот человек пройдет некоторое взаимодействие с культурно-социальной средой, получит от нее некоторые навыки, некоторые когнитивные способности, которые реализуются в том биологическом потенциале, который возник в момент рождения на основе генетического материала, переданного от родителей ребенку. Ну вот, собственно, все, что я хотел сказать и пояснить по поводу вопросов. И дальше передаю слово Дмитрию. 

S07 [00:18:25]  : Да, у тебя такой полноценный практически по времени доклад получился, с учетом того, что на всех по 15-20 минут получается. Ну, в общем, ладно. Если честно, я прошу прощения, у меня перерывы с интернетом, я поэтому с телефоном. Если честно, я не думаю, что все спикеры будут вести линию, вот как ты обозначил прямо, локальная vs. глобальная, потому что вот я, например, в своей архитектуре не дошел еще до этой дихотомии, и у меня немножко другие вопросы, надо было тоже их сюда дописать, но ладно. Поэтому я думаю, что это будет немножко шире, чем ты обозначил. Все равно рамочная тема reinforcement learning. Я, наверное, перед началом дам маленькую историческую справку, чтобы все, кто со стороны, кто с reinforcement learning не сильно дружит, расскажу, почему вообще мне такое внимание и зачем оно нужно. Это обучение с подкреплением, в общем-то, возникло как альтернатива обучению с учителем, потому что невозможно присвоить метки всему на свете, особенно когда речь идет о агентах, которые должны действовать в каких-то средах. Вот так появился reinforcement learning. Если посмотреть на игру ping-pong, которую Антон должен был показать, но не показал, Наверняка теоретически можно обучить классификатор, который на входе будет иметь текущее положение ракетки, положение мячика, а на выходе будет предсказывать движение ракетки. Но мы понимаем, что это не очень практично, и лучше наш пинг-понг будет учиться от сигналов обратной связи. Если мячик попал в ракетку, то положительный сигнал не попал, значит отрицательный. И тут получается два преимущества сразу. не надо делать ручную разметку, и мы знаем тому же, что живые организмы так и учатся. Значит, скорее всего, это перспективно, как минимум. Ну, вы знаете, да, дрессировка животных. Встал на задние лапки, получил сахар, подкрепление пришло в мозг, создался условный рефлекс, то же самое, реинфорсмент получается. Но если бы все было так просто, мы бы тут, конечно, не собрались. Такая простая схема работает только в средах, где награда поступает сразу от среды. Поэтому именно Deep Reinforcement Learning хорошо себя чувствует в играх Atari. Там, где сразу виден скор от игры, или если тебя съели, то ты сразу это видишь. Но такие среды редко встречаются в жизни. В жизни награда бывает не сразу, а может быть даже никогда. Сделал хорошее дело и получил по башке. Но мы знаем, что дети играют в игрушки, не получая награды. И играя, учатся физике, здравому смыслу и другим вещам. То есть есть какие-то более сложные механизмы, либо обратной связи, либо внутреннего подкрепления, или вообще какие-то другие виды обучения. Ну, собственно, вот о том и тема семинара, и про регламент. Как мы уже в начале говорили, давайте по 15, ну, максимум по 20 минут, потом все вопросы и ответы разом, ну, такое обсуждение просто устроим. Так, и первый, получается, у нас Евгений Витяев, пожалуйста. 

S06 [00:21:51]  : Так, я тогда сейчас расшариваю экран. У меня совсем немного, я не думаю, что будет долго, но я хочу напомнить с точки зрения теории функциональных систем, модели, которые я предлагаю, как это выглядит, глобальное и локальное подкрепление. Ну, я постараюсь довольно коротко обозначить как происходит выработка, принятие решений и подкрепление в теории функциональных систем. Есть мотивация, она идет как запрос в блок афферентного синтеза и принятия решений. Мотивационное возбуждение извлекается из памяти различные способы достижения цели. Они проигрываются. Проигрывание происходит таким образом, что есть некоторые возможные решения, Оно, возможно, включает достижения некоторых по цели. В этом случае идет запрос достижения по цели. В этих по целях принимается решение о том, как достичь соответствующей по цели. И здесь же вычисляется, находится соответствующее правило достижения по цели и передается вероятность того, что действительно эта по цели будет достигнута, уже в этой высокой в глобальный блок принять решение, который ответственный за достижение конечной цели. Соответственно, если есть другие по цели, то в них тоже, принимая эти решения, передается вероятность. После этого для этого конкретного способа достижения цели подсчитывается вероятность достижения цели путем произведения вот этих вероятностей на вероятность самого правила. Эта вероятность передается как возможный способ достижения цели в аппарат акцептера результатов действий и далее в прогноз достижения конечной цели с учетом аппарата эмоций. Здесь на самом деле есть интеграция теории функциональных систем и информационной теории эмоций Симонова. В соответствии с информационной теорией эмоций Симонова Для возникновения эмоций соответственно оценки нужности или притягательности того или иного способа достижения цели нужна мотивация и вероятность достижения цели. В этом случае эмоции оценивают с помощью этой вероятности достижения цели в соответствии с этим планом. После этого перебирается не только этот план достижения цели, но и другие способы достижения цели. Каждый раз эмоции оценивают конкретный способ достижения цели. Потом, в конце концов, когда все способы достижения цели перебраны, аппаратом эмоций выбирается окончательный способ достижения цели, наиболее эмоционально притягательный. Пока я буду говорить только о положительных эмоциях. Для отрицательных там картина аналогичная, но не совсем. После того, как решение принято, и фактически выстроена вся последовательность достижения цели вместе с прогнозом, только после этого начинается реальное осуществление этого плана, и подкрепление начинается только с этого момента. Вот мы начали выполнять план действий. Сначала мы достигаем первую подцель, то есть выполняем вот эту функциональную подсистему. Если мы в этой функциональной системе цель достигнули, у нас здесь уже не вот эта вероятность, а единичная вероятность того, что эта цель готова. В этом случае сразу же вероятность достижения конечной цели, в соответствии с информационной теорией эмоций сильно увеличивается. У нас в этом случае одна из вероятностей произведения становится единицей. Эмоции тут же в соответствии с информационной теорией эмоций тут же на это реагирует и дает положительную эмоциональную оценку. вот этого способа достижения цели, который приблизил к достижению конечной цели, значимую вероятность приблизил к достижению конечной цели. В этом случае те действия, которые были выполнены в этой функциональной подсистеме они подкрепляются. Дальше идет выполнение следующих этапов достижения цели. После того, как каждый этап достижения цели будет достигнут правильно и соответственно вероятность увеличена, здесь тоже в соответствующем блоке этот блок и способ им принятия решений и соответствующие правила, которые здесь сработали, они будут подкреплены. После того, как мы достигли конечную цель, у нас фактически те способы достижения цели и правила, которые сработаны, они будут подкреплены. Предположим, что в какой-то функциональной системе мы результат не достигаем. В этом случае у нас вероятность достижения цели сразу падает, эмоции оценивают это отрицательно, Идет перестройка плана достижения целей. Те правила, которые бы здесь применены и не привели к достижению соответствующей по цели, которая планировалась для достижения конечной цели, они будут наказаны. То есть вот это наказание будет локальным, хотя оно оценивается глобально. Поэтому здесь есть некоторая интеграция и глобальной оценки, и локальных оценок. Но теперь предположим, что у нас нет аппаратной эмоции. У нас чистая теория функциональных систем. В этом случае мы опять же рассматриваем достижение последовательности цели, но в этом случае подкрепление у нас только в самом конце, когда акцептор результата в действии, в конце концов оценивать, что план достигнут. В этом случае у нас подкрепляется вся последовательность действия, но она подкрепляется как? Что в каждой функциональной системе, в которой достигнут результат, соответствующие правила будут подкреплены, то есть локально будут подкреплены результаты каждой из функциональных подсистем. Таким образом, получается, что глобальное подкрепление нам дает множество локальных подкреплений при том условии, что все это правильно организовано иерархически. А правильно организовано иерархически, это значит, что они совместно организованы для достижения конечной цели, достижение которой заранее прогнозируется. То есть заранее прогнозируется, каким образом мы решаем задачей, каким образом мы достигаем эту цель. Поэтому даже в этом случае у нас глобальные подкрепления, локальные подкрепления, они у нас неразрывно связаны. но это с точки зрения теории функциональных систем информационной теории эмоций. Если вернуться к тем вопросам, которые рассказывал Антон, то мне кажется, что вот эта схема, она работает эволюционно буквально с клеточных организмов. Эта схема может работать в том числе и для оценки не только физиологические потребности, но и социальные, и она может использоваться, так сказать, моделирование социума, потому что, когда мы беседуем или, так сказать, организуем какую-то совместную деятельность с другими людьми, мы к ним тоже относимся таким образом, что эта группа совместно должна достигнуть цели, то есть мы все равно просчитываем не только свои действия, но и действия наших компаньонов и действия нашей группы. То есть, в принципе, эта схема тоже годится. Но если есть еще какие-то вопросы, то можно их задать. Или потом. 

S07 [00:29:28]  : Ну да, давайте все-таки потом. Хотя, ну там, ладно. Давайте тогда Николай Робчевский, пожалуйста. 

S02 [00:29:40]  : Да, добрый день. У меня, наверное, будет, как часто это бывало и раньше, достаточно отличное от общего мнение по поводу обсуждаемой темы. Давайте посмотрим на саму проблему поощрения наказания, в том плане, как она возникла и почему она вообще возникла. Сам термин и технология, она пришла к нам, как совершенно справедливо вот Дмитрий Салихов сказал, из дрессировки животных. То есть, если мы хотим надрессировать нашу собачку или кошку, или енота, или еще кого-то на какие-то действия, мы используем поощрение в тех случаях, когда мы замечаем правильные действия, и тем самым пытаемся что сделать? Мы пытаемся его внутреннюю мотивацию, которая у него изначально была, модифицировать для того, чтобы она стала такой, как мы хотим. То есть, чтобы у него появился мотив сделать то, что мы хотим. Таким образом вот в случае дрессировки животных поощрение наказания это есть способ формирования оценки ситуации и формирования мотивации к действию. Вот в том варианте о котором говорил Антон Колонин, когда есть организация многоуровневая и разные уровни работают по-разному и поэтому сложно определить степень наказания и поощрения нижних уровней в зависимости от успешности работы верхних уровней. Здесь ситуация уже несколько иная. потому что поощрение и наказание не являются единственным способом взаимодействия уровней. В организациях никогда практически мы не найдем ситуации, когда нижний уровень получает премию или наоборот ее лишается без всяких объяснений, почему это происходит. То есть, на самом деле, главным элементом является объяснение почему, а вторичным элементом, который заставляет учитывать это объяснение, уже является, собственно, награда или, наоборот, наказание. В этой связи мне представляется, что в системах AGI поощрение и наказание – это суррогат отсутствующей системы мотивации. Если система мотивации есть, Смысл и необходимость поощрения наказания отпадают, потому что система мотивации сводится к тому, что в каждый момент мы имеем способ оценки ситуации в соответствии с нашими нужными пожеланиями, с нашими мотивами. И нам не требуется ничего другого для того, чтобы определить, какие действия будут лучше и какие хуже. Ну и второй момент, который тоже делает саму проблему очень расплывчатой, это то, что последствия того, что мы сказали, мы вот даём наказание. они настолько разные в разных системах, что в общем сам термин «поощрение наказания» тоже становится неопределенно широким. В большинстве случаев речь идет о том, что у нас есть некие параметры, типа там вероятности, проходимости, возбудимости и так далее. И мы эти параметры как-то немножко модифицируем. По сути дела, если это так происходит, то мы имеем совершенно ясную систему, которая называется адаптация параметров системы для того, чтобы они соответствовали некому критерию хорошести. Но такие подкрепления с небольшими изменениями параметров системы работают и дают хороший эффект только тогда, когда мы начиная этот процесс, уже находимся вблизи хорошего экстремума желаемого. А системы как с нейральными сетями, так и другие, как правило, имеют большое количество параметров и огромное количество локальных экстремумов. Поэтому вот такое обучение подкреплением, оно может улучшить ситуацию до той, которая достижима вот вблизи нашего локального экстремума. А если мы будем пытаться сильно менять параметры, то мы получим вариант стахастического поиска, когда мы будем перепрыгивать от окрестностей одного экстремума к окрестностям другого, и закончится ли этот когда-либо процесс, совершенно непонятно. И вот эти соображения, они подсказывают, что сам подход, он работоспособен для очень простых систем, когда есть относительно простые последовательность действий. Одна и та же задача решаемая. Это не означает, что подход неприемлем, а означает только, что на самом деле, если у нас есть система сложная и мне есть какие-то модули подсистемы, которые решают свои собственные простенькие и постоянные от раза к разу задачи, то для них это может быть применено. Типа там предварительной обработки данных от сенсоров или еще что-нибудь. Но как вариант организации реальной интеллектуальной системы в целом, этот подход, в общем, мне представляется совершенно не работоспособным. Ну, у меня все. 

S07 [00:37:21]  : Хорошо, Николай, спасибо. Так, ну, Игорь Пивоваров, прошу. 

S03 [00:37:32]  : Добрый вечер. Ну, во-первых, я там, можно сказать, Антон Колонин в своем выступлении задал все вопросы, что, в общем, практически закрыл всю тему с точки зрения вопросов. Я в целом присоединяюсь к позиции Николая Рабчевского, мне она кажется там правильная. но со своей стороны там три копейки скажу конечно добавить во первых я сильно сильно не готовился к семинару тут был занят своими активностями дать пока не начал говорить минутку рекламы скажу мы сделали этот нужного монах очередной с итогами года так что если еще кто не видел можно почитать вполне интересная чтива а по сути Значит, по сути, подкрепление. Первый тезис. Ну, во-первых, конечно, мне кажется, что смешались две... в этом неаккуратном термине локальное и глобальное подкрепление смешалось две парадигмы. Во-первых, то, что я условно бы назвал короткое это подкрепление на коротком горизонте действий и на и на дальнем горизонте действий и вот то о чем там и говорил антон и сейчас николай подкрепление на нижнем там слой некой архитектуры на верхнем слой некой архитектуры которая на мой взгляд сильно зависит от архитектуры вторая вещь вообще ну она архитектура специфично в моей архитектуре которую я делаю оно есть все примерно так и обстоит так как то что я делаю это такая многоагентная своего рода многоагентная модель как раз вот построенный по таким принципам то там действительно есть, я не называю это локальным подкреплением, но я для себя этот тезис формулирую так, каким образом распространять подкрепление куда-то, как бы, так сказать, с уровней вверх и вниз, в зависимости от того, кто, какой из этих микроагентов, какие принято там решения. Это, конечно, ситуация специфическая, но мне кажется, что она не имеет смысла для общего обсуждения, потому что она архитектура зависимая, у одного архитектура такая, у другого такая. Говоря о таких вещах, каждый из нас будет говорить о чем-то своем, а остальные будут его слушать по-другому. Я не вижу смысла об этой стороне локального глобального говорить. А вот о стороне, как бы подкрепление на коротком горизонте действий и на длинном, это вот очень правильная история. И здесь мне есть пару моментов, что сказать. Во-первых, я целиком согласен с Николаем Равчевским по поводу как раз мотивации внутренней, но думаю, что никто из нас и не только из нас, а и вообще в этой области, пока не понимает, как эту, собственно, мотивацию сделать. Это пока такой один из смутных вопросов. То есть подкрепление, когда говорим про подкрепление, мы как бы апеллируем подсознательно терминами теории обучения с потреблением, reinforcement learning, где это уже математически реализовано, добавление этих дельт и так далее. Но когда мы говорим про мотивацию, то мы используем слово мотивация и наше понятие из нашего внутреннего мира, без опоры на какую-то математическую конструкцию, ни у кого из нас нет пока какой-то в голове математической конструкции, как это можно было бы сделать? Ну, как мне кажется. Хотя я согласен, что это точно правильная тема, достойная именно там где-то на пути этой понимание этой истории там все лежит, но не имея ее, а занимаясь именно подкреплениями, я, например, тоже в своих экспериментах сталкиваюсь именно с вопросами локального, если так можно так, короткого подкрепления и как бы дальнего подкрепления глобального. И даже на самом деле, Дмитрий, и на играх Atari тоже, потому что игры Atari, ну только кажется, что они короткие, а строго говоря, один раунд в игре от ари от начала игрушки до допустим до выигрыша очка это примерно 50 шагов в зависимости от игры там от 50 до там я не все пока смотрел но некоторые там от 50 до 80 шагов и это нас это как бы это не так уж и мало потому что эти 50 шагов комбинаторно, это очень длинная история. И я, например, с этим посталкивался. Если считать под локальным подкреплением, подкреплять условно каждый шаг коротким, я такие модельки строил, они прекрасно работают, но они абсолютно нежизненные. очень несложно сконструировать модель, которая дает сетап для модели. которая там дает модели на каждом шаге микро подкрепления, показывающие ей как бы куда идти. Такая модель прекрасно обучается, но вот эта вот как бы функция, показывающая куда идти, она абсолютно индивидуальная, она в каждом случае своя, и как бы эта модель в целом, она очень плохо будет генерализоваться, по моим представлениям. И поэтому я думаю, что этот шаг, это как бы путь неправильный, путь в никуда. правильный путь это именно опираться на вот эти дальние подкрепления которые существуют и от них танцевать другой вопрос что я бы так сформулировал как мне кажется главная вещь которую мы пока сегодня все то что не понимаем просто может мы об этом не задумывались а вот я задумался потому что начал экспериментировать на своих этих на играх а та и условно как бы так сказать в общем значит здесь будет такой не нужно делать короткие подкрепления на каждом шагу искусственные нужно ориентироваться только на реальные далекие подкрепления но нужно научиться обучать модель сперва на коротких задачах с короткими горизонтами, а потом постепенно увеличивать горизонт. Собственно, что мы делаем с детьми? Я играю в большой теннис. Давно уже не играл. Первым делом учат держать ракетку. Я не выхожу сразу на корт играть против звезд большого тенниса. Учат держать ракетку так, чтобы ложбинка на ладони была вот на вот этой грани. Потом мы учимся там замахиваться правильно. Не ударь, а замах. И этот тренер ходит и смотрит, как мы замахиваемся. Я помню еще по детству. из таких маленьких отдельных шагов и вот на каждом вот этом крошечном и тактике я получаю свое подкрепление он не говорит я правильно делали неправильно и как бы я научился спираль держать ракетку учился замахиваться потом я учился шагать как бы удар с шагом. шаг должен быть правильный. это же все маленькие кусочки. и только потом, когда ты научился шагать, научился по мячику попадать в стенку, там какое-то время поиграл, научился бегать, правильно останавливаться. только потом у тебя в принципе бывает накорд. ты играешь там как-то. а уж я молчу играть против противника а что мы делаем в играх отари я как бы сразу беру свою модельку вывожу ее на корд играть сразу против значит условно олимпийского чемпиона который блин гоняли по всему корду И говорю, а ты учись, только давай, а мы миллион шагов сделаем, чтобы ты научилась получше. А что там, а вычислительных мощностей у нас много, а мы сейчас 100 миллионов шагов сделаем. Вот примерно так сейчас все обстоит. То есть мы сейчас на самом деле неправильно учим, я лично неправильно учу, все, может быть, там, типа Майнди правильно учат, но пока я вот, у меня ощущение, что мы вот это вот локальное глобальное прикрепление должно решаться именно так. если мы хотим, чтобы у модели... но тут возникает свои сложности. во-первых, надо и учить правильно. нужен сетап обучения другой. и должна появляться вот эта иерархичность. иерархичность модели и постепенное настраивание, далеко не во всех моделях есть в современных глубоких сетях этого нет который будет постепенно как бы доучиваться на вот этих новых то есть это причет оба такое как знаете как и не я не такой как взаимодополняющие то есть и и обучение должно быть другой модель должна быть другая и они вы друг друга будут поддерживать вот я думаю что этот не парадокс, а как бы это дилемма, она будет решаться вот именно так, постепенным выращиванием, если хотите, вот как-то так. вот что могу сказать. 

S07 [00:47:45]  : спасибо, я сразу вопросы тоже сбрасываю, чтобы потом не забыть, потому что много спикеров получается. Владимир Смолин, пожалуйста. 

S10 [00:48:01]  : Вы меня слышите? Да, все хорошо. Но, значит, локальные и глобальные подкрепления, тема вообще очень широкая, и, как правильно говорят все, там на нее свой взгляд. Ну, кто уже там интересуется, какой у меня взгляд, понятно, что меня интересуют сложности, проблемы создания сильного искусственного интеллекта и какие конкретно там сложности. Но, в целом, значит, Тема очень широкая. Вот. Сразу скажу, что я, естественно, всю ее освещать не буду, но поскольку я думал, что будет 5 минут, и я, собственно, собирался только в шестом пункте освещать. Но, тем не менее, я пройдусь по плану о том, что вообще бы надо освещать, хотя, значит, подробно туда залезать не буду. Вот. Ну, во-первых, природная растевой революция, она в том, что, значит, стали обучать очень много параметров, и поэтому все какие-то сложные задачи вроде удается решать. Это как бы общий подход. Но, тем не менее, этих параметров много, и они дискретные. Каждый параметр имеет цифровое значение, либо 0,1, либо интеррывное, но само значение дискретное. Живем мы в... более-менее непрерывном мире, более того, мы склонны этот непрерывный, даже если мы знаем, что он дискрет, например, песчинки там на песке дискретные, или там листья у деревьев дискретные, или в лесу там деревьев много, мы склонны вот это как бы дискретное явление или объект рассматривать как непрерывный. то есть кроны дерева, лес, песчаный пляж, мы естественно не про каждую песчинку думаем, хотя описание понятно, что у нас какое-то там дискретное, то есть математика и прочее, ну там исключение геометрии, которая там рисует все аналитические представления, это вот именно дискретное описание. Ну и естественно дискретное описание, оно всегда более или менее локально, а когда мы описываем что-то нейтральное, там появляется некоторое глобальное. если бы все можно было легко описать дискретно, и более того, можно было перебрать все варианты дискретности, то проблем не возникало. описывать дискретно нам более или менее мы научились. во-первых, наш естественный мозг позволяет все на наших параметрах нейронной сети как-то все описать. Ну и у нас там хорошо математика развита, если вздумать, а аналитические все вот эти представления, они связаны именно с дискретными представлениями, то есть некоторые локальные описания достаточно непрерывных объектов у нас тоже хорошо подставлены. Но, значит, сложно, что мы пока не придумали единообразного описания нашего всего мира, и которое, что более того, автоматически как бы подстраивалось под свойства реального мира. Вот. Но, соответственно, я считаю, что, несмотря на все эти сложности, будут преодолены, естественно, будут на этом остановиться. Вот. Ну и в целом, значит, локальные задачи, как правильно сегодня говорилось, это ближайшие, которые надо решить, там как по пространству, так и по времени. А наши глобальные задачи, значит, они более далекие и, соответственно, их сложно решать. Ну, значит, наибольная глобальная задача нашей жизни в том, чтобы осуществлять постпроизводство. но, естественно, в каждой задаче, тем не менее, можно уклонно разделить на локальные и глобальные. Вот. Ну, собственно, сложности описания мира состоят в том, что он, значит, нелинейный. Если он был линейный, то, значит, сложность описания бы росла линейно с размерностью, и мы бы, значит, как бы хорошо все описывали, поскольку, значит, никаких затрат там особых не предвидится. Ну, или если мы бы умели все хорошо линейнизовать. Это тоже бы, как бы, мы перевели, значит, описание мира, который воспринимаем в линейную форму, и тогда все тоже было бы просто. но, к сожалению, у нас пока вот это вот не очень хорошо получается, хотя, в принципе, все вот наши формулы там, не знаю, закон Ома там или текстимерного тяготения, если заменить переменные, которые там логарифмы квадраты на две переменные, то они так ленятся, все как бы реализуют задачу и позволяют с ней работать достаточно проще. но все равно мы стараемся, чтобы там переменных было поменьше. Собственно, вот эти все сложности, сейчас с помощью нейронных сетей появляется надежда, что часть-часть из них удастся решить. Но, соответственно, позитивное свойство мира это то, что в основном взаимодействие является локально. Конечно, закон тяготения всемирный, но, значит, на меня локально здесь притягивает земля. Там где-то Марс, там или какие-то далекие галактики. Ну, в общем, влияет, конечно, но незаметно. Вот. Ну, и то, что есть повторяемость явления объектов, то есть мы научившись чему-то одному, есть надежда, что это такое нам еще в жизни встретится. Вот, и это знание наше как-то, может быть, можно применить. Ну, соответственно, нейросетевого описания, которое сейчас наиболее перспективное многими, в том числе мной, рассматривается в создании сильного искусственного интеллекта, есть как бы линейная и нелинейная часть. Линейная часть, она более глобальна, поскольку у нас линейные преобразования во всех искусствах. в формальных нейронах они, собственно, по всему пространству определены, а нелинейная часть более локальна, то есть, конечно, она тоже формально определена во всем пространстве, но ее нелинейные свойства, если посмотреть вот эти функции нелинейных преобразований, они сосредоточены в достаточно узком участке входного сигнала, ну, естественно, если брать вдоль вектора входных связей, а на перпендикулярном векторе там, конечно, они все равно достаточно глобальны, что, собственно, является некоторым недостатком перцептронного способа преобразования. Кроме перцептронов есть, соответственно, еще и конкурентное обучение, где вот этого недостатка, на мой взгляд, можно будет избавиться, но пока что как бы вот это направление плохо финансируется и развивается достаточно слабо, потому что пока что для решения ряда задач хватает перцептронов и этим как бы все пользуются, поскольку основная сейчас как бы цель сельскохозяйственная, срыв низкомесящих фруктов, и поэтому суперсектроны как бы всё давят. Вот. Ну, собственно, чтобы описывать сложный мир, как я говорил, важно, собственно, осуществлять разделение переменных, то есть осуществлять декомпозитивность наблюдаемого внешнего мира, и, соответственно, вот это разделение, оно даже в трецептронах осуществляется. То есть, естественно, каждый формальный нейрон выделяет некоторое направление вдоль вектора весов связи, и, соответственно, вдоль этого направления он как бы разделяет пространство входного сигнала, или что там, значит, работает. Ну, кроме того, есть всякие модели типа тап-энкодеров, которые, собственно, уже сейчас позволяют выделять существенные переменные, ну, как правило, в содружестве с ганами, там есть достаточно сложная модель, которая позволяет выделять. Я считаю, что важный склад конкурентного обучения, к которому может быть отнесено, это выявление простых объектов соявлений, то есть декомпозиция на пространстве состояния всех этих объектов. И поскольку они как бы мало пересекаются, их, вероятно, можно разделить, хотя, собственно, вот такие серьезные сработки мне не удавалось сделать, если бы я литературу не читал. Ну и, наконец, как у естественных нейронных сетей, так и у искусственных сетей, наличие многослойной структуры позволяет считать эротическую декомпозицию, обработку сигналов, ну и это тоже, в принципе, служит упрощению описания сложного окружающего нас мира. Вот. Теперь, собственно, какие-то элементарные вещи, которые я с рисунком попробую рассказать. Это, собственно, что такое подкрепление. Ну, собственно, все ссылаются на Павлова, о том, что, значит, есть безразличный сигнал, безусловный сигнал, и, соответственно, если их совместить во времени, то это, значит, является подкреплением. Вот. Ну, и, как бы сказать, что там считал Павлов по нейронным цепям, я, честно говоря, сейчас не всё вреду. Вот сейчас, значит, Институт высшей нейронной деятельности рисует вот такие картинки, да, что формируется, значит, некоторая нейронная цепочка, что, значит, увидели, допустим, там, свет, хотя рисуют звоночек, но неважно. Важно, что какой-то безразличный сигнал как-то отразился какой-то активностью в мозге и, соответственно, пошел вывод на слюноотделение из опыта Павлова насчет использования. Ну, я не подозреваю, что и Павлов предполагал, что какая-то нейронная дуга там образуется и, собственно, вот это вот Условия внешние создаются для того, чтобы какие-то внутренние механизмы мозга создали внутренние условия, чтобы эта дуга сформировалась. По поводу мотивации и подкрепления, которые передо мной пытались разделить, что это совершенно разные вещи, и мы не понимаем, что такое мотивация, а знаем, что такое подкрепление. Ну, значит, я считаю, что это вещи одного порядка. Просто у нас заложено подкрепление, что если мы что-то хотим сделать и у нас получается, то это нам дает подкрепление. И, собственно, вопрос отдельный, как там выбирать цель. Я не хочу сейчас это сказать, но, собственно, если мы умеем строить цели и, собственно, каким-то путем пытаемся их потом достичь, то это как бы хорошая база для подкрепления нашего внутреннего. И, собственно, вот эта мотивация состоит в том, чтобы как бы сказать, заложить в нас цель, которую мы считали бы, значит, истинной. То есть там или построить коммунизм, или Божьего царства достичь, или общество равных возможностей. Кому там что заливают по разным телевизорам, соответственно, к тому и стремятся. внутренние условия подкрепления это то, что значит создание условий для изменения свойств нейросетей, как естественно статистично, то есть там есть какие-то дискретные параметры, и там, и там, которые, соответственно, меняются, и это приводит к тому, что преобразование, которое осуществляется в нейронной сети, оно влияет. Соответственно, условия могут быть внешние, то есть первые сигналы, которые воспринимаются, и в результате образуется какой-то гормональный фон. Причем этот фон может быть не только следствием внешних сигналов, но и просто развитием. Пятилетнему мальчику женский пол безразличный, а если ему лет 15, то он на женщину смотрит уже по-другому. Ну и, соответственно, отличие, которое, к сожалению, многие биологи, я, естественно, всего стараюсь отфильтровать, состоит в том, что принято рассматривать не образование одной, никак не связанное с другими навыками, а формирование системы большого числа ассоциаций, реализованной на одной многослойной структуре. То есть все, кто занимается нейросетями, Видео, они, в общем, именно этим занимаются. Никто не пытается связать два явления. Это задача неинтересная. И, собственно, интересно как раз уже даже не просто какую-то систему осуществлять, а какие-то отдаленные события связать. Возможности появились значительно более серьезные, и они сложны. Вот. ну, собственно, в основном сейчас в нейронной сети основным местом потребления считается вес связи, хотя, конечно, сводится порог к весу связи, что я считаю неправильным, но, тем не менее, формально это можно сделать, и считается, вообще все определяется весами связи, мы их меняем, но, естественно, веса связи можно менять только по гейну. вот есть там правила хеба, есть и дифференциальные правила хеба, есть, значит, способы изменить связи по квартирам. На самом деле, в принципе, возможно. И, собственно, меня хоть слышно, а то мой интернет-коннекшн из unstable. Хорошо. Вот. И, собственно, Укрепление осуществляется тем, что мы создаем слови для изменения этих связей. Они могут быть внешним сигналом, заданием каких-то параметров. И, соответственно, в модели, когда мы создаем вот эти условия для изменения каких-то параметров сети, это, собственно, и есть подкрепление. Является ли это каким-то простым свойством сети, сложным сетей, связанным с какой-то отдаленной мотивацией, если это привело к изменению каких-то свойств сети, мы создали, собственно, некоторое подкрепление, которое привело к изменению параметров сети. ну и как уже говорилось о том, что backpropagation приводит к локальным минимумам, что является определенным недостатком, это видимо, и собственная проблема, что минимумов это много. очень много. с них на Николенко там приводится, что если есть хотя бы один локальный минимум, то если просто переименовать, перенумеровать в каждом слое нейроны, то мы получим с n пока всевозможных перенумеровок еще на других минимумах, которые нашлось в сети тоже возможно. а если таких минимумов можно несколько, то там, соответственно, получается еще больше идти. ну и, собственно, основная проблема Bad Propagation Error состоит в том, что он никак не настроен на обход этих минимумов, а, в смысле, почему непосредственно по градиенту не учат, а, значит, используют всякую регуляризацию, многие другие методы, которые позволяют, ну, в общем, худо-бедно как-то с этими локальными минимумами бороться, но еще и некоторые устойчивости к тому же сети обеспечивают. Ну, собственно, место подкрепления, оно, конечно, может быть локально. То есть, когда мы меняем какие-то параметры, то, собственно, само место подкрепления, оно локально. но можно менять и глобальные переменные, которые влияют на всех, то есть в законе обратного состояния ошибки, ну и в тех, которые там выписаны, есть лёнингрейд, альфа, которая влияет на все, изменение всех параметров, и изменение такого параметра влияет глобально, либо на целый слой, либо на всю сеть. и, собственно, некоторые авторы как раз находят отличие искусственных нейросетей от естественных в том, что вот у нас там сложный гормональный многодопонентный фон, а в искусственных нейросетях вот один, значит, learning rate и все. ну, это как бы глубокое заблуждение, то есть даже в современных backpropagation сетях там на самом деле много параметров. Менять их можно по-разному. Кроме того, что надо уменьшать ошибку на выходе, если брать просто апоксимацию, отдельно нужно смотреть, чтобы было какое-то отражение входного сигнала, для разных входных сигналов, чтобы была разная реакция сети. На этом нужно отдельно работать, и backpropagation на это не направлено. есть такие параметры, например, гладкость тех функций, которые образуются. в принципе, если у нас там не Relu, а какой-нибудь SoftPlus, которая вот такая гладкая модель Relu, то там, собственно, вопрос кривизны ее, значит, backpropagation не регулирует. а, в принципе, можно предложить механизмы, которые кривизну могли бы регулировать. Вот. Ну и потом есть всякие законы, моментное обучение, где много есть параметров. И, соответственно, это тоже позволяет говорить о том, что подкрепление тоже может быть разносторонним. Вот. Ну и, собственно, результат крепления тоже может быть как локальным, так и глобальным. Если, соответственно, мы изменили какой-то параметр, то он может повлиять на реакцию сети в какой-то локальной области сигнала, а может повлиять на реакцию во всей области входных сигналов. Ну, как правило, если мы меняем сейчас связи в перцептроне, то поскольку это меняется линейная часть преобразования, она определена, ну, как правило, Ну, во всей области. Другой вопрос, что потом нелинейная часть что-то отрежет и обратит в ноль или в отрицательное какое-то конечное число это линейное преобразование. Но, соответственно, при изменении локальных лицов связи у нас происходит глобальное изменение преобразования. И, с одной стороны, некоторые считают, что это плюс. Я считаю, что это усложняет процесс обучения, поскольку надо утрясать все эти изменения, которые таким образом происходят. Как я уже говорил, нелинейное преобразование более локально, по крайней мере, вдоль направления вектора связи каждого элемента входных. И, соответственно, вдоль него меняется нелинейность, которая, как правило, сосредоточена в одном достаточно узком месте. по входному сигналу. Хотя перпендикулярно у персифтронов тоже это изменение достаточно широкое, и это на мой взгляд недостаток. А основной на мой взгляд перспективы в дальнейшем применения сетей с крупнорядной активностью, что там в разных областях входного сигнала проявляют большую активность разные элементы, и это локализует их ответы, С одной стороны, это требует настройки примерно такой же, как при септроне, но, соответственно, как бы сказать, нет такой необходимости утрясать результаты изменения параметра по всей глобальной области. То есть, если мы что-то изменили в сети с конкурентной активностью, то изменения достаточно локальные, они не портят, значит, тех наших знаний, которые мы получили в более, значит, раннее время. Вот. Ну, из того, что раньше говорили авторы, если, значит, мне позволят еще сказать пару слов, значит, вот Антон Герванович просил, собственно, высказаться по поводу подкрепления эволюции сильного искусственного интеллекта. Ну, в принципе, вся эволюция и у кошек, и у бактерий, и у людей направлена на то, чтобы вид выживал. Но мы все-таки отличаемся от... омек тем, что мы можем прогнозировать свою деятельность, то есть мы не просто на основе случайного поиска выбираем свой ДНК и действуем в том, что в нем заложено, а можем на основе личного опыта менять свое поведение. Ну, собственно, Тегмор предложил эту жизнь 3.0, И, собственно, человек уже приближается к состоянию жизни 3.0, то есть мы уже можем менять код ДНК или строить роботов, которые будут воспроизводить себя и организовать производство таких же роботов. Когда вот эти агенты сильного искусственного интеллекта смогут заниматься амебой, расширенным себя воспроизводством и поддерживать свою жизнеспособность, А с другой стороны, не просто они её будут поддерживать, а будут способны конструировать и улучшать свою физическую структуру, вот это и будут те самые агенты сильного искусственного интеллекта, к которым сейчас приближается человек. Ну и по поводу выступления Витяева о том, что Схема Анохина, она как бы сейчас наиболее перспективна. Никто, естественно, не спорит со схемой. Теория функциональной системы Анохина, она, конечно, правильная, так же, как и Условный рефлекс Павлова, но хотелось бы из философов, идеологов обратить внимание, что мы переберем все варианты решения. Это вследствие того, что монетари не умеют считать. Если бы они умели считать, они бы поняли, что все возможные решения мы перебрать не можем. Можно посмотреть на ряде задач. можем перебрать очень небольшую часть возможных решений и из них что-то выбрать. И искусство состоит в том, чтобы найти, собственно, из большого числа возможных решений, которые перебирать, те, которые стоит перебирать. И это, вот как бы, важный аспект. Ну, значит, про то, что Робитеевский говорил про отличие поощрения от мотивации, я уже высказывался, но повторюсь, что конечно, мотивация, более сложная организация поведения, которая идет к утерплению, но в принципе, с точки зрения нейросети, это все равно одинаковые механизмы создания условий, чтобы как-то менялись параметры сети, которые определяют ее преобразование сигнала из входного в выходной. понятно, что это не так просто, с этим надо работать, но принципиальные невозможности это смоделировать ну, были какие-то более мелкие комментарии, но давайте, я очень много говорю, так что, спасибо, сдали договориться, и, собственно, если будут ко мне вопросы, я готов ответить. 

S07 [01:08:54]  : Вопросы обязательно будут. Давайте сначала, да-да-да, так, что у нас получается. Борис Новиков, пожалуйста. 

S00 [01:09:17]  : Добрый вечер, меня слышно? 

S07 [01:09:21]  : Да, все хорошо. 

S00 [01:09:22]  : Хорошо, да? Спасибо. Ну, во-первых, я хочу поранее попросить прощения, что я не сделал хорошей презентации. Во-первых, у меня нет опыта, во-вторых, у меня нет студентов и помощников, но все-таки кое-что я подготовил. У вас как нет? 

S07 [01:09:46]  : Борис, Борис, такое ощущение, что у вас внешний микрофон, и он как будто там... Вход у него нет, он не просто движется. У вас как будто плохое соединение микрофона с компьютером. Шумы сильные. Борис? 

S00 [01:09:59]  : Сейчас проверяю, соединю. Алло. 

S07 [01:10:18]  : Пока вроде нормально. 

S00 [01:10:21]  : Слышно, да? Да. Мне свою эту презентацию показать. Расширить экран или что нужно? 

S07 [01:10:38]  : Да-да-да, расширить экран, да, там демонстрация экрана внизу. 

S00 [01:10:45]  : Сейчас. Демонстрация экрана. Сейчас. Ну, ладно. Значит, что это? Во-первых, я хочу... могу говорить более-менее продуманно. Только об... естественном интеллекте. 

S07 [01:11:17]  : Соответственно... Борис, а вы хотели расшарить экран вроде? Борис, прошу прощения. Вы хотели расшарить экран, но пока ничего не расшарили. 

S00 [01:11:25]  : Не получается пока. 

S07 [01:11:28]  : Не получается? Может тогда вы вышлите, не знаю там... Расшарить экран. 

S00 [01:11:35]  : Внизу, да. Да-да-да. Демонстрация экрана. Сейчас. Видно? Пока нет. 

S07 [01:11:52]  : Там промежуточное окно, Борис, там промежуточное окно должно появиться, которое спрашивает, что вы хотите расшарить, там типа браузер, рабочий стол. И вот там еще нужно выбор сделать в нем. 

S00 [01:12:05]  : Вот там появился экран. Значит, мне надо нажать на экран, да? 

S07 [01:12:08]  : Да, да. 

S00 [01:12:10]  : Вот, вижу, вижу, что я хочу нажать. 

S07 [01:12:16]  : Сейчас видим. Сейчас появилось? Да. 

S00 [01:12:19]  : Видите, да? Хорошо. Так вот. Значит, я писал об общей теории создания. и соответственно о роли интеллекта в сознании. Вот принципиальным моментом является то, что у человека есть физическое тело и все функции, психика человека служит интересам тела и интересам популяции, а интеллект Это часть психики, которая нацелена на решение задач, которые поставлены извне. И вот если мы возьмем часть то, что связь человека с сообществом, то есть социальный интеллект, то, что в основном нас интересует, потому что есть еще двигательный интеллект, эмоциональный, работа с телом, но это обычно даже не считается интеллектом. Интеллект – это часть сознания, а сознание – это система информационных моделей с памятью, самосовершенствующей. И вот, соответственно, самосознание – часть Сознание, которое содержит модели этого сознания. И понимание, вот я бы хотел подчеркнуть, что я считаю понимание. Понимание чего-либо X субъектом S означает создание у субъекта S модели X и возможности его, используя его поведение, удовлетворительным для субъекта образом. То есть, если человек говорит, что он что-то понимает, например, то, что ему сказали, или какую-то теорему, значит, у него в сознании возникла модель того, что он услышал, или того, что он прочитал, или того, что он интуитивно придумал, так, что эта модель его удовлетворяет. при том удовлетворяет именно его. Тогда он говорит, что он понял. Других может не удовлетворять, а другие могут сказать, что он заблуждается, он этого не понял. Ну, а дальше смысл модели или высказывания – это то, что можно понять как результат понимания. Вот тут много говорится о том смысле, Вот я понимаю смысл таким образом. Ну, там дальше внимание сейчас. Теперь, собственно, об интеллекте. Интеллект – это не объект, это не мозг, это функция. Это свойство объекта, который обеспечивает возможность решения отдельных специальных задач или достижения заданных конкретных целей, которые уже ранее поставлены и определены для этого объекта или его интеллекта. И которые традиционно считались интеллектуальными задачами для человека. Например, рассмотрим игру в шахматы. Матч на звание чемпиона мира. Если у нас это рассматривает тренер в детской секции, то ему достаточно записи партии. Он будет их разбирать со своими учениками. А если будет рассматривать тренер претендента на звание чемпиона мира, то он должен будет рассмотреть значительно больше. И физическую форму, питание, сон, отдых и так далее. И это совершенно разные модели и разные задачи, и им-то нужен разный интеллект. И далее, если, скажем, у профессора на Мехматии и охотника Бушмена в пустыне Калахари мозги более-менее одинаковые генетически, но интеллект у них... их задачи, которые они решают, и интеллект у них совершенно разный. особенно на профессиональном уровне. Дальше я хочу сказать пару слов, как я понимаю, соотношение специализированного интеллекта и универсального интеллекта у человека. То есть человек живет как бы в двух реальностях, в бытовой и в профессиональной. И у отдельного человека в профессиональной области есть свой специализированный интеллект. И только в бытовой области на уровне здравомысла есть универсальный интеллект. И делать нам универсальный интеллект на уровне человечества абсолютно непонятно зачем. Их у нас и так имеется. Больше семи с половиной миллиардов, зачем нам делать ещё искусственные? А вот делать специальные интеллекты, которые будут решать задачи лучше, отдельные, узко, чётко поставленные задачи лучше, чем специалист, вот это то, что нам нужно. Задача сделать универсальный интеллект все равно, что сделать универсальный инструмент. Вместо того, чтобы делать отдельно лопату, молоток и иголку, сделать какой-то инструмент, который одновременно может выполнять функции лопаты, молотка или иголки. Это, в общем, несколько странная задача с моей точки зрения. И дальше, вот какие модели нужны человеку? Модель обязательно абстрагируется от большинства параметров реальности. Выделяет только значимые параметры, все остальные отбрасывает. И если это помогает человеку в его жизни, значит это правильная модель. А если мешают, то, соответственно, неправильно. И в этом суть теории философии инструментализма Дьюи. Ну вот, если кратко, то наши знания верные – это инструменты или модели, которые помогают нам лучше взаимодействовать с реальностью, то есть лучше жить. И в этом их полезность, то есть правильность. А если мешают, то вредность или ложность. Теперь вопрос. о социальном свойствах модели. Очень важно, что адекватность модели должна определяться не по отношению к объекту моделирования, а по отношению к решению тех задач, для решения которых эта модель предназначена. И еще требование пользователи, которые эту модель будут использовать. И законы природы – это не свойство реальности, а свойство моделей. Например, физика за пару тысяч лет, физические модели менялись кардинально, а физические объекты, по консенсусу мнения, не менялись. Там модель солнечной системы менялась кардинально. Солнечная система 2-3 тысячи лет как была, так и есть. Ну и при оценке качества моделей учитываются параметры точности, достоверности и сложности. При этом они имеют разный удельный вес и определяются эти места в основном не объектом моделирования, а кругом задачи пользователя. предполагаемых для этих моделей и подобный метод оценки моделей называют критерием практики вот то что я ввезу ссылки на мою книжку или отдельно на статью о сущности сознания а также ссылка на как я ответил на систему определение терминов в таблице господина Колонина, там 72 термина, я пытался сделать из них систему, исходя именно из того, что в любой теории мы пользуемся моделями, и только внутри модели возможно четкое определение терминов, в отличие от использования естественного языка, где полисимичности и всегда одно и то же слово всеми понимается по-разному. Но для этого нужно выбрать модель, в рамках которой мы работаем хотя бы внутри группы. Потому что в разных моделях будут разные термины, одно и то же слово будет пониматься по-разному. Скажем, слово «сила» имеет там кучу смыслов разных моделей. Дополнительно я хочу сказать пару слов о соотношении личного и социального. В фильме «Гардемарина вперед» был такой лозунг «Жизнь Родине, а честь никому». То есть у субъекта есть система ценностей. И только из системы ценностей и ситуации возникает постановка целей и выбор моделей, которые подходят для достижения этих целей в этих ситуациях. При этом, как правило, целей и критериев, которые нужно одновременно следовать, бывает очень много. Более-менее реальные практические задачи оптимизации всегда задачи многокаритериальной оптимизации. Кроме игрушечных ситуаций, когда мы играем в шахматы или в бо или на компьютере, у нас есть одна цель. Игру надо выиграть. Особенно если это... Борис, прошу прощения. 

S07 [01:23:11]  : Пару минут еще. 

S00 [01:23:13]  : Да, я заканчиваю. Если это виртуальная реальность, то в виртуальной реальности набор параметров, учитываем, задан извне, а в физической реальности забор внешних параметров практически бесконечен. И всегда при построении моделей приходится отбирать и самые универсальные слова при честном моделировании, это слова можно пренебречь. И поэтому, когда в нашей группе говорится об индивидуальных онтологиях, то мы работаем в рамках своей онтологии. Это значит, что мы отрезаем нашу модель от практики напрочь. Потому что онтология философии – это учение о бытии, то есть о реальности. Если мы говорим, что у нас своя онтология, значит, у нас своя реальность. а не общая физическая реальность. Ну и в заключение я бы хотел сказать, что на мой взгляд, повторить, нужно делать полезные инструменты человечеству, нужно делать полезные инструменты, а не страшных конкурентов. в виде универсального искусственного интеллекта, который будет командовать армией роботов, и что они будут делать с людьми абсолютно непонятно. Спасибо за внимание. 

S07 [01:24:42]  : Борис, спасибо. Я только вас попрошу вот эти ссылки выложить в группу нашу, потому что отсюда мы их скопировать не сможем, чтобы мы ознакомились с ними. Дайте еще раз, вы сейчас интерес подчеркнули, люди наверняка заинтересуются. Хорошо. Хорошо. Поговорили, спасибо. Получается, все выступили. Послушав всех спикеров, у меня не покидает ощущение того, что Игорь действительно прав, Пивоваров, о том, что, во-первых, понятие темы, про которую мы говорим, потребление и обучение на основании, оно у всех в голове разное, у всех разные модели. И то, о чем говорил Игорь, это то, что все эти вещи, модели специфичны, точнее, архитектура специфична. И, собственно, я все-таки думаю, что нужно немножко хотя бы как-то по поверхности пройтись по хотя бы тем архитектурам, которые уже оформлены как архитектуры, так, чтобы, может быть, кому-то стало бы какой-то маленький кусочек инсайта, распространился между нашими головами. Мне, во всяком случае, оказались интересными несколько моментов. Антон, ты здесь? Ты, поскольку был первым спикером все-таки, хотя себя не афишировал как спикер, но тем не менее, я бы первый вопрос как раз тебе задал. Ты можешь расшарить свою презентацию? Ссылку на которую ты дал в этом документе. Либо я расшарю. Сейчас, давай расшарю. Сейчас. 

S01 [01:26:44]  : Слайд седьмой. Сейчас, секундочку, секундочку, секундочку. Я дихорадочно ищу, где тут у меня шарится экран. Так, stop, continue, да. Вот, вот я зашарил. Так, теперь надо найти презентацию. Вот эту, да? 

S07 [01:27:04]  : Да-да-да, седьмой слайд. 

S01 [01:27:06]  : Ну он не седьмой, он пятнадцатый, видимо про другую презентацию говорил. Ну слайд вот этот вот. 

S07 [01:27:12]  : Нет, подожди. Так, давай вниз мотай тогда. Мотай-мотай-мотай. Короче, смотри, мне нужно там, где у тебя положение меча и ракетки описывается предикатами. Понимаешь? А, окей. 

S01 [01:27:30]  : Окей. Да. 

S07 [01:27:34]  : Вот этот вот. Да, вопрос, собственно, как вот ты, имея предикат, то есть правильно я понимаю, что в данном случае ты делаешь некую функцию, которая зависит от четырех параметров, положения там ракетки, положения меча и так далее, и вот это вот happy, то есть потребление. А как, собственно, ты обучаешь эту функцию? 

S01 [01:27:57]  : я не понял значит ну во первых там значит на самом деле сказать неважно что мы подаем на входе то есть на входе у нас может быть там не 4 функции у нас может быть сколько угодно функции у нас могут быть функции пикселов, если мы в дискретном пространстве работаем, и у нас могут быть функции положения меча и ракетки, если мы в функциональном пространстве работаем. То есть, мы работаем, опять-таки, с потоком предикатов, и на самом деле, в конечном итоге, мы работаем с потоком состояний, где состояние описывается некоторым набором значений некоторых предикатов. А как мы обучаем? Обучаем мы очень просто. Мы запоминаем последовательность состояний. И в какой-то момент, когда к нам поступает положительное подкрепление извне, когда случается хэппи, мы каким-то образом положительно воздействуем на все те состояния, Состояние, причем, включает в себя как то, что мы испытали, так и то, что мы сделали при этом. Состояние – это, на самом деле, переход. С точки зрения Минского, это как «трансфреймс». «Трансфреймс» – это переход из одного состояния в другое, которое включает в себя воздействие, которое, собственно, осуществляет этот переход. Каждый такой переход и воздействие в определенном контексте подкрепляется. И подкрепляется оно в том случае, если оно оказывается в некоторой последовательности, которая заслуживает подкрепления. А как мы определяем длину этой последовательности, которая подкрепляется? На сегодняшний день там находится безобразный костыль, который заключается в том, что как только мы получаем какое-то подкрепление, мы от счастья или от несчастья все забываем и начинаем формировать новую последовательность. Соответственно, получается такая ситуация, что если у нас подкрепление происходит в момент отскока мяча от ракетки, всё очень хорошо. Потому что как только отбили мяч, сразу же получили порцию эндорфина и все запомнилось. Если мы получаем подкрепление в тот момент, когда шарик ударился в потолок, тоже все хорошо. Потому что не так много времени проходит между тем, как мы отбили шарик и что он ударился в потолок. А вот если мы эту модель переставляем на OpenGM, Где подкрепление получается только в тот момент, когда игра оканчивается успешно, ты получаешь подкрепление. Или сейчас... В общем, там получается всё не в момент отбития речи, а даже не в момент попадания в мяча в ракетку. Там, когда ты зарабатываешь в итоге очки за успешно выигранную игру, у тебя вот случается счастье. И в этом смысле... Там у меня пока не получилось научиться. Просто потому, что именно путь, который накапливается за время между событиями, за то время, что путь получается такой длинный, что очень трудно этот длинный путь найти. И адекватно распределить подкрепление по такому длинному пути. И поэтому я, собственно, стал думать в двух направлениях. Первое направление, про которое говорил Игорь, что нужно, прежде чем играть с противником, научиться ракетку в руках держать. И примерно в этих же терминах мы с Олегом Серебренником говорили, что да, нужно научиться вначале попытаться подергаться вправо-влево и убедиться, что движение вправо, нажатие на кнопки вправо, приводит к движению ракетки вправо. И, собственно, к такой же проблеме в своё время мы пришли в проекте Supervisor Language Learning. в Singularity нет, в OpenCog. Когда мы пытались учить грамматику английского языка на корпусе Гутенберга. Какой мы ставили эксперимент? Мы брали искусственного ребенка новорожденного, запирали его в комнате с собранием англоязычной литературы для детей и юношества и рассчитывали, что через три года этот ребенок выйдет с прекрасным литературным английским. Но у нас, к сожалению, не очень это хорошо получилось. В связи с чем возникла гипотеза, что нужно вначале на полгода его запирать с азбукой, потом еще на полгода запирать с учебником для первого класса и так далее. И когда я подъел в какой-то момент, я обнаружил случайно… Да, и мы пришли к этому и собрались двигаться в эту сторону, но, с одной стороны, финансирование в данном проекте кончилось, а параллельно выяснилось, что это входит в моду. под названием Куриклум Лёнь. Ссылки на которые я дал. Ну вот, как-то так. А с другой стороны, всё-таки меня не оставляет ощущение, что всё правильно. Мы не учим так детей, но всё-таки даже если мы приходим на теннисный корт, и видим, что там какие-то дяди и тети играют в теннис, и нас никто не учит, но всё равно же, наверное, мы пытаемся сами что-то сделать. Вот. То есть мы, на самом деле, этот самый куррикулум лёнин сами, наверное, себе можем организовать в каких-то жизненных ситуациях. Вот. И для того, чтобы организовывать его в жизненных ситуациях, вот как раз нужны те метрики... Я вот, кстати, даже сейчас открою вот это вот... Мой экран же видно, да? Вот, я просто сейчас, кто не в Фейсбуке, я открою вот эти пункты. Я уже тогда хотел прокомментировать, но комментировать не буду, потому что просто выскажусь. Вот, значит, там было голосование где-то. А где же голосование его Олег Култунов разместил? Так, так, так, так. Вот-вот. На самом деле на эту тему говорил Александр Новиков из DeepMind на OpenTalks. Есть несколько костылей, которые мы можем использовать в качестве подкрепления для своих собственных действий, даже если мы не подкрепляем и никакого подкрепления извне, от учителя, вне зависимости, маленькими у нас шагами учат или большими. То есть, во-первых, если мы научаемся к каким-то действиям, которые позволяют сработать к пресловутому акцептору результата действия, то есть если мы протягиваем руку вперед, ожидаем у себя руку на расстоянии вытянутой руки и действительно ее видим после того, как мы ее туда протянули. то мы уже получаем подкрепление, что мы контролируем ситуацию. Управляемость тоже. То есть если я действительно хочу двинуть руку вперед и рука действительно движется, то вот сам факт того, что я делаю что-то в нужном направлении и контролирую это, то это вот тоже. По сути это одно и то же, но только в одном случае речь идет про ожидание того, что мы получим результаты действия, а в другом случае Насколько мы управляем… Первый и второй пункт, может быть, одно и то же, но на разных уровнях. Следующая – ожидаемая полезность. Тоже как-то близко, но здесь мы все-таки еще ожидаем полезность. Если мы предполагаем, что какое-то действие из нашего жизненного опыта нам даст какой-то положительный результат, то тогда Значит, даже если мы в этой ситуации оказались и не можем связать, связано ли это напрямую с какими-то нашими действиями или нет, но тем не менее, если мы что-то сделали и даже неожиданно для нас мы оказались в той ситуации, которая по нашему опыту приведет в конечном итоге к чему-то хорошему, наверное, мы тоже подкрепим вот это случайное действие, даже невольное. Ну и новизна – это если мы будем подкреплять себя за предсказуемость, мы будем все время сидеть на диване и смотреть на стенку, потому что все будет предсказуемо и управляем. Поэтому за новизну нужно подкреплять, чтобы не застрять в глобальном минимуме. Я согласен полностью. В локальном минимуме, точнее. 

S07 [01:37:16]  : Спасибо. Сергей Терехов просил пару минут, прежде чем дальше на вопросы приключимся. 

S09 [01:37:24]  : Спасибо большое коллеге, что дали такую возможность. Было очень интересно послушать. Во-первых, я просто хочу немножко сказать, что я занимался в одно время искусными задачами с подкреплением 20 лет. Задачи, которые стояли тогда, 20 лет назад, они касались, я даже вот тут найду свою старинную презентацию того времени, которая как раз касалась нейродинамического программирования автономных агентов, которые с помощью подкрепления обучались. Но не суть, просто задача, которая тогда стояла, Она состояла в том, что компании, инвестфонды, тогда очень много было, так сказать, образовывалось таких организаций, они очень интересовались проблемой, как управлять, вот у них сотни участников, так сказать, они все очень неграмотные, тогда никто же не умел делать ни ничего, никто не умел ни организовывать, ни план написать, бизнес-план, ничего не понимали. И вопрос в следующем, что непосредственно управлять этим коллективом, то есть давать им управляющий сигнал на уровне управляющего сигнала учителя, он не пойдет, потому что люди уйдут, люди, так сказать, лидеры, они не могут, они не воспринимают сигналы учителя. Мы умеем делать так называемый дизайн аукционов, то есть планировать аукционы мы умеем. Как сделать схему аукциона такой, чтобы она приводила к результатам? А вот как управлять этим конгломератом автономных агентов так, чтобы они не понимали, что на самом деле мы их не заставляем делать с учителем, а мы каким-то другим образом. И задача возникала как задача design of reward. Как правильно сформулировать, что такое будет ревард для того, чтобы он достигал каких-то целей. Вот результат, который там был, он такой, что фактически, на самом деле, эта задача сводится к задаче манипулирования. То есть нужно, вообще-то говоря, вот когда такая система создается, нужно манипуляционным способом обмануть вот этого агента, вот этого участника так, чтобы он, получая поощрение, думая, что он набирает информацию в виде поощрения, на самом деле решал ту задачу, которая нужна нам. Вот это есть смысл этого манипуляционного подхода и это есть подкрепление. Когда я с этими результатами выступил на конференции нейроинформатика, это было 18 лет назад, тогда еще был крепкий молодой Виталий Иванович Дунин-Барковский, которого, наверное, вы хорошо знаете, президент нашей ассоциации нейроинформатики бывшей. Вот он мне подошел и говорил, Сергей, Ты понимаешь, вот ты вместе с Сатаном и Барта не понимаете важного момента. Дело в том, что теория подкрепления это не обучение. Подкрепление это когда крыса уже умеет с вероятностью 10% прекрасно сама находить выход из лабиринта, из этого лабиринта. А подкрепление просто эти 10% превращает в 40%, в 30%. То есть оно усиливает, увеличивает вот этот вот эффект, который она уже нашла сама. Но подкрепление концептуально, в принципе, не способно научить находить выход из лабиринта. В этом смысле это не обучение. И это хорошо понимали классики, но, к сожалению, когда пришла новая волна, тогда новая волна типа Сатаны и Барта. Сатан, вот называется в Львонахе, в седьмом Львонахе, как вот выдающий, так сказать, специалист области эритмосуферии, того самого обучения с подкреплением. Хотя, на самом деле, Люди того времени понимали, что он не понимает. Но это отдельный вопрос. Так вот, что я хочу сказать. В этой связи подкрепление кардинально надо отличать от сигнала учителя. Вот как только появляется сигнал со знаком, то есть плюс и минус, это уже сигнал супервайс. То есть это сигнал, который корректирующий. Как в системе управления с обратной связью и так далее. Это корректирующий сигнал. Он не идеален. В том смысле, что он не равен производной ошибке. Он просто хотя бы знак имеет. Но это уже корректирующий сигнал. А вот подкрепление это совершенно другого типа суть его. И это не зависит от архитектуры. Хотя вот Игорь пишет пиару, что там вопрос архитектуры. Нет, это не архитектурный вопрос. Это идейный вопрос. Подход с подкреплением предполагает, что вы специальным образом строите некий способ управления этим агентом таким, чтобы его косвенно то поведение, которое у него получилось, следовало вашим целям. Эта задача имеет смысл как математическая задача, только если подкрепление аддитивный. Это и была самая главная проблема с теорией Беллмана, когда он предложил свое, так сказать, уравнение Беллмана. Долго возникал вопрос, а как же так вот американцы так это вывалили нам такую фундаментальную совершенно такую вещь, как же они там бесплатно все это открыли, раскрыли, опубликовали, там как же там могло такое быть. На самом деле потом, так сказать, вот люди-то поняли, что на самом деле это очень серьезное ограничение. Когда вы решаете задачу, которая состоит из маленького, из какого-то числа маленьких адективных участков, которые обязательно должны быть адективны. И только в этом случае это действие будет рационально. После того, как появился Сатан Барта и появилось, так называемое, вот это подкликание с обучением, на самом деле, как бы, хорошие-то книжки не те. Хорошие книжки, это вот книжки хорошие. Вот я покажу вам. Это нейродинамическое программирование Берцекоса. Вот хорошая книжка. Не Сатан Барта. Или вот эта хорошая книжка. Approximation Dynamic Programming. Ворона Павла. Это книги людей, которые решали задачи, которые решали проблемы, а не гоняли шарики. Эти люди говорят, что после того, как появился Сатан Барта, к подкреплениям стали относиться, как будто это какой-то инструмент программирования. Вот я могу подкрепление увеличить, могу как фичу его добавить, могу его взять, допустим, встроить какую-то функцию, наложить на него условия, а в этом случае даю, могу, не даю. В связи с тем, что, конечно, так можно программировать, это и будет та самая манипуляционная техника программирования, reinforcement design, не reinforcement design, а reward design, то есть способ дизайна этого реварда. Но это не будет иметь никакого отношения к исходной как бы идее, состоящей в том, что на самом деле мы-то хотим научить, не подкрепить существующее решение, которое уже есть. А вот что делать, как научить, это вопрос обучения с учителем. На самом деле, но это нас уведет далеко, нужна когнитивная карта, то есть без нее невозможно туда, сигналы учителя становятся случайными. В общем, это уже отдельный вопрос. Поэтому я хочу сказать, что, как всегда, вопрос у нас с терминологией. Он уперся в вопрос о том, что такое подкрепление. Поскольку мы об этом не договорились, в расширительном смысле подкрепление начинают называть и вещи, связанные со знаками, и путаница между сигналами с учителем и подкреплением. Вот я просто хотел обратить внимание, что здесь есть такая терминологическая вещь. Спасибо большое. И спасибо большое Николаю, который, как всегда, абсолютно точно и совершенно фундаментально сразу это сказал. Вы же понимаете, что она уже должна уметь это делать, прежде чем вы ее начинаете подкреплять. Спасибо. 

S07 [01:45:03]  : Сергей, спасибо. Единственное, я сразу вбил название, которое вы упомянули. Там вышла страничка, которую я сейчас расшарил в чатике, и на ней ссылка есть на учебник. который в формате PDF, там ссылка «скачайте», вот она битая. Если вы поделитесь этим учебником, будет здорово. Каким учебником? Твоим же. Моим учебником? 

S09 [01:45:28]  : Я не клал никакую ссылку сюда. 

S07 [01:45:30]  : Откройте эту ссылку, которая в чатике. 

S09 [01:45:36]  : Чат передо мной, так, а что там? 

S07 [01:45:38]  : Ссылка там есть. На allmath.ru. Ещё раз, куда? 

S09 [01:45:44]  : Ну, по ссылке кликните просто, Сергей. Я не вижу ссылки, я вот чат листаю. Второе сообщение снизу. Allmath вот этот вот? Да, да, да. А что там такое? Ну, зайдите. А, ну зашел. Ну так это ж не моя ссылка. Дело в том, что мои лекции бродят по интернету вообще без моего ведома. У меня есть учебник по нейронным сетям, которому уже 25 лет. Я его находил даже в монгольских сайтах. 

S07 [01:46:13]  : Я понял. Я к тому, что там говорится про ваш учебник, а ссылки на него нет. Если он у вас есть, вы можете его расшарить. 

S09 [01:46:22]  : Дмитрий, спасибо большое. Я раз понимаю это просто как комплимент. Он очень сильно устарел. Потому что это фактически позиция сразу после backpropagation. Это понимаете того времени, когда... Хорошо, я понял, но я думаю, что это только с исторической точки зрения интересно. Жене моей интересно, наверное. Ну-ка мне покажу. Хотя, ну, конечно, я попробую найти. 

S07 [01:46:52]  : Так, ладно, давайте пойдем по вопросам. 

S09 [01:46:55]  : Но все-таки давайте вот этот момент важный с тем, что знак с подкреплением. Вот я хотел бы, чтобы у Антона тоже было, Антон как-то правильно отреагировал, ну в смысле неправильно, а как-то отреагировал, что на самом деле принципиальный момент, что есть подкрепление, и у подкрепления не может быть отрицательного знака то, что он становится сигналом учителя. 

S03 [01:47:14]  : Сергей, а можно к тебе вопрос? Вот я в целом согласен с твоими тезисами со всеми, привет. Да, привет. Но там, после того, в частности, что подкрепление в сегодняшнем его виде не способно, это типа не обучение. Ну, как бы там, спорный тезис, но, допустим, согласились. но там ведущая контора сегодня, ведущие две конторы, которые сегодня этим занимаются, что DeepMind, что OpenAI, ну я бы сказал, что они явно демонстрируют, что большим брутфорсом и количеством... Не-не-не, Игорь, ровно это наоборот они демонстрируют. 

S09 [01:47:57]  : Во-первых, смотри, два утверждения, которые очень важны. Дмитрий, можно еще минуту? Да, конечно. Игорь, надо очень-очень четко это понимать. Во-первых, если ты следишь за публикациями DeepMind, то обрати внимание, у них сейчас везде появляется слово каузал, каузальное обучение. Потому что они поняли, что на тех играх Atari, вот если ты дальше посмотришь на игры Atari как таковые, отсортируешь их по результатам, которые получены по играм Atari, и как нормальный специалист посмотришь не на верхние строчки, которые предназначены для журналистов, а посмотришь на нижние строчки, ты увидишь, что там много игр, у которых результат просто строго ноль. То есть никакого прогресса вообще. А дальше название этих игр есть, их легко найти и посмотреть просто, а в чем состоит смысл этих игр. И сразу станет понятно, почему никакого, обращаю твое внимание, нулевого, строго нулевой прогресса, никакого прогресса в области с использованием реформ в этих играх нет и не ожидается. Потому что во всех этих играх требуется формирование промежуточных смысловых когнитивных структур при условии, что они выполнены, а это мера ноль. Рейфмонт Сент-Лени не может достичь меры 0. Он может достичь меры 5%, может даже 0-1%. Но в тех играх, где требуется мера 0, то есть логическое условие требуется, чтобы выполнилось, они не способны это сделать. Это сразу совершенно видно. И поэтому сегодняшние ссылки совсем другие. Я даже не знаю, времени нет, но слово casual теперь стало ключевым. Причем обращает твое внимание. в Калифорнийском университете. Калифорнийский университет. Фу ты господи боже мой. Колумбийский конечно. Колумбийский университет. То есть тот университет в котором был создан Манхэттенский проект. В нем создана лаборатория которая называется каузальная reinforcement learning. Руководитель лаборатории Баренбой, один из учеников Джуди Пирла, который уже много лет пытается объяснить людям, что они делают. Это сигнал, это принципиальный месседж. Дипмайнеры сейчас все пишут слово каузальный, потому что они поняли, что принципиально вообще невозможно достигнуть ничего, если внутри нет каузальной причинной какой-то структуры, на которую можно основывать это обучение. Это просто, ну вот, что называется Search Google, архив 

S03 [01:50:31]  : козла ресурс от ленин и ты увидишь 21 год он весь в 21 году ни одной публикации с ритуалом и без слов козла вообще нету вот это давай смотри вот я все-таки не могу удержаться я в целом с тобой согласен но ты делаешь одну это не то чтобы технологическую ошибку но но я хочу прояснить одно использование термина твоего, который ты делаешь, как мне кажется, еще ряд людей, когда под словом reinforcement learning понимают сразу две вещи. Значит reinforcement learning с одной стороны обучение с подкреплением, это парадигма обучения, когда у тебя есть некая модель, неважно что внутри, которая там где-то действует, есть некий агент, да, и у него есть там положительные сигналы, отрицательные, и он в зависимости от этого меняет свое состояние, вырабатывает некие стратегии достижения цели в зависимости от сигналов. Это как бы парадигма. другая история это то что есть существующие глубокие сети которые определенным образом построены для того чтобы этой парадигме работать и они показывают определенные результаты большинство людей называет reinforcement learning именно как бы вторую историю. 

S09 [01:51:48]  : Игорь, мы говорим о профессорах, мы говорим о не программистах, которые программируют какие-то системы, мы говорим о профессорах ведущих университетов. Эти люди хорошо понимают, что они имеют ввиду. 

S03 [01:52:02]  : Подожди, ты сейчас, ты хорошо понимаешь, что имеешь ввиду. Ты хочешь сказать. 

S09 [01:52:07]  : Я не профессор. 

S03 [01:52:09]  : Ну, не суть. ты хочешь сказать, что reinforcement learning как бы как парадигма обучения, то есть как парадигма, состоящая в том, что у агента есть сигналы того, что он сделал правильно, того, что он сделал неправильно, и в зависимости от этих сигналов выстраивать свою внутреннюю картины мира и выбирать какую-то стратегию. 

S09 [01:52:29]  : Но то, что ты говоришь, это парадигма обучения с учителем. Нету сигналов правильно-неправильно. 

S03 [01:52:36]  : Нет. Вот я с тобой не согласен, потому что в концепции... Вот тогда вопрос определения. Подожди. Верно. Вопрос определения. В концепции reinforcement learning концепции обучения с подкреплением не сказано откуда идут эти подкрепления. не сказано. они могут формироваться средой, они могут быть учителем и в этом смысле я как раз и считаю что ты сразу в одном термине хоронишь смешивая две вещи в одном термине, ты хоронишь одновременно позитивную часть в нем. 

S09 [01:53:10]  : Игорь, в обучении с подкреплением нет позитивной части. Надо понять это. Люди это поймут уже быстро. Большое количество людей это понимает. Это манипулятивная практика, которая состоит в том, что мы должны обмануть агента подсунуть ему таким способом такие яблоки, чтобы он, не зная о том, что он делает, вдруг решил ту задачу, которую мы хотим, чтобы он решил. Так вот это и есть обучение с подкреплением как парадигма. Но дело в том, что на этом пути возникает проблема. А именно, агент не может найти, таким образом используя только яблоки, те решения, которые требует поиска на уровне меры 0, на уровне логических соотношений между ними. И эта парадигма, она, к сожалению, Разрушилась как таковая, потому что ее же прорабатывали для агентов, не для того, чтобы на агентах применять. Конечно, ее прорабатывали для того, чтобы на людях применять. Это же очевидно, боже мой. Это как детский сад. Это способ, как можно управлять системой сложной. Вот что такое самообучение. Так вот выяснилось, что нет, есть ограничения, проблема есть на этом пути. И сейчас люди сходят аккуратно. Дипмайн, ты увидишь, что слово reinforcement исчезнет. Буквально через два года оно исчезнет медленно, тихонько. оно бы сначала заменено бы таким гибридным Лёнин, потом будет написано какой-нибудь там что-то еще Лёнин так, чтобы люди забыли это слово, потому что это оказалось плохо проданной идеей. Вот что я только хочу сказать. 

S03 [01:54:49]  : Видимо, мы с тобой просто по-разному понимаем объем того, что вкладывается в понятие reinforcement learning. У меня такое ощущение, что ты его понимаешь немножко чем я может быть я его неправильно понимаю я перечитаю не буду спорить И перечитать. 

S07 [01:55:03]  : Видимо, это должен был сделать DeepMind прежде всего, да, Сергей, судя по всему? 

S09 [01:55:07]  : Да, конечно, они первыми это сделали. Потому что именно они получили основные миллиарды долларов. Ребят, ну вы же все видели вот эту статью. Мне нет времени, к сожалению. У меня же есть это все скачано, я могу показать. Это casual reinforcement или casual mechanism of modern reinforcement signals. Вот такие названия пошли. А потом уже рефорс в конце статьи, а потом оно исчезнет. Я предсказываю. 

S07 [01:55:34]  : Запомните этот твит, что называется. Давайте посмотрим. Но если вы это все опишите еще где-то текстом, это будет очень здорово. 

S09 [01:55:41]  : Это просто поняли уже довольно давно. Уже в десятых годах это люди поняли. Или хотя бы ссылки дайте. 

S07 [01:55:47]  : У вас очень интересная мысль, Сергей. Я потом пересмотрю, поскольку мне как модератору сложно вникать еще и в слова. Но явно вы говорите, что это очень революционно. Поэтому, конечно, об этом стоит еще поговорить. Вы не меня читайте. 

S09 [01:56:01]  : Вы читайте Джуди Пирла. Джуди Пирла, он пишет все. И Барен Бойм. Ключевое слово. Элия Барен Бойм. 

S07 [01:56:07]  : Прекрасно, что Джуди Перл не предлагает, как это решить. Нет, Джуди Перл хорош, он говорит, в чем проблема, но он не предлагает путей решения. 

S09 [01:56:16]  : Да ты что? Ну вот это уже я тут с этим не могу совершенно согласиться. Вот, например, смотри, вот потрясающая статья Элия Баренбойм и Джуди Пирл. Casual inference and data fusion problem. Большущий обзор, который рассказывает, как, в каких случаях, какие собранные данные, почему с ними можно обучать систему, почему с ними нельзя обучать систему, какие данные всегда обязательно по определению запутают обучение с метками и с этим самым, для каких можно строить эти вопросы. таких статей это очень много и причем это же это вот вот люди ребят запомните вот эти вот или барон бой и джуди пил вот их читайте не меня я я я я учусь хорошо все эмоциональность этого товарища я запомнил до смысле джуди пил я уже давно знал вот этого 

S07 [01:57:21]  : Баренбой. 

S06 [01:57:23]  : Я уже нашел. 

S07 [01:57:24]  : Я нашел его, потом ссылку сброшу в чат. Вот так. Прикольная такая жаркая дискуссия. Мне нравится. Редко такое бывает. 

S09 [01:57:34]  : Я прошу прощения, я просто давно уже в этом ворюсь. Двадцать лет на это думаю, ну просто вы понимаете так же. 

S07 [01:57:45]  : Так, тогда давайте вернемся к спикерам нашим первым. У нас, получается, первым был тогда Евгений Евгеньевич. Вот. И у меня… Так, я не знаю. Вот, собственно, Борис Новиков. И мой вопрос тоже схожий, по сути. Вот у вас там, Евгений Евгеньевич, была иерархия целей такая, да? Но вообще, мне кажется, цель – это же такая верхнеуровневая штука. Она сама по себе ниоткуда не возьмется. Мы когда начинаем чему-то учиться, никто цели нам не дает в готовом виде. Они у вас откуда берутся вообще в вашей архитектуре? 

S06 [01:58:23]  : На самом деле цель – это любое желание. Есть самый хороший пример цели – это желание новизны. Мы живем в стандартной ситуации, она нам надоела. У человека есть даже такая потребность – новизна. Так вот, у этой новизны, может быть, нет точной формировки, но зато есть совершенно точные критерии, мы эту новизну получим или не получим. Вот пойдем к какой-то новоместной, мы ее, так сказать, удовлетворим или нет. И вот сам факт удовлетворения каким-то стимулом, вот это и есть, что на самом деле у нас была формулировка этой потребности, и мы ее, так сказать, удовлетворили. Может быть, даже это нельзя точно определить формально. Но тот факт, что она была и мы ее удовлетворили, Вот он и фиксирует, как раз такая цель была, и она потом достигнута, и все. Они могут быть очень разные, многоуровневые, иногда могут быть размытые. Но самый важный критерий, что это велание, цель, или, так сказать, задача, она была, потом она была снята. В некоторой ситуации, в некотором решении. 

S07 [01:59:36]  : Честно говоря, я все равно, конечно, не понял, но ладно. Просто смотрите, допустим, у нас есть игра в шашки, и непонятно, что нужно делать. Никто не говорит «выиграй». Условно, если агент играет в шашки, у него нет цели выиграть. Он просто начинает как-то ходить, только потом узнает, что он выиграл. Кто должен поставить цель такому агенту? Он же сам должен себе ставить. 

S06 [02:00:04]  : На самом деле есть еще такой более простой эксперимент. Вот кошку запускают в незнакомую комнату. Что она делает прежде всего? Она ее обследует. Вот она хочет построить модель мира. Это есть отдельная даже функциональная система. Нужно исследовать эту обстановку. Вот какая у нее цель? В точности она не формулируется. Но освоение этой ситуации, освоение вот этой обстановки, это есть отдельная функциональная система, которая это изучает. Для этого нет фиксированного набора действия, для этого нет заданных алгоритмов. Она просто изучает самое главное, какой эффект она в конце концов получит. Она знает, где что лежит. Вот когда она уже знает, где что лежит, у нее есть Некоторая модель этой реальности, она успокаивается. В этом случае этот цель достигнута. Действие могло быть достаточно разнообразным. 

S07 [02:01:01]  : Хотелось бы понять, как она конкретно это делает. Давайте это уже слишком долго углубляемся. Давайте спросим Николая Робчевского. Николай, вы здесь? Да, здесь. Скажите, вы же тоже делаете какую-то архитектуру? У вас же тоже есть какие-то конкретные наработки? У вас там вообще используется реинфорсмент в каком-то виде? 

S02 [02:01:25]  : Нет, не используется. 

S07 [02:01:28]  : Я знал, что вы скажете нет, потому что вы выступаете идеологическим противником. Неужели вы можете обойтись только ассоциативным обучением? 

S02 [02:01:47]  : Которую я пытаюсь реализовывать, и она в какой-то степени опробирована, заключается в том, что на основании накопленного в прошлом опыта мы получаем возможность прогнозировать результаты наших действий. Если мы умеем прогнозировать результаты действий, то нам достаточно иметь критерии полезности результата для того, чтобы выбрать правильное, исходя из наших предпочтений, действие. А для того, чтобы получить оценку полезности, мы должны иметь некий модуль, который будет говорить о том, как эту оценку формировать в зависимости от ситуации. То есть, если, скажем, у нас давно не ели, то наша оценка перспектив будет зависеть от того, как скоро мы сможем поесть. Если мы сыты, но попали в незнакомое место, то наша оценка будет доминирующую вещь того, о чем говорил сейчас Евгений Витяев. То есть получить удовольствие от того, что мы узнаем что-то новое, исследуем environment. То есть получается такая многоуровневая структура. Во-первых, способность прогнозировать, исходя из прошлого опыта, который должен быть запомнен. Второе – это оценка ситуации, которая в сжатом виде показывает ситуацию как вне, так и внутри системы. То есть холодно, жарко, сытый, голодный, уставший, интересно, неинтересно и так далее. И модуль мотивации, который конструирует текущую единственную оценку, исходя из вот этих компонент. В какой доле, так сказать, они должны входить для того, чтобы провести оценку к единому числовому показателю, который позволит выбрать лучший. Потому что выбор лучшего – это всегда сравнение двух чисел. Одно больше, другое меньше. То есть текущая свертка ситуации в одну функцию И выбор из вариантов, который дает нам прогноз на будущее. То есть это чисто цепочка, которая формализуема на каждом этапе. Я понятно объяснил или не очень? 

S07 [02:05:17]  : Мне сложно все равно ориентироваться, поскольку я читаю вопросы. Я потом буду пересматривать и задавать вопросы. 

S02 [02:05:24]  : Я даю ссылки на мой блог, который еженедельно появляется, начиная с какого-то времени. тексты, которые будут более подробно объяснять весь этот процесс. 

S07 [02:05:45]  : Хорошо. Следующая архитектура у нас Игоря Пиловарова. Игорь, вы с нами? 

S03 [02:05:55]  : Да, я здесь. Честно, я не очень понимаю 

S07 [02:06:00]  : смысл рассказывать про... Не-не-не, смотрите, я не про архитектуру Марти, я про теннисиста, который наш, значит, выходит на теннисный корт, и вначале он вообще ничего не умеет, потом он учится держать ракетку, потом он там как-то учится мяч отбивать очень просто. Но смотрите, вот допустим, вот он, допустим, научился даже мяч отбивать. Теперь ему нужно выиграть турнир, и получается это у нас такая целая большая иерархия цели, которую он должен держать в голове. Не получится ли нам, что одного постепенного расширения горизонта реинфорсмента, как вы говорили, хватит, чтобы Дальше комбинаторно не перебирать все маленькие цели, потом более крупные цели. Потому что чем выше в уровне целей мы поднимаемся, тем нам сложнее их дальше комбинировать, чтобы прийти к какой-то очень высокоуровневой степени. Понятно ли я формулирую вопрос? 

S03 [02:07:06]  : В жизни-то это работает, с людьми это работает, такое постепенное усложнение задачи постепенно безусловно работает. Другой вопрос, что меня, конечно, Терехов озадачил своими соображениями по поводу реинфорсмента Ленинга, я тут полез перечитывать определения, и у меня вообще, ну там, у меня сейчас пока внутреннее противоречие такое сформировалось, я сейчас про него думаю, что является вообще Что является рефорсным тренингом, что не является. Ну, кстати, я пока скажу, вот там был коммент по поводу боепропагейшена. вот это проще отметить, что backpropagation точно не является подкреплением, это как бы элемент архитектуры в прямом виде. без использования backpropagation нейронная сеть в принципе учиться не будет, это просто элемент, это как бы механизм корректировки весов и так далее. это не есть подкрепление в смысле там какой-то от среды или от учителя еще что-то. но вот у меня вот какой бы сейчас извини это я не то чтобы я на твой вопрос не отвечаю в каком-то смысле комик мне кажется он такой но вот там вполне себе был самостоятельно но я хочу вернуться вот к тезису который сейчас сергей терехов говорил и вообще как бы осмыслить для импульсного тренинга вот у меня есть непонимание опытный айджим которые вот эти игры от ари это что это это в чистом виде обучение без учителя вот когда когда модель получает там балл за удачно сыгранную игру или или минус балл за неудачно сыгранную игру это мы это можно классифицировать как ответ среды без какого-либо То есть, это стопроцентно мы классифицируем как обучение без учителя? 

S01 [02:09:10]  : Игорь, ну там же нет никакого учителя. Там даже есть его environment называется. Там нет интерфейса teacher. Там есть интерфейс environment. 

S03 [02:09:19]  : Постой, постой. Ты быстро отвечаешь. Я прекрасно понимаю, что нет интерфейса teacher. тебе сказать? Вот в жизни, в обычной жизни, у нас не бывает таких ситуаций. Вот сейчас, как бы сказать, в чем задача учителя? Задача учителя ясно тебе сказать, что ты делаешь правильно, а что сделаешь неправильно, и корректировать твое поведение для того, чтобы добиваться правильных результатов. Но обычно это делает учитель. он там есть много разных функций можно там как бы передавать опыт может элементы манипуляции использовать тоже сейчас подожди подожди но я другое я например в своей жизни не знаю как как ты сергей не знаю как вы коллеги но у меня было очень мало ситуации когда я ясно понимал и что делается хорошо, что делается плохо. В школе это понятно. Вот тебя учат, тебе говорят, да вот сделал правильно, там написал правильно, решил правильно, значит решил неправильно. А в обычной жизни, если мы не берем как бы школу, берем как бы некую среду просто абстрактную среду среда не говорит тебе ясно что ты сделал хорошо что сделал плохо это все размыто но почему ты не отвечаешь сразу ты как бы сразу быстро говоришь нет потому что ты в рамках я просто хочу сказать что в обычной жизни есть понятие обучения например какой-то технологии 

S09 [02:10:45]  : Вот человеку дают какое-то технологийное производство и говорят, работая по этой технологии, отклонения от нее правильно будут количественно оцениваться. Это обучение с учителем. 

S03 [02:10:55]  : Да, обучение с учителем, верно. Его много в жизни. Хорошо, вот Open AI Gym, игра в Atari. где по результатам этих 50 шагов я получаю модель получает ясный ответ она сыграла правильно или неправильно это обучение без учителя или с учителем если оценка количественная и ты можешь ее как количественную использовать для улучшения своей ситуации это отсроченный сигнал учителя если ты играешь с противником и просто выиграл или нет 

S09 [02:11:28]  : то это попытка обучаться из реинфорсмента. 

S01 [02:11:32]  : Коллеги, Игорь, Сергей, вы меня извините, но если я играю в футбол мячом, если я вышел в лес и пинаю там, шишку пинаю, и от этой шишки попадаю в дерево, нет, где тут учитель? Кто учитель, дерево или шишка? 

S09 [02:11:49]  : Твои глаза, учитель, потому что ты себе выбрал сигнал. 

S01 [02:11:52]  : Тогда это самообучение, тогда это самообучение. Подожди, подожди, подожди. 

S09 [02:11:56]  : Тоже имею право сказать, тоже один из спикеров. 

S01 [02:11:59]  : Смотрите, вот 21 год назад, когда еще не было термина reinforcement learning, Был у Герцеля термин experiential learning. Я там специально кинул ссылки. Сейчас в машинном обучении термин experiential learning вообще не используется. Для того, что сейчас называется reinforcement learning, У нас 21 год назад был термин «Experiential Learning» – это обучение на опыте. Что является опытом? Если ребенок побежал и стукнулся коленкой о пол, потому что упал, ему больно – это опыт. Если он побежал, а его поймали за шиворот и шлепка по попе – это тоже опыт. И в данном случае, неважно, опыт этот получается от живого папы или от мертвого пола. Это подкрепление. Если мы говорим про reinforcement learning, то нет разницы, учимся ли мы играть в футбол шишкой, которая выросла в лесу без всякой помощи человека, или мы учимся играть в пинг-понг на столе, который сделал папа, или мы учимся играть в Atari на компьютер, который написали какие-то программисты. Ну, мы можем сказать, что если мы играем в компьютер, то учителями являются программисты, которые написали эту программу. Вот. Тогда мы должны сказать, что вот тот человек, который посадил дерево, с которого выросла шишка, которой мы играем в футбол, что он учитель. 

S03 [02:13:43]  : ты утрируешь. во-первых, когда ты ты говоришь, играя в футбол шишкой. если ты взял шишку... ну, во-первых, нельзя играть в футбол шишкой. шишку можно кинуть, допустим, в дерево. я могу пнуть ногой. господи, ну пнуть ногой, хорошо. когда ты пинаешь ногой шишку и пытаешься попасть в дерево, ты сам себе В этом месте поставил цель. Ты не просто так пнул шишку, ты ее пнул для того, чтобы попасть в дерево. И у тебя появился сразу моментальный критерий. И ты, как учитель, сам себе поставил задачу. Но это мы уже начинаем игру определения. Нет, нет, нет. Ты здесь приводишь неправильную аналогию, которая уходит в сторону. Мне она кажется некорректной. 

S02 [02:14:25]  : пинание шишки в лесу это не то вот правда это не то здесь тоньше дайте николай рабчевский там явно хочет дискуссию а я хочу сказать вот что что когда мы пинаем шишку или мячик или играемся с ракеткой то мы учимся безусловно Но при этом у нас нет оценок. Или они есть необязательными. Мы не ставим перед собой никакой цели зачастую. Мы просто делаем что-то и смотрим, а что у нас получается. И это, да, это обучение на экспериментах. Но это обучение не с целью получить плюс или минус, получить удовольствие или неудовольствие. То есть удовольствие может быть только в одном. Я научился тому, чему я раньше не умел. Обнаружил некую возможность сделать то, о чем я раньше не знал. То есть это накопление просто опыта. Накопление некой базы для того, чтобы выбирать оттуда, когда нам нужно будет уже делать нечто целесообразное. С этим я согласен. Вот и то, что я хотел добавить. 

S01 [02:16:04]  : Короткая ремарка и замолкаю. Вообще мы, на самом деле, запутались в собственных терминах, потому что в англоязычной литературе вообще нет термина обучения с учителем. Если вы откроете Википедию, вы обнаружите, что supervised learning Это не обучение с учителем. Это обучение на тестовых выборках. Вот у нас в Атаре у нас тестовых выборках нет. Фу. В пинг-понге и в OpenAI Gym у нас нет обучающих выборок. У нас есть взаимодействие с виртуальной средой. Поэтому о некаком Supervised Learning речи не уйдет лет. И о никаком обучении с учителем речи нет. 

S03 [02:16:40]  : Потому что нет такого термина обучение с учителем. Я не говорил про Supervised Learning. Я не говорил, что Atari это супервайс ленинг. Мой вопрос был другой. Является ли Open AI Gym с этим пинг-понгом обучением без учителя действительно или нет? 

S09 [02:16:58]  : Игорь, оно является обучением без учителя, вернее попыткой узнать, можно ли, используя механизмы обучения только с подкреплением, достичь результата. Это экспериментальная попытка выяснить можно ли вот в каких-то играх Atari можно, а в каких-то нет. Вот результат сегодняшнего этого большого 20-летнего эксперимента. 

S03 [02:17:21]  : Хорошо, в общем я еще подумаю, ладно. 

S07 [02:17:24]  : Олеге еще слово просил Олег Серебренников, пожалуйста. 

S08 [02:17:29]  : Да, добрый день. Пару слов просто хочу сказать. Извините, я тут прерваться вынужден был, так что не всё слышал. Может быть, где-то повторюсь. Ну вот, знаете, дискуссия, она заставляет мне задать вопрос самому себе. Можно ли представить то, что представить нельзя? Нельзя, да? Представить то, что представить нельзя. Я к чему говорю? К тому, что если у меня в картине мира чего-то нет, То есть вот этого нет. Это с одной стороны. Если это новизна, то она должна быть все равно укладываться в картину мира. То есть вот невозможно захотеть полететь на Солнце. Вот это трудно очень. Представьте себе, чтобы в здравом уме человек это захотел сделать. Потому что это невозможно сделать из того, что мы знаем о мире. Поэтому нужно понимать, Мир – это причина следственной связи. Вот реплика, о которой кто-то говорил, что reasoning – это, по-моему, не важно. Causal relationships и так далее. Вот эти relationships, causal relationships, они подсказывают нам, что возможно и что нет. Вот идешь ты по лесу, пнул шишку. Неважно, почему ты это сделал, но ты точно знал, что это сделать можно. Пнул бы ты пень, вопрос. В детстве когда-то ты его пытался пнуть, возможно, какой-то тяжелый предмет, но ты быстро дошел до того, что, так сказать, самому больнее, поэтому лучше не делать. И пень тоже, ты знаешь, что он имеет корни, то есть у тебя есть картина мира, в которой он, даже если он легкий, по нему пинать нельзя, потому что он имеет корни, и он не сдвинется, сдвинется твоя нога, сломается. Это первое замечание. Второе замечание по поводу Atari, игр Atari. Ну, смотрите. Берём игру, о которой чаще всего разговариваем – пинг-понг. Там совершенно чётко есть Граница, граница селф, так называемая, когда вот где-то я нахожусь, а где-то не я, то есть вот где-то среда, которой я могу управлять, я могу свое селф. Как бы продлить дальше? Что значит продлить? Первое, у меня есть рука. Вот у меня есть возможность передвигать так называемую ракетку, но это рука на самом деле. И рукой я могу встретить мячик, могу не встретить мячик. Мячик – это среда. У него есть закон движения у этого шарика. Я его не придумал. Вот это объективная реальность. И вот когда берем и вдруг смешиваем то, чем я могу управлять, и то, чем я… не то, что я управлять не могу, то, что уже известно, как оно работает, достаточно causal relationship как раз. То есть если мы уже знаем, как это работает, и мы понимаем и закон, по которому он движется, мы можем дальше аппроксимировать уже свои действия. И вот вопрос здесь как раз. Где здесь подкрепление? Вы извините, если я умею действовать рукой, то есть я могу встретить мяч. Проблема не в том, что я встретить мяч не могу, я могу. Проблема в том, чтобы я имел такую цель встретить мяч определенным образом. Или наоборот его пропустить, что в примере Николая часто звучит. Вот в чем дело. А это отношение имеет к целям, с которыми я это делаю. Следовательно, есть модель мира, в которой есть я и среда, есть законы, которые я наблюдаю в среде и которые я могу предсказывать, и есть цель. И вот цель накладывается на всю эту историю со мной внутри среды и с законами, и с моими возможностями управления мной, и через меня, частью среды, в данном случае Шариком. Зная, как он движется. Вот, собственно, какая задача. Когда смешивают и кладут всю эту сложность огромную, вот эти слои, и вдруг их кладут в одну простую формулу Кулёнин, мне кажется это просто абсурдным на самом деле. Да, это работает. Ну а именно поэтому это работает только для конкретной игры. А вот как кто-то там говорит, что для каких-то игр не работает, потому что мир сложнее. То есть в простых случаях это можно сделать, а в приближенных к действительности нельзя. Вот, наверное, все. 

S03 [02:22:26]  : Олег, ну вы все правильно говорите, но там как бы реальность чуть другая. потому что для модели для нее нет руки вот представьте себе чтобы свою модель память последовательности завернули там в какой-то алгоритм и он подцепился к этому пинг-понгу модель не знает что это вот этот кусочек экрана этот кусочек рисунка это это это рука либо вы должны это как бы костылями описать как-то и там объяснить и как бы чтобы модель условно как-то знала то что это было связано либо она должна сама научиться что вот этот там что вот это действие является то что вы описали абсолютно правильно но это характеризует как бы наше внутреннее размышление как мы это делаем но модель делает 

S08 [02:23:15]  : Игорь, я перебью, извиняюсь. Я согласен тут и не согласен одновременно. Замечение разумное, безусловно, но давайте вернемся к тому, кем являемся мы сами. У вас дети есть, наверное? Вы наблюдали, когда родился ребенок, у него глаза смотрят в никуда. Потом он начинает обращать внимание на движущиеся предметы. видимо имеет корреляцию с какими-то сигналами, которые он пытается подать в среде. Он понимает, что вот он управляет вот этой штукой. Потом он узнает со временем, что это рука. Вопрос ведь не то. Условно говоря, если бы эти мозги ставили там Скорпиону, Искорпион бы видел, что шевелится лапа. Он бы никогда не узнал, что он должен был быть человеком и что мозги у него человечие, понимаете? То есть, он просто управлял бы клешнями этими. То есть, разницы нет. Поэтому, когда мы возвращаемся к Атаре и к тому, что внизу по координате Х движется условная ракетка, это и не ракетка ведь, верно? Это просто условное там нечто. Но важно другое. Важно, что наша свобода, как наша, как self, как я, вот моя свобода, она заключается только в этом. Первое – в управлении вот этой штукой, которая внизу движется. И второе – в изучении закона движения мячика. Потому что он от меня не зависит. Вот в чем соль. 

S03 [02:24:55]  : по этой причине у нас есть свобода я не знаю прошу прощения еще и два человека я не знаю как у вас но моя модель понятия не имеет что что есть мячик и что у него есть закон движения просто ну и ваши я честно говоря думаю тоже вы как бы смотрите последовательности которые появляются из этих последовательности вычленить что есть объект мячик у которого есть закон движения если вы это можете сделать я снимаю шляпу да я пока не понимаю но я могу объяснить у нас с вами была попытка обсудить но не получилось 

S08 [02:25:36]  : Уже не первый месяц замечу. И не потому, что я не готов. Но я не упрекаю, Игорь, это на самом деле просто есть, работает. 

S07 [02:25:46]  : Давайте дадим Александру Болдачеву, хотел сказать. Давайте только покоротенько, потому что еще один человек хочет. 

S05 [02:25:55]  : Добрый день. Спасибо всем. Было интересно. Две копейки, которые, кажется, проскочили мимо. Прежде всего нужно понимать, вот каждый, кто говорит, о каком уровне обучения мы говорим. Можно понимать обучение популяции одноклеточных тоже как обучение. Популяция через смерть отдельных особей, а популяция в конечном итоге переходит в новое состояние и чему-то обучает через смерть. Потом есть обучение, скажем, ручейника, который, не умирая, подбирает камушки. То же самое происходит, скажем, какое-то обучение уже у высших животных при помощи мамы и папы, подражание. Есть обучение на уровне человека, маленького ребенка, которому уже объясняют, объясняет, что делать. Он ничего не пробует, ему объясняют, и он это делает. Есть обучение на уровне предоставления моделей готовых. То есть в школе и в институте нам целые готовые учебники с моделями пытаются отдать. И есть следующее еще обучение, когда мы сами строим эти модели, исследуем мир и строим новые теории. Какая цель? На уровне одноклеточных, на уровне ручейника, на уровне, скажем, обучения в стае волков, на уровне обучения ребенка, на уровне обучения в институте или на уровне обучения в НИИ, когда создаются новые модели. На каком уровне мы хотим создать систему? То есть есть задача именно на уровне отбивать пинг-понг, то можете сами понять, на каком это уровне находится относительно человеческого интеллекта. У меня все. Спасибо. 

S07 [02:27:37]  : Спасибо. Иван, вы хотели сказать что-то? Да, здравствуйте. 

S04 [02:27:44]  : Слышно меня хорошо? Да, хорошо. Надеюсь, не проблема, что без видео. Насчет того, что у нас есть агент, и он в каждый момент времени не может знать, вернее, не так, наоборот, Я предполагаю, что можно сделать, чтобы в каждый момент времени агент мог текущее свое состояние, насколько оно хорошее в количественном выражении, то есть числом, определять, даже если он раньше в таком состоянии не был. Кто занимается нейронными сетями, то представим, что у нас трехслойная нейронная сеть. и на каждом слое какое-то количество нейронов. Так вот, когда мы подкрепляем такого агента, мы этими нейронами можем выразить какое-либо состояние в какой-то момент времени. Я понятно объясняю? Знаете, наверное, все это. В какой-то момент времени можно это просто входной сигнал от времени t. если мы подкрепляем агента в этот момент, то можно подкреплять каждый из отдельных нейронов. По сути, у каждого нейрона отдельного есть какое-то число, которое говорит, насколько этот нейрон был подкреплен положительно или отрицательно. Или, допустим, у нас всего одна шкала у каждого нейрона, мы можем подкреплять его положительно или отрицательно. Если отрицательно, значит уменьшать эту шкалу. Таким образом, у каждого нейрона у нас будет свой уровень подкрепления, а это значит, что в других ситуациях, в которых подкрепления не было, паттерн поменялся, но все равно у каждого нейрона есть какое-то подкрепление. Мы суммируем все это и получаем оценку текущего состояния. Причем неважно, что мы там никогда в этом состоянии раньше не были, мы все равно какую-то примерно оценку текущего состояния получаем. А это значит, что мы можем наши потенциальные действия оценить с точки зрения того, приведут они в лучшее состояние или в худшее. То есть сначала изначально у нас, не у каждого нейрона есть такая оценка, Агент обучается, и в итоге получается, что почти у каждого нейрона такая оценка, и в итоге мы можем почти каждое состояние оценить. Получается, что у нас возникает пространство, уже как бы размеченное. Пространство состояния становится размеченным подкреплениями разными. И мы можем от одного к другому переходить. Это одно, что я хотел рассказать. Второе – это насчет отложенного подкрепления. Насчет отложенного подкрепления. Дело в том, что события, которые происходили в прошлом, некоторые из них могли привести к какому-то положительному результату. Сейчас у нас время t0 и было подкрепление, а там есть время t-10, когда у нас случилось какое-то событие. Нам не нужно проверять каждое из событий, не стало ли оно причиной этого подкрепления. Мы можем часть событий выкинуть. Мы можем оставить самые подкрепленные события, самые часто повторяющиеся, и мы можем оставить события, в которых был максимальным показатель удивления. Вот еще важный момент. Я называю это показатель удивления. чисто технически это когда у нас предыдущий паттерн и последующий оказались наименее предсказуемыми. они наименее предсказуемы и поэтому у нас повышается уровень Если они более предсказуемы, то уменьшается уровень удивления. Мы можем просто из прошлого, из памяти, у нас есть какие-то память событий, мы можем выкинуть очень много лишнего. Получается, что у нас получается несколько гипотез у агента. И у человека точно так же. Если что-то произошло в прошлом и получился какой-то положительный результат, на самом деле, если это первый раз, если это ни на что не напоминает, что было в прошлом, то мы не знаем. Поэтому мы проверяем значимость события в прошлом, явились ли они результатом. Вот это еще момент. ну, вроде бы, вот эти два момента. 

S03 [02:32:54]  : Иван, а вопрос, а вы реально моделировали или это просто соображение? 

S04 [02:33:02]  : Пока это соображение. 

S03 [02:33:04]  : А вы помоделируйте. Соображения хорошие, как бы бесспорные, но надо помоделировать, тогда станет понятно, что не все реализуем. 

S07 [02:33:13]  : За счету Ивана скажу, что я пробовал моделировать то, что Иван сказал, новизна, то есть в моей модели ощущение новизны является сигналом рин-форса, которое позволяет агенту искать новизну. Это действительно гораздо сложнее сделать, чем сказать, но, тем не менее, смысл Ивана довольно-таки точно отразится. 

S03 [02:33:43]  : А результат какой? 

S07 [02:33:46]  : Агент ищет новизну. 

S03 [02:33:48]  : Нашел? Практика критерий теории. Я тоже могу рассказать, какие гипотезы я реализую, пытаюсь реализовать в своей модели. 100-500. И по поводу того, какие события вычли, много разных гипотез. Но, блин, работать должно. И пока это не работает, пока нет представленного результата, но как бы можно сколько угодно разных предположений выдвинуть, как оно должно быть, но мы не знаем, как оно реально будет работать. Понимаешь, я вот к чему. Удивление выглядит симпатично, но работает ли оно, я не знаю. 

S07 [02:34:29]  : стимул к этому стремиться, хотя бы потому, что мы так работаем. Нам любопытство очень важно и играет большую роль в нашем же обучении. Мы зачем-то все гоняем смотреть на другие страны, это явно нас драйвит, тяга к новизне. То, что мы пока это не реализовали, наверняка причина в том, что это сложновато. Это какая-то очень непростая схема. 

S03 [02:34:56]  : В случае обучения, скажем, там точно другая история. Вот, например, то, о чем говорит Сергей Терехов по поводу, допустим, игрушки. Ну, условно, есть там игра, допустим, там человечек прыгает, и он, допустим, должен там сперва пропрыгать там какой-то один кусочек, запрыгнуть там на платформу, она, значит, ездит, а потом он с нее, условно, должен прыгнуть дальше и там допрыгнуть до цели. Вот одна подзадачка – запрыгнуть на платформу, а другая задачка – прыгнуть дальше. И в этом смысле, когда мы получаем финальное подкрепление только в конце, за то, что мы допрыгнули до цели, то агент совершенно не знает, было ли это связано там в середине с прыжком на эту платформу. Он случайно, допустим, там прыгнул, а в следующий раз он не прыгнет на нее или он прыгнет на нее в другое место. В этом смысле правильное промежуточное действие, которое было сделано, оно никак не следует из финального подкрепления. Я не очень понимаю, где здесь механизм удивления, честно говоря, потому что в данной ситуации нужно отрабатывать как бы правильный прыжок, ну вот этими терминами. Это вопрос не удивления, а как бы, если хотите, в технике прыжка. 

S07 [02:36:08]  : Вот, смотри, есть большая разница между обучением агента в средах, где есть конкретная цель, да, и он просто ищет награды от этой среды, и обучением в средах, где целей вообще нет. Ну вот, я не знаю, посади ребёнка просто в комнате, да, и дай им игрушки. Какая у него цель? Нет у неё никакой цели. Но он, тем не менее, начинает играть, потому что ему интересно, да, он хочет получить какие-то новые ощущения. И это как раз задача гораздо ближе к AGI по сути своей. Понимаешь? Ну это уже целая отдельная тема, которую, ну как сказать, пока надо подумать, а потом, может быть, еще и отдельно это все обсудить. Потому что у меня тут как раз, я топлю как раз за этот self reinforcement, у которого одна из один из драйвов это новизна я прям за него конкретно топлю и исследует вот так еще хотел проблема зависают у телевизора агенты если можно очень короткие комментарии владимир секунд Ну ладно, давайте микрофон. 

S02 [02:37:22]  : Что считать новизной? Результат какого-то действия или всю цепочку действий? Если мы считаем результат полученный, то тогда получается то, о чем говорил Игорь Пивоваров. А если мы считаем всю цепочку новизной, то есть когда последовательное действие получилось такое, какое мы раньше не видели, Тогда, скорее всего, она будет то, о чём говорит Дмитрий Сальхов. Вот у меня всё. 

S07 [02:37:54]  : Так, ладно. И Смолин Владимирович, пусть завершит тогда своим словом. 

S10 [02:37:59]  : Ну, хорошо, я попробую. Может быть, было воспринято, что я не знаю всех этих сложностей. Но хочу сказать, что те люди, которые 20-25 лет в области, я считаю, что они здесь относительно недавно, чтобы это было понятно. И внуков у меня много, и детей, и опыт. Работал я в полубиологической лаборатории на рыбионике еще в 80-е годы. Вот, поэтому, значит, дело не в том, что я тут чего-то там не усёк, что вот это вот обучение с учителем, а это, значит, реинфорстинг, а в том, что у нас как бы всё свелось к выявлению определений. И определений мы хорошего, естественно, не дали, не дадим, потому что область вообще создания определений, она такая живая. То есть вот я наблюдал это много десятилетий, что определения меняются, называются одно и то же другими словами, И, в принципе, это очень полезно для продвижения тематики. Инвестор на старое не дает деньги, а на новое дает. И тема полезна. Ее, конечно, надо заниматься. Но кроме того, что есть систематизаторы, которые вводят новые определения, это полезно. Есть еще унификаторы, которые пытаются свести все более-менее к одному. Я себя отношу к последним, в смысле к унификаторам. Я все-таки дал какое-то определение, оно, может быть, не всех устроило, я так понял, что любое создание условий для изменения параметров – это и есть создание подкреплений для обучения. То есть, если что-то меняется, мы создали для этого условия, вот, собственно, мы наносим свои подкрепления. конечно, значит, тех, кто занимается спорами о том, что вот это вот reinforcement learning, а вот это вот experiential learning, еще что-нибудь, конечно, такое определение, оно неудоговоримо, его плохо продавать. но смысл, значит, как бы состоит в том, что Когда вы даёте много определений, ну, во-первых, слушатели теряются, и, конечно, для продажи это хорошо, если он вас не очень понимает, то вы ему выписываете что-то в тюрьме. Но, значит, для понимания белых хорошо бы всё-таки иметь какие-то простые определения. Я не буду против, если мы это как-то иначе назовём, но, значит, я хотел бы сказать, что все виды обучения в живых системах, они на самом деле связаны. То есть, чем больше разнообразие вариантов обучения, тем это лучше. Я вернусь к картинке, которая много нравится. В частности, Антону Полонину она нравилась. Если можно, я сейчас ее быстренько расшарю. это вот, собственно, плакат Немоя Яна Ликуна, и все его, наверное, много раз видели, я не буду подробно обсуждать, что есть, соответственно, reinforcement learning, supervised learning, self-supervised learning, но я еще добавляю, что есть еще возможность порождения зданий, то есть, как бы сказать, еще что, допустим, в 90-е и начале 00-х годов было, говорят, ну что, там ваша сеть может породить. Сейчас есть ГАНы, которые очень хорошо порождают различные ситуации. И поскольку опыт у всех субъективный, отвечая на повод того, что можно ли себе представить то, что непредставимо, то, конечно, можно. То есть, если я не могу что-то представить, то вы себе можете представить, а если вы не можете, значит, кто-то третий еще это может представить. Ну и, собственно, вопрос представления большой. Но если понять, для чего это порождается, то мы, значит, смотрим, порождаем новое издание с тем, чтобы представить, а что будет, если будет вот так. И, в принципе, это путь к тому самому reinforced learning, который здесь образован как вишенка на торте. То есть как бы таблица замкнулась, то есть самый большой объем знаний, который порождается, он дает минимальный выхлоп. То есть это вот та самая вишенка на торте, которая из того очень многого, что мы пытаемся себе представить, полезного оказывается очень мало. Это ведет к тому, что живя в джунглях, мы ничего серьезного развить не можем. Живя в обществе, обмениваясь знаниями, осваивая знания, которые были получены другими, можно... как бы продвигать вот эту цивилизацию, потому что, значит, я, конечно, многое себе могу представить, но, как вы понимаете, выхлоп небольшой. Это относится к большинству. То есть есть, конечно, кто-то больше себя там, что-то хорошее придумал, кто-то меньше, но в целом, значит, ни одного вы не назовете деятель человечества, который был бы сравним с остальной цивилизацией, которая была получена. Вот. Ну и, собственно, вопрос в том, что, в принципе, конечно, как-то можно называть разными терминами различные виды обучения. Они, значит, могут использоваться по отдельности. Вот той же картинке Лекуна, там, в принципе, есть модели, где только какой-то один из типов перечисленного обучения. А вот по рождению в Ганнах, там, соответственно, осуществляется тоже, в принципе, некоторый вид обучения, который тоже имеет конкретную схему и, естественно, имеет свое название. Это тоже, как бы, правильно. Вот, но в целом все виды обучения, значит, они, ну, по крайней мере, как мне кажется, в человеке, они связаны. То есть для того, чтобы, значит, хорошо ориентироваться в этом мире, мы используем все эти виды обучения. И вот это вот, как бы сказать, вопрос в том, какие условия создаются для... изменение параметров наших нейросетей, он важен не в том смысле, как мы это назовем, а как вот эти условия для изменения влияют на решение проблемы сложности взаимодействия с внешним миром. Вот как бы это, на мой взгляд, является важным. То есть, конечно, называть тоже как-то надо, но главное это все-таки вот попытка с различных сторон решения проблем сложности, которые тоже можно выделять несколько, я тоже грешен в некоторой технологии, я выделяю пять проблем сложности. можно, конечно, как-то их иначе классифицировать, но в целом Спорить надо не столько о терминологии, сколько о путях решения проблем, которые состоят не в том, что мы вот это называли так, а вот это назвали так. То есть это полезно для того, чтобы кому-то продать, а еще лучше втюрить. А, соответственно, для того, чтобы действительно продвигаться в научном плане, то лучше решать проблемы, сложности, которые есть в этом. 

S03 [02:43:48]  : Владимир, ну мы и пытались обсуждать как раз конкретные проблемы подкрепления, а вы это сводите обратно к терминам, так, на минутку. И говорите, что не надо говорить про термины, давайте лучше быть конкретными. Прекрасный призыв и абсолютно не то. 

S10 [02:44:01]  : Обсуждали терминологию. 

S03 [02:44:03]  : Нет, мы обсуждали не терминологию, вот совсем. 

S10 [02:44:07]  : Вы считаете так, я считаю. 

S07 [02:44:10]  : Ну что, наверное, уже пора закругляться. Дискуссия интересная получилась. Я открыл у себя штуки три вкладки, которые еще почитаю. В общем, выхлоп явно есть. И может быть даже повод собраться еще где-нибудь месяца через два, но там же. 

S01 [02:44:27]  : Мы на похожую тему будем говорить на следующем семинаре с Евгением Евгеньевичем Витяевым. Продолжим. 

S07 [02:44:37]  : В общем, всем спасибо. 

S03 [02:44:41]  : Спасибо большое, замечательно. 









https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
