## 23 сентября - AGI-программист - MVP, промышленное решение или мираж? - Эдуард Хачукаев, Виктор Носко, Виктор Казаринов (уточняется) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/5EH6GcXI2i4/hqdefault.jpg)](https://youtu.be/5EH6GcXI2i4)

Суммаризация семинара:

Семинар обсуждал несколько ключевых тем, включая семантические языки и антологии. Участники подчеркнули важность понимания и обучения в контексте искусственного интеллекта и программирования. В частности, отметили, что написание кода может быть не конечным результатом, а скорее процесс обучения с использованием различных инструментов.

Важным аспектом стало обсуждение сложности задач для решения небольшими группами специалистов и необходимости согласования. Был поднят вопрос о сетках и нейросетях, их способности обучаться на неправильных данных и эффективности. Участники отметили, что управление такими системами - это еще не решенная задача, и нужны методы управления, описанные в литературе.

Также обсуждалась работа с языковыми моделями и проблем сжатия информации, которое приводит к трудностям восстановления полноты данных. В контексте обучения систем понимать задачи и решать их, упомянули возможность работы с узкими спектрами задач и построения вопросно-ответных систем.

В заключение семинара были озвучены планы на будущее, включая обсуждение универсальных репрезентаций понятого и семантических языков в следующем семинаре.

В качестве важного эксперимента участник семинара Юрий Бабуров показал возможность распознавания текста на картинках с помощью эвристических приемов, что подчеркивает необходимость междисциплинарного подхода в ИИ.

В целом, семинар подчеркивал сложность и многоаспектность задач в области искусственного интеллекта и программирования, и важность междисциплинарного подхода к их решению.






S05 [00:00:08]  : Коллеги, всем добрый вечер. Сегодня мы неожиданно продолжаем тему MVP для AGI. И в данном случае идеей MVP для AGI будет искусственный программист на основе AGI, или сильного искусственного интеллекта, или просто искусственного интеллекта. Или если не искусственный программист, то ассистент программиста может быть. Я позволю себе сделать небольшую подводку к этой теме, рассказать четыре истории, которые являются подводящими к ней. Одна история – это моя собственная история. 30 с лишним лет назад. Потому что 30 с лишним лет назад, когда я начал заниматься серьезной разработкой софта, у меня возникла идея, что мне нужен помощник. Тогда это было все на MS-DOS. C, C++. Даже, по-моему, еще C++ не было на персоналках. Это был C. И я написал себе интеллектуальный драйвер клавиатуры. который делал примерно следующее. Он запоминал вообще все, что я делаю. Все последовательности клавиш на уровне биоса. Перехватывал прерывания и все, что я делал, он запоминал. К сожалению, памяти не хватало, чтобы хранить это долго, поэтому там был некоторый буфер. Какой-то N последних действий в буфере хранилось, а потом эта информация забывалась. И в любой момент я мог нажать некоторую комбинацию волшебных клавиш, и он пытался найти соответствие той последовательности действий, которые я только что сделал, некоторые последовательности действий, которые я делал раньше, с продолжением этой последовательности. То есть, если я, к примеру, набирал For, Он смотрел и видел, что какое-то время назад я набирал фор открытия скобочек и равняется нулю точкой с запятой и меньше и макс точкой с запятой и плюс-плюс. И он продолжал эту последовательность. И дальше был интересный вопрос, а как эта последовательность должна остановиться. Точка останова автокомплита в программировании, это интересная отдельная тема, про нее сегодня еще поговорим. применительно к OpenAI Codex. Я эту проблему решал так, что у меня была другая магническая последовательность клавиш, и я давал возможность этому роботу набирать информацию не очень быстро. То есть, если я видел, что он близок к завершению своего труда, я нажимал волшебную последовательность клавиш, он прекращал свой ввод, поставив фигурную скобку в закрытии цикла в данном случае, и я продолжал делать это дальше. Таким образом, по сути, я создал динамический макро-рекордер и макро-проигрыватель, который не нужно было настраивать, который просто из Shorter Memory брал все мои действия и это было очень удобно и этим легко было пользоваться вот там еще была на самом деле одна магическая клавиша еще было две магических клавиши если я хотел быть точно уверен что он найдет именно ту последовательность перед тем как начать набирать начальную последовательность я мог очистить буфер да то есть я мог нажать там значит control Escape какой-нибудь, и тогда он точно начинал подбирать в памяти ту последовательность кравиш, которую я нажал после вот этого маркера. Ну и вторая еще была магическая комбинация Control-Del, если вдруг он чего-то начипятал неправильно, Я нажимал Ctrl-Delete или что-то в этом духе, он стирал все то, что он натайпал сам, и я после этого продолжал правильную последовательность. Теоретически, конечно, можно было бы сделать еще возможность того, как это сейчас делается в Google. с выпадающими списками, значит, в сплывающем окне с подбором вариантов. Но тогда это было слишком страшно, тем более, что все это было сделано на уровне биосовского клавиатурного драйвера. Тем не менее, вещь была очень полезная. Единственная там случилась эта курьезная история с этим драйвером, что поскольку это были злые 90-е, компьютеров не хватало, И я на этой персоналке работал по ночам, а днем на этой же персоналке работал директор нашего программического кооператива. И в какой-то момент, когда он утром сел за работу, он не перезагрузил компьютер, а я уходя-уходя не выгрузил драйвер, и он продолжил работу с включенным моим драйвером. И оказалось, что в той электронной таблице, если кто-то помнит название Framework, была такая программа, такая же популярная все время, как сейчас Excel. Оказалось, что Ctrl-Enter, который у меня использовался как активация автоматического набирания последовательности, там использовалось в качестве сохранения. И когда он после правки каких-то бухгалтерских документов нажал Ctrl-Enter для того, чтобы сохраниться, мой драйвер активировался, принялся редактировать бухгалтерские балансы, выходить из программ, запускать другие программы, редактировать какие-то файлы, что-то удалять. В общем, достаточно серьезно напакостил, и была очень неприятная ситуация. Это я к чему говорю, потому что на самом деле проблема автокомплита для программистов очень больная. Я ее решал так, потом во многих продвинутых идешках появилось понятие макросов. где соответствующие макросы можно было записывать явно. Как сейчас эта задача решается, я, честно говоря, не знаю. Но как раз именно эта задача о комплитах, она неоднократно упоминалась товарищами, которых мы чуть позже увидим, кто их еще не видел из OpenAI, когда они говорили, что по сути мы реализовали вот такой продвинутый автокомплит для программиста. на основе тех принципов, о которых мы тоже будем сегодня говорить. Вторая история – это история более современная, и она, наверное, знакома почти всем здесь присутствующим. Когда 20 или 30 лет назад те, кто программировал для того, чтобы начать программировать, нужно было взять книжку по LISP или по FORTRAN или по C++, прочитать эту книжку и начать пытаться решать какие-то примерчики из учебника или какие-то свои практические задачи. Сейчас все делается немножко по-другому. Сейчас нам надо что-то написать на JavaScript или нам нужно сделать какую-то линейную регрессию на Python. Мы набираем в гугле Python Linear Regression Example или JavaScript Bubble Sort или Java Sort Time Series Processing. Нам вываливается куча постов, где в топе наверняка будет что-нибудь Stack Exchange. И мы в этом StackExchange смотрим, какой пример к нам больше подходит. Выясняется, что из десяти обсуждающихся примеров три нам не подходят, два вроде как подходят, из этих двух один не работает. Мы берем и последний в конечном итоге с какими-то костылями, а иногда в лед он к нам подходит, и мы просто копипастим его в свой код. И либо нам повезет и это работает дальше, либо мы что-нибудь скопипастили не так, и потом нам приходится решать проблемы копипейста. То есть вот такое программирование через Stack Exchange или программирование через Google это очень распространенный на сегодня паттерн, потому что разных фреймворков, разных библиотек, которые приходится использовать их столько, что запомнить их совершенно невозможно. Поэтому коллективный интеллект помогает. И в этом смысле технология, которая бы как некоторым продвинутым образом помогала программисту находить готовые темплейты, темплейте в широком смысле этого слова, то есть темплейт не как дизайн паттерн, а как некоторые образцы готового кода, который можно включить в свой код, либо чуть-чуть подшаманить и довести для рабочего варианта. Это на самом деле было бы очень удобно, особенно если бы эта штука еще делала какую-то селекцию отбор не работающих вариантов. Что, в общем, тоже является частью того решения, про которое сегодня будем говорить. Это вот вторая история. Третья история – это, собственно, история вот этих вот трех молодых людей, которые нам ее рассказывают. Так, мой экран же видно, надеюсь, да? Вот мы видим трех богатырей. Слева как водится Илья, правда не Муромиса, а Сусковер. Это товарищи из OpenAI Gym, которые нам представили замечательное решение OpenAI Codex Live Demo, которое вроде как решает обе проблемы. Или реализуют обе истории, про которые я рассказывал в начале своего разговора. И мы про это... Собственно, обсуждение того, что они нам показали, является первой частью нашей сегодняшней дискуссии. вот я нашел время с утра поглядел не то чтобы совсем по диагонали не то что совсем глубоко но в общем просмотрел эту статью вот и в общем у меня возникло ряд вопросов про которые я тоже буду сегодня говорить чуть позже Исходя из чего, что у меня не стыкуется. То, что я прочитал в этой статье не стыкуется с тем, что уважаемые коллеги продемонстрировали всему миру и в том числе покупателю в лице Майкрософта, который либо не задал до этого, либо вскоре после этого действия OpenAI приобрел. Вот. Это вот вторая и третья история. Ну и, наконец, четвёртая история. Её тут тоже, наверное, многие присутствующие с ней знакомы. Собственно, провокатор этой истории и провокатор сегодняшнего нашего совещания и обсуждения Эдуарда Хачукаева, который, к сожалению, сегодня не пришёл, потому что, значит, как выяснилось ему, что сегодня нужно идти на встречу в администрации президента, Он извинился, сказал, что не сможет присутствовать. Но история такова, что он пришел в группу AGI Bots и сказал, что у него есть заказчик, у которого есть бюджет на решетку, вполне конкретный. Даже не очень маленький, на первый взгляд. И у него есть совершенно конкретная задача, что нужно сделать систему, которая при методах искусственного интеллекта будет брать спецификацию, написанную на естественном языке, и эту спецификацию превращать в работающую программу. Казалось бы, то, к чему докладчики из OpenReagim, если не пришли, то двигаются семимильными шагами. Ну, я насколько понимаю, некоторые участники нашей сегодняшней встречи с заказчиком разговаривали. Разговаривали с ним и я. Я не знаю, удалось ли заказчику собрать команду мечты, или он передумал, или что там происходит. Значит, у кого-то здесь присутствующих есть интерес для этого заказчика или для какого-то будущего такую команду мечты собрать, то, собственно, вторая часть нашего сегодняшнего разговора... Так, у меня закрылся экран. Сейчас я его открою. Со списком вопросов. Таймпад, таймпад. Упад-папа-папад. Вот он. Да, собственно, вот после того, как мы обсудим, что такое OpenAI кодекс и с чем его едят, мы можем попробовать поговорить, а вообще, значит, можно ли строить подобные решения, значит, какова декомпозиция, да, то есть, если это решение может быть построено, то какова должна быть хотя бы примерная декомпозиция этой задачи на решение, какие там есть риски, какие там могут быть майлстоуны, Вот, что может быть на каком этапе реализовано и какова будет цена вопроса по каждому из этапов решения задачи создания искусственного программиста или ассистента искусственного программиста для того, чтобы мы могли как-то заняться решением этой задачи в качестве AGI MVP, так называемого. Ну вот, собственно, все, что я хотел сказать в качестве короткого не очень короткого вступления. Поэтому предлагаю участникам начать высказываться по вот этим четырем обозначенным вопросам. У нас прислал презентацию Сейчас я посмотрю. Виктор Казаринов, у него обычно плохая связь. Он собирался выступать, но он прислал презентацию, потому что у него было обычно плохое качество звука. Но насколько я понял, он будет, судя по первому слайду, он будет больше рассказывать про второй вопрос. Поэтому, наверное, презентацию… Виктор, если вы нас слышите, насколько я понял, вы больше будете говорить про архитектуру искусственного программиста, а не про OpenAI кодекс. Если это так, то мы тогда вашу презентацию послушаем чуть-чуть позже, во второй части обсуждения. А начать все-таки я предлагаю с первых трех вопросов. И если у Виктора Носко, который к нам присоединился… Виктор, если у вас есть что-то по этому сказать, то я бы вас попросил высказаться первым. Виктор, вы нас слышите? Так, давайте посмотрим. Почему я не вижу Виктора? Так, а Виктор статью не читал. Хорошо, тогда давайте я, значит, выступлю застрельщиком, значит, и скажу свое впечатление от статьи. Давайте тогда я все-таки к ней вернусь. Так, сейчас, секундочку, я вернусь к своей статье тогда. Точнее, не к своей, а к статье товарищей. Значит, что я понял из этой статьи, так сказать, из хорошего, да? Давайте начнем. Значит, из хорошего я понял, что они достаточно серьезно методологически подошли к решению следующей проблемы. Значит, проблема выглядит так. Вот у нас есть первые две задачи. Сделать либо автокомплит, либо подсказку кода по описанию текста на естественном языке. И мы хотим эту задачу решить, используя то замечательное явление, которое называется GPT-3 и кучу железа, на котором оно работает. Как бы нам что-нибудь из этого сделать? Вот. Каким образом они к этой проблеме подошли? Я буду, так сказать, давать своевольную интерпретацию этой статьи. Желающие потом могут эту статью открыть и убедиться, насколько это правда или неправда. Как они к этому подошли? Для того, чтобы говорить, как они к этому подошли, давайте вернемся к постановке задачи искусственного программиста. Что у нас есть в процессе разработки программного обеспечения? Во-первых, у нас есть какая-то спецификация. Это спецификация, скажем так, на естественном языке. Она может быть более высокого уровня, на уровне абстрактной хотелки, или это может быть уже функциональное требование, расписанное продакт-менеджером. Или это уже в конечном итоге может быть техническая архитектура и СРСР, расписанные архитектором. Вот как возникают первый, второй, третий виды документов, и как один из них перетекает в другой, это вообще отдельная тема, про которую, может быть, тоже сегодня успеем поговорить во второй части. Но будем считать, что у нас есть какая-то максимально техническая спецификация, что мы знаем, что нам надо сортировку временного ряда или нужно линейная регрессия на двухмерном пространстве каких-то данных. И вот в терминах уже конкретных данных, конкретных алгоритмов мы хотим ставить задачу этому коду. То есть спецификации пишем на техническом языке. После того, как у нас есть спецификация на техническом языке, у нас возникает алгоритм. То есть мы говорим, что мы хотим сделать сортировку, после чего мы принимаем решение. Мы будем делать сортировку методом пузырьковой сортировки или мы будем делать quick sort. То есть, в зависимости от того, как мы поставили задачу, мы выбираем алгоритм. Или, если нам нужно хранить временную последовательность, будем ли мы ее хранить в индексированном массиве, или мы будем хранить связанном списке, или мы будем вообще хранить в пандасе, в питоне. Какой у нас будет контейнер, какие у нас будут структуры данных, как они будут взаимодействовать, будут ли у нас блокировки или нет – это все, что касается алгоритма. Потом у нас возникает код, который реализует этот алгоритм. И после того, как у нас возник код, у нас еще могут возникнуть, а могут не возникнуть, в зависимости от той парадигмы и от того процесса, в котором мы работаем, тесты. Иногда тесты могут возникнуть вообще до кода. То есть, если мы работаем по TDD, мы после того, как написали спецификацию, мы честно выписываем все тесты. а потом уже добиваемся того, что эти тесты работают. Алгоритм может появиться после тестов, но перед кодом. А может быть мы вообще алгоритмы подумывать не будем, мы просто начнем колбасить код, подбирая последовательность операторов таким образом, чтобы тесты проходили и чтобы заказчик остался доволен. На самом деле так действительно происходит. Многие программисты не продумывают архитектуру, не придумывают алгоритмы. Они просто начинают колбасить код. Что на самом деле на практике не очень эффективно. Так работают. То есть, вот эти четыре составляют... Опять-таки, тестов можно не писать. Или можно написать тесты потом. То есть, если мы работаем не по ДД, мы можем написать тесты после того, как код написали. Для того, чтобы потом убедиться, что никто не сломает этот код, когда пойдет перефакторинг на следующую версию. В общем, эти четыре составляющие – это четыре кита, на которых по логике должен строиться процесс разработки программного обеспечения. в обсуждении меня покритиковать. Так вот, возвращаясь к тому, что сделали эти ребята. Они очень хорошо методологически разработали процесс тренировки Machine Learning на задачи написания кода по документации. Из тех составляющих, которые я назвал, они оставили документацию, Причем в документации подразумевается совершенно конкретная вещь, это док-стринг. То есть, если у нас есть док-стринги перед описанием функции в JavaScript или после описания функции на Python, то это у нас та документация, на которой мы тренируем свою самую нейросеть. Так, там кто-то стучится, сейчас я отпущу, секундочку. У них есть док-стринги в качестве документации и у них есть код, который под этими док-стрингами болтается в качестве того кода, на котором мы тренируем свою модель. И у них еще есть тесты, то есть они молодцы, они также подключили тесты. Для чего? У них там были разные методологии отбора кода и отбора, потому что, например, пытаться обучать системе в той постановке, которую я обозначил, что вот у нас есть док-стринги, есть код, которые под этими док-стрингами болтаются, на док-стрингах мы тренируем систему писать код. Если докстрингов нет, если документации в коде нет, соответственно этот код нам бесполезен. У них была технология отбора исходников таким образом, чтобы докстринги были правильно оформлены. Это во-первых. Все равно, правда, с этим были косяки, но, тем не менее, они это сделали. Я не понял, насколько это было жестко, потому что там они описывали огромное количество разных вариантов от своей базовой технологии и тех технологий, которые они использовали там. То есть, на основе GPT-3 у них было как минимум три разных стека, а может быть и больше. Я не сильно вникал, но как минимум три стека у них были. И как минимум один стэк, самый продвинутый, он обязательно требовал, во-первых, того, чтобы тот код, который идет в обучение, помимо докстрингов, он имел вот эти юнит-тесты, и чтобы юнит-тесты обязательно выполнялись. То есть они убеждались, что тот код, который соответствует вот тому докстрингу, что он обязательно пройдет юнит-тесты. Вот это они делали. А еще интересную вещь, которую они делали, они же в ГПТ-3 как? Там же ГПТ-3 на основе одного входа может генерить кучу разных выходов. То есть, у них есть понятие температуры. Мы можем печку раскочегарить до определенного градуса. И в зависимости от того, насколько мы ее раскочегарили, она относительно некоторого среднего результата будет давать больше или меньше разброс всяких вариаций того, что можно было бы ожидать. И они делали что-то вроде отбора естественного. После того, как систему научили, мы на основе одной и той же докстринги фигачили кучу вариантов кода, а дальше мы смотрим, а какой из этих кодов проходит юнит-тест или нет. Соответственно, если юнит-тест прошел, то он является валидным вариантом. На основе этого мы можем дополнительное обучение делать, то есть мы можем Забыл, как это слово Machine Learning называется, когда мы на основе одних и тех же данных генерируем новые данные и на них потом дообучаем систему. Вот. Еще у них там… То есть они вот эти тесты использовали. Значит, что важно в этой истории, что про алгоритм про то, что, собственно, система должна сделать, исходя из этого текста, про это вообще никто даже, так сказать, даже речи не идет. То есть даже в мыслях, судя по всему, авторов статьи, что алгоритм должен играть какую-то роль во всей этой истории, про это речи вообще не было. Ну и если говорить о результатах, то это одна постановка задачи, которая у них была. Это, так сказать, прямая задача на основе всей той обвязки, про которую я рассказал. Прямая задача была по докстрингам генерации кода. А вторая задача, это, так сказать, обратная задача. Нет, это не файнтунинг, это другое слово называется. Аугментация, да, аугментация. Спасибо, Виктор. То, что я говорил, называется аугментация. Вторая задача, обратная, которую они решали, это на основе кода генерировать док-стринги. Если у нас есть недокументированный код, а мы хотим понять, что он вообще делает, то на основе этого кода мы можем запустить тот же самый движок, натренированный на парах док-стринг плюс плюс код и сгенерировать docstring, исходя из этого, понять, а что этот код вообще делает. Причем, значит, там достаточно большое количество усилий у этих ребят ушло на то, чтобы вообще сделать возможность вот этого, так сказать, во-первых, отбора Вот этих вот, они же тренировались на огромном числе, какие-то страшные цифры тех проектов, которые они переколбасили из гитхабов публичных. Они там отдельно обсуждают еще легальные аспекты этой истории, насколько это вообще легально и не нарушает ли чью-то интеллектуальную собственность, они это делают. насколько это, так сказать, там вообще, так сказать, этично с точки зрения развития человеческой цивилизации. Там в статье куча разговоров на эту тему, вот. Но главное-то то, что для того, чтобы, так сказать, в массированный исполнять, значит, самый непонятно какой код, непонятно кем, непонятно зачем написанный, а может там вообще злые хакеры этот код специально положили, чтобы кто-нибудь его запустил, значит, самый Троянов распустил по всему свету. Они сделали специальную среду для того, чтобы можно было исполнение всего этого кода, который они надергали с одной стороны, и того кода, который они нагенерировали для того, чтобы убедиться, что этот код проходит юнитесты. Чтобы это ничего не сломало и никуда не вылезло, и никому не навредило, они делали специальную защищенную среду. Так вот, это вот, значит, теперь сказать, собственно, это вот то, что они делали, а теперь к тем проблемам, которые я увидел и про которые они на самом деле явно пишут. То есть я вот увидел три проблемы, да, я вот сейчас вот, если вспомню, все назову, значит, я помню, что их было три. И вот надо сказать, что вот эти три проблемы, которые я увидел, они вводят меня в ступор с точки зрения того, что я не понимаю, как эти три проблемы соотносятся с тем, что было продемонстрировано на этом видео. И если вдруг кто-то из присутствующих сможет мне объяснить, почему вот те три проблемы, которые я сейчас назову, они не препятствуют тому, что показали уважаемые коллеги, я буду просто очень счастлив. Значит, проблема первая, про которую они совершенно честно где-то пишут. Ладно, я не буду ее искать, я ее сбрасывал в Telegram. Они, значит, честно пишут, что вот процент Решение этих задачек, которые они решают самым лучшим своим движком, который на основе юнит-тестов отбирает решение и проверяет еще решение на основе юнит-тестов. Процент прохождения в лучшем случае сопоставим с теми результатами, которые дает студент. то есть вот студент там сколько-то поучился и вообще-то сказать там прочитал пол книжки и увидел там прошел несколько туториалов и вот он уже что-то начинает программировать вот примерно на таком уровне система задачи решает это при том что система для того чтобы решать задачи на таком уровне прочитала больше кода чем на порядке больше кода, чем любой программист супер продвинутый может прочитать за всю свою жизнь. То есть весь публичный гитхаб система прочитала, переварила и тем не менее проценты решаемости задач это вот примерно на уровне простеньких интервью для джуниоров. Это вот одна проблема. Значит, вторая проблема, она оказывается очевидной, когда они решают обратную задачу. То есть, вот где-то мне сейчас я найду, значит, там пример. Здесь есть DocStream, DocStreamGeneration. Да, вот здесь вот они тоже честно пишут. То есть, статья на самом деле честно все описывает. Ага, пожалуйста. Вот мы взяли код, значит, какой-то и попросили сгенерировать этот код. док-стринг, а док-стринг оказывается I just found this function online, типа я эту функцию где-то стырил, или просто пояснение, что типа этот код не работает. Ну то есть что получается? Получается, что какой-то чувак в каком-то публичном репрезитории написал какую-то хрень. К этой хрени честно написал, что это не работает или что он где-то стырил это онлайн, вместо того, чтобы это было хоть как-то похоже на спецификацию, мы на этом потренировались, и после этого мы начинаем на основе этого писать код. Используя вот эти вот дикие вычислительные мощности, миллиарды параметров, и отбирая решения с помощью юнит-тестов, которые исполняются в суперзащищенном окружении. То есть, что называется, где логика, где разум. Это вторая проблема, которую я увидел и которая, опять-таки, у меня никоим образом не стыкуется с замечательной презентацией, которую товарищи показали. И последняя проблема. Для тех, кто видел это видео, там должно быть совершенно понятно, что система достаточно четко умеет работать с контекстом вообще. Вот та система, которую они показывают, для того, чтобы делать то, что она делает в их видеопрезентации, она должна уметь работать вообще и, в частности, делать анафоро-резолюшн в NLP. То есть, они говорят, что вот там, так сказать, создай там объект, создай космический корабль, да? А потом спустя там несколько команд говорят, значит, там добавь к космическому кораблю какие-нибудь кнопочки. Я образно говорю, я не помню, там у них разные примеры были. То есть, она понимает, что это – это космический корабль. То есть каким-то образом у них в дополнение к тому, что мы генерируем из док-стрингов в код, есть какие-то костыли или какой-то еще дополнительный слой, который работает контекстом, который рисовывает анафоры. значит сама и подвязывает их значит вот к тому коду значит который на самом деле генерится а вот еще хороший пример данных а четвертая проблема четвертая проблема сейчас про нее скажу или другой пример они могут говорить там не это они могут говорить там корабль или могут говорить там человек да то есть они ссылаются к некоторым объектам в тексте на естественном языке, которые уже на предыдущем этапе реализованы в виде каких-то элементов кода. И каким-то образом у них есть решение, которое не просто там превращает некоторый текст в некоторый код, а каким-то образом увязывает, значит, собственно, некоторую логику или некоторую структуру данных хотя бы с тем кодом, который это генерируется. Про это в статье нет ни слова. Я, честно, поискал вокруг и ничего внятного на эту тему не нашел. Может быть, просто не успел найти. Ну и четвертый пример, который тоже меня слегка смущает с точки зрения этого видео. Вот они говорят, что там напечатай там слово привет да программа напечатала слово привет а теперь сделай это 10 раз и программа радостно пишет там значит самое 10 раз напечатать слово привет в цикле вот но простите как вы это делаете да как вы вообще разбираетесь с тем что 10 это значит именно раз которое надо повторить если Если у вас вот такая вот фигня случается, извините, то есть если вы вообще не можете разобраться с тем, что end объединяет x и w, и если вы не понимаете, что product of the four numbers относятся ко всем четырем значениям, которые вычисляются в ходе. То есть она честно сказала subtract 4 from. Да, вот она увидела, что нужно из чего-то subtract 4 и написала subtract 4 от того, что пришло в голову. Спасибо, дорогая. Или return the product of the four numbers. Ага, надо что-то на что-то умножить. Что на что-то умножим? Возьмем вот этих двух и получится умножение. Зашибись. Я, так сказать, пас для того, чтобы… Я не понимаю, как с этим можно делать вот это. Вот это вот все. Ну а в остальном, так сказать, если бы это не потребляло столько электричества и если бы был удобный интерфейс, который можно было бы набрать… Скажи мне, как сделать линейную регрессию для Time Series? Если бы мне выдавался не список thread на stack exchange, а работающий код, проверенный unitest, я бы его просто skip-pasted, это было бы очень удобно. Виктор, прокомментируйте. Виктор Носко. Вы с нами? Так. Виктора не слышно. Сейчас посмотрим, что у нас с участниками. Юрий Бабуров. Юрий, пожалуйста. 

S04 [00:35:33]  : Всем добрый вечер. Могу прокомментировать. Как мы сформулируем вопрос? Правильно. Нормально ли такое поведение для языковых моделей, что вот эти все четыре недостатка у нас есть? Нормально, да. то, что сетка может учиться на неправильных данных и включать их в обучение, при этом ничего не ломается и все работает при наличии достаточно большого процента правильных данных, это тоже фича сеток, за которую их очень любят. то, что они sample inefficient, все про это знают, все ужасно этим недовольны, но не знают, что с этим делать. и большие сетки, в них невозможно практически включить какую-то внутреннюю обработку в процессе. они как бы неуправляемые. что-то они нам делают. если оно нам подошло, то хорошо. не подошло, то плохо. но мы не знаем, что с этим сделать. немножко управлять этим можно. как раз Виктор про свой опыт может потом рассказать, как он этим управляет. в общем, это не решенная еще пока задача. хорошее управление такими сетками. Есть разные способы, описанные в литературе. Если есть какой-то конкретный вопрос, сформулируйте, пожалуйста, я попробую конкретно на него ответить. 

S05 [00:37:14]  : Юрий, вы здесь, наверное, у нас самый главный, если не считать Виктора Смолина, Владимира Смолина, специалист по нейросетям. Вы можете ответить, как с теми не косяками, а открыто обозначенными проблемами, которые обозначены в статье, которую я перечислил, как можно снимать те демонстрации, которые демонстрируются. Если абстрагироваться от того, что очень нужно было продаться Майкрософту. 

S04 [00:37:51]  : Ну, смотрите. заявлено. 23 процента случаев система решает нормально. да, показываем нормальный случай, не показываем другие случаи, которые не работающие, потому что понятно, что есть случаи, они явно про это говорят. но, конечно, мы показываем рабочие случаи. да, это называется черепикинг. и эта практика достаточно популярная, причем в статьях про это честно говорят, да, вот это черепикадные экземплы, потому что в целом разработчикам очень интересно посмотреть отдельно на ошибки, отдельно на хорошие примеры. и редко когда им интересно смотреть и то и другое вместе. но при этом они приводят примеры ошибок в статье, все нормально здесь. 

S05 [00:38:41]  : Окей. Юрий, спасибо. Николай, пожалуйста. 

S02 [00:38:48]  : Добрый день. Вот по поводу того, почему в итоге система работает на уровне студентов, оно вытекает из того простого факта, что они собирали данные в GitHub. Дело в том, что гитхаб очень широко используется студентами для того, чтобы делать задания по программированию. Они получают задания и пишут упражнения в гитхабе. И при этом именно эти, поскольку они учебные задания, они должны соответствовать формальным требованиям. То есть содержать строчку описания в начале и содержать тесты. Ну и, соответственно, именно они попадают в то, что требуется для отбора. Ну и результат соответствующий, то есть не всегда работающие программы. И ассортимент программ соответствует уровню начального обучения программирования. То есть ничего удивительного нет тут. Профессионалы пишут, Программы немножко по-другому. Во-первых, редко кто пишет, ну я, например. Я на Питоне написал довольно много и объемистых процедур. Если процедура играет, предназначена для реальной ситуации, она имеет большой объем. Описание вначале есть, но оно говорит не об алгоритме, а о том, для какой части системы она предназначена, что я в ней менял, когда и так далее. То есть эта информация не для... описание алгоритма, а наоборот информация, которая содержит те сведения, которые нельзя почерпнуть, глядя на код. Потому что когда программист смотрит на программу, ему реально описание в начале совершенно не нужно. ему нужно код смотреть. А описание говорит о том, для чего программа нужна, кто и когда ее делал и так далее, то есть дополняет. В тох случаях, когда речь идет о профессиональном подходе. Ну и объем слишком большой для того, чтобы можно было хоть как-то обычно отражать суть алгоритма в заголовках. А самих программ таких гораздо меньше, на порядке меньше, чем учебных. Ну вот, это и получается в результате. То есть, то, что они сделали, оно может быть полезно для чего. А те же самые студенты вместо того, чтобы самим писать, Таким образом, так сказать, списывать косвенным образом написанное другим. 

S05 [00:42:30]  : Дорого будет, дорого. Им нужно этим денежку будет платить. Это дорогое удовольствие. 

S02 [00:42:35]  : А тут же массовость. Как это в анекдоте про старушек этих убитых. преступникам за рубль. Рубль здесь, рубль там. 

S05 [00:42:56]  : Да, Николай, кстати, вот по поводу того, что вы сказали насчет описания. Они в статье тоже пишут, разбирают тот случай, что по идее должно бы быть так, что чем более подробное описание, тем качественнее программа. А у них экспериментально как-то статистически значимый результат, что чем длиннее и подробнее описание, тем хуже получается программа. Потому что система просто ломается на сложных связанных текстах и вообще не понимает, что от нее хотят и пишет полную билиберду. То есть, там что-то, по-моему, больше, чем два предложения. Вот так вот. Больше, чем два, так сказать. То есть, если задача состоит больше, чем два шага, более, чем двухшаговых задач, они вообще, так сказать, резкое падение. 

S02 [00:43:46]  : Ну да, да. И еще один аспект. Вот по поводу тестов и по поводу юнит-тестов. Для сложных задач юнит-тесты делать сложно, и их по этой причине делают мало. А для простых задач пишут юнит-тесты студенты, при этом сами юнит-тесты зачастую еще более неправильные, тестируемая программа, не в том смысле даже, что у них там ошибки могут быть и оно не компилируется, а в том смысле, что юнит-тест требует тоже ж мозгов, то есть надо понимать, что именно тестировать. Когда юнит-тест есть, и он просто говорит, что а я вот какое-то исходные данные дал и оно мне какой-то результат получило. Это юнит тест. А на самом деле он может быть совершенно бессмысленным в таком выражении. Юнит тест должен покрывать все варианты, рассматривать особые случаи, проверять, так сказать, уязвимые места, а не просто демонстрировать, что какой-то пример проработал. Вот у меня всё, что я могу сказать. 

S05 [00:45:24]  : Спасибо, Николай. Я тоже отрефлексирую, что про юнит-тесты. На самом деле, тут очень интересная вещь, что в этом четырёхугольнике спецификации, алгоритм, код, Тесты, на самом деле, переходить можно по этому графу из четырех точек из любого места в другое. То есть, теоретически, можно автоматически тесты генерить по коду. А потом убеждаться в том, что тесты написаны правильно, подправлять по необходимости, убеждаться в том, что код работает. Или можно, написав много правильных юнит-тестов в парадигме TDD, по тестам генерить код. А можно по тестам генерить документацию, то здесь в принципе если делать настоящий искусственный интеллект, то теоретически можно из всего генерить все что угодно в зависимости от текущей подребности. Вот еще комментарий от Игоря Романко. мое мнение значит там же не строятся логические связи там больше идет попытка построить ассоциации между входом и выходом с повторить 10 раз так хорошо работает потому что скорее всего этот вход чаще всего ассоциируется с кодом for с простой математикой может быть так тяжело работать потому что разные формулировки инпута с разными комбинациями ассоциируется с разными выходами и за счет такой большой неопределенности тяжело создать жесткую связь. Юрий Бабуров, пожалуйста, прокомментируйте еще, а потом слово Владимиру Смолину дадим. 

S04 [00:47:14]  : Там был вопрос конкретно в тот момент, когда я говорил. я не очень согласен, что кода студентов очень много и так далее, но дело в другом, что мы строим башенку понимания, и тут разница между человеком, который заучил ответы, и человеком, который действительно понимает. экзаменаторы все умеют эти два типа людей распознавать, различать друг от друга. Можно дать хоть нестандартную задачу, можно какие-то чуть менее стандартные условия поставить для системы, она тут же посыпется. А то, что не воспроизводит текущую систему поведения человека, они не мыслят. они лишь собирают какие-то статистики, но на этих статистиках можно строить, по идее, другие более сложные статистики и приближаться как-то к пониманию. Но другое дело, что это должно быть какое-то направленное движение, что-то типа мышления. И вот эти сложные алгоритмы, их отдельно надо как-то программировать, внедрять в систему, и без этого система хаотична. Эти алгоритмы не воспроизводят, и поэтому не поднимается высоко. а по поводу... остальное все менее значительно. самый важный момент. по поводу конкретно docstring, почему хуже работает, чем длиннее docstring. по той же собственно причине. она называется интерполяция против экстраполяции. когда мы просим в рамках линии, нарисуем линию, потом стираем половину линии, просим компьютер вторую половину линии воспроизвести, вот эту стертую, он спокойно ее воспроизводит. а если мы рисуем функцию и просим ее продолжить, эта задача намного сложнее. и вот это режим экстраполяции. в режиме экстраполяции нейросетки работают из Rubconplot, Эта проблема изучается очень подробно, очень многими. По-другому, это проблема плотности распределений, потому что очень легко моделировать распределения в точках, где они плотные и тяжело. Представьте, у вас пространство из тысяч размерностей, это значит, что для большинства точек вы даже никогда не видели точки рядом с ним. и теперь вас просят определить, какое будет значение функции в этой точке. и теперь перед вами возникает вопрос, на какие, даже просто из этих тысяч измерений, на какие опираться. вам надо продолжать не одномерную линию, не двухмерную, а тысячемерную. задача нормальная. человекам она, в общем-то, тоже нормально не решается. человек потеряется в такой задаче. ну и, соответственно, вот пытаемся все вместе придумать какие-то способы частные или более общие для решения подобной проблемы. но, безусловно, текущие системы с этим не справляются нормально. но иногда немножко как-то работает. 20-30 процентов, иногда 80. но для задач этого тоже может быть мало. бывают задачи, для которых нужно там 99 и не меньше, как мы знаем там с движением по дороге. а для других задач достаточно... то есть вот я пользуюсь, например, это подсказчик, у которого 3 процента точности по данной измерению. но тем не менее он удобен, когда его используешь именно как автокомплект. то есть он может тебе в очевидных случаях подсказать. то есть если ты четко знаешь, что случай очевидный, ты просто жмешь тап и он тебе подсказывает. и почти всегда это верно. то есть мы сами ограничиваем уровень, на котором он подсказывает, и тогда система дополняет человека. то есть она не может принимать решение за человек, но как система поддержки принятия решений, как генерации кандидатов для принятия решений, вот она, в принципе, уже работает, как многие другие системы в уровне AI узкого. 

S05 [00:51:44]  : Юрий, спасибо. Владимир? 

S07 [00:51:49]  : Слышно меня? Мне было приятно послушать Юрия Бабуру, потому что всё-таки он пытался не чисто внешние какие-то свойства системы проанализировать, а всё-таки не то чтобы глубоко, но всё-таки залезть внутрь системы и понять, что там происходит. Потому что вот все эти обсуждения про ГПТ, про написание этих программ мне очень напоминают старый анекдот о том, когда у девушек спрашивают, вы знаете, как работает трансформатор? Она говорит, конечно, знаю. Он говорит, как? Вот примерно тем же самым мы занимаемся, когда обсуждаем ГПТ. Кто-то загрузил его на себя и начинает ему задавать вопросы. Он гудит в ответ. Вот мы теперь обсуждаем, как работает ГПТ. Мы же поняли. вот все понятно вот ну и конечно дело не только в том что поколение егэ там вот о том что жизнь как бы у нас толкает к такой необходимости что значит если там 50 лет назад каждый мужчина дома мог любой прибор отремонтировать сейчас как бы Ну то есть я знаю отдельных умельцев, которые до сих пор могут, но это скорее как бы не общее явление, а скорее такие исключительные. Причем они, как правило, еще на этом зарабатывают. Вот, а, соответственно, просто жизнь, как бы, усложнилась. Не только, значит, в Москве схема метро стала большая, что ее уже никто, значит, целиком не помнит, а в молодости все помнили, значит, схему метро. Вот, а сейчас, соответственно, все приборы стали сложными, и, как бы, чтобы их ремонтировать, ну, значит, вот с нейросистемой, конечно, еще хуже. Там они, конечно, сложные, значит, как-то про них хочется говорить, а понять, что там внутри достаточно сложно. но от того, что мы попробуем, по-разному включаем, понимаете, если бы это был хотя бы трансформатор, и то как бы сложно по звуку понять, как он работает, понимаете, а вот это вот GPT-3 и прочие языковые модели на миллиардах параметров, Ну, в общем, нам много веков надо включать, чтобы что-то там прояснилось. Вот. То есть, если мы не будем залезать внутрь и не пытаться решить какие-то проблемы, там, сложности, соответственно, каких-то мыслительных процессов там организации, там, проверок там организации, то если мы просто, соответственно, обсуждаем, что вот мы повключали, послушали, о, нам что-то стало ясно. Это очень обманчивое впечатление. Значит, так мы... Мягко говоря, ничего не поймем. То есть, конечно, я согласен с Юрием, то, что он рассказывал, что какие-то простые примеры можно решать, и от этого может быть польза. Но рассчитывать, что дальше этого что-то пойдет, по меньшей мере, на мой взгляд, это наивно. Вот, собственно, мой комментарий. 

S05 [00:54:39]  : Владимир, спасибо. Так, значит, ну давайте так, сейчас вот Игорь Пиваров, видимо, хочет высказаться оппортунистически. 

S01 [00:54:49]  : Игорь, пожалуйста. Я всех слушаю, и да, добрый вечер всем. Такой прекрасный хор, и с одной стороны я со всеми согласен, но с другой стороны хочется немножко напалму подлить, а то что-то все в одну сторону грибут. а знаете я что скажу? я конечно согласен допустим со всеми спикерами, что и Владимиров сейчас с последним, что в некотором предельном смысле мы конечно все понимаем что gpt-3 не умеет программировать она не понимает, что пишет, и это просто как бы компиляция кода. Но вот честно вам скажу, 90% программистов занимаются компиляцией кода из существующих источников. А некоторые экземпляры, которых я видел и которым я ставил задачи, у меня даже нет ощущения, что они понимают вообще. Сказать, что я им говорю, такое ощущение, что он как бы просто вот услышал как бы край мух и тут же что-то как бы написал и типа как бы все я сделал ты будешь ну ты хоть подумай вообще как бы что ты делаешь то а он как будто даже не думает в этом смысле я бы сказал что же пт-3 вполне себе на некоторых таких программистов уже походит но я здесь знаете я просто хочу как бы мой тезис здесь в том что давайте мы поймем, что такое для данного диалога, который у нас осмысленный, осмысленных людей, что такое умеет программировать. Если же ПТ-3 пишет на тезис, напечатай hello, она пишет print hello, я боюсь, что мы должны признать, что она умеет программировать hello world. ну как бы, если мы словом умеет называем, вот я ставлю задачу программисту, он как бы делает мне код. ну в некотором смысле я должен признать, что она умеет программировать на уровне Hello. мы просто должны тогда, просто знаете, я когда начинал, я себя считаю программистом, хотя вообще сегодня уже как бы это оказывается ругательное такое. в общем там как-то у них очень много разных уровней, то, чем я занимаюсь, там сейчас называется всякое архитектор и прочее, я не очень понимаю в этих уровнях, я себя по-прежнему считаю программистом, но видимо надо как-то точнее вообще понять, какие есть уровни. я бы сказал, что в общем некоторый функционал примитивный, видимо, gpt3 делать может. вот мой напал в этом. давайте мы на уровне, на какие-то разобьем и поймем дальше как к этому относиться. какие-то критерии надо вводить более тонкие. 

S05 [00:57:47]  : Игорь, спасибо. Вот здесь Юрий Бобуров тоже добавил, что писать printHelloWorld на соответствующий запрос – это значит программировать уже лучше, чем 97% людей в мире. Хорошо. Теперь все-таки мне хотелось бы дать слово Виктору Казаринову. В комментариях у него плохая связь, поэтому я Буду работать с его транслятором. Комментарий. Как и все, что сделано на GPT-3 не является искусственным интеллектом, о чем нам хорошо рассказали милые дамы из гугла Избера на одном из предыдущих семинаров. Поэтому, все на что способен OpenAI кодекс – компиляция из бигдаты. Главная проблема таких систем – они не смогли перейти грань понимания задачи и не умеют программировать вовсе. И на этой высокой ноте давайте мы перейдем ко второй части нашей дискуссии и поймем, что же такое на самом деле программировать с помощью искусственного интеллекта. Сейчас я попытаюсь запустить презентацию Виктора. Это его презентация. Сейчас, как мне это сделать? так вот видно мой экран сейчас программа и джип и джипе видно так видно видно автоматический программист на основе сильного искусственного интеллекта коллеги слышно звук да слышно ну давайте тогда значит я запускаю снова сейчас 

S00 [00:59:28]  : программист на основе сильного искусственного интеллекта. Часть 1. Назначение «Общая структура MVP Этапа 1». Редакция 20210923. Назначение. Программист на основе сильного искусственного интеллекта предназначен для автоматической разработки программного обеспечения на основе интерактивного взаимодействия с квалифицированным пользователем. Программистом на естественном языке с целью повышения производительности труда пользователя. Структурная схема программиста на основе сильного искусственного интеллекта. Общая структурная схема Автоматический программист на основе сильного искусственного интеллекта состоит из следующих модулей. Входной интерфейсный модуль Входной интерфейсный модуль осуществляет ввод текстовых сообщений пользователя с помощью HTML-страницы в браузере. Анализатор входного потока текста на естественном языке. Анализатор входного потока текста осуществляет основные виды анализа текстовых сообщений и выдает структурированную информацию в виде, пригодном для использования антологическим процессором. Центральный процессорный модуль. Центральный процессорный модуль осуществляет онтологический анализ поступающих от пользователя сообщений, содержащих команды и данные, поиск решения и осуществление последовательности действий, необходимых для выполнения найденных решений. Генератор текста на естественном языке. Генератор текста на основе графа по проблемной антологической модели результата создает текст на естественном языке в форме, наиболее удобной для восприятия пользователям. Выходной интерфейсный модуль. Выходной интерфейсный модуль представляет пользователю выходное сообщение в виде текста на HTML-страничке браузера. Анализатор входного потока текста на естественном языке. Анализатор состоит из следующих модулей. Токенизатор. Токенизатор представляет функционал по разделению предложения на составляющие, слава, знаки припинания. Выделитель предложений. Он разбивает текст на предложения, учитывая знаки препинания, использующиеся для сокращений, например, имён, отчеств, слов-сокращений. Морфологический анализатор. Позволяет определить нормальную форму слова или формы, если их несколько. Обработчик суффиксов. Определитель составных слов. Определитель сокращений. Вероятностный определитель частей речи и неизвестных слов. Фонетический кодировщик. Фонетический кодировщик предназначен для определения сходства слов по произношению. Определитель похожих слов на основе SED. Этот модуль может извлекать из своего словаря записи, наиболее похожие на форму ввода. Сходство вычисляется в соответствии с настраиваемой мерой расстояния редактирования строки SED. Определитель именованных сущностей. Распознаватель дат, чисел и т.д. Продолжаем рассмотрение анализатора входного потока текста на естественном языке. Анализатор состоит из следующих модулей. Формирователь посттегов. Детальный анализатор на основе диаграмм. Статистический маркировщик семантических ролей. Смысловой аннотатор и устранитель неоднозначности на основе WordNet. Экстрактор семантического графа. Разрешитель корреферентности. Основанный на правилах анализатор зависимостей. Статистический анализатор зависимостей. Классификатор именованных сущностей. Центральный процессорный модуль. Центральный процессорный модуль состоит из следующих модулей. Синтезатор антологического графа входного сообщения. Модуль общей антологической модели мира. Модуль проблемной антологической модели мира. Модуль проблемной антологической модели исходного состояния мира. Модуль антологической модели действий. Модуль проблемной антологической модели целевого состояния мира. Планировщик. Модуль управления. Модуль выполнения плана. Модуль проблемной антологической модели результата. Командный модуль. Синтезатор выходного результата. 

S05 [01:04:29]  : Виктор, если вы нас слышите, 

S08 [01:04:33]  : Я слышу, вы меня слышите? 

S05 [01:04:35]  : Да, мы вас слышим. Я, честно говоря, не понял, где здесь программирование. 

S08 [01:04:40]  : Я не успел сделать полную презентацию, к сожалению. Я только первую часть, третью часть сделал. 

S05 [01:04:46]  : то есть то, что я увидел, это как бы описание системы Natural Language Processing. 

S08 [01:04:51]  : вот смотрите, здесь написано, я поясню насколько смогу, эта система этапа 1, видите, да? это этап 1, который позволяет создавать простые решение если посмотреть сейчас скажу может быть вот презентацию последнюю страничку включите пожалуйста промотать саму просто презентацию да да да да вот значит то мы увидим, что у нее есть несколько модулей, выделенных фиолетовым цветом. Эти модули – это главное, с чем работает система. Все остальное – это текстовый процессор, который преобразуют в токены антологии. А синтезатор антологического графа формирует уже запрос, то, что человек сообщил, в граф антологии, маленький подграф. который, собственно говоря, и подлежит дальнейшей обработке. То есть это команда какая-то или данные, которые сообщает пользователь во время работы с таким автоматической системой, во время сеанса работы. Так вот, смотрите, я не написал, даже не успел написать, даже описать простейший сеанс взаимодействия с такой системой. Человек садится и начинает вначале сообщить или заставить систему извлечь из памяти модуль проблемной онтологической модели исходного состояния на предпоследнем центральной фиолетовой квадрате. Что он означает? В этом модуле хранится граф модели шаблона мира. то и решительная задача. Допустим, это модель стекового процессора или компилятора. Дальше мы должны, если она уже есть, то этого не надо делать. И тогда мы должны наполнить своим конкретным содержанием, это следующим, То есть, мы должны туда внести свои конкретные данные. 

S05 [01:07:25]  : Виктор, извините, что я перебиваю. То есть, на абстрактном уровне это все понятно, но у нас все-таки тема сегодняшнего разговора, как нам сделать искусственного программиста. 

S08 [01:07:37]  : Я вам сейчас скажу. Подождите, вот ту модель, которую я недоговорил. Можно еще три минуты? Да, конечно. Итак, мы сначала сообщаем модель, абстрактную модель должна знать, либо мы должны словами сообщить решателя, то есть проблемного мира задачи, которую нужно решить при программировании. Допустим, мы должны сложить 10 чисел, прибавить это, умножить на то и так далее, какую-то вычислительную задачу, или 10 раз напечатать какое-то слово и так далее. Все это должно в каком-то виртуальном пространстве внутри системы представить это все, то есть манипулировать. Вот это и есть среда. Ее мы должны вначале, эта система должна иметь в своей, грубо говоря, голове, как и человек. Ну, допустим, переменная 1, переменная 2, переменная 10, там строка. Вот эти мы сначала располагаем такими вещами. Вот это должно внестись сначала в систему. Дальше мы должны внести туда какие-то исходные данные. Мы должны сказать, что вот эта переменная содержит это, строку и так далее. То есть исходные данные для постановки задачи. Это только часть. Мы же не можем абстрактными сферическими конями в вакууме манипулировать. Мы должны конкретные какие-то вещи сообщить системе для того, чтобы она начала дальше соображать, грубо говоря. Дальше мы должны определить или сама система должна иметь конкретный набор своих способностей, то есть действий, которые она может применить к этой системе, к этим данным для того, чтобы искать конечное целевое состояние. И мы должны третье сообщить ей – целевое состояние мира. То есть мы какую цель преследуем? Одну или несколько целей, которые мы хотим, чтобы задача была выполнена. В данном случае программистская задача. Если мы говорим между исходным состоянием и конечным, есть поле для поиска решения, которое состоит из построения плана действий, алгоритма, И решение задачи в виде тестов, допустим, тестового набора. Вот о чем говорили. Так вот, это все подготовка была для того, чтобы запустить планировщик, который в случае, если он находит это решение в виде алгоритма, потом тестирует, вот на последней листике есть модуль выполнения плана, он тестами прогоняет, смотрит, проходят ли эти тесты. И после этого он выдаёт результат. Получил он результат, не получил результат в виде алгоритма и в виде тестового набора одного или нескольких тестов, прогнанных на каких-то конкретных данных. Всё. То есть речь идёт об этом, а не всё остальное. Но вся система управляется речью. Она должна понимать некоторые команды. Допустим, создай модель такую, создай модель такую, создай модель действий, запусти, сохрани. Вот для этого есть еще командный модуль, такие вспомогательные элементы. По сути, эта система относительно простая. На языковом модуле много уделил внимания, который сейчас не является центром данного обсуждения. Но я словами попытался объяснить суть этой системы. Конечно, тут еще только поверхностное вот это объяснение, потому что эта система должна и обладать еще опытом. Вот то, что ГПТ-3 и кодекс OpenAI, он охватался много информации, но он ее недостаточно скомпилировал. Здесь вот как человек делает, он изучает чужие коды, изучает один, десять, сто или тысячу в том же гитхабе, но он вынимает оттуда главное – структуры, алгоритмы, в отличие от GPT-3, который вынимает форму. То есть вот форма, вот как есть этот код, вот этот кусочек кода, может быть, я могу и показать. Ну, к примеру, я так предполагаю. Поэтому она должна учиться, и общая онтология должна помогать в этом планировщике именно на этапе получения решение выработки плана, она должна не только текущим пользоваться, но и ранее запомненными сведениями. Ну, где-то так. Это я сейчас пока оставил за бортом обсуждения. Но как это решать? У меня в голове конкретно есть варианты. Все. 

S05 [01:12:12]  : Виктор, спасибо. У меня такое ощущение, что все, что вы рассказали, за исключением двух-трех фраз в конце, это настолько абстрактно, что может быть применено к управлению космическим кораблем, управлению умным пылесосом, управлению умным холодильником. То есть, это все универсально, абстрактно, основано на антологиях, все как бы корректно, но настолько же абстрактно, насколько не очень полезно для решения, мне кажется, конкретной задачи. Почему? 

S08 [01:12:43]  : Минуточку, минуточку. Я говорю о том, что я лично испытывал и тестировал несколько месяцев. 

S05 [01:12:48]  : У нас же есть совершенно конкретная задача. 

S08 [01:12:50]  : Правильно, но программир, вот сейчас, когда эта задача обозначилась месяц, не больше месяца назад, я физически не мог сделать, в коде все это сделать для того, чтобы показать вам так же, как эти ребята проехали. с прекрасными сезиономиями, показывающие, что они там все достигли. я физически это не мог за месяц сделать, чтобы именно в программном приложении. да, эта система универсальная, поэтому мы можем любую модель туда любые наборы действий и любые результаты получать в разных видах, да, действительно это универсальная вещь, но при программировании специфика будет вырабатываться именно когда мы обучим ее именно программистской части, то есть данными, то есть так же как И они именно гитхабом и другими вещами кормили. Они же не кормили просто обычными текстами, литературными, художественными. То же самое здесь. Мы должны его сделать проблемную область. Я поэтому говорил про определенные проблемные направления. А в данном случае из области программирования. Этого сейчас у меня, естественно, нет, но это предполагается. То есть я не реализовал это. Но в других направлениях я попробовал. И сейчас я говорю, этап один. То есть самая примитивная, самая простейшая вещь – реализовать. МВП этап 1. Я же не говорю, что это самая продвинутая и замечательная система должна быть. То есть я никакой фантазией здесь не занимался. Всё. 

S05 [01:14:28]  : Спасибо. Комментарии? Комментарий Дмитрия Салихова. Тут получается, что для того, чтобы научить систему решать какую-то задачу, нужно заложить в нее полную картину предметной области и всех программистских паттернов, которые могут пригодиться для ее решения. То есть нужно, по сути, сначала решить ее как программист, а потом система оформит это в виде кода. Дмитрий, я прокомментирую, за исключением того, что вы написали про всех программистских паттернов, это, собственно, задачный подход Евгения Витяева, и насколько я понимаю, это близко к тому, что рассказывал Виктор, и то, что обсуждалось недавно у нас в телеграммной группе, что да, если мы не можем построить универсальную систему, совершенно универсальную систему, которая будет решать любую задачу. Мы можем построить систему, которая при загружении в нее определенных условий, описывающих некоторую операционную среду, будет решать задачи в этой операционной среде. Но все паттерны туда не обязательно закладывать, то есть как раз некоторые паттерны она может учить сама. Но в принципе да. Комментарии на Юрия Бабурова, Дмитрию Сальхо. «Дмитрий, это хорошо, если такое еще получится. Мы готовы один раз описать картину всей предметной области, если это решит нашу задачу. Увы, так это не работает». Значит, мышление – это намного больше, чем перечисление программистских паттернов и выбор лучшего. Да, наверное, так Дмитрий Харифов отвечает, это решит одну узкую задачу в этой предметной области. Ну, опять-таки, мне кажется, что вот подбор паттернов – это вот, собственно, задача, которую которую нельзя, так сказать, заложить. То есть, паттерны нужно искать, но паттерны, они должны опираться на операционную среду и онтологию, которую эта операционная среда описывает. Еще комментарий Юрия Бабурова по поводу про композиции моделей. Вот здесь вот, мне кажется, есть интересная тема для дискуссии. Значит, про композицию моделей я тоже много говорил. Качество композиции Что-что? Модули. Да-да-да, про композицию модулей я тоже много раз говорил. Качество композиции двух модулей по 90% будет на уровне 81%. Большие сетки как раз и пытаются это преодолеть путем отказа от модулей. Одна большая сетка покажет те же 90%, то есть будет лучше, чем композиция двух по 90%. Ну а на евристиках писать такое, вместо сеток, получить качество на том же уровне, но потратит намного больше времени. Вот здесь, мне кажется, у меня есть, если не дискуссия, то, Юрий, вопрос к вам. И для того, чтобы этот вопрос задать, я вернусь все-таки в исходную точку дискуссии. Я попытаюсь заостриться на последнем синеньком квадратике Виктора, модуль проблемной онтологической модели результата, с точки зрения того процесса, которые используются при разработке сложного программного обеспечения. То есть, предположим, мы пишем не hello world. Предположим, мы хотим написать некоторую систему, которая будет приносить некоторую пользу, либо человечеству, либо бизнесу. И у нас здесь возникает, если мы будем эту задачу декомпозировать, мы же когда делаем автомобиль, мы же не пытаемся построить такой GPT-3, куда мы будем засыпать куски порезанной резины, электропроводов, битого стекла. Оно пожужжит, пожужжит, а потом оттуда выйдет автомобиль, где в ключ вставляю и он поехал. Да, это вот, Юрий, я пытаюсь немножко сарказма на вашу концепцию, что композиция не нужна, а нужно просто все сразу через большую сетку. попытка решить все одной большой сеткой, мне кажется, это попытка сразу получить готовый автомобиль из большого числа химических элементов, из которых он состоит. Отдельно, что сама машина разберется, где у нас будут колеса из резины, а где кузов из металла. Все-таки, мне кажется, что нужно учитывать специфику разработки процесса программного обеспечения, где Одна проблема заключается в том, чтобы вообще понять, в чем задача. И для того, чтобы написать даже функциональное требование из хотелки бизнеса о том, что вот мне нужно, чтобы было много денег или чтобы все было красиво, нужны определенные аналитические способности, чтобы вообще понять, о чем, собственно, требование-то. Какой у нас бизнес-процесс и какую задачу мы решаем. Вот. Дальше, после того, как мы поняли, какую задачу мы решаем, возникает вопрос эту задачу как-то донести до программиста. И очень часто навыки бизнес-аналитика, которые в состоянии общаться с бизнесменом и понять вообще сущность задачи, они не всегда достаточны для того, чтобы программисту донести информацию на его языке. То есть есть некоторые аналитики, которые в состоянии вообще в конечном итоге выдавать программистам код на SQL, а эти программисты потом этот код на SQL встраивают уже в какие-то решения. Но очень часто между аналитиком, бизнес-аналитиком, который пишет функциональные требования на основе хотелок бизнеса, возникает еще тот самый архитектор, про которого Игорь сегодня говорил, который строит уже архитектуру, который на основе функциональных требований пишет СРСы или ТЗшки уже для программистов. А уже дальше возникает вот та задача, с которой к нам пришел Эдуард, когда у нас есть ТЗ, и эту задачу нужно превратить в код. И вот здесь есть тоже история, которую я сейчас расскажу, что на самом деле тема превращения спецификации в код и автоматизации этой истории, это тема, на которую были потрачено чудовищное количество денег порядка четырех десятков лет назад. То есть вот компания Oracle тогда уже была, компания IBM тогда уже была, была еще тогда Известная в свое время компания Tejas Instruments. По масштабам это было примерно то же самое, что сейчас какой-нибудь Google наряду с IBM и Microsoft. Сейчас она, по-моему, вообще уже прекратила существование, а тогда это был главный производитель калькуляторов. Одна из крупнейших IT-компаний наряду с Oracle. IBM. И вот у каждой из этих трех компаний у них был свой флагманский продукт, который решал задачу написания кода спецификации. Это была целая индустрия. Эта индустрия называлась Case-Aided Software Engineering или CASE. И в рамках этой технологии делалось следующее, что создавались инструменты для аналитиков, с помощью которых аналитики рисовали разного рода диаграммы, заполняли разные роды формы. И таким образом, с помощью этого инструментария, который на сегодняшний день свелся к тому, что называется UML, Надеюсь, что многие это знают из-за графической спецификации. С помощью разных специфичных для каждой из этих трёх платформ технологий, кроме трёх технологий была ещё куча мелких фирм, которые тоже со своими решениями были. Но суть была в следующем, что мы генерировали некоторые геограммы, А потом сгенерировали, нарисовав фотиограммы кнопочки, которые выдавали работающий код на Каболе, на PL и SQL, на C++, то есть на том языке, на генерацию кода, на котором данная система была настроена. Вот. И проблема-то свелась к тому, что это все не взлетело. То есть, на сегодняшний день такие системы, я, честно говоря, даже не знаю, где они используются. И не взлетело это потому, что выяснилось, что после того, как вы изгенерили этот код, его программист пошел и поправил. Потому что код выяснилось, что там есть какие-то где-то баги, где-то нужно оптимизировать, где-то изменились требования. А если изменились требования, то, конечно, с одной стороны аналитик может пойти и поправить эту диаграмму. и тогда можно перегенерировать новый код но новый код уже программист соптимизировал и получается конфликт что программист старый код сгенеренный из исходной модели уже соптимизировал или поправил какие-то баги А и потерять свои изменения, применив новый код с генеренной моделью с учетом новых требований, уже невозможно. То есть можно только начинать с нуля новую версию системы. Ну и вот, насколько я понимаю, чисто вот в силу таких технологических проблем этот подход в целом не пошел и если переходить на как бы применение искусственного интеллекта не просто для того чтобы там ткот тырить значит по кусочкам для решения каких-то функций ну тут конечно нормально или там автокомплит какой-то делать тоже нормально А для того, чтобы применять искусственный интеллект именно для автоматизации процесса в целом, то вот проблема стыковки исходных моделей с исполняемым кодом – это проблема неразрешимая. И, собственно, на решение этой проблемы были направлены усилия ряда товарищей, включая меня. Также этим занимается группа Дмитрия Ивановича Свериденко, который сегодня не пришел, но тот тоже мог бы про это рассказать. Подход заключается в том, что мы, вообще говоря, не пытаемся генерить код. Мы строим фокус нашего решения не на коде. который находится в центре у ребят из GPT-3. То есть мы из докстрингов генерим код, ну и потом еще и нетесты тоже, наверное, можем сгенерить или там использовать существующие. А алгоритмов-то у нас нет, у нас только код и все, и документация. А вот в том подходе, про который я говорю, гипотетическом, к сожалению, на сегодняшний день, в основе лежит именно алгоритм. То есть у нас алгоритм является тем, что исполняется в бизнес-приложении. То есть в этом смысле нам нужна не технология, которая будет язык спецификаций превращать в программный код на некотором конечном языке программирования, а нам нужна технология, которая будет исполнять алгоритмы и бизнес-правила и бизнес-процессы, специфицированные на том или ином языке, будет их исполнять в некоторой операционной среде, которая будет транслироваться в процессорную инструкцию на той или иной платформе. И у меня было несколько реализаций таких проектов пилотных, они были достаточно успешны в каких-то узких областях. Как большой бизнес это не полетело, но у коллег Евгения Витяева из компании iLine У них это поставлено на конвейер. То есть, язык Delta0SL, который, кстати, будем обсуждать на следующем семинаре про языки программирования AGI, он, собственно, это реализует. Что такое язык Delta0SL? Это язык для построения доменспецифических языков для любых пресловутых операционных сред, где В терминах этого языка вы можете описывать любые задачи. И, собственно, исполняется не программа, которая говорит, как нужно решать ту или иную задачу, а исполняется спецификация, которая говорит о том, что, вообще говоря, должно происходить. И там нет программистских паттернов, потому что там есть некоторые правила, там есть некоторые решения. Поскольку эта программа является по сути материализацией некоторого семантического графа или смыслового графа, то никто не мешает методами логического вывода а-ля NARS, P-WANG или а-ля систему Discovery Витяева искать новые паттерны, искать более оптимальные подграфы, реализующие или альтернативные графы, реализующие тот или иной текущий граф и строит новое решение. Но в этой ситуации у нас вообще исключается процесс генерации кода. Потому что код в этой ситуации не нужен. А если код нужен, то естественно его можно сгенерить. Если у нас есть алгоритм, то проблема генерации кода из алгоритма решена большим числом компаний для большого числа языков программирования уже 30-40 лет назад. и проблему не имеет. А проблема получения... Вот. Соответственно, остается вторая проблема. Остается проблема генерации алгоритма по коду. И вот здесь как раз недавно была интересная статья. Я вот что-то ее не приготовил. Кинул потом ссылку. Значит, статья очень интересная. По-моему, тоже, кстати, она из OpenAI. И они попытались реализовать, собственно, концепцию семантического перевода. языкового перевода, то есть сек-ту-сек, трансляции из русского в английский, из докстринга в питон или из докстринга в джаваскрипт, они попытались сделать трансляцию из естественно-языкового представления в семантическое представление. То есть, получается, мы как бы решаем задачу перевода, но у нас целевой язык, в который мы переводим, он не естественный, он семантический язык. Это набор инструкций или каких-то взаимодействий, комбинации из этих инструкций, которые мы можем выполнять. А инструкции дальше могут быть любые. В том примере, который будет в той статье, который пошлю, там просто инструкции для робота. То есть, если мы хотим сказать, что робот должен сделать, то мы просто делаем трансляцию из текста на естественном языке в язык конкретных команд конкретного робота. И если мы на доменспецифическом языке, того же типа Delta0SL или того языка, который я в своих проектах использую, URL, но это будем на следующем семинаре говорить. Если мы научимся описывать с одной стороны алгоритмы на некотором семантическом языке, И у нас будет тренировочный корпус описания каких-то типовых алгоритмов на этом языке. Если мы можем и будем иметь возможность описывать эти алгоритмы на естественном языке, и мы сможем создать параллельный корпус для какого-то числа типичных задач, то тем самым мы научимся сначала генерить любые семантические программы на основе любых текстов на естественном языке. Если они используют один и тот же словарь и работают в тех же операционных пространствах. Ну а генерация кода по семантической программе, как я уже сказал, это задача чисто механическая, которая решалась 30 лет назад. Извиняюсь, что занял много времени. Ей была рука, видел у Виктора Носко. Виктор, пожалуйста, и дальше пойдем по вопросам, по комментариям. 

S03 [01:31:11]  : Да, здравствуйте. На самом деле, я что хотел? На самом деле, вы, Антон, сейчас многое сказали из того, что хотел сказать я. Но я привяжусь к чему? К тому, что у нас недавно был пост в сообществе о том, что есть некий заказ или проект или некое желание от человека какого-то. который хочет сделать систему похожую на OpenAI Codex. Я проводил обсуждение, поскольку у меня нет никакого идеи, мы не подписывали и не договорились, я считаю, что я имею возможность рассказать какие-то базовые вещи, результаты нашего обсуждения, хотя оно было достаточно недолгим. я буду сначала зачитывать тезисы, которые были там в этом посте в группе, их все знают, просто буду зачитывать и сразу же буду давать на них комментарии. первое, что требуется в этой системе. самое важное, что я выяснил в результате обсуждения, это действительно, что повторение кодекса не нужно в этом проекте. вы говорите, мы все обсуждали, видели этот пост, повторение кодекса не нужно, это означает, что написание кода в этом проекте не является конечным результатом, а является нечто другое. так вот, я выяснил, что нечто другое, это как раз то, о чем вы говорили сейчас, то есть это именно обучение, да, смотрите, внимание, скажем, я скажу общую задачу, внутри нее есть некоторые задачи, которые вы перечисляли, то есть это обучение человека программированию с помощью всех тех инструментов, в частности, описание и объяснение алгоритма, описание и объяснение какой-то определенной последовательности действий, как правильно ее делать. Но здесь есть большое количество подводных камней. И когда я услышал эту задачу, я понял, что эта задача уже не является такой, скажем так, не является такой крутой и сложной, соответственно, не нужно повторять иконы и кодекс, и это означает, что мы вот здесь в России, я уверен, что есть много команд, которые могли бы выполнить, возможно, не всю задачу, но какие-то некоторые ее элементы. И в частности, вот я хочу сказать, сейчас буду по порядку идти и скажу про один из элементов, который, мне кажется, мы можем, в частности, мы выполнить. вот поставка задачи, пользователь пишет на ТЗ, на естественном языке, здесь проблема следующая, как уже здесь говорилось, что проблема в том, что проблема сжатия, вы когда берете много подробную информацию и ее сжимаете, у вас потом в обратную сторону разжать ее не получается и вы видите то примеры этого, когда нейросетки дорисовывают якобы восстанавливая картины, дорисовывают их. Что они делают? Они делают перенос наиболее популярных черт лица на эти картинки. Поэтому восстановление Цезаря с помощью черт не является легитимным. Соответственно, здесь проблема полноты. Невозможно, скажем так, невозможно по некому короткому промпту, тексту тезе раскрыть его в какие-то компоненты, требуется итерационный процесс, и этот заказчик, скажем так, он это понимает, мы это обсуждали, он это понимает, и поэтому мы движемся дальше, я говорил про эту проблему, мне нужно что-то делать. вторая задача вообще, как понимаю, нерешаемая, прога должна распознать смысл задания пользователя, понять смысл стоящих перед ней задач и быть способным их решить. Ну, здесь можно долго спорить о слове «смысл», но и, в общем, здесь второй этот пункт является на текущий момент неразрешимым, как мне кажется, потому что было высказано пожелание создать мыслящую машину, которая хотя бы мыслила над какими-то категориями, естественно, Когда мы говорим про смысл и мышление, мы видели, какие у нас там были споры на одном из прошлых семинаров, поэтому я здесь на этом пункте останавливаться не буду. Скажу, что он достаточно тяжелый и неразрешимый. Следующий пункт. В случае, если программа не понимает суть конкретной задачи или конкретного действия, то она должна задавать уточняющие вопросы, принимать ответы на эти вопросы. и тогда в процессе вот такой итерационной работы эта программа-продукт начнет понимать суть. Вот здесь, поскольку мы специализируемся на чат-ботах и на QA-системах, вот здесь эта штука уже близка к тому, что решить можно. Смотрите, мы можем на самом деле обучать систему понимать какие-то определенные, как писали здесь в чате, в чате зума определенный узкий спектр задач и построить вопросно-ответную систему, про которую я, кстати, говорил немножко так мельком на одном из семинаров. что она будет делать? она будет вытаскивать из различных источников, естественно, в интернете, в научных статьях, она будет доставать оттуда описание алгоритмов, которые, возможно, человек, этот обучающийся какой-то программист, не способен сформулировать вообще. То есть, допустим, он говорит про некий алгоритм, но не знает, как этот алгоритм называется правильно. Даже если он знает, как этот алгоритм называется правильно, он не знает, как он работает внутри, что он получает на вход, что на выход, какие у него есть граничные условия, какие правильные паттерны применимости этого алгоритма, причем видов этих алгоритмов огромное количество. Соответственно, мы можем брать только лишь определенную узкую сферу. Что тогда происходит? Мы можем обучить нейросетку, в частности трансформер, понимать некоторый кашаобразный запрос юзера, которым пишут простыми словами, он говорит, что я хочу сортировку пузырьком. Ему система скажет, что сортировка пузырьком — это устаревшая вещь. Давай сортировка вставками. Откуда она это знает? Она знает это из научных статей, из различных обзоров. И этому систему научить можно. Она ему посоветует правильный алгоритм. Затем он спросит, как работает сортировка вставками. И здесь тоже в системе QA в частности, которую мы сделали, она способна делать следующее. Она из разных источников достает с помощью Deep Passage Retrieval, достает тексты, в которых содержится правильный ответ, но, возможно, он содержится не в каком-то одном тексте, он разбросан по различным статьям, по каким-то отдельным абзацам. Так вот, такая штука на основе Барта Такая система позволяет сгенерировать из различных кусочков знаний правильный ответ и дать ему короткое достаточно описание. В общем, что-то типа поисковой системы, но только более крутой, типа QA-системы. Здесь важно, я скидывал некоторые демы этой системы, я видел, что многие не поняли, в чем суть ее. Я сейчас могу сказать, в чем суть. Именно в том, что она не является retrieval-based. то есть она не достает готовые ответы, которые уже где-то содержатся, она их собирает как человек. Это основная фишка, и именно эта фишка позволяет применить эту систему к данной сложной задаче описания какого-либо алгоритма или описания границ его применимости. ну естественно самый сложный пункт это понять какому перечню алгоритмов можно применять такую систему. здесь тоже можно большую-большую дискуссию, но в общем суть в чем, в том что Когда мы сейчас ввели обсуждение, мы говорили о том, что задача супер-супер сложная и к ней вообще никак не подступиться. Более того, я бы сказал, что вряд ли кто-то из нас мог бы повторить результаты OpenAI кодов, потому что у них 150, вот если откроете статью, у них 159 гигабайт GitHub. То есть ни у кого нет доступа. У Microsoft, потому что он его купил, у него доступ есть. нет, поэтому физически это очень дорого и так далее. но вот некоторую небольшую часть этой системы сделать вполне реально. и эта небольшая часть будет как раз делать полезную вещь. она будет образовательная, она будет помогать экспертам, программистам. дискуссионная часть. дело в том, что существуют паттерны программирования. там фабрика и прочие вещи. то есть это такие штуки, которые внутри программирования некоторые вещи там очень круто оптимизируют. их не нужно писать повторно. таким вещам в принципе научить подсказывальщика вполне можно. 

S05 [01:40:14]  : Виктор, спасибо. Небольшой комментарий. С моей точки зрения вы слишком много и в отношении слишком большого числа пунктов говорили невозможно и неразрешимо. Но там я не буду впадать в дискуссию, только по поводу GitHub скажу. Ничего невозможного в доступе к гитхабу нет. То есть, вы пишете обычный кроллер, который кроллит гитхаб. Значит, эти ребята не использовали закрытые проекты. Соответственно, здесь вопрос не столько доступа, сколько на количество железа, которое нужно для обработки этого дела. У меня, знаете, еще какой вопрос, пока не забыли. Юрий Бабуров, вы можете на мой наездно ответить по поводу одной большой сетки? Вы будете настаивать, что нужно все-таки решать задачу целиком, а не пытаться ее на кусочки дробить? 

S04 [01:41:11]  : Скажем так, я описал только часть, то есть я примитивно говорил про как бы про сложности проекта Виктора. в таком модульном делении всегда возникают проблемы. именно когда модули некачественно работают, при композировании модулей возникает еще больше проблем. при этом мы, увы, не можем бесконечно повышать размер сеток и все укладывать в одну сетку, поэтому на практике используется комбинированная модульная структура. то есть мы какие-то модули делаем нейросетками или какими-то способами, а другие модули мы делаем вручную. то есть комбинируем эвристики, эвристический подход, когда вручную изучаем проблему, и комбинируем какие-то нейросетевые эффекты, когда нейросетка сама обучается и какую-то задачу может решать. Зависит от задачи, но дело в том, что, например, ни один программист не может написать эмаристически программу распознавания изображений, которая бы работала сравнимо с сетками. неважно, будет он год писать, 10 лет, 100 лет эвристиками, качество того, которое сетки показывают на image нет, он не достиг. понимаете? сложность-то именно в этом. люди считают, что программирование классическое лучше сеток, потому что оно дает гарантированный результат, и этот результат 100%. Но это не так для сложных проблем. Та же самая проблема повторяется еще раз, как в зеркале, когда мы обсуждаем в целом проблемы программирования и искусственного программиста. Мы можем с помощью языка высокого уровня, сверхвысокого уровня, которым является домен language, мы можем с его помощью решить далеко не все задачи. Мы можем решить с его помощью императивные задачи достаточно простые. Для примера самый лучший способ понять, что такое неимперативные задачи. Начнем с задачи. Поставь таймер, который сработает через 5 секунд. Напишите мне императивную программу, которая это сделает. вы можете использовать sleep, но sleep не гарантирует, что она сработает через 5 секунд. sleep – это то, что текущий процесс будет 5 секунд занимать. чтобы решить эту задачу, вам нужно сравнивать текущую дату, периодически получать эту дату. вот получается event-based programming. теперь возьмем какое-нибудь более сложное действие. например, я скажу, напишите программу, которая, когда пользователь говорит О, выводит красный прямоугольник мне на телевизор. справится ли компьютер с такой задачей? не справится. вам требуется разобраться со спецификацией, как работает телевизор, как выводить на него изображение, вам требуется разобраться, что за звуковое устройство у пользователя, как считать с него звук, как этот звук, что на него, какую другую программу из велиона, строккода или с сетками натравить. и это не сводимо просто к простому какому-то алгоритму. хотя для человека эта задача кажется такой же примерно простой, как и первая задача, что через 5 секунд выдать мне, не знаю, запищать через 5 секунд. то есть сложность именно в том, что если обычного человека, не программиста, допустить до программирования и сказать ему формулировать задачу, он вам наформулирует таких условий, которые вы никогда не сведете к оперативному программированию и даже не сведете к простому even basic программированию. и значит вам потребуется куча знаний, которые отличают программиста от обычного человека. программист не только умеет на основе того, маленького запросика говорить ответ, а он именно декомпозирует проблему, он учтет над систему, то есть если мы делаем машину, мы должны знать, что машины врезаются друг в друга и поэтому заложить в машину подушку безопасности. Понимаете, это совсем другое знание, нежели просто про химические элементы. при этом для создания каких-то частей машины мы вполне можем использовать автоматические методы, когда просто компьютеру говоришь, что сделать такой-то узел такой-то формы из таких химических элементов. и он сам справится. то есть опять же на низовом уровне компьютер помогает, может как-то помочь. по сути, я бы сказал, что нейросетка – это способ, как соединить и получить автоматически миллионы эвристик на основе миллиона картинок или чего-то, миллиона фактов. Эти эвристики автоматически смешать таким образом, чтобы задача решалась на этих картинках, находился ответ. И в том случае, если эти картинки отражают общую совокупность в мире, эта задача решается. Но когда мы приходим на больший уровень, у нас сложность задачи повышается, и уже генеральная совокупность перестает наблюдаться. Конкретные задачи мы простые решим таким образом, а сложные задачи потребуют совсем других знаний, и для каждой задачи эти знания будут уникальны и новые. Поэтому все правильно. Мы можем заложить антологию, нам нужен какой-то алгоритм, который будет по антологии ходить, как-то думать, и вот это как раз и будет мышление. и с помощью мышления, если мы его натренируем, вот это думание по антологии и какую-то генерацию по внутреннему представлению чего-то, это и будет нам решать все задачи уже более хорошо. но вот это достаточно объемная задача, достаточно сложная. И, безусловно, это не просто вытаскивание каких-то там ответов на основе кода, это еще преобразование вот этого внутреннего мира антологии. И вот это преобразование во внутренний мир антологии, увы, сейчас не решено на хорошем уровне задачи. И все проблемы, все упирается именно в это. То есть, например, вы знаете, что машинный перевод ушел намного дальше, чем просто понимание компьютером человека. Почему так? Потому что для машинного перевода, как и для человеческого, не требуется как раз большая часть этого домысливания. У нас уже есть слова, которые достаточно точно описывают какие-то элементы мыслительные, которые нам нужно описать. Какие-то вещи, какие-то предметы, какие-то действия, какие-то атрибуты. И поэтому перевод на другой язык, где есть другие слова, но похожие, и которые позволяют все это передать, мы эти слова можем компьютером подобрать. А как только у нас ставится задача из нашего языка письменного перевести во внутренний мыслительный язык, у нас нету большого дата сета, у нас нету даже понимания, как этот внутренний мыслительный язык устроен, и у нас пока что нету хорошего для этого транслятора. То есть мы не можем построить транслятор, который работает на сетках, потому что у нас нет большого числа примеров и мы не можем построить эвристический транслятор, потому что это как раз одна из тех задач, как с распознаванием изображений, которые эвристиками можно долбить хоть там сто лет и ничего не сделать. поэтому давайте попробуем с этим что-нибудь придумывать. как-нибудь в следующие разы попробуем подумать. то есть про мышление уже говорили, но может еще раз надо поговорить о том, как мышление может, как подобный транслятор мог бы работать в ту или в другую сторону. 

S05 [01:50:28]  : Юрий, спасибо. Я согласен с вашим главным тезисом, с десятью руками, но вначале вы сказали нечто, что, мне кажется, противоречит вашему главному тезису. Я вот чуть-чуть прокомментирую. Вы сказали, что люди, какие это, я не понял, какие люди, кого вы имеете в виду, считают, что все можно сделать евристиками, в то время как ничего сделать евристиками нельзя, все гораздо лучше делают нейросети. Я что-то такое услышал. Вот, значит, я здесь две вещи скажу. Во-первых, вот на моем текущем проекте, про который я не могу подробно рассказывать, но, тем не менее, мы там занимаемся сентиментоанализом в частности. Так вот, на том, что вы называете евристике, конкретно мой сентиментоанализ, построенный на евристиках, результаты пока что получаются лучше, чем на любой из нейросетевых моделей сентимент-анализа. И там, и там из коробки. То есть, пока что мы файн-тюнингом ни на одной модели не занимались, только вот позавчера на Берте, специально затюненном на Fintech, получили где-то результаты, которые чуть-чуть дотягиваются до моих. хотя у меня как бы тоже евристики. То есть, я бы не стал так говорить, что везде ничего нельзя сделать с евристиками. Это один момент. Второй момент. Я думаю, что людей можно делить на три части. И мне кажется, мы относимся с вами к одной из этих частей, к одной и той же части. Есть люди, которые говорят, что ничего нельзя сделать на евристиках, а все можно сделать на нейросетях. Другие люди есть, которые говорят, что ничего нельзя делать на нейросетях, а все надо делать на евристиках. А третьи люди говорят, что на евристиках можно делать, но нужно евристики генерить с помощью нейросетей, потому что вручную вы столько евристик никогда в своей жизни не напишете. Вот мне кажется, вот эта вот последняя позиция наша с вами общая. И если это так, то я очень рад. Пожалуйста, Владимир Смолин, у вас есть комментарии. Я вижу и верю в это. 

S07 [01:52:37]  : Комментариев у меня много, но я постараюсь как бы основные рассказать. Начнем так, немножко издалека, что когда появляется какой-то предмет, его сэкрализируют. То есть, понимаете, вот мы что-то можем запомнить о книге и можем записать больше. И если вы почитаете легенды, то там искали волшебную книгу, которая решала все проблемы. Потом появились компьютеры. Компьютеры, вы понимаете, тоже могут вычитать лучше, чем мы. И, собственно, у нас есть песня о том, что нажми на кнопку, получишь результат. И, значит, все проблемы решатся. Но, как понимаете, это не про книги, не про компьютеры, это неправда. То есть и то, и другое полезные устройства, они много чего хорошего делают, они нужны, но не надо, значит, предполагать, что они решат все проблемы. И, соответственно, с нейросетями, я считаю. Сейчас идет такая синхронизация, что говорят, что мы сейчас примели нейросет, и мы решим все проблемы. Это вот как бы... Мне сказать, что никакие проблемы не решаются. Много проблем решается хорошо, но сказать, что применили нейросети, решили все проблемы, такого даже близко нет и, скажем так, в ближайшие годы не предвидится. Все-таки надо понимать, что имеются узкие задачи, которые нейросетями решаются хорошо, а если мы пытаемся их применить к широким задачам, как задачи программирования в частности, то она решается плохо. Чтобы, значит, нейросети, конечно, обладают положительными свойствами, их надо использовать, но надо, значит, сложную задачу, значит, программирования разбивать там на части и смотреть, что если есть какие-то там, скажем так, серийные задачи, которые решаются хорошо, на некоторых статистик хорошо накапливаются, во-вторых, они, значит, имеют какой-то спрос, и там, соответственно, можно эти самые нейросети применять, и от них будет польза. Вот. А говорить о том, что мы сейчас как жпт там научим речи вообще ну как же пт будет собственно какие-то фразы говорить хорошо какие-то фразы там ну совершенно не уместно вот ну и потом собственно программист это же понимаете очень собирательное понятие вот чтобы это было понятно то есть вот я сам не люблю но значит здесь как-то это принято Меня много раз учили программировать. Причем первый раз произошло еще в средней школе. Это был 1972 год прошлого века. И нас в школе стояло БСМ-4. У нас было каждую неделю, кроме десяти часов общей математики, четыре часа вычислительной математики и еще программирование было отдельно. Но причем те, кто нас учили, говорили, что, ребят, ну мы вас, конечно, учим на программистов, но никто из вас программистов не станет. Почему? Потому что вы все поступите в институт и будете там развивать математику. А если вас не учить в математике, то и у вас программистов не получится. И причем это было правда. У нас, правда, там это подкрепили, свозили в консервировскую дивизию, показали, значит, как в процессовой дивизии хорошо, значит, в армию. В институт поступило сто процентов С-класса. вот и программистами никто не стал что интересно действительно вот это вот как бы сказалось то есть кодировщик он конечно тоже программист но это кодировщик вот но значит хорошую программу кодировщик сам по себе не напишет им должен тот руководить соответственно выяснять сойдется ли там алгоритм вот значит конечно значит какие-то части повторюсь вот этого сложного процесса который значит как бы на самом деле не как бы два человека, заказчик и кодировщик, а там должно быть какое-то научное основание, либо он сам должен знать, а лучше когда несколько специалистов решают проблему. То есть, чем больше специалистов, как правильно говорит Боборов, тем больше проблем, что кто-то друг друга недопоймет, и там будет сложный процесс создания системы. С другой стороны, если один человек все пишет сам, то, скорее всего, в каких-то частях задач он плохо сам разбирается. И вот это вот как бы, если какую-то часть, значит, можно более или менее, значит, сказать, что там есть много общего и достаточно набрать хорошую статистику, которая приоритетативна, и нейронные сети с ней будут справляться, это вот как раз то место, где они, собственно, могут быть реализованы. Ну и вот с чем я хочу с Антоном поспорить, о том, что он, как и многие из нас, нас еще тогда в средней школе учили, что неизвестно, когда машина научится думать как человек, а вот человек довольно быстро научится думать как машина. И вот мое такое впечатление, что когда мы себе представляем, что мы, значит, собираемую нам информацию, сворачивая в семантические сети, это вот как раз мы пытаемся думать как машина. Ну вот через две недели, значит, если меня там не передвинуть, я расскажу, что все-таки тот общий язык, который там кошки, лошади, люди и, может быть, роботы будут представлять там окружающий мир, он все-таки должен быть другим, но это, на мой взгляд, там у каждого, конечно, свое, может быть, мнение, вот, но... В любом случае, даже если будет это понимание, то оно не отменит специализацию. Сложные задачи одним устройством решить не удастся. Каждое устройство или человек всегда имеет состязательность. Мы решаем сложную проблему, надо собирать коллектив, который отдельные части задач будет решать. то есть, понимаете, в ту же школу, хотя это школьный курс был, средняя школа, все-таки в вычислительной математике нам за два года дали больше трехсот часов. И то, что там машина будет консультировать заказчика о том, какие там будут алгоритмы, может быть, не тридцать, но даже тридцать часов он как бы очень, скажем так, утомится слушать. вот то есть как бы вопрос общения с заказчиками это одна проблема вопрос выяснения устойчивости вот потом как бы сказать говорить о том что не автоматизируется программирование но это как бы странно потому что эти языки программирования визуальное программирование, я работаю в институте прикладной математики, у нас защиты каждый год проходят по программированию, и каждый год 3-4 защиты по различным оптимизаторам, то есть вы пишете код, автоматическая программа его оптимизирует и улучшает ваш код. то есть, в принципе, конечно, задача большая, и, видимо, и нейросетям в этой задаче тоже есть место, но только, как бы сказать, если вы хотите получить какой-то результат, нужно все-таки браться не вообще, как сказать, всех специалистов подвинуть, а давайте подумаем, какое узкое место там может взять на себя нейросеть, и там, действительно, она может реализоваться. Ну, не знаю, я еще много о чем мог бы говорить, но, боюсь, я устану. 

S05 [01:59:26]  : Спасибо, Владимир. Еще у нас было два комментария от Виктора Казаринова. Кстати, Виктор, у вас сегодня было прекрасно слышно, то есть у вас какое-то чудо произошло с интернет-связью. Виктор прокомментировал, забыл сказать, что моя система должна искать именно алгоритмы, которые затем преобразуются в программный код на несколько десятков языков. Окей, то есть да, вам спасибо, что в отличие от OpenAI вы включаете алгоритмы в вашу архитектуру. И тоже комментарий от Дениса Попова, что алгоритмы желательно вводить из кода того же GitHub. Ну да, собственно, вот в статье как раз ребята из OpenAI писали, что прямая задача это мы по коду генерим код, когда нам нужно по описанию задачи реализовать этот код. А обратная задача, это когда мы из кода, для того чтобы понять, что делает программа, мы генерим описание. Можно генерить описание, а можно генерить алгоритм. Это надо договориться, в каком представлении этот алгоритм будет в UML, в DeltaNoiseL, в RL или в RationalProcess. Дальше комментарий от Николая Робчевского. Проблема понимания. На самом деле есть проблема достаточно универсальной репрезентации понятого. Мне кажется, что про универсальную репрезентацию понятого мы как раз и будем говорить на следующем семинаре, если я правильно понимаю. говорить о языках HI, на которых можно описывать универсальные репрезентации доменных онтологий, которые мы либо понимаем, либо выражаем. Я угадал. Спасибо, Николай. Олег Серебренников пишет. Компиляторы состоят из фронт-энда и бэк-энда. Причем фронт-энд генерирует промежуточное представление для бэк-энда. И уже последние генерируют машинные коды. Так вот, проблема создания семантического языка сводится к возможности интерпретации с помощью промежуточного представления. И значит, это вопрос проектирования и правильного промежуточного представления. Да, собственно, вот семантические языки как раз-то, насколько я понимаю, на следующем семинаре будем обсуждать. То есть семантический язык переизобретается таким языком и является правильно спроектированное промежуточное представление. Ну да, то есть в моем понимании язык это некоторый способ просто визуализации или вербализации или текстуализации промежуточного представления. Совершенно верно. Олег дальше пишет «Моя компания Intestron просто не дотянула для создания генератора кода программы на основе UML диаграмм, хотя промежуточное представление было под это заточено». Ну вот, как я уже сказал, тот опыт многочисленных компаний, начиная с Oracle, IBM и Tejas Instruments, которые потратили кучу усилий на генерацию кода на любых языках на основе умных диаграмм и потратили деньги впустую, потому что в продакшене ничего не провелось, как раз вот меня это и наводит на мысли, которую разделяют коллеги из группы Свериденко и Витяева, что Не нужно генерить код, нужно просто интерпретировать на лету внутреннее представление или внутреннюю систему понятий, как Java компайлер. Вы можете исполнять Java код на виртуальной машине, а можете через hotspot генерить сразу байт-коды. процессорные инструкции, исполнять процессорные инструкции. Это быстрее просто получается. Мне кажется, вопрос правильного движка. Так, дальше вопрос Игоря Романко. Разве нет лучших алгоритмов для распознавания изображений? Возможно, вы имели в виду алгоритмы для распознавания картинок разного назначения. Для каких-то картинок определенной направленности вроде есть хорошие алгоритмы, которые должны превосходить нейросети. Вот, кстати, хороший вопрос. И вот Виктор Казаринов пишет тоже. «Я на одном из предыдущих семинаров представлял внутреннее око для того, чтобы и мог представить в уме образы, аналогичные человеку». И дальше Виктор Казаринов мне пишет сейчас как раз на эту же тему, что есть вариант, можно генерить эвристики автоматически и нейросетками. Вот, соответственно, у меня вопрос с одной стороны к Юрию Бабурову, а с другой стороны вот к Виктору. И, значит, если кто-то еще хочет сказать, мы можем сказать убедительно, что в задачах распознавания Ничто не может превзойти нейронные сети. Или наоборот, что есть задачи, где распознавание эффективнее решается не нейросетями. Кто-то может, если коротко и убедительно? 

S04 [02:04:47]  : Скажем так, я давайте попробую очень коротко. Не знаю, насколько получится убедительно. два способа, если по большому решение задач, ИФы условные, они же деревья принятия решений, и второй способ – сетки, которые похожи на деревья принятия решений, но отличаются одним нюансом. они могут суммировать какие-то элементы вначале, а потом уже по сумме этих элементов мы будем принимать какое-то решение. и дело в том, что кроме как сеток, кроме как суммировать какие-то элементы, усоединять, делать крупные операции с изображениями, с блоками, с большими и много таких операций делать, собирай какие-то промежуточные фичи. без этого просто деревьями принятия решений нормально распознавать изображение не получается. другое дело, как вы будете эту систему делать, которая будет суммировать какие-то элементы. ну в принципе вы ее можете запрограммировать наифо. метод виолы джонса, он вообще говоря допускает программирование вживую. то есть вы какое-то качество получите. до сеток вы не потянете. и есть много таких задач, которые связаны с тем, что нам факторы не представлены в таком виде, в котором сразу можно записывать деревья. в этом случае их надо как-то объединять, делать фич инжиниринг. Вот сетка за вас делает фич-инжининг, ну вы теоретически можете его попробовать, повторить и сделать выключенную. Я как хорошо разбирающийся в сетках и в том, как они работают, да, иногда. Вчера показал людям, как распознавание текста на картинках блока мест, где текст написан, можно сделать эвристическими приемами. за час подобрал генетическим алгоритмом фактически на мне самом, то есть пробовал разные варианты, примерно понимая, какие элементы я должен скомпозировать, получил штуку. очень крутая штука получилась. да, вы можете попробовать таким способом программировать. качество способа остается под вопросом, особенно в широком случае, когда нам надо что-то большое писать и сложно. 

S05 [02:07:31]  : Юрий, по поводу того, что сетки сами сделают фичи инжиниринг, а выбор параметров нормализации фич тоже сетки будут делать? Одна сетка будет подбирать нормализацию фич, а другая на нормализованных фичах уже инжиниринг сделает. 

S04 [02:07:46]  : На текущий год это, по сути, решенная задача, то есть всего, чего добиваются AppTML, это 2% точности. То есть не 90, а 92% точности, условно говоря, на задачи. это подбор всех параметров архитектуры, скорости обучения, прочих параметров. примерно все более-менее стандартизовано. есть несколько классов сеток, но внутри одного класса уже все стандартизовано. 

S05 [02:08:22]  : Юрий, спасибо коллеге. Кто-нибудь хочет аргументированно возразить, что есть задачи, которые решаются лучше, чем нейросетками? 

S07 [02:08:31]  : Ну, я готов, да. Собственно, если помните, была такая фирма Абби, и она хорошо распознавала сканированный текст, машинописный, и никаких нейросеток там не использовалось. Были часы выставки. вот и в целом то есть если задача скажем так относительно простая то действительно человек может ее решить вот как вот в случае с фирмой обе или там три человека собраться решить то значит несколько там десятков юристов написать согласовать они будут хорошо работать и будут работать даже лучше чем работает на россии в смысле, с меньшими вычислительными затратами, быстрее получать результат, ну и, соответственно, зная все эти информации про вычислительную математику, которые мне и моим коллегам давали, мы, конечно, сможем это улучшить. Но когда, значит, становится распознавание кошек и собак, то в СИЧе и там получается много. Можно, конечно, собрать 100, значит, ученых, которые будут изучать. И каждый, значит, вроде бы хорошо изучит. Но когда мы будем согласовывать между этими места учеными, чтобы в СИЧе вместе работали, то, как бы, задачи становятся неподъемными. А у нейросетки, как бы, эти проблемы, они решаются внутри ее. И вот это согласование там осуществляется внутри. Поэтому если задача не требует таких, скажем так, привлечения большого числа специалистов для её решения и последующего согласования между ними, то, значит, юристики имеют хорошие шансы. А если задача сложная для решения небольшой группы, узкой группы специалистов, с хорошей возможностью согласования, то тут, конечно, на рассетке, значит, на голову выше, и никаких надежд у юристов в этих задачах нет. Вот, собственно, ситуация. 

S05 [02:10:16]  : Спасибо. Виктор Казаринов, выскажитесь, а потом Николай Робчевский. 

S08 [02:10:23]  : Меня слышно? 

S05 [02:10:24]  : Да-да, пожалуйста. 

S08 [02:10:26]  : Значит, я, как уже делавший распознавание документов с помощью онтологии человек, могу сказать, что работа с такими системами не сводится к эвристикам. Я вообще не пользовался эвристиками, ничего не писал. То есть, речь идет, видимо, о чем-то другом. Поэтому я отвечу только за то, что я достиг. Насколько оно лучше или хуже нейросетей, я не знаю. Я не специалист в нейросетях, поэтому про свёрточные сети знаю только одно, что, допустим, ядро свёртки может быть какого-то размера. Я не знаю. насколько большим оно может быть. но у меня аналогичные фичи. система определяет независимо от размера. допустим, определить маленький, средний или большой. и для этого числительных мощностей много не надо. при этом все происходит распознавание с однократным обучением. то есть речь не идет о сотнях и тысячах обучающих примеров. Я предъявляю образец, она определяет фичи и создаётся, грубо говоря, шаблон образа, то есть целевой образ. Таких образов я могу создать несколько. Указать единственное могу то, что является постоянной частью, то есть присутствует данному классу документов. Есть какие-то разовые, там, росписи и так далее. Это мы можем указать, именно эти вещи. И всё. Для этого нужно 5 минут. 5 минут для того, чтобы мы класс документов создали. Всё, закидываю на сервер, и она с этими работает, документами. Можно идти 5-10 таких классов, 20 закинуть на сервер, и всё она распределяет. То есть она и классифицирует, и идентифицирует при этом. Но при этом она пользуется свойствами, первичными, вторичными и так далее, более абстрактными, только внутри онтологического распознавания с помощью звезда онтологии. Я ничего не создаю, не пишу правила, вообще не пишу правила продукционные. Никаких эмбаристик не закладываю туда. Но сообщаю в редакторе в простом, указываю, целеуказания даю, то есть просто графическом редакторе указываю. Вот это не надо, вот это надо. Всё. Вот что я имел и что у меня действует. а говорить огульно о том, что есть символьные вещи, которые работают с продукционными правилами, и есть чисто нейросетевые. Но я говорю, видимо, в третьем варианте, и он у меня вполне работает. просто по фотографии с фотоаппарата любого телефона нормализует, поворачивает, делает, выделяет документы, вырезает части и распознает, и нормализует, и при этом выделяет смысловые части. Да, там, конечно, некоторые нейросеточки используются для отдельных элементов на входе, но только как самые первичные элементы получить. И сразу она преобразуется в онтологическое представление. внутрь попадает общий котел и дальше только в этом идет обработка. все что я хотел сказать. поэтому есть опыт. 

S04 [02:13:40]  : Виктор, ваше дерево, ваша онтология это и есть ваше дерево эвристика по сути. и плюс у вас есть матч на алгоритм против этих эвристик. это о том в общем-то и речь. 

S08 [02:13:53]  : Так я же их не создаю вручную. Нет, правильно, что и в ристике, да. 

S06 [02:13:56]  : Ну, значит, не создаёте вручную. 

S08 [02:13:59]  : А откуда антология появляется у вас? Смотрите, я вручную создаю только одно. Маленькую антологию, она состоит из 20-30 или 40 понятий для того, чтобы описать мир документов. Она никогда не видела никакой документы, эта маленькая антология, предельно простая. Этот мир, я все, забрасываю в систему, она в двух режимах работает. Первый режим, это ей говорит, что вот это является образцом, и указываю, буквально несколько обвожу зон, которые на документе не нужны. То есть они действительно будут, ну вот, мне не нужны, чтобы я их в классификацию включал. Это может быть уникальный баркод или какой-нибудь поле, почтовый ящик конкретного человека. Все. Говорю, а вот остальное ты мне определи, что документ соответствует этому моему пожеланию. Независимо от размера, формы, наклона, поворота, тени, яркости, цветности, найди мне. И она меня с высокой степенью вероятности и обнаруживает. эти документы и обнаруживает положительные и отрицательные ошибки, сообщает вероятности всякие, все вещи. То есть она работает в фузе логика, то есть она нечеткая. И антология с нечеткой логикой работает. Вот и все. 

S04 [02:15:21]  : Что я тут могу прокомментировать? Выбор одного документа из трех или ста работает, выбор одного из десяти тысяч таким образом уже 

S08 [02:15:31]  : еще минуточку, подождите, я говорю о том, что мы берем один класс документов, допустим, накладная такая, накладная другая, протокол такой-то, договор такой-то, это вот такого типа документа, там 10, 15, 30 типов документов, шаблонов, мы закладываем туда, то есть мы целевые классы закладываем, что найди мне, и она говорит, вот это по буквам лучше, буквы, тексты совпадают лучше, здесь у нас рисунок лучше, совпадает больше, а там всё наоборот. Бывает, что ошибочные, то есть происходит перемещение, перекрёстье классов, как всегда, на выходе, но, тем не менее, эта система довольно успешно справляется с этими вещами. Я не ответил на ваш вопрос. 

S05 [02:16:18]  : Виктор, спасибо. Я думаю, мы сейчас углубляемся в дискуссию по поводу антологии versus нейросети. И там интересный вопрос у Олега Серебренникова еще есть, но у меня такое ощущение, что это нужно отдельно делать разговор по поводу того, кто что подразумевает под антологией, и насколько это соотносится с нейросетями и деревьями решений, и обсуждать отдельно. Сейчас хотелось бы, чтобы Николай Рабчевский еще высказался. У нас не так много времени осталось. 

S02 [02:16:49]  : Да. Вот по поводу эвристики против нейросетки. Ну, во-первых, реальные задачи можно разделить на две части. Одни можно решить используя только эвристики, а другие можно решить, используя эвристики и нейросетки. Потому что задач, которые можно решить чисто нейросетками, нет. В частности, с теми же изображениями. Если у меня есть изображение в 4К, и я на нем хочу что-то найти, то понятно, что мне нужно делать некую внешнюю обвязку еврейсическую, которая будет использовать нейросетку в качестве одного из элементов или одного из шагов действия. Второй момент по поводу обработки изображений нейросетями. Есть вещи, которые нейросети не делают и никогда не будут делать. Ну, например, есть изображение. Нужно построить его контурный вариант, в котором все линии заданы аналитически. Будучи заданными аналитически, они пригодны для дальнейшей обработки теми методами, которые мы обрабатываем тексты без использования нейросетей, теми методами, которые работают, скажем, компиляторы анализируя текст. Поэтому никто не спорит о полезности как эвристик, так и нейросеток. Важно находить разумное, и я думаю, что это похоже на то, что Владимир Смолин говорил, разумный способ сочетать полезные стороны одних и других для того, чтобы получать то, что нам требуется. Вот у меня всё. 

S05 [02:19:04]  : У меня тут родилась гениальная мысль, пока вы говорили, что на самом деле у нас нет вообще в природе И, по крайней мере, в жизни человеческой задач, которые бы в чистом виде решались нейросетями. Потому что даже если мы пытаемся решить задачу распознавания кошек и собак, у нас все равно участвует онтология, в которой есть два концепта. Концепт кошка и концепт собака. И на самом деле у нас есть гибридная задача, где мы с помощью нейросетей пытаемся отличить одну вершину в графе онтологии под названием кошка от другой вершины под названием собака. Отношений нет, но концепт уже есть. Значит, уже есть онтология. И еще есть комментарии Олега Серебренникова. Олег, вы в заключающем слове скажете или мне зачитать? Так, Олега не слышно, давайте это… – Могу сказать, могу сказать. – Да, пожалуйста, Олег. 

S06 [02:20:06]  : – Ну, тут несколько комментариев сложилось на самом деле. Первый по поводу того, что говорил Бабуров. Я с ним согласен, что вот такие императивные, он назвал, задачи, они не решаются. Просто потому, что нет модели мира, и мы их не могли бы решать, не будь у нас моделью мира. По этим, собственно, и объясняется сложность образования, допустим, людей, которые не видят и не слышат, а только чувствуют прикосновения по коже. Я только одного такого видел в передаче, который получил образование, смог получить образование. А так бы Маугли остался. Это первая вещь. Вторая – по поводу онтологий. Слушайте, ребята, меня это постоянно аж подбрасывает в кресло, когда начинают говорить. Одно дело – решать задачи, как говорит Николаев. Давайте тогда и говорить, что с практической точки зрения сейчас, поскольку мы не знаем, искусственный интеллект должен работать, общий искусственный интеллект, с точки зрения практических, конечно, нужно использовать онтологии, потому что это единственный способ быстро решить задачу от беспомощности. Но это вовсе не значит, что естественный интеллект не опирается на мультимодальность, наоборот, он как раз и опирается именно в этом его сила. И он, как вы говорите, генерализирует, да, он обобщает какие-то концепции, в частности, с первого взгляда. Еще какой-то, Антон, вопрос был, да, там три было аспекта, я не помню. 

S05 [02:21:37]  : Еще на что-то не ответил? Не помню, нет, ну как бы просто вот комментарий ваш хотел услышать. 

S06 [02:21:44]  : Да, я просто со зрением сегодня совсем плохо операцию делал. 

S05 [02:21:48]  : Ну, как бы вот вы под зафиксировали главный тезис, по-моему, который... А, и позвольте я вернусь к ЮМЛ. 

S06 [02:21:55]  : Это то, что вы говорили, сначала слышал. По поводу ЮМЛ, коллеги. Задача программирования принципиально сейчас нерешаема в общем виде. Нельзя сейчас делать робота, который заменит программистов. Именно потому, что программист обладает картиной мира. Хороший пример у Бабурова был про телевизор, выведенный на мой телевизор, «Красный квадрат». он огромное количество информации о мире содержит. Потому что это надо знать, кто такой я, где я нахожусь, почему у меня телевизор находится, в какой из моих комнат и что за телевизор, и так далее, пошло-поехало. Поэтому говорить об этом, с моей точки зрения, преждевременно, возвращаясь к вашему утверждению, Антон, относительно семантического языка. Еще раз повторюсь, мы в свое время, я сделал компанию с ребятами из МГУ, и мы создали единственный компилятор переднего плана языка C++ в России. Он NCC тоже понимал, там был совместим с Бурландом и Майкрософтом и так далее. Поэтому я говорю, считайте, что из первых рук получаете информацию, потому что это единственный здесь был сделан компилятор реальный. Так вот, это исключительно вопрос внутреннего представления, потому что для того, чтобы передний компилятор у вас мог перелопачивать все для разных архитектур, Вы сначала делаете промежуточное представление, а уже его интерпретируете в марш-кодах для любой архитектуры. И вот гибкость такого представления – это и есть ноу-хау, по сути, вот такого рода компаний. И Женя Зуев этим занимался, он у Схамлина воспитывался. Сейчас он и в Иннополисе в Казани работает, преподает и здесь тоже. Поэтому я знаю, о чём я говорю, и вот, по сути, это уже сделано было однажды. Но вот в нашей стране не всё складывается не всегда удачно, так сказать. Вот компания «Камелавлету», хотя до сих пор есть весь код, и я бы с удовольствием кому-нибудь помог его запустить всю эту историю заново. Спасибо. 

S05 [02:24:26]  : Олег, спасибо. Очень вдохновляющая история. Хотелось бы иметь возможность наблюдать её продолжение. Я только в подтверждение ваших слов насчёт внутреннего представления скажу, что, насколько я знаю, история с Google Translate, про которую Юрий Бабуров сегодня говорил, она полетела как раз после того, когда Google начал тренировать на разных языковых парах одни и те же корпуса. Таким образом, что из одной и той же сообщения мы с разных языков преобразуем на разные языки, и у него стали проявляться внутренние представления инвариантные к входным и выходным парам. То есть, они на самом деле получили некоторый внутренний язык, с помощью которого они переписывали То есть, на самом деле, может быть, это даже есть какое-то внутреннее понимание, но только не в пространстве реального мира, а в пространстве языковых моделей, с которыми оперирует Google. 

S06 [02:25:22]  : Да, Антон, но Бабуров еще одну важную вещь сказал, что у Google Translate было достаточно представления о модели мира переводческой деятельности, потому что переводчики имеют дело именно с текстами, а все тексты у них были. Именно этим является успешность, первое, и второе, закономерность, возможная закономерность, о чем уже вы говорите, перехода к обобщенной модели семантического и промежуточного представления. Об этом, да, об этом следует задуматься. Я думаю, что в этом есть смысл, но повторюсь, здесь не хватает модели мира и модель мира в случае программирования, поскольку программируем мы для реального мира. К сожалению, там пока не будет общей модели мира, не будет и такой машины, которая научится для нее программировать. 

S05 [02:26:09]  : Вот я тогда еще раз про модель мира и про возможность перевода языковых представлений в модель мира постараюсь не забыть кинуть ссылку в группу. И на самом деле очень интересно поговорили. Я даже не ожидал, что так выйдем. С одной стороны подготовились к следующему семинару про семантические внутренние языки, а с другой стороны наметилась тема поговорить про то, что такое антологии и нужны они или нет, и что мы под ними подразумеваем. Коллеги, всем огромное спасибо, до свидания и до новых встреч! Счастливо! 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
