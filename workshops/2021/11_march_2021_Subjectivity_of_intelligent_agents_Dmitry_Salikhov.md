## 5 ноября 2020 - 11 марта 2021 - Субъектность интеллектуальных агентов — Дмитрий Салихов — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/KGV6bS7V2qw/hqdefault.jpg)](https://youtu.be/KGV6bS7V2qw)

Суммаризация семинара:

Общая тема и контекст

Семинар посвящён обсуждению концепции субъектности в контексте интеллектуальных агентов. Участники обсуждали вопросы реализации субъектности в агентах, включая механизмы обучения, обобщения и использования ранее полученных знаний.

Основные тематические блоки


1. Механизмы обучения и обобщения
   - Обсуждение механизмов обучения агентов, включая подкрепление и случайный поиск комбинаций действий.
   - Примеры реализации обучения на примере агента, который учится добираться до сыра.
   - Важность обобщения в процессе обучения и его различие от генерализации, заложенной в генах.

2. Использование ранее полученных знаний
   - Рассмотрение способов использования ранее полученных знаний для обобщения и генерализации.
   - Важность ассоциативной зоны для связывания понятий и образов, что позволяет агенту генерализовать понятия.

3. Субъектность и мотивация
   - Обсуждение субъектности как внутренней мотивации системы, позволяющей принимать решения вне зависимости от внешних стимулов.
   - Примеры системы, которая становится разной в процессе своей работы, приобретая опыт и реакции на ситуации.

4. Распознавание последовательностей
   - Объяснение распознавания как детекции последовательностей, включая фонемы, слоги, слова и образы.
   - Примеры схем, кодирующих не только одну последовательность, но и её обратную, и обсуждение порядка активаций в схемах.

5. Технические и программные аспекты
   - Обсуждение технических и программных аспектов реализации агентов, включая использование C++ и архитектурные решения для масштабирования.
   - Примеры реализации контроллеров и обучения на основе дофаминового подкрепления.

Итог и вывод

Семинар показал, что концепция субъектности в интеллектуальных агентах является сложной и многогранной. Участники обсудили различные аспекты, включая обучение, обобщение, мотивацию и распознавание последовательностей. Были представлены примеры реализации и обсуждены технические и программные решения. В целом, семинар подчеркнул важность дальнейших исследований в области создания агентов с субъектностью, способных к самостоятельному обучению и генерализации знаний.




S09 [00:00:01]  : Да, коллеги, всем добрый вечер. Сегодня у нас Дмитрий Салихов из Сбербанка будет нам рассказывать про субъектность искусственных интеллектуальных агентов. Да, сегодня про естественных агентов пойдет речь. 

S03 [00:00:16]  : Не-не-не, все правильно. Естественно, агенты, они гораздо сложнее и не так просто это все. Да, попробую. Мой доклад действительно называется «Субъектность интеллектуальных агентов. Как это устроено у живых». Но это будет с неким прицелом. Посмотрим, как у живых, и сделаем это искусственно. Вот примерно про это слово «живые» в данном случае, в этом контексте. Ну что, поехали. Доклад, как обычно, очень технический. и позитивный, в отличие от предыдущего докладчика Александра Болоточева, я считаю, что HCI возможен и не просто возможен, но и даже неизбежен. И этот позитив я постараюсь подкрепить в своей теории, которую я вам сейчас и расскажу. Что я понимаю под субъектностью? Субъектность – это свойство агента действовать от своего имени и согласно своим внутренним потребностям. Когда человек открывает дверь, дверь совершает действие, не являясь при этом субъектом, а человек, если он живой, все действия совершает как субъект, даже если его принуждают к этим действиям. Но зачем она нужна? Это субъектность вообще. Тут все дело в AGI, а если более точно, в его обучении. Когда мы имеем дело с моделями в машинном обучении, процесс довольно простой и понятный. У нас есть некая задача, к этой задаче полагаются данные, и, значит, есть целевая функция. Ее надо аппроксимировать. У данных есть вход и выход. Выход – это метки или непрерывная величина, или другими словами, эталон. Из разницы между эталоном и предсказанием возникает ошибка, мы ее уменьшаем и таким образом обучаемся. Но с общим интеллектом это не работает, так как нет задачи в том узком смысле, в котором она ставится для модели. Как можно загнать в рамки машинного обучения задачу научиться говорить и понимать язык? Мы можем поставить задачу, ответить на вопрос или предсказать следующее слово. Но, как вы понимаете, это совсем не то же самое, что уметь говорить, а лишь одно узкое проявление. Но если у нас нет задачи для того, чтобы считать ошибку и что-то аппроксимировать, то как заставить нашего агента учиться? Как его заставить вообще хоть что-то делать? Вот тут необходимость возникает, чтобы у нашего агента была цель. А цели не бывают без потребностей. А чтобы достигать цели, нужна воля. То есть возникает целый пласт понятий, которые прямо залезают в философию и не имеют однозначных определений. Но мы видим эти вещи каждый день у живых организмов. А значит, есть какая-то механика, которая работает и нам это все обеспечивает. Интересный, кстати, вывод получается на правах наброса. Без агентной парадигмы, то есть без разделения на агента и внешнюю среду, без мотивации и подкрепления получается, что AGI вообще нельзя сделать. И сейчас я попытаюсь создать такого вот живого искусственного агента шаг за шагом. Начнём моделировать с простых вещей и постепенно усложним нашу модель, чтобы она позволяла нам реализовать всё более сложное поведение. В процессе объяснения буду использовать много терминов из нейробиологии про мозг. Но это не значит, что мозг именно так работает. Но в процессе разработки теории пришлось полагаться на устройство мозга и, тем не менее, дисклеймер. Это не объяснение работы мозга, попытка сделать архитектуру по его принципам, скажем так, biologically inspired. Второй дисклеймер. Я здесь не рассматриваю задачу распознавания образов из сенсорных потоков. Все, что будет здесь происходить, это как бы следующий уровень абстракции, то есть работы уже с готовыми образами. Для начала давайте посмотрим, на базовой строительной блоке. У меня это паттерны активности, нейронные области и нейронные зоны. Концепт паттернов активности в оригинале звучит как Cell Assembly. Он предложен Дональдом Хэббом еще в 50-х годах и вытекает из Хэббловского правила обучения. Нейроны активно вместе связываются друг с другом. Вот на картинке у нас нейронная область. Это как сеть малого мира. Она условно отделена от других областей плотностью связи. Синаптические связи с другими областями гораздо меньше, чем связи внутри области, между ее отдельными колонками. В нашей области Условно 16 колонок. Одновременно активным может быть лишь небольшой процент колонок, потому что как только колонка становится активной, она подавляет активность других колонок рядом, вокруг себя с помощью тормозных связей. Получается, что внутри области фиксированного размера может существовать довольно много таких разреженных паттернов активности, и каждый такой паттерн кодирует какой-то образ. У Анохина, если вы его читали или слушали, это называется «клеточный ансамбль» или «КОК». В настоящем мозге в этих ансамблях, конечно, более сложная динамика. Там есть ядерные клетки, которые вызывают сжигание всего паттерна, а есть просто клетки, которые иногда втягиваются в паттерн, а иногда нет. В общем, смотрите видео Анохина, где он выступает на архе, по-моему. Нам для моделирования достаточно, чтобы паттерн активности реагирует на определенный образ, и одна область может кодировать много таких паттернов. Теперь у нас две области. Если две области связаны между собой большим количеством связей, то один паттерн в одной области вызывает другой паттерн в соседней области. Это другой по форме паттерн, но несет ту же самую информацию, но с небольшой задержкой. Таким образом, один паттерн активности вызывает по цепочку активации аналогичных паттернов в других участках мозга и тем самым передает одно и то же сообщение в разные зоны. Вот здесь он рисовал, какие связи могут быть между областями. сверху вниз. Однонаправленная, двунаправленная, двунаправленная с разными знаками. Это когда одна область другую зажигает, а вторая в ответ гасит первую. Скорее всего, с помощью гамма-аминомасляной кислоты. Самое интересное явление здесь – это слияние паттернов, когда паттерн в третьей области зажигается от двух входящих паттернов одновременно. Таким образом можно сделать распознавание последовательности. Например, в данном случае третья область может запомнить паттерн слога K, если в первой и второй были фонемы K и A. Несколько нейронных областей, объединенных определенной функцией, образуют функциональную зону. В мозге, вы знаете, зоны специализируются. Есть зона визуального тракта, слухового тракта, зона брака и так далее. Вот справа, в нижнем правом углу, с большим количеством областей и связей нарисована зона-энкодер, которая может кодировать длинные цепочки паттернов в один паттерн, то есть делать сжатие, другими словами. Это все были такие кубики Лего, из которых мы дальше будем собирать нашего субъекта. Возьмем агента и поместим его в клеточный мир. Во-первых, агент должен действовать. Без действия у нас интеллект не возникает. Сделаем три нейронные области, и каждую область назначим ответственность за одно действие. Когда область активируется, мы считаем, что агент начинает какое-то определенное действие. Пусть у нас это будет движение прямо, поворот налево и поворот направо. Здесь и дальше. Экран будет, где половина разделена, левая половина, соответственно, это то, что будет происходить в его виртуальном разуме, а справа – это то, как он движется в своем мире. Кто-то должен подавать активацию на эти области. Давайте сделаем вот такой второй блок, назовем его диспетчер действий, который работает по простому принципу. Когда у диспетчера активируется какой-то паттерн, он передает активацию на область, которая соответствует этому паттерну. В динамике то же самое. Здесь разные паттерны обозначены разными цветами. Красный цвет означает активацию области, где паттернов как таковых нет или они нам не важны для объяснения. В общем, красный – это просто активация без паттерна. Следующий вопрос. Откуда у диспетчера возьмется активация? Давайте сделаем такой блок, назовем его дофаминовым наркоманом. Соединим этот блок с диспетчером действий. Дофаминовый наркоман будет постоянно отправлять сигналы активации на все, что с ним связано, на все блоки, и будет таким источником постоянной активности. Ну как, не совсем постоянной. Он может получить дозу дофамина, и в этом случае он на какое-то время замолкает. Но какое действие будет активировать диспетчер при получении активации от дофаминового наркомана? Пока наш агент ничего не умеет, он будет генерировать случайные паттерны, которые будут активировать случайные действия. И теперь наша система пришла в состояние, когда агент хаотично движется в поисках дофамина. Наверное, такой агент будет не сильно полезным, да и в живой среде такой организм не проживет долго. Очевидно, нам нужны более разумные действия, а для этого нам потребуются сенсоры, чтобы видеть, что происходит в окружающей среде. Сделаем такой блок. Он будет означать универсальный сенсор, который активирует определенный паттерн при наблюдении какого-то состояния среды. То есть среда в нашей модели – это дискретный набор состояний, и каждому состоянию сопоставлен какой-то паттерн активности. Да, это мало похоже на сложный реальный мир, который аналоговый прежде всего, но в целом аналогия прослеживается, так как на верхних уровнях наших сенсорных контуров – зрительного, звукового, метод дельных сигналов, фонем или колбочек – есть вполне абстрактные представления типа стол, яблоко, кошка и так далее, то есть уже дискретные представления. Как сигналы дискретизируются и абстрагируются по пути от сенсоров до верхних областей, мы здесь рассматривать не будем. Это отдельная и сложная тема. Мы сделали сенсор, который реагирует на сыр, когда он в прямой видимости, когда агент на него прямо смотрит. Обозначим его реакцию фиолетовым цветом. У нас есть сенсорный блок, и как-то надо его соединить с остальной конструкцией, так, чтобы действия были обусловленными состояниями среды. Мы можем соединить его напрямую с диспетчером, но лучше сделать это через промежуточный блок, назовем его блок правил. Таким образом, сенсор передает активацию на блок правил, и диспетчер передает тоже активацию на блок правил, то есть они оба. Когда активность идет одновременно от сенсорного блока и от диспетчера, на блоке правил создается паттерн, который является объединением объединением паттерна активности сенсорного блока и диспетчера. Срабатывает принцип временной корреляции или простейшее правило Херба. Такой паттерн для простоты назовем правилом, который в терминах живых организмов называется условный рефлекс. Но рефлексия просто так не закрепляется при сочетании сенсорных паттернов и паттернов действий. Иначе у нас будет полный комбинаторный набор всех сочетаний в состоянии среды и всех действий, которые можно совершить. То есть это не будет иметь большого смысла. Но если мы говорим про агента, у нас по умолчанию правила создаются, но не активируются. А какие правила нужно активировать и когда? Нам нужны только те правила, которые приводят к нужным целям. А что у нас цель? Вот тут нужно ввести дофамин как награду за достижение цели. Пусть у нас в мире агент, подойдя к еде, автоматически получает дофамин. И получив дофамин, агент на время отключает нашего наркомана, но при этом запускает другой интересный механизм, который он называет активацией правила. Во время активации правила происходит следующее. Берется последнее активное правило. Последнее, потому что это временная корреляция. И связи укрепляются таким образом, что правило теперь реагирует на сигнал паттерна сенсора. То есть укрепляется связь между сенсором и правилом. И укрепляется связь от правила до паттерна действия, которые активируются в диспетчере. Тут главное не путать, что связи создаются и укрепляются между паттернами, а не между блоками. Между блоками связи уже есть, так сказать, biodesign. После активации правила получилась такая схема. Паттерн активности на сенсоре теперь через правило вызывает определенное действие. В нашем кейсе для сенсорного паттерна еда прямо передо мной вызывается действие шаг прямо. Если на мышку посмотрите, когда он поворачивается к сыру, зажигается сенсорный паттерн, и он делает шаг вперёд к сыру. Вопрос. Как сделать более общее правило, чтобы находить еду не только тогда, когда мы в одной клетке от неё и смотрим прямо на неё, но и, допустим, если мы дальше от неё и смотрим в другую сторону, Тут нам нужен механизм самоподкрепления, когда агент вознаграждает себя сам, а не от получения еды, то есть как бы предвкушая ее. Сделаем второй блок, которым будет выделять дофамин по условию, то есть не тот безусловный механизм, который хардкодно связывает дофамин с едой, а тренируемый, то есть условный рефлекс с дофамином вместо действия. Свяжем этот блок сенсорным блоком. Теперь каждый раз, когда происходит выброс дофамина, образуется возбуждающая связь между паттерном состояния среды и прямой выдачей дофамина. В этом мультике агент движется так, как будто он уже все умеет, но по факту он ничего не умеет и движется случайным образом. Просто ему повезло, и он сразу дошел до сыра. Так вот, про наш механизм самоподкрепления. В первом прогоне у нас Этот блок пока не работает, но в момент получения еды происходит связывание предыдущего наблюдения среды с этим внутренним источником дофамина, который я назначил DSR, и он тоже загорается фиолетовым цветом. То есть вид сыра прямо перед собой вызывает связь с выделением дофамина. В следующем прогоне агент движется тем же путем, и за счет самоподкрепления получает дофамин на один шаг раньше, только за счет того, что он увидел еду. После получения подкрепления происходит привязка этого блока к уже предпредыдущему шагу, то есть когда агент видит сыр в левом зрительном поле. Таким образом, получаются цепочки правил и действий, которые ведут агента к еде. если он, конечно, видит. Блок, реализующий всю эту логику связывания паттернов с действиями, я дальше буду называть контроллером. И такие блоки мы будем использовать дальше. Если уж говорить про сложность, есть еще кортизол, это вещество, которое создает тормозные связи, которые нужны для отмены существующих правил или избегания опасности. Есть много дополнительных когнитивных механизмов. рабочей памяти, временной памяти, сенсорной памяти. Все эти вещи позволяют создать живую систему с уровнем интеллекта, примерно как у ящериц. Но сейчас мы в эту сторону пока не пойдем. Пока у нас есть довольно примитивный агент, реализующий некую функцию, которая является функцией от состояния окружающей среды, и только от нее. В терминах reinforcement learning это называется Q-функция. Вы спросите, а где тут мышление, планирование, язык? В моей теории все высшие когнитивные функции начинаются с языка или с языковой модели мира. Язык как операционная система, понимановская система №2. Но чтобы научить агента языку, мы не можем просто дать ему корпус на триллион слов. целевой функции предсказания следующего слова. Это модельный подход, про который мы уже вначале говорили, который не может выйти за рамки той задачи, на которой модель обучалась. Но есть еще агентный подход, в честности ради, но в той конфигурации, которой сейчас это делают большие парни из DeepMind, Это тоже не поможет. Мало толку будет, если поместить агента в виртуальную среду и заставить его отвечать на вопросы или выполнять действия по языковым командам. Это всего лишь тренировка решения одной конкретной задачи. Генерализация и выработка навыков в этом случае не происходит, так как агента не награждают за приобретение навыков и генерализацию. Язык можно выучить только с нуля, как это делают дети. Чтобы реализовать самое примитивное языковое поведение, нам потребуется несколько новых блоков. Начнем с сенсорных зон. Их нам потребуется две. Одна будет воспринимать фонемный поток, другая – визуальные образы. Зона, которая воспринимает поток фонем, как раз вот показана сейчас на слайде. Я ее называю энкодер, так как она кодирует и сжимает информацию. Красные стрелки означают возбуждающие связи, а синие – тормозные. В этом примере агент слышит слово «киса». Как с детьми разговаривают, что это «киса». Видно, как фонемы двигаются по связанным областям первого столбика и происходит слияние их паттернов во втором столбике. Таким образом, фонемы склеиваются в слоге, как только распознается слог во втором столбике, он как бы гасит продвижение фонем вниз, гасит продвижение именно тех фонем, из которых он образовался, так, чтобы они в дальнейшем не мешали. То же самое происходит между вторым и третьим столбцом, но там уже слоги склеиваются в слова. Еще интересное свойство энкодера – это выделение дофамина при распознавании последовательности, чем Более высокого уровня последовательности мы распознали, тем больше дофамина выделяется. Нам это тоже впереди пригодится. Давайте пока забудем про визуальную составляющую и сконструируем простейший речевой контур нашего агента. Возьмем энкодер Fonem, соединим его с контроллером произношения или речевой контроллер. Контроллер будет контролировать речевой аппарат. Обратите внимание, что от энкодера фонем в контроллер идет два информационных потока. Паттерн фонемы или слога, или слова передается на сенсор контроллера. Это красная стрелка. А дофаминовое подкрепление передается дофаминовому наркоману. Это зеленая стрелка. Контроллер занимается тем, что хаотично подает сигналы в речевой аппарат. Но вот путем перебора случайно получилась фонема, агент сам же и распознал, то есть услышал. Здесь мы считаем, что агент уже распознает монетический ряд своего языка, а также слоги и слова. У детей это бывает, они еще до рождения усваивают основные атрибуты языка, ритмику, тембры и так далее. Так вот, распознав знакомую фонему, энкодер вырабатывает дофеминовое подкрепление. Это приводит к тому, что вырабатывается правило, связывающие действия по произношению звука и самого паттерна этого звука. Похожий процесс происходил, когда агент искал сыр, только здесь наоборот. Сначала агент действует, а потом получает новое наблюдение от среды. Ну вот, связывая паттерны фонем и действия по их произнесению, агент учится повторять звуки, которые только что услышал. Ну и также хаотичным перебором звуков агент иногда воспроизводит слоги, характерные для фонетического ряда его языка. Это тоже вызывает подкрепление со стороны энкодера. И давайте посмотрим, что в этом случае происходит. Вот мы взяли речевой контроллер, который может произносить 4 фонемы. И справа к нему присоединим энкодер, который мы кодировали фонем пару слайдов назад, но немного другой. Видно, что у этого энкодера есть система с сенсором и правилом, только она подпитывает среднюю колонку в данном случае. Посмотрим, как это работает в динамике. Предположим, агент случайно произносит два звука подряд, К и И. Фонемный энкодер, то есть собственный слух, воспринимают это как слог, то есть активируют второй уровень абстракции. И этот уровень тоже выделяет дофаминовое подкрепление, и чем выше уровень абстракции, тем выше уровень этого подкрепления, я говорил. Сначала в энкодере действий, который справа, происходит создание паттерна последовательности, то есть произнесения звуков «к» и «и». Потом в подкрепление приходит наш контроллер, то есть правую часть, и закрепляет связь между распознанным слогом key и паттерном действия key. В итоге агент научился повторять уже слоги. Теперь, когда правило закрепилось, посмотрим реакцию на то, что агент услышал слог key. Это общая схема. На ней видно, как информация движется между зонами. Аналогично происходит при распознавании и выучивании слов. Что происходит в речевом контроле и в динамике? Видно, что юнит, хранящий паттерн последовательности key, который сейчас горит, передает активацию двум областям более низкого уровня абстракции. и они последовательно включают активацию на диспетчер, который уже дальше отдаёт команды голосовому тракту. То есть информация распространяется в обратную сторону. Получается общий принцип, когда мы запоминаем, информация идёт в одну сторону, воспроизводим в обратную. Аналогично, когда слоги складываются в слова, я уж тут не стал рисовать, так же каскадом активация спускается от верхних уровней, от абстракции к нижнему. Вот такая получилась инженерная схема для реализации самого примитивного феномена, такого как повторение слов. Тут мы явно не все учли. Например, нужен регулятор дофаминового потока, который тормозил бы его, если распознанный паттерн повторяется. Иначе наш агент попадет в бесконечный цикл и будет повторять все, что услышал. Давайте попробуем пойти дальше. И сделаем следующий сценарий. Сделаем так, чтобы агент говорил то, что видит. Для этого нам потребуется визуальный энкодер, но мы не будем его разбирать детально, просто примем, что если агент смотрит на кошку, энкодер возвращает паттерн кошка. Возьмем теперь энкодер Fonem, энкодер визуальных образов и ассоциативную зону, которую я называю визуальный лексикон. И вот таким образом их соединим. Получается, что паттерны слов и паттерны визуальных образов, они будут здесь объединяться. Образы, которые часто встречаются вместе, будут создавать устойчивые паттерны. Например, вместе с визуальным образом кошки, ребенок часто слышит разные фразы. Киса говорит «мяу», киса кушает, киса ушла и так далее. Но самой сильной связкой здесь будет сочетание слов «киса» и визуального образа кошки. Агент слышит слово «киса» и повторяет это слово, как он уже научился делать на предыдущем слайде. Что происходит во время повторения? Происходит связывание паттерна кошка от визуального лексикона с паттерном голосовой последовательности киса, который внизу в контроллере. В следующий раз, когда увидев кошку, агент скажет слово «киса» уже без звукового стимула. Здесь я показал и еще покажу несколько феноменов интеллектуальной деятельности, довольно-таки примитивные, но эти примеры не связаны в цепочку, как шаги последовательного обучения. Они просто демонстрируют какие-то разные аспекты инженерного устройства мозгового агента. Следующий сценарий. Давайте заставим агента отвечать на вопросы. Начнем на один самый простой. Что это? Покажем ему изображение, как вы догадались, изображение кошки. Основное ядро нашей системы – это речевой контроллер. Здесь я его изобразил схематично, больше мы не будем с ним играть. такие вот кружочки мерцающие. Он принимает данные от сенсорных и ассоциативных зон фонетического энкодера и визуального лексикона. Напомню, что визуальный лексикон управляет паттерном, связанный с фонетическим образом того, что сейчас видит агент. Если посмотреть на схему инженерным взглядом, сразу видны ее недостатки. Во-первых, непонятно, какому потопку отдать приоритет, кинетическому или визуальному. Во-вторых, агент все время будет говорить. Ну, в общем, так оно и обычно бывает у детей до полутора лет, они мыслят вслух, но мы хотим, чтобы наш агент был немного более разумным и взрослым. Решить проблему поможет механизм шлюзов. Шлюзы – это промежуточная область, которая пропускает или не пропускает информацию через себя, а саму информацию не меняет. В мозге, скорее всего, закрытое состояние шлюза соответствует ситуации, когда выделяется гамма-аминомасляная кислота и происходит полное торможение активности в этой области. Кто будет управлять шлюзами? Конечно, контроллер. Сделаем еще один вложенный контроллер. Входы у него обозначим стрелками, а управляющие выходы – зелеными стрелками. Обучаться этот контроллер будет точно так же – дофаминовым подкреплением. Для простоты контроллер будет один, хотя реально мне кажется, что контроллер должно быть по одному на каждый шлюз. И посмотрим, как себя будет вести этот механизм. В нашем кейсе отвечание на вопрос «что это?». Поначалу наш контроллер шлюзов хаотично вызывает все действия, которые открывают или закрывают шлюзы. Открытый шлюз я здесь обозначил салатовым цветом. Как только встречается комбинация «шлюз от визуального лексикона открыт» и «шлюз на речевой тракт открыт», сейчас он добежит до этого состояния, Агент скажет слово «киса», поскольку образ пройдет снизу вверх от лексикона до плечевого контроллера и автоматически получит вознаграждение от своего воспитателя, то есть родитель в данном случае. Получив вознаграждение, закрепляется правило. Если на входе от фонетического энкодера есть фраза «что это?», а на выходе от визуального лексикона есть распознанный объект, тогда откроем два шлюза, как показано на картинке. И это правило закрепляется в нашем контроллере. На самом деле, конечно, все сложнее. Учиться агент должен частично за счет подражания, а частично за счет случайного поиска комбинации действий. Но нарисовать такую схему у меня просто уже не хватило сил. Давайте разберём ещё последний кейс, он самый сложный, и он про обобщение. Обобщение или генерализация – это чуть ли не основное свойство интеллекта, без которого мы не сможем представить не то, что человека, но сколько-нибудь развитое животное. Я имею в виду, конечно, то обобщение, которое нарабатывается в процессе жизни, а не то, которое прошито в генах. Обобщение для интеллекта – это не просто использование абстракции, это еще часть моделей мира. Так вот, сценарий будет такой. Воспитатель показывает агенту картинку, на которой изображена кошка и собака, и говорит агенту «это звери». В результате эксперимента мы должны увидеть, что понятие «звери» связывается с понятием кошка, и при активации паттерна кошка любым способом, или через слово, или через картинку, активируется паттерн зверя. Для этого нам понадобится еще одна функциональная зона, я называю ее зоной связи или ассоциативная зона. Она чем-то похожа на энкодер, похожа тем, что запоминает последовательность. Но отличие в том, что однажды запомнив последовательность из двух элементов, она может воспроизвести второй элемент, если на вход подать первый, и наоборот воспроизвести первый, если приходит второй элемент на вход. Не будем углубляться сейчас в нейронный механизм, как это может работать в мозге. Мне кажется, иногда проще сделать как нужно, чем сделать биологически правдоподобно. Вот такая простенькая схемка должна реализовать нужные информационные потоки. Хотя она гораздо проще, чем нужно, на самом деле, чтобы это все работало. Но просто для того, чтобы показать все инженерные блоки, которые нам сделают SUMAGI. Кроме ассоциативной зоны, у нас есть еще контроллер мыслей. Он будет управлять потоками информации между зонами. обучаться этот контроллер будет от дофаминового подкрепления, как и все остальные контроллеры. Также есть буферная зона, вот она посередине, смысл которой в создании буфера для циклической обработки ассоциаций. Зачем она нужна? Дело в том, что цепочки ассоциаций, в отличие от вложенных конструкций, они потенциально бесконечны. Если вы можете закодировать любую в последовательности фонем, допустим, 10-12 элементов с помощью энкодера, допустим, с четырьмя уровнями максимум, поскольку там логарифмически бывает количество уровней, которое потребно. То есть можно такую структуру содержать анатомически в мозге, но вот чтобы хранить ассоциации, то есть связи сущностей друг с другом, такая ограниченная структура уже не подойдет. Поэтому я здесь придумал такую конструкцию. Все ассоциации хранятся в виде трехзвенной штуки, справа она изображена, чтобы переходить от одной ассоциации к другой. Мы будем использовать циклическую активацию через буферную зону. Вы спросите, почему эти зоны связаны именно так, а не иначе? Понятно, что если у нас больше двух блоков, их можно соединить в кучу способов, Эти связи я подбирал экспериментально. Я смотрю, как синхронизируются информационные потоки внутри системы и понимаю, как лучше. На самом деле, в реальном мозге, мне кажется, все эти зоны связаны со всеми. Так вот, сценарий. Агент видит картинку, на которой изображены кошка и собака, и слышит – это звери. Во-первых, нам нужно как-то выделить слово «звери» из прочего фонемного потока, так как это слово новое и его нужно по-особенному обработать. Тут, возможно, два варианта. Первый, когда слово вообще впервые встретилось, и второй, когда оно раньше встречалось, но оно впервые встретилось после слова «это». И в первом случае нам потребуется детектор новизны. Что такое детектор новизны? Агент должен удивляться новым сочетанием паттернов, потому что это важно. и этот механизм должен быть встроен на уровне генома, то есть быть рабочим сразу. В нашей схеме энкодеры сами предоставляют нужную информацию и нужно лишь ее прочитать. Вот такие блоки, подключенные к нижним слоям столбиков, они будут реагировать на два паттерна в предпоследних областях. Если на них появились активные паттерны, значит, следующий уровень абстракции их не погасили, их активация не погашена, а, следовательно, паттерн их сочетания не был распознан. Например, один слышал два слога «звери». Оба слога распознались, а слова нет. Это значит, левый детектор опознает эту ситуацию. Ну, а правый детектор, в свою очередь, будет срабатывать на сочетание слов, которых незнакомых нет. Ну и второй вариант – это если слово «звери» уже распознается, наш речевой контроллер будет реагировать на слово «это», которое следует перед нашим словом, и запускать ту же самую программу, что и с новым звуком. Он, естественно, тоже должен обучиться этой программе, но выносим это за скобки. А программа простая. Повторить то же самое слово и достигается это открытием нужных шлюзов внутри речевого контроллера. И повторяем это слово до тех пор, пока датчик новизны не перестанет срабатывать. То есть он повторяет, повторяет, повторяет, и потом слово начинает распознаваться, и датчик уже больше не вызывает эту оптикацию. Тут весь процесс. С помощью речевого контроллера происходит повторение слова «звери». Надо сказать, что это повторение делается вслух только на первых порах развития, пока не сформировалась связь между речевым контролем и фонетическим энкодером. Когда эта связь уже сформирована, агент может говорить при себя, не мешая окружающим. Но пока агент повторяет слово «звери», мыслительный контроллер открывает шлюз в ассоциативную зону, и туда поступает последовательность паттернов слова «звери» и образа «кота». Ну, а потом такая же последовательность, только слово «звери» и образа «собаки». Но еще также может образ «собаки» и образ «кота» тоже туда залететь, и они вместе окажутся в ассоциативной зоне. В результате получились две связки. Кот – звери и собака – звери. Если на вход поступает паттерн кот, будет активирован паттерн звери. Если поступает собака, то будет тоже активирован паттерн звери. Но если придет паттерн звери, то какой паттерн нужно активировать на выходе? Тут должен сработать принцип «победитель получает все» – winner takes it all. Не имея никаких других вводных, можно предположить, что тот паттерн, который более часто встречается в жизни агентов. У живых организмов это называется праймингом. Когда вас просят назвать, например, пример фрукта, многие из вас скажут яблоко. Жители тропика скажут манго или что-то в этом роде. Но более общий случай применения ассоциаций требует связки с другими языковыми конструкциями и сложных правил на уровне работы контроллера. Собственно, это все находится в разработке, я этим постоянно, в силу свободного времени этим я и занимаюсь. Ну, собственно, и все, чтобы подытожить краткие тезисы. AGI возможен. Верхнеуровневая когнитивная деятельность базируется на языке. Язык тесно связан с органами чувств и деятельностью в окружающей среде. И в том числе поэтому им невозможно овладеть, выучивая языковые модели на огромных корпусах. Можно лишь овладеть, погружая агента в виртуальную среду, где ему нужно дать жить, развиваться и поощрять его зречевое поведение. Спасибо за внимание. 

S08 [00:38:35]  : Дима, спасибо. Там было живое обсуждение на тему того, что все, что нам нужно – это много дофамина. 

S03 [00:38:47]  : Я, кстати, не вижу его. 

S08 [00:38:49]  : Это в чате, да? В чате, да. И сразу я забегаю вперед. Там был вопрос по поводу того, что играет роль дофамина в программной реализации. 

S09 [00:39:06]  : Ладно, я раз уже начал говорить, тогда первый вопрос. А что будет? Корректно ли будет или нет? Или частично корректно, а частично нет? Даже вот так вот. Как, с точки зрения вот той схемы, про которую ты рассказываешь, можно связать пресловутый дофамин, который у тебя проходит везде красной нитью, и то, что я в своих докладах последних называю глобальным подкреплением или глобальным фидбэком? 

S03 [00:39:32]  : Но подожди, давай разберемся тогда, что ты имеешь в виду под глобальным фидбэком. 

S09 [00:39:37]  : Окей, тогда давай лучше сниму вопрос, давай тогда пойдем по порядку. Если останется время, обсудим. Так, значит, вот вопрос от Евгения Бабарыкина. Надо ли под субъектностью понимать самосознание? Давай сразу тогда, Дим, я тогда сразу ещё добавлю свой вопрос, чтобы вкусно отвечать. Значит, вот первый вопрос – это надо ли под субъектностью понимать самосознание? А у меня ещё такой вопрос похожий был. Как ты связываешь понятие субъекта, значит, субъектности, сознания, Вот, то есть, дублирую этот вопрос. Но и мультимодальности. Вот я услышал, что у тебя где-то всё это возникает на стыке мультимодальности, а на семинаре по сознанию, который Душкин проводил в прошлом году, там тоже в конечном итоге основная канва была, по-моему, в Душкинском докладе, что сознание возникает там, где возникает мультимодальность. Соответственно, вот как ты связываешь сознание, субъектность и мультимодальность? 

S03 [00:40:34]  : Я бы вообще слово «сознание» здесь выделил в отдельную категорию и не связывал его с мультимодальностью. В моей картине мира всё-таки сознание – это уже последний рубеж того, к чему мы приходим, когда у нас уже всё есть. развитые функции обучения, функционирование информационных потоков внутри агента. Грубо говоря, я считаю, что ребёнок получает сознание, когда он уже достаточно развит. Два-три года примерно, не раньше. Пока нет достаточно развитой когнитивной деятельности, о сознании говорить ещё просто рано не приходится. Мультимодальность принципиально важна для того, чтобы учиться, для того, чтобы, в принципе, нам формировать картину мира. Если у нас нет двух потоков из разных источников и нет их сочетания, то непонятно, как отделять одно от другого, как вообще разделять сущности между собой, как выстраивать связи между ними. Во всяком случае, мысленный эксперимент я такой представить не могу. Поэтому вы знаете, наверное, что даже у слепых, глухонемых детей, когда они учатся говорить, они делают это через две руки. То есть у них идет разделение потоков от двух рук. Одной рукой они ощупывают предмет, а во второй руке они получают такой языковой вход, то есть им показывают знаком, что этот предмет, как он называется, если я ответил на вопрос. 

S09 [00:42:20]  : окей следующий вопрос есть ли у агента память значит это 3 есть ли у агента память и что вот с точки зрения вот твоей модели про которую ты рассказываешь подразумевает видеть видеть вот как вот он видеть все что значит видеть сыр давайте вернемся к этой схеме где у нас сыр То есть, два вопроса, на самом деле, два вопроса, они, по-моему, немножко не связаны, но тем не менее. Есть ли память и как он видит сыр? И сразу вопрос еще и тогда насчет видения. И как он видит? Все поле или только прямо? 

S03 [00:42:56]  : Смотри, в моей схеме она предельно упрощена. Как в природе, получается, у нас постоянно идут какие-то связанные ходы. Они очень многомерные, очень много сигналов, какие-то из них важные, какие-то шумные и так далее. Я все упростил до предела. У нас есть сенсор, который буквой S обозначен сверху, и он воспринимает какое-то состояние среды. Давайте на следующий слайд переключимся. Когда мы смотрим прямо, допустим, на сыр, то это соответствует состоянию наблюдения, который мы обозначим фиолетовым. Если мы немножко вбок повернулись и сыр у нас чуть-чуть слева, это будет зелененькая, зелененький паттерн активности. Если сыр у нас чуть подальше, это будет синенький. То есть мы просто все возможные состояния наблюдений, мы просто их дискретизуем и подаем в виде разных отдельных дискретных значений на сенсор. Потому что это позволяет обучаться, то есть мы как бы абстрагируемся от сложной цепочки потоков от настоящих многомерных сенсоров до вот этого уровня, где у нас уже есть абстракции. И дальше уже сосредоточимся на обработке этих образов. Это, собственно, как он видит. Но, конечно, когда мы будем делать AGI уже полноценный, развернутый, нам потребуется зрение, нам потребуется анализ пикселей, не знаю, саккадическое движение какое-нибудь, фонемы, я уж не знаю, нужно ли ему будет действительно реагировать на настоящий звук. По идее, нужно, потому что интонация и прочее. Здесь все упрощено для того, чтобы показать принцип. Это про зрение, про видение. Второй вопрос. Есть ли у агента память? Память здесь получается на нескольких видов. Во-первых, память – это то, что мы научились распознавать. Когда мы с языком работаем… У нас уже здесь в энкодере Fonem какие-то паттерны уже знакомы, и они распознаются. Это, получается, распознающая память. Следующая память у нас – это память команд. Соответствие одних вещей к действиям. Когда нам приходит на вход какой-то стимул, мы совершаем какое-то действие. Связь этих вещей – это тоже память. Ну и третьим можно отдельно выделить память – это память связей, когда у нас какой-то визуальный образ связывается с фонетическим образом, и допустим разные образы, кошка связывается словно с зверем – это связь, это тоже память. Я не знаю просто, как ее замапить на… известной терминой, типа временная память, рабочая память и так далее. Теоретически можно замапить, но я не буду сейчас здесь популяцией заниматься. Просто здесь вот такие виды памяти присутствуют. 

S09 [00:46:24]  : Спасибо. Комментарий от Александра. На самом деле это комментарий, а не вопрос. Но может быть ты прокомментируешь этот комментарий. Что под распознаванием докладчик понимает найти в памяти то, что пришло на сенсор входа. Если в памяти памяти ничего не нашел, то и не распознал. Это правильная интерпретация? 

S03 [00:46:47]  : Ну, почти. Мы распознаем не то, что мы знаем, а некую последовательность. Распознавание – это всегда детекция последовательности чего-то. Слог – это последовательность фонем. Слово – это последовательность слогов. Визуальная картинка – это тоже, по сути, последовательность. Мы перебегаем глазами от одного объекта к другому, они у нас выстраиваются в последовательности, мы не объекты, а атрибуты. Глядя на лицо, мы смотрим на лицо, на губы, на лоб, на рот, на нос и так далее, и всё это связывается в некую последовательность образов, которые позволяют воспринимать конкретного человека. Каким образом? 

S09 [00:47:36]  : Спасибо. И вот сразу тогда я тут ставлю один из своих вопросов. Вот по поводу последовательности как раз. Там была у тебя схемка, где показано объединение паттернов, когда один и два соединяются в три, и таким образом ты говорил, что мы Фонемы К, КК и А распознаем как слог К. Но вот эта схемка кодирует не только КА, но и АК. Соответственно вопрос, а все-таки как мы отличаем КА от АК? 

S03 [00:48:12]  : Давай посмотрим на эту схему. 

S09 [00:48:15]  : То есть я правильно понимаю, что всё-таки вот та схема, которая сейчас у тебя перед этим была, она всё-таки представляет как АК, так и АК? 

S03 [00:48:25]  : Да, она не учитывает порядок. Вот эта схема уже учитывает порядок. Вот видишь, они идут, сначала приходят активации на верх, на самый верхний кружочек, а потом она спускается вниз. Соответственно, таким образом они показывают порядок. исследования этих двух паттернов. И именно этот порядок запоминается у нас первом кружочке второго столбца, как слог. 

S09 [00:48:52]  : Спасибо. Потом комментарий есть от Игоря Пивоварова. Не знаю, актуален он еще или нет по поводу того, что непонятно, не говорится про то, как агент обучается. То есть, описан механизм обучения, но не то, как агент обучается. Игорь, если вопрос актуален, может быть, уточнишь? 

S05 [00:49:15]  : Нет, это был не комментарий. Это же я Илье отвечал, по-моему. А, окей. 

S03 [00:49:23]  : Я могу прокомментировать. Тут как бы за ширмой осталось много вещей, которые, ну да, действительно, нужно было про них сказать. Ну, допустим, агент что-нибудь там, ну, среагировал как-то на стимул, да, какое-то действие. И у нас должен быть какой-то дядька, воспитатель, ну, который, естественно, электронный дядька поначалу. а потом это должен быть реальный человек, который, собственно, дает морковку нашему агенту и говорит, это правильно, вызывая поток дофамина во все нужные центры, где дофамин ожидается. Только так получается. То есть у нас либо должны быть прописаны жестко сценарии, что стимул, действие, награда, если действие такое, либо это должен быть человек, интеллектуально распознаёт правильное действие и награждает агента. 

S09 [00:50:18]  : Окей. Вот тут как раз мы подошли к дофамину. И вопрос. Что такое дофамин с точки зрения программной реализации? Как мы будем эмулировать потоки дофамина в программной архитектуре? 

S03 [00:50:34]  : Ну, собственно, у меня это сделано так, что… есть сценарий, в котором прописан какой-то вход в агента и ожидаемый выход. И, соответственно, если выход совпал с ожидаемым, происходит впрыск дофамина во всю систему. То есть, начиная с агента, это как, по сути дела, набор зон. Вот эти все зоны. Давайте я покажу. Каждая зона получает свою дозу дофамина. Каждая зона понимает, ей сейчас нужен дофамин или нет. Она ожидает какого-то вознаграждения за то, что она сейчас сделала или нет. У нее эта логика встроена, прошита. И, соответственно, дальше зона распределяет дофамин внутренним областям. Область тоже смотрит, так, мне сейчас нужен дофамин, если нужен, коп, контроллер конкретно получает эту порцию и, соответственно, выполняет свою логику по закреплению этих самых правил, которые связывают вход и выход. Примерно так, то есть как бы снизу вверх, вернее, сверху вниз от в целом всего агента с растеканием по всем отдельным блогом. 

S09 [00:52:02]  : Ну и логически следующий вопрос у Игоря Пивоварова. Эта модель, она в какой-то среде работает? На каком-то языке программирования написано? Или это пока просто как бы дизайн для обсуждения? 

S03 [00:52:17]  : Да, у меня все это есть. Я не помню, там GitHub свой привел. Вот у меня на GitHub это все выложено. Естественно, там оно немножко отстает от того, что я рассказываю. Некоторые последние фичи я еще не реализовал. Но в целом, да, как я говорил, я все это делаю. Все вот эти гипотезы о том, с чем должно быть связано, куда должна идти информация, я проверяю. Потому что то, что я вам показал, это один из пары десятков экспериментов. потому что как-нибудь свяжешь вот так, и оно ведет совершенно не так, как ожидается. Поэтому да, все делается на питоне, потому что это самый простой язык для прототипирования. И примерно в той же самой парадигме, о которой я вам сейчас рассказал, Welcome, можете код ревьюить. можете идеи подбрасывать. 

S09 [00:53:10]  : – Но до реализации какого-нибудь страуса, бегающего по виртуальному миру в поисках сыра еще не дошло, да? 

S03 [00:53:17]  : – Ну, сейчас у меня что-то типа однолетнего ребенка. То есть он умеет повторять слова, он умеет говорить то, что видит. Пока на этом все закончится. Более сложная когнитивная схема пока еще не дошли. 

S09 [00:53:32]  : – А в демонстрабельном виде это есть в каком-то, чтобы показать? 

S03 [00:53:36]  : Ну, прямо так, что нет. То есть нужно же какой-то веб-интерфейс сделать. А тебя, Антон, впечатлит, если он повторит слово, которое ты ему скажешь. Это же можно сделать простой if den, написать и все. Или он видит образ кошки, который закодирован даже конкретным словом, и он тебе скажет, что это кошка. 

S09 [00:53:59]  : Ну вот надо тогда как-то это попробовать. Хорошо. Я дошел до своей записи на вопросы. У меня есть несколько. Первое. У тебя там была схемка, где от диспетчера идут разные стрелочки на разные паттерны, насколько я понимаю, в самом-самом начале. С точки зрения моего понимания схемотехники, это означает то, что он одновременно на все посылает сигнал. Но, видимо, я неправильно это интерпретирую. Потому что это все-таки коммутатор. То есть, он все-таки коммутирует, он все-таки принимает решение, по какой стрелочке сигнал пойдет или нет. И если да, то, видимо, у него внутри какая-то должна быть еще своя логика. 

S03 [00:54:42]  : Но логика здесь как у реле. Или, не знаю, реле трехпозиционное, допустим. То есть, если в таком состоянии, то ток течет через правый провод. Если в таком состоянии, то ток течет через средний провод и так далее. 

S09 [00:54:57]  : То есть у него внутри есть еще какая-то логика, не видная на этой схеме, которая обеспечивает то, что ток течет только по одному каналу, правильно? 

S03 [00:55:08]  : Да, да. Давай вернемся прямо к первой схеме. Видишь, у тебя паттерн – это какие-то определенные нейроны или колонки. Представь, что у тебя конкретно сочетание колонок 

S09 [00:55:26]  : получается что на выходе вот из этого коммутатора вот есть вот так вы и на выходе из него идет вот такая матрица до 16 16 разрядной матрицы у него выходит и в этой 16 разрядной матрицы могут быть одновременно активны значит только три канала правильно да например тогда и каждый вот эти вот 

S03 [00:55:47]  : Каждая своя комбинация привязана к какому-то проводу. То есть провод, по нему потечет ток. Именно такое сочетание, а не другое. Именно так. 

S09 [00:55:59]  : Хорошо. Теперь вопрос к самому философскому началу. У тебя прозвучала такая вещь, что нам для AGI нужно потребности, нужно мотивацию, и прозвучало слово «воля». Нужна воля. И прозвучало, что понятие живых организмов, и что можно начинать вообще с какого-то простейшего уровня. Вот вопрос – на каком простейшем уровне организации живой материи можно говорить о воле? Есть ли воля у собак, у кошек, у гидры, у клетки, у вируса? У кого воля появляется? 

S03 [00:56:43]  : Я же смотрю на все эти понятия с механической точки зрения. Как философское понятие воля – это просто слова. Как конкретно устроена воля? В моем понимании воля – это просто соотношение между сигналом, который поступает от дофаминового наркомана, то есть то, что у тебя зудится прямо сейчас. То есть схема, которая решает, надо ли мне это. Живому организму нужны ресурсы для любого действия. Нужно сжечь какой-то объем энергии и так далее. Вот если наша мотивация от этого центра мотивации превышает, порог того, что считается целесообразным для совершения этого действия. Собственно, это и есть проявление воли, получается. То есть он может что-то захотеть, но ему будет лень вставать. Это значит, что мотивации не хватило, импульса не хватило, чтобы преодолеть этот порог. 

S09 [00:57:46]  : Ну а вообще вот как тогда быть? Тогда смотри, тогда получается есть еще проблема с краткосрочной и долгосрочной волей, потому что у меня вот такая воля, что она меня, значит, зовет выпить водки, значит, это краткосрочная воля, а долгосрочная воля, значит, меня заставляет готовиться к экзамену. И вот две такие воли меня тянут к разным целям. 

S03 [00:58:08]  : Ну это вечная борьба между неокортексом и лимбической системой. Ну и там и там есть воля в твоих терминах, правильно? Да, но по сути дела это, как я понимаю, два сигнала, которые идут один из неокортекса, высшая мотивация другой лимбической системы, и они соревнуются между собой. И winner takes a role здесь тоже работает. То есть точно так же, какой из них окажется сильнее, туда ты и пойдешь. 

S09 [00:58:36]  : Я, кстати, согласен в принципе с таким подходом. Спасибо. И последний вопрос от меня. Как ты относишься на данный момент к соотношению между AGI реинфорсмент леарнинга и пресловутым OpenAI Jim. Насколько они далеки и близки, в каком соотношении друг к другу? 

S03 [00:59:02]  : Смотри, реинфорсмент леарнинг сама по себе прекрасная вещь. В конце концов, мы сами так учимся. Но в том сетапе, в котором действует сейчас DeepMind, главный протагонист, Deep Learning, точнее Reinforcement Learning, это не ведет к HAI, насколько я считаю, по причине, опять же, не та архитектура и не та схема мотивации. То есть то, что делает DeepMind, опять же, со своими агентами, агент 57, последний, который умеет в 57 Atari игр играть, сделали бы они так, что пусть он научится играть в 56 игр, а 57 игру сам освоит как человек, действительно мы поймем, что он чему-то научился, что он приобрел не просто способность проходить игру, но и навыки прохождения игры, то есть какое-то обобщение приобрел, но они же так не делают, у них в принципе нет такой такой цели, либо цель есть, но они понимают, что это нереально с помощью эти пленинга сделать. Это вот про reinforcement learning. То есть сам по себе он хорош, но его надо правильно готовить. То есть его нужно сочетать обязательно с какими-то другими когнитивными штуками, чтобы это все заработало в правильную сторону. И про что-то еще ты говорил про… Ну и GI, RE… А, про GIMP ты говорил, да? Джим – это же просто платформа для тестирования, и она, в принципе, живет в той же парадигме, в которой работает DeepMind. То есть у нас есть игра, и нужно ее постичь. Главное – это как у стахановцев – пройти игру лучше человека, сделать лучше человека. И все. И это считается большим достижением. Опять же, это неправильно. Возьмите и сделайте очень простую какую-то вещь. Учите играть агента в крестике нолике, но так, чтобы он не знал заранее, что он играет в крестике нолике. Тогда это будет уже AGI-подход. Тогда это будет приводить к навыкам и обобщению вместо решения конкретно этой задачи. Поэтому я считаю, что Джим в той парадигме, в которой он сейчас живет, он не мотивирует нас делать какие-то общие интеллектуальные системы. 

S09 [01:01:35]  : Дима, очень короткий комментарий. На самом деле, когда ты играешь в джим, ты не знаешь, во что ты играешь. 

S03 [01:01:42]  : У тебя есть просто входы и подкрепления, поэтому в данном случае, мне кажется, это как раз... Опять мы говорим про то, что научись играть это за три прохода или за 300 тысяч. То есть, когда у нас есть брутфорс в кармане, мы, конечно, можем этот брутфорс 

S09 [01:02:02]  : А это означает, что мы должны накладывать еще и ограничения по ресурсам в соответствии с формулировкой? 

S03 [01:02:09]  : Да, мы с тобой тогда очно обсуждали эту проблему. 

S09 [01:02:14]  : Давай тогда эту дискуссию свернем, чтобы дать другим вопросам задать. Может вернемся ближе к концу. Здесь еще есть большой один вопрос у Игоря Пивоварова. 

S05 [01:02:25]  : Да, спасибо. Сейчас, и прежде чем вопрос, у меня ощущение, что в сообществе регулярно путают дипленинг, реинфорсмент ленинг, что это такое, надо на эту тему как-то отдельно вообще поговорить. потому что это вещи, лежащие в разных измерениях, если так можно выразиться. И, Дмитрий, то, что вы делаете, это явно будет так легче использовать парадигму реинфорсмент ленинга. Это просто такой комментарий. Второй комментарий, он такой для всех, скорее, и для Дмитрия тоже, что в докладе было несколько вещей смешано, и поэтому люди этого не поняли. Вы знаете, как я понимаю, рассказывали условно про архитектуру и давали пример этой архитектуры на одном там конкретном агенте, который выглядел как мышка, который ищет сыр. При этом часть народа решила, что вы именно этого агента и делаете. я понимаю я просто это скорее для всех говорю что речь прошла про некую архитектуру которую можно масштабировать там как угодно делать этого агента сколь угодно сложного вы там придуете на то что это некая архитектурная история меня на принципе вполне нравится что она но не противоречит всему что я знаю и вполне себе может быть реализована конкретный модуль может быть реализована на нейросети это может быть там вот модуль, который там и Евгений Витяев делает, и Шумский делает, и там еще многие другие. То есть, короче, это вполне себе история не противоречивая. В этом смысле я не совсем согласен с вами, с вашим комментарием по поводу дипленинга, потому что просто дипленинг делает это на более низком уровне. Вы как бы, грубо говоря, вы пытаетесь связи между ними, а они, грубо говоря, делают большую сеть, в которой неявно эти модули сами должны создаться и неявно эти связи должны прорисоваться. Я не вижу здесь какого-то антагонизма, просто вы как бы пытаетесь более короткий путь найти, и он мне кажется с одной стороны разумным, с другой стороны мы понимаем, что он столкнется с такими ограничениями. Но теперь вот вопрос как раз главный. Да, у меня был вопрос, собственно, есть ли программный код. Я верю, что есть программный код. Но главный вопрос, он другой, он про больное. Знаете, как было у Жванецкого в известном монологе. Жаль, что мы так и не услышали начальника транспортного цеха. значит вот вы все время говорит про транспорт на цех транспорт на цех но ты бишь про субъектность вот субъектность агента и все начало про нее сказали я субъект ты не увидел дальше нигде и вообще как бы его про него ничего не было я увидел там много контроллеров присыпанных допамином обильно и понимаю что такая ну как бы вы вы делаете некую машинку она вполне может пределе там что-то делать там в какие-то стороны крутиться но вот вы постарайтесь сейчас своим языком объяснить где вы там видите субъекта и в чем там субъектность проявляется на ваш взгляд собственно субъектность она в этом и заключается что у нас есть какая-то 

S03 [01:06:04]  : это шило, которое нас колет постоянно и заставляет действовать. Это корень его деятельной энергии, его источник, скажем так. А дальше, соответственно, у него возникает уже куча, исходя из этого, возникают потребности. Вот там, где потребности, там и возникает субъектность. 

S05 [01:06:23]  : А мои механические часы с автоподзаводом обладают субъектностью? У них все время есть шило, которое их колет, а они все время идут. 

S03 [01:06:32]  : Если бы они самообучались и у них была бы какие-то вот эти механизмы, которые позволяли бы… Получается как? У них есть пружина, которая заставляет что-то делать. И у них нет механизма, чтобы погасить эту пружину. Цель, получается, часов. сделать так, чтобы пружина больше не давила, да, то есть как бы действия противодействия. 

S05 [01:07:09]  : Там нет цели, там нет цели, ну перестаньте, это же, это физика, это диссипация энергии, там я могу много чего рассказать, специально привожу часы в пример, потому что это не субъект, ну сто процентов это не субъект, но я хочу понять, почему вы считаете, что система, которую вы сконструировали, Почему вы используете слово субъектность? Я понимаю слово агент, понимаю даже интеллектуальный агент, даже самообучающийся. Мне интересно, где вы там видите субъекта? 

S03 [01:07:37]  : Вкратце, субъектность – это оно есть. У нас есть пружина и есть механизм, который гасит эту пружину. Все, это субъект есть в моей философии. Естественно, в жизни это очень наворочено. основной принцип он просто не надо усложнять в вашем понимании мои часы с автоподзаводом являются субъектом потому что они гасит эту пружину нет у них нет они не гасят в том то и дело то есть они если бы у них был механизм который позволял бы эту пружину гасить быстрее чем она гасится естественным образом то есть не не тикать А вот он как-нибудь извернулся бы так, и эту пружину бы просто выкинул. Ну, в чистом смысле. Тогда это было бы уже субъектом. 

S05 [01:08:29]  : Я, честно, не понимаю вашу мысль. Хорошо, давайте на примере вашего агента. Вот ваши блоки, контроллеры, какая-то окружающая внешняя среда. Что вы называете... субъектность почему как бы ну допустим условно если я сделаю на там на лимита на там куленинге какому-нибудь там таблицу которая будет на reinforcement learning запомнит как как ходить к сыру это будет субъектность у этого агента или нет да очень примитивно в очень примитивном мире она 

S03 [01:09:10]  : принципиально не отличается от нас. То есть просто наш мир гораздо сложнее и мы сами гораздо сложнее. Но принципы те же самые. 

S05 [01:09:20]  : Ну то есть я бы так сформулировал что если некий агент демонстрирует целенаправленное поведение которое при этом как-то учится его там корректировать свое поведение, то для вас достаточно этого, чтобы назвать этого агента, что у него есть некая внутренняя субъектность. Да. 

S03 [01:09:50]  : Хорошо. Давайте подискутируем. Расскажите ваше понимание, мне тоже интересно. 

S09 [01:09:58]  : Ну, давайте, может быть, всё-таки все вопросы и комментарии проведём, если останется время, тогда устроим ещё дискуссию. У меня там тоже есть подискутировать на этом ключе. Значит, единственная просьба коллегам. У нас запись вопроса и комментарии по записи в чате, вот, потому что в какой последовательности руки кто поднял, трудно запомнить. Вот я знаю, что Николай Робчевский поднимал руку реальную, а Александр поднял руку виртуальную, но в какой момент это было? Непонятно, поэтому я пока иду по списку в чате. Соответственно, Евгений Евгеньевич просил про возможность прокомментировать. Евгений Евгеньевич, вы здесь еще с нами? 

S06 [01:10:35]  : Да, здесь. Дело в том, что мы тоже занимались мышами и тоже, причем в очень полковой ситуации, то есть тоже есть сыр, тоже удаленный, тоже, так сказать, шаг вправо, тоже движение и все прочее. И я могу даже провести видео, то есть это все реализовано в виртуальной среде, реализовано в программе, то есть это все работает, работает достаточно успешно. Если интересно, я могу даже видео показать. Но вопрос на самом деле другой. Дело в том, что то, что мы делаем, оно сделано в соответствии с такой достаточно общей архитектурой теории функциональных систем. И более того, эта архитектура, вместе с этой мыслью, кстати, я докладывал на основном семинаре, где выступают физиологи, то есть в Институте нормальной физиологии имени Анохина, у них прямо на семинаре по математической формализации теории функциональных схем, и там возражений не возникало. То есть в этом случае эта схема, она действительно описывает теорию функциональной И эта схема в этом случае не удовлетворяет потребности и дофамина, и любой другой. То есть она в этом случае, кроме того... по архитектуре достаточно универсально. Я могу сейчас просто сбросить ссылку на этот доклад. Мне кажется, что имеет смысл, по крайней мере, познакомиться с этим делом. Детальное сравнение, я думаю, не нужно как-то говорить, что-то в этом плане делать. Но просто познакомиться с этим, я думаю, имеет смысл. Я могу ссылку бросить. 

S03 [01:12:03]  : Я, в принципе, смотрел уже несколько ваших либинаров. где про Мохинские теории функциональной системы. Я считаю, что это фреймворк немножко более высокого уровня, чем то, о чем я сейчас рассказывал. 

S06 [01:12:14]  : Он не совсем отличается от того, что вы говорили. Да, это даже не то, что отличается. Он намного сложнее на самом деле. 

S03 [01:12:20]  : Это фреймворк более высокого уровня абстракции. То есть я предложил его конкретную реализацию, показал там шестеренки, винтики и так далее. ТФС – это просто более такая общая схема того, как это в принципе может работать, и другим способом это можно тоже реализовать. Так что я считаю, что у меня ТФС – совместимая штука. 

S09 [01:12:45]  : Спасибо. Вопрос от Бориса Новикова. Можно ли в вашу модель включить культуру взаимодействия агентов и их взаимное обучение? Кстати, вот у Евгения Евгеньевича это можно, потому что культура агентов это язык программирования, язык DSL 0 и мыши взаимодействуют и учатся совместно находить сыр. Как у вас с культурой и взаимодействием агентов? 

S03 [01:13:05]  : Я считаю, что это все до этого немного рано. В том смысле, что пока он не освоил какие-то простейшие языковое поведение, общаться он не может. То есть мы, конечно, можем хардкодно прописать какую-то знаковую систему, но весь принцип всей моей архитектуры в том, что нельзя хардкодно прописывать никаких знаковых систем, он должен сам ее получить от взаимодействия. с миром и с другими агентами. Если сейчас однолетний ребенок у меня изображен, то это нужно хотя бы до двухлетнего ребенка, чтобы он как-то научился коммуницировать хотя бы примитивным образом. А так в принципе да. Получается такая эмерджентность должна произойти. 

S09 [01:13:57]  : А вот тогда вопрос как раз от Сергея Терехова. Если мы случайно первый раз в жизни нашли сыр, к примеру, в туалете, чтобы нам каждый раз не ходить в туалет за сыром, а научиться всё-таки, что его искать сперва надо на кухне и в холодильнике, как происходит забывание, вытеснение ранних случайных ассоциаций? И как происходит переход от симметричных ассоциаций к несимметричных. То есть, как мы переходим от корреляции к причинно-следственным отношениям, что важно для долгосрочных, построения долгосрочных сценариев. Два вопроса тут я вижу. Да, два вопроса. 

S03 [01:14:40]  : Забывание. На самом деле, это слабое место. То есть, я продумывал забывание и как его можно механически реализовать. Но я упоминал уже кортизол. Соответственно, должен быть противоположный дофаминовым стимул, разочарование, которое я явно должен дать. в виде какого-то символа условного. И, соответственно, у нас точно так же, как дофамин, в этом случае должен пролиться кортизол на нашего агента сверху и разойтись по всем блокам, и, соответственно, отключить те правила, которые привели к этому последнему действию. Ну как-то так. 

S07 [01:15:28]  : Антон, мне можно будет уточнить вопрос, да? Да-да-да, конечно. Дмитрий, я вот что имел ввиду под этим вопросом. Дело в том, что ассоциативных памятей нужно очень много схем. Ваша схема замечательная, мне очень нравится. Я тоже инженер, и как бы это вот оно. Вот, все классно. Их много, начиная там с 50-х годов, и у Кахона там в 80-х замечательно были схемы и так далее. Но фишка состоит в том, что запоминание целенаправлено. То есть, когда вы начинаете накапливать ассоциации, вы это получаете в виде целенаправленных сигналов. А вот забывание, оно не целенаправленное. Вы не можете ощутить или четко вербализовать, но, конечно, когда вы взрослый человек, уже можете, что вот это бы мне надо забыть. А вот когда вы находитесь в потоке вот этой самой информации, то нет никакой возможности целенаправленным образом сказать, что вот эта цепочка, она уже может быть большой. Представьте себе, у ребенка сложный мир и сложных ассоциаций. То есть они все уже закреплены все и все неправильные. И вот какого-то направленного механизма, который бы включал вот таким вот стрелкой включал бы вот это забывание, это главная проблема ассоциативных памяти, потому что они в результате не умеют адаптироваться, они вот только расти умеют. Вот в этом был вопрос. Но вы, собственно, ответили, что на самом деле с этим проблема, понятно, я понял. 

S03 [01:16:51]  : Но по второму вопросу тоже можете? Можно еще раз второй, я что-то забыл. 

S07 [01:16:58]  : Опять-таки достаточно несложно сделать системы симметричные. а там и тензорная моя модель, и другие системы, когда ассоциации запоминаются в виде комбинации. И то же самое по времени. Время в данном случае не важно. Сам факт того, что что-то раньше, что-то позже, это тоже не важно. Это показано много раз. А вот вопрос стоит в том, как перейти от этих корреляционных фактически ассоциаций, молниегроза, к причинно-следственным, к ассоциациям, грубо говоря, следующего уровня, когда вы из вот этих симметричных структур получаете несимметричное, что нечто является причиной, а нечто является следствием. Ну и дальше уже там контрафактное мышление там и так далее, но об этом сейчас уже мы не говорим. Вот как вы тут... Интересный вопрос. 

S03 [01:17:49]  : Да, у меня есть, я думал над этим, ну так, не сильно прямо, чтобы заморачиваясь, но тем не менее, да, вот у Джуди Перл там есть И он рассуждает, что причинно-следственные связи – это самое ядро, и пока интеллект не пришел к пониманию этих связей, он вообще интеллект существовать не может. Я, с одной стороны, согласен. И действительно, почему такая проблема? Потому что из временных корреляций причинно-следственные связи напрямую не следуют, и вообще в принципе их невозможно вычислить. глядя только на одни лишь корреляции. Это факт, с которым ничего не поделаешь. И давайте посмотрим на нас, на самих, как мы выучиваем причинно-следственные связи. Я думаю, что это просто. Нам об этом говорят взрослые. То есть о том, что гром и молния. Ребенок спрашивает у мамы, а как это так? почему гром там и так далее. Она объясняет, что гром, потому что молния вызывает разрезы и так далее. То есть у ребенка закладывается это на уровне языковой модели и на уровне ассоциативных связей, которые он получает извне. Сам ребенок, получить эту картинку, просто глядя на явление, никак не может. 

S07 [01:19:11]  : Ой, Дмитрий, тогда это очень сложная сразу тема. Тогда вопрос в том, кто был тот первый, кто сказал тому Адаму, что вот это вот причина следственного связи, яблоко ешь, яблоко не ешь. То есть это же вот вопрос. Если это только культурно, вот Борис Нойков кивает, возможно у него есть более точный комментарий. 

S03 [01:19:31]  : Ну, давайте я сначала свою версию скажу. Культура – это шорткат. То есть это те знания, которые мы могли бы получить эмпирически, но нам подают их в сжатом готовом виде. Но, соответственно, если бы у нас не было культуры, если бы мы были Маугли и сами бы исследовали мир, то нам пришлось бы с помощью экспериментов и вниканием в этот предмет в очень медленно и мучительно выцеживать все эти причинно-следственные связи. Только так. Только экспериментом. 

S07 [01:20:06]  : А можно попросить Борису Новику дать возможность выставить? Антон, он прямо сейчас хочет аргументировать. 

S09 [01:20:10]  : Да, хорошо, давайте. Борис, пожалуйста. 

S04 [01:20:13]  : Я уже задавал вопрос, можно ли эту модель развить до взаимодействия агентов и взаимодействия их с культурой. Сейчас ровно про это же. Культура возникает... Значит, во-первых, у нас есть знания генетические, как результат биологической эволюции. Дальше у нас есть знания культурные и навыки, как результат культурной эволюции. которая, видимо, начинается еще до появления хомо. Даже у шимпанзе и касаток родители обучают детей некоторым навыкам. И это тоже есть проявление культуры. Но у нас они накапливаются. И, на мой взгляд, принципиально для человека всего две вещи. Это освоение огня и освоение письменности. Теперь культура накапливается не только в субъекте, в личности, но и в обществе. И передается от общества в субъект. И по поводу субъектности я попробую. Это, на мой взгляд, главное. И у меня есть еще ответ на вопрос о субъектности. Можно? Хорошо, давайте. Я считаю, что субъектность проявляется в том, что так называемый дофамин получается разными субъектами за разные, и субъект может это менять сам. И это равно свободе воли. За что получать поощрение и наказание? Это субъект определяет сам на основе генетической и культурной эволюции, взаимодействия со своей биологической природы, из культуры. И вот в этом и проявляется субъектность человека как личности. Ну это уже немного получается философский вопрос, поскольку... Но я вообще не интересуюсь философскими вопросами, я не разработчик. 

S03 [01:22:21]  : Для того, чтобы он сам определил свой источник дофамина, ну кто должен это определить? Какая механика должна это сделать? Ну как? 

S04 [01:22:30]  : Я же сказал, первая филологическая природа, безусловные рефлексы, дальше условные рефлексы, а дальше уже свобода воли. То есть к чему ценности человека, а потом цели и средства. И самооценка. 

S03 [01:22:50]  : Ну вот в моем парадигме вот эта вот свобода воли – это естественное развитие, это усложнение вот этого аппарата условных рефлексов и тофаминового подкрепления до такого состояния, когда оно уже начинает работать само по себе. 

S04 [01:23:07]  : Примерно так. Только что значит само по себе? Вообще есть реальность и есть ее модели. Вы совершенно правильно сказали в самом начале, что вы делаете модель. И так бы мы ее не усложняли, мы все равно делаем модель. Вся наша наука, все наше искусство, это все модели реальности. И соответственно, То, что мы говорим про дофамин, это тоже модель. Значит, там на самом деле разные уровни. Можно опускаться на атомный уровень, на субатомный, подниматься на уровне всей системы, организма, общества и так далее. Поэтому есть разные модели. И вот субъектность эта проявляется в том, что Субъект сам определяет во многом, с какими моделями он работает. По крайней мере, свобода воли — это тоже удобная модель. Она может сочетаться как с детерминизмом, так и с индетерминизмом. Просто когда мы принимаем, скажем, судебную ответственность, значит, мы предполагаем свободу воли. Иначе это бессмысленно наказывать человека за то, что он не мог не сделать. 

S09 [01:24:34]  : Спасибо, Борис. Я здесь прокомментирую чуть-чуть. Как раз в том проекте, которым я сейчас занимаюсь, есть проблема, что нужен искусственный интеллект для того, чтобы выбирать модели, которые будут реализовывать искусственный интеллект. Здесь возникает некоторая иерархия. У нас нужна модель. Может быть, модель, которая будет использоваться для того, чтобы выбирать модели, а те модели могут, в свою очередь, использоваться для того, чтобы выбирать другие модели. 

S04 [01:25:02]  : Правильно, только ключевой момент в слове «нужно». Кому нужно? 

S09 [01:25:07]  : агенту для того, чтобы получить подкрепление, дофаминовое подкрепление в результате достижения долгосрочной цели. Ну давайте, коллеги, давайте сейчас все-таки дискуссию немножечко отложим, есть еще вопросы. 

S07 [01:25:18]  : Антон, чтобы второй раз не подключаться, там у меня еще комментарий маленький был, можно? Дмитрий, вот я просто обращаю ваше внимание, есть такие сети Петри, наверняка знакомая штука, начиная с 60-х годов, они занимаются формализм для моделирования большого количества параллельных синхронизирующихся процессов с адаптацией и так далее. если не знакомы, то может быть интересно, если знакомы, то хорошо. это 60-е годы, сети Петри. 

S03 [01:25:47]  : честно говоря, да, я слышал. 

S07 [01:25:51]  : возможно, там вы что-то и подчеркнете, потому что вы ничего не говорили о синхронизации, они естественным образом еще и вас с этой стороны. 

S03 [01:25:58]  : это отдельная больная тема. 

S07 [01:26:05]  : поэтому я обращаю ваше внимание, что есть сети Петри, это 60-е годы. все, спасибо, я отключаюсь. спасибо еще раз, Дмитрий, за замечательный доклад. 

S06 [01:26:15]  : Вот о причинных связях здесь был небольшой рассказ. Вот я хочу сказать, что действительно причинные связи обучиться невозможно, потому что чисто на данных их узнать нельзя. Но человек, что использует для обнаружения причинных связей? Когда он полностью контролирует внешний мир и контролирует ситуацию, он видит, что при изменении одного элемента объект падает. происходит такое-то следствие, и больше ничего не изменяется в окружении, то есть ситуация, когда он полностью в состоянии контролировать и окружение тоже, он тогда может действительно проследить причинную связь. 

S09 [01:26:52]  : Спасибо. Есть вопрос практический. Каким образом реализованы вот эти вот кружочки у вас в коде? Это нейросетки или какая-то эльгроматика или что-то еще? Евгений Бабарыкин спрашивает. 

S03 [01:27:08]  : Так, сейчас я расшарю. 

S09 [01:27:10]  : И сразу тогда уж, значит, если будете расшаривать, ссылки на первоисточники какие-то можете дать? 

S03 [01:27:18]  : Так, в смысле о том, как возникают паттерны в нейронных областях или о чем вопрос? 

S09 [01:27:23]  : Ну, какова реализация? То есть, вы сказали, у вас есть реализация. Там в этой реализации что, нейросетка или какая-то? 

S03 [01:27:28]  : Посмотрите, смотрите. Есть два уровня. Есть сама нейронная динамика, там, где вспыхиваются колоночки, и сигналы передаются от одной области к другой. Я не стал на этом заморачиваться. Хотя для того, чтобы реализовать обработку средственных сигналов, этим придется заморочиться в любом случае. Но я пока еще откладываю на потом. Я сразу перешел к абстракции. область, у которой есть какой-то стейт. Она сейчас имеет такое сообщение, сверху область, это просто класс в Питоне, у него есть какой-то стейт, и этот стейт обозначает какой-то паттерн, который на нем сейчас активен в этот момент, в этом таймфрейме. А потом следующий таймфрейм, он управляет это сообщение, Ну, каким-то там связанным областям. Вот и всё. То есть, это реализовано на таком очень высоком уровне абстракции. 

S09 [01:28:34]  : Спасибо. Так, и вот прежде чем… Вот ещё два вопроса есть по поводу дофамина. На самом деле, я уже пытался эти вопросы задать, но вот дошли до них. Дофамин, когда идёт, он идёт одному блоку? какому-то выбранному, или он идет глобально всем блокам, или он идет к какому-то подмножеству блоков, то есть к вопросу о глобальном подкреплении. 

S03 [01:29:01]  : Я уже вкратце отвечал. Идет всем, и у каждого блока есть свой алгоритм, как с этим дофамином жить, что с ним делать. 

S09 [01:29:10]  : Ну и правильно ли понятно, что дофамин, с точки зрения программной реализации, у вас дофамин – это просто особый сигнал. 

S03 [01:29:16]  : Это просто сообщение, которое рассылается бродкастом на всё. 

S09 [01:29:20]  : Вот и всё. Спасибо. Ну и тогда комментарии Николая Робчевского, пожалуйста, следующий. Николай, вам слово. 

S00 [01:29:29]  : Спасибо. Во-первых, спасибо за интересный доклад. Во-вторых, у меня… несколько комментариев таких. Первое – это то, что нейромедиаторы с точки зрения программирования – это ровно то, что называется глобальные переменные, набор которых дает обобщенное представление о текущем состоянии. Второй момент – вот то, что Дмитрий рассказывал сегодня, очень-очень напоминает ту схему, которую в свое время Николай Амосов пытался вот в Киевском институте кибернетики делать. И тут ситуация такая, что их проект остановился, потому что они не смогли достичь вот того уровня, который сейчас мы называем AGI. То есть проблемы были не количественные, а принципиальные. То есть до уровня, скажем так, насекомых, способностях учиться или низших животных получалось, а дальше как-то процесс не пошел. То есть прекратили этим заниматься не по причине того, что не было желания, потому что уперлись как бы в логическую такую стену. Ну и по поводу субъектности. С моей точки зрения, субъектность начинается там, где есть вот некий модуль внутренней мотивации. Что это означает? Это означает то, что система принимает некие решения о том, что делать вне зависимости от наличия или отсутствия внешних каких-то стимулов и раздражителей. То есть нет стимулов, нет раздражителей, а решение принимается, и при этом оно не… одно и то же всегда, а зависит от внутренней ситуации внутри этой системы. И это ведет к следствию того, которое сложно отделить от первого, а именно то, что системы идентичны в момент запуска, в процессе своей работы или жизни, как это угодно назвать, они становятся разными. То есть начинают разниться по своему опыту, по своей реакции на ситуации и так далее. Ну вот у меня все. 

S03 [01:33:00]  : Я могу даже прокомментировать оба предположения. По поводу Амосова, я прочитал примерно половину его книжки, и мое впечатление, почему они остановились и дальше не пошли – они некую архитектуру положили в самое начало, и дальше Он рассчитывал на то, что внутри этой архитектуры возникнет самоподдерживающийся разум. Но я считаю, что так оно не работает. Для того, чтобы разум уровня человеческого возник, нужна архитектура гораздо более сложная. Отнять у нас какие-нибудь связи, мозгу обрезать, и всё. У нас ничего просто крутиться не будет. Вот эти прайеры, которые нам даются в виде связей, каниктома, они очень важны. Именно на основании определенной конфигурации связей появляется возможность возникнуть необходимому информационному обмену, который приводит к высшим когнитивным вещам. Ну, мне кажется, просто он не сделал достаточно детально вот эту архитектуру изначально. Что касается самомотивации, у меня есть такой слайдик, где у нас есть тут цикл. Ну, в принципе, вот здесь вот цикл есть, и здесь вот есть цикл. То есть самомотивация и вообще вот это вот всё само-само-само – это всё какие-то замкнутые петли в нашей архитектуре. сами себе чего-то говорим, оно возвращается нам же в виде слов, оно активирует дальше какие-то ассоциации, и вот так это все прокручивается, в результате приводит к каким-то вот этим вот установкам, которые нам дают мотивацию, вот эту внутреннюю, про которую вы говорите. Так я это вижу. 

S09 [01:35:04]  : Спасибо. Вопрос от Владимира Смолина. Где же всё-таки в этой модели обобщение и использование для обобщения ранее полученных знаний? То есть, где в этой модели находится способность обобщать и использовать для этого ранее полученные знания? 

S03 [01:35:31]  : Но обобщение довольно-таки широкая вещь, и здесь я взял какое-то очень примитивное обобщение, когда у нас два образа связываются с третьим образом, который является их общим выражением – звери, кошка, собака. Вот эта ассоциация, которая потом возникает, это самый простой примитивный уровень обобщения. У человеков обобщений гораздо больше, они гораздо более высокоуровневые. Обобщаются там и действия, и абстракции между собой тоже так же группируются и создаются еще более абстрактные конструкции над ними. Но для того, чтобы до этого дойти, нужно, собственно, ну, мы не можем перепрыгнуть через ступеньку, мы должны этот механизм, как бы, ну, довести вот эту вот его ассоциативную модель до того состояния, когда у нас уже возникают абстракции из абстракции и так далее. Вот так я понимаю обобщение. 

S09 [01:36:34]  : Окей. И про масштабирование тоже хотелось бы понять Владимиру Смолину, как в данной модели оно будет реализовываться, когда у нас там станет много кошек, собак, катапсов в больших количествах и на разных языках. 

S03 [01:36:55]  : Первая мысль это все перенести на C++. Это конечно интересный вопрос, но гораздо важнее сейчас сделать процесс, который позволит двигаться в сторону большего масштаба. чтобы это всё возникало, эмерджентность, самостоятельное поведение. И я считаю, что это возможно без привлечения, без модели мира, которая состоит из десятков тысяч понятий и связей. Можно по более простому примеру это всё сделать. 

S09 [01:37:38]  : Окей, у нас кончились вопросы. Соответственно, может быть, кто-то еще хочет прокомментировать или устроить дискуссию по каким-то положениям. 

S10 [01:37:52]  : Я могу, конечно, прокомментировать? 

S09 [01:37:53]  : Да, Владимир, пожалуйста. 

S10 [01:37:55]  : Ну, значит, хорошо, что Дмитрий говорит о том, что должны возникать новые абстрактные уровни, но в этой модели абстрактных уровней не возникает, здесь просто ассоциации возникают, а это не то же самое, новый уровень абстракта. Расскажите разницу тогда. Грубо говоря, нужна быть новой системой понятий, новой системой переменных. И, соответственно, разница, она всё-таки, мягко говоря, есть. И, в целом, такое впечатление, что то ли вы, значит, как бы считаете, слушали на уровне понятий, значит, Павлова, который выяснил, что можно не святым духом что-то делать, а есть условные рефлексы, есть какие-то физические причины, что можно осуществлять. Ну и, конечно, Павлов показал, что можно создать искусственный интеллект. И, соответственно, вот за собакой, значит, смотрите, звенит звонок, слюна течет, значит, физические причины, собственно, не больше духом, а реально, и, собственно, вот как бы работает. Вот как бы я вот воспринял модель, значит, потому что, как правильно говорится, что Анохинская это более высокая модель, там она еще когда-то будет, вот. И, соответственно, Ну и, как вы знаете, я всегда буду рассказывать про проблемы сложности. Тут они тоже никак не прозвучали. То есть вот как, значит, мы сложный мир в эту модель будем запитывать. То есть пока там две кошки, одна собака, все понятно. Когда там, соответственно... понятие сторожится там тысячами, десятками тысяч, и они еще все непрерывные, то есть аппроксимация какая-то должна быть, ну и много чего. То есть вот эти проблемы, они современные, они в этой модели почему-то не прозвучали. Ну, может быть, они когда-нибудь появятся, но пока что это, к сожалению, не объявится. Вот, собственно, одной стороны, значит, для тех, кто вот недавно вошел в тему и вообще не представляет, как там все работает, это интересно, а принципиальных проблем, к сожалению, у модели не затратишь. вот как бы ее основные недостатки. 

S03 [01:39:51]  : я могу только согласиться, действительно, я до этого еще не дошел, и то, что сложности с масштабированием и вообще как это все отлаживать, когда 

S10 [01:40:01]  : сущностей тысячи просто не представляю проблемы сложности масштабируем еще будет проблема устойчивость то есть когда появляются замкнутые связи там нужно чтобы ничего там не заглохла и наоборот не разгорелась там бесконечно это тоже большая проблема то есть все вот современные проблемы которые в реальных моделях решают ну пока что тут все не затронуты до них же видимо должен быть какой-то процесс хотя бы их понять и как начать систему включать согласен 

S09 [01:40:30]  : Коллеги, еще комментарии? Вопросы? Дмитрий, у меня есть еще один вопрос, который мы затронули, но свернули дискуссию. Сейчас все-таки хочу вернуться немножко сбоку к проблеме обучения и верификации того, что мы называем AGI, после той дискуссии, которая у нас была на AI Journey. Когда мы говорили о том, что можно рассматривать, к примеру, среду OpenAI Gym как среду для программирования AGI, если мы могли бы осуществлять некоторый transfer learning между задачами, то есть, допустим, Мы научились играть, к примеру, в пинг-понг. И если мы научились играть в пинг-понг, то тогда верификацией AGI будет то, что мы в Arkanoid научимся играть быстрее. То есть, если я правильно понимаю, у нас была такая идея. Но на самом же деле, мне кажется, не обязательно AGI – это способность к трансферленингу. В конечном итоге, если я могу одинаково быстро научиться играть и в пинг-понг, и в арканойд. То есть, если я могу сделать агента, который научится и в пинг-понг, и в арканойд играть с нуля, допустим, за тысячу итераций, за каждый, то это вот одно. Предположим, это вот один агент. Возьмем другого агента, который за миллион итераций может научиться играть в пинг-понг и потом за пять тысяч за пять тысяч операций в Arkanoid. То есть, вроде как он действительно способен к трансфер-ленингу. То есть, он очень долго учился одной игре, а потом гораздо быстрее научился другой. Но при этом какой-то другой агент может с нуля научиться каждой игре независимо и гораздо быстрее. И с моей точки зрения, вот этот первый агент, который учится любой игре с нуля быстрее, чем второй агент, который учится первой игре очень долго, а второй игре просто долго. Вот мне кажется, что с этой точки зрения все-таки возможность научиться большому числу разных скиллов, не зная тому, что это за, какие скиллы требуются, да, потому что когда в Open Gym вы играете что в пинг-понг, что варканует что там пытаетесь балансировать там палочкой вам на вход просто приходит идет поток цифр и вы не знаете каким сенсором реального мира эти цифры соответствуют вот и в этом смысле как раз именно вот как бы степени AGI, я согласен с позицией, что AGI это не некоторый качественный барьер, а некоторая количественная способность решать более широкий круг задач, чем менее AGI система. В этом смысле как раз количество сред, в которых я могу научиться решать задачи, и при уменьшении скорости обучения решению этих задач одновременно, вот это является все-таки критерием идеальности, а не способность просто использовать знания, обученные в одной среде, и переносить ее на другую. Хотя последнее тоже важно, но мне кажется, это вторично. 

S03 [01:44:15]  : Ну смотри, у меня два есть замечания, потому что ты Мы, на самом деле, учимся не делать какую-то задачу, а мы учимся каким-то общим навыкам. И потом эти общие навыки мы применяем для других задач. То есть, у них на самом деле нет каких-то общих навыков. То есть, мы учимся не делать какую-то задачу, а мы учимся каким-то общим навыкам. И потом эти общие навыки мы применяем для других задач. То есть, у них на самом деле нет каких-то общих навыков. То есть, мы учимся не делать какую-то задачу, а мы учимся каким-то общим навыком. нет трансфера, есть просто абстрагирование и обучение навыкам. Вот это первое. Второе, вот ты говоришь, пусть будет два агента, которые просто с нуля очень быстро учатся любой задачей, не обязательно с трансферингом, но это же означает, что у него есть какие-то прайеры на входе, он должен что-то уметь на входе, мы не можем взять абсолютно, и научиться за тысячу проходов. Ну, это уже и есть, получается, шаги. То есть, если мы как-то заложили эти прайеры, в этом же самая большая проблема сейчас – найти такие прайеры, которые нам позволят с минимальным доучиванием решать задачи. Об этом, кстати, было. Почему эти прайеры? Почему Freezing Challenge у Шале? Он тоже был об этих самых навыках. нужно иметь уже заранее. 

S09 [01:45:38]  : А мы этим прайером не можем учиться? То есть у нас самообучение этим прайером не может являться частью задачи? 

S03 [01:45:46]  : Почему нет, можем. Попробуй придумать такую задачу, которая сделает это. 

S09 [01:45:54]  : ну вот с моей точки зрения вот задачи openjim они удовлетворяют этому критерию но сказать ладно значит сейчас не будем углубляться в дискуссию потому что появился здесь еще комментарий во первых я увидел руку наконец александра александр у вас рука еще держится да пожалуйста 

S02 [01:46:17]  : Спасибо за доклад. Мне понравился стиль языка, который выбрал докладчик для того, чтобы представить нам то, как он размышляет про искусственный интеллект. Я имею в виду, что мы выбрали язык схемотехники, а не низового программного кода, как любят, наверное, программисты, которые вот через программный код понимают, про что идет разговор. Это первое. Второе. Насколько я понимаю, докладчик исходит из того, что агент, кем бы он ни был, например, ребенок родившийся, вот он говорит, что это маленький ребенок, один год, это тот, который обучен запоминать. То есть, если вот ребенок или какая-то любая другая организованность материи не обучена запоминать, то это не агент. 

S03 [01:47:26]  : Он не сможет выполнять ничего, никакие когнитивные функции не будут работать. 

S02 [01:47:30]  : Вот я и говорю, что вы, скорее всего, и я так тоже считаю, я с этим согласен. То есть, когда мы тихим во что-то и говорим, это агент, мы первое, что говорим, это тот, который обычно запоминает. Вот стол – это не агент. Самолет – это не агент. 

S10 [01:47:49]  : Да. 

S02 [01:47:50]  : Согласен. Вот. И поэтому вы начали с того, что вы говорите, вот у меня есть агент, и значит, я его должен сделать таким, чтобы он был обучен запоминать дальше вопрос запоминать что ну начиная с самых простых вещей просто какие-то там камень палка там собачка и так далее до очень сложных вещей таких как например как запомнить ассоциацию совсем одно дело запомнить и глядя вот на камень да и другое дело запомнить ассоциацию наверно это Самые механизмы запоминания могут быть очень сильно отличаться. Но надо начинать с простого. И это нормально. Итак. Ребенок рождается не обученный запоминанию. В процессе общения со своим родителем, со взрослым, он обучается запоминанию. и в этом смысле становится неким агентом. Если у этого агента, кем бы он ни был, опять же, ребенок или искусственный какой-то интеллект, можем ли мы говорить, что обученность чего-то запоминать, даже вот такие сложные вещи, как ассоциации, говорит о том, что у этого агента возник интеллект. Насколько я понимаю ваш доклад, и я тоже с этим согласен, что интеллект не сводится только к умению запоминать. Это одна из низовых необходимых когнитивных процессов, функций, которые Создать только базу для возникновения интеллекта, но не более того. Интеллект возникает тогда, когда агент, ну вот тут развилка, либо, как Пивоваров говорит, агент становится субъектом, В каком смысле он пытается спросить у других? И у вас он спрашивал. Вы давали свой ответ, я вот сейчас дам свой ответ. В том смысле, что если этот агент обучается или обучен самостоятельно принимать решения, то он и есть субъект. У него возникает субъектность. Это первый ответ. А второй ответ про возникновение интеллекта у этого агента, который уже научился запоминать. Это мой ответ. Ответ о том, что если агент обучен строить знания новые, то вот это на самом деле в этот момент этот агент, у него возникает интеллект. Просто играть и лучше играть, чем человек в какие-то игры, это еще, когда вы говорили, спорили с Антоном о различных представлениях интеллектуальности. Даже если некоторый искусственный интеллект научился играть быстрее и лучше в какую-то игру, чем человек, это еще не признак того, что он обладает интеллектом. Я тоже с вами согласен, если вы подтвердите. подтверждаю. пока еще не создан такой интеллект ну человек вот единственный пока такой агент который обладает таким интеллектом который научился тут можно говорить в процессе эволюции или еще как или это какое-то божественное провидение кто как или какой-то мировой космический разум ему такую способность передал это кто как хочет пускай Но, как факт, надо признать, что человек научился строить знания. И это основной признак и свойство наличия у него интеллекта. Как только мы научим искусственный интеллект самостоятельно строить знания, любые знания, причинно-следственные, либо какие угодно, то только в тот момент мы скажем, что мы создали агента, обладающего интеллектом. 

S05 [01:52:21]  : вот такой комментарий спасибо спасибо александр появилось два комментария у игоря пивоварова а потом у сергея терехова да но я уча слушал александра и понял что ну так сказать там что что что мне один такой комментарий на обе на обе вещи Смотрите, у меня ощущение, что у нас очень много, ну как бы в нашем маленьком сообществе, я думаю, что и во всех остальных тоже очень много дискуссий и непониманий и пустых затрат времени на попытки, значит, ну там совместно определиться с некоторыми словами и понятиями. И в частности вот здесь сейчас тоже говорили про то, что вот эта модель AGI она или не AGI, а OpenGM это то или не то. И у меня на эту тему первый комментарий вот какой. А можно я экран расшарю на одну минутку, Антон? 

S09 [01:53:23]  : Конечно, конечно, вроде не запрещено. 

S05 [01:53:25]  : Да, значит, вот если видите, я сходу нашел картинку в интернете. Вы наверняка ее видели, но я не уверен, что она там последняя, но просто то, что нашлось по-быстрому. Виден мой экран, да? Да-да. Это картинка, которую любит показывать Константин Владимирович Анохин в своих докладах. когда говорит про там методы исследования мозга я думаю что большинство из вас ее видела там есть условно по горизонтали время по вертикали некоторые размеры условно в условных единицах и смысл ее в том что допустим там ну там верхний левый если взять я не знаю виден а мышка моя видна наверное допустим если мы там используем электроэнцефалограмму то она работает на уровне всего мозга, на маленьких диапазонах, но как бы сразу на всем. Мы не можем один нейрон, допустим, померить. А, например, если мы возьмем микроскоп, то мы можем очень маленькие какие-то вещи померить, но очень грубо с точки зрения, допустим, времени и пространства. Или, допустим, если у нас есть какая-нибудь FMRT, то она в течение минут активность мозга меряет, и можно более-менее, даже на уровне маленьких властей, миллиметровых мерить. Я к чему эту карту показываю? Не к тому, что мы говорим про методы мозга, а про то, что я вообще… Если мы с вами будем использовать термин «методы исследования мозга», то каждый из нас будет думать про что-то свое. И мы, блин, один может иметь в виду микроскоп, а другой имеет в виду электроэнцефалограмму, а третий там вообще просверлить мозги и посмотреть что там глазами. И мы всегда оказываемся в таком очень спорном положении. Поэтому я думаю, что нам бы напрячься совместно и сделать какую-нибудь ну допустим карту, может быть она будет вот такая плоская, может быть что-то такое, где мы попробуем ну хотя бы изложить свои соображения, что такое, что мы имеем ввиду под этим самым AGI. И тогда докладчик, который будет, если Дмитрий вы вспомните, то мы с вами очень долго ваш доклад обсуждали на OpenTalks.ai потому что когда вы хотели сразу рассказывать про свою систему тестирования, мне казалось, люди не поймут. Я вас попросил сперва нарисовать на что-то вроде вот этой схемы, условно, чтобы дать более общую картинку, а потом сказать, а я занимаюсь вот этим вот кусочком, вот этим как бы лидер бордо вот здесь, конкретно языковая схема. Ну вы как-то это сделали, я остался недоволен, но неважно, идеал недостижим. потому что я, честно говоря, сам дня три думал, как бы это сделать, и так и не придумал, ну и я забросил. Но я вот к чему. Если бы каждый из нас, рассказывая про свою модель, начинал бы доклад с некоторой более общей картины, типа этой, допустим, условно, как некие карты айджайности, если хотите, и говорил, ну как бы это все хорошо, а я вот занимаюсь вот этим, на самом деле, кусочком в ней, я понимаю и признаю, что есть много других вещей, но как бы я занимаюсь вот этим, то у нас половина вопросов отпала, половина критики бы отпала там, а вот ваша модель не работает в этом, а вот ваша модель не делает того. Да я и сам, блин, понимаю хорошо, но как бы мы же не в силах охватить необъятное. Но и для самого человека тоже полезно определиться, где и что он делает. Мой, собственно, первый комментарий про это. Я думаю, что нам бы надо совместными усилиями как-то, в общем, подумать над таким... потому что вот допустим модель который дмитрий рассказывает но его подход мне в целом нравится и она там у нее есть некие граница применимости чем еще вот эта схема нравится тем что здесь ясно видно что у каждой модели есть диапазон применимости, понимаете? У любой модели он есть, и поэтому бессмысленно про нее считать, что вот, ах, это он, это AGI в полном смысле. Ну нет, конечно, но какой-то кусочек он закрывает. Это, в общем, первый комментарий-предложение подумать и в общем давайте мы как бы эту вещь там над ней подумаем а второй комментарий так я расшарить могу уже убрать второй комментарий вот какой по поводу субъектности мне эта тема очень ну как бы нравится она очень интересная она очень такая глубокая И вот там Дмитрий меня спросил, а рассказал бы я о том, что такое. Я могу на это ответить, но в два слова это не впишется, к сожалению. Я сейчас на эту тему пишу, уже даже написал, вообще некий большой текст, потому как одно из моих открытий, благодаря большому количеству общений с разными людьми за последнее время, что в двух словах очень многие вещи сказать невозможно. Ты должен сперва задать куда больший контекст, а потом как бы в этом контексте уже очертить то, что ты хочешь, и тогда тебя лучше понимают. А иначе мы как бы... Но я вот к чему. Я понял сейчас, слушая Дмитрия, его ответ на вопрос, в чем-то как бы, Дмитрий, я с вами согласен. То есть вы немножко инструментально определяете эту субъектность, но Как бы можно было поспорить, но не буду спорить, потому что это определение тоже для некоторых целей работает. Я знаете, я вот сейчас просто подумал, слушая Александра, который дал тоже там некоторое свое определение, ну не определение, а понимание, что на самом деле субъектность это некоторое тоже, если хотите, ну не карта, а это некоторое шкала что ли в общем это некоторые уровни и вот я так ну над ними тоже надо подумать может быть даже поговорить о них на каком-то отдельном семинарчике в общем это несколько уровней внутренних для меня субъектности это ну другая вещь куда более сложная и комплексная с другой стороны ну про нее сложно сказать про другого человека или про другое существо что оно обладает этой субъектностью а инструментальные вещи как бы некоторые можно сказать в общем я к тому что это субъектность такая провокационная история я думаю что реалистично она такая про нее можно говорить на разных слоях не знаю чего понимание реализации в общем по человека она как бы очень полная и и там я не знаю вот ну как бы включающиеся там наше осознание и самостоятельную постановку целей и нарушение всех правил которые вообще как бы возможны потому что если мы так как бы если я так хочу то понимаю что это нужно и заканчивая там ну какими-то очень низшими проявлениями этой субъектности. Еще к тому, что это интересная тема, я думаю, что ее сложно определить, кроме как опять-таки в некотором контексте и выбрав какой-то диапазон. И на эту тему надо просто отдельно подумать или отдельно поговорить. Вот такой второй комментарий. 

S03 [02:01:08]  : У меня, Игорь, сразу вопрос к вашему первому комментарию. А сколько измерений будет в этой карте? Потому что двух измерений, мне кажется, явно не хватит. Там всякие восходящие парадигмы, восходящие... Символьные, нейросимвольные и так далее. То есть, если мы начнем набрасывать, то... А я сейчас не про архитектуру. 

S05 [02:01:26]  : Вот вы меня сразу слышите, Дмитрий, очень как бы... То есть, вы такой очень инженерно подходите. Правильно. Я не про архитектуру, я про... Я, скорее, знаете, про проявление. Вот мы смотрим на модель. Вот смотрим мы на вашу модель, да, и для кого-то она и джайная, А для кого-то вот как бы она недостаточно эйджайная, блин. И вот как бы люди говорят, а вот в Open Gym она у вас не играет, а вот она, значит, недостаточно эйджайная. Так вот я, вот именно вот эти проявления, то, что мы как бы считаем, если хотите, этой эйджайностью, ну условно, допустим, там, какое-то поведение, демонстрирует ли она какое-то поведение в любых средах или только там виртуальных, она там, Я не знаю, честно говоря, сколько будет. Я вообще не знаю, будет ли это картой. Может быть, это еще как-то. Я просто к тому, что пока мы рассуждаем общим термином ИДЖАЙ, большой коробкой, в которой можно положить все, что угодно. Более того, каждый в нее пихает все свои там страхи, чаяния, надежды, воображения. У кого фантазии на что хватает, вот как бы это ИДЖАЙ. Но мы до тех пор обречены про каждого говорить, что это не модель, а полная фигня. Что он в этом понимает? Да ничего. У меня нет ответа. Это скорее просто рефлексия того, что надо бы подумать на эту тему. 

S09 [02:02:59]  : Соглашусь с Игорем. К сожалению, у нас была уже попытка определиться с терминами. Но она, кстати, есть. Периодически новый человек пытается добавить туда колонку. Но, правда, существенного вклада пока после Бориса Новикова нет. Но, по крайней мере, есть с чем работать. Но с картой труднее, потому что в таблице каждый свою систему координат рисует. А вашу карту, чтобы еще все с ней согласились, каждый будет пытаться нарисовать свое место в своей собственной карте. И у каждого действительно будут свои измерения. Потому что даже когда вы говорили про изменения, я сразу стал пытаться примерить, какие мы будем измерения вкладывать. И у меня возник тот же самый вопрос, что и у Дмитрия. Хотя, наверное, под измерениями я имел в виду немножко другое. Но это просто комментарий. А так я согласен. Сергей Терехов еще хотел высказаться. 

S07 [02:03:58]  : А потом Илья... Просто Игорь задал некий масштаб сразу такой вот, да, и сейчас действительно там не хочется там мельчить. Но фактически что в отношении этой карты можно сказать? я так понимаю, что надо создавать онтологию, вообще-то говоря, то есть надо подойти к этому процессу как к научному процессу, чтобы это была не аддитивная просто сумма каких-то мнений, а это была некая онтологическая структура, и подходить к ней вот с этой научной позиции, тогда с ней можно и двигаться, и понять, куда она развивается, какие сущности там возникли. Александр, спасибо. Вот. А второй момент вот какой. В отношении transfer learning и AIG и других методов, которые возникают, таких вот подходов, которые тут есть. Но дело вот в чем. Дело в том, что в истории известны ситуации, когда человечество для того, чтобы обеспечить некую управляемость чего-то большого, того, чего начало разрастаться, создавала некоторый там понятный слой повидла, в котором могли плавать большое количество разных людей, доходя до этого повидла и спокойно в нем работая. Пример такого повидла это, например, бухгалтерия. Она, будучи созданной и снабженной Excel, привела к тому, что напрочь исчезло понятие финансового планирования, понимание финансов, их роли в организации общественной и так далее. Потому что бухгалтерия, она вот это экранировала. Вот у нас сейчас, мы с вами в нашей области присутствуем в двух таких экранах. Первый экран называется Kaggle, а второй экран называется iGem. Это два повидла, созданные для того, чтобы большое количество людей, которые непонятно какой тенденцией, то ли массовым каким-то психозом, то ли там чего-то, то ли, например, я там после школы могу сразу пойти там без всякого высшего образования уже там что-то работать, создала способ, где ты можешь как бы квази реализоваться. Более того, очень скоро появятся, если не появились, я не слежу, Но если появятся какие-то тулбоксы специально, чтобы играть в игры, которые там вот в этом айджиме. Вы можете, каждый школьник может привинтить свою ручку и уже, так сказать, играть. И то же самое Cagle. Мы уже слышим на конференциях, в том числе, Игорь, и на твоей конференции, люди, значит, выступают прямо со сцены, которые говорят. Наша задача превратить вашу реальную задачу в задачу Cagle, потому что в этом случае мы знаем, какие, так сказать, питоны с какими другими питонами соединять и можем дальше двигаться. Отношение к Open Gym, я не против задачников, задачники это очень хорошо, но он не дает ту самую планку, ради которой имеет смысл двигаться. Я хотел бы сказать, куда двигаться, но Игорь тут меня нассалил, сказал, что сначала определимся с энтологией, а потом поймем, куда двигаться. Но вот трансверление, это принципиальная вещь. Трансфер Ленин нужен, если предположить, что вот в этой карте, которая Левантология, которая еще не создана, присутствует некая масштабная цель, например, сделать систему, которая может полететь на Марс и там 10 лет самоуправляться, разбираться. А лучше не на Марс, а куда-нибудь дальше. То мы обязательно должны вкладывать в такую систему ее возможность адаптации на новом масштабном уровне. Ну вот, например, мы берем две модели когнитивных карт в стиле Джуди Пирла, вот эти структурные модели. Пусть одна из них маленькая, она описывает контрафактическую ситуацию, какие-то дополнительные смешивающие переменные и какую-то логическую ситуацию. И модель научается оперировать с данными, оперировать с ситуацией, касающейся вот этой когнитивной карты. Теперь мы берем другую когнитивную карту, а потом мы берем их объединение, а потом мы строим систему такую, чтобы она легко адаптировалась, когда эта штука начинает объединяться, начинает расти, возникает какие-то кросс-связи. Вот если мы такую планку зададим в росте нашего искусственного интеллекта, то тогда у нас есть ощущение того, что то, что мы делаем, оно будет действительно общего назначения. General. То есть она будет способна двигаться дальше интеллектуально по этому пути. А если мы в горизонтальной плоскости движемся, увеличивая количество стрелялок, увеличивая количество заделок бока и собирания этих самых, то это торможение этого процесса. Вот в этом смысле негативная роль Open AI Gym состоит в том, что это определенный слой повидла. в котором предположительно должны застрять большое количество людей массовость там и так далее на основе ну дальше я уже не буду повторяться это вот моя точка зрения но общий месяц это вот я согласен здесь соберем надо сначала действительно понять а что же мы по-крупному антологически как мы как ученые с каким объектом мы имеем дело я почему вот этот момент еще хочу прежде чем окончательно закончить хочу отметить такую вещь Вот есть, например, такая замечательная ассоциация, Ассоциация Искусственного Интеллекта, Российская Ассоциация Искусственного Интеллекта. Я вот в нашем подписке на Google, который Антон организовал, спасибо ему большое, я туда иногда буду бросать новости от Ассоциации Искусственного Интеллекта. Она борется за чистоту определения понятия искусственный интеллект. Рассматривает это как раздел определенной математики и строгости в определенном смысле. Это научная дисциплина, имеющая строгое определение. Если мы говорим, что мы занимаемся каким-то следующим слоем, то мы должны такой же научный уровень предложить. Иначе мы будем любители, которые просто собрались пообщаться. Вот это, собственно, в поддержку того, что предлагает Игорь, только вот так, как я это вижу. Спасибо огромное. 

S09 [02:09:51]  : Сергей, спасибо. Илья? Илья, ваша рука еще в силе? Да-да, слышно меня? Да, слышно, пожалуйста. 

S01 [02:10:07]  : более технические вопросы к митрю я вот послушал весь доклад не заинтересовала там одна схема то есть он включит экран где он показывал схему я наглядно на примере посмотреть еще раз нет ритуал вы здесь готова там вот схема где когда где память забывается и добавляется ниже ниже ниже ниже ниже вот это где красный и да и синий вот это меня заинтересовало вот мне вот стало интересно как ее можно спрограммировать на языке потому что ну и сего доклада я понимаю тут много воды как бы ну я вот например хочу сделать именно вот эту часть вот этот кусочек например и хочу более понять как она работает именно в технической части. я не обязательно, что может быть вы ответите или может кто другой ответит. например этот вопрос может быть ко всем. кто как бы реализовал эту схему? вот именно каким образом? 

S09 [02:11:26]  : Вначале можно попробовать посмотреть, как реализовал Дмитрий, он же ссылку на код дал. 

S03 [02:11:31]  : В целом да, я могу там даже индивидуально прокомментировать, в каком классе находится. Если реализовал, то отлично будет. Да, конечно, это все реализовано, но реальные энкодеры, которые у нас есть, узнавание символов, фонем и так далее, они, конечно, посложнее, чем эта схема. 

S01 [02:11:56]  : схема достаточно интересная. мне чем она понравилась? тут идут входные данные. он принимает эти данные и в зависимости от принятых данных он забывает не другие данные. это довольно интересный механизм. 

S03 [02:12:11]  : он отсекает менее абстрактные вещи в пользу более абстрактных. 

S01 [02:12:18]  : вот мне интересно, как это можно реализовать в плане математики. если у вас реализовано, можете показать. 

S03 [02:12:26]  : да-да, я покажу. но я думаю, что это уже потом за рамками. ну то есть в коде я же не буду сейчас комментировать код. 

S01 [02:12:36]  : попозже покажете. и, например, можете объяснить технически это более детально. 

S03 [02:12:45]  : Ну, сейчас, что ли, прямо? Или что? Всем остальным? 

S01 [02:12:48]  : Если можете, конечно. Если не можете, то ладно. 

S09 [02:12:50]  : Можно сначала короткий вопрос? У нас еще есть 15 минут для объяснения, но вот просьба короткий вопрос ответить. От Евгения Бабарыкина. Энкодеры и декодеры, то что вы используете, это понятия функциональные или есть что-то общее с энкодером и декодером в смысле нейронной сети, в смысле трансформера? 

S03 [02:13:19]  : С функциональной с точки зрения да, и те и другие сжимают информацию, то есть имея очень высокоразмерный вход они в итоге сжимают это до низкоразмерного выхода. То же самое происходит у меня, но механика, конечно, совершенно разная, что в нейросетях и что у меня. Да, можно назвать это в каком-то смысле сверткой. 

S09 [02:13:49]  : Хорошо, ну если других вопросов нет, у вас есть минут 10-15 на подобное объяснение того, как это работает на предыдущих. 

S03 [02:13:59]  : То есть все-таки нужно объяснить, да? Ну давайте, ну смотрите, значит, если мы говорим про вообще сам механизм, у нас есть вот эти вот области, да, вот эти кружочки, это функционально это объекты, да, в питоне. И у каждого такого объекта есть набор связей между ними, ну вот, собственно, стрелочки, и эти связи обозначают. И у нас вся деятельность развернута в разрезе таймфреймов, то есть у нас на нулевом таймфрейме ничего нет, да, просто есть вход, а потом, соответственно, первая finema поступает на первую область, да. Дальше мы проверяем, по связям, к каким следующим областям она должна передать свое сообщение. То есть проверяем это уже во втором таймфрейме. И, соответственно, если она должна принести это в кружочек ниже, соответственно, мы это сообщение туда передаем. Ну и так далее. Там, конечно, очень много правил, на самом деле, о том, как передача осуществляется, когда гасится, когда не гасится и так далее. Но в целом это просто цикл, который итерируется по таймфреймам, и в каждой итерации мы проверяем условия того, какое сейчас сообщение нужно принять от всех других областей, какое сообщение, скажем так, зажечь в этой текущей конкретной области. То есть она каждую область опрашивает, Собственно, определяется, чего сейчас эта область будет делать. В смысле, весь цикл. Примерно так, вкратце. Надеюсь, стало понятнее. 

S01 [02:15:39]  : Вот еще интересно, а в обратной последовательности он также работает? Он обратно может также декодировать данные? 

S03 [02:15:48]  : Да, может. Это схема, которая у меня там где-то в… Вот здесь у меня обратный декодинг, то есть то же самое здесь видно. Две толстые стрелки, которые идут влево и влево-вверх. Это, собственно, процесс декодинга получается. Как-то так. 

S09 [02:16:25]  : Спасибо. 

S01 [02:16:26]  : Да, спасибо. 

S09 [02:16:28]  : Коллеги, есть еще вопросы? Комментарии? Нет? Ну тогда спасибо большое докладчику и слушателям. И до новых встреч. Всем до свидания. Дмитрий, спасибо огромное. Счастливо. 

S03 [02:16:48]  : Счастливо. 









https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
