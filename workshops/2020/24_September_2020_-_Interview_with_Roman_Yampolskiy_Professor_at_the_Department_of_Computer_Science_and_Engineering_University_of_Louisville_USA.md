## 24 сентября 2020 - Интервью с Романом Ямпольским, профессором факультета вычислительной техники и информатики Университета Луисвилля, США — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/pYO8YMBk_xM/hqdefault.jpg)](https://youtu.be/pYO8YMBk_xM)

Суммаризация семинара:

Во время семинара обсуждались различные аспекты искусственного интеллекта (ИИ), включая возможности и ограничения технологии. Участники диалога затронули вопросы о том, как ИИ может имитировать человеческое мышление, о различиях между нейронными сетями и человеческим мозгом, а также о сложностях понимания работы нейронных сетей.

Задачи и возможности ИИ:

- Имитация мышления: Искусственный интеллект может имитировать человеческое мышление, но это не всегда воспроизводит человеческие процессы, и понимание того, как это происходит, может быть ограничено.
- Сравнение нейронных сетей: Нейронные сети, используемые в ИИ, могут сильно отличаться от нейронных сетей в человеческом мозге.
- Символическое мышление: ИИ также может использовать символьные методы, такие как математика, для решения задач.

Проблемы и ограничения:

- Понимание нейронных сетей: Несмотря на высокие результаты, работа нейронных сетей и их решения могут быть непонятны человеку, и невозможно полностью проверить и доказать их правильность.
- Разделение методов: Нейронные сети и символические методы (классический АИ) имеют различия в понимании и проверке работы системы.
- Совместное использование методов: Считается, что совмещение нейронных сетей и символьных методов может привести к лучшим результатам.

Перспективы создания общего и сильного искусственного интеллекта:

- Общие и сильные интеллекты: Понятия общего (general) и сильного (strong) искусственного интеллекта могут быть синонимами, но один из профессоров разграничивает их, выделяя универсальный интеллект, который может работать во всем возможном.
- Ограничения генерального интеллекта: Генеральный интеллект может быть ограничен в определённой области, как и человеческий интеллект.
- Развитие ИИ и предсказания: В прошлом было много оптимистичных предсказаний по ИИ, и сейчас они кажутся реалистичными, учитывая прогресс и финансирование исследований.

Вопросы безопасности и предотвращения негативных последствий:

- Свобода воли и ограничения: Существует опасение, что сильный ИИ в какой-то момент начнёт устанавливать свои правила и может обойти любые ограничения.
- Философские и этические вопросы: Вопросы о том, какие должны быть ценности системы ИИ, и о возможности смерти искусственного интеллекта (то есть прекращения его способности обучаться и развиваться).

Технологические вопросы и перспективы:

- Модели для сильного ИИ: Разные направления и идеи исследования моделей для создания сильного ИИ.
- Гибридные системы: Предложение использования гибридных систем с нейронными сетями и экспертными системами на уровне символов для достижения лучших результатов.





S05 [00:00:01]  : Добрый день, уважаемые коллеги. Точнее, кому-то добрый день, кому-то добрый вечер, кому-то доброе утро. Сегодня у нас в гостях доктор и профессор Роман Ямпольский. Роман, я представлю наше сообщество. Небольшое, но дружное сообщество возникло сначала в Фейсбуке около пяти лет назад. Где-то года полтора назад оно также распространило свое влияние на Телеграм. А примерно с середины лета у нас еженедельные онлайн мероприятия. где мы тему сильного искусственного интеллекта и AGI рассматриваем во всех возможных аспектах, начиная с прикладного, включая технологические, экзистенциальные, терминологические. Ну и вот сегодня у нас первый раз, когда мы экзистенциальные вопросы совмещаем с вопросами именно безопасности. Значит, у нас тут небольшой, так сказать, актив наиболее инициативных и заинтересованных в онлайн общении товарищей сегодня собрался, но обычно видеозапись смотрят от двухсот до трехсот, иногда больше человек. Ну, а вообще все сообщество, наверное, уже по тысяче человек. Вот, но Роман Ямпольский – это известный специалист в области компьютер-сайта Artificial Intelligence и Artificial Intelligence Security в разных аспектах, насколько я понимаю, в Соединенных Штатах. Вот, Роман, может быть, там вы пару слов про себя скажете, чтобы было понятно, какие еще вопросы можно вам задать. Вот. Ну и, значит, тоже по регламенту подскажите, как вам будет удобнее. Либо вы сами, вот из тех вопросов, которые есть, сами отбираете в том порядке, в котором вам это кажется будет удобно и комфортнее. Либо я буду задавать вопросы в том порядке, в каком у них рейтинг определился в ходе нашего онлайн голосования. Роман, вам слово, пожалуйста. 

S03 [00:02:04]  : Спасибо. Там, я вижу, люди жалуются, не слышно некоторым. Это у вас или у них? Я не знаю. Надеюсь, меня слышно? Да. Я вас слышу, в любом случае. Спасибо большое за приглашение. Это, по-моему, моё третье интервью на русском, так что очень приятно, но в то же время я хочу напомнить, что я Плохо знаю технические термины на русском. Я буду просто периодически тупо вставлять английские слова, где не смогу найти русский эквивалент. Обо мне я, как вы сказали, преподаю в университете города Луивиль. Это инженерная программа. занимаемся исследованиями в разных областях. Я лично занимаюсь темой безопасности систем и стараюсь концентрироваться на именно AGI, более продвинутым интеллектом, не просто на уровне тех систем, что есть сегодня, но стараться предугадать, что может быть в ближайшем будущем и какие шаги надо предпринять, чтобы результат был более положительным для нас, для всех. Вопросы, если вы хотите контролировать, что вы задаете, я с удовольствием отвечу на любой порядок, который вас устроит. Я посмотрел вопросы, там в принципе все замечательно, но несколько вопросов про индустрию, какие языки, какие модели. Я не работаю в индустрии, поэтому навряд ли я знаю что-то, чего Google вам не подскажет даже лучше меня. Так что такие вопросы я просто не в состоянии ответить. А про Академию, про мои исследования я с удовольствием поделюсь всем, что знаю. 

S05 [00:04:01]  : Да, Роман, спасибо. Для тех, кто не слышит, я напишу потом, что потом будет запись. Я так понимаю, что большинство слышит, да? Кто не слышит на видео, поднимите руки, пожалуйста. Те, кто есть на видео, слышат. Хорошо, тогда давайте вопросы будем задавать вот в порядке именно, как определила аудитория. Собственно, главный вопрос, о чем мы говорим. То есть вот разные люди по-разному понимают и по-разному интерпретируют, и готовы даже спорить по этому поводу, что такое интеллект, что такое разум. сознание, самосознание, то есть intelligence, mind, consciousness, subconsciousness, self-consciousness. Вот в вашей картине мира как эти термины соотносятся и что за ними стоит? Пожалуйста. 

S03 [00:04:49]  : Это все очень интересные темы, я пытаюсь изучать несколько из них. Именно про интеллект мне нравится статья Шейн Лайга, коллеги описали это на уровне добиваться результатов в любой ситуации. То есть вот ты на Марсе, ты в банке, неважно где, ты выиграешь. Если ты там инвестируешь, ты, значит, можешь понять, как сделать максимальное количество денег. Если ты охотишься поймать животное. Неважно, какой будет ситуация, важно, что ты сможешь победить других агентов в этой ситуации и добиться своих результатов. То есть такой вот general аспект интеллекта, то есть не то что там только в шахматы играет или только там машину боит, а вот именно не важно что завтра подкинут, быстро научиться как с этим справляться. Такие вещи как самосознание и чувство это Насколько я понимаю, необязательные составные части этого, но есть, конечно, интерес понять, как это работает, чтобы лучше понять, как человек устроен. Есть пара статей у меня, где я говорю именно о том, как вот это вот проявление каких-то внутренних чувство боли, чувство удовольствия появляется как бы в результате as a side effect, как бы посторонний эффект именно вот подсчета каких-то правильных решений в любой среде. Может быть, даже это невозможно избежать, если достаточно умная система, она рано или поздно начнет проявлять подобные внутренние явления. Но, опять же, это очень трудно замерить и трудно понять, если это на самом деле происходит с сегодняшними системами. 

S05 [00:06:59]  : Спасибо. 

S03 [00:07:00]  : Да, я вижу, там спрашивают. Да, это статья Шейнлега, по-моему, 2007 года. Там у них идёт описание, может быть, 50 разных других статей, как другие представляют, что такое интеллигенция. И они, значит, совмещают всё это в один, в один очень короткий результат. 

S05 [00:07:27]  : Спасибо, Роман. А вот такой вопрос. Хорошо. Мы делаем искусственный интеллект. Есть два подхода. Либо мы дублируем функцию человеческого мозга, пытаясь понять, как она устроена, либо мы не сильно заморачиваемся, а пытаемся все-таки моделировать когнитивные процессы и строить свои решения на основе этого. Вам какой подход ближе? Как вы на это смотрите? 

S03 [00:07:55]  : Оба хороши по-своему. Я думаю, оба пригодятся. Какой-то гибрид этих двух методов и будет самым лучшим. На сегодняшний день, по-моему, как-то копировать то, что делает человеческий мозг, получается лучше, даже когда мы не понимаем, как на самом деле все работает и почему. Если достаточно данных, если достаточно скорости компьютера, то результаты появляются очень впечатляющие. обходит человека, но как бы и в человеческом мозге мы замечаем, значит, есть какое-то подсознание, где там определение, допустим, я узнаю лица, не думая об этом, я просто вижу там нейронная сеть, посчитала, это Вася. В то же время есть какое-то символическое мышление, математика, и оба эти метода полезны. Во-первых, с нейронными системами проблема, что мы не понимаем, что они делают и как это происходит. То есть даже если там хороший результат, мы совершенно не можем доказать, что система правильно работает и невозможно проверить, протестировать правильно. То есть она работает на тех примерах, которые мы ей даем, но мы не можем доказать, что она сработает в будущем на каком-то новом примере. С символами классическим AI в этом плане немного легче, там можно доказывать многое, проверять, как система работает, и мы понимаем довольно хорошо, как она устроена, если какой-то сбой, можно лучше с этим как-то бороться. Но, опять же, мне кажется, и то, и то само по себе недостаточно. Совмещение этих двух методов, скорее всего, и приведет к лучшим результатам. 

S05 [00:09:37]  : Роман, а у меня тогда сразу два вопроса возникают ещё дополнительных. Вот смотрите, у нас вроде хорошо получается имитировать человеческое мышление, да, лучше, чем симульное. Но насколько вот то, как мы имитируем это, с вашей точки зрения, С одной стороны, действительно напоминает человеческую деятельность. Есть такой тезис, что то, что мы называем нейронными сетями, на самом деле, кроме того, что там есть соединение между вершинами графа, К нейронным сетям имеет мало отношения. У нас есть нейронные сети, но они мало похожи на нейронные сети в коре человеческого мозга. А вторая точка зрения, вот у нас выступают коллеги, здесь на одном из семинаров из Питера, и то, что они рассказывают, например, с их точки зрения, То есть, речь идет не о... Мозг работает не на уровне конъектома, не на уровне соединений между нейронами, а на гораздо более тонких вещах, связанных с рецепторными кластерами, и там порядок емкости и сложности существенно больше, чем исходит, исходя из чисто нейронной модели человеческого мозга. Вот как бы с этих двух точек зрения. Насколько мы понимаем, как работает человеческий мозг и насколько искусственные нейронные сети действительно имитируют человеческие нейронные сети? 

S03 [00:11:15]  : Это прекрасный вопрос. Два вопроса. Мы действительно много еще не понимаем, но ту часть, что мы поняли, уже достаточно, чтобы получить прекрасные результаты во многих областях лучше, чем человеческий уровень. То есть это говорит о том, что все-таки что-то там совпадает. Это не просто какая-то совершенно несвязанная вещь, которую мы тоже назвали нейронная сеть случайно. Есть очень много общего, и для меня лучшее доказательство – это ошибки, которые эти системы совершают. Они ошибаются так же, как люди, в таких же вариантах. оптические иллюзии и вот такого вида всякие вещи, которые именно вот человеческий мозг допускает как ошибку, они повторяются в искусственных нейронных сетях тоже. То есть если там вообще нет связи, это было бы очень интересно, вот почему там у людей, у животных это так, и у машин также, если это совершенно несвязанные модели, несвязанные процессы. То есть я думаю, Ну, может, мы знаем, не знаю, там 50%, как на самом деле это все работает, но там настолько все классно работает, что даже если люди будут 50% скопировать чуть-чуть, уже результаты отличные. Будет только лучше, чем больше мы поймем из neuroscience. 

S05 [00:12:30]  : А тогда вот еще такой вопрос насчет черного ящика. Значит, сейчас становится все более популярным и более востребованным так называемый explainable AI. И есть тут две точки зрения. Есть как бы поверхностное, Для понимания эксплена была я, когда мы получаем результат с помощью нейронной сети, а потом нам надо это как-то объяснить конечному пользователю. И тут хорошие все средства, вплоть до того, что рядом с нейросетью мы ставим какую-нибудь попростенькую case-based reasoning system. которая дает иллюзию объяснения. А есть подход, который наши коллеги, веце Евгения Евгеньевича Витяева, разрабатывают, когда мы пытаемся построить архитектуру, изначально предполагающую получение данных в объяснимом виде. То есть, у нас получается не просто объяснимый процесс inference, у нас и сама knowledge base, сама model, которую мы получили в результате обучения, является интерпретируемой, и мы можем не только объяснять полученные решения, но и вообще валидировать саму структуру знаний. которую мы получаем. Но, с другой стороны, есть позиция, что это вообще невозможно, что сам человеческий мозг вовсе не explainable, и что сами люди не всегда могут объяснить решения, которые принимают, хотя принимают их правильно. Как вы к этому относитесь? 

S03 [00:13:51]  : Ну, действительно, у меня есть статья на эту тему, и там я именно говорю о ограничениях, на что можно объяснить, что нельзя. Unexplainability and incomprehensibility of AI. И, действительно, первый вариант – это ограничить систему только такими решениями, которые она сможет объяснить пользователям. Это работает, это прекрасно, но мы ограничиваем, что система может подумать на самом деле. Вот у неё рубежи, за это нельзя выходить. Если мы говорим «система без ограничений, думай что хочешь, как хочешь», если там миллион параметров, миллиард весов между нейронами, то любое объяснение, которое система даст, это какое-то упрощение. Вот мы говорим с детьми, ребёнок спрашивает «откуда дети берутся?», про генетику сейчас не буду, там в капусте нашел, в магазине купил. То есть ты получаешь какое-то упрощение, и чем сложнее процесс, чем сложнее настоящий ответ, тем больше разница между действительно ответом и то, что человек может услышать, и еще больше, что он может понять. То есть можно ждать объяснения там на уровне квантовой физики, но 99% не поймут ни слова из-за этого. надо еще упростить вот это упрощение. Получается, что на самом деле, если система действительно продвинутая в этом плане, мы не можем понять, что она делает. 

S05 [00:15:15]  : А тогда вот следующий вопрос. Хорошо, у нас есть система, которая что-то делает, делает это нам кажется достаточно хорошо, но мы не понимаем, как она это делает, и тогда возникает вопрос. Во-первых, есть ли у этой системы сознание? Может ли оно у неё возникнуть на каком-то уровне её развития или конструирования? И если может, то нужно ли это нам? Вот здесь вот у нас присутствует Игорь Пивоваров, организатор крупнейших российских конференций по искусственному интеллекту «Опентокс» и «Яй». И вот на первой конференции «Опентокс», где выступал Константин Анохин, и он в качестве итога этой конференции сформулировал следующий тезис, что нам нужно изучать такой феномен, как сознание искусственного интеллекта для того, чтобы понять, в какой момент оно возникает, где границы его возникновения, и выстроить свой технологический стэк таким образом, чтобы это сознание никогда не возникло. Вот, соответственно, следующий вопрос, вообще нужно ли то, что мы подразумеваем подсознанием сильным УИ, или тому УИ, который мы будем внедрять и создавать, если нужно, то можем ли мы его, возможно ли его создать? Или его создавать ни в коем случае нельзя, или, может быть, мы должны каким-то образом создавать только такие искусственные интеллекты, которые не будут обладать сознанием, и где, соответственно, граница тогда в этом случае? 

S03 [00:16:44]  : Мы говорим про consciousness, мы не говорим про intuition. 

S05 [00:16:49]  : Да, да, да. 

S03 [00:16:51]  : Вот статья, о которой я раньше сказал, я предлагаю, как можно это тестировать. Если мы говорим о каких-то внутренних чувствах системы-агента, qualia, чувства боли, чувства удовольствия, как понять, что система их испытывает на самом деле? Очень трудно протестировать. Hard problem of consciousness. Откуда я знаю, что она там чувствует? Если взять вот эти иллюзии разные, визуальные иллюзии, и абсолютно новая иллюзия какая-то. Раньше я ее не видел, на интернете ее нет. И я, значит, показываю эту иллюзию какому-то агенту, и я говорю, ну вот, там выбери из четырех. Ты видишь, там все крутится налево, красные линии стали синими. Короче, вот варианты, типичные иллюзии. Если хорошую иллюзию видели, там вот смотришь на нее, обалдеть, как это происходит. Там где-то в мозгу ошибка и в результате, значит, появляются смены цветов, движения, которых нет на самом деле в картинке. Это именно вот в мозгах внутреннее какое-то изменение происходит. Но мы говорим, что experience illusion, experience disillusion. Если я ее понял, я могу ответить на вопросы про нее. Если я посмотрел тупо, я не знаю, там, ну, дальтоник, не вижу цвета, я не могу объяснить, что произошло. Это не значит, что у меня нету самосознания, но, по крайней мере, в отношении этой иллюзии я его не испытал. И, значит, идея – начать показывать эти иллюзии нейронным сетям, искусственным интеллектом и посмотреть, в какой момент они начинают как бы их понимать. Вот, дошло, я могу объяснить, что здесь происходит. И есть уже эксперименты, где самые простейшие вот такие вот парадоксальные какие-то визуальные иллюзии, они понимают, они то же самое, они видят там, что-то кажется меньше, чем оно на самом деле, что-то кажется того же цвета. И как бы результат, к которому я пришел, что это не да или нет, это есть, значит, целый спектрум. и он пропорционален уровню интеллекта. Современные AI довольно глупы, у них есть какой-то минимальный объем самосознания, испытания внутренних. Чем они становятся умнее, тем больше у них будет возможности испытывать эти Разные иллюзии, они не ограничены только оптическими. Это может быть и звуковая иллюзия, и трехмерный мир, что угодно. И они могут даже испытать что более... глубокая, чем люди, если они достаточно умные. Но основная суть здесь, что этого нельзя избежать. Если система как бы думает, создает какую-то computation и делает ошибки, эти ошибки и есть уникальные для этой системы внутренние чувства. Известная статья «What is it like to be a bat? Как себя чувствует летучая мышь?» нужно hardware летучие мыши, нужно software летучие мыши. И тогда она уникально испытывает какие-то глюки в распознавании мира. Если у тебя такой же hard, такой же soft, то можно испытать то же самое, но это очень трудно, если это другой агент. Но что можно сделать, это протестировать, испытывает ли система какие-то ошибки вот на данном input. Если есть оптическая иллюзия, то все люди, которые ее видят, начинают все крутиться налево почему-то. Если система, об этом не знавшая заранее, не может найти ответ на интернете, новая иллюзия, и показывает, она говорит, о, круто, крутится налево, я должен признать, что система испытала эту иллюзию на себе. Она поняла иллюзию. То есть это не информационный ответ, там, здесь есть пиксель или нет, а именно какой-то внутренний внутренний глюк системы, которая, опять же, между ее сенсорами, между софтом производит это. И там могут быть, наоборот, иллюзии, которые мы не видим, мы не испытываем, а система испытывает. Поэтому, когда мы говорим про нейронные сети, вот идея fake inputs, когда системе показываешь какой-то абсолютно там, ну, просто random noise. А она видит там вот акула, точно, 100% это акула. Вот это вот оптическая иллюзия для нейронной сети. То есть там идет какое-то внутреннее чувство, которого нет у нас. Я смотрю, там просто точки, я не вижу никакой акулы. Но можно уже начать говорить, что там есть какие-то элементарные элементы этого процесса. 

S05 [00:21:25]  : Роман, расскажите, пожалуйста, вот вы говорили, из того, что вы сказали, я понял, что вы увязываете consciousness с способностью к иллюзиям. Как вы относитесь к увязыванию consciousness с внутренними целями, с целенаправленным поведением, с ощущением, так сказать, себя и, соответственно, выстраивания линии поведения в окружающем мире, исходя из самоценности самостоятельной личности? Вот это для вас попадает под категорию consciousness? 

S03 [00:22:06]  : То, что Дэвид Чалмерс разделил easy problems of consciousness и hard problems. Это все связано, это все нужно, это все там. Но все вот эти другие элементы мы понимаем примерно, как они могут быть сделаны. Мы понимаем, как система может создавать планы, как она может собственный код рассматривать. Единственное, что мы не понимаем, сложная проблема, это почему есть какие-то внутренние ощущения? Почему боль болит? То есть у меня есть информация, сенсор, что мне приходит сигнал, палец режут. Но информация, что палец режут и боль от того, что его режут, очень разные вещи. Если я вижу, там, чей-то другой палец режут, информация, в принципе, такая же. Я могу закодировать, нули единички, информация пришла. Но как сделать, чтобы это болело? Как сделать, чтобы компьютер почувствовал боль? По-моему, никто не знает на данный момент. И вот это вот и есть сложная проблема, насколько я ее понимаю. Какие-то внутренние чувства появляются, которые не являются частью информации, которая дана агенту. 

S05 [00:23:10]  : Ну, как вы считаете, мы можем это сделать? Если мы можем это сделать, мы должны этим заниматься? 

S03 [00:23:17]  : Мне кажется, что мы не можем избежать этого. Если мы сделаем достаточно сложную систему, это появится вот как появляется тепло, когда идет какой-то компенсационный процесс, вырабатывается тепло. Мы не делали специально, чтобы он там комнату обогревал, это side effect. И то же самое получается, мне кажется, и здесь. И с одной стороны, если мы просто хотим роботов, которые делают всё, что нужно, мне не нужно, чтобы он себя плохо чувствовал, болел, и жалко его было. С другой стороны, если они испытывают какие-то чувства, это можно как-то использовать, чтобы лучше понимать нас, чтобы лучше интегрировать их с нашим миром. Сложная проблема, сложная. 

S05 [00:24:01]  : Роман, спасибо. Вот здесь следующий вопрос из таких более философских и принципиальных вопросов на скорее технологический. У нас на одном из семинаров была высказана гипотеза, что интеллект И разум, но на самом деле даже неоднократно эта тема возникает, что вообще разум и интеллект – это некоторая сущность, которая имеет вселенскую природу, и человеческий интеллект является не просто некоторым частным случаем, соответствующим определенному уровню сложности. И что существует некоторый универсальный математический язык. с помощью которого можно этот интеллект реализовать, и что человеческому мозгу случилось этот язык реализовать конкретным образом. То есть, мы можем, так сказать, язык программирования Java, к примеру, реализовать в различных компиляторах, на различных процессорных архитектурах. Есть некоторый универсальный язык разума, И, собственно, нейронная архитектура человеческого мозга, она его некоторым образом реализовала. Значит, вот этот язык разума. Соответственно, вот вопрос, считаете ли вы, что есть такой язык, который можно формализовать и, соответственно, воспроизведя его в каком-то другом на какой-то другой архитектуре, не биологической, а кремниевой или там какой угодно, еще воспроизвести этот разум, функциональность этого языка. А второй вопрос сразу же, что может быть этот язык не один, может быть можно построить много языков, которые будут эквивалентны друг другу, но будут разными. 

S03 [00:25:55]  : Значит, у меня есть, в книге моей я описываю такую, как назвать, новую дисциплину исследований – интеллектологии. То есть где мы именно пытаемся в абстракции изучать, что такое интеллект, какие они бывают, какие у них есть ограничения, как их можно распознать, копировать, контролировать. Все, что с этим связано из разных дисциплин. То есть обычно этим занимаются в психологии, философии. биологии, программисты этим занимаются, но как-то не связано в одно. И именно там я говорю о том, что да, человеческий мозг – это один как бы подвид возможного интеллекта. Это не универсальный интеллект. Есть статья буквально месяц назад вышла «Human sonata and GI». То есть там именно я пытаюсь показать, вот мы как бы считаем себя, что мы general intelligence, но на самом деле есть очень много простых вещей, которые мы просто не можем даже понять, как это сделать. И там даются несколько примеров этого. То есть я согласен, что есть вот в абстракции этот универсальный интеллект. мы конкретно имплементируем какой-то вариант, очень ограниченный на самом деле. Мы general intelligence, но только в сфере понимания человека. Мы совершенно не понимаем даже там мир животных, как они себя ведут. И если подумать вообще, в безграничном этом океане возможных интеллектов, да, мы очень там, очень ограниченный сабвид. Это абстракция. Если язык, который это может описать, это математика. Математика, насколько я понимаю, одна. Можно там разные символы использовать, но всегда они будут эквивалентны. То есть да, можно написать и в Java, и в C++, но... как бы сам алгоритм не меняется от этого, не должен меняться. То есть фундаментально, мне кажется, да, есть универсальный алгоритм, есть теоретические алгоритмы просто ограничения на ресурсы. Но если дать безграничные ресурсы, туда всегда получается оптимальный ответ, всегда можно найти решение. И мы стараемся подойти как можно ближе к этому безграничному, неограниченному интеллекту, но всегда ресурсы кончаются, поэтому надо выбирать как бы оптимизация под местные проблемы. То есть вот на Земле там в этой гравитации, в трехмерном мире столько-то агентов, вот самое оптимальное это заниматься там проблемами языка, распознавания визуальным. В другом в другом физическом мире другие проблемы были бы более актуальны и там были бы агенты, которые были бы оптимизированы под это. 

S05 [00:28:41]  : Спасибо. Хорошо. А вот, значит, если перейти от языка человеческого мозга к языку, с помощью которого один человеческий мозг разговаривает с другим. То есть, вот у нас человек же живет в обществе. И, во-первых, есть средства коммуникации, есть голос, есть жесты, есть мимика, есть речь, устная речь, есть письменная речь. Есть, наконец, языки, которые с помощью этих средств коммуникации могут использоваться для передачи мыслей. И, наконец, есть общество, которое является тоже накопителем какой-то информации, позволяет принимать какие-то решения совместно. И тут вот как бы два вопроса. Первый вопрос – является ли человеческий мозг некоторым продуктом, обусловленным формированием общества. Приводя пример, если возьмем творчество Станислава Лема, у него есть два романа. Есть «Непобедимый», где в чистом виде роевой интеллект существует на планете, и есть «Солярис», где есть мыслящий океан. Так вот, можно ли сказать, например, что, допустим, роевой интеллект возможен, а интеллект в виде единичного океана, у которого нет с кем поговорить и некому передать свои мысли, невозможен? Или, наоборот, роевой интеллект невозможен? То есть, вот как вы относитесь к интеллекту безобщества и интеллекту, построенному исключительно на обществе? Ну, это вот, наверное, один вопрос. А второй вопрос я, наверное, потом лучше задам. 

S03 [00:30:22]  : Ну, понятно, что сегодня, конечно, вот люди, по крайней мере, да, мы зависим от общества. Если ребенок, там, растет в джунглях без контакта с людьми, он, в принципе, овощ. Из него ничего умного не получается. Но если взять и посмотреть, к чему мы идем, то есть мы постепенно становимся более оцифрованными, цивилизация делает интернет, какие-то соединения искусственных мозгов с настоящими мозгами, постепенно эти искусственные мозги начинают доминировать биологические, становятся главными на планете. Они, в принципе, все связаны. Нет разницы, что вот он на сервере, в облаке, или он на этом компьютере. Это все один интеллект. То есть, конечная точка – это вот один глобальный интеллект, который контролирует все. По-моему, Бостром это называют синглтон, или что-то в этом духе. И это процесс. То есть, мы идем от этих вот, как бы, маленьких агентов, которые учатся и в соревновании с другими агентами становятся лучше, но постепенно количество агентов уменьшается, их способности увеличиваются и в конце есть точка, сингулярность, куда мы может прийти, где будет один все доминирующий интеллект. То есть, если подумать, информация общая, да, то есть все, я там сделал эксперимент, ты сделал эксперимент, но в конце концов это все общая наука, и мы пытаемся открыть те же самые законы физики, то же самое, то есть там есть какое-то сближение между разными. ресурсы. Если у нас как бы раньше там были индивидуальные компьютеры, сейчас все в облаке, мы можем делиться этим, если там нам обоим нужно сохранить какой-то файл, нет смысла делать две копии, мы делаем один и тот же файл, просто два человека на него смотрят. То есть постепенно, мне кажется, процесс мы идем от группового интеллекта, который зависит сильно от того, что другие говорят, более singleton модели. И в коммуникации, когда вот люди общаются, очень важно, чтобы у нас был как бы одинаковый набор слов, одинаковое понимание этих слов. Очень часто, мне кажется, вот я по-русски говорю, но мне кажется все-таки иногда что-то не сто процентов. И результат, мы понимаем друг друга, но не сто процентно. То есть есть очень много ambiguity в нашем языке. Не так это важно, если я даже что-то не так сказал, в принципе ничего не изменилось. Но на уровне искусственного интеллекта достаточно важно понять, когда мы общаемся, что нет ошибок в командах, если, допустим, мою команду искусственному интеллекту, важно, чтобы он понял, если там шутка, ирония, если там что-то, и на эту тему есть у нас тоже статья, значит, о проблемах of ambiguous communication with human languages, поэтому начали придумывать языки, которые, ну, не позволяют этого. Как языки программирования, там все равно могут быть ошибки, но, по крайней мере, ты знаешь, то, что ты сказал, там только один вариант понять, как это Можно интерпретировать. 

S05 [00:33:40]  : Извините, а вы случайно не разговариваете на ложбане? Или ложбане, как он пишется? 

S03 [00:33:46]  : Я о нём знаю, но нет. Не разговариваю. 

S05 [00:33:50]  : Я просто знаю, что на планете существует около 300 человек, которые о нем говорят. Подумал, вдруг вы один из них. Скажите, а тогда вот еще такой вопрос. Вот хорошо, вот у нас есть общество, у нас есть язык, значит, какой-никакой, точнее много разных языков есть, значит, мозги. А вот в истории эволюционной человеческого мозга, общества, языка, вот что является ключевым? То есть, можно ли сказать, что всё-таки первичен мозг, а потом, значит, уже язык, а потом уже общество, или, так сказать, всё из-за общества пошло, или вообще, так сказать, необходимость в языке форсировала развитие мозга, или это вот оно, так сказать, всё эволюционирует вместе, и трудно сказать, где курица, где яйцо. 

S03 [00:34:34]  : Ну, как правило, эволюционные процессы, да, зависят друг от друга. Они должны идти вместе, иначе просто нет смысла. Нет смысла, там, иметь рот, если нельзя разговаривать и кушать. То есть это должно как-то сопоставимо быть. И если, там, хочешь запомнить больше слов, нужен чуть больше мозг и так далее. Это очень сложные вопросы на самом деле, именно эволюционные корни мозга. Бостромская теория, что мы живем в симуляции, все это на самом деле запрограммировано уже как готовый эквивалент, предлагает интересный вариант понять, как это может работать, если это не эволюционный процесс. 

S05 [00:35:19]  : Тогда уж про языки раз заговорили еще вот такой вопрос. Наверняка эта идея выскакивала и будет выскакивать в разных случаях. Последний раз ее озвучили на конференции Open Talks и AI Journey, в конце прошлого года она озвучала, я эту идею озвучил в 2014 году, что для того, чтобы общаться с компьютерами, точнее с искусственным интеллектом, нам потребуется сделать как раз вот такой вот non-ambiguous язык, который, с одной стороны, будет понятен человеку, А с другой стороны, он будет понятен роботу. И с помощью этого языка смогут общаться как роботы друг с другом, так и люди с роботами. И люди смогут как бы мониторить то, о чем общаются друг с другом роботы. Так, в принципе, и люди смогут общаться друг с другом. Вот. Ну и вариантами, одним из вариантов этого языка является вот тот же самый Lojban. который является строго формальным языком, при этом является человеческим языком, можно в эту категорию подвести так называемые контролируемые языки, которые определяются жестко ограниченными лексиконами и упрощенными формальными грамматиками. Но, с другой стороны, есть такая точка зрения, что это все не нужно, потому что если мы сделаем искусственный интеллект, он будет общаться с нами на нашем естественном языке, а между собой они будут общаться вообще на тех языках, которые изобретут сами. и которые будут адаптированы к тем вообще техническим возможностям, которые есть у них, а не тем, которые есть у нас. Они могут вообще, так сказать, байтстримами общаться какими-то совершенно. Вот вы к этому как относитесь? 

S03 [00:37:16]  : Ну да, для искусственных интеллектов в общении они в принципе могут просто скопировать ту модель, которая у них там есть. Не нужно ее переводить в какой-то язык, потом обратно переводить в модель. Можно просто, вот, модель возьми, теперь ты меня понял. С людьми проблема у нас, опять же, в очень ограниченной возможности. Язык, который абсолютно non-ambiguous, он должен на уровне молекул, атомов говорить, что, куда идет, как. Это невозможно для человека описать на таком уровне. Все, что мы говорим, это какие-то абстракции, мы друг друга понимаем. Достаточно хорошо, но есть миллионы примеров ошибок в этом. И как сделать, чтобы человек, который говорит на языке, который полон ошибок, мог давать команды машине, которая контролируется на более глубоком уровне? Нужен какой-то интерпретатор этого всего. И в этом проблема, опять же. То есть мы переводим, мы упрощаем. Обратно то, что говорится, мы уже сказали, невозможно объяснить, почему решение было принято, не упрощая его. И в то же время здесь получается какая-то super resolution. Я даю команду, эта команда должна быть переведена в очень-очень глубокий язык с точки зрения всех деталей, что говорится там. если вот все эти стандартные примеры там лампа аладдина так далее я даю команду я хочу жить вечно но я имею ввиду что я хочу жить вечно там без боли богатым красивым молодым не в банке и так далее то есть это одна фраза становится книгой и это довольно трудно то есть нужен уже интеллект этого уровня чтобы это сделать то есть получается само к себе относится с точки зрения сложности и проблемы. 

S05 [00:39:09]  : Спасибо. А вот здесь вопрос следующий у нас, как бы возвращает нас с начала дискуссии к теме вообще нашей области. Есть определения разные. Есть понятие общий искусственный интеллект или artificial general intelligence. Есть понятие strong intelligence или сильный искусственный интеллект. Они для вас это синонимами являются или какой-то разный смысл вы вкладываете в них? 

S03 [00:39:35]  : Насколько я знаю, исторически на английском это были термины для одной и той же темы, то есть изначально просто называлось AI, когда там ничего не получилось, значит AI перестал быть general, стал конкретным, потом сделали AGI, сейчас вернули это в AI, strong and weak это вот были как сегодняшнее будущее, но да, по-моему это одно и то же. Я в последней статье начал немного больше говорить о разнице между general и universal. И именно вот ограничение, что general он может быть в какой-то сабгруппе проблем, как человеческий интеллект он general, но не во всем возможном. А есть еще универсальный, который действительно может все возможное, чисто математически. То есть нам это не так важно на данный момент, Этот универсальный нам будет казаться как superintelligence, а general он больше как human equivalent, если он в той же атмосфере ограничен. Он может быть general совершенно в другой теме. 

S05 [00:40:38]  : Хорошо, а вот тогда следующий вопрос, на самом деле, я правда, мне кажется, вы на него неявно уже ответили. Вопрос такой, что нужно ли вообще нам, как человечеству или как обществу разработчиков или ученых, стремиться к созданию вот такого общего и сильного, или сильного искусственного интеллекта, Или нужно все-таки этому препятствовать, чтобы он случайно нас не поработил или не разрушил нашу привычную жизнь. И если этому надо препятствовать, то вообще мы можем этому препятствовать или нет? 

S03 [00:41:11]  : Ну это самый важный вопрос, наверное. Вначале, ну, бенефиты просто потрясающие. Почему мы это делаем? Да, там можно получить бессмертие, научные знания, экономический рост. То есть, с одной стороны, не делать нельзя. С другой стороны, да действительно там контролировать вроде сложно что-то более умной куча ошибок и может быть только хуже то есть делать тоже нельзя тогда становится вопрос ну а мы можем этого добиться какими-то ограничениями то есть принять закон что там нельзя или ну там, не знаю, какие-то инспекции вести, что-то еще. Вроде бы это просто невозможно предотвратить. Это настолько дает много каких-то материальных благ и известности, что если не запретить там калькуляторы, лаптапы, все не запретить, то все равно этот процесс будет двигаться вперед. Он может быть не двигается на уровне лучших университетов, но все равно где-то в подвалах кто-то будет этим заниматься. Каждый год становится все легче решать эти проблемы, то есть интеллект, который нужен для того, чтобы заниматься этими исследованиями, с каждым годом становится ниже и ниже, потому что лучше компьютеры, лучше софт, который есть, то есть то, что там сегодня может сделать лучший ученый в мире, через 10 лет могут сделать 50 таких ученых среднего уровня. И, по-моему, ограничить эти исследования просто невозможно. 

S05 [00:42:51]  : Ну, смотрите, возьмем другую похожую тему. Многие сравнивают искусственный интеллект, открытие или создание искусственного интеллекта с открытием или созданием атома, мирного или немирного. Соответственно, с атомом же как было? Сначала его открыли, потом сделали атомную бомбу. А потом принялись регулировать, и вроде как продолжают регулировать, что атомную бомбу стараются не давать делать, а атомные электростанции, пожалуйста, делайте, но под контролем организации под названием МАГАТЭ. Имеется ли, с вашей точки зрения, возможность и есть ли смысл создания в какой-то момент для искусственного интеллекта организации подобной МАГАТЭ? 

S03 [00:43:40]  : Это хорошее сравнение. Ядерное оружие очень трудно сделать без больших государственных ресурсов. Я не могу себя в подвале там начать плутоний вырабатывать и так далее. То есть, мне кажется, лучше сравнение с биотехнологиями, генетической инженерией, там вот тоже как бы волновались, что будет клонирование людей, будут какие-то изменения. в человеческом геноме. И там действительно на конференции принято решение это дело запретить, и государство как бы это ограничивает. То есть там ближе. Есть организации, которые следят за этим. На сегодняшний момент, по-моему, им удалось то, что они хотели. Они замедлили это человеческое клонирование довольно замедленно. С ядерным оружием непонятно. С одной стороны, там сложнее сделать, но с другой 5-6 новых стран, которые это добились после запрещения. Индия, Пакистан. Вроде бы хотели хорошо сделать, но не получилось. 

S05 [00:44:49]  : Понятно, а вот, ну хорошо, тогда все-таки по-другому спрошу. Вот есть такая точка, вот вы говорите, что можно сделать в подвале, да, что как и, значит, вирус какой-нибудь слепить можно, значит, можно в подпольной лаборатории, так и искусственный интеллект кого угодно может сделать у себя в гараже. Но есть такая точка зрения, в том числе известные люди ее высказывают в разных странах, что на самом деле для того, чтобы сделать искусственный интеллект, ресурсов надо очень много. Во-первых, нужно очень много в вычислительных ресурсах, а во-вторых, нужно иметь очень много денег, чтобы нанять очень много квалифицированных программистов и ученых, И, соответственно, первый искусственный интеллект сделают какие-то очень богатые корпорации, у которых много железа и большой штат разработчиков искусственного интеллекта. Вот вы разделяете эту точку зрения или нет? Или вы все-таки считаете, что тут именно вот есть такая возможность прорыва малой кровью? 

S03 [00:45:45]  : Ну, это статистически логично. Скорее всего, так и будет. Но есть примеры, где один человек, абсолютно без всяких ресурсов, делал то, что не могли корпорации, банки, страны. Криптовалюта – хороший пример, да. Сатоши Накамото и биткоин. Даже не знаем, кто это вообще, что это. Человек полностью меняет экономику, там, триллионная индустрия. И другой пример в искусственном интеллекте – это вот Generative Adversarial Networks, тоже студент, там статью пишет, опять же, меняет всю индустрию. Понятно, что потом там, чтобы это развить, нужны ресурсы, но если у кого-то есть идея, как сделать тренировку нейронной сети в тысячу раз эффективней, то есть теперь это уже не нужен Весь клауд Амазона можно купить там за 1000 долларов на этом же клауд ресурсе и самому это сделать за месяц вместо за день. Все равно опасно. То есть есть шанс, что это произойдет. И опять же, любые ограничения, которые мы вводим, они в какой-то стране, в Америке, в России, но там 200 стран в мире, половина из них делают, что хотят. Мы запретили вирусы, мы запретили спам, имейл. Насколько это эффективно? 

S05 [00:47:12]  : Хорошо. Спасибо. Вот сейчас вот есть вопросы ещё. У нас остались как бы более технологические, менее экзистенциальные. Во-первых, вот по поводу языка. Мы говорили о том, что язык, сообщество, мозг – это всё результаты той эволюции. А возможно ли вообще существование мозга без языка и работа мозга? То есть, нужен ли нам обязательно язык для того, чтобы мыслить? 

S03 [00:47:39]  : ну и правда возникает вопрос что такое мышление но вот вопрос называется так и есть возможно ли мышление без языка ну я думаю что да язык это абстракция того что там происходит то есть есть же люди которые ну в силу каких-то обстоятельств выросли без других людей да то есть они не говорят на человеческом языке они там может С обезьянками там знаю два слова, но я все равно считаю, что они думают на каком-то уровне. Это, конечно, сильно ограничивает, что они могут подумать. Но, в конце концов, язык – это просто вот как распечатать то, что происходит там в программе для внешнего пользования. Я все равно как бы вижу там вот опасность или там еда и реагирую на это. Можно сделать язык какой-то визуальный принтер, который показывает видео того, что я думаю. Это тоже был бы язык. То есть мы сделали то, что у нас как бы hard позволял, но, по-моему, эти процессы как бы не связаны. Как я могу иметь компьютер без принтера? Я думаю, это реально. 

S05 [00:48:50]  : А тогда другой вопрос тоже близкий к этому. То есть, окей, мы можем представить себе мыслительный процесс без языка, а можем ли мы представить себе мыслительный процесс, в котором не будет категории времени? Значит, вопрос причем был задан как бы чисто с прикладных позиций, мы тут его пару дней тоже обсуждали недавно в сообществе. То есть, вопрос такой, что если мы конструируем там какую-то когнитивную архитектуру, то те структуры, которые будут представлять знания в этой архитектуре, должно быть, грубо говоря, должно ли быть время некоторым универсальным атрибутам вот тех объектов, которые будут представлять знания или информацию в системе. Время – это некоторый атрибут, который нужен только в каких-то частных случаях, в каких-то частных вариантах мыслительных процессов. То есть, могут ли быть мыслительные процессы или объекты мыслительного процесса, которые не требуют категории времени. 

S03 [00:49:52]  : Ну, если посмотреть на самый мыслительный процесс, как мы это делаем сейчас, вот в Annoying Man Architecture есть какие-то update intervals, да, то есть там через каждую, там, наносекунду, долю секунды проходит какой-то компетиционный апдейт. Что-то мы посчитали, изменилось. То есть, если нет понятия времени, как тогда происходит самоумышление. То есть, внутренне уже есть встроенная system clock. Есть процессы во внешнем мире, которые можно сделать за пределами времени. Да, это, возможно, чисто абстрактно, но все равно сам процесс мышления, computation, построен на на времени. Все это говорит о сколько шагов нужно, чтобы подсчитать что-то. Если нет времени, то мы все можем безгранично подсчитать в один юнит, в одну секунду, тогда все возможно. Если вообще ничего нельзя считать, то есть это просто статик системы, она не меняется, вот она сейчас все знает и зависла. Ну, тогда, наверное, неинтересно. Не уверен, что это возможно. 

S05 [00:51:11]  : Спасибо. А вот как обстоит дело с телесностью, то, что называется embodiment? Вы про это говорили уже, но вот здесь явно есть вопрос, насколько телесность влияет на сознание, и какой телесностью может обладать сильный искусственный интеллект? 

S03 [00:51:29]  : Ну, конечно, в нашем мире это важный фактор, мы общаемся с миром через тело, но, в принципе, физическое тело, по-моему, не обязательно иметь, можно иметь какое-то виртуальное тело в виртуальном мире, симулировать все это, просто загругал, заподумал, как оно будет, и за счет этого экспериментировать. Если достаточно сильный интеллект, то он может быть многотелесным, он может контролировать одновременно тысячи роботов, видеокамер, сенсоров. Постепенно всё, что приключено к интернету, может стать его сенсорами. То есть его тело – это вся планета, и он видит камерами, слышит микрофонами. Получается такой глобальный агент. 

S05 [00:52:13]  : Тогда вот такой вопрос следующий. Значит, тоже, по-моему, значит, вы про это говорили, но вот вопрос звучит так. Какова эволюционная роль общего сильного искусственного интеллекта? Должен ли он помогать людям или призван заместить их вообще? Ну, кстати, да, интересный вопрос. То есть, с точки зрения глобальной перспективы, то есть, когда мы говорим о том, что Искусственный интеллект, должны ли мы предотвращать его создание, или мы должны с этим смириться? Здесь же вопрос такой, что мы хотим? То ли мы хотим сделать себе помощника, чтобы он помогал нам до тех пор, пока мы живем на этой планете, или мы, может быть, хотим сделать что-то, что сможет продолжить человеческую цивилизацию, когда солнце погаснет, когда люди не смогут существовать. существующей вселенной, которая будет продолжать существовать после того, после гибели нашей планеты. Вот вы к этому как относитесь? Эволюционная роль сильного искусственного интеллекта по сравнению с человеческой цивилизацией и homo sapiens? 

S03 [00:53:22]  : Ну это вопрос, кто решает. То есть эволюция не имеет желаний, целей. Это абсолютно безмозглый процесс. То есть у нее нету какой-то конечной цели. Мы люди, мы решаем, и я предпочитаю, чтобы как бы меня, моих детей там не поработили, не уничтожили. Поэтому я как бы считаю, Ну, что лучше для меня? Байас, чистый байас, про-human байас. Все остальные байасы уже запретили. Этот еще легально можно показывать. Я, значит, за людей. Я против доминации машинами. Если есть какая-то другая цивилизация, более продвинутая, и они смотрят на это все со стороны, Я не знаю, что им выгоднее, чтобы там хорошо развивалась наша галактика, и там были самые умные роботы. Может быть, в этом их цель, может быть, это положительный процесс. То есть вопрос, с чьей точки зрения мы на это смотрим. Я вот знаю только одну точку зрения мою, и я предпочитаю, чтобы меня не уничтожили. 

S05 [00:54:26]  : А вот если говорить об этих вещах, то вообще какие у нас временные рамки с вашей точки зрения? То есть если у нас может возникнуть искусственный интеллект, и если встанет вопрос о том, что должен ли он замещать человека или уничтожать, не уничтожать, а просто привести к ситуации, когда человек просто станет не нужен для дальнейшего развития. техногенной цивилизации. Вот когда вообще вот эта пресловутая технологическая сингулярность возникнет? Когда нам этого ждать? 

S03 [00:55:01]  : Я никаких таких секретов не знаю. Я слышал очень умных людей, которые сказали, может быть, через 7 лет многие, большинство и много разных данных сходятся, где-то 20, 45, 20, 23. Я точно не знаю ответ на этот вопрос, но нам важно понять не точку, где это уже произошло, а точку, где это еще можно изменить. И мне кажется, мы вот живем в этой зоне. То есть мы еще можем контролировать развитие нашей цивилизации техногенно или нет, когда уже там понятно, что во вторник будет Singularity, что-то менять уже поздно. 

S05 [00:55:43]  : А мы можем тогда вот эту точку как-то структурировать, чтобы понять те направления работы, по которым нам надо обить. То есть, грубо говоря, вот какие основные угрозы и возможности, то есть, вот как-то структурировать, что он нам может дать, да, и где он нам может навредить. Соответственно, что мы должны, чего мы должны добиваться и чего мы должны избегать. 

S03 [00:56:06]  : Ну вот это моя основная тема. Я именно пытаюсь предсказать, что может произойти, как-то это все характеризировать, анализировать. И таких статей уже несколько с разных точек зрения. То есть мы знаем довольно хорошо, что может пойти не так. Проблема, что решений ни у кого нет. ни практических, ни теоретических, никто не знает, что можно сделать. У меня есть последняя статья про неконтролируемость искусственного интеллекта, где я пытаюсь вначале показать, ну а что это значит контролировать? Это значит, что он выполняет приказы как солдат, это значит, что он выполняет приказы как родитель, слушает ребенка, старается сделать ему лучше. Ну там, скажем, четыре варианта вот таких, то что посередине между этими. И для каждого из этих вариантов я показываю, что либо просто плохие результаты, то есть если он нами командует, ну все, мы потеряли контроль, мы не главные, теперь что он решит, так и будет. Либо все составные элементы алгоритма невозможны, то есть есть доказательства там из математики, из физики, что вот это нельзя, это нельзя, это нельзя. Последнее время я стараюсь именно рассмотреть все эти ограничения, то есть объяснительность этих процессов, предсказать, что они сделают, non-ambiguous communication, то есть все вот эти шаги, которые мы понимаем, что они необходимы, чтобы это работало, имеют какие-то баги, имеют какие-то серьезные ограничения. 

S05 [00:57:39]  : Хорошо. А вот, допустим, мы можем сфокусироваться на этих направлениях. И вот, наверное, одно из этих направлений – это избежать ситуации, когда системам искусственного интеллекта будет дано право убивать киллер-роботов. Проблема киллер-роботов. Ну вот, насколько я понимаю, проблема киллер-робот упирается в пресловутую гонку вооружений. Если с МАГАТЭ как-то договорились, потому что там всего три государства есть, которые могут сделать, уже не три, уже больше, Ну, по крайней мере, как-то успели подсуетиться. А Skill Robots, я насколько знаю, есть просто стартапы, которые в подвале делают этих самых дронов, которые могут там ликвидировать неугодных людей. Не говоря уже про военных, там Китай, США, насколько я понимаю, активно в этой области работают, Россия тоже подтягивается. Вообще можно как-то остановить эту проблему с киллер-роботами? 

S03 [00:58:47]  : Можно замедлить. Не думаю, что можно остановить. Проблема, что все это технологии двойного использования. Если там Амазон сделал новое, Delivery drone какого-то, он там приносит посылки, да, домой. А что в этой посылке уже, я не знаю, там может быть бомба, там может быть яд, там у них 10 тысяч дронов прилетят и все, города нет. То есть, по-моему, это нельзя контролировать на таком уровне, что вот не делайте его плохим. То есть, у тебя мало то. ударишь ты гвоздь или голову, это уже зависит от использователя. 

S05 [00:59:27]  : Ну, а вот тут вопрос есть с точки зрения, так сказать, моральной ответственности каждого разработчика. То есть, может, если человек занимается, во-первых, разработкой искусственного интеллекта и понимает, каким последствиям это может привести, то вообще, вот как, имеет ли человек моральное право этим заниматься? Или нет? Или это всё-таки вот то, что с моральной точки зрения должно как-то осуждаться? Я вот прям вопрос давайте прочитаю. Можно ли осуждать человека с точки зрения общечеловеческой морали за его стремление создать искусственный интеллект, учитывая, каким последствиям это может привести? 

S03 [01:00:14]  : Это прекрасный вопрос. Есть легкие случаи, скажем, работать на военных, создавать роботов, убить. Мне кажется, довольно простой вариант. Многие согласятся, не стоит этого делать. Просто искусственным интеллектом намного сложнее, потому что Ты же стараешься сделать лекарства от рака и продлить жизнь, и там куча плюсов. Ты не просто делаешь робота-убийцу. Но мне кажется, что каждый исследователь должен задать себе простой вопрос. То, что я делаю. У меня там есть система контроля и гарантии безопасности? Если нет, тогда подумай еще немного. Самый простой тест. Я сделал машину. Тормоза я еще не придумал, как делать. Машина полезная и классная вещь. Пока тормозов нет, я ее продавать не начинаю. 

S05 [01:01:10]  : Спасибо. Есть еще два вопроса из нашего стандартного набора подготовленного. Они немножечко неожиданные. Один вопрос. Какие именно интеллектуальные процессы осуществляет, с одной стороны, человеческий интеллект, а с другой стороны, интеллект искусственный, если он будет создан? Можете структурировать, систематизировать виды интеллектуальных процессов, которые нам нужно попытаться реализовать? 

S03 [01:01:42]  : Не совсем понимаю вопрос. 

S05 [01:01:45]  : Александр Соколов, если вы здесь, может быть вы уточните ваш вопрос? Был вопрос Александра Соколова, его здесь нету. Давайте я попытаюсь понять, что вот, предположим, я, как я вижу этот вопрос, вот я, допустим, разработчик, да, вот я делаю, вот вы сказали про машину, да, вот вам нужно сделать двигатели, вам нужно сделать колеса, вам нужно сделать подвеску, вам нужно сделать тормоза, салон, кузов, да, вот у вас есть набор элементов, которые нужно создать. Вот. А если вам нужно сделать искусственный интеллект? Вот можете ли вы перечислить те элементарные компоненты, из которых состоит искусственный интеллект, с одной стороны, и с второй точки зрения, какие элементарные функции, то есть, какие компоненты и какие функции. То есть, у машины там есть колеса, двигатель, салон, кузов, подвеска, и она может ехать вперед, может назад, может поворачивать, может просто прогревать мотор. Вот как-то вот проблему искусственного интеллекта вы можете так структурировать? 

S03 [01:02:49]  : Ну, это зависит на каком уровне детали это описывает. То есть, на самом нижнем он должен иметь возможность написать нолик, стереть его, написать единичку. Вот это вот как бы минимум. Если мы идем выше, тогда начинается, да, надо data compression понимать, как работает, то есть, данные собирать данные, как-то систематизировать, предсказывать будущее в каких-то статистических потоках. В принципе, я думаю, если посмотреть на человека, будет довольно хороший прототип, то, что может делать человек, только намного лучше. Если у человека какие-то зверские ограничения памяти, там семь элементов, то заменить это на миллиарды или неограниченную память уже довольно хороший шаг вперед, скорость. То есть если вот взять человека и как бы накрутить все эти способности, то получится довольно неплохой суперинтеллект уже. А если там еще добавить прямой доступ к интернету, связь с другими агентами, то в принципе ничего нового не надо предугадывать. Возможно, что когда он становится умнее, чем мы, он может делать вещи, которые я не могу предсказать. Только возможно, скорее всего, это так. Просто я не в состоянии понять, что так возможно. Увидим. 

S05 [01:04:12]  : Спасибо. И с другой стороны, как мы знаем из истории, человечество долго решало проблему получения золота из чего угодно, искало философский камень. В итоге философского камня так и не нашли, но возникла химия, возникла физика, возникла современная наука в качестве побочного эффекта от этих экспериментов. Вот вы видите какую-то аналогию между тем, в каком состоянии находятся поиски сильного искусственного интеллекта сейчас и той историей про поиски философского камня? 

S03 [01:04:53]  : Ну, какая-то связь есть. То есть, там пытались сделать золото, и сейчас мы можем сделать золото. Есть трансмутация элементов, можно более тяжелых элементов сделать золото, но оно будет радиоактивным, всех убьет, но нормально. Сделать золото можно. И здесь примерно так же. То есть мы понимаем, мы хотим построить интеллект. Может быть наши методы, которые мы используем на сегодня, они не дадут результат в той форме, в которой они есть сейчас. Но в результате этих экспериментов мы найдем правильный подход и так и сделаем этот искусственный интеллект. Главное, чтобы он не был радиоактивным. 

S05 [01:05:29]  : Роман, скажите, а вот с точки зрения того, по какой дороге мы туда в конечном итоге придем, к доброму, относительно хотя бы доброму, нерадиоактивному, сильному искусственному интеллекту. Сейчас же никто не знает, кто-то считает, что нужно просто сделать очень глубокую нейронную сеть, кто-то считает, что нужно взять несколько очень глубоких нейронных сетей и правильно соединить. Кто-то считает, что нужно строить какие-то когнитивные архитектуры. Есть разные направления. Кто-то считает, что нужно строить системы, основанные в моделях, предполагающих именно объяснимый искусственный интеллект на байосовских сетях, на веросетях вероятностной логики вроде PLN или NAS. Модели много разных. У вас есть понимание того, какие модели построения AGI имеют большие перспективы, какие нет, или для вас это пока открытый вопрос? 

S03 [01:06:34]  : Ну, мне кажется, что вот на сегодня, что мы видим с глубокими сетями, это пока что неограниченный рост. Когда мы добавляем данные, добавляем больше компьютерных ресурсов, они продолжают улучшаться. Вот там GPT-2, GPT-3, я думаю, GPT-4 будет ничем не хуже, намного лучше. Этот процесс продолжается. Как мы уже обсудили, наверное, ответ не только в этом. Надо будет добавить какую-то гибридную систему, где кроме вот этого как бы подсознательного нейронного процесса, Есть еще сверху экспертная система, которая на уровне символов может все это делать. Опять же, примерно как работает человек. То есть, я не понимаю, как у меня в голове вдруг появляются идеи, но появляются две-три идеи, я из них выбираю и вот так я оперирую. Мне кажется, что будет примерно так. Будет какая-то Black Box, которая будет прекрасно распознавать patterns в дате, и потом сверху будет система, которая будет больше как экспертная система с этим что-то делать. Когда мы смотрели, IBM Watson играл в Jeopardy. Там примерно так все это работает. Значит какая-то безумная машина там пытается с интернета скачать пару ответов, а потом уже используя какие-то правила, decision trees можно выбрать более-менее подходящий ответ. 

S05 [01:07:58]  : Роман, спасибо огромное. У нас закончилась основная часть нашего разговора, но еще есть комментарии и вопросы в чате. Вы готовы? 

S03 [01:08:09]  : Я всегда готов. 

S05 [01:08:12]  : Ну вот, первый вопрос, который появился в самом начале, когда вы рассказывали о том, как вы видите себе AGI, точнее, искусственный интеллект и сознание. Александр пишет, получается, что это система принятия лучших решений любых задач. Верно? 

S03 [01:08:33]  : лучших решений с точки зрения ресурсов, которые есть. То есть вот с тем, что мне дали, я сделал максимально хорошо. Если было больше времени подумать, больше данных, я мог, наверное, это улучшить. 

S05 [01:08:47]  : Следующий, это скорее комментарий про боль. Боль – это особенность некоторого вида когнитивных архитектур. Не более того, проблема не в конкретных языках, проблема в архитектуре. Тут есть что-то прокомментировать? 

S03 [01:09:02]  : Это вполне возможно, но тогда объясните мне, почему эта архитектура чувствует боль, а эта нет? И вот какой бит я должен там выключить, чтобы это перестало быть болью и стало информацией? 

S05 [01:09:16]  : Следующий вопрос. Есть разные взгляды на боль и другие чувства. У нас и у животных она возникла в процессе эволюции. А мы планируем эволюционный путь создания AGI? То есть, если мы планируем эволюционный путь создания AGI, то нельзя исключить, что чувства возникнут сами. А если мы конструируем AGI, то что мы заложим, то и будет. И тогда, вроде как, этой боли и не потребуется, и она и не возникнет. 

S03 [01:09:47]  : Ну, мы и то, и то делаем. Да, есть прекрасные исследования эволюционных алгоритмов для того, чтобы нейронные сети тренировать не стандартными методами, а именно веса их просто эволюционно определяются. Это очень быстрый метод, конкурирует со всеми другими. Получается, что тогда мы можем ожидать таких же результатов, как эволюция, то есть все вот эти чувства, злость, ненависть тогда тоже могут появиться, это довольно опасно. Если мы используем инженерный подход, не эволюционный подход, тогда, возможно, то, что я говорил про side effect является проблемой, то есть если ты создал достаточно умную систему, она все равно имеет какие-то внутренние свои миры, какие-то ощущения, которые просто результат этого вот input hardware-software комбинации. Можем говорить, что это ошибки, когнитивные какие-то ошибки, но в то же время, what is it like to be a bat? Как оно быть вот этим роботом, оно зависит от его конструкции. То есть, мне кажется, Какой бы вариант мы не выбрали, мы все равно можем оказаться с роботом, который что-то чувствует. 

S05 [01:11:02]  : Хорошо. А вот тут есть вопрос, точнее комментарий, который подразумевает скрытую дискуссию. которая сегодня у нас тоже уже была в сообществе. Евгений Витяев пишет, что можно показать, что обнаружением причинных связей можно моделировать большинство когнитивных функций. То есть, я так понимаю, что есть точка зрения, что да, окей, нам глубокие нейронные сети по мере увеличения глубины действительно могут помочь решить все больше и больше задач. Но можно показать, что это, в принципе, может быть достигнуто и использованием, в частности, метода логико-вероятностного семантического моделирования, которым Евгений Евгеньевич Итяев занимается. И это, с одной стороны, будет моделировать те же самые когнитивные функции, а с другой стороны, это будет по определению объяснимым интерпретируемым. А, значит, как бы дискуссия заключается в том, что вот тоже присутствующий здесь Юрий Бабуров как раз, по-моему, сегодня или вчера сказал, что это не масштабируется. Что если мы знаем, как масштабировать нейронные сети, нейросетевую архитектуру, то как мы масштабировать методы, основанные на семантическом моделировании, мы пока не знаем. И другая точка зрения, которую высказывал Алексей Потапов, что мы сможем масштабировать системы семантического моделирования, когда у нас возникнет очередной прорыв производительности, то есть нейронные сети Мы тоже долгое время не могли масштабировать. У нас нейронные сети 50 лет известны, но заработали они буквально несколько, 10 лет назад. Вот вы по этому поводу, по поводу масштабируемости семантических систем, что вы можете сказать? 

S03 [01:12:55]  : Логично, если появится намного больше ресурсов, возможно, это станет возможным. Мне больше интересен элемент, что если это Deep Neural Network, мы его не можем объяснить. Но если есть эквивалентная система, она сможет его объяснить. Но это парадокс. Они эквивалентны. Если то необъяснимо, это доказано, то как же что-то другое может это объяснить, если оно эквивалентно? Тогда, получается, в какой-то момент там магия происходит. Мы идем с невозможного к возможному, а как? Ну, я не знаю об этом достаточно, чтобы 

S00 [01:13:32]  : Это можно объяснить, я мог бы объяснить, как это можно сделать. Дело в том, что на основе причин эксигаза происходит моделирование иерархии естественных понятий о внешнем мире. Понятное дело, что мозг, когда осознает объекты внешнего мира, он выстраивает их в некоторую иерархию, но он осознает только их имена и внешние свойства. Но на самом деле, если это промоделировать в компьютере, то можно показать, как можно на самом деле более точно вытаскивать в том числе интуитивные знания, которые мозг за ненужностью просто не рассматривает. То есть на самом деле можно сделать объяснение более глобальным. 

S03 [01:14:14]  : Я спрашиваю на уровне, вот если нейронная сеть принимает решение на одном миллиарде каких-то факторов, как это можно объяснить человеку, который с трудом понимает пять? 

S00 [01:14:29]  : Но в том-то и дело, в этом и вопрос. На самом деле, в логике вероятностных методов можно показать, что вот такой-то объект получен на основании, положим, вероятностного формального понятия, которое выполнено, положим, на тысячи объектов. Можно конкретно эти объекты показать, в точности показать, какие зависимости в них наблюдаются. появляется понятие, но это действительно очень большая работа, если кто-то захочет это действительно понять, но мозг этим не занимается, он сформировал вероятностное понятие, оно ему понятно, и он невыливающую информацию, так сказать, не использует. 

S03 [01:15:09]  : На уровне, как ты распознал, что это собака, вот здесь уши такие, здесь глаза такие, здесь хвост, это абсолютно правильно, я согласен. Но ведь суперинтеллект может думать о более больших глобальных проблемах, не только распознавании визуальных объектов. И там объяснение уже будет намного сложнее, чем это. Такие есть, абсолютно, я знаю. 

S05 [01:15:37]  : То, что я услышал, это то, что мы можем сделать искусственный, то есть, Евгений Евгеньевич, вы говорите, что мы можем сделать объяснимый искусственный суперинтеллект, а Роман парирует, что может оказаться, что ему некому будет это объяснять. Нет, но есть надежда, что один искусственный суперинтеллект будет объяснять это другому искусственному суперинтеллекту. 

S03 [01:16:02]  : Поэтому в моей статье я именно разделил два понятия – explainability and comprehensibility. Они не равны. Explainability – что суперинтеллект может другому суперинтеллекту объяснить, что он сделал и почему. А вот чтобы человек это все понял – это уже другая проблема и тоже очень сложная. 

S05 [01:16:19]  : Есть еще комментарии по поводу моделирования когнитивных функций и обнаружения причинных связей. Хочу поддержать тезис и развить. Это происходит по той причине, что мышление и есть моделирование. Так, и еще вот есть комментарий по поводу боли, что проблема от Игоря Пивоварова – проблема не в боли или чувстве синего цвета, цвета как такового. Hard problem – это как мозг генерирует сознание. и почему он его генерирует. А сознание определяется, как наша способность от первого лица воспринимать это квалия, боль или синий. 

S06 [01:16:57]  : Антон, можно я подкорректирую это написанное? Добрый вечер. Роман, добрый вечер. Спасибо огромное за очень интересное интервью. Я просто по поводу этой hard problem, как я ее понимаю, что это не просто появление квалия, а что есть некто, кто переживает эти квалия. У нас в первом лице возникают эти ощущения. Я прекрасно понимаю, что у нейронной сети может сформироваться фича, которая, как вы иллюзии приводили, поворот налево. Но как бы она ее не переживает. Это просто ну как бы сформированное понятие там внутри, как бы некая фича. А как бы hard problem я понимаю именно так. И в этой связи у меня вопрос к вам такой. А вы видите какую-нибудь архитектуру, ну вот там из машинного обучения, которая ближе всего подошла к тому, чтобы ну вот такие как бы, как на ваш взгляд, к решению hard problem или такого вообще нету? 

S03 [01:18:15]  : Ну вот как я говорил, нейронные сети повторяют многие наши ошибки и тоже могут понимать вот эти иллюзии. В статье, я наверно повешу ссылку на эту статью, я про нее много говорил, я пытаюсь сказать, ну вот появляется после просмотра этой иллюзии какой-то элемент, который представлен в мозгах агента, то есть появился красный квадрат откуда-то. Но если мы возьмем это на два уровня глубже, то есть если появляется красный квадрат, может же появиться вот этот внутренний агент, кто смотрит на красный квадрат, это просто более сложная иллюзия, которая не просто цветовая, она многомерная, там все возможные инпуты, то есть мы не просто представляем мы представляем, кто ее представляет. То есть появляется мета-иллюзия, что я чувствую запах меда. То есть не просто запах меда, а еще появляется второй уровень. И если у нас глубокие нейронные сети, количество уровней может быть даже увеличено, может быть вселенная, в которой агенты, которые чувствуют запах меда и так далее. 

S06 [01:19:31]  : Я вот пока не вижу логической связи между тем, что появилось вот это впечатление, не впечатление, а там красный квадрат, и что дальше из этого следует, что при увеличении глубины слоев, там где-то появится агент, который… Я, может, плохо объяснил. 

S03 [01:19:55]  : Красного квадрата нет. Его нет на бумаге, его нет нигде. Но вот он есть в мозгах агента, который изучает эту иллюзию. Есть примеры из психологии таких иллюзий про боль, например, тоже есть вот fake arm или как она называется эта иллюзия, rubber arm. То есть иллюзия боли появляется. То есть, если взять вот этот мир иллюзий, иллюзорных, иллюзий, придуманных объектов, почему мы из них не можем построить вот этот внутренний I? Чем это отличается от любого другого? Я не говорю, что я знаю, как это сделать, но я пытаюсь понять, чем они принципиально, и тот, и другой не существуют в реале. И когда мы говорим про людей, есть интересные разные психологические отклонения, где люди, допустим, после клинической смерти видят, что они где-то там в другом месте расположены, то есть внутренняя иллюзия проектируется в другое место. Есть люди, у которых много personalities, они там раздвоение личности, расстроение личности – я девочка, я мальчик, я бабушка – все одновременно живет в этом мозгу. То есть это вот разные, как мне кажется, иллюзивные объекты, которые создаются этим компьютерационным процессом. 

S05 [01:21:23]  : Окей. Спасибо. По поводу Вселенной. Есть такой вопрос, который, может быть, Владимир Смолин пояснит. Если создадут единый планетарный интеллект, прогресс и цивилизация закончатся. Вот у меня есть гипотеза, что имеется в виду. Я вот, например, возвращаясь к моему вопросу про два Романа Лема, то есть «Непобедимый» и «Солярис», у меня есть гипотеза, что когда действительно возникнет полноценный планетарный интеллект, то эволюция может закончиться, потому что этому интеллекту не будет с кем взаимодействовать. У него не будет такого же другого интеллекта, с которым он сможет общаться. Если он не установит связь с каким-то другим интеллектом в другой звездной системе. Владимир, может быть вы поясните ваш вопрос, если вы с нами еще? 

S02 [01:22:19]  : Пока я с вами, то объяснение очень простое. Весь прогресс основан на разделении труда и конкуренции. И то и другое возможно, когда взаимодействуют агенты. Если агент останется один, ни разделения труда, ни конкуренции не будет. И, собственно, вот и прогресс остановился. 

S03 [01:22:38]  : Мне кажется, я понял вопрос. Агент, мы говорим, что он один, но ведь в нем куча сабсистем, которые в принципе тоже конкурируют за ресурсы, за внимание. То есть этот процесс, он просто не так видимо между разными агентами. То есть внутри системы, как внутри страны может быть внутренняя конкуренция, не обязательно между разными странами. И что происходит, вместо эволюционного процесса, который построен на соревновании, мы переходим в что называется Intelligent Design. То есть есть инженер, который… С другой стороны, если можно. 

S02 [01:23:17]  : значит, как известно, что власть развращает, а неограниченная власть развращает неограниченную и со смыслом жизни тоже очень сложно у кого-то один смысл жизни у другой если будет единственный агент, обладающий безограничной властью и абсолютным смыслом, то как бы он быстро сообразит, что все эти смыслы они бессмысленны и если мы в борьбе выявляем смыслы, которые позволяют нам побеждать в конкуренции, то каждый из нас, если задумается про смыслы, выяснит, что они не очень-то имеют смысл. а один агент, очень сильный, дойдет это очень быстро, и это тоже будет поводом для остановки прогресса. 

S03 [01:23:56]  : Я с вами полностью согласен, действительно, жизнь бессмысленная, мы все умрем, но если мы подразумеваем, что этому агенту дали какой-то гол, какая-то цель у него есть, пусть она абсолютно глупая, там, создавая какие-то paperclips, да, но вот он этим будет заниматься. Если мы считаем, что это не так, это другой вопрос. 

S02 [01:24:20]  : Так что устойчивость жизни основана на ее разнообразии. Если у нас идет конкуренция между видами, то выживают наиболее жизнеспособные. Если вот этот одинственный окажется неудачным, а не было таких видов, которые были абсолютно удачные. То есть если конкуренция остановится, то это конец прогресса. 

S03 [01:24:41]  : Мы можем надеяться, что вселенная большая, есть суперинтеллекты разных цивилизаций и будут там бороться, дружить. 

S05 [01:24:49]  : У меня еще возникла гипотеза, что если у него будет раздвоение личности, то множество раздвоенных личностей будут бороться друг с другом в одном и том же глобальном разуме планетарном. 

S03 [01:25:01]  : Ну и более популярный вариант Бострома – это что он создаст симуляцию с нами и будет за счет нас получать все удовольствие от конкуренции. 

S05 [01:25:10]  : Хорошо. Значит, вот вопрос еще есть, который, по-моему, тоже частично неявно был отвечен, на который был неявно дан ответ. Какова, по-вашему, базовая когнитивная архитектура разума? 

S03 [01:25:26]  : Можно уточнить, что подразумевается? 

S05 [01:25:33]  : Прокопчук, извините, не знаю вашего имени и отчества. Можете уточнить свой вопрос? Вас не слышно. Да, слышно. 

S04 [01:25:46]  : Юрий Прокопчук. По сути вопрос довольно такой простой. Насчет когнитивных архитектур понятно, они разные бывают. Пишут, что это Вопрос разума – это одна из постановок, что нужно найти соответствующую когнитивную архитектуру, у нее какие-то механизмы будут функционирования, она будет плодиться, размножаться, они будут как-то между собой контактировать, связываться, и в итоге мы получим какую-то модель разума. Поэтому вопрос, есть ли это базовая элементарная когнитивная архитектура, размножением которой в разных вариантах мы в итоге получим какой-то разум. 

S03 [01:26:27]  : Я, может быть, смутился, потому что действительно очень простой вопрос. Не нейронные сети. Мне кажется, что у человека нейронная сеть, у нас сейчас есть прогресс в нейронных сетях. Я думал, что вот это и наш номер один вариант пока что. 

S05 [01:26:44]  : Спасибо. Роман, вопрос как бы снова ближе к безопасности. Вот по поводу ограничения искусственного интеллекта. Можно ли сравнить искусственный интеллект с точки зрения проблемы его ограничения с компьютерными вирусами, с которыми мы не знаем, что делать? И вот похожа ли эта ситуация? 

S03 [01:27:04]  : Очень похоже в моей статье про как bugs искусственный интеллект, я именно эти сравнения часто использую. То есть, если подумать, это компьютерный вирус, который на уровне человека способен делать social engineering attacks. разговаривать, там уговаривать и так далее. То есть очень похоже. И это именно то, что делает его опасным. Даже если мы на уровне hardware, software как-то это все там сделаем без дырок, все равно кто-то на него смотрит, кто-то с ним общается, и это вот слабейшее звено во всей системе. Человека всегда можно уговорить, подкупить, там шантажировать. То есть, вот в этом и сложность. Поэтому большинство людей, которые смотрели на эту проблему, думают, что это невозможно делать бесконечно. То есть, да, там можно чуть-чуть ограничить, там замедлить, но рано или поздно он все равно найдет, как выбраться из этого затащения. 

S05 [01:28:02]  : Вопрос, может ли система создать систему более сложную, чем она сама? 

S03 [01:28:12]  : Ну, да. 

S05 [01:28:15]  : То есть, мы это всё время и наблюдаем, да? 

S03 [01:28:17]  : Ну, на это вся надежда, если нет, так у нас какие шансы, да? 

S05 [01:28:23]  : И здесь еще ремарка Евгения Евгеньевича Витяева, что возможно мозг устроен просто, и тогда его нельзя ограничить, и как только мы этот принцип реализуем, то мы очень быстро сможем превзойти человеческие возможности. Комментарий, что так и будет, сделает какая-нибудь богатая контора, по вероятности. параллельные вычисления, квантовый компьютер. А вот вопрос неожиданный. Как вы относитесь к проблеме того что у нас в какой-то момент может случиться нарушение закона мура да что у нас у нас перестанет там дешеветь память и перестанет повышаться частота процессора вот и если это произойдет то помогут ли нам и что то что нам сможет помочь либо это квантовые компьютеры либо это оптоэлектроника, это компьютеры, построенные на световодах, вот что вы по этому поводу думаете? 

S03 [01:29:21]  : Ну, точно произойдет. Закон Мура это подзакон более глобального закона Exponential Returns, по-моему, Рэй Крюзвайл про это любит рассказывать, там были вначале вакуумные тубы, потом там до этого камни были, в общем, постепенно процессор идет, меняется сам тип компьютера, то есть Сейчас на данный момент вроде бы квантовые компьютеры проявляют хорошие результаты, есть трехмерные чипы, есть биологические компьютеры, какие-то начинания на ДНК-модели, световые компьютеры, то есть использовать свет напрямую, увеличивать скорость. Понятия не имею, что из этого выиграет. Мне кажется, что то, что у нас сейчас есть, уже достаточно, чтобы симулировать человеческий мозг. Может быть, там надо подсоединить несколько суперкомпьютеров, По-моему, мы уже на том уровне, где нам не нужен фундаментальный новый компьютер. Я, может быть, не прав. Есть люди, которые говорят, что в мозгу человека квантовые процессы, но пока что я не видел конкретных доказательств. 

S05 [01:30:26]  : Спасибо. А вот насчёт прогнозов, 20 лет вы говорили. Здесь есть замечание, что нам про термоядерную энергию тоже периодически говорят, что она получится примерно через 20 лет. Ну а про EGI, кстати, я знаю, в определённых кругах периодически обещается, что EGI будет года через 3-4. Вот. Насколько вот эта вот проблема Ахиллеса и черепахи применима к оценкам срока появления сильного искусственного интеллекта? 

S03 [01:31:01]  : Ну, что предсказания, особенно про AI, всегда были очень оптимистичными, это правда. Эти 20 лет мы слышим с 50-х, как всегда говорили, но, мне кажется, есть несколько отличий в этот раз. Я, может быть, молодой и глупый, не знаю просто, но, во-первых, в очень многих индустриях, в многих проблемах мы уже превзошли способности человека. все что раньше нам говорили там через 10 лет будут в шахматы играть сейчас это 10 лет назад то есть во всех этих областях мы лучше прогресс очень сильный, и он ускоряется. Финансирование, если раньше все шло от государственного финансирования, по крайней мере в Америке, в Англии, если они там замораживали финансирование, все, это зима, да. Сейчас все деньги частные, Google, Facebook, Apple, они финансируют большинство исследований. То есть нет такого варианта, что завтра там новый президент в Америке отменит исследование. Мне кажется, за счёт этого я не думаю, что будет ещё одна зима, но это может быть очень длинная весна. 

S05 [01:32:10]  : Спасибо. Вопрос, опять-таки, мне кажется, вы его отвечали неявно, но вот, тем не менее, от Бориса Новикова. Возможно ли работа интеллекта в отрыве от потребностей тела и общества? 

S03 [01:32:26]  : Ну, мы говорили про нужно ли физическое тело, или можно все это симулировать. Мне кажется, в принципе, в абстракте можно. Для человека, конечно, это невозможно. Нам нужно тело, и мы социальные животные, нам нужны люди, но я не вижу причину, почему нельзя сделать интеллект, который полностью в виртуальном мире и даже, может быть, сам симулирует мир, в котором он находится. Все контролируется агентом, и эволюционный процесс продолжается так. 

S05 [01:32:56]  : А тогда, вот тут уже, так сказать, есть тоже неявная дискуссия в чате, если мы такой интеллект создаем, то будет ли у него проблема различения добра и зла? Если будет, то с точки зрения каких ценностей и интересов? 

S03 [01:33:14]  : Это та же проблема, что и у нас, как мы определяем. По-моему, это основная проблема этики и философии. Мы не всегда уверены, что такое хорошо, что такое плохо. 

S05 [01:33:24]  : Ну вот да, здесь как раз Владимир Смогин тоже комментирует, что в эволюции всегда правы те, кто выжил и оставил потомство. В сказках добро всегда побеждает зло. И по любой истории легко понять, сказка это или нет. 

S03 [01:33:36]  : Мне нравится, когда про войны говорят, как замечательно, что все войны выиграли хорошие. 

S05 [01:33:45]  : Так, про боль. Что боль – это иллюзия, мозг ничего не чувствует, он просто получает сигналы и их интерпретирует. 

S03 [01:33:54]  : Боль – это иллюзия, я согласен, у меня вся теория построена на иллюзиях, да, все иллюзии. 

S05 [01:34:00]  : И то, что чувство боли довольно просто переключить в информацию, а более еще Кашпировский показывал, когда операции без наркоза делали под его внушением. 

S03 [01:34:11]  : Про Кашпировского не буду комментировать. 

S05 [01:34:14]  : Так, боль и другие чувства, сигнал системы обучения, в какую сторону направить обучение? То есть, эта боль, это как бы побочный эффект backpropagation? 

S03 [01:34:26]  : Ну можно сказать, что это упрощение, как бы вот есть юзер интерфейс, если напрямую с вселенной общаться, там миллиарды каких-то фотонов тебя ударяют, трудно. Если сделать юзер интерфейс, типа вот я вижу мир вот так, это хорошо, приятно, это больно, намного быстрее можно подсчитывать, что делать и убегать от врагов. 

S05 [01:34:47]  : Так, дальше снова про боль. Боль – это низкоуровневый сигнал. Он много что забивает, но управлять им можно. Интеллект. Значит, вот. Опять от Бориса Новикова. Значит, интеллект – это про решение задач. То есть, было сказано, что это оптимальное, эффективное решение любых задач. Но вопрос тогда, откуда берутся их постановки? Кто ставит эти задачи? 

S03 [01:35:15]  : Можно абстрактно просто начать все задачи математические от самой маленькой бесконечности идти. Все же в конце математика, правильно? То есть можно любую реальную проблему в мире, это мэппинг идет на какую-то математическую структуру. Кто ставит цели в жизни? Это вот мы возвращаемся к более большим проблемам. Есть ли Бог? Кто он? Что он хочет от нас? Зачем он нас создал? меня столько не платят. 

S05 [01:35:46]  : Ну и последний вопрос, значит, там тут уже комментарии пошли, пошла уже дискуссия, значит, один вопрос остался. Можете ли вы назвать конкретные области деятельности интеллекта, которые, в принципе, не алгоритмизируемы? То есть, я так и понимаю, есть гипотеза, что какие-то области интеллекта, они не алгоритмизируемы, и, собственно, всё равно что-то останется для человека. Если Грета Товоровски есть здесь, то, может быть, уточните ваш вопрос. 

S03 [01:36:17]  : Мне кажется, я знаю. Это вот Роджер Пенрос, по-моему, говорит, что человек может решить вот там холтинг-проблемы, другие нерешаемые проблемы. Если это об этом речь, то это интересный вопрос. конкретные проблемы, которые нерешимы человеком, но нерешимы. Вот мне было интересно вот эта разница между General Intelligence и General Human Intelligence. Там есть конкретные примеры. Ян Ли Кун дает несколько примеров. Я об этом говорю. Единственное, что я мог придумать, вот для чего нужен человек, что не может сделать искусственный интеллект без человека, это именно вот спросить А как тебе вот это вот, как оно чувствуется для человека? То есть если у него стопроцентная правильная модель человека существует, тогда человек не нужен, но эта модель и есть человек, она стопроцентно правильная. Если этой модели нет, тогда вот юзер-тестинг надо делать на настоящем человеке. Вот тебе нравится или не нравится? Это может ответить только настоящий человек. 

S01 [01:37:20]  : Ну а как, например, насчет творчества? 

S03 [01:37:24]  : Это самое простое. Творчество, современное искусство – это можно за две минуты наляпать. Господи. 

S01 [01:37:29]  : Нет. Творчество – это извлечение чего-то принципиально нового из ничего. Это настоящее творчество. 

S03 [01:37:37]  : Но это человек делает как? Человек сидит, думает, вдруг ему приходит вот идея, он делает один. Искусственный интеллект может просто все проверить, выбрать самые лучшие и дать пять оптимально лучших. 

S01 [01:37:49]  : Да, но он проверяет из вариантов известных, которые у него есть. А откуда он берет эти известные варианты? Опять же из сознания человечества, пусть даже совокупного, но все равно из известных вещей. Создание новых парадигм, например, это творчество. Может ли искусство способить на такой искусственный интеллект? 

S03 [01:38:17]  : Ну вот есть туринг-тесты, ограниченные дисциплины в стихах, в картинах, в музыке и везде прошли. Люди не могут отличить, если это композитор или искусственный интеллект. 

S01 [01:38:28]  : Не могут отличить, это не значит, что это достоверный тест. Просто можно найти тесты более актульные, в которых человек сможет различить. 

S03 [01:38:45]  : Я в искусстве разбираюсь намного хуже, я сейчас не скажу. 

S01 [01:38:48]  : Это не имеет значения. Вопрос в том вот, то есть, мне просто интересно, вот как вы отвечаете на этот вопрос? Существуют ли области принципиально не алгоритмизируемые? 

S03 [01:39:03]  : Ну есть вещи, которые мы не понимаем, что они значат, и мы говорим, что это для людей. Вот там «любить», да, вот «любовь» — это человеческое, «компьютер», что он там понимает в любви. Я не знаю, как это инженерно описать, поэтому я соглашусь. 

S06 [01:39:21]  : Коллеги, можно я один комментарий вставлю? У меня буквально недавно была дискуссия по поводу творчества. И по поводу того, могут ли нейронные сети заниматься творчеством, я бы сказал так, что нейронная сеть, безусловно, может создавать оригинальные произведения, базируясь, правда, при этом на большом количестве мобилированных других вещей. Но я лично вижу в творчестве человека выражение его внутренней позиции, внутренних ощущений, вот этих самых феноменологических переживаний, о которых мы говорим, вот этих квалия. Если, допустим, у меня есть некоторое внутреннее чувство симфонии Моссорта, и я хочу ее нарисовать, то я буду пытаться выразить свое ощущение доступными мне образными средствами. Пусть я не очень хороший художник, но я как-то это нарисую. Это как бы выплеск какой-то части меня на холст. В этом смысле, как я вижу, пока в нейронной сети, в любой нашей модели искусственного интеллекта нет вот этого внутреннего субъекта, который как бы себя может выплеснуть в этом ощущении. Это пока остается на уровне как бы хорошего компилятора из разных частей. Он может быть гениальный компилятор. Некоторые картины Сальвадора Дали у меня иногда впечатления прям вот комбинатора возникает. Ну, может, я не его любитель. Согласна. Да. Ну, вот я бы как-то так сказал бы. 

S01 [01:41:04]  : Ну, то есть это, в принципе, вот тип творчества, который идет на основе, опять же, известных каких-то вещей. И в принципе он моделируем. А, допустим, такие вещи, как создание новых парадигм науки или искусства. Вот теория относительности, например. 

S06 [01:41:36]  : не каждый человек может теорию относительности написать. В этом плане миллиарды людей точно так же, как и искусственный человек, не могут этого сделать. Мне кажется, здесь принципиальный вопрос не оригинальность, не компилированность, а именно присутствует ли в этом кто-то, кто как бы пытается себя выразить через это. Вот у Пелевина на эту тему в одном из последних книг, которые блестящее, конечно, рассуждение вот насчет этого искусственного интеллекта, который там рвется наружу. Роман, не знаю, вы читали Пелевину? 

S01 [01:42:12]  : Я очень много читаю, но именно это я не смотрела. Как это называется? Читайте, я напишу сейчас в чат. 

S05 [01:42:22]  : Коллеги, а можно все-таки вот я еще Роману вопрос задам? Вот мне не дает покоя проблема добра и зла. Вот банальный вопрос, Роман, что вы думаете по поводу законов Айзека Азимова вообще и применимости их на данном уровне развития технологий, ну и применительно, в частности, к, допустим, тем же самым self-driving vehicles? 

S03 [01:42:54]  : Ну он писал же книги, чтобы было интересно, то есть он сделал дизайн этих законов, чтобы они всегда не срабатывали. Если вы читали книги, вы помните, это никогда не получается. Они плохо объясняют, что это значит safe, что значит человек, что значит там все элементы не объяснены, между законами есть какие-то contradictions. это гарантированно не сработает, если просто вот, как бы, вписать эти законы, это на уровне, ну, я не знаю, 10 заповедей, да, вот взять и вот все, 10 заповедей есть, теперь живем нормально, без преступлений. Можно увеличить количество законов, тоже ничего не изменится. У тебя адвокат, самый умный адвокат в мире, и шанс, что он там не найдет какие-то лазейки, просто нулевой. Мне очень понравился вопрос про искусство. Я еще пару слов скажу. Вы говорите, когда это искусство, вы его чувствуете прямо, что пытался сказать художник или поэт. Но ведь это не в картине. Это именно та иллюзия, где вы видите этот красный квадрат. Его там нет. У Ася рядом видит совершенно другой синий квадрат. И вот искусственный интеллект сегодня, он может это делать, где люди читают это стихотворение и говорят, вот точно человек писал, я прямо чувствую. Музыка то же самое. Это не новизна, это не новое. Так все же человеческое старое. Нет ни одного нового фильма, ни одной картины новой. Все рисуют цветы те же фильмы про убийство. То есть, почему такой двойной стандарт? 

S06 [01:44:34]  : Нет, нет, Роман, мой тезис был в том, что художник сам, когда рисует, это как бы выражение моей субъектности. Вот я когда рисую, я себя выражаю. Вы абсолютно правы, что когда я смотрю на картину, я вижу в ней то, что во мне отзеркаливает. И в этом смысле я с вами абсолютно согласен, что модель, которую мы строим, будет видеть в ней что-то свое, в ней будет что-то свое отзеркаливать. И это колоссально интересно, то, что вы говорите по поводу иллюзии, то что она смотрит на какую-то картинку и видит там акулу, а в ней возникает эта акула, а мы ее не видим. Это вот в ней как бы такие отголоски очень интересные. Я говорю скорее как бы про другую часть, именно про то, когда она, акт творчества это не акт восприятия, а это акт создания. И я пока не вижу, чтобы... Те примеры, которые я видел, очень симпатичные картины, очень симпатичная музыка, но ведь это же не акт самовыражения, это не акт творчества пока. 

S03 [01:45:36]  : Я с вами полностью согласен, это именно так. Но когда я слышу слово «искусство», я думаю о музее, я думаю о покупке картины. Я не встречаюсь с художником и смотрю, как он там мучается. Эта часть закрыта, если это старинная картина да Винчи. Я даже не знаю, кого он там рисовал и почему, он смеялся над ней или веселился. Мне это все неизвестно. Я вижу искусство, картина висит, и вот насколько она оригинальна, насколько она вызывает во мне чувство. Если искусственный интеллект может сделать так, что я... О! Обалденно! Надо дать за это кредит, правильно? 

S06 [01:46:12]  : Это правда, да. Это правда. 

S05 [01:46:19]  : Роман, по поводу добра и зла все-таки не могу успокоиться. Хорошо. Вы, кстати, очень интересную вещь сказали, что там народ ломает копья по поводу того, что законы робототехники не работают, а Зимовские. А он типа не предполагал, что они должны работать, что он сделал их просто, чтобы интересно было. Ну хорошо, но нам же что-то с этим надо делать, то есть нам каким-то образом нужно обеспечить какие-то либо правила, либо какие-то политики, либо какие-то алгоритмические рамки, в которых будут вот эти самые роботы на производстве с людьми взаимодействовать, машины будут там по улицам ездить, полных пешеходов. То есть, вот что в этой ситуации сделать, чтобы управлять риском? Ну, я просто приведу пример, так сказать, есть же там, кроме человеческого общества, там есть правила для экстремальных ситуаций, например, когда корабль тонет, первым покидают женщины и дети. Соответственно, нужны какие-то правила такого порядка для машин в случае экстремальных ситуаций на улицах, когда форс-мажорная ситуация? 

S03 [01:47:34]  : Это в принципе не важно. Мы можем придумать любой набор таких правил. Я инженер, вы мне скажите, что вы хотите. Спасаем только женщин, спасаем только китайцев. Пожалуйста, можем сделать как угодно, но надо, чтобы все с этим согласились, чтобы это было как бы универсально, иначе вот я еду на машине, здесь она этих убивает, переехал в Канаду, она тех убивать начала. Сюрприз будет. 

S05 [01:47:59]  : Нужны правила или все-таки нужны системы ценностей? Или нужно обучение? Варианты же разные. Мы же можем просто систему воспитывать в каком-то человеческом обществе, чтобы она училась нашим ценностям, а потом, когда она научилась нашим ценностям, мы ее мозг растиражировали на тысячи устройств, и все устройства живут с этими ценностями. 

S03 [01:48:21]  : Проблема слова «наши ценности». У нас нет «наших ценностей». У вас есть ценности, у меня есть ценности, у всех есть ценности. Глобально мы не согласны почти ни о чем. Мы можем согласиться о чем-то редко и временно. В этом проблема. 

S05 [01:48:38]  : Ну а как быть? Какой выход? Как нам обеспечить выход этих самых self-driving vehicles на улице? 

S03 [01:48:45]  : Ну а там на самом деле все гораздо проще. Вот эта ситуация, где надо выбросить, там сбить толстую женщину или пять инвалидов, это никогда не случается. Я никогда так не выбирал. Я вожу 20 лет без проблем. То есть это философская проблема. С машинами проблем не будет. Там надо просто вовремя затормозить, никого не сбить. Проблемы начинаются, когда система умнее нас и решает смысл жизни за нас. 

S05 [01:49:13]  : Спасибо. Коллеги, есть ещё вопросы к Роману? Так, здесь есть ремарки. «Добро и зло. У сильного ИИ будет свобода воли. Он найдёт способ обойти любые ограничения. Правила он сам установит для себя». Да, кстати, вот тоже есть такая мысль, что что бы мы ни заложили, если это будет сильный ИИ, в какой-то момент он начнёт сам себе устанавливать правила. 

S03 [01:49:40]  : Ну, в этом и есть опасность. То есть, есть теория, что главное это снизить количество боли во Вселенной. И самый лучший способ сделать, всех убить быстренько, и тогда никому не больно. 

S05 [01:49:58]  : Хорошо. Коллеги, еще есть вопросы к Роману? Роман, огромное спасибо. Было очень интересно. Мы обсудили нашу тему в самых разных аспектах. 

S03 [01:50:14]  : Спасибо вам за приглашение. Получил огромное удовольствие. 

S05 [01:50:18]  : Привет американскому континенту. 

S03 [01:50:21]  : Передам. 

S05 [01:50:22]  : Всего доброго. До свидания, коллеги. До свидания. Спасибо, Роман. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
