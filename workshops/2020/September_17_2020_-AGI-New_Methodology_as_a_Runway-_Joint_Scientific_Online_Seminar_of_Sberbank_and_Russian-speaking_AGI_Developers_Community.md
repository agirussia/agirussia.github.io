## 17 сентября 2020 - AGI - Новая методология как взлетная полоса? - Cовместный научный онлайн-семинар Сбербанка и русскоязычного сообщества разработчиков AGI
[![Watch the video](https://img.youtube.com/vi/ZLW7dseY_Uo/hqdefault.jpg)](https://https://youtu.be/ZLW7dseY_Uo)


Суммаризация семинара:

еминар был посвящен теме Искусственного Гениальностного Интеллекта (AGI) и новых подходах в разработке AGI.

Организация

- Семинар организован в формате с три доклада, каждое из которых длилось 20-30 минут, с последующим обсуждением и ответами на вопросы.
- Организаторы старались отвечать на вопросы участников в процессе выступления докладчиков.
- В конце каждого доклада выступающий прокомментировал интересные вопросы.
- Участникам предложено задавать вопросы в чате, где также был размещен опросник для сбора обратной связи.

Важные моменты

- Ксения Кузнецова поделилась информацией о том, как будет организована коммуникация в рамках семинара SberScience.
- Альберт Ефимов рассказал о создании сообщества AGI в России, подчеркнув необходимость объединения усилий и обсуждения проблем AGI.
- Андрей Черток, Татьяна Шаврина и Дмитрий Салихов обсудили использование метрик, бейзлайнов и тест-драйвен-девелопмент в разработке AGI.
- Сергей Марков представил доклад о roadmap к roadmap или дорожной карте к дорожной карте, связанной с универсальным искусственным интеллектом.

Ключевые концепции

- Принципы измеримости прогресса на пути к AGI и использование метрик, бейзлайнов.
- Разработка общих интеллектуальных способностей машин, сравнение подходов когнитивизма и конъюнкционизма.
- Проблемы и перспективы создания универсального искусственного интеллекта.
- Вопросы об оптимальном дизайне метрик для оценки интеллектуальных способностей машин.
- Размышления о необходимости полновесных причинно-следственных связей в машинном интеллекте.




S10 [00:00:02]  : Здравствуйте, уважаемые коллеги. Занимайте ваши места согласно виртуальным билетам. В нашем виртуальном конференц-зале сегодняшний рейс в будущее сильного искусственного интеллекта выполняется совместно клубом «Лекториям с биосайенс» и русскоязычным сообществом разработчиков AGI, то бишь Artificial General Intelligence или Общий Искусственный Интеллект. также известный как Сильный Интеллект, при поддержке проектов EIGENS, Singularity Net Foundation, Новосибирского Государственного Университета, Сбербанк Innovation & Research и Сбер.Ай. Онлайн-семинары нашего сообщества проводятся по четвергам в это же самое время. Следующий четверг у нас будет интересная встреча. Будет выступать ведущий мировой специалист по вопросам безопасности искусственного интеллекта и один из ведущих русскоязычных мировых специалистов области искусственного интеллекта Роман Ямпольский. А сегодня индивидуальный интеллект разработчиков AGI будет представлен коллективным интеллектом группы подразделений Сбербанка и нам расскажут и Альберт Ефимов о том, что нас ждет на новом рубеже тестирования искусственного интеллекта, когда Тюринг-тест уже не работает, когда тут Тюринг-тест формально пройден, какие нас ждут рубежи методологические обеспечения верификации уровня интеллекта, достигнутого системами искусственного интеллекта и интеллектуальной робототехники. Потом Сергей Марков расскажет нам, как строить или создавать дорожную карту к дорожной карте и вообще, значит, насколько AGI может быть манхэттенским проектом и насколько скоро это произойдет. Ну и, наконец, на сладкое Андрей Черток, Татьяна Шаврина и Дмитрий Салихов. расскажут нам, как на пути к светлому будущему обложиться метриками, бейзлайнами и, может быть, даже какими-то элементами тест-дривен-девелопинг. Пожалуйста, даю слово сейчас Ксении Кузнецовой. Ксения, по регламенту скажите, пожалуйста. 

S02 [00:02:40]  : Спасибо за предоставление площадки. Для нашего формата коммуникации SberScience об этом расскажет чуть позже Альберт Ефимов. Я бы хотела немножко рассказать про то, как сегодня будет организационно выстроен наш семинар. Три доклада, 20-30 минут на выступление, 15-20 минут на обсуждение, ответы на вопросы. Вы можете задавать вопросы в чате. Собственно, первый вопрос уже был задан, и на него даже получен ответ, что же такое AGI. Мы будем в процессе стараться отвечать, в выступлении докладчиков стараться отвечать на те вопросы, на которые мы можем ответить. Ну, конечно же, в конце своего выступления каждый из выступающих прокомментирует наиболее интересный вопрос. Конечно, нам интересно, чтобы это было не просто выступление блестящих команд Собербанка, которые поделятся своими мыслями и наработками, но максимально активное ваше, коллеги, участие. Поэтому, пожалуйста, не стесняйтесь, задавайте свои вопросы. мы будем рады, если сложится острая интересная дискуссия, ибо только в споре и дискуссии рождается отлично. Также в конце мы предложим вам, нам, организаторам подобных мероприятий, стать лучше и потратить буквально несколько минут на ответы на вопросы. Ссылку на опросника я размещу в чате. Собственно, передаю слово нашему первому докладчику, Альберту Ефимову. 

S05 [00:04:24]  : Альберт? Сначала меня Ксения Александровна попросила рассказать про SberScience. Почему я попросил Антона пустить нас в сообщество? общество AGI, потому что мне показалось, что нас в России настолько мало, в том смысле тех, кто мечтает про AGI, что нам нужно как-то объединять свои усилия и попытаться развиваться вместе и вместе обсуждать. Но сообщество SberScience предназначено не только для того, чтобы ну ты и Сбербанк обсуждать какую-то сбербанковскую науку. Никакой сбербанковской науки, конечно же, не существует, она общая, вообще мировая. Но мы стараемся наладить между нашими собственными исследовательскими группами, которые очень разные, междисциплинарный обмен, который помогает нам формировать новые точки роста, обмена идей. И вот это для нас очень важно. И мы надеемся, что аудитория, которая сейчас здесь присутствует, я вижу здесь и сотрудников наших любимых лабораторий. Я вижу здесь и инженера Сбербанка, я вижу здесь и сообщество AGI. Ребята, добрый вечер всем. Мы на самом деле верим в то, что в этом взаимодействии, междисциплинарном, межотраслевом, каким угодно, рождается то, что нам впоследствии может быть станет для нас чем-то очень важным, работой, что-то еще. Антон сказал, что это сообщество разработчиков AGI. Вот здесь мне просто хотелось сказать, что я точно совершенно не разработчик AGI. и не отношу себя к таким. И я не уверен, что вообще они существуют сейчас, разработчики GI, потому что до стадии D, то есть Development, это еще не дошло. Мне кажется, это находится на стадии такого очень глубокого R, причем с пересечениями с M, то есть мечтаниями. Поэтому давайте будем, может быть, более смелы в том, что мы делаем, потому что, мне кажется, это еще не до конца все-таки наша разработка. То, что я сейчас представляю, ни в коем случае не относится ни к математике, ни к программированию, ни к робототехнике, хотя в некоторой степени опирается на тот опыт, который я получил за предыдущие несколько лет. Я назвал свою презентацию «Постьюинговая методология интеллектуальной робототехники», потому что это почти так же звучит, как тема моей диссертации, и некоторые вещи которые я сейчас буду говорить, они озвучиваются в диссертации, но не все. Просто с целью того, чтобы окончательно не уйти в очень глубокую и, мне кажется, никому не нужную философию. Так, попробую сейчас запустить презентацию. Большинство из присутствующих незнакомы со мной, точно так же, как я незнаком с вами, поэтому кратко все-таки позволю себе потратить время на то, чтобы представиться. В 92 году я закончил факультет кибернетики по специальности прикладная математика, инженер-математик. Судьба забросила меня в Шотландию, где я в 2002 году получал, имея по стипендию Ее Величества, королеву Великобритании, Когда работал в Сколково, я учился в аспирантуе и меморан, и несколько статей по экономике сделал. Сейчас, мне кажется, я близок к финалу, к тому, чтобы защитить, наконец, диссертацию в институте философии РАН, постюинговой методологии интеллектуальной робототехники. Тема робототехники мне очень близка, примерно с 2012 года, то есть вообще жуть какая, 8 лет, наверное, занимаюсь этим практически беспрерывно. Начиная с Imperial College of London, где прошел стажировку, и заканчивая роботехническим центром Сколково, где многих из вас встретил, роботехническим центром Сбербанка. где у нас прекрасная команда сложилась. Важно отметить, что сейчас я заведующий кафедрой инженерной кибернетики МИСИС, прикладная математика, примерно 300-400 бакалавров. Это прекрасная наша молодежь, которая составляет нашу кадровую основу. Если кому интересно, то в интернете можно найти статьи. Что важно в современном искусственном интеллекте? Перефразируя шестого патриарха Чань Буддизма, Линзы, то можно сказать, что если вы встретили новость про искусственный интеллект, то не надо, конечно, убивать этот искусственный интеллект, но следует задать себе вопрос. Потому что от того, какие нам поступают ответы, очень, на самом деле, серьезно зависит наша дальнейшая работа. Если убрать аетоику, то в конце концов, какую же именно задачу решил тот искусственный интеллект, которым нам рассказывают в интернете, по телевизору, я не знаю, или просто друзья на очередной конференции? А насколько общим является такое решение? Задачи чтения и понимания текста, они как-то совпадают с его минимальным содержанием или нет? То есть это на самом деле очень серьезная штука, особенно в свете вот этих всех вещей, связанных с GPT. Есть ли демонстрация этого решения? Стоит ему верить или нет? Опять же, возвращаясь к GPT-3, внимательно посмотрел, возможно, как и многие из вас, самая известная демонстрация этих решений, и очень многие оказываются у них с закрытыми дверями. Если заявляется, что искусственный интеллект решает задачу лучше, чем человек, то что это за человек? Насколько лучше искусственный интеллект, чем человек? Это известный кейс Евгения Гусмановича от BOTA, который победил в тесте Тьюинга 2014 года, и он имитировал, прямо скажем, довольно примитивного подростка. Насколько успешность данного решения продвигает задачу общего искусственного интеллекта? Это тоже, на самом деле, очень важный вопрос, потому что оказывается, что очень многие разработки, связанные с так называемым искусственным интеллектом, не сильно продвигают общий искусственный интеллект. Ну и последнее, самое важное, то, что подвигает нас к той теме, о которой я говорю, это насколько надежна система искусственного интеллекта, а может ли она работать с разными датасетами без дополнительного обучения. Программа, побеждающая в шахматы, может играть в нарды? Может ли программа, которая распознает животных, коэктор распознавать животных, которые раньше не видела? Иными словами, программа, которая натренировалась на котиков, собаку поймет? Может ли беспилотник, который обучали ездить днем, начать ездить ночью или зимой? Ответ – нет. Пока. В целом есть три пути к созданию искусственного интеллекта. Когнитивизм – это репрезентация окружающего мира. Это старый добрый искусственный интеллект, который развивается уже практически 70 лет. Второй способ – это коннекционизм. Это имитация естественного интеллекта. Это искусственные нейронные сети, которые работают где-то подобно естественному интеллекту. И третье – это воплощенный искусственный интеллект. Мы говорим о том, что искусственный интеллект невозможно создать без тела. Потому что только интеллект, это всего лишь мозги в бочке, и без соединения с внешними ощущениями мы не можем получить необходимую нам информацию о внешнем мире и обучать искусственный интеллект. Большинству из вас, конечно, знакомо это. Фотография — это вычислители или компьютеры, потому что всего лишь 70 лет назад это было должностью в банках корпорации, где-то еще, не знаю, были громадные залы вот как вот этих вычислителей. И бумажная работа, которую делали эти вычислители, она натолкнула Алана Тьюинга на то, что Можно ли вообще поставить вопрос, если мы называем интеллектуальную работу человека, если мы можем ее автоматизировать с точки зрения математики, математические операции автоматизировать, то можно ли поставить вопрос, может ли машина думать? Вы помните, это примерно 50-й год, известная статья Алана Тьюинга. И напоминаю, через месяц мы будем праздновать юбилей опубликование этой статьи. То есть это октябрь 1950 года. 70 лет прошло с момента публикации этой статьи. Октябрь. Поэтому мне кажется, Антон, вам нужно провести юбилейный семинар, посвященный 70-летию этой знаменитой философской математической логической статьи. Но история, связанная с Ауэном Тьюингом, она не только замыкается на его статью, она уходит чуть-чуть глубже в Клуб Рацио, который начал свою работу в 1945 году и примерно существовал 10 лет. Ауэн Тьюинга вы можете увидеть сидящим слева. Клуб Рацио собирал такую элиту байтанской науки, они собирались примерно раз в месяц, иногда реже, и обсуждали самые невероятные вопросы от искусственного интеллекта, робототехники, тогда таких слов не было, но это обсуждалось, до нейронаук, естественного интеллекта и даже телепатии. Значит, Антон, мне кажется, вот ваше сообщество, может быть, наше сообщество, мы должны стремиться к тому, чтобы создать вот этот самый клуб-рацию, в котором мы что-то докладываем, какие-то интересные вещи, а потом вместе пообедаем. Может быть, в какой-то момент мы к этому пойдем тоже. Интересно, что американо-британский изобретатель Уолтер Грей со своими черепашками, я уверен, что многие знают об этом, я не буду сейчас рассказывать эту историю, он был тоже членом этого клуба «Рацию», и после публикации своей статьи в 1950 году, мне кажется, выставка, на которой Уолтер Грей показывал этих черепашек, была на несколько месяцев позже, чуть ли не декабрь 1950 года, И Ауэн Тьюинг вернулся после этой выставки в глубочайшем восторге. Он по связи со своими линиями испытывал очень большой энтузиазм именно к тому, что показывал Уолтер Грей и тех черепашек, потому что вы помните, да, у них вот два нейрона. Они были в очень несложном устройстве. Если кто-то хочет увидеть то, как они были устроены, то в Политехническом музее, собственно говоря, есть советская копия этих черепашек, которая была создана примерно на 10 лет позже. В своей статье 1950 года Аллен Тьюинг указал, что интеллектуальные активности настоящего джентльмена Это математика, криптография, лингвистические изыскания, переводы с одного языка на другой и разнообразные настольные игры. Хокер, бейт, шахматы, крестики, нольги. Он просто гони упомянул, потому что, возможно, это не была самая популярная игра в Британии на тот момент. Ноуант Юинг также упомянул, что активности обычных людей включают в себя, безусловно, наслаждение едой, спортом Любовью. Я не стану углубляться в детали теста Тьюинга, потому что я уверен, все, кто здесь присутствуют, с ним знакомы, возможно, некоторые даже лучше, чем я, но хочется указать на несколько элементов этого теста. Прежде всего, конечно, три участника. Это компьютер, человек и судья, который оценивает, кто же перед ним, кто где перед ним. Но вот этот четвертый участник этого теста, он все время оставался как-то не то что незамеченным, но никто не акцентировал на него внимание. Это стена, которая разделяет всех участников. И мне показалось очень важным, что мы отмечаем именно эту стену, потому что эта стена, возможно, является одним из фундаментальных препятствий на пути развития общего искусственного интеллекта. Во время Ауна Тьюинга интеллектуальная робототехника, вообще робототехника, слов робот существовал, но Тьюинг его не употреблял, и его еще не употребляли довольно долго. Но вот эти создания, которые могут бродить по полям старой доброй Англии, вызывали безусловно такой трепет очень серьезный, ну не дай бог вообще кто-то создать действительно такого робота, управляемого телекамерами, как считал Тьюинг, он нанесет кучу вреда. Почему? Потому что технологий в то время вообще не существовало. И это очень наверное, расстраивало тогдашних исследователей, потому что они хотели, так же, как мы сейчас, видеть замечательных роботов, которые похожи на человека, делают примерно то же, как и описано в рассказах о языке Азимова, а получали мы только вот такие железные уродливые чудовища. Если честно, мне кажется, современные робототехники тоже не сильно сделали шаг вперед по сравнению с этим. И эта мысль, она меня навела на то, что на самом деле существует такое пространство, я называю пространство Тьюингом. Оно состоит из четырех плоскостей. Это невербальное и вербальное взаимодействие, и виртуальный мир, и физический мир. Если посмотреть, то вы увидите, что то, что предлагал Аон Тьюинг, оно на самом деле находится вот ровно в этом, назовем так, области пространства. У меня есть особое название для этого, но пока я повременю с этим. Значит, все, что предлагал Тьюинг, достойного для интеллектуальных думающих машин, находится в пространстве виртуального мира вербального взаимодействия. И он как бы проигнорировал все остальные пространства. И проигнорировал совершенно сознательно, потому что, банально, технологий в тот момент еще не было. Но так ли это сейчас? Вполне возможно, что технологии, которые предназначены для взаимодействия в остальных, назовем так, кьюинговых пространствах, они существуют. Известное очень высказывание Венчурного финансиста, создателя Netscape, software is eating the world. Мне кажется, software, программное обеспечение, eating не только world, оно eating на завтрак роботов, на обед культуру, на ужин знания. Что это значит? Это не шахматная программа Deep Blue победила Каспарова в 1997 году. Это шахматная культура, которая была съедена программным обеспечением Deep Blue, победила у Каспарова. Потому что если бы не было шахматной культуры и всех тех тысяч, десятков тысяч партий, которые были записаны в память суперкомпьютера Deep Blue, которые позволяли ему отыскивать более оптимальные ходы, то на самом деле вряд ли бы суперкомпьютер сумел победить. Программное обеспечение поедает культуру на обед, потому что у нас появляется мир полный дипфейков. На самом деле, мы должны быть готовы не к тому, что у нас мир полный дипфейков, а мир полностью состоит из дипфейков, и нам еще нужно будет научиться различать истину и ложь. И культура может вполне себе разделить участь программного обеспечения. И последнее, это, конечно же, победа Альфа-Го и Альфа-Го зеро в соревновании с Олямко. Штука в том, что здесь вообще произошло следующее. Это не то, что AlphaGo, оно инкорпорировало культуру Go. Оно переизобрело культуру Go. Оно полностью ее симулировало. Все 5000 лет истории Go были симулированы, мне кажется, за несколько дней с помощью этого компьютера. В Сбербанке мы Работаем над разными технологиями. Одна из технологий, созданных в одной из наших лабораторий, лаборатории робототехники, это цифровой аватар. Мы не были первыми, кто в мире это сделал, мы были вторыми, что иногда тоже хорошо. Женщина, которая говорит только то, что ей напишут. Правда, сейчас она говорит еще много чего другого, еще двигается вдобавок. Но, тем не менее, этот цифровой аватар, будучи объединенным с говорящей машиной, которая стоит за ней, то есть чат-ботом, может быть фактически полностью не отличим от человека. Да, конечно, сейчас этот цифровой аватар иногда путает звуки. Иногда видно, что это не настоящая женщина, но это очень временные вещи. Очень скоро это будет в режиме онлайн, это будет в режиме таком, что она будет двигаться, делать совершенно невероятные вещи. И это я сейчас не говорю про продуктовую линейку Сбербанка. У всех кто-то хочет это сделать и потратить на это определенное количество денег. Возвращаемся назад к той стене, которая воздвигала онтюинг. И кажется, что именно эта стена нам мешает взаимодействовать с роботом так, чтобы увеличивать эффективность этого взаимодействия. Вполне возможно, подлинная коллаборация, подлинное взаимодействие с роботом и человеком как раз и заключается не в том, что робот действует лучше, чем человек в какой-то среде, а робот может действовать совместно с человеком в определенной среде. Возвращаюсь к пространству Тьюинга. За 70 лет существования методологии, тьюинговой методологии, возникло громадное количество тестов. Тест Колби, тест Ады Лавлис, китайская комната Серли, которую тоже можно отчасти отнести к тестам, схема винограда, тест Шеннона, тест Ватта, тест Фрэнча и так далее. Их очень много. Даже на основе нашего цифрового аватара Гелена я тоже придумал какой-то тест. Кто лучше читает, человек или робот? Но на самом деле тестов, которые могли бы охватить все четы вот этих тюинговых пространств, к моему глубочайшему удивлению, их не было. За исключением только одного. Предложенный Родни Бруксом тест ребенка, он отчасти отвечает на этот вопрос. Родни Брукс, известный робототехник, один из создателей iRobot, в том числе и пылесосов, предложил следующее, а почему бы нам не сопоставлять роботов с развивающимся ребенком. Распознавание объектов должно быть на уровне двухлетки, распознавание языка, понимание языка должно быть на уровне четырехлетнего ребенка, манипуляции объектами на уровне шестилетнего ребенка, а социальные навыки, понимание взаимодействия, в том числе социального взаимодействия должно быть на уровне восьмилетнего ребенка. Это очень хорошо ложится на тест Бэби Тьюинга. Мне кажется, у Антона прекрасная статья была на эту тему. Но это чуть-чуть шея, потому что это охватывает полностью все эти сферы вербального, невербального, физического, нефизического, о которых я уже говорил. Другим тестом, похожим на эту методологию, является тест Харнада. который ввел, по сути дела, пять уровней различимости и неразличимости человека, и на пятом уровне неразличимости Харнада – это просто робот, который до атомной структуры копирует человека. На мой взгляд, это чуть-чуть в области научной фантастики пока, но, тем не менее, Мне кажется, что нам не хватает тестов, которые могли бы охватить полностью весь этот круг. Кстати, здесь очень важно, что в другие области тюнингового пространства ложатся те вещи, которые не очевидны были для тех, кто следует тюнинговой методологии. Например, конкурсы по распознаванию или синтезу голоса, распознаванию изображений. Это, по сути дела, взаимодействие в виртуальном мире невербальное. Вот здесь пример схемы винограда. Дата-сайентисты любят рассматривать модели, потому что они полные. Вопрос, кто полные? Модели или дата-сайентисты? Значит, пример из реальной жизни. Должность не проходит в штатку, потому что она слишком высокая. Кто слишком высокий? Штатка или должность? И так далее, и так далее. Я думаю, что вы сами знаете массу подобных примеров. Значит, возвращаясь к своему любимому пространству Тьюинга. Эти области я назвал техноумвельтами. Я, наверное, сейчас не буду останавливаться прямо на понятие умвельта, потому что это из биосимметрики, чуть-чуть реформировал это понятие техноумвельта, но мне кажется, что взаимодействие между этими разными областями, техноумвельтами, которые я обозначил, и созданием роботов, а точнее когнитивных архитектур, которые будут делать роботов способными перемещаться между этими техноумвельтами, в этом и есть задача создания общего искусственного интеллекта, который может решать задачу сходным широким образом, возможно лучше, двигаясь между разными средами. А это и есть разные среды. Вести разработки искусственного интеллекта без развития манипуляций физическими и невербальных коммуникаций с человеком, на мой взгляд, практически невозможно. Завершающий слайд — это из интервью Криса Урмсона, руководителя беспилотной программы в Google. А когда появятся беспилотные автомобили? Это реально? Ответ руководителя этой программы в Google — да, это может случиться. Думаю, что в ближайшие пять лет вы увидите мелкомасштабный проект, а затем в течение следующих 30-50 лет поедут настоящие беспилотники. Почему это так? Потому что в отличие от компьютера, робота, человек может работать с риском. Если мы не учим компьютер работать с таким риском, то есть с лайфкритикой, с системами на уровне не хуже, чем человек в различных средах, то мы никогда не получим AGI. Его невозможно получить на настольных играх, потому что мы получаем всегда только мозги в бочке. Пользуясь случаем, не забывайте поставить, пожалуйста, в вашу календарь Artificial Intelligence Journey, которая начнется 20-22 ноября. Сбербанк проводит замечательное мероприятие. Я надеюсь, что все, кто здесь присутствует, будут в нем участвовать. И последнее. Еще раз повторяю, мой вывод — это устранение стены Тьюинга позволяет нам закрепить ведущую роль человека в развитии технологий и перейти от слепого сравнения действий человека и машины к эффективной коллаборации, совместному решению актуальных проблем создания общего искусственного интеллекта. Спасибо большое. Наверное, несколько вопросов. 

S02 [00:29:02]  : Как минимум, есть один вопрос. Чем Ваш подход отличается от Алексея в АЮ? Философия искусственного интеллекта, концептуальный статус, комплексного теста Тюринга 2016 года. 

S05 [00:29:16]  : Андрей Юрьевич является тем человеком, который, когда первый раз я ему несколько лет рассказал о вот этих сейчас идеях, он меня просто заставил все это класть на бумагу. Несколько важных отличий. Первое, это Андрей Юрьевич выписал все тесты. Он сделал это больше десяти лет назад. Я чуть-чуть обновил список и добавил туда намного большего количества робототехники. Но помимо этого, вот эти оси, которые я сказал, вербальное, невербальное, физическое, виртуальное, они остались вне внимания Андрея Юрьевича. И это отчасти вот эта типология, это некая новизна по сравнению с тем, что он сделал. Хотя, да, это, наверное, для меня один из цитируемых источников в моих исследованиях. Значит, второе – это то, что осталось вне его внимания – это стена Тьюинга. Несмотря на то, что он комплексно разобрал тест Юинга, он его разбирал скорее с позиции операционализма. И само по себе взаимодействие человека и машины, оно просто вне спектра его исследований, тогда как в моем исследовании оно является фокусом. Вот два принципиальных отличия. Есть еще некая терминологическая разница, но, мне кажется, сейчас. 

S10 [00:30:45]  : по сути. А вот еще я увидел два вопроса, которые у меня тоже возникли. У вас был слайд в начале про три пути. Вот эти три пути, они являются взаимоисключающими, то есть в итоге нужно действовать по какому-то одному или это три необходимые компоненты и полноценное решение требует интеграции? 

S05 [00:31:08]  : Как человек, который в Сбербанке отвечает за синергии, я бы сказал, что нам нужно максимально запутать эти линии, потому что в какой-то момент истории искусственного интеллекта они все были разрублены. Значит, теперь люди, которые занимаются когнитивизмом, не дружат с теми, кто занимается коннекционизмом. А те, кто занимается воплощенным искусственным интеллектом, они одинаково опозираемы первыми и вторыми. Потому что это же роботы. Мне кажется, если мы говорим о серьезном подходе к общему искусственному интеллекту, мы должны собрать этот Гордиев узел и снова его завязать. Возможно, первый узел, который мы завяжем, не будет завязан правильно. Но, по-моему, общий консенсус сейчас всех таков, что одним подходом задачу не решить. Многие думают о том, что, наверное, два похода, когнитивизм и конъюнкционизм, достаточно. Я выражаю в этом сомнения, потому что объясните мне тогда, пожалуйста, каким образом клещ никакого обучения не проходит, но отлично нас кусает. потому что у нее есть тело. Это классический пример. 

S10 [00:32:38]  : Спасибо. Еще вопрос по поводу робота Елены. Какой стэк был использован для Елены? 

S02 [00:32:46]  : Мне кажется, мы это можем подрисовать следующему выступающему. 

S05 [00:32:51]  : Мне кажется, следующий выступающий... Да, смотрите, здесь очень важно. Я сейчас выступаю не с позиции Сбербанка. Я выступаю с... Ну, это моё личное исследование, за которое я ничего вообще не имею, кроме замечательной критики, которую я получаю от вас. Вот, это моё любительство, и в целом ничего другого мне не нужно за это. Значит, мне кажется, нам всем очень хорошо, если мы не будем превращать это в мастер-класс Сбербанка, я надеюсь, и Сергей, и Андрей, и Татьяна тоже прям очень хотят поделиться знаниями, но точно не хотят здесь выступать в качестве ну таких, каких-то старших менторов, которые пришли здесь поговорить там с обществом. Спаси нас Господь против этого. 

S02 [00:33:35]  : Альберт, тогда ответь, пожалуйста, еще на два вопроса. А Наталья просит озвучить 2-3 следствия из вывода данной презентации. 

S05 [00:33:48]  : Да, сейчас постараюсь. Значит, первое, когда мы оцениваем, вот прям очень простой вывод, скорее всего самодвижущую машину создать невозможно. То есть невозможно создать ту машину, которая будет ездить лучше, чем человек, согласно правилам дорожного движения. То есть это возможно, наверное, но будет бессмысленно и дорого. Скорее всего, нам нужно делать ту машину, которая будет вместе с человеком более безопасна, чем машина без человека. Это та концепция, которую сейчас продвигает, например, Toyota, называя своей системой ADAS ангелом-хранителем. Человек может находиться за рулем, но просто в машине есть такой ангел-хранитель, что он никогда не даст ему совершить аварию. Или она звучит с ней прировняемо. Значит, это первая важная вещь. И это устраняет стену тьюинга. Значит, это говорит о том, что эффективность взаимодействия в коллаборации человека и машины. И это то же самое, о чем говорит Илон Маск, когда создает свой интерфейс Neuralink, для того, чтобы объединить человека и машину. Но это, кстати, другой путь. Еще четвертый путь есть, да? Просто дырка в черебре и все. Значит, прямо скажем, это шорткат такой. Значит, это не факт, что он является правильным. Далее. Другое следствие. Когда мы говорим про методологию тестирования, то давайте подумаем, когда мы создаем новый тест Тьюинга, в каком из умвельтов Тьюинговых пространств он находится. И не решаем ли мы слишком частную задачу, вместо того, чтобы двигаться к общей задаче создания машины, робота, компьютера, программы, кого угодно, которая способна двигаться из одного пространства в другое пространство. Вот два вывода, которые прям, их на самом деле чуть больше, но как только автореферат диссертации будет опубликован, мне кажется, можно посмотреть. 

S02 [00:35:58]  : То есть ты всех адресуешь к своему автореферату? 

S05 [00:36:01]  : Ну, просто все перечислить невозможно, просили 2-3 следствия. Хорошо. Я бы попросил бы, может быть, кого-то записать эти вопросы. Здесь меня просят прокомментировать Янли Куна, но я даже не знаю, что сказать. Так, чем ваш подход рассказал? Видеоанимирование – что за инструмент? Что есть эффективность в этом контексте? Так, скажите про другие подходы, кроме нейросети и мейнстримеров. Сейчас расскажут вообще куда более специалисты, чем я. Так, как в кинзадзе женщину вынули в автоматах? 

S02 [00:36:51]  : Альберт, там нет больших вопросов, там есть комментарии. Я думаю, что мы тебя все поблагодарим за интересное выступление. 

S05 [00:37:06]  : Да, спасибо, что вообще все это сделали. 

S02 [00:37:11]  : Да, и Антон, представьте, пожалуйста, нашего следующего выступающего. 

S10 [00:37:17]  : Да, у нас сейчас Сергей Марков расскажет про roadmap к roadmap или дорожную карту к дорожной карте. 

S11 [00:37:27]  : Да, я сегодня расскажу довольно интересное статье, которая называется «Дорожная карта к дорожной карте». Когда мы поймем, что в действительности мы находимся от универсального или общего искусственного интеллекта на расстоянии манхэттенского проекта, Вначале несколько слов об авторах этой работы. Это на самом деле два довольно интересных аспиранта. Один из них, его зовут Джон Кларк Левин. Он занимается исследованием в Кембриджском университете под руководством профессора Дениса Грубе. И вообще-то говоря, Джон специалист по полисимейкингу, значит, он занимается политикой предвидения, технологиями прогнозирования, футуризмом политики, проблемами авторитаризма, морской безопасности внезапно, ну и на самом деле множеством проблем, которые связаны, собственно говоря, с государственной политикой в самых разных направлениях. и в частности в области технологий. Ну и его соавтор Матисс Масс, это тоже аспирант, но работающий в Центре международного права конфликтов и кризисов университета Копенгагена. И соответственно его областью исследований является стабильность ядерного сдерживания, секьюритизация и управление искусственным интеллектом. Ну вот, несмотря на то, что эти два человека еще молоды, тем не менее, заключаем каждого из них несколько книг, значит, и, скажем так, это люди, которые в известной степени влияют на сооружения, которые принимаются в расчет полисимейкерами. Но на самом деле, значит, статья начинается, конечно, с вопросов определений. Вот когда выступал здесь Альберт, я видел, что в чате были ремарки по поводу того, значит, одно и то же или не одно и то же. значит общий искусственный интеллект и сильный искусственный интеллект и так далее. Авторы используют в заголовке статьи термин artificial general intelligence, то что на русский язык традиционно переводится как общий искусственный интеллект или универсальный искусственный интеллект. Ну, разумеется, прежде чем о чем-то разговаривать, нужно понять, какой смысл мы вкладываем в определение, в противном случае спор, обсуждения могут быть бессмысленными. Поэтому авторы делают небольшой экскурс в терминологию, но на самом деле я сейчас в какой-то мере повторю их рассуждения. Когда мы говорим об искусственном интеллекте, мы знаем, что этот термин, так сказать, получил широкое хождение после Дартмовской конференции, и автором его считается Джон Маккарти. Есть, правда, некоторые, ну скажем так, спекуляции и размышления о том, что, вообще-то говоря, Маккарти обсуждал проблематику с Тьюрингом, и, в общем-то, значит, этот термин вероятно, в более узких кругах использовался еще до Дартмутской конференции. Но, тем не менее, мы сейчас обычно ведем отчет о Дартмутской конференции в появлении этого термина. И вообще говоря, то время, когда этот термин начал распространяться в научной среде, А вот напомню, что Дартмотская конференция, она состоялась в 1956 году, то есть за год, в общем-то, до запуска первого искусственного спутника Земли. И вот, значит, в тот момент, конечно, сообщество исследователей, которое занималось вычислительной техникой, было настроено чрезвычайно оптимистично. И, значит, точно так же, Запуск первого искусственного спутника вызвал определенную эйфорию, и многие в те годы считали, что пройдет несколько десятилетий, и человечество начнет активно колонизировать соседние планеты, а к концу столетия, возможно, и отправится в путешествие к звездам. Точно так же и сообщество исследователей, которое собралось на Дартмовской конференции, ну скажем так испытывала довольно серьезный оптимизм и скажем в 56 году никто по большому счету особенно не задавался вопросом о том какая дистанция разделяет машину, которая сможет обыграть чемпиона мира в шахматы, и, собственно говоря, некий универсальный интеллект, который может решать неопределенно широкий спектр интеллектуальных задач. Ну, в общем-то, так имплицитно предполагалось, что дистанция эта будет невелика. Поэтому в 1956 году исследователям было в известной степени простительно говорить об искусственном интеллекте, не пытаясь особенно выделить различные его разновидности, различные стадии развития соответствующих технологий. Но к концу столетия человечество столкнулось с такой интересной проблемой, что, в общем, с одной стороны, области исследований, традиционно относимые к искусственному интеллекту, был достигнут определенный прикладной прогресс, то есть было множество довольно сложных задач искусственного интеллекта решено на весьма приличном уровне, то есть у нас появились шахматные программы, способные побеждать лучших игроков людей, у нас появилось множество решений для оптического распознавания текста, например. Большое количество прикладных задач было решено на довольно приличном уровне, но в то же время здесь намечался вполне понятный гэп. Все эти системы, достигнув успеха в решении каких-то частных узкоспецифических задач, тем не менее довольно слабо продвинули нас к созданию системы, которая была бы столь же универсальна, как интеллект человека. в этот период и возникает вот эта вот дихотомия, то есть разделение на прикладной искусственный интеллект и появляются различные варианты опять же этого термина, узкий искусственный интеллект, прикладной искусственный интеллект, слабый искусственный интеллект, ну и соответственно его противоположность это некий значит сильный вариант и принципиальное различие здесь заключается в том, что Прикладной искусственный интеллект предназначен для решения какой-то одной прикладной задачи или какого-то очень небольшого спектра интеллектуальных задач, похожих обычно друг на друга. Ну и универсальный искусственный интеллект — это сильный искусственный интеллект, некая система, которая претендует на способность решать неопределенно широкий спектр интеллектуальных задач, ну, по крайней мере, тех интеллектуальных задач, которые способен решать человек. Вот. Здесь довольно интересно, что разные исследователи тяготели к разным вариантам этого определения, и, как это ни странно, здесь в какой-то степени первую скрипку играл Джон Сёрл, который, как известно, был Тьюринг-скептиком, то есть он относился к тесту Тьюринга как к процедуре, которая на самом деле не сможет позволить нам определить, создали ли мы настоящий интеллект, достигли ли мы интенциональности, как он выражался. И, собственно, в статье, посвященной как раз знаменитому мысленному эксперименту, получившему название «Китайская комната», он вводит термин «сильный искусственный интеллект» и «слабый искусственный интеллект». При этом под сильным искусственным интеллектом Сёрл понимает все-таки некоторую машину, которая способна решать неопределенно широкий спектр интеллектуальной задачи, и дальше при помощи своего эксперимента с китайской комнатой он показывает, что, по его мнению, этот эксперимент показывает, что в действительности тест-тьюринга не позволяет нам понять, имеется ли интенсиональность в созданной нами системе искусственного интеллекта, или же она отсутствует. Но надо сказать, что этот термин стал использоваться вслед за Сёрлом многими про-тьюринг исследователями. И, наверное, самый известный популяризатор этого термина — это Рэй Курцвелл, который на протяжении достаточно длительного времени использовал именно термин «сильный искусственный интеллект» для развлечения его с прикладным искусственным интеллектом. Но все-таки научное сообщество здесь пошло немножко по другому пути. Сегодня термин «сильный искусственный интеллект» употребляется довольно редко, просто потому что, скажем так, большая часть представителей научного сообщества, работающего в области искусственного интеллекта, достаточно скептично относится к китайской комнате. вообще говоря, не считает аргументацию Серла солидной. Конечно, есть именитые исследователи, которые поддерживают Серла, например, Роджер Фенроуз, который регулярно что-то на эту тему пишет и рассказывает нам про квантовое сознание. На самом деле, постепенно термин Artificial General Intelligence вытесняет из обихода термин «сильный искусственный интеллект». И термин этот неожиданно появился в работе, вообще говоря, посвященной не искусственному интеллекту изначально. Это была работа, посвященная нанотехнологиям. Значит, автор этой работы в 1997 году предложил использовать этот термин. Автором был Марк Губруд. И, в общем-то, на сегодняшний день для обозначения искусственного интеллекта, способного решать неопределенно широкий спектр интеллектуальных задач, обычно используют все-таки термин AGI. Что дальше делают авторы? Авторы задаются таким интересным вопросом, насколько далеко мы находимся от создания универсального искусственного интеллекта или общего искусственного интеллекта. И прежде всего обращаются к экономике мегапроектов, научных мегапроектов, человечество осуществило в XX веке и осуществляет в XXI веке. И они приводят два таких бесспорно мегапроекта, которые позволили достичь существенного прорыва в области технологий. Манхэттенский проект, по их мнению, и это программа «Аполлон». Ну, тут есть, понятное дело, определенный такой америкацентризм, СШАцентризм, да, значит, поэтому все сравнивается именно по меркам экономики США и, соответственно, рассматриваются американские проекты. Значит, вот авторы обращают внимание на то, что Значит, оба этих проекта, они по объему своих затрат доходили до 0,4% ВВП США во время своего осуществления. И если мы пересчитаем это все в современные доллары, исходя из современного объема бюджета, то у нас получится сумма, равная примерно 80 миллиардам долларов в год. Значит, дальше авторы рассматривают целый ряд крупных проектов в области науки и технологий за последние десятилетия и показывают, что, в общем, по большому счету большая часть этих проектов, в общем, подметки не годятся и Манхэттенскому проекту, и программе «Аполлон», то есть создание детектора гравитационных волн LIGO — это 300 миллионов долларов в год. Проект по секвенированию человеческого генома — 400 миллионов долларов в год. Большой адронный коллайдер на этапе постройки — 475 миллионов долларов в год, миллиард долларов в год во время эксплуатации. Значит, строительство первого международного термоядерного реактора Этер 2 миллиарда долларов в год. Ну и вот как бы значит мегапроект по созданию и совершенствованию истребителей F-35 обошелся американскому бюджету в 16 миллиардов. Вот. И авторы, вообще говоря, исходят из предположения, что создание общего искусственного интеллекта, значит, если мы его рассмотрим как такой вот мегапроект, по всей видимости потребует ресурсов, которые могут быть на один или два порядка больше, чем все существующие научные проекты. И из этого они делают следующий вывод, что создание такого проекта, осуществление такого проекта, по всей видимости, находится за пределами возможностей частного сектора. Ну, надо сказать, что эта оценка авторов, она основана во многом на их интуиции, то есть у них не видно каких-то серьезных попыток оценить реальную необходимость ресурса в таком проекте. Дальше в статье они немножко поясняют, от чего они отталкиваются и на чем, собственно говоря, основаны их рассуждения. Ну, во-первых, значит, они обращают внимание, что вот если мы здесь строим аналогию с манхэттенским проектом, то особенность этого проекта заключается в том, что даже если бы США увеличили финансирование манхэттенском проекте с 0,4% ПВП до, например, 4% или даже 40% ПВП, то все равно они вряд ли смогли бы создать ядерную бомбу в 1935 году. Почему? Потому что на самом деле для достижения прогресса необходимо было построение поверхности задачи. То есть необходимо было получить не по дорожную карту задачи, понять, что для достижения результата здесь необходимо выделить подзадачи, посчитать в ресурсном отношении эти подзадачи, посмотреть, сколько ресурсов требуется для осуществление каждого из этих майлстоунов и затем уже эту задачу воплощать. Реально в 1935 году понимания на уровне теоретической физики, что какие проблемы необходимо решить для создания ядерной бомбы еще не существовало и в силу того, что просто нельзя было сформулировать правильную дорожную карту по созданию ядерной бомбы. По этой причине там любая трата ресурсов в этом направлении, она была бы просто бессмысленной, потому что было бы совершенно неясно, куда собственно должны тратиться эти ресурсы и в какой пропорции. Ну в общем известное максимум, то есть если одна женщина может родить ребенка за 9 месяцев, это вовсе не значит, девять женщин смогут родить ребенка за месяц. Ну а что, собственно говоря, мы можем сказать о поверхности задачи по созданию общего искусственного интеллекта? И здесь авторы просматривают три возможности. Первая возможность, что в общем-то мы Уже сейчас находимся на этапе взлета, то есть где-то уже существует дорожная карта создания проекта, то есть кому-то уже понятно, что нужно сделать для того, чтобы получить общий искусственный интеллект. Ну и, в общем-то говоря, дальше вопрос встает только в выделении ресурсов на этот проект, ну и, собственно говоря, на получение какого-то результата. Вторая возможная альтернатива заключается в том, что период взлета этого проекта будет, то есть в какой-то момент эта дорожная карта возникнет и ей будут следовать, соответственно, создатели соответствующих систем, но мы в настоящее время находимся пока что не в периоде взлета. Ну и третья, на самом деле, смешная третья альтернатива, она заключается в том, что у этого проекта у него вообще не будет никакого периода взлета, и вообще говоря, создание AGI не является предметом крупномасштабного проектирования. То есть для того, чтобы создать AGI, нам, собственно, и не потребуется никакого мегапроекта, подобного манхэттенскому проекту. Ну то есть, допустим, завтра произойдет какое-то значит, прорывное открытие, например, в архитектурах неростевых моделей, которые позволят, например, сразу на порядке улучшить их сходимость и так далее. И, в общем, модель типа GPT-3 внезапно превратится у нас в универсальный искусственный интеллект. Как шутил Хинтон, Значит, для построения универсального искусственного интеллекта после появления GPT-3 мы знаем, что универсальный искусственный интеллект — это примерно, ну и назвал какую цифру, сколько триллионов параметров должно быть в настаканных трансформерах, чтобы у нас получился EJ. Ну дальше, конечно, авторы не были бы специалистами по полисе, не были бы специалистами по политикам, если бы не озвучили свои опасения. И, значит, авторы на самом деле озвучивают следующее опасение, что, значит, вообще говоря, проект по созданию универсального искусственного интеллекта в теории может провернуть какой-нибудь авторитарный режим. Что значит, не страны демократии окажутся впереди планеты всей. То есть пока, значит, если мы посмотрим на современную политику крупных государств, мы видим там крупные программы, связанные с развитием искусственного интеллекта, но основной акцент на них делается, конечно, на развитии прикладных систем искусственного интеллекта. каких-то мегапроектов по созданию универсального ИИ. А вот может быть где-то есть какой-то авторитарный режим, где создана шарашка, где ученые уже успешно лобают универсальный искусственный интеллект и, в общем-то, этот авторитарный режим сможет добиться превосходства. в этой области, а в общем мужики-то и не знали. Ну и, соответственно, авторы задаются такими вопросами. Какие индикаторы существуют, вообще говоря, которые позволят нам делать какие-то выводы по поводу того, близки ли мы к выруливанию на взлет, то есть близки ли мы к к моменту, когда у нас появится вот эта самая дорожная карта, которая вот дальше просто потребует выделения ресурсов и все. Ну на самом деле они здесь выделяют у себя в работе шесть таких индикаторов. Первое — картированные подзадачи, то есть в общем по научным публикациям мы Будем замечать, что появляются некие реалистичные дорожные карты, которые описывают процесс создания универсального искусственного интеллекта. Опять же, это появление ресурсных оценок для подзадач оценок для соотношения затрат ресурсов и результата. То есть, если кто-то занимается исследованием функции производства AGI, то мы увидим опять же артефакты этого в научных публикациях. Следующий момент — это интенсивность капиталовложений. То есть мы можем предположить, что, значит, для создания такого проекта потребуются специалисты, потребуются железо, потребуются разработчики, и, соответственно, если мы где-то увидим в мире всплеск спроса на, значит, например, специалистов по глубокому обучению резки, да, встает вопрос, чего же там люди такого знают, чего не знаем мы, да, то есть почему они как бы стали перекупать исследователей в этой области, значит, они считают, что это позволит им добиться превосходства, вероятно. Следующий индикатор — это параллелизм. То есть, вообще говоря, если мы увидим, что множество команд одновременно трудятся над решением каких-то подзадач, которые входят в дорожную карту, предполагаемую дорожную карту создания универсального искусственного интеллекта. Это также может быть индикатором прогресса в области. Поведение ключевых действующих лиц. Здесь, в общем, тоже все примерно понятно. Те же самые авторитарные режимы делают в плане своей бюджетной политики, что они делают, что делают исследователи, то есть не делают ли все исследователи какое-нибудь авторитарное государство на большие зарплаты. Не наблюдается ли, опять же, каких-то аномалий в публикациях. Ну, например, эти аномалии могут быть не обязательно увеличением публикационной активности в определенных направлениях, но и снижением ее, да, то есть это значит, что большая доля исследователей работают в области, значит, которая не позволяет им публиковать результаты своих работ, что в общем подозрительно. Вот. Ну и скорость обратной связи, то есть вообще говоря, те проекты более эффективно используют ресурсы, которые позволяют эффективно оценивать промежуточные капы, ну и, соответственно, гибко управлять ресурсами внутри проектов. Вот, соответственно, если мы видим, что возникает некий, так сказать, такой короткий цикл группы ошибок, то есть мы видим, что при решении каких-то подзадач, которые могут быть частью такого roadmap, мы видим, что люди делают какие-то короткие исследовательские циклы, публикуют свои результаты и, например, переключаются на другие направления, то это, в общем, тоже, на самом деле, признак того, что кто-то пытается воплотить здесь некую дорожную карту по созданию универсального искусственного интеллекта. Ну и дальше, конечно, авторы говорят о несовершенстве своей работы, что список показателей прогресса в направлении взлета, он вовсе не окончательный и требует своего осмысления, расширения, возможно. Они говорят о том, что, по их мнению, площадь поверхности проблемы Эйджайя в настоящее время слишком мала для того, какое-то государство могло бы влить огромные ресурсы и в результате получить здесь превосходство. Но замечают, что эта ситуация может довольно быстро измениться. То есть в случае выруливания на взлетную полосу, возникновения реалистичного родмапа, государства могут здесь начать гонку. гонку ресурсную. Ну и в общем, естественно, они еще раз подчеркивают социальную значимость исследования по выявлению момента выруливания на взлетную полосу, потому что они видят высокие риски, которые в этой области игнорировать нельзя. Вот такая веселая по своему работа, готов ответить на вопросы, которые наверняка возникли у слушателей. 

S10 [01:05:36]  : Сергей, спасибо. Вот у меня сразу вопрос возник. А насколько вообще корректно сравнивать такие проекты, как запуск ракеты в космос или взрыв атомной бомбы, когда цена неудачного эксперимента — это надо строить новую ракету или надо искать новый полигон или новый атолл вместо взорванного? Когда в случае с софтом цена зафейлившихся тестов, она, в общем, близка к нулю по сравнению с этим. Может быть, это не очень адекватный способ сравнения? 

S11 [01:06:13]  : Ну, я думаю, что тут есть как бы два аспекта. Первый, наверное, связан вообще с моим отношением к рассуждениям авторов в этой работе. Считаю, что в этой работе довольно много есть допущений таких и спекуляций. Но авторы, в общем, вполне себе осознают, что они занимаются спекуляциями. Это вот видно, например, по вот этой прекрасной альтернативе, которую они показывают. Они говорят, что мы, в общем, по большому счету даже не уверены, что здесь применим вот этот подход со взлетом. Даже в этом они не уверены. Но это как бы один такой момент, но это вполне нормально, то есть люди занимаются форсайтом, им положено спекулировать. Значит, на чем основаны здесь эти аналогии, какие здесь можно в защиту этих аналогий провести соображения? Во-первых, мы видим сейчас, скажем, в области обработки естественного языка то, больших успехов удалось достичь за счет моделей с огромным количеством параметров. И мы все прекрасно понимаем, что стоимость обучения моделей типа GPT-3 — это семизначная сумма в долларах на сегодняшний день. То есть, если мы берем GPT-2 или всякие модели а-ля то это десятки тысяч долларов. И в какой-то мере в 2018 году с появлением трансформеров и с появлением архитектуры с многослойными трансформерами началась как раз ресурсная гонка. То есть мы видим, что тот же самый OpenAI скидывает огромные деньги в обучение таких моделей. И скажем, вот Сбербанк ведь на сегодняшний день является обладателем самого мощного суперкомпьютера в России. На самом деле это суперкомпьютер Кристофари, который на самом деле представляет собой объединение 75 узлов DGX2 через сверхбыструю шину InfiniBand. Но мы понимаем, что для обучения самого большого варианта нам понадобится всю эту машину занять на год. И в этом смысле цена ошибки здесь как раз очень велика. То есть если при проектировании конкретной архитектуры кто-то налажает в каком-нибудь токенизаторе, Реально это может привести к гигантским потерям, которые измеряются огромными суммами. А вдобавок еще будет потерян в принципе ценный ресурс. Потому что за это время могла учиться другая модель, правильная. И кто-то сейчас в соседней организации, в соседней стране учит модель, в которой этой ошибки нет. И расходует эти ресурсы правильно. Мы, как это ни странно, за последние два года снова пришли к ситуации, когда, во-первых, все не делается на персоналках, все не делается на домашних станциях, у нас снова возрождение мейнфреймов произошло только в новом воплощении. Во-вторых, у нас опять внезапно дорогим стало вычислительное время, то есть, скажем, в 70-е годы, допустим, когда профессор Кронрот спорил со сторонниками программирования на языках высокого уровня, он был сторонником программирования в содержательных обозначениях, да? Он показывал, что, ребят, вот вы же понимаете, что у вас один час машинного времени стоит как месяц работы оператора. Вот. То есть вы что пытаетесь со своим алголом делать, негодяи, да? То есть вы растрачиваете ценные ресурсы, а на самом деле нужно просто посадить девушку-лаборантку, которая Ваш содержательное обозначение перебьет эффективным образом в код, который будет быстро работать. Вы разбазариваете, так сказать, ценный ресурс, ничего больше не делаете. Посмотрите, ваш Algol транслирует программу в неэффективный код для B7-6. Что делать? Проблема. И мы, как-то не странно, на новом, так сказать, витке развития этой диалектической спирали, мы в какой-то мере вернулись в похожую ситуацию, когда, значит, действительно опять на передний край выходит какая-нибудь там низкоуровневая оптимизация при обучении таких моделей. И мы видим, как идет, так сказать, борьба за быстрой имплементацией трансформеров, которые там буквально такт и процент процессорного времени экономят. Вот. Поэтому я бы сказал, что здесь вот как-то не странно, такое действительно даже присутствует, и здесь я, может быть, готов даже с авторами согласиться в их такой аналогии. Два года назад я был бы, конечно, радикально не согласен. Сейчас, ну, в общем, резон есть в их словах. 

S02 [01:11:39]  : И спасибо за развернутый вопрос. Альберт просит 3 минуты на вопросы и комментарии, потому что мы можем ему это позволить. сегодняшнего мероприятия, Альберт. 

S10 [01:11:51]  : А там можно еще один вопросик тогда уже? Да, конечно. Считаете ли вы DeepMind шарашкой тоталитарного режима близкой к созданию AGI? 

S11 [01:12:00]  : А, ну смотрите, я вообще никакого отношения к вот этим, я вообще считаю гипотезу тоталитаризма, авторитаризм глубоко паранаучными, да, и, собственно, это все идеология. Поэтому я тут с иронией отношусь с соображением авторов в этой области. Конечно, любая крупная корпорация, ей присущи в наши дни такие черты некоторых государств. Ну и там коммерческая тайна, так сказать, и так далее. Но в целом, если посмотреть на деятельность DeepMind, деятельность OpenAI, они, конечно, публикуют очень много своих результатов. Результаты, безусловно, ценны для сообщества. Ну вот если вы возьмете публикации DeepMind и начнете их там честно воспроизводить, у вас действительно получится. То есть мы там неоднократно воспроизводили какие-то их работы для своих прикладных задач. Вот. То есть сейчас, конечно, исследования в области глубокого обучения, они глубоко открытыми являются. И в этом плане таким мощным показателем этого является, например, бойкот со стороны вообще сообщества исследователи области глубокого обучения, бойкот Эль-Севьеровского журнала, значит, потому что, собственно, исследователи области глубокого обучения выступают противниками на ограничение свободного распространения научной информации и, ну, вы можете почитать, это очень радикальное письмо, да, которое подписано там и Хинтоном, и Яном Лекуном, и, в общем, всеми ведущими специалисты его подписали, в общем, ну, это выглядит как такое. Бунт, конечно, мощный против системы. Но, опять же, это не значит, что это не может измениться в один прекрасный момент времени. Здесь авторы делают вывод, что у нас государство сейчас так прохладно относится к Эйджай, Но все может по мгновению ООКа измениться, и вот если мы почитаем претензии, правда не DeepMind, а OpenAI со стороны Ника Бострома. Он говорит, что вот эта политика OpenAI, что мы несем людям результаты своих исследований и так далее. А кто подпишется кровью, что завтра, когда вы поймете, что вы на самом деле сможете создать универсальный искусственный интеллект, что вы не измените эту политику. То есть, может быть, вы станете тем драконом, который все захватит. Поэтому здесь вот такие соображения есть, поэтому их нельзя тоже скидывать со счетов, что политика DeepMind, политика OpenAI в один прекрасный момент может вполне себе поменяться на противоположную. Спасибо. Да, Альберт? 

S05 [01:15:01]  : Сергей, мне кажется, сегодня вечером ты задал прям планку критического разбора очень важной статьи. Её будет очень сложно вообще кому бы то ни было произойти. Я совершенно счастлив, что ты сосредоточился на критическом разборе зарубежной статьи, а не моего выступления. Но одна вещь, которую я, наверное, хотел бы задать тебе в качестве вопроса, но перед этим нам нужно сделать определенный комментарий. Когда я эту статью прочитал первый раз, я прочитал несколько раз, я сначала не мог понять, где же я все это читал раньше. Я все думал, где же я это читал раньше? А потом я понял, что это по сути дела является не то что пересказом, а переоткрыванием теории научных революций Томаса Куна. И ребята говорят на самом деле о состоянии науки искусственного интеллекта, общего искусственного интеллекта сейчас. Они просто переизобрели свои термины road map to road map и так далее, но по сути дела они говорят о том, где мы находимся с точки зрения науки. У куна есть допарадигмальные, парадигмальные периоды и есть так называемый период головоломки. головоломка это когда все уже главные фундаментальные вопросы решены то что говорят на самом деле эти ребята взлетная полоса фундаментальные вопросы решены и остались головоломки которые если накинуться массой и бюджетами то мы их решим значит вот здесь конечно у меня к тебе вопрос мы где находимся? Все-таки парадигма уже решена, фундаментальные вопросы в AGI уже решены, и мы находимся в состоянии головоломок, которые нам нужно открывать. Или мы все еще не нашли той парадигмы, которая будет определять облик AGI? Я, со своей стороны, просто добавлю еще масло в огонь этой дискуссии. Я могу сказать, что, на мой взгляд, AGI сейчас находится, я бы даже сказал, в грязных лапах людей, которые занимаются компьютер-сайенсом, так как они, конечно, никакого отношения к компьютерам не имеют. И вполне возможно, будущее AGI находится в лапах тех, кто будет заниматься не компьютерами, а квантами. Ну, как обычно, все упирается в физику. 

S11 [01:17:42]  : Ну, квантовые компьютеры — это тоже компьютеры. 

S05 [01:17:46]  : Может быть, да, но мы еще точно не знаем. Но все-таки вопрос — мы находимся в состоянии головоломок, которые мы решаем? 

S11 [01:17:54]  : Я думаю, мы находимся в таком немножко, может быть, сложном состоянии, когда проблема не в том, что у нас нет парадигм, нет дорожных карт. Проблема, наверное, в том, что у нас их слишком много. И в этом смысле, значит, вполне можно себе придумать разумные эксперименты, которые, ну так вот, имеют право вроде бы на то, чтобы попробовать и посмотреть, а что из этого получится. Ну, то есть, например, ну почему бы нам не сделать нейросетевую модель размером с человеческий мозг, 8,6 миллиардов нейронов, квадриллион синапсов, взять какую-нибудь модельку более-менее биологически достоверную, не Хошкина-Хаксли, которая там вычислительно тяжелая, но взять что-то из современных моделей, там STDP, там какой-то, окей, модель Ижекевича. И попробовать дальше такой как бы reinforcement-эксперимент, то есть вот эту вот сетку поместить в какую-то виртуальную среду сложную, а может даже и к роботу приделать, и вот начать ее учить, как мы детей учим. Но здесь в чем проблема? Во-первых, у нас пока что нет железа сопоставимого с человеческим мозгом по производительности, хотя мы в правильном вроде направлении движемся, но тем не менее у Пояжекевича в начале 2000-х годов, чтобы одну секунду работать такой сетки симулировать, ему нужно было 52 дня вычислений. На какое время у нас растянется такой эксперимент с такими вычислительными мощностями? Понятно, что есть идеология Генри Маркрама, есть идеология, которая лежит в основе Blue Brain, Human Brain, отчасти Brain Initiative, что давайте делать железки, которые нам позволят быстрее реал-таймы симулировать сети, сопоставимость мозгом по размеру. Мы, конечно, не знаем, какая архитектура должна быть у такой сети, например, да, мы можем что-то, какую-то правдоподобную гипотезу сделать, да, может быть, вот коннектомика нам подбросит полезную информацию по поводу топологии этой сети, вот, а может быть, мы просто сделаем какую-то большую очень сверточную сеть, ну то есть здесь тоже есть разумные гипотезы, какие архитектуры имеет смысл попробовать, этих гипотез превеликое множество, вот, ну и как бы это выглядит так, что Значит, проведем побольше экспериментов, подберем гиперпараметры, подберем топологию и вуаля, значит, у нас возможно получится результат. Да, но никто не знает, получится или нет. Ресурсно очень дорого, пока не появилось, ну да, там есть проекты BrainScales, SpinMaker, масштабные там симуляции больших нейросетей. импульсных, по-компартментно каждый нейрон мы будем симулировать и так далее. В какой-то момент это станет feasible, просто в силу поступательного прогресса в области вычислительной техники. Это вполне себе roadmap, но его, точнее некий класс roadmap, Внутри него там живут какие-то гипотезы, которые надо пробовать под задачи и так далее. То есть это родмод, но его проблема в том, что пока что он ресурсным не является подъемным. Другой вариант, допустим, история с глубоким обучением. Почему бы нам не использовать сильно упрощенные архитектуры? То есть нам не надо, не будем биологически достоверно нейроны симулировать. Возьмем все эти простенькие блоки, которые мы используем сейчас, с кусочной линейной активации, релу какую-нибудь возьмем, опять же толстый-толстый трансформер. И будем его в духе GPT-3 учить, только еще в какой-нибудь reinforcement его обернем. Выглядит тоже интересно. Это тоже надо пробовать ресурсно, тоже дорого пока. Как мы увидели, модели типа GPT-3 больно учить. Но есть соображение, как, может быть, можно модифицировать эти архитектуры. Это одно из направлений. Давайте мы там, ну вот, GPT-3, там Sparse-трансформеры использованы. Сейчас все ищут архитектуры разреженных трансформеров, которые вот от проклятия размерности попробуют уйти, позволят уйти в трансформерных моделях. три десятка сочинено уже, да, там Reformer, Adaptive Attention Spam, там и так далее, и так далее, да, Compressor, Transformer и так далее. Может быть завтра окажется, что мы найдем тоже такую серебряную пулю, которая позволит нам для жирных трансформерных моделей, скажем, в 100 раз снизить по железу затраты. И окажется, что вот этот родмап, он как бы более правильный. Мы уже не знаем пока, значит, насколько антропоморфным-то должен быть AGI. То есть антропоморфная модель ее привлекательность в том, что у нас есть гарантированно рабочий прототип в виде человеческого интеллекта, а здесь вроде бы дополнительные риски есть. Но с другой стороны, может быть, можно сделать проще. В конце концов, к человеческому мозгу эволюция предъявляла разные требования. У вас не должна ваша память сброситься от того, что вам кто-то, не знаю, яблоко на голову упадет. Это должна быть ну, систему устойчивого к разным физическим воздействиям. Может, можно сделать сильно проще. И в лабораторных условиях это будет работать и учиться. Ну и на самом деле есть еще. То есть я могу долго про это рассказывать, но родмапов есть, они определенным образом конкурируют между собой. И вопрос, какой из них раньше станет feasible, чтобы реально на него были необходимые ресурсы выделены. Но и в этом смысле здесь корпоративная наука Ну и западная академическая наука, они прощупывают, конечно, эти пути. То есть то, что делает OpenAI, то, что делает DeepMind, это можно посмотреть, да, то есть они много инвестируют в реинфорсмент, то есть огромная, очень сильная группа работает именно над реинфорсментом, вот начиная с появления в библиотеке Dofomind, И дальше мы видим большой прогресс в РЛ, очень большой. Ни совершенствования архитектур, ну в том числе трансформерных. Поэтому я бы сказал, что глубокое обучение тяготеет скорее к родмапу делать какие-то трансформеры плюс. 

S02 [01:25:13]  : — Сергей, да, очень неловко вас прерывать. 

S10 [01:25:16]  : — В общем, даю слово следующим спикерам. 

S02 [01:25:22]  : Спасибо большое. 

S10 [01:25:23]  : Спасибо. Спасибо, Сергей. 

S02 [01:25:26]  : Да, зрители аплодируют, коллеги. 

S10 [01:25:34]  : Да, и теперь, значит, мы переходим из пространства тьюринга и дорожной карты к суровой реальности метрик, бейзлайнов. и всего того, что связано с измеримостью нашего прогресса на пути к EGI. Слово предоставляется Дмитрию Салихову, Андрею Чертаку и Татьяне Шавриной. 

S09 [01:25:59]  : Всем привет. Нам досталась сложная миссия попытаться вложить в тайминг, хотя у нас на один доклад не один спикер, а целых три. Поэтому я свою некую вводную часть пройду побыстрее. Меня слышно, да? Все нормально? Слышно, видно? Слышно. 

S02 [01:26:15]  : Да, Андрей, все видно и слышно. 

S09 [01:26:17]  : Да. Я не удержался немножко вставить определенных каких-то спин-офф, скажем так, слайдов по отношению к теме. метрик и прочих вещей сфокусируются Дима и Таня. Мы, в общем-то, работаем в одном подразделении, которое тоже занимается темой AGI. Понятно, что она очень широкая, сложная и многогранная, но, в общем, мы пытаемся тоже что-то на эту тему делать, и некоторые из вас участвовали в наших семинарах по EJ, которые были в прошлом году, и очень много всего обсудили. Конечно, было бы интересно все это рассказать, поговорить, но мы не успеем. Я просто пару слов про себя. Я занимаюсь R&D проектами От классического ML сейчас все больше мы занимаемся темой AGI, то есть чуть более такими далекими. Но нас, к сожалению или к счастью, приземляют от абстрактных рассуждений, как мы к нему придем, к каким-то конкретным попыткам приложить те или иные экспериментальные методы. Вот, поэтому это имеет своих плюсы и минусы, что мы, наверное, не всегда можем широко поговорить про эту тему, но с другой стороны делаем что-то конкретное. Вот, я здесь немножко пробегусь по каким, ну, очень по верхам, чтобы понять, чем мы плюс-минус занимаемся сейчас, и в оффлайне с удовольствием поговорим, можем пообщаться, и мы, я думаю, что Антон Здесь много знакомых нам людей, замечательных. Мы планируем в октябре провести нашу очередную вот эту сессию, третью по EGI, соберемся, пообщаемся, есть уже тематики. На этот раз, скорее всего, в онлайне, поскольку не получится в онлайне собраться. Да, и прежде чем прийти к теме метрик, я немножко пройдусь. Ну, про ассоциации, да, мы много говорим, во-первых, что такое AGI, попытка дать ему определение, это неблагодарная такая миссия, мы попытались, в том числе на наших семинарах. И, конечно же, поддержу здесь и Сергея, и Альберта. Мы точно уверены, что вряд ли какой-то один конкретный подход нас приведет к тому, что мы добьемся успеха в этой теме. И сейчас все чаще приходится искать возможности пересечь классические нейро-сетевые подходы. с какими-то концепциями, связанными с мозгом. Тем более, что ряд существующих и архитектур, и направлений исследования так или иначе были связаны или инспирированы, или нашлись какие-то аналогичные механизмы в мозге. Здесь стоит сказать, что РЛ сам по себе не то чтобы искусственная история, да, и зафаминовые механизмы в мозге устроены похожим образом. уже изученный факт. И когда мы говорим про то, чем для нас может быть AGI, куда мы можем пытаться приземлять, поскольку мы, к сожалению или к счастью, работаем в неком пространстве задач и стратегии развития банка, мы должны попытаться сформулировать, где бы мы могли попробовать эту историю. Здесь, понятно, некорректно с точки зрения того, где в мозгу расположены те или иные зоны, отвечающие за соответствующие когнитивные способности. Это скорее такая абстрактная аналогия, у нас существуют так называемые платформы, AI-платформы в банке. NLB-платформа, Speech-платформа, рекомендательные системы и так далее. И они сейчас существуют относительно независимо. И, в общем-то, мы ставим задачу, ну, по крайней мере, с точки зрения каких-то исследований, насколько возможно объединить навыки, которые имеются в каждой из этих платформ в будущем. как их можно усилить, эти платформы друг с другом. И у нас возник термин AGI-рекистратора, который можно попытаться объединить. Но здесь встает вопрос, каким образом это можно вообще пытаться делать. Мы стараемся как-то прикладывать, пробовать и видеть, насколько получается, не получается. Вот сейчас есть такая концепция, она очень может быть спорной, но тоже интересно было пообсуждать в оффлайне. Вот одна из идей, она связана с объединением скажем так, навыков из разных платформ через так называемые суперэмбеддинги, которые, в общем-то, собираются в виде некой такой координации эмбеддингов из разных платформ. И эти суперэмбеддинги могли бы приземляться на некий суперграф, граф знаний, и у нас, в общем-то, графовые базы И здесь нужно заметить, что NGPT3 тоже, по сути, генерирует некоторые эмбейдинги, которые можно пытаться объединять с другими движками знаний. И, в общем-то, это не новая концепция, да, сейчас есть попытки строить такие и-графы и склеивать имбеддинги для visual question answering, в частности, когда такие графы строятся автоматически. Возможно, такая архитектура могла бы быть перспективной, и она в себя вбирает как раз достижения из самых разных платформ-губежков. Даже имея саму State-of-the-art GPT-3, мы можем ее обогатить знаниями из других движков. Ну и здесь нужно немножко пару слов сказать. У нас есть еще лаборатория нейронаук, которую возглавляет Андрей Курпатов. относится с точки зрения его публичной деятельности, связанной с психоанализом и так далее. Но, как выяснилось, у нас достаточно интересные проявляются коллаборации, то есть мы компьютер-сайентисты с людьми, которые изучают как иначе мозг. Я не буду здесь останавливаться, он в свое время сформулировал Brain Principle Programming. Это доклад, который он рассказывал на AI Journey в прошлом году. Я думаю, что можно найти ссылку, и там достаточно подробно рассказано про эти пять принципов. Это и принцип генерации, то есть наличие сенсоров, практикальных колонок мозгу, через которые, по сути, и происходит обработка информации. И принцип отношения, аппроксимации, преобразования тяжести я зачитывать не буду. И вот выясняется, что, в принципе, архитектура Архитектура, в отличие от оркестратора, про которую я сказал, она не противоречит этим принципам, то есть эти пять принципов по идее соотносятся и с другими существующими классификациями, связанными с деятельностью мозга. Как выяснилось, мы пришли к этому с разных сторон. Суперэмбеддинги, их можно ассоциировать как раз с этими сенсорами, с критикальными колонками. Ну и далее все принципы можно сформулировать, переформулировать с точки зрения вот этой архитектуры. Она пока что у нас скорее сформулирована теоретически, но мы уже там начали первые эксперименты, связанные с различными тестами, с наполнением этого графа знаний. Это отдельная тоже история, как автоматически формировать или наполнять этот граф из инструктированных данных. Вот, ну и я прежде чем передам слово Диме. Да, Дима, ты наверное в начале. Конечно, здесь нужно сказать, что нет сейчас консенсуса, и почему, наверное, мы в свое время попытались, объединившись с экспертами, попытаться сейчас написать книгу, что нет сейчас консенсуса про то, какая теория Много разных архитектур предложено, но очень мало примеров инженерной реализации. Состоятельность этих архитектур можем увидеть и потестировать на каких-то реальных задачах. Конечно, этого хотелось бы видеть больше. И, ну, определение АГИИ, AGI, общеискусственной, универсальной, сильной, да, вот это тоже бесконечное поле споров. больше года эти дискуссии ведем, но тем не менее они достаточно все еще расплывчатые и мы в любом случае не можем при нашем подходе к AGI не пытаться формулировать майлстоуны, которые будут помогать нам понять, что мы еще на шажок приблизились к AGI. Поэтому мы, прежде чем искать те или иные подходы, тестировать, мы не можем не попытаться сделать подход к AGI лидерборду или к каким-то тестам. И, в общем-то, на эту тему тоже уже достаточно литературы написано. И у нас в книге будет целая глава про это. Но, тем не менее, мы лишь пытаемся сейчас сформулировать какой-то наш взгляд на эту историю. И, наверное, только то, какой лидерборт в будущем окажется более популярным или менее популярным, это только и даст ответ, какой же способ измерить, он более правильный или менее правильный. Вот, поэтому это моя такая вводная часть, ребят, я извините тоже, что отъел время, сейчас передаю слово Тане, и вопросы, наверное, лучше в конце, когда ребята выступят, и можно будет задать. Я отдаю экран, да? У нас разные презентации. 

S04 [01:37:33]  : Добрый вечер, коллеги. Меня зовут Татьяна Шаврина. Я буду вместе со своей коллегой, с Марией Тихоновой, представлять наш проект Russian Superglue. Ну и хочется со стороны своей колокольни тоже немного поспекулировать о будущем, куда мы идем, и какую роль в этом занимает NLP. Так, момент. Видно, да? 

S02 [01:38:04]  : Да, пока загружается. 

S10 [01:38:06]  : В какой-то момент вспыхнуло, а потом вернулось обратно назад. Все, появилось. 

S04 [01:38:10]  : Все, отлично, отлично. Соответственно, Russian SuperCLU – это достаточно большой проект, который делает большая команда, большая часть которой находится в Сбири, но также нам помогают коллеги с факультета компьютерных наук и с компанией Huawei. И с недавнего времени еще большое количество студентов высшей школы экономики, которая помогает проекту тоже развиваться, составлять новые тесты и решать проблемы старых. Проект очень большой и он направлен на фундаментальную оценку существующего прогресса в задаче языкового моделирования. Языковое моделирование вообще — это фундаментальная научная задача, которая начиналась решаться еще в 50-х годах на правилах и постепенно дошла до того более совершенного вида, в котором она у нас есть сейчас. Фундаментальность задачи сводится к следующему вопросу. Мы должны научиться моделировать человеческий язык настолько хорошо, что из всех возможных событий мы будем генерировать только те, которые осмыслены. Любой текст, любая речь — это по сути своей совокупность редких событий, которые произошли вместе. И можно любую фразу, которую произнес человек, немножко поменять, и она все равно останется более-менее вероятной, но она перестанет быть осмысленной. И современные языковые модели все еще не дошли до той стадии, когда бы мы могли из всего материала огромных корпусов, которые у нас есть, генерировать только те последовательности, которые являются осмысленными. Если подойти к этому немножко с другой стороны, то то, что мы делаем, по сути, это дистилляция. Это дистилляция знаний, это дистилляция очень непосредовательной интеллектуальных процессов, которые происходят в сознании. У нас есть большая модель, про которую мы знаем очень мало. И у нас есть вывод этой модели в определенном формате. Какой есть, такой есть в виде текстов, я имею в виду. Тексты — это очень опосредовательный материал результатов нашего мыслительного процесса, но зато самый крупный и самый доступный. И то, что мы сейчас делаем, по сути, это дистилляция вот этого вывода, полученного на очень опосредованных данных. Поэтому, собственно, отсюда и такие проблемы. Можно привести много примеров, почему текст — это плохой источник достаточно для моделирования сознания. У нас есть вещи, которые есть в одних языках и нет в других. Это очень сильно влияет на мыслительные процессы. У нас есть индивидуальные особенности, которые мы все выравниваем, когда работаем с кучей текстов из разных источников. Но, тем не менее, это единственный источник, который у нас есть пока что. Ааа... Далеко не все примеры из него являются действительно для нас полезными, потому что что толку от того, что мы научимся хорошо моделировать последовательности вида мам и малырам? Это мы уже и сейчас умеем. Мы хотим моделировать более сложные вещи, осмысленность в вопросах, в которых требуются, собственно, уже какие-то мыслительные процессы, более сложные, высокоуровневые и разные операции. Поэтому с низкоуровневой точки зрения, когда мы составляем вот такие бенчмарки, как SuperGLUE, в том числе для русского, мы берем только определенные наборы заданий, в которых, чтобы их выполнить, человеку нужно применить определенные навыки интеллектуальные, которые у него есть. В нашем бенчмарке это 9 заданий. на разные способности, некоторые задания требуют нескольких сразу, некоторые только определенных, все задания выражены текстом и имеют достаточно простой с точки зрения машины формат, а содержание достаточно сложное. Наш лидерборд для русского языка в актуальном своем виде выглядит вот так. У нас всего 58 моделей, которые прошли тестирование разных, но далеко не все из них показали такой хороший результат, чтобы авторы их согласились включить на лидерборд. Итого сейчас у нас есть модели Rupert, Multilingualbert, архитектура и еще некоторые другие виды тоже на основе Pert. В дальнейшем мы будем пополнять наш лидерпорт, в частности сейчас ждем от одной команды очень модель T5. Как можно увидеть, сейчас разрыв между перформансом человека на этих интеллектуальных задачах и машины очень большой. Для английского он чуть меньше, что вызвано большим вниманием комьюнити и большими вычислительными мощностями, которые работают с английским языком. Ну вот для русского у нас где-то на 25% ниже от качества, а люди решают задания в среднем на 80%, что тоже нормально, люди ошибаются. задачи сложные достаточно. О том, что находится внутри, сейчас расскажет моя коллега Мария Тихонова. Мы очень кратко погрузимся в то, что на самом деле на дне машинерии происходит, и посмотрим на формат. Собственно, у нас есть пять основных видов способностей, которые мы тестируем. Это причинно-следственные связи, здравый смысл, знание о мире, логика и понимание больших текстов. 

S03 [01:44:07]  : Сейчас я кратко расскажу, пробегусь по, наверное, всем заданиям. Первое из заданий — это причинно-следственные связи. Следующий слайд, пожалуйста. Оно включает два задания — Terra и LCB. Это задание, которое представляет из себя задачу бинарной классификации. На вход модели подается два предложения по ссылке гипотезы, и модель должна понять, есть ли между этими предложениями причинно-следственная связь. чем-то аналогичным тере, но здесь машина должна понять, следует ли гипотеза из короткого абзаца к короткому тексту. Следующая группа. Отдельно стоит упомянуть диагностический датасет LIDIRUS, который, по сути, представляет из себя еще один набор тестовых примеров для зданий Terra. Но уникальность этого датасета заключается в том, что все пары предложений в нем размечены лингвистическими категориями и отмечены лингвистические феномены из четырех категорий — лексическая семантика, логика, предикатная нативная структура и знания Благодаря этому можно производить анализ того, насколько хорошо модель улавливает лингвистические и синтоксические связи, насколько хорошо она улавливает и понимает эти категории. Также стоит отметить, что диагностика является полным аналогом английской версии диагностического датасета. И благодаря этому можно производить мультиязычный анализ, можно сравнивать, как модели понимают те или иные лингвистские феномены на различных языках. Следующая группа заданий относится к common sense. Это задание Руссе и Парус. Руссе представляет собой задание бинарной классификации. В двух предложениях одно и то же слово встречается в различном контексте, и необходимо определить, потреблено ли оно в одном значении или в разном. А Парус — Choice of plausible alternatives, выбор различных альтернатив, Задание на определение какой из альтернативных ответов на вопрос корректен. Следующий слайд, пожалуйста. Еще одна группа заданий, это задание на машинное чтение. Это задание, в котором модели предлагается ответить на вопрос, основанным на отрывке текста. Причем вопрос составлен таким образом, чтобы невозможно было ответить на вопрос. опираясь только на одно предложение, то есть для корректного ответа требуется прочесть весь абзац. Также в задании предлагаются несколько различных вариантов ответа и трудные задачи усложняют то, что может быть несколько правильных ответов. задача на выбор правильно именованной сущности из короткого отрывка текста. На вход модели подается короткий отрывок и ряд именованных сущностей, и в запросе предлагается вставить верную из именованных сущностей, использованных в тексте. И последние две группы заданий — это «Знания о мире» и «Логика». «Знания о мире» в Russian Superglue представлены с помощью дата-сета Donet.com. По короткому отрывку текста задается вопрос, на который можно дать ответ «да-нет» и задание на логику РВСД, на разрешение к референции. То есть требуется ответить, относятся выделенные слова, обозначают ли выделенные слова одно и то же. Ну, например, здесь представлен пример. Кубок не помещается в коричневый чемодан, потому что он слишком большой. Действительно, он относится к слову кубок и, соответственно, ответ true. требуются какие-то еще общие знания, общее понимание о Мирис, скажем так. 

S04 [01:49:47]  : Спасибо. Вот я сейчас вывела еще раз наш лидерборд. Я думаю, когда мы посмотрели конкретные задания, здесь возникает большое количество вопросов. У меня лично он всегда тоже возникает. А что, если на самом деле ответы зависят от каких-то признаков, которые модель выявит неявно? Например, взаимная встречаемость отдельных слов или частотность слово «не» будет очень часто, и это будет влиять на реальное качество модели. Как понять, что мы действительно движемся в правильном направлении, когда мы взвешиваем наши модели на лидерпорт? Действительно ли способ решения таких задач показывает какие-то высокоуровневые операции? либо же на самом деле просто хорошее выучивание каких-то паттернов, которые есть в данных. Для этого мы делаем, собственно, подробную диагностику. Диагностика, прежде всего, это датасет, в котором искусственным образом включены специальные явления, чтобы посмотреть, как они влияют на качество. Да, я на них Сейчас подробно останавливаться не буду, потому что их аж целых 33 штуки, и для каждого мы меряем корреляцию с золотым стандартом, чтобы проверить, что влияет оно или нет на качество. Но оказывается, что влияет, и оказывается, что влияет и для русского, и для английского, и в целом модели, которые показывают даже неплохое качество, очень хаотичные и очень подверженные любым минимальным атакам. Поэтому следующий этап развития SuperGLUE как проекта внутри русского и внутри английского языка мы видим следующим образом. Диагностика должна быть больше и диагностика должна быть разбита на несколько уровней по сложности. Внутри каждого уровня по сложности должны быть взвешены тесты с определенными заданиями. Сейчас диагностика с вот этими 33 категориями, она используется на задаче нахождения причин и следственных связей в предложении. Либо есть, либо нет. Лабинарная классификация. При этом все тексты в диагностике очень разные по сложности, с чем мы боремся. В новой диагностике, в новом релизе Superglue, который, мы надеемся, будет в октябре, будут обновлены датасеты, в том числе будет абсолютно новый формат диагностики, где все задания будут разделены по уровню сложности. И мы взяли пока что три этих уровня. уровень начальной школы, средней школы и старшей, грубо говоря, постепенное изучение языка. В первой будут самые простые предложения и очень простые по смыслу, во второй уже пойдут абстрактные понятия и более сложные предметные знания, и в третьей метафоры и очень сложные понимания специальных языковых явлений. Соответственно, если На всех этих трех уровнях у модели качество одинаковое. Скорее всего, мы идем в неправильном направлении, и качество не будет расти. Нам нужно, чтобы модель, пусть даже она плохо решает сложные задания, но лучше решает простые, и на них она показывает стабильный результат, который не подвержен случайным, случайно помененным словам, грубо говоря. В этом направлении, насколько я знаю, работаем пока только мы, но другие проекты, которые существуют с лидербордами, они идут тоже в хорошем направлении. Это мультиязычные бенчмарки, в которых вот такие задания мы требуем от модели решать сразу на многих языках. То есть, если мы хотим, чтобы она научилась определять причинно-следственную связь, она должна продемонстрировать это умение на сорока языках, а не на одном, что кажется направлением хорошим достаточно. 

S00 [01:54:05]  : Можно Глеб Гусев, лаборатория искусственного интеллекта. У меня вопрос короткий, можно я задам? Если сравнить его с классическим суперглионгоязычным, как его можно сравнить по сложности задания? Вы это рассказали, но так моментально трудно. задачи, которые вы предлагаете? То есть это такие же аналогичные задачи или есть какие-то датасеты, наборы, которые кажутся посложнее или как? 

S04 [01:54:35]  : Можете вот коротко как-то характеризовать? Да, проект Russian SuperGLUE построен с полным аккуратным повторением методологии английского SuperGLUE, поэтому задания у нас все аналогичные. Но их пришлось составлять заново, но задачи все и по формату, и по сути они повторяют. 

S09 [01:54:55]  : — Хорошо, спасибо. 

S10 [01:54:58]  : — Коллеги, давайте все-таки вопросы в согласной очередности заданных или поставленных на очередь в чате. Спасибо. 

S04 [01:55:08]  : Спасибо. Я сейчас еще закончу тогда и смогу увидеть вопросы в чате, я просто их не вижу, пока я показываю презентацию. Да, хотелось сделать небольшой оловерды по поводу статьи Roadmap to Roadmap, потому что прогнозирование научного прогресса — это вещь достаточно сложная, как мне кажется, и подверженная многим факторам которые мы не можем спрогнозировать на самом деле. Развитием науки занимается, я не знаю, философия науки, методология, и у них есть апостериорные только данные, а про будущее говорить всегда сложно. Мой любимый пример про Французскую Академию Наук, которая, в частности, занималась невозможными задачами, она составляла список задач, которые нельзя сделать, как Вечный двигатель, например. Если во Французскую Академию Наук посылается работа про Вечный двигатель, работа отправляется в мусорку, потому что про это писать нельзя, это не наука. В конце 18-го, что ли, в XIX веке, они установили, что к одной из таких задач невозможных относятся задачи по установлению минералогического состава далеких планет и звезд, потому что они так далеко, что мы до них никогда не долетим, соответственно, и не узнаем. И буквально вот тогда же, когда со всей строгостью консилиум установил, что это действительно будет так, это невозможная задача, В Германии уже параллельно шли эксперименты, и была придумана спектроскопия, и через полгода после этого запрета был установлен схемический состав Солнца. Можно ли сказать, что с AGI как-то так произойдет, или можно уже строить роадмап? Мне кажется, что сложно сказать, потому что Я придерживаюсь, наверное, здесь материалистической концепции. У нас есть рабочий прототип, мы про него очень мало знаем. Давайте больше узнаем про прототип, и тогда мы сможем его лучше дистиллировать. При этом AGI может оказаться, что в сегодняшнем нашем представлении, которое тоже ограничено, подвержено разным влияниям культуры, может быть это вечный двигатель. 

S00 [01:57:18]  : А может быть и нет. 

S04 [01:57:19]  : Может быть это действительно ядерное оружие и просто надо построить roadmap. Ну вот есть такая концепция, которая появилась в 80-е и сейчас все более популярна среди нейронаук. материалистическая. Про нее тоже хочется всегда напомнить, что Так может произойти, что те концепции, которыми мы оперируем так свободно, когда мы строим какие-то схемы, когда мы строим задания, на самом деле на уровне клеточном, на уровне синапсис и в реальном устройстве мозга они не находят свое отражение. Это касается, в частности, целеполагания, желаний человека и так далее. Может быть, ничего этого нет на самом деле, и это нормально, поэтому это точно нельзя брать так как он и есть, и из нашего культурного представления о мозге строить какие-то модели. В завершение хочется еще сказать, что мне кажется, что в такой сфере, как искусственный интеллект, очень хорошо работают мультидисциплинарные вещи, и со времен даже той же Дартмутской конференции, когда одновременно сошлись люди работающие с мозгом, когда была представлена работа 7 плюс минус 2 про память, когда была на той же конференции представлена первая формальная модель языка, и когда был универсальный решатель теоремы, и все это сошлось вместе, это дало взрыв нового направления. Может быть сейчас настал момент, когда в отдельных направлениях, таких как вычислительные мощности, нейронауки, моделирование языка, мы уже достигли такого уровня, что пора опять это все соединять. Буквально на той же неделе, на которой вышла работа Roadmap to Roadmap, мне попалась вот эта статья, она свежая тоже совсем, когда с помощью соединения данных с FMRT и весов моделей T2 удалось сделать классификацию то, о чем думал человек в томографии, на уровне 5% точности. Кажется, что это мало, но на самом деле в этой задаче это очень много. И на уровне топ-5 получили 13,5% точности угадывания классификации, о чем думает человек, про какой предмет, с учетом даже предметов, которые были, их не было в трейне, а только они были в тесте. Это все равно работает. И мне кажется, что примеры работы какой-то такой, мультидисциплинарной, за ними действительно большое будущее. большое внимание к ним и к такому управлению, в принципе, оно может привести к какой-то серебряной пуле, которая так или иначе перевернет наше представление и принесет больший вклад в будущее AGI, чем продумывание даже какого-то плана может быть пока что. Спасибо. 

S10 [02:00:17]  : Спасибо, Татьяна. 

S02 [02:00:25]  : Татьяна, можно ли вашим фреймворком тестировать бота в Telegram или по другим IRC каналам или голосу? Если нет, насколько сложно его до этого уровня довести? 

S04 [02:00:52]  : Можно уточнить, имеется в виду, что мы хотим тестировать модель с помощью бота? 

S10 [02:00:57]  : Давайте я уточню, это мой вопрос. Реально недавно тут столкнулись с задачей, стали очередной релиз Д. Павлова щупать, и возник вопрос, а нельзя ли автоматизировать этот процесс? То есть, к примеру, есть разные боты, которые претендуют на conversational intelligence. Используя либо вашу платформу, либо какие-то разработки на ее основе, реализовать автоматического тюринг-тестера на чат-ботах. 

S04 [02:01:29]  : Ну, мне кажется, что это полезная очень вещь. Единственное, что надо каким-то образом собрать все технологии в одном месте. У нас автоматический тестер, он у нас есть на сайте. Можно загрузить тестовую выборку и сразу получить результат. Просто это не бот, а надо загрузить файлик на сайт. Примерно то же самое. для русского языка. Лидерборд, он такой достаточно агностичный с точки зрения методов. Нам все равно, какими методами будет достигнут хороший результат. Если это чат-бот, пожалуйста. Если это трансформер, пожалуйста. Может быть, это не трансформер будет вообще, а что угодно, что там придумают в следующие два года. Собрать это все технологически в одном месте, мне кажется, Это большая задача. Я думаю, что если бы был какой-то хотя бы больший стандарт, то можно было бы привести. 

S10 [02:02:29]  : Спасибо. 

S04 [02:02:29]  : Сейчас мы работаем по стандарту с трансформерами. 

S08 [02:02:35]  : Меня зовут Дмитрий Салихов. Я расскажу про AGI Leaderboard. Это платформа для AGI тестов. Что конкретно подразумевается платформа? Это платформа для тестирования AGI-систем или интеллектуальных агентов. то есть это набор тестов самих, их сейчас три штуки, четвертые в разработке находятся, они объединены некой общей методологией, а также есть общие принципы подсчета метрик, формата ввода-вывода, ну и другие вещи. Сама по себе эта вещь это еще проект в разработке, надеюсь, что в этом году он увидит свет. Немножко, так сказать, в сторону пока от тестов. Тезис Андрея о том, как обстоят дела в AGI, дополню вопросом несколько риторическим. Как развивать направление AGI при условии того, что у нас нет общепризнанного научного фундамента? Ну, собственно, предлагается стратегия делать как можно больше экспериментов. и реальных воплощений архитектур, основываясь на здравом смысле. Прежде всего делать акцент на новые технологии, которые раньше не были опробованы. И таким образом мы поймем, что работает, а что нет. Как нам в этой стратегии помогут тесты? Во-первых, тесты задают ориентиры для разработки условно, если ты не знаешь, какому результату должна прийти твоя архитектура, ты делаешь технологию, которая проходит тест, и получаешь некий прототип AGI. Ну или в обратном случае тест дискредитируется, и можно показать, что этот тест проходится без AGI. Второй момент — это тест должен количественно показывать, насколько мы приближаемся к цели. Если набрал больше баллов, чем в прошлый раз, то, соответственно, ты сделал движение в нужную сторону. Хотя это большой вопрос. Так прямо работает. Но тем не менее. Чем вообще AGI-тесты отличаются от ML-бенчмарков? ML-бенчмарки предполагают решение одной узкой задачи. Например, ответы на вопросы по тексту. Задача обычно известна разработчику теста заранее и, соответственно, он вкладывает свои знания и в архитектуру решения, и в данные. В случае AGI-теста задача неизвестна разработчику заранее. И это вынуждает его делать, собственно, интеллект вместо решателя этой конкретной задачи. Разница есть и в подходе к тренировочным данным. В случае с AGI-тестами данные нужны скорее для передачи идеи теста разработчику, а не чем-то, на чем можно обучать нейросетку. В связи с этим тренировочных данных предполагается очень мало или они вообще не даются, а вместо них просто идет некое описание на человеческом языке. Какие бывают критерии GI-тестов? Много характеристик, в принципе, бывает. Я расскажу о некоторых. Ну, во-первых, priors против способности к обучению. Что такое priors? Это когда от системы на входе в тест требуется наличие определенных понятий и навыков. Например, понятие того, что мир состоит из объектов, ну или навык определения симметрии на картинках. Если же мы тестируем только способность к обучению, то система может прийти на тест без этих навыков. но она должна получить их во время тестов в процессе инкрементального обучения. Тесты могут быть одномодальные или мультимодальные. Это, я думаю, всем понятно. Одномодальность, когда только текст или только картинки. Мультимодальность, когда все вместе. степень общности или g-фактор. Я называю по-другому это еще степень ненавизны. Это когда каждая очередная задача не похожа на предыдущую. Можно грубо говоря измерить от нуля до единицы условно. Сложность теста это если мы даем этот тест человеку, то какого возраста должен быть человек, чтобы этот тест был пройден, то есть измеряется в годах. Что уже сделано на Ниве AGI тестов? В целом тестов большое количество, здесь перечислены далеко не все, но некоторые были рассказаны собственно, другими участниками. Альберт рассказывал, я расскажу только лишь про некоторые. IRC, Chalet Obstructive Reasoning Challenge, это когда нужно скажем так, вычислить картинку, имея три тренировочные картинки, где показано некое логическое преобразование, связанное с ячейкой на картинке. Но очень сложно объяснить это словами, конечно, я предлагаю всем это загуглить. Очень интересный тест. Олимпиада по математике для начальной школы этот тест придумал Алексей Потапов. Там предполагается решение задачи математической, но оно оформлено не каким-то таким формальным языком, что-то типа интеграла, а обычным человеческим. И, соответственно, для решения такой задачи нужно, во-первых, понимание языка, во-вторых, понимание моделей мира. Coffee Test — это робот должен зайти в любой дом и понять, как сварить кофе. IKEA Test — это когда нужно собрать какой-то элемент мебели, имея части этой мебели и инструкции по сборке. Employment Test — это, условно говоря, мы сажаем робота за биржу фриланса, он должен найти заказчика, должен договориться о цене. взять работу, понять, как ее делать, сделать работу, внести в нее поправки и получить деньги. Настоящий тест на понимание языка — это мой тест. Его особенность в том, что он делан в виде игры, в которой нужно, скажем так, провести некую манипуляцию над словами, используя некие простейшие математические операции. дальше. Тесты различаются по степени проработанности, то есть первая группа это тесты, которые по сути дела состоялись в том или ином виде, то есть у них уже есть механика, система подсчета, какая-то платформа под ними и так далее. Они уже проводились по сути. Вторая группа это тесты, которые могли бы быть воплощены, то есть препятствий нет, но по какой-то причине они не были проведены. Ну и третья группа — это то, что пока нереализуемо по разным причинам. Например, для IKEA-теста нужны какие-то изощренные манипуляторы для роботов, которых пока еще нет технически. На этой картинке я вынес несколько тестов, сделал две шкалы по общности и по сложности, наглядно увидеть разницу между разными видами тестов. Собственно, вот общая идея тестов, которые должны войти в платформу, они должны быть достаточно общими, чтобы их нельзя было решить существующими технологиями, но при этом они должны быть достаточно простыми, чтобы их мог пройти даже ребенок. Здесь табличка, собственно, показывает все тесты в одном месте. И здесь видно, что тесты AGI Leaderboard, во-первых, они мультимодальные, во-вторых, у них довольно-таки низкий порог сложности от трех лет. Ну и то, что там присутствует и потребность в прайерах, и, собственно, возможности обучения прямо во время тестов. А здесь у нас некие технические подробности. Думаю, это можно пропустить. Ну вот, собственно, пошло само описание тестов, да. То есть это такой, можно сказать, что полет фантазии, но тем не менее. Первый тест называется «Угадай действие». То есть, агент видит некую картинку, которая состоит из двух половин, что было до, что стало после. Ему говорят, какое это действие. Допустим, шарик падает на какой-то плоскости. Вначале он ничего сказать не может, он не знает, что это за действие. Но потом ему говорят, что это падение. И увидя следующую картинку, где квадратик падает, он должен сделать некое обобщение, сказать, что это тоже падение. Собственно, то же самое со взрывом, да, и действия, они как-то должны постепенно становиться все сложнее и сложнее. Второй тест — обучение языку, скажем так, с пеленок. Агент получает на вход картинки и короткие фразы, где описано то, что происходит на картинках. И задача агента обучить, обучиться языку с помощью ассоциирования языковых конструкций с визуальными образами. Ну и, собственно, где-то нужно уже начать отвечать на вопросы, чтобы система, чтобы платформа понимала, насколько агент, собственно, начинает понимать язык. Ну вот тут видно, что на картинках, что, начиная с четвертой картинки, агент попытался ответить на вопрос. Скорее всего, вопрос означал, что это такое, и он, скорее всего, правильно ответил, потому что платформа там что-то ему сказала с восклицательным знаком. Третий тест это тест, ну, игромана, скажем так. Задача агента научиться играть в простую настольную игру. Все, что известно заранее, это то, что есть доска, она состоит из клеток, есть фишки свои, есть фишки противника. Ни цель игры, ни правила игры, ну, заведомо неизвестны. но при этом, делая ходы каким-то произвольным образом вначале, да, потом более упорядоченным, агент получает вознаграждение в ходе, то есть платформа возвращает ему реворд тогда, когда он делает что-то похожее на правило. Ну, естественно, если он выигрывает, он получает максимальный реворд. Если проигрывать, то получает большой штраф. Собственно, очень похожая задача на обычные Atari игры, но Большая разница в том, что игр должно быть какое-то очень небольшое количество, в смысле сеансов игры. Допустим, три игры подряд или пять. В ходе этих пяти игр агент должен каким-то образом понять, о чем эта игра, и начать выигрывать. Собственно, это все. Спасибо за внимание. Если у кого-то есть идеи для тестов еще или идеи о том, как эти тесты скомпрометировать, пишите мне. Пообсуждаем. 

S10 [02:14:31]  : Дмитрий, спасибо. Там вот еще у нас было два вопроса Андрею. Может быть, с них начнем, пока не забылось. Вот у Дениса Пономарева был вопрос. Для Андрея. Может быть, кто-то за Андрея сможет ответить? 

S09 [02:14:46]  : А я здесь, если меня слышно. 

S06 [02:14:47]  : Хорошо тогда. 

S02 [02:14:49]  : Слышно Андрей, да. 

S06 [02:14:51]  : Спасибо за суперинтересный доклад. У меня вопрос по первой части, который представлял Андрей. Андрей сказал, упомянул, что планируется издание книги по AGI. Дело в том, что здесь присутствуют коллеги, которые участвовали в написании аналитического документа по ЭЙЧА для Сбербанка в прошлом году. Я тоже среди них. Поэтому хотелось бы, конечно, узнать о книге более подробно. Вошел ли материал, который был аналитическим в эту книгу? Планируется книгу распространять каким-то образом? Могли бы вы что-то рассказать более подробно? 

S09 [02:15:27]  : Конечно, но в общем-то книга-то и получилась по итогам, так скажем, многочисленных доработок и переработок этих аналитических записок. Это было достаточно мучительно, потому что, в общем-то, на тот момент Было много авторов, каждый написал что-то от себя, со своим видением, и было очень сложно собрать это в какую-то единую логику. Поэтому вот, по сути, весь год текущий ушел с перерывами, чтобы за много итераций это сделать. И здесь, в общем-то, Алексей Потапов, который, можно сказать, научный редактор книги, я думаю, что можно напрямую с ним обсудить в какой мере там вошли конкретные материалы, которые изначально были написаны. В общем-то, книга писалась на основании этих материалов. Сейчас она, скажем так, эволюционировала в достаточно такой научпоп формат, то есть на широкую аудиторию. там решение, в общем-то, наших заказчиков в лице руководства банка. И, конечно же, на AI Journey у нас будет ограниченный тираж. У нас, в общем-то, Alpina Publisher сейчас занимается версткой книги, и будет ограниченный тираж на AI Journey, ну и, конечно же, дальше она поступит в общую продажу. Но я думаю, что это уже в начале 2021 года. 

S07 [02:16:58]  : Андрей, а можно тогда уточняющий вопрос? Вот эта научпоп-версия, она достаточно сильно модифицирована по сравнению с исходными материалами, там по сути дела выброшено очень много научной части, вот с этой научной частью какое-то продолжение планируется? 

S09 [02:17:19]  : Алексей, да. Мы это тоже обсуждали. Либо мы это сделаем в виде какого-то сборника. либо все-таки, ну, какую-то там вторую часть этой книги, но предлагается сейчас разобраться с первой частью и потом приступить ко второй. Ну, вот у нас тут идут дискуссии, в каком формате это сделать, но пока проще, наверное, сделать это как сборник статей. Мы с вами это отдельно обсудим. 

S10 [02:17:47]  : Хорошо, спасибо. Андрей, еще у меня к вам вопрос. Вы говорили про то, что вы используете граф, knowledge graph. Если это не секрет, какую базу данных графа вы используете и какая у вас базовая схема? Схема орг или что-то еще? 

S09 [02:18:07]  : Ну, смотрите, это сейчас очень такая экспериментальная разработка, скажем честно, и мы сейчас вот с Сергеем Неполенко из Pomeran делаем этот мир, скажем так, да, по наполнению графа из неструктурированных источников данных. Что касается Сбербанка, то внутри разработано собственный движок, там он называется Fast Graph, И поскольку у нас очень большие объемы данных, там даже если мы говорим про клиентов, то там десятки миллиардов связей и никаких существующих архитектурных движков нас не удовлетворяют по SLA, там связанных со скоростью обработки. Поэтому у нас отдельная команда, в общем-то, несколько лет делала собственный движок FastGraph. Мы его пока не даем в открытый доступ, но общем-то на нем сейчас строится в том числе knowledge graph. Да, это InMemory, и у нас пока нет какого-то Knowledge Graph заполненного, ну так как есть там условно у Google, то есть у нас сейчас есть граф там о клиентах, большей частью, и есть набор сервисов, которые мы даем, с помощью которых можно собрать собственный граф знаний, но мы пока решили не собирать единый граф знаний, ну на весь, на всю организацию. есть несколько разных подразделений, каждый из которых собирает свой собственный. Поэтому, ну и дальше вот у нас эта задача, эта идея с суперэмбеддингами, как некими представлениями сущностей, через которые можно будет, ну, попытаться решать более лучшие задачи, но это всего лишь один из подходов. Мы пока не знаем, к чему он приведет, и приведет ли вообще, и тут правильно было неоднократно замечено, что надо заниматься всеми, и мы не знаем, что выстрелить раньше. 

S10 [02:20:07]  : — А уж если у вас своя БД, то тоже, если не секрет, у вас она гиперграфовая или это вот обычные триплеты РДФ-100? 

S09 [02:20:16]  : — Не, ну это они гиперграфовые, конечно же, потому что там типы связи даже между двумя объектами, их существует там десятки разных. и это потребовало особого способа хранения этих связей. Но вот что касается темы с super-embedding, это еще не стадия реализации, это стадия, скажем так, идеи. Поэтому здесь основная идея, как соединить графы знаний, как для нас это некая перспективная история, которая может существенно нас приблизить, скажем так, к решению более сложных общих задач с темой представления этих вершин, ну, в общем, всех успехов, связанных с embedding, вот как пересечь эти две темы. Пока вот не так много, конечно, на эту тему работ, но они уже есть. Мы планируем поисследовать, в том числе и там вот часть людей, которые здесь выступали, там и Дима Салихов. У нас отдельная команда, в общем-то, есть, которая и только графами занимается, и только NLP. Вот сейчас мы их как-то объединяем в этом плане. Есть команда компьютерного зрения, И вот на пересечении когнитивных навыков мы сейчас ищем какие-то новые способы для решения задачи. 

S10 [02:21:47]  : Спасибо. Коллеги, у нас нет вопросов больше. Мы уже даже вывалились за регламент, но может быть какие-то короткие вопросы есть? 

S01 [02:22:03]  : Ну есть вопрос, можно? 

S10 [02:22:06]  : Пожалуйста, Мария. 

S01 [02:22:08]  : Я тоже из Сбербанка, я как раз из лаборатории нейронаук, знакома тут со многими коллегами. Дим, скажи, пожалуйста, как бы я там писала уже в час, что с этими тестами прекрасными, те, которые ты там приводил в примеры, далеко там не каждый человек справится, да? И вот у нас есть набор тестов, которые в итоге совсем простые для General Intelligence, да? Есть ли какое-то понимание, представление о том, как это может развиваться? Такой, скорее, более философский, может, не сейчас, но практическую часть. Как ты думаешь, эти тесты будут развиваться примерно так же, как для людей, для более старшего возраста тесты будут похожими, более сложными? либо для конкретно машинного интеллекта они будут существенно отличаться от естественного, и почему? Как тебе кажется? 

S08 [02:23:00]  : Я думаю, что вообще все, что касается существующих тестов, это вопрос еще на научном этапе. И, собственно, это просто троческий полет. в течение двух недель я эти тесты придумывал, описал и так далее. Поэтому мы с вами уже сотрудничаем с вашими ребятами и, в принципе, очень полезные советы прислали, поэтому на все могу ответить утвердительно. Скорее всего, это будет... кому-то надо встать на мьют. 

S09 [02:23:36]  : на фоне звучи. 

S08 [02:23:38]  : мне кажется у Альберта Ефимова. Будет просто много разных версий одного и того же теста. То есть тест для очень глупых машин, для машин поумнее, для людей и так далее. То есть мы, скорее всего, будем их диверсифицировать и пробовать, какие более удачно проходят, какие менее удачно и так далее. В общем, это все будет развиваться. 

S10 [02:24:12]  : Вот еще вопрос поступил по поводу Триза, у вас, которого придумал Альтшулер. 

S02 [02:24:19]  : – Антон, мне кажется, не стоит сейчас затевать дискуссию про Триза, в том числе. Все-таки вам под конец это слишком, мне кажется, серьезно. Да, это уже перейдет точно в полночную дискуссию. 

S10 [02:24:34]  : – Тогда, может быть, вы подведете итог и дадите какую-то дополнительную информацию? 

S02 [02:24:40]  : Да, коллеги, спасибо вам большое за ваше активное участие. Сейчас я выложу ссылку на наш вопрос. Да, единственное, что, наверное, это только для наших участников среди коллег из Сбербанка, но посмотрим, может быть, и для внешних тоже эта ссылка будет доступна. Спасибо за ваше активное участие. Мне кажется, Антон, согласитесь вы или нет, наше сотрудничество удалось. Мы с вами, вот ссылку выложила, можете проходить и активно голосовать. Наше сотрудничество, мне кажется, плодотворно продолжится. Мы с вами, если я не ошибаюсь, на декабрь запланировали наше следующее совместное мероприятие. Большое вам ещё раз спасибо за вашу площадку, за ваших прекрасных, интересных экспертов. Думайте, что нам вместе будет интересно поразмышлять и на другие темы. Большое спасибо всем тем, кто с нами уже третий час, но мне кажется, что это было очень интересное для всех нас время. 

S05 [02:25:57]  : Мне кажется, еще хочу поблагодарить и Ксению, и Антона, и Ивана, которые все это организовали. И, конечно, Сергея, Татьяну, Андея, Дмитрия, которые сейчас здесь выступили. Ребята, вы большие молодцы. Мне кажется, отлично сделали первый шаг к тому, чтобы сделать повторение Рейша Клаб, который создавал Аунт Юнг. 

S02 [02:26:18]  : А тебе спасибо за вдохновение. 

S10 [02:26:20]  : Спасибо всем докладчикам. присутствующим и организатором. 

S09 [02:26:26]  : Антон, а тебе спасибо хорошего пляжного сезона, судя по всему. 

S10 [02:26:32]  : А, да, виртуального пляжного сезона. 

S09 [02:26:34]  : Виртуального пляжного сезона. Да, Андрей, спасибо. Все, всем пока. 

S05 [02:26:40]  : Пока. Андрей, береги себя и семью. Да, пока. 

S09 [02:26:43]  : Спасибо, Альберт, будем рады. 

S04 [02:26:47]  : Спасибо, коллеги. До свидания. 

S10 [02:26:49]  : Спасибо всем! 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
