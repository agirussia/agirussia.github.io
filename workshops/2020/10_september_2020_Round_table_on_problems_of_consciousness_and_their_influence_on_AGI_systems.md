## 10 сентября 2020 - "Круглый стол", посвящённый проблемам сознания и их влиянию на системы AGI (Artificial General Intelligence или Общий Искусственный Интеллект) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/B9aDvikjAhw/hqdefault.jpg)](https://youtu.be/B9aDvikjAhw)

Суммаризация семинара:

Семинар посвящен проблемам сознания и их влиянию на системы искусственного интеллекта (AGI). В ходе семинара были рассмотрены различные аспекты сознания, включая его механистическое представление, модели внимания и связь искусственного интеллекта с сознанием.

Общая тема и контекст:
Семинар начался с обсуждения использования естественного языка и определения понятий в системах AGI. Участники семинара подчеркнули, что для полноценного взаимодействия агентам общего уровня необходим сознание. В частности, Владимир Сергеевич Смолин и Владимир Васильевич обсудили тему "мир зомби" и его представимость, а также свободу воли и личности наделенных сознанием.

Тематические блоки:

1. Механистическое представление сознания:
   - Участники семинара обсудили, что сознание может быть представлено как модель внимания, действующая на четырех уровнях сознания.
   - Анна Андреевна Лупенченко представила модель внимания, которая действует на четырех уровнях и является общей для человека, искусственного интеллекта и человека с экзокортексом.

2. Модели внимания и сознания:
   - Было отмечено, что внимание и сознание тесно связаны, и что сознание может быть рассмотрено как присмотр за направлением внимания в деятельности.
   - Участники обсудили, что сознание необходимо для решения качественных задач, таких как написание текста или игры в шахматы.

3. Связь искусственного интеллекта с сознанием:
   - В ходе семинара было подчеркнуто, что для искусственного интеллекта сознание необходимо для качественного решения задач.
   - Участники обсудили, что сознание и искусственный интеллект могут быть рассмотрены как взаимодействующие системы, где искусственный интеллект помогает решать задачи, становящиеся все более сложными.

4. Экзокортекс и коллективное сознание:
   - Было обсуждено, что экзокортекс (внешняя система обработки информации) играет важную роль в удержании внимания и сознании.
   - Участники семинара выделили четыре уровня сознания, но также отметили, что возможно существование и более высоких уровней сознания, включая коллективное сознание на уровне эпохи.

5. Собранность и удержание внимания:
   - Важным аспектом обсуждения стало понятие собранности, как удержание внимания до изменения состояния физического мира.
   - Участники семинара подчеркнули, что изменение поведения на соответствующем уровне (от привычки до жизни) и удержание внимания до изменения состояния мира является ключевым для изменения некоего состояния мира.

Итоги и выводы:
Семинар показал, что сознание и искусственный интеллект тесно связаны и что для создания более интеллектуального искусственного интеллекта необходимо рассматривать сознание как повторимую модель. Участники обсудили, что для изменения состояния мира необходимо изменить поведение и удержать внимание до изменения состояния мира. Семинар также подчеркнул важность коллективного сознания и экзокортекса в современном мире.



S06 [00:00:02]  : Коллеги, предлагаю начать. Всех приветствую. Сегодня агентство искусственного интеллекта совместно с сообществом разработчиков систем общего искусственного интеллекта проводит семинар по проблемам сознания. Сегодня мы постараемся обозначить и раскрыть суть этих проблем и как это связано с искусственным интеллектом. Сейчас ни для кого не секрет — тема искусственного интеллекта горяча как никогда. Достижения, которые мы имеем в микроэлектронике, которые позволили получить относительно дешевые колоссальные усилительные мощности и, можно сказать, ограниченное пространство для хранения информации, позволяют сейчас создавать искусственных интеллектуальных агентов, И сервисы на базе искусственного интеллекта, робота, наделенный этим интеллектом, выполняют широкий круг задач. И в большинстве случаев эти задачи они выполняют лучше, чем среднестатистические особи вида homosapiens. Понятно, что Это серьёзно повлияет на развитие нашей цивилизации, и Brandeis утверждает, что к 2030 году роботы могут отобрать у россиян почти половину рабочих мест. В зону риска попадут 20 миллионов человек. По оценкам Фонда развития интернет-инициатив, в ближайшие 10 лет стране сократят до 6 миллионов человек. Еще 25 миллионам придется переучиваться, чтобы сохранить свою работу. На всемирном экономическом форуме предсказали потерю 75 миллионов рабочих мест к 2022 году. Но это по всему миру. Под нож попадут такие профессии, как бухгалтеры, нотариусы, кассиры, курьеры, охранники, водители, секретари, банковские служащие, сметчики, переводчики, операторы полцентров. Это все виды деятельности, которые хорошо формализованы и имеют низкую вариативность. Роботы активно осваивают даже творческие профессии. Так вот Microsoft, Forbes, Associated Press уже сейчас используют искусственный телег, чтобы писать новости по некоторым направлениям, таким как бизнес или спорт. На очереди, таким образом, профессии копирайтеры, радиотелеведущие, блогеры, шоумены. Дипфейка — это вот всё туда же. В общем, искусственный интеллект наступает, но если мы погрузимся в технологии, лежащие под громкими заявлениями, под этими страхами и шумихой вокруг всего этого, то вдруг мы поймем, что искусственные интеллектуальные агенты в существующем виде — это сервисы или роботы — они на самом деле отнюдь не так интеллектуальны. Они очень и очень далеки от общего уровня интеллекта того же среднестатистического человека разумного. Да, такие интеллектуальные агенты умеют, или даже лучше сказать, когнитивные агенты, могут распознавать определенные визуальные образы, распознавать звуки, понимать смысл написанного или сказанного, двигаться и тому подобное, но наделены ли они сознанием? Это тоже вопрос. И сейчас мы на него отвечаем, что точно нет. А что будет в будущем? Можно ли в принципе создать искусственного агента, наделенного сознанием? И нужно ли это делать? Можно ли вот функционирование такого агента сопроводить с объективными приватными состояниями, чтобы он осознавал себя и его деятельность не проходила, ну скажем так, во внутренней темноте? Вот, что ж, давайте постараемся сегодня найти ответы на эти вопросы, и мне кажется, что это будет очень интересно. Начнем с Анной Андреевной Лупенченко, которая представляет Школу системного мышления. Анна нам сегодня расскажет, как принципиально можно подобраться к проблеме сознания через рассмотрение модели, которую вывели на основе исследований на стыке областей нейробиологии и искусственного интеллекта. Анна, прошу ваш доклад. 

S02 [00:04:39]  : Владимир, спасибо большое за представление. Да, действительно, мы сегодня поговорим о том, как в школе системного менеджмента и, в частности, в системном мышлении мы рассматриваем проблему внимания и сознания. И основные тезисы, которые мы будем сегодня рассматривать, это четыре темперальных уровня внимания, которые выделили в школе. Вот, соответственно, общая модель сознания, которая действует на тех четырех уровнях, и в проблему extended cognition, то есть экзокортекса, и как раз в проблему связи искусственного интеллекта и насколько он интеллектуальный, обладает ли он сознанием. И как мы применяем эти положения у нас в школе. И начнем мы с того, что мы, если вы обратили внимание к тему доклада, что мы говорим не только о сознании, но и о внимании. И почему мы начинаем с внимания. Потому что в последние годы пошел тренд на исследование, когда пытаются исследовать сознание, начинают исследовать внимание. Почему так? Пытаются демистифицировать. Последние исследования в области сознания пытаются демистифицировать. сознание, лишить его вот этого мистического, субъективного, неповторимого компонента, фактически вот такого магического, неповторимого ореола, M-consciousness, то, что называется, мистическое сознание. Если раньше рассматривать, у нас есть некий мистический, неповторимый опыт, который не может быть повторить ни человек, ни машина, ничего, все остальное, то в последние годы начинают пытаться рассматривать сознание иначе, как некую повторимую модель. И, в частности, это произошло в результате попыток создать более интеллектуальный искусственный интеллект, который смог бы решать всё более и более сложные задачи. То есть, как уже упоминал Аладдин, написать новости, решать, проводить, исследовать неочевидные, находить неочевидные закономерности, даже проводить какие-то, может быть, научные исследования, копирайтеры и всё-всё-всё, вот это всё туда же. И что в этих всех исследованиях общего, то что сознание здесь рассматривается как способ управления вниманием. И что конкретно в школе мы взяли? Внимание мы, в принципе, подробно на определении внимания мы рассматриваем, мы останавливаться не будем, мы можем сказать, что только что в самом общем виде мы внимания рассматриваем, выделение этих фигур. Исходно, как в механической традиции, главное у нас то, что мы рассматриваем, мы говорим, что внимание также имеет свои четыре системных уровня. Что мы рассматриваем внимание не просто моментальное внимание, как то важное, на что мы осознанно направляем внимание в данный момент, фигурой сфоны, которую мы уделяем в данный момент. Мы говорим о том, что у нас внимания бывает на четырех уровнях. Как мы их выделили? Просто рассмотрели виды деятельности, человеческой деятельности на временной шкале и учли основные типы психопрактических процедур. Почему так? Потому что в целом, именно в системном мышлении нас интересует человек как деятель, который каким-то образом меняет физический мир. И поэтому нас интересует его деятельность, что у него происходит в рамках этой деятельности в течение разных временных промежутков. И поэтому наше выделение именно такое. Сразу оговорюсь, что выделение у нас, эти четыре аспекта внимания, которые мы выделили, четыре уровня внимания, это не единственный способ выделять эти уровни внимания. Мы не претендуем на то, что это единственное уникальное для всех, но мы говорим о том, что именно вот такое рассмотрение внимания помогает нам с этим что-то делать в школе. Конкретно что, я еще все время смотрю. Мы в школе системного менеджмента, одна из наших новостей, мы выделяем четыре уровня внимания. Это мгновенное внимание, это состояние эмоций в момент действия мышления. При том момент это такая канарная личина, в принципе он может длиться как от нескольких миллисекунд, что данную миллисекунду или даже секунду направлена ваше внимание, до примерно полутора минут. Поэтому в моменте могут быть тоже разные темы. Есть фокусное внимание. Это удержание внимания на рассуждении. Обычно мы говорим, что фокусное внимание длится в течение десятки минут-часов. Все известные техники вроде Pomodoro, они как раз действуют на уровне фокусного внимания. У нас есть также привычное триггерное внимание. Это внимание на уровне постановки привычки и удержания этой привычки, пока оно не становится автоматизмом, пока мы не применяем ее на автопилоте. То есть это могут быть дни, месяцы, вплоть до нескольких лет, если это какая-то большая сложная привычка. И четвертый уровень — это уровень, на котором мы уделяем внимание нашим психологическим интересам, нашим потребностям, нашим лонгитудным состояниям. Это уровень, на котором мы занимаемся своим личным стратегированием и определяем, чего мы хотим от жизни в целом. И как мы будем, допустим, что мы будем делать в течение нескольких лет следующих. Это может быть в нескольких лет, в нескольких десятках. 

S06 [00:10:11]  : Можно вот по ходу... Вопрос, мне кажется, он важный. Александр Соколов спрашивает, а что все-таки понимается под вниманием? 

S02 [00:10:20]  : Внимание, я говорила еще до этого, сказала, что в целом мы рассматриваем внимание как некое выделение фигуры сфоны, обращение внимания на выделение фигуры сфоны, на то, на что мы обращаем внимание сознательно или не сознательно. То есть, как психонетическая традиция, выделение фигуры сфоны. Сказать, что это то, от чего мы получаем информацию, скажем так. Мы говорим о том, что у нас уровни внимания, они системные, выделяются вниманием в работающей системе. И что у нас каждый следующий уровень внимания воспринимается как поток непрерывного состояния предыдущего уровня. То есть что это означает? Это означает, что если мы рассматриваем уровень привычки, то мы не говорим о том, что если вы непрерывно удерживаете внимание на постановке привычки, то это не значит, что вы думаете о нём каждую секунду, каждую минуту, каждый час. Это значит, что вы, допустим, каждую, если вы хотите поставить себе привычку тренироваться раз в неделю, допустим, по средам, то это значит, что вы каждую среду идёте в спортзал, например, и тренируетесь, и вот без пропуска. Вот это действительно означает непрерывность. Если вы пропускаете, то, естественно, непрерывность нарушается. поток внимания в предыдущий уровень. И что у нас чаще всего как раз запрос на внимание идет с уровня выше, то есть если мы хотим что-то сделать, то чаще всего нам нужно сначала подумать, что сделать, потом нужно этим, скажем так, определиться, допустим, в жизни определиться с чеми направлениями или с теми проектами, которые мы будем реализовывать. И, соответственно, дальше уже эти... планировать неким образом эти работы по этим проектам и их выполнять. При этом чаще всего, если запрос идет с уровня выше, то чинить проблемы чаще всего нужно на уровне ниже. Допустим, на уровне постановки привычки. Скажем, если у вас есть проблемы на уровне постановки привычки, то Возможно, во-первых, в первую очередь, вы должны действовать уровнями, допустим, методами, которые способствуют поставке на привычки, создать условия подходящие и прочее. Если это не помогает, если вы не можете сфокусироваться на этом, или вы не можете сфокусироваться, например, на чтении книги в течение часа, то, скорее всего, у вас есть проблемы на более низком уровне внимания, допустим, на уровне внимания моментального. Вам нужно спускаться на этом уровне ниже и чинить направление ваших органов чувства, некие фигуры из фона конкретно на этом уровне внимания. И мы говорим о том, что у нас сознание — это механизм управления вниманием на всех этих уровнях. включая осознание уровня жизни. Жизнь здесь рассматриваем как жизненное внимание, это длинная временная шкала 20-30 лет, а не как разные аспекты жизни, разные ваши сферы, ваши споры, ваша семья и так далее. И основной принцип, который мы говорим в системном мышлении, это то, что мы, в первую очередь, идем в верхней шкале. Когда мы рассматриваем внимание, мы не рассматриваем то, что происходит с человеком на биохимических уровнях, на нейрофизиологическом уровне. Когда он обращает внимание, скажем, когда он читает книгу или слушает музыку, мы в первую очередь рассматриваем всегда внимание с точки зрения нашей деятельности и того, что мы делаем. И, соответственно, мы идем вверх для того, чтобы реализовывать постоянно проекты все более и более сложными, повышать сложность решаемых нами задач. И это важный момент, который здесь мы выделяем. И в нашей модели сознания именно внимание является основой. Новейшие исследования, которые в последних лет строят модель сознания вокруг внимания. Это стандартная модель сознания, которая появилась, исследования, которые там появились, тексты, которые появились в 2019 году от Грозиана, которые построены на более ранних исследованных текстах, это и теории глобального пространства, это и китайские теории, это и теории сознания высшего порядка и прочее, это и теории обязательной схемы внимания, и эксперименты для тестирования этой схемы внимания и модели сознания. Ну и, разумеется, предсказательные кодирования predictive coding и active inference. И основные эти положения теории сознания, которые мы используем для выведения модели внимания, это, как мы уже говорили, то, что у нас сознание мы рассматриваем чисто механистически, без духовности, без эзотерики, без какого-то исключительного объективного опыта. И сознание рассматривается как скелла для внимания. То, на что, то, как, и каким образом мы обращаем внимание на некие объекты из фонда. Внимание к тому, на что направлено внимание. допустим, в ходе разговора вы обращаете внимание на то, как вы говорите, что вы говорите, контекст, которым вы говорите, может быть, даже вы обращаете внимание на окружение, в котором вы говорите. То есть аналогия для схемы внимания, это подобрано было из нейрофизиологии, это схема тела нейрофизиологии, при помощи которой, например, объясняются такие явление как остаточная боли при ампутации в конечности. И мы говорим, что у нас в модели, что у нас внимание и сознание связаны через процесс cognition, то есть некое восприятие или познание. в том числе внутреннего вычисления мышления. Процесс построения неких картин мира, процесс выведения неких закономерностей, паттернов и предсказаний дальнейшего состояния мира и для того, чтобы действовать в этом мире. Мы все время говорим о деятельности. Мы обращаем внимание на то, зачем человек действует. Говорим, что у нас cognition — функция отважности и осознанности информации, и что у нас сама модель сознания строится как компьютерная, с входами и выходами, и потоками информации в обе стороны. В общем-то, это модель сознания, мы рассматриваем ее на английском языке просто потому, что у нас именно модель, более терминология вся взятая из английского языка, Предложен русский перевод, у нас есть отдельный слайд, я покажу его дальше, но мы прочитаем все-таки английскую терминологию, именно просто потому, что она являлась базовой и более, скажем так, точной, например, потому что, конечно, перевод на русский язык можно перевести двумя способами, и как восприятие, и как познание, и, к сожалению, не вполне отображают русские термины всегда то, что имеется в виду на английском. Что мы говорим? Мы говорим о том, что у нас модель сознания общая на всех четырёх уровнях. От первого уровня, мгновенного, до жизненного внимания. И что ей соответствуют такие же уровни сознания, мгновенное сознание, до жизненного сознания. И что они связаны при помощи информации, при помощи процесса когнища. То есть у нас на входе мы получаем наших органов чувств и информацию, визуальную, аудиальную и прочее. И через процесс вот этого восприятия, познания функции нашей осознанности, мы осознаем информацию или не осознаем, на что мы обращаем внимание, И функция отважности, выделяем, обращаем, что важно, а что не важно. В ходе разговора, например, на улице мы обращаем внимание на разговор, а не на шумы проезжающих машин. Для нас это не важно. В нашем сознании они не задерживаются. И на выходе, получается, мы получаем здесь предсказанное состояние мира. И в дальнейшем, в соответствии с предсказанным состоянием мира, мы действуем, возможно, действуем дальше и получаем некую новую информацию. И если мы хотим изменить результаты, которые мы получаем в реальном физическом мире, результаты нашей деятельности, то нам нужно сделать следующее, нам нужно изменить вот эту закономерность. И изменить эту закономерность мы можем при помощи сознания. Мы загрузить некий изменившийся паттерн поведения, скажем, мы поставим себе привычку. Мы курили до этого, мы хотим, допустим, избавиться, например, от привычки курить. И курить мы начали как-то, как-то вот, ну, Так повелось, что вы начали курить, да, и у нас, соответственно, из-за этого, может быть, ухудшается здоровье. Хотим получить более здоровое тело. И поэтому мы сознательно, например, отказываемся от курения, используем практики внимания, которые на соответствующем уровне внимания выделены, и пытаемся изменить состояние. И нам нужно, что в этом процессе в этот момент важно, нам важно удержать внимание вот здесь на как раз вот этом изменении своего образа жизни для того, чтобы получить более здоровое тело. Мы влияем, как отмечено здесь, мы входим при помощи сознания, мы можем влиять на что? Мы можем влиять на то, на какую информацию мы обращаем внимание, на какую информацию мы предаем. Предаем ли мы в ходе разговора или размышления, практики, на какую информацию мы предаем более высокий уровень важности, приоритетности, какой более низкий? осознаем ли мы, что скрыто за словами, не осознаем. То есть мы можем вот это все выделять для того, чтобы в дальнейшем там изменить наше паттернное поведение. И точно так же в ходе, когда мы пытаемся удержать внимание, скажем, на нашем изменившемся паттерне поведения, удержать внимание на привычке отказаться от курения, на привычке ходить в спортзал, то мы можем опять же осознавать Что мы делаем сейчас? Мы сейчас пытаемся, скажем, пропустить наш очередной поход в зал, просто потому что, например, не хочется, или тяжело, или лень. И важно ли в этот момент для нас все-таки встать и пойти, перебороть себя, или это не важно. Здесь это то, на что мы можем влиять. Остальное, в принципе, то, что мы говорим, то, что мы особо не влияем. И мы говорим то, что здесь новация, то, что если есть разные уровни внимания, то значит есть разные уровни сознания. Соответственно, с этими разными уровнями сознания можно и нужно работать иначе, по-разному, по разными практиками, разными способами. Вот, собственно, модель внимания здесь на русском, с русским переводом вы видите. Здесь можно будет, если у нас будет доступна презентация, надеюсь, можно будет его посмотреть, презентация. Как мы применяем это все? Мы говорим, во-первых, что если рассматривать модель сознания так, как рассматриваем ее мы, то она получается общая и для искусственного интеллекта, и для человека, и для человека с экзокортексом. Внешняя система — это обработка информации человека с искусственным интеллектом. Также мы говорим, что здесь при помощи такой модели мы можем даже выйти на коллективную модель сознания, что у нас, возможно, и не просто индивидуальность мы рассматриваем при помощи такой модели, не только индивидуальное сознание, но и коллективное сознание, коллективное построение картин мира и удержание схемы ситуации. То есть, например, сейчас наша презентация PowerPoint удерживает и мое, и ваше внимание на том, что я говорю, что я рассказываю. тезиса. Онлайн-табло в очередях удерживает внимание, допустим, в очереди, например, в Циберпанке может удерживать внимание большого количества людей на то, куда подойти, к какому окошку. То есть внимание и кассиров, допустим, операционистов, и внимания людей, которые сидят в очереди. И мы говорим о том, что в принципе мы сейчас выделяем четыре уровня сознания, но вполне возможно, что и будет уровень сознания выше четвертого. Это коллективное сознание, сознание на уровне, допустим, эпохи. И, соответственно, что для нас важно, мы говорим о том, что если мы говорим о внимании сознания и о том, что если мы хотим изменить некое состояние мира, то нам нужно, допустим, изменить паттерн своего поведения. изменить свое поведение на соответствующем уровне, на уровне привычки, на уровне рассуждения, на уровне выполнения отдельных задач, например, или на уровне жизни, на постановке задач жизненного стратегирования коллективного. Нам нужно изменить паттерн и удержать внимание до этого момента, пока ситуация не изменится, пока не сменится состояние физического мира. И вот это удержание внимания мы называем собранностью, то есть это в английском self-collectedness и computer-aided collectedness. Мы говорим, что мы включаем как и личную собранность, личное собирание себя в кучку для того, чтобы сделать что-то, как и коллективное. То есть это собирание больших коллективов людей для того, чтобы реализовать большие сложные проекты, в том числе сделать более интеллектуальный интеллект. И мы говорим, что у нас собранность 13 цифр для разных системных уровней. Четырех, даже пятого коллективного сознания. Соответственно, Если рассматривать гаджет так, то мы говорим, что в процессе восприятия участвует расширенный состав психики. Мы включаем в него не только тело и мозг, но и гаджеты и экзокортекс. И мы говорим, что экзокортекс — это внешняя система обработки информации, это ваши записные книжки, ваши заметки в телефоне, это может быть ваш блок, если вы видите такой блок, ваши посты и прочие, ваши записки, заметки, любые ваши списки дел, которые, опять же, вы можете ввести, конечно, на ручке с бумажкой, но все-таки большинство уже предпочитает как-то это ввести электронным виде, просто потому что это удобно. И мы говорим то, что Экзопортекс здесь мы используем для эффективного удержания внимания как вашего личного, так и коллективного. Всякие системы, модели коллективные, допустим. Это модели для проектов, системы для управления жизненным циклом проектов, это системы для проектового менеджмента в отдельных проектах, например, инжиры. Есть примеры из-за корпуса. Либо, допустим, ваша личная база знаний. И если мы рассматриваем сознание так, если мы рассматриваем человека, не просто человека, но человека с бумажкой, то говорим, что в принципе с проблемой зомби особо у нас нет проблем с зомби, потому что у нас как бы зомби нет, у нас все происходит, у нас человек, у нас нет отдельного искусственного интеллекта, отдельный человек, они у нас взаимодействуют, и, в принципе, искусственный интеллект просто нам помогает, нам нужен для того, чтобы помогать решать задачи все более и более повышающейся сложности. То есть то, что там роботы не заберут работу, просто у нас сумма труда на планете не константа, да, и то, что мы Наоборот, работа нам позволит повысить сложность задач, которые решают люди с абсолютно, допустим, разным уровнем готовки. И, соответственно, на курсах в Школе истинного маркетинга мы предлагаем практики собранности не просто для человека, но для человека с компьютером. Мы сразу же ставим Вот Compute Rapid Collectiveness, да, которое включает себя и мышление всего моделирования — это то, чтобы люди более эффективно решали свои задачи в жизни, чтобы они создавали более сложный проект, который утилизирует интересы большего числа людей, чтобы они решили повышающиеся задачи, более сложные и сложные задачи успешно решали. и получали более полную, интересную, утвержденную жизнь. И, в частности, мы это делаем на наших курсах в курсе системной собранности, курс в данный момент называется «Введение на…», где мы предлагаем практике собранности на четырех уровнях сознания. И у нас студенты пишут посты, блоги даже по этим всем, про пройденную информацию. Это у нас уже есть. И, в принципе, мы также ведем исследования, и исследования ведутся группой. В частности, Анатолий Левенчук занимается системным рассмотрением сознания, у нас Пион Ведерис, который изучает агентность, Александр Вяткин — это inference, собранность психопрактики изучает я, и у нас также по пятнице найдется открытая семена 19.5, найдется открытая семена «Системный подход к жизни». И записи у нас есть в логифере. И таким образом мы... предлагаем эти практики в собственности, говорим то, что в принципе на этих разных уровнях сознания, и говорим то, что искусственный интеллект нам не помеха, не проблема, с зомби нет, мы рассматриваем то, что мы рассматриваем всегда людей вместе с компьютером, потому что это позволяет нам, это искусственный интеллект нам не опасность, а нам помощь. решение нашей задачи. На этом все. 

S06 [00:28:53]  : Спасибо большое. Есть несколько вопросов из зала. Я предлагаю дать слово Борису Новикову. Он, я думаю, что несколько вопросов задавал и сейчас уже после вашего доклада сможет, может быть, это консолидировать и спросить у вас. Борис, 

S01 [00:29:14]  : Здравствуйте. Меня слышно? 

S00 [00:29:17]  : Да, слышно. Здравствуйте. Значит, у меня первый вопрос. Вы пользуетесь естественным языком и не определяете понятия, пользуетесь ими как словами с многозначным смыслом? Да. Или вы строите некоторую модель, которая есть неопределяемые понятия и есть определяемые? Если так, то как? неопределяемое, что определяемое, как определяемое. 

S02 [00:29:46]  : Смотрите, мы в первую очередь пользуемся естественным языком, не говорим, что у нас прямо точные определения, точные четкие определения для всего, всего вместе и сразу. Вот не совсем, возможно, правильный подход, который может какие-то упустить какие-то отдельные моменты. Жизнь здесь рассматривается как сознание жизни, это как уровень сознания, уровень внимания. И здесь жизнь мы рассматривали как разные аспекты жизни. Тут зависит от контекста, который мы рассматриваем. Сказать, что мы прямо четко, что здесь четкая иерархия, нет. 

S00 [00:30:33]  : Хорошо. 

S06 [00:30:33]  : Спасибо большое. У нас еще три докладчика. Я вот вижу ваши контакты на экране. Я думаю, что коллеги, которые задавали вопросы, у нас их контакты тоже есть. В принципе, можно и прямой контакт установить. И эти вопросы мы, естественно, без внимания не оставим. Спасибо большое. Переходим к докладу Романа Викторовича Душкина, директора по науке и технологиям Агентства Искусственного Интеллекта. Роман в своём докладе затронул глубокую философскую тему, и сейчас он нам расскажет, в чём вопрос. Роман Викторович, прошу вас. 

S03 [00:31:25]  : Здравствуйте, коллеги. Приветствую всех участников нашего круглого стола. Запускаю таймер, чтобы не выбиться из регламента. Анна, спасибо большое за такое этакое введение в проблему, что такое сознание и как оно управляется. Слушатели разогретые, я сейчас представлю больше такой философский доклад на тему вопроса о распознавании и дифференциации философского зомби. Вот вы на экране видите человека, кто ввел в понятие философский зомби — это Дэвид Чалмерс. Собственно, давайте поговорим об этом, зачем нам нужно об этом говорить, и можем ли мы в принципе распознать и дифференцировать философского зомби. Итак, Владимир меня уже представил. Я директор по науке и технологиям агентства искусственного интеллекта. В конце слайда будут мои контакты. Опять же, все могут написать, обратиться в свои вопросы. Но я надеюсь, мы в конце моего доклада побеседуем на эту тему. В общем-то, как обычно я говорю, будущее уже здесь, в нашем агентстве работает искусственно-интеллектуальный секретарь, ее зовут Мария, и прямо сейчас по указанному идентификатору в Телеграме вы можете к ней обратиться и забрать эту презентацию, она вам ее отправят Просто спросите у неё презентацию, докладу по вопросам сознания или напишите. название этой презентации, вопрос о дифференциации философской логики. Как-нибудь так, в любом, в любой фразе, которая как-то намекает на наше текущее мероприятие, название презентации моей, она ее распознает и пришлет вам презентацию. Я надеюсь, иногда она чувствует себя не очень и, собственно, присылает не то. Но попробуйте. Тем не менее, вопрос. Вот Мария. Есть ли у неё сознание? И Дэвид Чалмерс придумал такой мысленный эксперимент для того, чтобы попытаться сказать, что те те искусственные когнитивные системы, которые мы создаём, они, в общем-то, от людей будут отличаться. И мы сейчас речь ведём немножко о другом сознании, чем то, о чём говорила Анна в предыдущем докладе. Я веду речь о так называемом феноменологическом сознании. Это тот набор внутренних ощущений, который называется квали, которые Мы воспринимаем прямо сейчас, каждое мгновение в своей жизни, мы воспринимаем весь набор, весь комплекс ощущений. Это воспринимается тем, что мы называем своим «я». Собственно, концепция философского зомби, которая введена Дэвидом Чалверсом, заключается в том, что можно представить себе гипотетическое существо, которое выглядит как человек, которое ведёт себя как человек, которое абсолютно неотличимо от человека в принципе никак, но только у него всё темно внутри и тихо. То есть у него нет вот этих внутренних квалитативных состояний, феноменологического сознания, о котором я говорю, набора квалификаций. Но фактически… Дэвид Шалмер задает вопрос, зачем они нужны, эти хвали? Зачем нужны? Ведь можно реализовать когнитивные системы, которые будут действовать как человек, но при этом у них будет всё темно внутри и пусто. Действительно, Размышления на эту тему приводят к пониманию того, что это действительно возможно, и возможно, нас на Земле окружают такие существа. Мы, люди, не можем доказать, что все другие люди не являются философскими зомби, кроме как мы сами лично. Хотя некоторые философы, например, Дэниел Деннитт, он считает, Но это известный тролль. Он считает, что, в принципе, никакого феноменологического сознания нет. Иногда он так пишет. На самом деле, конечно, он так не считает, потому что это все дано ему в его ощущениях. Хотя, если он является философским зомби, то он может себе позволить так говорить. Но фишка философского зомби в том, что если его спросить «Послушай, а у тебя есть внутренние квалификативные состояния кинемиологического сознания?», он ответит «Да», хотя у него их нет. Таким образом, концепция философского зомби, в принципе, является не верифицируемой и не фальсифицируемой. Она не научна. Это всего лишь тот философский мысленный эксперимент, который вел Дэвид Чандерс для того, чтобы показать, что мы не можем залезть в голову никому, в том числе и искусственным когнитивным агентам, которых мы, в общем-то, можем сделать. И, возможно, у них будут такие же состояния. Возможно, у нас, в нашей цивилизации, есть системы, отличающиеся от человека, у которых есть квалификативные состояния уже сегодня. Например, всё взаимодействие государств, мира, оно осуществляется примерно по той же схеме, как и взаимодействие нейронов внутри нашего головного мозга. Другое дело, что как нейрон не может осознать, понять, ну если бы он был, например, разумным, что у нас, как у целостной личности, есть какое-то политативное состояние, так и мы, люди, являющиеся агентами в государственных системах, взаимодействуя между ними друг с другом, не можем понять, что там, возможно, есть какие-то политативные состояния, нам недоступны абсолютно. Это вопрос каналов связи и опять заглядывания внутрь системы. Но зачем же нам нужно вообще размышлять об этой проблеме, если она ненаучна, неверифицируема, не фальсифицируема? Моя точка зрения заключается в том, что это очень важный вопрос. И именно субъектность определяется через наличие вот таких вот квалификативных состояний. в том числе и юридическая субъектность. Поэтому нам нужно думать, как дифференцировать философского зомби, особенно сейчас, когда мы вступаем в ЭРУ, когда вокруг нас будут находиться искусственные когнитивные агенты, разумные существа иной природы, а не кто. эти разумные искусственные существа, они вещь или уже не вещь? Или они субъекты? Субъекты права отношений в том числе. И если у них есть внутреннее квалификативное состояние, то, скорее всего, они субъекты, поэтому нам надо об этом думать. Это вопрос этики искусственного тела. Ну, собственно, вот, да, будут ли наши будущие порождения, наши потомки, так скажем, обладать вот этими самыми квалификативными состояниями или они будут зомби? Будут ли они вещью или будут ли они субъектными существами? Когда, как я написал на английском языке, when a thing become a being, когда вещь становится существом. Вот когда. Давайте попробуем понять это. И, соответственно, я хотел бы представить некоторый операционный фреймворк. Операционный фреймворк, который немножко отступает от мысленного эксперимента Дэвида Чалмерса, поскольку, как мы сказали, он не верифицируем и не полицифицируем, и он рассматривает концепцию философского зомби с несколько более слабой позицией. Нам надо ослабить эту позицию, чтобы хотя бы подступиться к этому. И это ослабление позиции заключается в переходе на антропоцентричную позицию. Мы люди, и у нас нет никакого другого опыта. Помните, как писал Томас Нагель, мы не знаем, как это быть летучей мышлей. Мы не знаем, в принципе, как это быть кем-то ещё, кроме нас самих. И, собственно, Антропоцентричная позиция заключается в том, что мы рассматриваем возможность наличия внутренних квалитативных состояний у других через свою собственную призму, через призму своего собственного разума, интеллекта и вот этого самого феноменологического сознания. И, собственно, в этом и заключается антропоцентрическая позиция, антропоцентричная. Поэтому давайте я её объясню. Давайте проведём первый мысленный эксперимент. У меня заготовлено сегодня в докладе несколько мысленных экспериментов. Первый из них — это тотальная депривация ощущений. Представьте себе, что вас погрузили в камеру тотальной депривации внешних чувств. И все информационные потоки через ваши сенсоры, глаза, уши, активную информацию — все приключены. И вы постепенно погружаетесь во тьму. во тьму, в тишину, в отсутствие каких-либо тактивных стимулов. Но у вас внутри вашей головы всё равно начинают возникать некоторые образы, потому что у вас есть сенсорный опыт. Из вашей памяти начинают всплывать образы, и чем дальше вы погружаетесь в сенсорную депривацию, тем ярче эти образы становятся. Вы можете попробовать, это достигается при помощи медитации, или есть возможность сегодня в камере сенсорной депривации побывать. Это, конечно, не тотальная сенсорная депривация, про которую я сейчас говорю, но это очень похоже. И если вы не боитесь, то можете попробовать. В принципе, если долго этим не заниматься, то всё будет нормально. Если долго, то некоторые психологи отмечают, что Возможно, диссоциация личности — это довольно страшно. Но давайте изменим условия этого мысленного эксперимента и проведём второй мысленный эксперимент. А что, если мы возьмём ребёнка, который только что родился и вылез вот из утробы матери, и мы его сразу же поместим в камеру сенсорной депривации? В принципе, утробу можно рассматривать как такую камеру сенсорной депривации, потому что там температура такая же, как у ребёнка. Там ничего не видно, ничего не слышно. Ну, конечно, с нюансами, но тем не менее. И вот ребёнок рождается, мы его сразу же помещаем в камеру сенсорной депривации, подключаем все необходимые системы жизнеобеспечения, и он там живёт. Он ничего не слышит, ничего не видит, ничего не ощущает. И в процессе взросления у него не появятся внутренние образы, в принципе, никаких внутренних образов не появится, феноменологического сознания у него не появится. Он даже не сможет задать себе вопрос, кто я такой, потому что символьной системы у него не будет, мне так кажется. Можно подумать на эту тему, я предлагаю, и мы идём дальше. Есть такой же классический мысленный эксперимент, который придумал и Важунь и я. Это эксперимент «Гипотетическое животное лодцы». Этот мысленный эксперимент был описан в книге Орхи Борхеса. про разных животных. Вот есть гипотетическая животная лодца, которая может ощупывать окружающий мир при помощи одного сенсора, тактильного сенсора. В принципе, неважно, какой сенсор, любая модальность может быть, но это одна точка, одна точка, через которую мысленная животная лодца ощущает внутреннюю внешнюю среду. И, соответственно, задаётся вопрос. Оно может познать окружающий мир или нет? Я отвечаю на этот вопрос «нет». Но оригинальный ответ был «да». Да, сможет, и там вроде как доказывалось. Но я говорю «нет», потому что это гипотетическое животное, лодца, не сможет дифференцировать себя из окружающей среды. И, таким образом, Нам нужна так, даже если у нас есть одна сенсорная мордальность, она должна быть то, что я называю продолженной, непрерывной, неточечной. То есть если у нас есть всего лишь одна точка нашего сенсора, и которым мы можем ощупывать окружающуюся среду, то мы не сможем распознать из себя своё собственное тело и познать, кто я такой. И у нас будет белый шум, воспринимающий органе будет белый шум, который поступает вот из этого сенсорного органа. Собственно, есть пример подобного. Я, тем, кто заинтересован в этом, я рекомендую почитать про Загорский педагогический эксперимент. В Советском Союзе проводился такой эксперимент по адаптации слепоглухих с рождением детей. То есть представляете себе человека, который с рождения одновременно слеп и глуп. То есть он в темноте и в тишине. Какое сознание технологическое может у него там обнаружиться? Он не видит образов, он не видит ничего, он не слышит звуков. У него в голове формируется символьная система, которая может представлять собой некие тактильные ощущения. И фактически Таких людей, детей, попавших в загорский интернат для слепоглухих с рождения, их адаптировали для жизни в нашем мире, их обучали. Некоторые из них становились полноценными членами общества. Но они не могли ни говорить, естественно, ни слышать, ни видеть ничего. Они общались при помощи рук. И обучение происходило так. Учитель через одну ладонь давал некие последовательные знаки, а знаки — это нажатие рукой, пальцами так или иначе по ладони, то есть вот разные вот такие вот комбинации. а другой рукой этот ребенок ощупывал разные предметы. И вот видите, здесь как бы одна и та же модальность тактильная, но она продолженная. То есть два разных канала воспринимают информацию, и внутри в голове происходит некоторая сенсорная интеграция. И вот ирландский натурфилософ Малинью задал такой вопрос Джону Локу. Это наш Четвёртый мысленный эксперимент. А что если слепому от рождения ребёнку научить его распознавать куб и шар одинакового размера, которые сделаны из одного и того же материала? Он их на ощупь распознает. Это куб, это шар. А потом вернуть ему зрение. и показать ему куб и шар, но не давать ему ощупывать. Сможет ли он отличить куб и шар? Все философы, которые рассматривали этот мысленный эксперимент, говорили, что нет. И потом этот мысленный эксперимент люди смогли, учёные смогли провести в натуре, потому что некоторые Варианты глоукома, вырожденной глоукома, которая ввела к потере зрения, стали измечиваемым. И, собственно, этот эксперимент удалось провести. И ответа действительно нет. Люди, которые не использовали зрительную модальность с самого рождения и научились дифференцировать куб и шар друг от друга только при помощи тактильной модальности, не могут этого сделать при помощи зрения. То есть им показывают куб и шар, они не знают, что из них куб, а что шар, пока не потрогают. Но как только они потрогали и увидели одновременно, они могут после этого распознавать через зрение. И есть еще один такой тонкий момент, что Есть дети, у которых нарушена сенсорная интеграция, то есть какие-то проблемы с таламусом. У нас в голове, внутри, в среднем мозге есть такой орган, как таламус, который отвечает за мультисенсорную интеграцию разных сенсорных сигналов, приходящих из наших органов чувств в единую целостную картину окружающего мира. И вот у некоторых детей этот процесс нарушен. Он идёт, но он нарушен. И у них очень серьёзные проблемы с формированием личности, с формированием символьной системы. В общем-то, это объяснимо. И, собственно, вот здесь, просмотрев эти четыре мысленных эксперимента, я предлагаю следующий операционный фреймворк для определения, кто является кемосовским зомби, а кто нет. Соответственно, у философского зомби, вернее, не так, для того, чтобы не быть философским зомби, необходимо выполнение как минимум трёх критерий. Это наличие сенсорных систем, хотя бы одной, но при этом, если она одна, она должна быть протяжённой. Это второе, возможность отделять себя от среды, то есть чтобы не было белого шума, в осознающем органе. И третий — это мультисенсорная интеграция сенсорных модальностей для того, чтобы целостно воспринимать среду, в которой мы обитаем. И, собственно, именно такое Эти три критерия позволят говорить, что вот существо, которое обладает этими тремя критериями, оно не килосовский зомби. Это, конечно, очень антропоцентричный подход, но у нас другого нет. Другой позиции мы не знаем и не можем в неё встать. Но с этой точки зрения, как пример, возникает вопрос, есть ли квалия у насекомых, есть ли квалия у млекопитающих. На первый вопрос я отвечаю нет, потому что у них нет сенсорной интеграции, и насекомые — это биологические машинки. Такие вот биологические, кибернетические машинки, которые действуют по программам, которые в них заложены на генетическом уровне. А млекопитающие — это осознающие и обладающие феноменологическим сознанием существа. Ну, в принципе, Вообще не с млекопитающих, а с хордовых это идёт. То есть у хордовых уже есть механизмы сенсорной интеграции. И мы проведём ещё пару мысленных экспериментов. Номер пять — это перекрёсток проводящих путей. На экране схема сенсорной интеграции. Как это сделано у человека? Ну, здесь приведен пример на двух модальностях. Это зрительная модальность и слуховая модальность. Соответственно, сигналы приходят в сенсоры, зрительные и слуховые, соответственно, проходят по промежуточным нейронам. попадают в модуль сенсорной интеграции в Таламус, и также попадают в слуховую зрительную кору. Информация из Таламуса и, соответственно, двух вот этих вот типов коры попадают также в ассоциативные нейроны, где формируется комплекс всех ассоциаций. И именно так мы изучаем язык. Мы видим и слышим одновременно. Это чашка, это чашка. Вот мы видим чашку и слышим слово «чашка». У нас формируется в ассоциативных именной коре вот эта взаимосвязь. Давайте мы два раза перекрестим связь. Соответственно, перекоммунитируем сенсорные потоки от аудиальной системы к зрительной, и наоборот, от зрительной к аудиальной. И есть два варианта того, как это делать, во время обучения и во время работы, функционирования. Собственно, здесь показаны варианты перекоммутации до мультисенсорной интеграции и после неё. На иллюстрации A у нас схема до мультисенсорной интеграции. Я здесь не стал для того, чтобы не загромождать схему, рисовать вот этот вот таламус, но вариант A — это до интеграции, вариант B — после. И, собственно, если мы перекоммутируем до, и обучим перекоммутированного агента так, как мы его обучаем, в общем-то ничего у него не произойдет. А если мы перекрестим «после» и будем обучать, то у нас возникнет… мы будем видеть звуки, а слышать то, что вокруг нас. И в этом будет проблема. Такой агент не сможет ориентироваться в окружающей среде. Я считаю, что ослабленная концепция философского зомби, про которую я вам рассказал, она уже может быть проверена на практике. По крайней мере, она верифицируема. Мы можем это использовать при помощи искусственных нейронных сетей, провести верифицирующие эксперименты. Собственно, ну и она также фальсифицируема, потому что можно задать вопросы, что вот если как сказать, если вот что-то не произойдет, то гипотеза моя, которую я представил, она некорректная. Ну то есть я считаю ее фальсифицируемой, хотя, конечно, это еще надо показать, но верифицировать ее точно можно именно на искусственных нейронных сетях. Все, коллеги, благодарю за внимание, я на две минуты выдался из тайминга, здесь мои контакты. статью про всё вот это, что я рассказал. Статья, которая называется «К вопросу о распознавании и дифференциации философского зомби». Она опубликована в философском журнале, и её можно скачать, изучить. Там всё, что я рассказал, более конкретно и простыми словами описано. Ну и контакты в моём экране. А сейчас я хочу посмотреть ваши вопросы и ответить на них. 

S06 [00:54:32]  : Давайте, пока Роман Викторович смотрит на вопросы, мы Алексею Потапову дадим слово. У него есть вопрос. Мне кажется, что его вопрос, он в себе несет, знаете, такой базовый вопрос. Что такое сознание? Мне кажется, что это определение до начала семинара не было выровнено, да, то есть на самом деле, может быть, его и нельзя выровнять, потому что этих определений много. 

S01 [00:55:02]  : Но, тем не менее, я хочу Алексею дать слово. Вопрос такой, как захват никакого параметра в цифровом языке и передача его, он сильно отличается сенсорным стеклом, то есть способом, как приходят эти конверсии, конверсии между разными типами сигналов, светового, электрический, электрический, там, нейротрансмиттер и так далее, как они отличаются. Как в вашем модели они отличаются от, собственно говоря, Есть, допустим, регистр, и пока эта информация не попала в регистр и не сравнима с чем-то, не была сравнена, не произошло никакого осознания этой информации. То есть сенсорный поток шел, обосприятие шло, но не произошло его осознания. То есть не произошло понимания, что это за информация. И понимание даже, а вот его как бы сравнение, ну фактически понимание, да. 

S03 [00:56:29]  : Да, Алексей, вас очень плохо было слышно, и если я сейчас отвечу не на то, на что вы спрашивали, я прошу прощения. Ну, смотрите, я оговорился в самом начале, что я рассматриваю в своей презентации именно феноменологическое сознание, то есть не то, что называется awareness по-английски, то есть самоощущение, внимание, вот то, о чем говорила Анна, а именно наличие каулитативных состояний. И, собственно, Как пример, сон или галлюцинирующий мозг под веществами. Мы видим что-то, но мы не осознаём этого, потому что в первом случае мы спим, а во втором мы находимся в изменённом состоянии сознания. А сознание именно в том смысле, что Мы отдаём себе отчёт, кто мы такие, что мы за личность. Но мы всё равно видим вот эти квалитативные свойства восприятия. Они нам даны. И, собственно, ваш вопрос относится ко второму типу сознания, который я не рассматривал в своём докладе, и поэтому я думаю, что я могу себе позволить не то что не отвечать на этот вопрос, но то, что я рассказал, оно неприменимо к тому, что вы спрашиваете. 

S06 [00:58:02]  : Роман, а сама по себе вот сенсорика, она необходима для того, чтобы появилось сознание? Ну то есть вот первичное вот то, что вы рассказывали про слепых, глухих и немых детей, первичное обучение этих детей чему-то является необходимым для того, чтобы у них возникло сознание? Или они от рождения на длины сознания? 

S03 [00:58:24]  : Я считаю, что феноменологическим сознанием делены от рождения все млекопитающие, ну, все хордовые, в принципе. Но для того, чтобы получить осознание, осознание себя, осознание себя как личности, необходимо обучение, как создание всего комплекса ассоциативных связей в наших нейросетях и построение символьной системы для того, чтобы мы могли рассуждать об этом. В принципе, вопросов еще много. У меня еще есть две минуты, и я передам слово Владимиру Сергеевичу. 

S06 [00:59:26]  : Александр Соколов. Давайте на вопрос Александра Соколова. 

S03 [00:59:33]  : Если ощущения нет, то сознание не возникнет. Моя точка зрения заключается именно в этом, что если ощущения нет, а сенсорные системы отключены или подвергнуты тотальной депривации, то сознание не возникнет как таковое. И я считаю, что это очень важный момент. Я считаю, что это очень важный момент. Если человек уже вырос, обучился, у него уже есть сознательный опыт, опыт восприятия, и его подвергнут тотальной депривации, у него будет в наличии память. Но потом, в конце концов, из-за отсутствия сенсорных ощущений, его сознание, его эгоизм, его эгоизм, его эгоизм, его эгоизм, его эгоизм, его эгоизм, его эгоизм, самосознание затуманится, он просто заснёт. Ну, если вы бывали в камере депривации или побываете, вы просто поймёте, что это такое, вы заснёте, когда вы там окажетесь. Ну, через какое-то время, естественно. Вот. Если долго этим заниматься, то можно с ума сойти. Ну, кстати, один из видов пыток был как раз в том, чтобы помещать человека в тёмную комнату абсолютно закрытую для всех звуков и раз в день ему туда засовывать ложку с едой. Через какое-то время человек сходил с ума. Поэтому да, для того, чтобы человек стал полноценной личностью, ему нужен сенсорный опыт. И для того, чтобы он ей оставался, нужен сенсорный опыт. 

S06 [01:01:14]  : Всё, Владимир Сергеевич. От сенсорного опыта невозможно рассматривать. 

S03 [01:01:19]  : Да, да. Всё, Владимир, передаю тебе слово. И, собственно, Владимир Сергеевич, я как бы предварил ваш доклад. Да, спасибо. 

S06 [01:01:33]  : Владимир Сергеевич Смолин, научный сотрудник институт преподной математики РАН. Владимир Сергеевич считает, что в продолжение к тому, что говорил Роман, что мир зомби, в отличие от одного зомби, не представим. Потому что вот и агентам общего уровня необходим сознание для полноценного взаимодействия. Давайте послушаем детали. 

S04 [01:01:58]  : Хорошо. Я, значит, сейчас расшарю экранчик. Быстренько. Видно мой экранчик? Я надеюсь... Да, Владимир. Видно, да. Ну, вот, собственно, представлю, значит, мои координаты, значит, название доклада. Ну, он, конечно, немножко эпатажный, потому что, значит, буквально через... на следующем слайде я скажу, что все-таки можно себе представить мир зомби, другое дело, что есть один исключительный случай, который, собственно, нас и интересует, когда это представить нельзя. Вот. Ну, и, в целом, мой доклад, он, скорее, такой, технической направленности, то есть я тоже, как вот и первая выступавшая Анна за то, что надо демостифицировать систему сознания, но это нужно не только в познавательных целях, но и с целью создания относительно сильного искусственного интеллекта и ряда других технических задач. Ну, собственно, раз уж я поставил название «Зомби» в доклад, то, собственно, различные мысленные эксперименты Дэвида Чалмерса, они интересные. Вроде бы я написал, что мир «Зомби» непредставим, но повторюсь, что он непредставим только, собственно, в одном случае. Но этот случай как раз для нас и важен. То есть зомби, как правило, понимают целоподобное существо, не обладающее сознанием. А, собственно, зачем нам сознание? Ну, и говорить о том, что мир зомби невозможен, что он невозможен вне человеческого общества. То есть если говорить о том, что Когда-то вообще не было животных, мир развивался физическим правилом, то естественно никакого сознания в этом чисто физическом мире не было. Все биохимические законы, простейшие организмы тоже не обладают сознанием, вряд ли это у кого-то вызывает серьезные сомнения. Если не верить в вселенский разум или какие-то другие нематериальные идеи, то живут они по тем правилам, которые у них заложены. В человеческой традиции принято отказывать от наличия в сознании большинства животных. Ну вот, Роман, значит, говорил о том, что хорды все-таки, наверное, обладают сознанием. Ну, тут, значит, не могу сказать, что нижние хорды, низшие хорды могут быть. Ну, и если они обладают сознанием, то очень, значит, в слабо выраженной форме. Но, наверное, высшие животные, например, питающие, действительно, сознание обладает. Причем не только. Там, в принципе, есть и моллюски, достаточно развитые нервной системой. Есть некоторые пресмыкающиеся, но крайняя точка стояния стоит в том, что сознание обладает только человеком. Не будем проделывать такой мысленный эксперимент, что если всех людей перестрелять, откатимся просто на несколько сотен тысяч лет назад, когда никакого человека не было. А если взять несколько миллионов лет назад, то был мир животных, когда еще, может быть, и хордовые не появились. И, соответственно, они жили под достаточно простым правилом. И, соответственно, вот такой мир зомби, он возможен. То есть существуют достаточно простые животные, которые действуют согласно заложенных их рефлексам, вырабатывают какие-то у себя условные рефлексы. Соответственно, как-то живут в этом мире. Но если мы говорим про развитие цивилизации, то не то чтобы она невозможна. Эволюция в животном мире все равно шла. Но эта эволюция была очень медленной. Быстрая эволюция появилась, во-первых, когда появились животные, обладающие сознанием, хотя это произошло задолго, на мой взгляд, с чем я соглашусь с Романом Викторовичем, до появления человека. Ну а человек как-то сделал следующий скачок, о котором я поговорил, и, соответственно, пошло быстрое развитие цивилизации, которая в мире зомби, на мой взгляд, было бы невозможной. Но в целом, значит, вот эта эволюция животных, она, значит, как бы сказать, шла в направлении формирования смысла. Ну вот Тегберг там в своей книге говорит о том, что когда появилась Вселенная, она никакого смысла не имела. Развивалась физическим законом. И только появление разумной жизни привнесло в эволюцию Вселенной не столько смысл, сколько его понимание. Хотя этот смысл мы сами для себя не столько даже придумываем, сколько в процессе эволюции вырабатываем. Ну и, собственно, говорить, что есть эволюция биологических видов, и главное свойство этой биологической эволюции в том, что те виды, которые не выживают, ну они как бы перестают участвовать в эволюции, и, собственно, выживание это не столько цель, сколько свойство эволюции. Но в то же время это выживание является как бы смыслом естественного отбора. Процесс эволюции создавал различные системы, дыхание, кровообращение, нервную систему. И одним из важных свойств нашей нервной системы является центр удовольствия. В мозге, про которое Стюарт Рассел в своей книге проводил мысленный эксперимент, рассуждения на тему того, что если вот стимулировать эти центры удовольствия, то мы можем сильно изменить свое поведение. То есть, в принципе, и наркотики этим стимулируют, и, значит, зомби-ящик тоже наши центры удовольствия стимулируют. Ну, значит, есть разные пути, значит, цивилизованные, не очень там. Вот. Ну а в целом, значит, как бы в результате Биологические эволюции у нас, во-первых, сложились в эти самые центры удовольствия или нейросистеме, ну и поскольку мы живем в цивилизации, там тоже есть какие-то цивилизационные нормы, мы их тоже, значит, учитываем, и, значит, и сочетание вот этих двух, как бы, основных направлений являются основой для выбора целей. Важно отметить, что вот эти вот оценки, которые нам дает как цивилизация, так и наша центры удовольствия внутренние, они являются векторными. То есть нет такой скалярной оценки хорошо-плохо. Можно быть там бедным, но здоровым, или там богатым, но больным. То есть если бы одновременно там быть богатым и здоровым, понятно, что это лучше, чем быть бедным и больным. Но, значит, промежуточные варианты, они, значит, много. Ну, скажем так, сложнее сравнить. И в принципе вот эта векторная оценка состояния может быть достаточно сложной. В целом эволюция жизни, если так вспомнить, она начиналась с эволюции ДНК, то есть никаких особых рефлексов простейших, одноклеточных не было, потом они какие-то стали появляться, уже заложенные в ДНК, но они передавались чисто через ДНК. Соответственно, потом стали появляться условные рефлексы, отрабатываться. Ну и, о чем мы будем говорить, появилось сознание, и от сознания, соответственно, будем пытаясь объяснить, для чего у вас, до моей точки зрения, оно... Ну, то есть, возвращаясь к той же книжке Рассела, он тоже рассказывает про направление валюты, и указывает, что после условных рефлексов должно, собственно, Включиться в учет вероятности свойств нашего мира и современный искусственный интеллект, это учет вероятностных свойств. Моё мнение всё-таки другое, что это вопрос сознания. Но уже для условных рефлексов и для сознания нужны некоторые оценки действий, что важно. Но разница в том, что если мы выработали на основе оценки действий какие-то условные рефлексы, то насколько мы их хорошо выработали, определяет, собственно, эволюция. Либо мы, значит, оставили потомство, либо не оставили потомство. Вот. А, значит, если мы используем сознание, то мы можем предварительно прикинуть, а хорошо это или плохо, но, конечно, тоже можем ошибиться. Но в целом, значит, как бы вот это наличие сознания и возможность прикинуть, хорошо ли это или плохо, оно, собственно, позволяет улучшить наш выживание. То есть вместо калькулятора для окончательных расчетов, которые на рисунке слева можно, уже вводить какие-то калькуляторы для предварительных расчетов. И смотреть не просто, выжил или не выжил, а смотреть лучше или хуже, и это дает большую гибкость в адаптации к окружающей среде. Но трудностей, проблем и сознания много. Но одно из сложных проблем в определении сознания стоит в том, что нельзя ее определять как некоторую интеллектуальную функцию. Есть вопросы компетенции, которые сейчас у машин все время растут. И, соответственно, нет особых сомнений, что компетенция машин будет повышаться. они будут решать все больше интеллектуальных задач, пока не решат все. Если мы будем определять о том, что интеллектуальные задачи — это те, которые не решаются машинами, то скоро интеллектуальные задачи не останутся не только у машин, но и у человека. Допустим, если за робота сейчас будет играть AlphaZero, то, естественно, она у любого человека в шахматы выиграет, и является ли это ее высокая интеллектуальность, основанием считать то, что у неё есть сознание. Но, значит, с одной стороны, как бы, не является. И я буду говорить о том, что, конечно, что там Вальсроу, значит, сознания нет, но есть какие-то элементы, которые, значит, направлены на сознание, и, собственно, попытаюсь объяснить, а зачем оно нужно для, собственно, высокоинтеллектуальных систем. Следующий вопрос состоит в том, что мы не можем напрямую физически исследовать сознание. Мы можем рассказывать, что мы думаем про свое сознание, а это непрямой эксперимент. Есть биологические пути, которые позволяют непосредственно наблюдать даже сейчас не тысячи, не сотни тысяч, а активность миллионов нейронов одновременно, но пока, к сожалению, не удалось понять, что с этой информацией делать. То есть пока нет понимания, зачем это нужно, то вот такие большие объемы информации, которые сейчас биологи в большем объеме будут получать, они пока не позволяют исследовать деятельность мозга, в том числе и сознания, как физический объект и получать объективные данные. Но это не значит, на мой взгляд, что это нельзя исследовать. То есть мы сейчас как-то его обсудим, это тоже некоторые исследования. Но, значит, на мой взгляд, главное, собственно, понять, а для чего может быть нужно сознание. То есть когда вот строили, собственно, первые самолеты, и сейчас как бы есть некоторый успех в самолетостроении, собственно, птичек не ловили. Не то чтобы их нельзя было поймать, но, значит, поняли проблему, значит, разработали там экспериментально, там как должно быть устроено крыло, Теорию там Николай Егорович Жуковский, наш соотечественник, развел. И, соответственно, в авиационных лузах сейчас про птиц вообще ничего не рассказывают. И, соответственно, проблема все равно. На мой взгляд, такое же отношение должно быть и к сознанию. То есть, может быть, когда-то мы там сможем исследовать какие-то биологические аспекты, но главное, собственно, это понять проблему. Ну а для чего это, значит, сознание? Сразу отмету, что есть там много подходов к сознанию, есть большого в экономическом словаре, что сознание – это высшая форма психологического отражения, свойственно общественно развитому человеку и связанная с речью, и идеальная сторона целеполагающей деятельности. Многие отходят от этого определения, в том числе и я, наверное, отойду. Но рассматривается как нематериальная душа, как идеальная сторона деятельности, как новое физическое явление, как необходимость внесения в обработку информации каких-то суперучислений, как обязательная символиная обработка информации. Я становлюсь в одном направлении, связанном именно с универсальными алгоритмами обработки окружающейся информации из достаточно сложного мира. Стараюсь объяснить, зачем для этой обработки информации из сложного мира нужно сознание. В принципе, мы можем зрительно, тактильно, на запах, на вкус наблюдать различные предметы окружающего мира. Даже довольно простой предмет, как полигольный мяч. У него можно выдавать различные названия, свойства, которые он имеет, ну и параметры, которые он может принимать в текущий момент времени. Вот. Ну, естественно, в каждой модальности сенсорного восприятия там эволюцией сложилась некоторая предобработка, которая может быть в своей модальности как-то специализированная. Ну, и, собственно, когда мы управляем своими эффекторами тоже, там может быть какая-то специализированная обработка. Ну, иначе эти вопросы я в докладе совершенно не буду отголодывать. Я, собственно, постараюсь поговорить про как бы универсальную обработку, которая позволяет, собственно, вот из этой разномодальной сенсорной информации, может быть, прошедшую предварительную обработку к некоторому более-менее стандартизованному виду, провести некоторую универсальную обработку, получить вот эти основные параметры, которые здесь перечислены, и, соответственно, зная эти параметры, как понятно, уже нам будет легче справляться с этим по объектам, и, может быть, мы можем предпринять какие-то разумные действия. Ну, понятно, что мяч, он очень простой объект, но более сложный про объекты это те руки, которые этот мяч держит, и которые нам его могут очень по-разному бросить. Естественно, задача не такая простая, как будет написано, всего там несколько, полтора-десятка параметров, полтора-десятка. Но, тем не менее, как раз сложность этой проблемы ведет к тому, что сознание становится необходимым. Много есть примеров про сложность окружающего мира. Стюарт Ресселс в последней книге 1919 года Рассказывает о том, что есть некоторые сета Lloyd, которые предлагают сделать квантовый компьютер, который будет в миллиард триллионов раз быстрее, чем самый быстрый компьютер в мире. И он предлагает, а что можно сделать на таком компьютере? Он говорит, давайте рассматривать различные комбинации словаря. Ну, словарь сейчас большой, поскольку пишут в разных формах слова. Слов терминов много. И говорят, что за год такой мощный компьютер может рассмотреть комбинации из одиннадцати слов. То есть, чтобы рассмотреть комбинации из двенадцати слов, ему может потребоваться не один год, а триста тысяч лет. Ну и так далее. Ну, правда, наоборот. Если там из десяти слов смотреть комбинации, уже ему там потребуется одна трехтысячная годом. Но в целом, значит, ситуация такая, что Значит, вот один из слов в стихотворении выделено, то есть если мы просто перебором хотели написать стихотворение, то вот на этом супермощном компьютере нас бы, собственно, за год мы могли бы, значит, в числе прочих рассмотреть вот только вот эту часть стихотворения, хотя в полном стихотворении там шесть четверо стишек. Ну и, собственно, что пишет Рассел, что мы намного дальше от рациональности, чем слезняк от обгона, значит, фантастического звездолета «Энтерпресс», летящего на варке 9.9. Ну это какая-то функция. совершенно фантастическая сверхсветовая скорость. Мы не можем рассматривать все возможные комбинации и можем выбирать только несколько вариантов комбинаций тех событий, которые мы наблюдаем. Для того, чтобы выбрать хороший путь. Ну и, значит, когда мы говорим о универсальной обработке, понимаем, что и у нас, наверное, сети, и сейчас в искусственном интеллекте, значит, все больше, как бы, используют сети формальных нейронов. Но, собственно, основное, как бы, суть этого преобразования, ну, табличная. То есть мы, в принципе, вектор умножаем на матрицу, матрица это таблица, и, собственно, получаем, значит, некоторые преобразования. Но есть там другие варианты табличных преобразований. Важно то, что мы на опыте, то информация, которая есть, формирую в некоторую таблицу и использую потом для преобразования. Но, тем не менее, подход очень хороший, широко использовались, сдал прогресс в решении многих задач, но есть, собственно, и ограничения табличных преобразований, они ограничены существенной размерностью, в точных видах, в длинной последовательности выполняют действие. Ну, примерно так, как, собственно, писал Рассов про нашу ограниченную рациональность. Мы не можем рассматривать очень многомерные объекты, один и последний. Ну, естественно, не можем только путем полного перебора. Мы можем находить различные юристические алгоритмы, предлагать какие-то сетевые алгоритмы, которые, тем не менее, от этого полного перебора уходят и, значит, решают. И, собственно, это локальное оптимальное решение можно осуществлять путем декомпозиции сложных объектов и анализа ограниченного числа по последовательности. То есть мир нужно себе представить не как хотят гуманитарии гармонически во всей его сложности, а соответственно разбить его на какие-то простые объекты, выделить достаточно простые законы. Но если какие-то объекты независимы, то это неинтересно наблюдать. То есть вот этот пространствосостояние этих объектов, оно, во-первых, достаточно большое, но информация не несет. А вот если, допустим, шестеренка катается по, значит, зубчатой рейте, то, значит, есть связь между углом, соответственно, шестеренки и положением на рейте. И, соответственно, во-первых, у нас, значит, получается пространство в состоянии значительно меньше размерности, а во-вторых, это уже какая-то информация. То есть если мы знаем одну переменную, можно, значит, определить вторую. Ну и, собственно, знаем, в каких свойствах, значит, наша система наблюдает. Не всегда эти зависимости жесткие. Может быть, речь про вероятность той зависимости. То есть, если у нас, допустим, две шестеренки свободно катаются, и, допустим, они неравномерно, значит, их вероятность нахождения в разных точках распределена вдоль рейки, то, соответственно, у нас есть какие-то два распределения. И, значит, если мы возьмем совместное распределение, будет такой, в один, значит, город, значит, круглый, там, значит, если вот так сверху горизонтально начать сеть. Вот. И, собственно, если вот это совместное произведение, совместная вероятность будет просто равна произведению этих вероятностей, то, как бы, понятно, что их положение независимо. Другое дело, что если у нас получится не горб, а вдоль диагонали, как отмечено горбами, то пойдет волна диагональная, которая будет говорить о том, что все-таки есть зависимость. Хотя распределение каждого положения не изменится, но вероятность зависимости может быть выделена. И это как раз и представляет интерес наличия зависимости. То, что мы наблюдаем в обучении, в принципе, все нервные сети в той или иной степени работают на выявление различных корреляций. Вот, собственно, один из примеров в таком выявлении. Сетей сейчас, на самом деле, достаточно много, они все интересные, какие-то работают лучше, появляются хорошие и еще более хорошие. При этом, с одной стороны, прогресс, конечно, радует, но при этом надо понимать, что вот эта идея о том, что, говоря, скажем так, поиск, градиентный спуск, поиск, говоря, оптимальное решение, он, собственно, проблемы особо не решает. То есть, чтобы, значит, вот эти все сети хорошо работали, значит, нужно брать не ведро с нейронами и, значит, случайно их связать и потом оптимизировать. а нужно все-таки закладывать какие-то свойства окружающей среды, что, допустим, держит в эволюционных сетях, допустим, вероятность зависимости соседних точек, в последовательности тоже какие-то свои свойства закладывать. Но вот это вот разбиение модели на какие-то блоки со своими свойствами их взаимодействия, они, собственно, говорят о том, что, значит, получение таких моделей чисто путём прямой оптимизации, оно идёт очень медленно. То есть, конечно, опыт эволюции жизни показывает, что всё-таки это возможно, но это требует геологических масштабов, и как по времени, так и по пространству, и, собственно, нереальные условия для развития цивилизации. Но, если помните, я говорил о том, что надо выделять Какие-то свойства. Самое простое устройство это автоэнкодер, который можно предложить для понятного эксперимента. У нас есть входной сигнал и мы его пытаемся откопировать с помощью сети. Если у нас значительно меньше элементов, чем на входе, то вот эти элементы удалось нам откопировать. Входной сигнал и выходной воспроизвести. то вот эти элементы, они как раз несут существенную формацию сигнала. Ну и кроме того, значит, хорошо бы их еще откортировать, потому что если мы хотим потом, значит, генерировать различные состояния объекта, то не любые состояния вот этих локентных переменных, они соответствуют каким-то разумным состояниям сенсорного входа. Ну и, собственно, если, значит, есть какое-то облако вот этих, значит, состояний, то можно разместить некоторую карту и поменяя координаты этой карты, если она отображает эти координаты, можно давать на выход только такие сигналы, которые чему-то реально соответствуют. Есть, конечно, другие пути решения задачи, это просто как пример. Важно, что такой подход может быть разным. многоуровневый подход, то есть когда мы откортировали различные состояния латентных переменных, то на нижнем уровне, собственно, вот эту карту, которая обладает своей активностью, можно рассматривать как сенсорный вход и, соответственно, попробовать еще раз выделить, какие там имеются зависимости. Так же, как мы на одном уровне выделяли зависимости между сенсорными компонентами сенсора сигнала, значит, также вот от активности карт, причем не одной, а нескольких карт, может быть, значит, выявлено наличие зависимости между, значит, этими картами, ну и, значит, то же самое. Выделены какие-то существенные перемены, то есть не те, которые не несут информацию, а те, которые, собственно, отражают информацию, а наблюдаем в явлениях. Вот, ну, значит, Наиболее близко из того, что нарисовано, это то, что Джефф Хокинс там рисует свои многослойные микроколонки, мини-колонки. Но смысл в том, что то, о чем я рассказываю, хотя структура должна быть похожая, Но, значит, просто активируются колонки, которые отражают те объекты, которые есть в входном сигнале, и, соответственно, своей активностью отражает состояние разных объектов. И, собственно, в этом автоэнкодере, который я показывал на предыдущем слайде, соответственно, можно потом восстановить ту сцену из моделей простых объектов, которые мы, собственно, можем делать, а модели сложных объектов нам как бы делаться трудно. и, соответственно, получать представление, построен ли у нас более-менее правильная модель, или не построена. То есть, если мы смоделировали сенсорный вход, то мы можем оценить, насколько правильно мы понимаем, как это пройдет. Как я уже раньше говорил, у нас есть центр удовольствия, который осуществляет оценку внутреннего состояния. Но, значит, мгновенная оценка нашего внутреннего состояния, она, как бы, не дает нам полной информации о том, как надо действовать. Потому что, значит, если у нас есть там вот эта вот многоуровневая модель, значит, зависимости которой, значит, мира, который состоит из достаточно простых, да, объектов, которые мы наблюдали, она, соответственно, позволяет строить последовательность ходов, ну и собственно, чтобы выбирать лучшие последовательности наших действий, она, значит, состоит в том, что мы перебираем различные последовательности и, значит, выбираем из них наилучший. Опять-таки, проблема в том, что все последовательности мы перебрать не можем и, собственно, это как бы вот хорошо использовалось там в альфа-го, в альфа-зеро, там поступила достаточно хорошая система перебора, значит, всех вариантов, и, соответственно, они как-то там, ну, я не буду рассказывать, как система работает, надеюсь, кому интересно и так далее, не могу рассказать на то сейчас. И, собственно, важно, что вот оценка позиций, оценка, значит, полезности ходов, это как бы разные оценки, поскольку, во-первых, позиция никогда не повторяется, ну и ходы, ходы уже, значит, более или менее одинаковые, но мы не можем анализировать все ходы. Важно выбирать те ходы, которые, собственно, стоит анализировать. Кроме того, что оценки нужны именно для анализа последовательности, это как бы речь о том, могут ли, собственно, алгоритмы что-то ощущать, поскольку говорят о том, что сети они моделируют электрическую активность нейронов, формальных нейронов в сети, а моральное воздействие на них не работает. На самом деле это не так. Есть уравнения, по которым мы считаем активность формальных нейронов и, допустим, обучаем их по закону обратного состояния ошибки перед каким-то другим алгоритмом, то они содержат эффициент. И вот если мы эти коэффициенты для всех нейронов всей сети или слоя меняем, то это соответствует моральному воздействию и, соответственно, производит изменения либо в поведении, либо в процессе обучения, и это соответствует тому, что те эмоции, которые мы ощущаем, они меняют наше поведение. То же самое есть в систему заложенной оценки, значит, простых ситуаций для простых объектов, то, значит, строя вот этот, значит, анализ продолжения, можно, ну, собственно, получать оценки для каких-то последовательных действий и, собственно, на этом основе строить цели и, значит, много чего там еще, как бы, развивать. — Владимир Сергеевич... — Да. 

S06 [01:29:01]  : — Владимир Сергеевич... — Я понимаю, что я заканчиваю. — Вернуться просто уже немножко к регламенту. — Да. — Ключевой вопрос. Расселская ограниченная рациональность, она, по вашему мнению, требует сознания? Да. Можно еще раз вот здесь сконцентрироваться? 

S04 [01:29:24]  : Я попробую начать с того, отвечая на вопрос, что такое сознание. Во-первых, нам приходится два вида деятельности постоянно испытывать. Это выполнять различные действия и думать, какие действия лучше выполнить. Сознание, с моей точки зрения, это процесс соотнесения мыслей с типичным состоянием мира и распределения. значит, вычислительных возможностей менее выполнением и выбором от выполнения действий. Значит, соотнесение, опять-таки, сводится к экономии вычислительных наших ресурсов, потому что мы не можем моделировать произвольные ситуации. Нужно моделировать такие ситуации, которые имеют прикладное значение в текущей ситуации. И, кроме того, не всегда у нас есть возможность подумать. Мы бы и хотели хорошо подумать. Но, собственно, такое у нас. И, собственно, сознание должно контролировать. Мы должны делать то, что мы первое можем сообразить или можем поанализировать. Такое действие будет легче. Ну и это зависит от того, насколько хорошо у нас выполняются те цели, которые заранее при моделировании мы смогли сформулировать и, собственно, сознание контролировать. Насколько хорошо выполняются те цели, которые мы поставили раньше. Если хорошо, то верхние уровни могут заниматься тем, что готовить новые цели для поведения, а, соответственно, нижние уровни, не обращаясь к верхним, поскольку цели им уже дискретно заданы, они к ним не стремятся. они выполняют ее достижения. 

S06 [01:30:45]  : То есть, вот Александр Токолов тогда в продолжении спрашивает, а сознание — это вычислительная машина? 

S04 [01:30:54]  : Ну, как бы все, значит, нейроны, они достаточно физический процесс. Неважно, там, искусственные они, естественные, все равно, значит, они выполняют какие-то операции, вообще говоря, с информацией. В этом смысле, конечно, она вычислительная машина. Другой вопрос, что Это не моделирование, не внимание, не еще какие-то свойства, а это именно контроль за тем, как все эти действия сочетаются, и в основном центральная часть это распределение этих мощностей на выполнении текущих задач. Ну, такой пример, значит, можно привести, что если, допустим, вы играете, значит, с мастером спорта, там, не знаю, в теннис, там, или в бадминтон, то он, значит, может вам перекидывать, там, мячик или воланчик, там, разговаривать по телефону, там, здороваясь с друзьями, и внимание у него не теряется, значит, мячика. Вот. А вас, соответственно, поскольку вам это сложнее всего, вам необходимо задействовать больше целей. Если вас кто-то просто откликнет, то вы, значит, уже мячик промахнулись. Ну и важным еще моментом состоит в том, что сознание в достаточно примитивной форме, оно, конечно, есть и у животных, на мой взгляд. И вот Роман Викторович уже эту форму дает сознание. Но человек, в отличие от животных, резко выделяется тем, что он сформулированные цели внутри своего сознания может вербализовать и передать либо себе, другим людям с тем, чтобы они пропускали через свою систему анализа. Поскольку она эротическая, то физиологически она и у животных, и у нас ограничена. То есть мы не можем сделать больше ступеней анализа. То есть вот первый доклад Чиберлупер-4, я думаю, что их там немножко больше, но, конечно, их там не десятки, как сейчас в моделях нейронных сетей. Если мы сформулировали какую-то цель и дали другому человеку, или себе же поставили, то мы можем еще раз эту цель проанализировать на нашей иерархической системе, и, собственно, вот этот многоуровневый анализ получается значительно больше. Ну, грубо говоря, вот этот язык нам позволяет разделять задачи и, собственно, устроить иерархическую систему управления, и это дает нам значительное преимущество над животными. 

S06 [01:33:09]  : Сейчас в ответах на эти вопросы вы прекрасно резумировали суть вашего доклада. 

S04 [01:33:17]  : Я предлагаю... Прекрасно, конечно, времени не хватило. Да. Ну, собственно, это позволяет говорить про интуицию, понимание, инсайт. То есть, значит, если мы как бы Насчет интуиции, насчет многих вопросов демистификации. Когда говорят, что интуиция, там есть только у человека. С такой демистифицированной точки зрения любой модели, которая сейчас есть, и вообще у любого устройства есть интуиция, потому что есть какой-то вход, она не задумываясь создает какой-то выход. Вот, скажем так, даже AlphaGo, она может играть на интуиции, то есть она может не адресировать продолжение, а играть на интуиции. кандидата в Министерство спорта по шахмату. Вот. А, соответственно, если дать Альфа-0 еще проанализировать продолжение, она играет значительно лучше, то есть надо у всех играть. Вот. То есть, как бы, интуиция — это, как бы, первая реакция, соответственно, понимание, это уверенность в том, что есть прогноз. Хотя понимание тоже может быть ошибочным, и оказывается, что ты думаешь, что прогноз стоит, что он будет. А собственно говоря, Оценки нужны для различных алгоритмов, которые... Во-первых, сознание необходимо для строительства и поведения в сложном мире. 

S03 [01:35:46]  : Я боюсь, Владимир Сергеевич потерял связь и мы его потеряли. Может быть перейдем к нашему четвертому докладу? 

S06 [01:35:56]  : Давайте перейдем к четвертому. Заведующий лабораторий когнитивной архитектуры ЦНТИМ. И Сергей Александрович считает, что нам необходима действующая модель психики как для практических целей, так и для понимания работы человеческого мозга и психики каковой. Сергей Александрович, вам слово. Здравствуйте, коллеги. 

S05 [01:36:26]  : Сейчас, секунду, переключусь. Видно всё? Меня видно, слышно, всё? Могу рассказывать? 

S03 [01:36:38]  : Слышно, но презентации нет. 

S05 [01:36:40]  : Пока презентации не видно. А, сейчас, погодите, сейчас, делаю. 

S00 [01:36:45]  : Делаю. 

S05 [01:36:54]  : Сейчас нормально? 

S03 [01:36:57]  : Да, отлично. 

S05 [01:36:57]  : Все, хорошо, поехали. Да. Значит, ну вот я назвал её нужное ли сознание роботом, но сначала разберёмся, давайте, с нами, с людьми и с живыми существами. Ну, вообще всем живым существам и людям тоже у нас есть такая способность, как ощущать. В частности, мы можем ощущать состояние своего мозга, то есть ощущать своё мышление. Вот это вот Видимая нам часть мышления — это, собственно, и есть сознание живых существ. Вот этот образ мне очень нравится, Айсберга, потому что тут видно, во-первых, что есть подсознание, и, в общем-то, большая часть человеческого мышления протекает в тишину, и мы его не ощущаем. А во-вторых, видно, что какое мышление, такое и сознание. Большой айсберг, большое сознание, маленькая рединга, маленькое сознание. Чего называть айсбергом, это вопрос определения. Но известно, что сознание требует некоторого времени, чтобы включиться. Есть множество очень быстрых Процессов мозга, например, 25 кадр или другие процессы, которые в экспериментах делают, никогда восприятие не переходит из задней части мозга в переднюю и не осознаётся человеком. То есть он не может воспроизвести, вспомнить об этом и не может рассказать о том, что он ощущает. При том, что известно, что эти процессы идут, и они оказывают влияние на наше мышление. А для сознательного мышления требуется всё-таки, чтобы перетекли сигналы из задней части мозга в переднюю, и образовалась такая система обратных связей, что и ощущается нами как сознательное. То есть вот предмет в зоне внимания, он всегда характеризуются тем, что есть некая глобальная система возбуждений в мозге, и они работают сообща. То есть, с точки зрения физики, сознание — это некий особый динамический режим в мозге, когда формируется глобальная конгерентная активность нейронов, которая, собственно, и обеспечивает нам единство ощущений и представлений, И именно эта конгерентность включает обратные связи в мозгу и формирует глобальную модель, которую мы ощущаем как некий акт сознания. И сознание идёт квантами, то есть вот такие конгерентные состояния, они наступают примерно раз в 0,4 секунды. 400 миллисекунд. Примерно это время, когда мы произносим слово. Вот такие слова, они не зря имеют такую длительность. И очень важно, что про связь внимания и сознания я уже сказал, но очень важно, что сознание обеспечивает запоминание. Бессознательное не запоминается. Вот если нам то, что с нами происходит во сне, если мы не запомнили сон, значит он не вошел в сознание. И это свойство, оно ключевое. Ну и важно еще сказать, что существуют разные режимы сознания. Вот там литература выделяет сознание 1, сознание 2. С ним отвечают разные глобальные системы колебаний в мозге. Есть так называемая дефолтная сеть, которая отключается тогда. Большую часть времени проводим в дефолтной системе. Это когда мы слушаем истории, слушаем сказки, болтаем друг с другом. не включая наш интеллект. Но вот когда сознание 2 — это ясность мыслей, то есть решение задачи, когда мы начинаем решать задачи, то вот картина возбуждений в мозгу качественно меняется, и возбуждается так называемая центральная исполнительная сеть. И видно просто вот здесь на фотографии, другая качественная картинка. Есть сети, которые переключают сознание, которые следят за тем, что сейчас важно или не важно, и переключают мышление из одной моды в другую. Вообще в мозге несколько таких базовых сетей и разные их комбинации могут нам обеспечить разные ощущения, разные формы мышления, То есть мы можем сказать, что сознание обладает некоторым религиозным, мы в каждый момент времени на этом религии где-то находимся. И в одних частях чувственное восприятие мира обеспечивается, в других — моделирование мира и себя в этом мире. В этом смысле сознание есть, конечно, и не только у нас, в наших мечах, но форма вот этого вот рельефа, она разная и у людей, и у зверей. Ну вот, здесь я просто написал, что сознание один это, но дефолтная система это то, как мы проводим обычное время, не включая мысли мы начинаем, то есть интеллект, кстати очень хорошее определение интеллекта у Анатолия Юрьевича в книжках, интеллект это способность ориентироваться в новую ситуацию. В новой ситуации получается вот эта центральная исполнительная система и мы начинаем моделировать, то есть мы начинаем не действовать по наитию, а перебирать варианты наших действий, прежде чем действовать, сравнивать разные варианты друг с другом, удерживать результаты рабочей памяти и выбирать из них лучшие. Ну вот, это совсем разные режимы, совсем разные внутренние переживания того и одной мысли. Понятно, что сознание тоже эволюционировало. Понятно, что оно появилось у непопытающих как способ собственно, запитывать информацию в кору. Кора — это специализированный орган, универсальный орган для запоминания. А сознание — это способ загнать в эту кору какую-то память. И поэтому с помощью внимания, тут видно, исследовательское поведение млекопитающих, включает аналог системы 2, то есть какое-то там управление вниманием и поисковое поведение, освоение новых навыков, манипуляции предметами. У общественных животных, у приматов, модель мира усложняется и кора соответственно расширяется, расширяется за счет системы социальных связей, то есть появляются не только модели предметов, но и модели агентов. В частности, агент появляется под названием «я», то есть появляется самосознание и возможность манипуляции не только предметами, но и субъектами. в чём состоит наша социальная жизнь. Ну и, наконец, с очередным расширением коры появляется уровень абстрактного мышления, когда возникает возможность манипуляции абстрактными идеями, то есть символами. И язык, по образному выражению Франсуа Шальде, является операционной системой сознания. То есть именно с помощью него мы идеи формулируем, мы ими манипулируем, и мы их убиваем вместо себя, когда мы пытаемся моделировать действительность. Ну, теперь переходим, собственно, к роботам. Будет ли сознание роботов? Ну, какое-то будет, просто потому что сознание — это атрибут алгоритмов мышления, то есть не субстраты, а именно алгоритмы, потому что субстраты у нас всё время один и тот же мозг, да, и физические объекты там, физические явления там происходят всё время одной и той же природой, вспыхивают нейрончики, они гаснут, но только определённые, только высокоуровневые алгоритмы они обеспечивают сознание, когда возникает должная мера сложности и связности мышления. Собственно, Джулия Тантамони предлагает измерять сознание как мера сложности и связности мышления. В этом смысле схожие интеллекты со схожими алгоритмами будут иметь схожие уровни сознания. Но уровни сознания еще не означает, что сознание как ощущение будет одинаково. То есть, скорее всего, но не скорее всего, а просто обязательно, форма мышления у роботов будет... форма мышления у роботов будет отличаться от человеческого просто потому, что Разные субстраты означают разные алгоритмы. Ну, если просто взять и скопировать там алгоритмы мозга, то просто из-за того, что субстрат у машин такой, что там скорость мышления в миллион раз больше, то такой мозг будет мыслить в миллион раз быстрее, и мы с ним просто не сможем общаться. То есть наверняка мы сэкономим на чем-то и придумаем другие низкоуровневые алгоритмы мышления, чтобы задействовать вот это преимущество скорости и при меньшем количестве железа обеспечить мышление на человеческом уровне. Но понятно, что разные внутренние и внешние сенсорики у нас, понятно, разные врожденные инстинкты, то есть мотивация, поведение, будут разные эмоции, будут разные ощущения для мышления, но важно, что содержание мышления, оно всё-таки задаётся тем, о чём мыслят субъект, да, и что он моделирует. А вот содержание мышления у нас и у роботов должно быть более-менее одинаково, потому что Живем мы в общем мире, мы работаем в общей среде, в общей экономике, решаем задачи, передаем друг другу информацию, обладаем одними и теми же знаниями, у нас одни и те же цели, в общем-то ценности, иначе социума не получится. Ну вот, рефразируя Щедровицкого, можно сказать, что Это свет общественного праздна на машинном интеллекте. Это сознание роботов. Но очень важно, что одно из отличий, которое сразу просматривается, это связность мышления, коллективного мышления. Люди связаны между собой очень тоненькими каналами связи. Несколько секунд. А роботы способны обмениваться со скоростью гигабайт. Это значит, что они могут передавать друг другу очень большие блоки информационные, которые, естественно, называют знаниями. И в этом смысле мысль-то будет сеть, которая будет обмениваться. То есть сознание у роботов, оно будет такое очень динамичное, и в каждый момент времени набор навыков может меняться в зависимости от ситуации. Таким образом, разные роботы будут обладать, с одной стороны, разным масштабом психики, и поэтому разным уровнем сознания, а с другой стороны, они будут обладать ещё и разными навыками, поскольку эти навыки могут подгружаться динамически и отгружаться. Но резюмируя, сознание — это режимы глобальной синхронной активности, которые обеспечивают у человека идейское восприятие целей и действий. служит механизмом обучения умрекопитающих. А у будущих роботов, обучающихся, будут другие механизмы обучения. И сознание будет, может быть, такого же уровня, но другого качественного состава. Проверить мы это сможем, как правильно уже сказали. По-другому мы будем только ограничены нашими рассуждениями и бездоказательными. Ну и вот в заключение я приведу слова Калмогорова, что модель мыслящего существа есть само мыслящее существо. Спасибо, коллеги. 

S06 [01:51:56]  : Сергей Александрович, спасибо за интересный доклад. Хотелось бы еще раз спросить. Вы определение сознания разделяете с определением, которое Джульетт Аноним привел? 

S05 [01:52:14]  : Это определение не сознания, это определение меры сознания, то есть уровня сознания. 

S06 [01:52:20]  : А что такое тогда сознание? 

S05 [01:52:23]  : Сознание — это атрибут алгоритмов мышления, которые они сами ощущают у себя. То есть это видимое мышление, часть самого себя. 

S06 [01:52:41]  : — Ну тогда если к теме нашего семинара. Сознание возможно у искусственного интеллектуального агента? 

S05 [01:52:50]  : Да, конечно. Просто оно будет нечеловеческим. 

S06 [01:52:56]  : А зачем? То есть мы как бы стараемся его создать или оно просто появится автоматически? 

S05 [01:53:03]  : Нет, я думаю, что создавать его специально никто не будет. Оно должно появиться автоматически. Если поведение будет человекоподобным и психика искусственная, настолько же сложная, как человеческая, то и сознание будет на уровне человеческого. Если это будет, там, психика на уровне собаки, то и сознание будет на уровне собаки. Если психика на уровне мышки, то и сознание на уровне мышки. 

S06 [01:53:31]  : Ну, то есть, получается, если сознание появится, и психика появится, появится личность, мы каким-то образом придумываем законы под деятельность, да, и взаимодействие с этой личностью. А если мы как цивилизация захотим этого не делать, если нам это не нужно, мы посчитаем, что это нам просто не нужно, мы можем это как-то не допустить? 

S05 [01:53:57]  : Ну, мы просто будем считать, что нам это нужно, потому что без этого мы не справимся со сложностью современного мира. Мы же компьютеры создаем и совершенствуем, и создаем искусственный интеллект. Нет хорошей жизни. для того, чтобы улучшить нашу жизнь. Решить те задачи, которые мы не можем решить без вот этого инструмента. Этот инструмент расширяет возможности цивилизации. Если мы захотим остановить развитие цивилизации, пойти по какому-то восточному пути внутреннего созерцания, ну, тогда это возможно, конечно. Но я думаю, что это невозможно. Мой вопрос сейчас все-таки 

S06 [01:54:39]  : однозначного ответа на то, что вы высказали, ваше спективное мнение. Конечно. Сергей Александрович, спасибо большое за доклад. Я предлагаю, знаете, в завершение нашего семинара все вопросы, которые я сейчас адресовал Сергею Александровичу, адресовать нашим предыдущим участникам. Вот если с Анной начать. Анна, можете ответить на вопрос, что же такое сознание? 

S02 [01:55:11]  : Да, конечно, как уже и говорила в докладе, мы рассматриваем сознание с позиции механистических теорий сознания и как схему внимания. То есть функция сознания здесь как присмотр за тем, куда направляем внимание в нашей деятельности и на разных промежутках. И, собственно, при таком рассмотрении сознание, мы говорим, что есть и у искусственного интеллекта. И для чего оно нужно? Для того, чтобы качественно решать задачи, писать качественный текст, а не просто какой-то бессмысленный суда в качестве новостей. Может быть, выиграть игру в шахматы или в бо, и так далее. И оно как, собственно, и согласно с предыдущим докладчикам, сознание у искусственного интеллекта, в своём понимании, нам нужен способ более совершенного и продвинутого управления вниманием. Не просто опираться на собственный мозг и тело, но опираться на алгоритмы, которые нам позволят расширить нашу возможность управления вниманием. И для того, чтобы решать более сложные задачи, повышать наше качество жизни в итоге. И отказываться от повышения качества жизни нет смысла. Я считаю, и это решение проблемы Зонги непонятно, что изменится в реальном физическом мире. Изменится ли? Если кратко резюмировать ответы на вопрос. Владимир, я вас не слышу. У вас вечный микрофон. 

S06 [01:56:35]  : Прошу прощения, я говорю, что вы считаете так же, как Сергей Александрович, что решение сложных интеллектуальных задач, нахождение вариантов решения в новых ситуациях невозможно без сознания? 

S02 [01:56:51]  : Да, конечно, если сознание присмотрит за вниманием, да, определенно. Без сознания невозможно, и нам нужны те средства, которые позволяют это делать лучше. что лучше решает такие сложные проблемы человек с ручкой или бумажкой, или лучше решает все-таки человек с компьютером и сложными системами для управления проектами, не знаю, для вашей медиа-записи? Кто быстрее ответит на вопросы? Человек с углом или человек, который будет пытаться обратиться к своей собственной памяти для того, чтобы ответить на вопрос? Кто быстрее, точнее, это сделает, да? 

S06 [01:57:26]  : А философский зомби, он не может решать эту задачу? 

S02 [01:57:30]  : А смысл вообще как бы говорить о зомби? У нас как бы здесь нет смысла говорить о зомби. Что изменится от решения проблемы зомби? Почему зомби должен решать задачу? 

S06 [01:57:51]  : Он запрограммирован так, у него есть цель, он может себе ставить цели, он действует, как Роман Викторович любит говорить, он действует в темноте, то есть у него внутри ничего нет. 

S02 [01:58:07]  : Он же кем-то запрограммирован, значит, он решает цель этого волоска, в первую очередь, кто его программировал. Пока что это делают люди. 

S06 [01:58:16]  : Спасибо. Роман Викторович, Ваша позиция по этому вопросу, что такое сознание? 

S03 [01:58:25]  : Ну, если рассматривать мою сегодняшнюю презентацию, я отвечу на этот вопрос как комплекс тех феноменологических явлений, которые внутри нас происходят. То есть сам термин «сознание», он соотносится с разными объектами, с разными феноменами того, что мы ощущаем. Но вот я сегодня рассматриваю именно феноменологическое сознание. Собственно, я могу ответить, что, скорее всего, возможно, у искусственных интеллектуальных агентов Но оно будет другим. Оно будет нечеловеческим, как правильно сказал Сергей. Как сказал Сергей, не знаю, правильно или нет. Я тоже занимаю эту позицию. Познать его мы вряд ли, нам это удастся. И в данном случае... Я хочу рассказать про свой опыт. Я читал книжку Марвина Мински и Гарри Гаррисона «Выбор по Тьюрингу». Там был эпизод, когда главный герой хотел выкрасть своего робота. У него был робот, он хотел сам убежать из того места, где он находится, и своего робота забрать. И, соответственно, он его поместил в такой футляр. И робот ему сказал, оставь мне щелочку, чтобы мне не было темно. И вот здесь меня как бы поразило осознание того, что этот робот не является зомби, у него есть кавалитативное состояние. Хотя если бы он был зомби, он бы точно так же сказал то, как описали этот эпизод писателя Гарри Гаррисон. Ведущий специалист по искусственному интеллекту, один из ведущих, один из титанов прошлого, Марвелинский, в общем-то показалось, что да, у него были именно внутренние квалифактивные состояния. И вот здесь, отвечая на третий вопрос, который перед нами поставили, нужно ли феноменологическое состояние, феноменологическое сознание искусственным когнитивным агентам, я отвечу, что да. Я здесь хотел бы немного дополнить Владимира Сергеевича по поводу непредставимости мира зомби. Да, Чалмерс в своей книге показал достаточно Я считаю, он хорошо показал, что отдельные зоны могут быть представимы. Я могу самодействовать и таким образом выстраивать модели другого внутри себя. А это без феноменологического сознания, скорее всего, невозможно. И здесь можно обратиться к такой аллегории как интроспекция изучение третьего лица лица это объективное научное познание а что такое изучение от второго лица это наблюдение за собой в зеркало и вот как бы осмысляя вот это вот, осмысляя позицию отцовского лица, можно всё-таки понять, что такое феноменологическое сознание, зачем оно нам нужно и почему мы должны отражать внутри себя вот эти, чтобы их воспринимать и строить их модели поведения для того, чтобы успешно с ними взаимодействовать. Поэтому если у нас будет мир зомби, эти зомби не смогут взаимодействовать друг с другом. А если мы хотим построить искусственных агентов общего уровня, которые взаимодействуют в нашей реальности, не в каком-то виртуальном мире решают глобальные задачи стратегического управления цивилизацией, а именно которые воплощены в нашей реальности, Им будет нужно именно феноменологическое сознание для того, чтобы успешно взаимодействовать с нами людьми и с другими когнитивными агентами. То есть со всем множеством когнитивных агентов, которые населяют, будут населять наш мир. Отвечая на четвертый вопрос, нужно ли это нам, я считаю, что да, нужно. И только так мы повысим качество жизни всех людей нашей цивилизации в целом и, в общем-то, Я, в принципе, отношусь к будущим вот этим вот существам, не побоюсь этого слова, как к нашим потомкам, как нашим детям. Поэтому, как бы... считать, что наши дети достойны быть зомби, но это немножко как-то странно, поэтому давайте сделаем все хорошо. Ну и, соответственно, пятый вопрос. Если бы я считал не так, если бы я считал, что они должны быть зомби для того, чтобы не иметь никаких этических препятствий для того, чтобы, например, его выключить. Он же зомби, он вещь, его можно выключить, да? 

S06 [02:03:37]  : цель поставим, что нам нужна база на Марсе, и эти искусственные спектральные агенты просто нам эту базу на Марсе сделают. Но мы не хотим, чтобы они обладали сознанием, чтобы с ними не взаимодействовать как с людьми или с нашими потомками, как вы говорите. 

S03 [02:03:52]  : Да, вот если такое нам нужно сделать, то как раз если вот тот мой операционный фреймворк, который я представил, если его можно верифицировать и он будет подтвержден, что да, он именно операционный и помогает это сделать, то нам нужно будет проектировать этих когнитивных агентов в соответствии с этими принципами. То есть не давать им, например, мультисенсорную интеграцию. чтобы они не могли построить целостную картину окружающей реальности. То есть у них отдельно визуальная составляющая, отдельно аудиальная, отдельно тактильная и так далее. Всё по отдельности. И фактически это получаются отдельные агенты в одном теле. Вот в таком случае, скорее всего, не будет у них сознания. 

S06 [02:04:37]  : Вот немножко расширю список вопросов. А можно ли… Соответственно, вот вопрос я Сергею Александровичу задавал. Это сознание возникнет, если автоматически оно будет наделено свойством приватности, как сознание, например, людей. То есть мы тоже его не сможем познать, мы тоже его не сможем увидеть. Или из-за того, что это будет все-таки… построено на моделях, которые мы сами придумываем, мы все-таки сможем эту приватность нарушить? 

S03 [02:05:13]  : Я считаю, что в конце концов мы сможем нарушить приватность даже нашего собственного того, что там находится. Это вопрос времени. И само собой разумеется, что приватность будущих искусственно-когнитивных агентов тоже Вопрос в том, когда это произойдет. Скорее всего, изначально они будут так же приватны, как и мы, но в конце концов мы взломаем этот код и добьемся того, чтобы видеть глазами другого. Ну, фактически, сейчас уже есть эксперименты по воссозданию внутренней картинки, по очень многоканальному съёму ЭКГ или по томографии, я сейчас не могу точно сказать, но такие эксперименты ведутся. И те же нейросети позволяют вот эту картинку очень смутно нарисовать. Пока смутно, но это вопрос технической реализации. 

S06 [02:06:15]  : Спасибо, Роман Викторович. Владимир Сергеевич, 

S04 [02:06:20]  : Вам те же самые вопросы, что такое сознательность? Я уже в принципе сказал, что это способ управления, ну в смысле механизм, который управляет нашим распределением, нашим вычислительным кругом возможностей. То есть мы много сил тратим на выполнение действий, и когда у нас с выполнением действий все получается хорошо, мы можем, значит, придумывать себе новые цели и, соответственно, вот распределять усилия между этими двумя задачами, которые различны. И они в сложном мире, они всегда стоят и будут стоять не только перед нами, но и теми, значит, роботами, которые мы будем создавать. Ну, если, конечно, мы не хотим просто строить автомат, который нам открывает дверь или поднимает трус на высоту, им-то, конечно, сознание не нужно. Но проблема в том, что наша с сильным искусственным интеллектом проблема не столько техническая, сколько социальная. То есть наше общество, оно на самом деле не очень справедливо. Сейчас идет большое экономическое разделение, расстояние общества, и оно как бы углубляется. И проблема идет от отрицательного отбора в собственно руководство, как компаниями, так и странами и прочими организациями. И соответственно, те решения, которые принимаются достаточно высокого уровня, они как раз сложны. И поэтому если мы хотим улучшать наше общество, то надо как-то бороться с тем, чтобы эти решения принимались лучше, в том числе методами сильного искусственного интеллекта. Сознание – это необходимая часть работы в сложном мире, просто без сознания это делать невозможно. Во-первых, соотносить задачи с реальным миром, иначе мы не можем анализировать весь клуб задач, которые мы можем себе представить. Нам никогда вычитать не подможется, чтобы анализировать все не хватит. Поэтому мы должны выбирать, какое есть состояние, какую часть возможных стратегий развития можно проанализировать. И, собственно, какая нам еще нужна дополнительная информация, какие дополнительные действия нужны, чтобы мы могли, значит, определять какой-то новый цепь. И вот это управление, это наш процесс. И, на мой взгляд, есть это, собственно, сознание. Значит, второй вопрос — это, собственно, возможно ли оно в искусственном интеллекте? Да, и, на мой взгляд, оно возникнет не... как сказать, не эмержентно, как принято, хотя какие-то эмержентные процессы происходят, то есть никто не ждал, что так вот нервные сети набрат последние ошибки из работы. Тем не менее, вот это произошло. Вот. Но, значит, сейчас вот этот прогресс все больше утрачивает эту эмержентность, то есть сейчас все больше строится, как бы, очень структурированная модель, о чем, да, тоже показывал слайд. И, собственно, вот, значит, вот сознание, я думаю, будет вполне, значит, сконструировано эти новые, значит, модели. Ну и, может быть, это улучшит понимание, что происходит у нас в мозгу, где там что померить, чтобы понять, что с нашим сознанием. И не только в роботах мы сможем его контролировать, но и у человека контроль улучшится. Но, как я говорил, решать сложные задачи роботам нужно. Боюсь, что вы сейчас перестанете меня слышать, но, может, и не перестанете. И, соответственно, к сожалению, люди плохо решают сложные задачи, и поэтому роботов нужно будет, общество будет вынуждено все больше привлекать к решению сложных задач, а при решении сложных задач сознание будет. Вот. Соответственно, нужно ли это нам? Ну да, нужно, потому что, повторюсь, если бы человек хорошо справлялся с этими задачами, было бы мило. А так, соответственно, нужно. Значит, кто-то в своем обществе может это запретить, тогда там, где это не запретят, допустим, где-то они выиграют эту гонку и будут иметь значительные преимущества над теми, кто это запретил. Вот. Ну и можем ли мы это не допустить? Ну как. Ядерная война, уничтожение человечества, и все будет в порядке. Никакого, собственно, сознания машины не возьмет. Других путей я не вижу. Вот. И, собственно, вот я, правда, уже частично ответил на ваш дополнительный вопрос про... Сможем ли мы его понять? Ну, если, значит, он не эмержент и возникнет, а мы его создадим, конечно, мы сможем понять. Более того, и у человека нам станет понятно, как это работает. Ну, во-вторых, что... Надо понимать проблемы, которые перед нами стоят при обработке сложных задач и собственном пути их решения, и как это можно быть решено у нас в экологических системах. Их позволит нам, естественно, понять и контролировать. И, в связи с этим, нужно ли их внедрять в общество, или они должны быть отдельным сообществом машин? Есть, конечно, такое обстоятельство, что автопилотные автомобили кого-то задавил, его посадили в тюрьму или высечь, это, конечно, бессмысленно, ему совершенно безразлично. Но это связано с тем, что его алгоритмы обучения никак не связаны с теми воздействиями со стороны общества, которые на него влияют. То есть то, о чем я говорил, что если мы меняем какие-то коэффициенты или алгоритмы обучения после наших воздействий, или непосредственно меняем эти алгоритмы, то значит какого-то поведения он начинает избегать, какого-то, значит, поведения стремится, и, собственно, этим всем нужно управлять, вот этими, значит, предпониманиями, как все это складывается. И соответственно, то, что у человека и у животных есть центры удовольствия, в принципе, они же должны быть у робота и строиться на представлении о том, что оно должно существовать, не получать наказание от окружающей среды, а от общества наоборот, получать энергию, какие-то базовые потребности. Они есть не только у человека, но и у любого сущности, которая хочет как-то... Главное – нести ответственность за свое поведение. И эта ответственность может быть связана с тем, что сама природа обработки информации такая, что есть возможность влиять на то, к чему этот стремится. Если мы его наказали, то он к этому стремится. то есть в чем смысл нашей системы наказания. Ну или поощрение, то есть к этому надо стремиться, а к этим действиям нужно избегать. В принципе, управляя алгоритмами обучения и алгоритмами поведения, в принципе, все это можно регулировать и, собственно, Но Трассел, книжка, про которую я говорил, о том, что если мы закладываем жесткие цели, ну, если там открыть дверь перед входящим, мы вряд ли ошибемся. Но если мы, значит, для каких-то сложных мест начинаем закладывать цели, даем большие возможности для их реализации, то мы, скорее всего, ошибемся. И Трассел приводит такой пример, что если, значит, кто-то там находит бутылку с жином, И, соответственно, Игорь Жиринов говорит, три желания, любые, выполняем. Значит, загадывает ему первые два желания. Третье желание, как правило, одно и то же, чтобы первые два отметить. То есть сложные желания, когда, значит, мы пытаемся проверить, у нас как бы так хорошо никогда не получается, и мы, соответственно, свои цели всегда меняем по мере того, как приближаемся. Если, значит, робот у него заложили, он потом не может менять эти цели под наши желания. ну или под как бы вот принятые в обществе требования, то естественно эти цели никогда хорошо не будут. То есть цели должны формироваться, они формироваться должны с учением, с учетом мнения общества и соответственно... Не слышно, пропал звук. 

S06 [02:14:27]  : Владимир Васильевич, спасибо большое. Не слышно последнего, что вы сказали. Я понимаю, что всё то, что вы говорили, нас подводит ещё к одной глобальной теме, которую, наверное, мы в рамках этого семинара подискуптировать не сможем. Это свобода воли, вообще, личности наделённых сознанием. Но это, я думаю, вот... Роман Викторович, можно вам заключительное слово дать? Что нас ждёт дальше? 

S03 [02:14:55]  : Дальше нас ждет... Не могу пока сказать, что нас ждет дальше. Следите за анонсами наших мероприятий в фейсбуке, в телеграм-чатах. Возможно, мы придумаем что-то интересное, новое и всем полезное. Я хочу еще раз поблагодарить всех участников, всех тех, кто пришел нас послушать. Я хочу поблагодарить спикеров, которые доложили свое видение по проблеме сознания. Я думаю, мы добились тех целей, которые ставили перед собой. Спасибо большое, Владимир. 

S06 [02:15:39]  : Всем спасибо, всем прекрасного вечера. Я надеюсь, что эта тема была интересна и ту информацию, которую вы сегодня получили, она была полезна. Спасибо всем докладчикам за прекрасное выступление. До свидания. 









https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
