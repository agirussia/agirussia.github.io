## 1 октября 2020 - Александр Панов - Знаковые субъективные представления для построения общего ИИ — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/EvwFXzAuJW0/hqdefault.jpg)](https://youtu.be/EvwFXzAuJW0)

Суммаризация семинара:

ТЕМА
- Семинар посвящён теме знаковых субъективных представлений в контексте создания искусственного интеллекта (ИИ).

СУТЬ
- В центре внимания находится разработка архитектуры искусственного интеллекта, которая включает в себя элементы антропоморфного ИИ.
- Используются методы машинного обучения для автоматического формирования сценариев и планирования поведения ИИ.
- Разработана система, позволяющая агентам использовать фрагменты сценарной сети для генерации планов в различных ситуациях.
- Обсуждается вопрос извлечения информации из текстовых документов для использования в ИИ, а также примеры использования системы ассоциационно-реляционного анализа текстов для когнитивного ассистента.

ДЕТАЛИ
- Приведены примеры работы с задачами, связанными с планированием поведения роботов, включая анализ ситуации и формирование картинки мира ассистента.
- Рассмотрены вопросы вариативности операционного состава ИИ и ограничения вариативности действий на нижнем уровне иерархии.
- Обсуждается использование вероятностного подхода в ИИ и интеграция DSM без вероятности.
- Поднимается тема планирования поведения ИИ, включая моделирование протяженных событий и предсказание исходов на основе цепочек предшествующих событий.
- Приводится информация о том, как в системе функциональных систем Олокина проверяются и выполняются предсказания в процессе действия.
- Упоминается важность работы Леонтьева, Анохина и других в контексте знаковой системы и антропоморфного ИИ.

РЕЗУЛЬТАТЫ
- Семинар демонстрирует прогресс в создании антропоморфного ИИ, акцентируя внимание на междисциплинарном подходе к созданию систем ИИ.
- Приводятся примеры успешных разработок и достижений в области ИИ, таких как победа в соревновании на NIPS с использованием экспертных данных.
- Выделяются важные аспекты, такие как использование знакового представления для кодирования пространства и интеграция обучения с подкреплением с планировщиком.
- Подчеркивается практическое применение разработок в таких областях, как когнитивный ассистент для здоровья и сбережения, и возможности их использования в реальных задачах.





S01 [00:00:00]  : Всем добрый вечер. Спасибо большое за приглашение поучаствовать в, на мой взгляд, очень классном, хорошем начинании русскоязычной комьюнити по универсальному или общему искусственному интеллекту. Здорово, что она инициирована не в Москве, а в Новосибирске. На мой взгляд, это очень классная инициатива, которая в будущем, я надеюсь, поможет собрать хороший коллектив, внутри которого будут рождаться классные, хорошие идеи и будут, так сказать, продвигать нас к эре, когда мы узнаем, возможен ли AGI, а если возможен, то продвинутся в его создании. Сегодня тема моего доклада — это знаковые субъективные представления. На самом деле, на мой взгляд, название не очень удачное, но будем пытаться от него отталкиваться, поговорим, в общем, Центр когнитивного моделирования, которым я руковожу, то есть такое небольшое самопредставление будет. Потом поговорим про Embodied AI, то есть это наше понимание, что такое универсальный искусственный интеллект, как мы его видим. Немножко и про тесты AI поговорим. Потом я расскажу про нашу архитектуру СТРЛ и про нашу теорию знаковой картины мира, которая, на мой взгляд, является хорошим основанием для создания одной из версий. систему сильного и общего искусственного интеллекта. Чуть-чуть в подробности погрузимся, если будет время, поговорим про каузальные сети и про один из вариантов реализации когнитивных функций и планирования поведения. Ну а потом я в конце, надеюсь, останется время, поговорю про конкретные задачи. Понятно, что AGI на текущий момент, о его создании достаточно сложно говорить, поэтому мы придерживаемся концепции нервного AGI, как термин Герцель ввел, мне он очень нравится. На мой взгляд, это очень хороший путь того, чтобы мы продвигались к созданию AGI, то есть решать некоторые узкие задачи той системы, которая потенциально может решать и более общие задачи. Давайте я расскажу про Центр когнитивного моделирования, который объединяет специалистов из Фистеха и Федерального исследовательского центра информатики и управления. Пару слов про себя. Я видел в чате знакомых коллег, в том числе и по сессиям в НИЖА и в Сбербанке, и так в целом по нашей деятельности на тематике искусственного интеллекта. Но, тем не менее, много коллег, которых я не знаю. Думаю, что нужно представиться. Соответственно, я выпускник Новосибирска государственного университета, поэтому мне очень отрадно, что именно в Новосибирске родилась идея организовывать такие семинары. Сейчас я являюсь заведующим отделом лаборатории диктуально-динамической системы и когнитивные исследования. Федеральное исследовательское центро информатики управляет академическая организация. И заведую лабораторию, руковожу центром когнитивного моделирования и лабораторией когнитивно-генетических систем. Мы собрали вокруг хороший коллектив. Я являюсь учеником Геннадия Семеновича Осипова, который, к сожалению, этим летом ушел от нас. Но мы в нашем коллективе продолжаем его идею, вообще школу искусственного интеллекта советскую, которую очень начинал Дмитрий Александрович Поспелов. И в связи с этим я являюсь и членом российской ассоциации искусственного интеллекта РАИ. Это достаточно старая организация, которая объединяет, теперь уже нельзя сказать, что всех, но некоторых значимых представителей искусственного интеллекта. Как Антон уже говорил, я в том числе организую различные конференции, принимаю участие в организации, в том числе и по биологическим. Инспирирован когнитивным архитектурам, правда, сейчас Алексей Сансонович отходит от такого более узкого понятия и в такое более широкое понятие переходит. В этом году у нас в октябре будет большой камерес национальный. Всех приглашаю к участию. Он у нас будет в онлайне, в зуме. Работаю в некоторых журналах, лауреат медали РАН для молодых ученых, ну и проекты РФ и РНФ. Понятно, что в текущих реалиях для всех исследователей это необходимость. Вот на этом слайде хотел бы показать команду нашего центра. То есть мы собрали вокруг идеи создания таких общих систем управления, которые изучают различные аспекты искусственного интеллекта, такую хорошую большую команду, которая включает и докторов наук, и кандидатов наук. Эта команда достаточно междисциплинарная, включает в себя и психологов, и поэтому мы придерживаемся концепции именно такого междисциплинарного подхода к созданию систем искусственного интеллекта, в том числе и общих систем. И вот у нас наша команда базируется в трех таких отделах. Это лаборатории на Фистехе, Это лаборатория когнитивно-динамической системы, лаборатория интеллектуального транспорта. На фестивале мы решаем более конкретные прикладные задачи, в том числе с индустриальными партнерами. То есть как раз придерживаемся такой концепции NERO. Создавая некую большую концепцию, пытаемся ее приложить к конкретным насущным проблемам. И в официо-уран у нас более фундаментальное направление, где мы как раз в том числе и теоретические работы в области знаковых и картинных мер развиваем. Так, ну что ж, я подумал, что необходимо нам в любом случае начать с некоторых определений, как это принято в научном сообществе. К сожалению, не все успел посмотреть семинары AGI сообщества, поэтому точно не знаю, определяясь вы с терминологией, но думаю, что это всегда будет не лишним. Потратим на это несколько минут. Ну, вот я здесь привел те определения искусственного интеллекта, которые притерживаются мы в нашем коллективе. В первую очередь, конечно же, это определение, которое отталкивается от того, что искусственный интеллект — это наука об интеллектуальных агентах. То есть это некая автономная сущность, это может быть устройство или программа в симуляционной среде, которая отделена от среды, каким-то образом ее воспринимает и взаимодействует с ней, то есть выполняет некоторые действия, и реализует некоторое целенаправленное поведение. Она пытается максимизировать некоторые шансы и функции полезности, которые позволяют ей достигнуть некоторой цели. Мой учитель Геннадий Семенович Осипов еще один аспект, очень важный, на мой взгляд, отражал в своем определении того, что такое искусственный интеллект. Это, в первую очередь, такой набор методов, которые призваны решать такие задачи, у которых нет заранее определенного алгоритма решений. Таким образом, можно назвать методом инсекуции интеллекта только тот метод, который выдает в том числе и алгоритм решения задачи. То есть не просто решение, но и алгоритм решения. Алгоритм имеется в виду что-то, выраженное наинтерпретируемым человеком последовательность действий того, что было сделано для того, чтобы эту задачу решить. Ну и если говорить про универсальный искусственный интеллект, хотя на мой взгляд, конечно, это достаточно искусственное выделение, наверное, связанное с тем, что в начале 2000-х годов искусственный интеллект стал очень сильно сужаться до конкретного раздела, до машинного обучения. в многом и до понятия нейронных сетей, поэтому возникла такая инициатива, что все-таки давайте будем возвращаться к истокам, тогда, когда все хотели моделировать мышление человека и решать большой спектр задач, и поэтому появился термин AGI, на мой взгляд, в целом, почему бы и нет. Для нас в целом система AGI или система E – это одно и то же, если мы понимаем искусственный интеллект в таком. первоначально его с 50-х годов определения. Еще такой третий момент, который нужно отметить, который универсальный искусственный интеллект отличает, это подраздел искусственного интеллекта, в котором разрабатываются системы, которые могут без внешнего вмешательства разработчика или архитектора этой системы перенастраиваться на решение различных классов задач. Вот эти три момента, которые в этих определениях я хотел собрать, то есть это интеллектуальный агент, достигающий своих целей, получение интерпретируемого человеком алгоритма решения и перенастройка на другой класс задач. Вот эти три, наверное, самых важных составляющих, которые, я считаю, должны быть ключевыми в любой системе, которая претендует на то, чтобы называться системой общего и универсального искусственного интеллекта. Естественно, что и на сессиях Сбербанка мы все сошлись к тому, что чем более широк этот класс задач, для которых предназначена эта система, тем большую степь универсальности мы можем ей придать. Справа тут такая картинка изображена с нашей меж дисциплинарной позиции, так как у нас в центре работают и психологи, и лингвисты. Все-таки искусственный интеллект, на мой взгляд, это подразделение направления когнитивных исследований, которые занимаются тем, что исследует в целом человека. Антропология исследует некоторые исторические аспекты развития вида человека, лингвистика, язык исследует, психология мышления, нейрофизиология, такой субстрат физиологический. И искусственный интеллект в данном случае это такая база экспериментальная. То есть мы хотим не только математическую модель построить в разных процессах, которые исследуются в других науках, психологии или нейрофизиологии. Мы хотим, чтобы это было реализовано на каком-то другом, отличном от того, что мы сейчас видим у человека в субстрате, на какой-то машине Тюринга или на квантовом компьютере, если в дальнейшем будет возможно это сделать. Ну вот про определение, коллеги, я вот, к сожалению, не вижу чата и вопросов. То есть, если будут вопросы возникать, я сделаю несколько там по ходу своего доклада пауз, и можно будет там кратенько обсудить. Но я боюсь, что я в целом не уложусь в час, поэтому думаю, что все-таки постараюсь все основные вопросы на конец оставить. Поэтому прошу терпения, если какие-то дискуссионные вопросы будут. С другой точки зрения, мы придерживаемся концепции, которая называется воплощенное познание. Это распространенное на Западе направление когнитивных исследований, которое в первую очередь то, что мышление нельзя отрывать от самого субстрата, в котором оно реализуется. Нам очень важно исследовать не только процессы того, как генерирует поведение человека, но и как это связано с его телом, грубо говоря. Другими словами, между чувственно-моторным опытом и поведением, которое генерирует человек, существует очень сложный освет. И мы на самом деле не можем строго отделить, провести границу, где заканчивается интеллектуальный агент и где начинается среда. В каком-то смысле окружающая среда в Embodied Cognition-подходе – это часть когнитивной системы. На этом рисунке видно, что весь когнитивный цикл – это на самом деле цикл, который затрагивает и протекает не только где-то там в когнитивной архитектуре внутри, но он на самом деле затрагивает и те процессы, которые происходят во внешней среде. И на самом деле это во многом подтверждается тем, что даже в отсутствии связи с окружающей средой, познания и мышления, используют те механизмы, которые на самом деле работают, когда происходит взаимодействие со средой, то есть когда человек что-то воспринимает и совершает какие-то моторные действия. И, на мой взгляд, это не случайно. Полноценная система искусственного интеллекта, система AI, может быть реализована только в том случае, если мы ее реализуем на каком-то реальном субстрате. Поэтому мы в нашем центре очень много занимаемся робототехникой, я сейчас к этому подойду. Конечно же, мы можем долго дискутировать по поводу того, что такое реальность и как это отличать от симуляций, но мне очень нравится такая книга «Структура реальности» Дойче, может быть, кто-то из вас с ней знаком. На мой взгляд, там очень хорошо написано, что это не тот вопрос, которому следует очень сильно задаваться. Нужно заниматься своим делом, как говорится, строить систему искусственного интеллекта. Тут у меня будут время от времени некоторые ссылки во многом и на свои работы. Я не делал специально какие-то большие обзоры или ссылки на известные работы, хотя мы их, конечно же, знаем и про те подходы, которые я буду говорить, это в основном наши подходы, мы их сравнивали с другими. Антон правильно говорил, что я знаком со многими когнитивными архитектурами. В наших статьях можно будет посмотреть конкретно, если мы захотим с чем-то сравниться. Мы про это знаем, мы постарались выбрать все самое хорошее и классное. нужная для реализации системы AGI. То есть если собрать то, что я только что сказал в кучу, для нас важно, что нужно проводить отделение агента от внешней среды, но тем не менее не отрывать его от этой среды, то есть реализовывать концепцию Embodied AGI. Мы хотим, чтобы агент с этой средой взаимодействовал, то есть выполнял некоторые действия. И то, что я еще сейчас не говорил, это наличие других активных участников в среде, то есть других агентов, которые на самом деле обладают таким же уровнем, грубо говоря, интеллектуальности, как и тот агент, которым мы хотим управлять, поведение которого генерировать. И, что очень важно, должна существовать ограниченная возможность коммуникации между этими агентами. То есть, грубо говоря, мы не должны их сливать в одну систему и не позволять обмениваться любой информацией, которая нужна. Нужно вводить некоторые ограничения, которые в каком-то смысле связаны с ограничениями на естественный язык, которые накладываются, когда мы обмениваемся с вами какой-то информацией. И, что очень важно, мы хотим, чтобы в нашей системе AGI пиво и денег генерировалось интерпретируемым образом. Интерпретируемым не обязательно для человека, то есть не обязательно результат того, как решил задачу в системе AGI можно было транслировать на какое-то высказывание на естественном языке. Интерпретируемым, например, другими участниками деятельности. То есть в той мультиагентной или многоагентной среде, про которую я только что говорил. Нам важно, чтобы вот этот алгоритм решения задачи, который решает система AGI, она могла транслировать вот в эту систему коммуникации, в этот канал коммуникации, грубо говоря, передать его не обязательно человеку, а любому другому агенту через вот этот узкий канал. И вот это мы называем интерпретируемым поведением. Грубо говоря, нам нужно не только решить задачу, но и передать знание о том, как ее решать, то есть алгоритм, другим участникам в среде. И вот эти все компоненты мы считаем ключевыми для создания системы AJ. Я сегодня на самом деле буду в основном говорить про такую проблему, которая называется проблемой привязки символов. На мой взгляд, она очень хорошо отражает такую проблематику в создании системы AI, не сказать, что если мы ее решим, то все будет решено, но, на мой взгляд, это одна из ключевых проблем. В других своих докладах я и про другие проблемы говорю, про распределение ролей, про представление знаний, но тут я хотел отметить именно проблему привязки символов. В оригинале это термин «Wilhelm» в «Symbol Grounding Problem» И, на мой взгляд, в текущих работах ей недостаточно удивляется внимание. Напомню, что есть концепция классического искусственного интеллекта, где мы оперируем некоторыми символами, предикатными символами, но всем понятно, что это какое-то сужение. То есть мышление – это что-то большее, чем просто оперирование символами. То есть нам нужно эти символы заземлять на сенсорику. Это, конечно же, в контексте embodied cognition является ключевой проблемой, поэтому я и начал с embodied cognition. Конечно, можно сказать, что существующие подходы, связанные с нейросетевой привязкой, нейросимволик интегрейшн и так далее, тоже имеют место на жизнь, но все-таки это не полноценная семантическая привязка. То есть мы эту привязку не можем назвать семантической. Грубо говоря, нейронная сеть – это некоторое продолжение сенсоров. И вот эта связь, она не обладает динамическим уровнем интерпретируемости, что хотелось бы получить в реальной системе AGI. Ну и естественно, что для робототехники, а мы занимаемся в нашем центре робототехникой, вот эта проблема, она… очень актуально. Она называется символ анчеринг. Естественно, что если мы хотим, чтобы наш робот не действовал реактивно, а демонстрировал активное автономное поведение, нам эту проблему обязательно нужно решать. И естественно, что критериями, в какой степени мы решаем эту проблему, в такой степени мы и решаем проблему интеллектуального поведения роботов во многом. Это очень взаимосвязанные проблемы. Ну и тут я добавил слайд, на этот слайд меня натолкнула дискуссия заочная у нас с Дмитрием Сариховым по поводу теста. Я на самом деле достаточно скептически отношусь к тестам, хотя наши товарищи очень, коллеги, сотрудники любят участвовать в различных соревнованиях, но я считаю, что любой тест, какой бы мы ни придумали, он всегда будет подпалкивать людей, участвующих создание системы решающих НТС каким-то таким костылям, как это говорится, каким-то обходным маневром по иску лазей. Но, тем не менее, исходя из того определения и понимания EJ, о котором я только что говорил, мы хотим проверить, что некоторая система является интеллектуальным агентом, то есть отделена от среды, решает некоторую задачу, то есть действует автоматически, достигает некоторой цели и выдает интерпретированный алгоритм решения этой задачи. И, что я говорил, что тоже очень важно, самостоятельно перенастраиваться на другие задачи. Таким образом, если мы говорим про тест SGI, то он должен в себя включать широкий класс заданий, о которых агенту ничего не известно. Ничего – это важный момент. Это значит, что задание, если мы его выдаем нашей системе, она должна включать все правила и ограничения по получению этого решения. То есть, грубо говоря, само задание должно включать в себя определение, а что за среда, с которой агенту предстоит взаимодействовать. Может быть, это виртуальная или реальная среда. Это точно так же, как человеку могут сказать, ну вот поиграй либо в тетрис, либо сходи дверек открой, потому что душно. В этом же задании должны быть правила взаимодействия со средой, модальность сенсорного входа, тип цели, который нужно решить, и модальность акторного выхода. Акторного выхода я имею в виду, какие вообще действия можно совершать. Это включается в задание. И, естественно, чем больше таких заданий различных мы нагенерируем, тем больше уровень универсальности сможет демонстрировать наша система. Таким образом, по-настоящему полноценный EJI мы сможем проверить только тогда, когда мы этой системе вообще ничего не скажем о той системе заданий, которую мы будем выдавать. То есть это одновременно может быть и задание в виртуальной среде или ответ на вопрос, и одновременно это может быть и действие во внешней среде, что на наш взгляд концепцией будет EJI тоже очень важно. То есть нельзя замыкаться только на симуляционных средах или, например, на вопросно-ответных системах. С точки зрения робототехники, у нас в дискуссиях и такие брендштормы, была такая идея AGI флешки. То есть это система управления роботехническим устройством, которая записана на некоторое приносное устройство, флешку. Естественно, это такая условность, мы все можем и по сети передавать, но тем не менее. Мы эту флешку вставляем в некоторый разъем устройства автономного. позволяем ей некоторое время, грубо говоря, понимать, на каком субстрате она действует, что из себя представляет внешняя среда, может быть, ей даем возможность подключаться к необходимому симулятору, и затем мы выдаем ей команды на естественном языке, для того, чтобы выполнить какие-то операции в этой внешней среде или ответить на какие-то наши вопросы. Естественно, что здесь очень важен процесс обучения. Чем более качественный симулятор мы ей предоставим для прохождения первоначального этапа, меньше времени мы сократим на то, чтобы эта система начала полноценно действовать во внешней среде. Естественно, что во всех работах сейчас, которые связаны с робототехникой, симуляторы играют очень важную роль, потому что все хотят решить задачи в симуляторах, а потом применить симуляторы и не тратить большие ресурсы в реальной среде. 

S00 [00:21:55]  : Такое введение. 

S01 [00:21:56]  : Прошу прощения, если все это было уже известно, много раз обсуждено. Будем переходить, собственно, к нашим работам, которые мы реализуем в центре официи Урана и на Фистехе. Я начну с нашей архитектуры, то есть с нашего подхода, который мы строим для того, чтобы управлять реальными техническими устройствами, наша архитектура состоит из трех таких уровней. Первый это реактивный уровень, тактический это второй уровень и стратегический уровень. Реактивный уровень это естественно необходимые элементы системы интеллектуального управления. Там есть некоторая модель динамики объекта. Мы интегрируем уравнение этой модели динамики, возможно, с учетом различных геометрических ограничений, которые накладывает у нас реальная пространственная среда. У нас есть некоторые органы управления, и именно этот реактивный уровень реализует все команды, которые поступают с верхних уровней. Грубо говоря, следование по траектории, стабилизация, выполнение элементарных перемещений – это все на реактивном уровне. Именно здесь идет оперирование с конкретным железом. Чем мы управляем вообще? Манипулятором или мобильной платформой? Или каким-нибудь мануэльным роботом? На тактическом уровне мы решаем так называемые тактические задачи. Это задачи, связанные с компьютерным зрением и задачи, связанные с планированием траектории. Здесь мы работаем с пространственной моделью местности. Мы ее представляем в виде некоторых кейдов или набора различных в том числе лидарных точек. Здесь мы решаем задачу картирования локализации, здесь же и прогнозирование траектории, в том числе и других участников деятельности, и построение уже более длинных траекторий, избегание препятствий и мониторинг выполнения плана, плана по перемещению. И, наконец, на стратегическом уровне, где мы используем нашу собственную систему, знаковую картину мира, мы реализуем уже более сложные планы, в том числе коллективные, планы поведения, которые включают в себя не только действия по перемещению, но в том числе и действия, которые могут не мапиться на какие-то изменения координат. Например, действия, связанные с перемещением других объектов или посылками сообщений другим участникам деятельности. Здесь мы строим описание текущей ситуации, строим план и осуществляем процедуру перепланирования, если план не выполняется. Естественно, что, как я уже говорил, нам очень важно, что есть другие участники коалиции, с которыми мы можем обмениваться сообщениями по определенному протоколу, который нам определяет некоторый язык высказываний через которые мы посылаем информацию, которую получил текущий агент, или посылаем информацию о том, что же нам нужно решать. С помощью планирования мы таким образом составляем план решения, алгоритм решения задачи, который как раз мы надеемся, что может быть эксплицирован. Следуя этой архитектуре, мы и решаем различные нейровые задачи, про которые я, надеюсь, скажу в конце. А сейчас поговорю про этот стратегический верхний уровень, про картину мира. Но зайду немножко издалека. У нас сейчас выходит статья. Я не буду очень сильно перегружать какими-то формулами следующие слайды. Всех интересующихся я могу прислать эту работу. Сергею Шумскому уже тоже высылал, когда мы с ним обсуждали такую концепцию. В общем, симбиотический агент – это как раз верхний стратегический уровень. Все эти тактические реактивные уровни здесь просто сжаты до такой границы между внутренней и внешней средой. Но мы считаем, что они есть. Нам очень важно, что деятельность предметная. Я чуть позже скажу, почему это важно для нас. Геометрический агент на стратегическом уровне оперирует с конкретными предметами. Он оперирует некоторыми сущностями, с которыми он совершает некоторые действия. Естественно, что эти сущности могут быть и абстрактными, и конкретными объектами, но тем не менее мы всегда оперируем с какой-то сущностью, нам это важно, потому что имена языковой системы мы прикрепляем к этой сущности. Вот этот коричневый N – это имя некоторой сущности. Есть два основных аспекта поведения агента. Это восприятие, это функция f от p, это функция распознавания тех самых сущностей, которые есть во внешней среде. Мы реализуем такой иерархический способ, я чуть позже про него скажу, он реализуется с помощью специальной каузальной предикторной сети. И второй аспект очень важный – это генерация действий. Так как мы говорим про embodied cognition, для нас важны оба этих аспекта. То есть нам нужно провести привязку символов и нам нужно сгенерировать некоторое поведение. И тот и тот процесс – это иерархические процессы. Здесь мы работаем с последовательностью сигналов, признаков, нам важна развертка во времени. Я, правда, не говорил про некоторые постулаты, что в embodied cognition нам важно, что любая когнитивная функция выполняется в течение некоторого времени, но здесь как раз этот момент. То есть мы во времени действуем, нам нужно выполнять определенные операции к определенному времени. То есть мы не можем бесконечно рассуждать прежде, чем сделать какое-то действие. И у нас есть внутренняя среда и внешняя среда. Внутренняя среда тоже может быть источником определенных признаков, которые мы называем признаками сущности «я». И в каком-то смысле это отделение внутренней и внешней среды достаточно условно. Это как раз реализует эту концепцию embodied cognition, когда мы не можем строго отделение внешней и внутренней среды провести. Естественно, что у нас есть некоторые модели действительности, которые мы храним в виде специальной сценарной сети, а поведение мы генерируем с помощью так называемой акторной сети, которая реализует кодирование целей и функции полезности тех действий, которые мы с помощью данного агента совершаем. Все вот эти три концепции, которые привязаны так или иначе к конкретной сущности или предметам, мы вот таким образом здесь разными цветами обозначаем. То есть красненький – это некоторая привязка к сенсорике агента, зелененькая – это привязка к тем действиям, которые мы совершаем с этим объектом, и синенькая – это привязка к некоторой абстрактной памяти. Естественно, есть четвертая серия компонентов – это имя. Это, грубо говоря, некоторая последовательность символов языка, на котором мы составляем сообщение для коммуникации. Немного формализма. Еще раз, я тут им не пригружал, все подробности можно в этой статье будет посмотреть. Для нас очень важно, что процедура распознавания работает на основе каузальной предикторной сети. Я чуть позже скажу, что это такое. Мы говорим, что ее результатами является так называемый образ сущности. Я сейчас веду эти три понятия образ, смысл и значение. В каком-то смысле это исторически сложившееся определение. Можем сказать, что это не образ, а множество признаков, еще что-то. Будем оперировать такими понятиями. Как я уже говорил, есть некоторый набор внутренних признаков, которые с помощью вот этой функции распознавания определяют состав выделенной сущности с именем «я». Это нам очень важно, потому что поведение любого агента у нас связано с тем, что это личностное поведение, именно его, ему нужно отличать свое поведение от поведения других агентов. Соответственно, процедура генерации действий, такая нисходящая активность, это иерархическая процедура разворачивания этих действий. Эту пару, стратегию, операционный состав этого действия и цель, для которой мы этот операционный состав выполняем, то есть акцептор результата, если мы говорим о функциональной системе Анохина, то эту пару мы называем смыслом этой сущности. Понятно, что понятие личностного смысла это более глубокое, мы можем говорить о том, что это еще и некоторая эмоциональная окраска и так далее, но здесь такое послуженное использование в целях интеллектуальных агентов и робототехники. Соответственно, множество всех смыслов кодируют с помощью каузально-акторной сети. И наконец, эта память верхняя, про которую я только что говорил, она состоит из сценариев. Ядром каждого этапа сценария является обобщенная ролевая схема действия. Это идет из лингвистики и называется значением этой сущности. Чуть позже я покажу подробнее каждый из этих компонентов. И все сценарии вместе образуют такую структуру, которая называется сценарная каузальная сеть. Все было бы хорошо, но нам очень важно, чтобы эти три концепции, три типа информации, с помощью которых мы описываем некоторые предметы, с которыми действует агент, они находились не раздельно друг от друга, а были связаны. Их связывают между собой так называемые функции связывания. Мы их все обозначаем. У нас три компонента, если мы не учитываем имя, то у нас шесть таких функций. Каждая из них очень хорошо интерпретируема. Если мы говорим, что мы связываем образ предмета со смыслом, то мы говорим, Актуализируем реализацию действий по текущим активным признакам. Грубо говоря, нам нужно сгенерировать некоторые действия в ответ на описание некоторой текущей ситуации. Текущая ситуация здесь таким фокусом внимания обозначается, S от T. Функция перехода от значения к смыслу – это конкретизация обобщенной схемы действия. Когда мы переходим от смысла к значению – это обратная операция, сопоставление текущей реализации действия с его ролевой структурой. И вот все эти функции параметризованы именем. То есть мы говорим, что каждая из этих функций осуществляет переход именно в рамках некоторой конструкции, которая моделирует нам Некоторые данные о конкретном предмете, который в языковой системе именуется с помощью какого-то набора букв N. Эта локализация информации – это ключевой момент, который выделяет всю нашу концепцию. Именно за счет этой локализации информации мы можем ускорять некоторые процедуры планирования или вывода на этих сетях. Все эти три концепции, на самом деле, как обратили внимание мои учителя, очень хорошо подходят под концепцию знака. Вот эти три информации о сущности, которые, я дал определенный образ, значение, личность и смысл, они выполняют роль таких образующих большой активной базы знаний агента или, как она называется, картины мира агента. Образ или структура образа представляет собой взаимосвязь внешних сигналов и внутренних характеристик субъекта-агента. Это сенсорно-моторное представление той информации, которую наблюдает робот. Структура значения – это некоторая долговременная память, если мы аналогию с когнитивными архитектурами проводим. Это обобщенность значения в соотношениях во внешнем мире. Нам очень важно, что вот эта структура значений согласована в некоторой группе субъектов. Грубо говоря, когда мы говорим о том, что у нас есть некоторая языковая система и сценарная сеть, эти сценарии на самом деле должны быть общими для всех участников некоторой группы. То есть это сценарии, которые одинаковы, то есть поведение в этих сценариях, последовательность шагов обобщенных. Она в целом одинакова у всех агентов. Это некоторая разделяемая память, грубо говоря. Естественно, мы ее не разделяем между всеми агентами, а канализируем в некоторые ограниченные каналы обмена сообщений. Личностный смысл – это ситуационная потребностно-мотивационная интерпретация знаний. То, для чего агенту нужен тот или иной предмет, какую именно операцию он с ним выполняет, какую цель он преследует, когда он взаимодействует с этим объектом. Ну и в целом понятие знака для нас – это очень важное понятие. В целом правильная модель знака на наш взгляд и решает эту проблему привязки символов. Нельзя сказать, что наша текущая реализация этой модели полностью позволяет нам эту проблему привязки символов решить. Иначе мы бы уже сказали, что мы построили систему AGI. Но, на мой взгляд, именно движение в этом направлении и позволит эту проблему в итоге как-то так или иначе решить или понять, что она не решаема. И отличие между символами здесь очень простое. У символа обычно нет структуры, нет каких-то привязанных к ней процедур, которые позволят обучаться или привязываться к какой-то сенсорике. И вот в этом смысле такое понятие знака, которое обладает некоторой структурой, он восходит ко многим логикам и лингвистам, и Пирксу, и Фреге, и, что очень важно, в психологии тоже это понятие имеется. Идея формализовать это понятие, использовать его в качестве структурного элемента представления знаний и моделирования когнитивных функций – это, на мой взгляд, центральная идея, которой придерживается наша школа, которая развивает эту теорию знаковой картины мира. Но нужно сказать, что такие идеи в советской школе развивались еще с 80-х годов. Есть такое направление, как прикладная асиммиотика. И здесь уже такие основные принципы, таких баз знаний асиммиотических закладывались. В первую очередь, это некоторое структурирование, связанность, что очень важно, активность, чтобы были устроены процедуры их пополнения. На мой взгляд, недооцененный момент – это рефлексивность. Когда мы говорим про интерпретируемость алгоритма решения, мы говорим, в первую очередь, о том, что агент должен обладать некоторой моделью рефлексии. иметь некоторое представление о том, в каком состоянии находится его знание. То есть он должен не только о чем-то внешнем рассуждать, но он должен рассуждать о том, в каком… согласованы или не согласованы его собственные знания. То есть это реализация некоторого мета-уровня. Ну и, естественно, принцип матрешки, это в целом такие идеи, которые в советской школе развивались достаточно давно, и мы на основе этих эволюционирующих идей в данном случае поддерживаем теорию знаков картины мира. Пару слайдов совсем скажу про психологическую интерпретацию. На мой взгляд, такая российско-советская школа психологическая, она очень сильная, она очень хорошо локатируется за рубежом, и психологи, вот именно когнитивные психологи, то есть не какие-то психологи, которые занимаются психодиагностикой, а вот именно исследователей мышления, они отправятся тоже на очень хорошую школу, культурно-исторический подход Луготского, который вот как раз, на мой взгляд, Точно вот такими неформальными методами такой психологической теории, ее сложно назвать, но тем не менее концепциями охарактеризовала, что такое знак с точки зрения психологии мышления и с точки зрения личности, то есть не с точки зрения лингвистики. Есть некоторая социальная среда, есть психологические орудия, которые на самом деле, знаки-символы являются такими психологическими орудиями, которыми обладевает ребенок в процессе своего развития. И затем вот эти некоторые процедуры, они сворачиваются, интерьеризуются во внутренний план. Эта интерьеризация происходит вокруг некоторых предметов, с которыми взаимодействует ребенок, и потом он их называет отдельными именами. Поэтому вот эта вот вся интерьеризация в структуру знака, она является центральной идеей в культурно-историческом подходе. Естественно, что развитие – это стадиальный процесс, сознание развивается через диалог. Это как раз идея о том, что если мы говорим о сознании, что должно зарядиться в моделях общего искусственного интеллекта, то, естественно, нам нужно поддерживать мультиагентную среду или, по крайней мере, дать возможность этой системе ЭДЖАЙ включаться в культурную среду человека. Ну и про теорию деятельности – это уже такая более частная теория того, как генерирует поведение человека. То есть это некая двойная эротическая структура мотива цели, действия, операции, деятельности, что это целенаправленно активный процесс. И вот как раз Леонтьев предложил вот эту структуру, образ, значение, смысл у знака, которое вот потом было добавлено, характеризуется некоторым именем, который его обобщает вот эти все три компонента. Ну и в целом понятие «знака» на самом деле очень широкое и богатое. Вообще семиотика, если мы говорим про семиосферу, то, что Лотман рассказывает, на мой взгляд, исследования междисциплинарные в этой области очень продуктивные. Я, конечно, фанатом междисциплинарного подхода являюсь, и, на мой взгляд, работы в этом направлении действительно многообещающие. Если все это собрать вместе, то картина мира субъекта деятельности – это некоторые представления субъекта о внешней среде и своих собственных характеристиках, целях, мотивах и других участников деятельности, и генерация некоторых когнитивных функций на основе этого представления. Вот пример такого сна, как книга, его образ, обложка, страницы, личный смысл — это читать конкретные действия с ним связанные и некоторые сценарии того, что такое, например, читать или покупать. Нужно сказать, что вот эта трехкомпонентная структура или четырехкомпонентная, она на самом деле находит свои подтверждения и во многих других моделях. То есть, например, в психологической теории трехкомпонентные модели Станович или, например, нейрофизиологических данных как распространяется сигнал, хотя это, конечно, многими подвергается сомнению, но тем не менее, например, та же модель Global Workspace Sphere, она все эти три компонента точно так же упоминает. то есть это все те компоненты, которые обязательно должны присутствовать в описании некоторого предмета. То есть когда мы говорим про Global Workspace Series, это тоже некоторая локализация всей информации, которой обладает наш агент. Сейчас немножко про математический формализм, который мы используем. Все вот эти идеи, которые я говорю, это такие больше мотивационные моменты. Естественно, что главные работы, которые мы делаем, это математическое описание и программная реализация всех тех идей, про которые мы говорим. Естественно, что не все пока получается реализовать в программном коде, но тем не менее кое-что получается. Все эти работы именно с такой роботехнической составляющей мы ведем с 2010 года, то есть первые публикации у нас появились. То есть уже на протяжении 10 лет мы такую работу делаем и есть определенные успехи в этом направлении. Базовый математический объект, который мы используем для… Я начну с каузальной сети на образах. Это каузальная матрица. Это структура, которая кодирует сенсорную информацию на разных уровнях. Мы ее представляем как развертку во времени, поступающих одновременно, понятно, что дискретизация – это тоже некоторый параметр, признаков нижнего уровня иерархии. Эти признаки могут быть как элементарными, так и представляться другой каузальной матрицей. И что очень важно, мы вот эти моменты времени можем разделять на две группы. Это признаки, которые кодируют условия и эффекты, то есть выделение причинно-следственной связи. То есть мы не просто кодируем признаки, то есть такую пространственную группировку признаков делаем и временную, но мы еще выделяем причинно-следственную связь. Мы говорим, что у нас в процессе наблюдения этих признаков мы видим, Эти всегда встречались до того, как появились вот эти. Естественно, что вот эту матрицу мы можем в процессе деятельности агента набирать различными вариантами и появляется вот такая третья ось – это прецеденты. У нас есть время, то есть развертка, описание некоторого объекта во времени с помощью признаков, которые появляются в течение времени. вот эти сами признаки, которые по Эрику, и вот эти прецеденты. Сколько раз мы этот объект видели, его распознали, и вот эти прецеденты мы можем динамически друг с другом склеивать или, наоборот, сохранять, обобщая в целом некоторое представление об объекте. Количество этих прецедентов мы можем регулировать обобщающую силу нашего представления. Все это в трехмерную матрицу сжимается. И естественно, так как у нас есть ссылки на другие матрицы, все это вместе формирует каузальный образ. Это, естественно, некий ориентированный, помеченный граф, у которого есть узлы, которые представляют собой кортеж каких-то каузальных матриц, то есть такой тензор. Мы проводим ребро, если у нас есть ссылка с некоторого столбца на другую каузальную матрицу, делаем пометки, которые нам говорят, в какой момент времени появляется этот признак и к какому признаку он соответствует. Простой пример этой глаузальной сети на образах. Есть, например, такая картинка, которую мы можем моделировать с окады взгляда, которые сначала концентрируются на в одном узком фокусе, потом перескакивает на другой и так далее. Таким образом мы временную развертку генерируем. И можем сказать, что сначала мы наблюдаем левый глаз, правый глаз, потом нос и рот. Все это вместе составляет признаки отдельной сущности лица, которые, в свою очередь, являются некоторой составной частью тела. Такие отношения на каузальной сети образов мы можем интерпретировать как признаки отношений части тела. И вот функция распознавания, про которую я говорил, которая является важной функцией в деятельности агента, она работает за счет распространения активности. Мы используем правила Байзовского вывода по вершинам узлов вот этой каузальной сети. И в каждом из этих узлов происходит распознавание признаков конкретной предметной области. То есть мы группируем эти каузальные матрицы в зависимости от типов признаков. Грубо говоря, если мы говорим про распознавание звуков – это один узел, если мы говорим про распознавание цветов или пространственных соотношений – это другой узел. Так функция распознавания работает. На первом этапе мы в момент времени t подсчитываем правдоподобие каждого события на основе значений входящих признаков. Вектор значений признаков с каждого уровня, мы называем это гетерархия, потому что у нас многомодальность, мультимодальность может быть, подсчитывается с помощью последовательного соединения координации из дочерних узлов. И, что очень важно, мы подсчитываем предсказывающий сигнал. Мы не только распознаем то, что мы получаем в текущий момент, но и предсказываем, что еще может случиться на несколько шагов вперед. Это позволяет нам затем генерировать некоторый план действий в том числе. Таким образом, давайте очень простой пример актуализации знака, который на таких матрицах работает. Вот у нас есть некоторый набор таких признаков, есть предсказывающий сигнал с верхнего уровня. Мы этим признаком сопоставляем некоторые наборы наших косзальных матриц. Поступает сигнал в данный момент времени с нижнего уровня иерархии, мы его сопоставляем с толпцом, который кодирует у нас этот признак, вот этот поступающий зеленый вектор. Используя одну из метрик, например, Ивкидову, мы отсеиваем те матрицы, которые слишком расходятся от текущего входного сигнала. Первую отсеив мы делали по сигналу предсказания. И на основе того, какие у нас получились после отсева матрицы, мы генерируем, что же, скорее всего, мы наблюдаем в данный момент на данном уровне. На основе того, что у нас есть следующий шаг во времени, мы можем сгенерировать предсказывающий сигнал на нижний уровень иерархии, который для данного уровня иерархии вот здесь вот нам приходит. На разных уровнях иерархии у нас разная развертка во времени. Грубо говоря, на верхнем уровне иерархии у нас один шаг во времени проходит, внизу 10 шагов во времени. Таким образом, мы повторяем этот цикл в зависимости от того, какой у нас предельный размер по времени для распознавания этого объекта есть на данном уровне иерархии. Следующий вектор поступает, мы опять отсеиваем признаки и так далее. Такая структура соотносится с некоторыми идеями из нейрофизиологии. Про нейронные субстраты я сейчас не буду говорить, но, тем не менее, многие из вас, наверное, знакомы с работами по нейрофизической временной памяти, и мы инспирировали такую архитектуру, основываясь на этой концепции. Нельзя сказать, что она полноценно очень хорошо реализует все принципы устройства даже неокортекса, но, тем не менее, это одна из немногих хороших рабочих теорий, которые хоть как-то пытаются математическую теорию и программную реализацию этого построить. Мы ей пользуемся. Естественно, что нам важно не только иметь некоторую структуру кодирования, нам важно эту структуру кодирования пополнять. Именно для обучения в этой предиктор-экранузальной сети мы используем нейросистическую временную память. То есть, по сути, вот эта временная развертка – это как раз такая марковская подсеть, когда мы говорим, что у нас есть некоторое событие, и вслед за ним может случиться целый ряд других событий. И мы обновляем с помощью так называемого temporal memory, временной памяти, мы обновляем статистику того, что зачем случилось. И у нас есть некоторый временной группировщик, который, соответственно, и группирует эти признаки с нижнего уровня иерархии и говорит, что за тот или иной сигнал у нас, соответственно, какой-то набор признаков. Те, кто из вас знаком с аэротической временной памятью, могут отметить, что нейросетевая реализация, которая там используется, там специального вида биологических правдоподобных нейронов используется с набором дендрипов. Они реализуют еще один важный принцип – это подавление нерелевантной информации. То есть, грубо говоря, активизация некоторого нейрона приводит к подавлению всех остальных нейронов. Это очень важный принцип. Мы как раз в процессе обучения его повторяем, используя фреймворк, который развивается с помощью NUMENT. И в целом, если мы собираем все это вместе, у нас клаузально-предикторная сеть, У меня опечатка тут должна быть не предикторная, а акторная. Мы сейчас с вами говорили про структуру образа, сейчас переходим к структуре смысла, то есть следующего компонента знака. Акторная каузальная сеть – это тоже некоторый граф, направленный с множеством вершин и ребер. Нам очень важно, что, как я уже говорил, у нас к каждому узлу в акторной сети Это элемент, который отвечает за цель на текущем уровне, а Q – это функция полезности. Функция полезности, как это принято в обучении с подкреплением, это некоторое действительное число, которое характеризует по текущим активным признакам на данном уровне абстракции, на данном уровне иерархии, полезность того, что мы выполняем некоторое действие, которое раскладывается в следующем уровне иерархии на операционный состав P. P – это стратегия на текущем уровне, реализующая некоторое действие A. Мы связываем в этой каузальной акторной сети два действия друг с другом, если один является элементом стратегии, реализующей операционный состав следующего действия на следующем уровне иерархии. И вот эта процедура разворачивания действий проходит у нас итерационно. Мы говорили про процедуру распознавания, такую иерархическую с предсказанием, и есть процедура разворачивания действий в нижний уровень, в генерацию действий. Мы выполняем эти операции на каждом уровне иерархии и в итоге генерируем последовательность элементарных операций, например, моторных команд для робота. Вначале проходит идентификация текущей цели. Про это я чуть позже расскажу, если будет интересно, какие алгоритмы для выделения по цели мы используем. Выбор оптимальной стратегии, например, жадным, если мы используем такую идею, как value-based методы, то есть просто по функции полезности выбираем, генерируем некоторое распределение, либо выбираем с максимальным значением. Ну и затем переходим на следующий уровень иерархии, генерируем последовательность операции на основе некоторого распределения, который у нас задает вот эта стратегия с учетом текущей нашей ситуации. Естественно, что каузальную актуальную сеть мы тоже обучаем. Для ее обучения мы используем иерархическое обучение с подкреплением. Это та схема, которую мы реализуем. Если вы заметили, кто-то из вас знаком с option framework, это такой подход к иерархическому обучению с подкреплением. Наша модель очень хорошо на него ложится. При том, естественно, что мы можем вот эту вот отсечку сделать до какого-то уровня абстракции и говорить, что у нас вот эта вот стратегия, которая генерирует нам определенный состав действий и зависит от текущего набора признаков на текущем уровне иерархии, она, например, может реализовываться нейронной сетью. То есть для некоторых примеров нейроподходов, которые мы делаем, мы можем Он говорит, что эту связь между актуаторами и последовательность действий мы проходим за один шаг некоторым нейросетевым блоком. Обучение его мы производим с помощью общего фреймворка, который нам позволяет на каждом уровне иерархии, в зависимости от того, какая у нас есть целевая ситуация, обновлять такими итерационными методами нашу стратегию. Мы используем подход Actor-critic, то есть разделяем модуль, который обновляет ошибку предсказания того, хорошо ли мы выполнили это действие или нет, ошибку предсказания, полезности. И отдельно у нас есть голова, которая генерирует действия с учетом того, какую поправку вносит критик. И, наконец, про сценарную каузальную сеть. Это, напомню, третий компонент. Это компонента значения. Ее определение, как и всех двух оставшихся каузальных сетей, мы говорим, что это некоторый направленный граф с множеством вершин. Здесь особенность заключается в том, что каждый узел представляет из себя предикатно-ролевую структуру. Предикатно-ролевая структура — это понятие, которое идет из лингвистики, когда описывают некоторые глаголы или действия. Как говорят лингвисты, у любого предикатного слова, например, глагола, есть семантические валентности. Например, это субъект, объект, инструментатив, локатив и так далее. То есть набор таких валентностей ограничен, их 60-50 в зависимости от типа выделяют. Мы говорим, что в нашем сценарии, ядром сценария являются некоторые действия со своим ролевым составом. На верхнем уровне представляют себя очень абстрактные роли, то есть субъект-объект. Каждую эту роль может заполнять некоторый категориальный класс, как в лингвисте говорят, существительного. В данном случае это тоже некоторые наши объекты действительности, сущности. У нас есть некоторый знак роли, и таким образом это является одним из отношений на сценарной и каузальной сети. И второй тип – это причинно-следственная связь. Переход выполнения одного действия в сценарии приводит к тому, что мы можем или должны выполнить следующее действие. Таким образом, у нас сценарий представляет некоторый обобщенный план действий, который есть в среде. Естественно, что это обобщение должно согласовываться с другими участниками деятельности. Грубо говоря, мы говорим, что мы заполняем этот ролевой состав некоторыми сущностями до такого уровня абстракции, который согласован всеми остальными участниками деятельности. Грубо говоря, когда мы говорим, что Директор руководит предприятием, в данном случае руководит это некоторый элемент сценария того, что значит руководить некоторым предприятием, и в данном случае заполнение субъекта, то есть кто руководит, должна быть определенный класс категориальный, который определяется тем, что это не какие-то другие должности, а именно директор руководит предприятием. И, естественно, значения точно так же могут пополняться. Структура значений и сценариев точно так же может модифицироваться вне зависимости от того, как действуют другие компоненты. Естественно, что это должно быть связано с анализом некоторых текстов или инструкций, потому что это как раз тот самый канал коммуникации, который используют агенты в своей среде. И вот в FITSU Uran есть хороший текстовый анализатор, который послужил ядром для различных инструментов поисковых систем и текстового анализа. Это ситуационно-религиозный анализатор. И вот с помощью него мы как раз реализуем процедуру пополнения этих сценариев на основе текстов. То есть это как раз выделение предикатов, шагов в сценарии, например, покупки автомобиля или, например, поездки в отпуск или покупки билета на ЖД и так далее. в соответствующем применении такого стационароэляционного анализатора мы можем выделять действия, промежуточные цели, орудия, существители и различные заполнители вот этого ролевого состава каждого действия. В итоге, все это обобщая вместе, все процедуры и обучение в том числе и выводы, то есть генерации поведения, они должны быть согласованы локально в структуре конкретной сущности. Это делается за счет работы функции связывания, о которой я вам уже говорил. Обобщая все это вместе, можно сказать, что знаком в знаковой картине мира является некоторая динамическая структура, которая задается некоторой четверкой. Z – это набор каузальных матриц или фрагментов каузальных сетей, про которые я говорил. Такие, что эти функции связывания на самом деле переводят одну компоненту в другую, когда мы последовательно компоненту саму в себя. То есть, грубо говоря, это должна быть некоторая неподвижная точка вот этих операторов, если мы говорим про них как про переводящие из множества образов множество значений, например, знаков. Естественно, если мы последний дух от друга их применим, мы должны вернуться в тот же самый компонент. Это значит, что все эти компоненты согласованы друг с другом. И раз они согласованы, значит, они определяют собой некую консистентную единую информацию о некоторой источнице, и тогда мы ее называем знаком. Я уже говорил про то, что процедуры вывода, у нас есть процедуры обучения, но я не говорил подробно про процедуру вывода. Их мы обобщаем в четыре правила. Локальные правила распространения активности по структурам каузальных сетей. распространение активности при распознавании объектов. Я такую маленькую процедуру того, как это работает, уже показывал. Восходящее правило, предсказывающее правило – это все назначение некоторых величин, активации конкретных элементов нашей коллайзальной матрицы или фрагментов сценария, если мы говорим про сеть значений. Так, ну что, товарищи, я уже целый час рассказываю, буду сейчас по себе переходить к Нейровой Жае, мне нужно будет еще 15 минут. Антон, есть у меня еще 15 минут? Конечно, да. Хорошо, спасибо. Я вот вижу, что появляется там в чате много вопросов. Прошу прощения, что я их не читаю, иначе я просто боюсь, что совсем ничего не успею. Я надеюсь, что там не только ругаются на меня, но и есть что-то интересное. Сейчас буду заканчивать, и потом это все можно будет обсудить. И есть некоторые глобальные правила распространения активности, которые как раз работают за счет того, что у нас есть функции связывания. Грубо говоря, если у нас активен один компонент, мы можем предактивировать другой компонент. И вот только тогда, когда у нас активированы все три компонента, которые с помощью функции связывания замыкаются в знак, тогда мы говорим о том, что у нас активированы некоторые знаки. Модель когнитивной функции в теории знаковой картины мира – это последовательность активации знаков. Любая реализация когнитивной функции – это последовательность активации знаков. Мы будем сейчас говорить про планирование, там будет последовательность активации знаков, которая генерирует ту или иную ситуацию. Так, сейчас кратенько про планирование поведения. Это одна из функций, которую мы очень хорошо, на мой взгляд, смогли реализовать в этой концепции знаковой картины мира. И планирование поведения – это вообще ключевая задача в робототехнике, поэтому мы ей уделяли большое внимание. Планирование поведения у нас – это иерархическая процедура, которая в связи с тем, что у нас есть иерархические структуры и в сценариях, и в смыслах, и в образах, то, естественно, и процедура планирования тоже иерархическая. Как раз это концепция того, как мы связываем все эти три компонента вместе. Планирование происходит повторением так называемой мап-итерации. Вначале мы ищем прецеденты выполнения действий в текущих условиях, затем мы поиск применимых действий, то есть обобщенные сценарии, которые могли бы быть применимы. Потом мы генерируем смысл, то есть реализацию конкретного действия, то есть, помните, генерация процедуры. с помощью функции fA и описание следующей ситуации, то есть предсказания того, что должно произойти. И потом генерация снова действия, которые нужно выполнить, и в итоге мы получаем такой поиск, который должен пройти некоторой целевой ситуации. Вот пример того, как распространяется активность на наших сетях. Это фрагмент на сети значениях из такого модельного примера «Мир кубиков», когда нам нужно составить некую башню или концепцию башни. Есть начальная ситуация, когда все кубики лежат внизу. Есть целевая ситуация, когда нам нужно составить башню. И вот пример того, как мы, например, генерируем некоторые действия, проверяем, что мы можем поставить один кубик на другой, мы распространяем активность по определенным правилам, которые я только что говорил, вот по вот этой сети. Грубо говоря, это в данном примере очень хорошо ложится на классическую парадигму стрип-спланирования, когда мы производим некоторые постановки вместо каких-то переменных константы в предикатные силы, как это в STRIPS обычно делается. Наш алгоритм планирования своей особенностью имеет то, что мы сохраняем прецеденты планирования. Используем не только оценку того, успешно или неуспешно мы завершили для того, чтобы куфункцию обновить, но и на самом деле сохраняем вот эти прецеденты в сеть на смыслах. То есть, грубо говоря, те операции, которые мы выполнили, мы можем обобщить ее до некоторого уровня и сказать, что вот у нас есть операция построить башню, И это новое действие, которое мы сохранили, то есть новое правило. После того, как мы из кубиков собрали некоторую башню, мы это действие можем сохранить и использовать как некий прецедент при более быстром планировании других операций, когда нам, например, несколько башен нужно составить. Тогда мы уже не будем планировать, как составлять конкретную башню, Будем использовать это уже как некоторое метадействие, как раз ту самую опцию, то есть действия на более верхнем уровне, которые реализуются операциями, которые мы уже знаем, как делать. Их не нужно искать. Процедура целеполагания – это один из ключевых моментов. Это одно из открытых исследований в нашем направлении. Мы одну из процедур целеполагания в процессе планирования описали. Когда у нас есть некоторые процедуры, точнее, прецеденты выполнения плана, Мы можем использовать эти прецеденты для генерации промежуточных подцелей. Мы можем использовать метадействия, которые приводят нас к выполнению нужных для достижения конечной ситуации подцелей. И считать это как новой целью, то есть для того, чтобы уточнить вот это метадействие в текущих условиях, то есть обновить некую стратегию на более низком уровне иерархии, мы ставим новую цель, которая является подцелью для достижения высокоуровневой цели. Естественно, что это ограниченный вариант целеполагания, но тем не менее он тоже в процедурах планирования важен и находит свое применение. Наверное, этот слайд я пропущу. Это про источники активности и про сеть на именах. То есть я сейчас говорил в основном про сеть на образах, значениях и смыслах, а также существует эта сеть на именах, которая может содержать в себе такую дополнительную информацию. То есть когда мы говорим про язык, естественный язык, то в каком-то смысле естественный язык вообще служит дополнительным инструментом не только хранения знаний, но и источником некоторого вывода, ограничения. Структура языка сама по себе задает некоторое семантическое поле, с помощью которого мы можем локализовать некоторые выводы. или подстановку индивидуальных переменных, когда мы хотим специфицировать какой-то сценарий. Источники активности – это на сети образов, это поступающие сенсорные сигналы, которые заставляют агента обновлять. И для сети вещеских смыслов – это некоторые внутренние потребности. Помните, я говорил, что есть внутренняя среда для агента, которая является генератором, во-первых, функции вознаграждения, которые обязательно нужно использовать, когда мы применяем обучение с подкреплением, и некоторые внутренние сенсоры, которые говорят о том, что есть, например, какие-то подробности типа голод или опасность или что-то в этом духе. Просить на именах я сейчас пропущу, но это тоже очень важная компонента, которая в робототехнике пока нами мало используется, но это один из направлений будущих исследований. Ну и про уровни представления. Если все это вместе собрать в кучу, то есть у нас есть некоторые компоненты знака, которые реализуются с помощью таких структур, как каузальные сети разного вида, у нас есть активности, генерируются некоторым образом, поступает сенсорная информация или генерируется некоторая потребность, они приводят к тому, что распространение активности все время поддерживается. Эта активность приводит к тому, что мы генерируем некоторый план и таким образом активируем некоторые компоненты знака, которые говорят о том, какие действия нам нужно выполнить и какая ситуация у нас будет в итоге. Кроме планирования, мы занимаемся еще моделированием рассуждений. Здесь вот тоже такой модельный пример на кубиках, сейчас не будем на нем останавливаться. Давайте поговорим про прикладные задачи, которыми мы занимаемся в нашем центре. Естественно, что практические задачи, когда мы говорим, что у нас есть конкретная задача, нам не нужно не все их сразу решать, то естественно, что нам нужно некоторое подмножество. всей той модели, которую мы разрабатываем в нашем центре. То есть, грубо говоря, когда мы хотим там некую роботехническую задачу решить, то нам необязательно, например, все три компонента знака использовать, вполне мы можем использовать только сенсорную моторную составляющую, использовать обучение с подкреплением и некоторую простенькую модель, не обязательно такую, которая будет прям в виде всех сценариев представляться. Но тем не менее, вот в общую концепцию мы всегда все наши задачи стараемся так или иначе подвести. Напомню, что мы работаем вот в этой концепции архитектуры STRL, то есть мы в нашем центре работаем и с интеллектуальным управлением, у нас есть коллеги, которые занимаются теорией управления, есть коллеги, которые занимаются планированием траекторий и задачей слама и компьютерного зрения для того, чтобы мы составляли некоторое промежуточное представление. И мы занимаемся, собственно, стратегическим умом, о котором я сейчас только что вам и говорил. Я сейчас перечислю несколько задач, которые мы выполняем в рамках проектов в нашем центре, и по некоторым у нас есть хорошие успехи, уже готовые инструментарии, какие-то у нас только в разработке находятся. Первая задача, на мой взгляд, очень важная и интересная, это так называемая задача VQA – Visual Question Answering. Это очень хороший пример того, как работает определенная система граунинга. У нас есть набор датасет изображений, у нас есть некоторые вопросы к этому датасету, и нам нужно ответить правильно на эти вопросы. Грубо говоря, у нас есть несколько объектов на сцене. Вопрос такой, какой формы красный объект, который находится слева от сферы? И нам нужно сгенерировать правильный ответ. Мы используем нашу концепцию структуры образной составляющей, то есть каузальной предикторной сети, для того чтобы сгенерировать сообщение на естественном языке, которое являлось бы ответом. Мы используем небольшую модификацию нашего представления. Мы вот эту прецедентную информацию в каузальном тензоре кодируем так называемым распределенным представлением, то есть Sparse Representation, который и в HTM в том числе используется. но мы используем так называемый VCA, вектор символик. В данном случае мы используем упрощенную версию HTM-представления. Такие высокоразмерные вектора, от 1000 размерность которых. И с помощью них мы можем реализовывать некоторые логические рассуждения, то есть с помощью операции байнинга-банлинга на этих векторах мы можем моделировать простые этапы рассуждений, которые позволяют нам как раз ответить на некоторый вопрос, то есть провести некоторый логический вывод, какой же объект какой формы находится слева от этой сферы. Классические решения во многом нерастевые. Например, для представления и кодирования эмбейдингов для предложений мы используем нерастевой подход в том числе. Частью такого нейро-решения, которое заменяет нам остальную архитектуру, мы используем нейросеть, которая кодирует смысл предложения. Сейчас в NLP очень хорошие трансформеры есть, которые очень хорошо работают. Еще один пример нейро-задачки – это так называемый minor L-challenge. обучение агента в среде Майнкрафт по достижению определенных целей. Очень важно, что здесь такой lifelong learning в каком-то смысле использовался, то есть нужно достичь итоговой цели, найти алмаз, но для этого нам нужно определенный по цели выполнить. собрать какой-то топор, нарубить деревья, чтобы построить печь и так далее. То есть на самом деле достаточно большую цепочку сделать. И естественно, что без каких-то подсказок текущий алгоритм ERL с этим совершенно не справляется. В прошлом году был такой челлендж на NIPS, который предлагал использовать экспертные данные. То есть у нас есть игроки, которые играли в эту игру, и давайте попробуем их использовать для того, чтобы обучить нашего агента. Мы заняли в этом соревновании первое место, мы предложили нашу архитектуру, в данном случае она более узкая, она касалась только генерации действий по некоторым представлениям. В качестве FP мы использовали нерастивые эмбеддинги, а в качестве генератора действий он у нас был иерархический, то есть мы двухуровневую иерархию здесь использовали. И здесь мы смогли продемонстрировать очень хорошее решение. В итоге наше решение смогло добыть алмаз. Единственное из всех решений, которые были на этом соревновании. Соответственно, что-то ближе к робототехнике. Мы планируем пространственные перемещения. Вот здесь один из способов кодирования пространства с помощью знакового представления. Мы используем так называемую псевдофизическую логику, которую предложил Дмитрий Александрович Паскелов в 1980-х годах. Она в данном случае очень хорошо ложится на нашу знаковую интерпретацию. Мы кодируем некоторое пространство, разбиваем его на участки. У нас ерехическое представление, мы можем дискретизацию пространства динамически менять в нашем планировщике. И вот это пример сценарной сети, которая кодирует некоторое расположение объекта. То есть мы можем сказать, что объект находится близко от стола или слева от стола. И с помощью нашего планировщика, про который я вам рассказывал, мы можем кодировать перемещение агента. Например, из одной участка до другого участка. Эту же концепцию планировщика мы объединяли с обучением с подкреплением. У нас планировщик работал на верхнем уровне. в первом приближении, что все выполняется идеально, то есть мы процесс обучения действия отключали, а потом объединили его с простой реализацией одноуровневой иерархии, когда мы говорим, что у нас есть верхний уровень операции, который может раскладываться на операции, и эти операции нужно обновлять, то есть как раз тем самым иерархическим способом, про который я говорил, с помощью обучения с подкреплением. И это тоже у нас заработало и очень неплохие результаты показало. Еще очень важная задача, в которой мы занимаемся, это навигация до объектов. Вот здесь вот наша архитектура, которую разрабатываем мы в нашем центре, здесь у нас много модулей, которые работают с помощью нейронных сетей, то есть решают конкретные задачи, которые ускоряют нам в целом процесс. сама задача заключается в том, что мы, имея РГБД-камеру, на мобильном роботе должны исследовать пространство таким образом, чтобы подъехать к конкретному объекту, который мы задаем. Например, мы даем команду подъехать к столу, и агент должен построить автоматическую карту с помощью только одной видеокамеры и доехать до этого объекта. То есть мы одновременно здесь решаем задачу и картирования, и локализации, и определения позы, и генерации некоторых по цели, чтобы быстрее исследовать среду, и инстант сегментацию, чтобы выделять конкретные объекты. То есть это, на мой взгляд, тоже одно из классных, хороших примеров того, как можно решать более узкую задачу привязки символов. Вот пример задачи. Тут у меня, видите, название слайдов переплыл. То есть навигация до объекта – это предыдущий слайд, а вот этот слайд – это распределение ролей. Я очень говорил, что важно нам использовать несколько агентов. Наш планировщик работает также в мультиагентной среде. При решении определенных задач, когда агенты обладают разной функциональностью, генерировать для них согласованные планы, которые говорят, что один агент выполняет один набор операций, другой другой, для достижения общей цели. Вот как здесь, когда один агент может разрушать препятствия, а другой нет, но мы можем, тем не менее, вместе их доводить до общей цели. Соответственно, в нашем центре мы работаем с роботами. Как я уже говорил, у нас есть набор мобильных маленьких роботов. Недавно прибыл в нашу лабораторию большой робот Хаски с хорошим манипулятором. Мы создаем свои собственные программные реализации того, что я вам рассказывал. Вот здесь пример нашего планировщика, который здесь реализован. Ну, наверное, все. Видео я уже показывать не буду. Спасибо за внимание, коллеги. 

S03 [01:15:28]  : Александр, большое спасибо вам. Очень интересно. Давайте перейдем к вопросам. Так, ну вот первый вопрос от Бориса Новикова. А цели задаются извне, человеком или и сам их формулирует? 

S01 [01:15:48]  : Ну смотрите, вот если мы говорим про общую концепцию, про которую я рассказывал из семиотического агента, то определенном уровне иерархии мы генерируем цели автоматически. Некоторая общая цель того, грубо говоря, цель жизни, тем не менее, все равно должна задаваться изначально. Сейчас у нас в нашей концепции семиотического агента нет возможности генерировать высокоуровневую цель. Мы реализуем концепцию goal generation только для нижних уровней иерархии. 

S03 [01:16:21]  : Спасибо. Вот вопрос от меня. На самом деле, так сказать, я здесь как-то в плохого парня сейчас буду играть, потому что я тоже всегда рассказываю про объяснимый ИИ. Вот и вот у вас на первом, по-моему, слайде или там, так сказать, на втором сразу же было определение, что искусственный интеллект по определению должен быть объяснимым, вот. А у нас, значит, периодически здесь на семинарах эта тема обсуждается, и был, значит, в частности такой тезис высказан, что объяснимый ИИ, например, он вообще бесполезный, потому что, на самом деле, нам искусственный интеллект нужен для того, чтобы бороться со сложностью, которую человек не может понять. Вот. А если искусственный интеллект может решать задачи в этих условиях, то не факт, что он может быть объяснимым для человека, например. Вот. Ну, и вообще, как бы, вот, является ли объяснимость вашей... Почему, с вашей точки зрения, объяснимость является необходимой? Вот. И можно ли действительно ее добиваться всегда? Или, может быть, в каких-то случаях она просто недостижима? 

S01 [01:17:24]  : Да, спасибо за вопрос. Я не знаю, почему плохого парня, но очень хороший вопрос. Во-первых, я хочу сказать, что я интерпретируемость говорил, что не обязательно для человека. Я говорил, что нам очень важно, чтобы наша система AGI работала в многоагентной среде, где работают подобные системы, и между ними есть некоторый канал коммуникации. Я говорю про интерпретируемость относительно этого канала коммуникации. Может быть, этот канал коммуникации куда более богатый, чем наш естественный язык может оказаться в итоге. Это первый момент. А второй, я на самом деле верю в человека. Я на самом деле не вижу ни одного примера какой-то задачи, в которой человек не может разобраться или которую он не может понять. Естественно, мы с вами должны отличать. Грубо говоря, анализ огромного массива терабайтов данных, где не нужно понимание, а нужно анализ. А есть понимание, собственно. Вывод некоторого закона, формулировка, обобщение, философский термин понимания. Я думаю, что человек все может понять, поэтому ему все можно объяснить. 

S03 [01:18:26]  : Спасибо. Вопрос Дмитрия Салихова. Зачем много агентов? Как это помогает обучению? 

S01 [01:18:35]  : В нашей концепции у нас есть такая структура, как сценарная сеть. Мы считаем, что именно сценарий – это некоторое обобщенное знание, распределенное между агентами. Вот этот уровень абстракции, который используется в этих сценариях он согласовывается среди агентов. Грубо говоря, коллектив помогает определить уровень абстракции, который необходимо сохранять и который еще будет полезен для того, чтобы ускорять планирование или выполнять некоторые действия агентов. 

S03 [01:19:13]  : Спасибо. Вот вопрос от меня теперь снова. Вы говорили про эмбодимент, да? Но можем ли мы считать эмбодиент агентом, телом которого является, например, поток банковских проводок? 

S01 [01:19:31]  : Принципиально я считаю, что должна быть среда. Это может быть в каком-то смысле тоже быть средой. Естественно симуляционная среда это тоже среда. Наши алгоритмы ERL, например, использовали и для оптимизации холодных звонков. В каком-то смысле можно сказать, что это просто один из типов задач, которые общая система AGI должна решать. Я говорю про embodiment. Это то, что среди всего того набора задач, которые должна решать система AGI, должно обязательно быть подмножество задач, связанных с реальной средой. Грубо говоря, если такого подможества задач не будет, мы не можем говорить, что это реальная система IGA. Я говорил про эмбодимент именно с этой точки зрения. Я не говорю, что обязательно должно быть взаимодействие с реальной внешней средой, но возможность в ней взаимодействовать обязательно должна быть. 

S03 [01:20:26]  : Спасибо. Вопрос от Виктора Сенкевича. Можно ли будет выложить потом PDF с презентацией? 

S01 [01:20:34]  : Да, конечно. 

S03 [01:20:34]  : Вот. Дальше вопрос от Владимира Смолина. Уровней принципиально три. Спрошу иначе. В каждом из трех уровней число под уровнем определено? 

S01 [01:20:46]  : У нас 3 это не уровни, а все-таки компоненты знания, компоненты знака. Количество уровней в каждом из них, в тех примерах, которые мы применяли, мы всегда фиксировали. Грубо говоря, у нас есть только пара работ, где мы генерировали структуру иерархии для действий. У нас была иерархическая система обучения с подкреплением, для которой мы генерировали автоматически вот эту структуру уровней. Но на самом деле это не очень общий подход, у нас пока не получилось его обобщить. В нашей концепции семиотического агента это в целом не задается некоторым параметром, но для задач, которые мы решали, у нас только одна задачка, где мы пробовали генерировать это количество уровней динамически. Но пока общего подхода для того, чтобы их можно было наращивать, скажем так, динамически во всех трех компонентах, к сожалению, пока нет. 

S03 [01:21:43]  : По поводу языка вопрос. Все время у вас фигурирует язык. А вот если агент один, то вообще ему нужен язык? Если он один, то с кем ему говорить? То есть у вас множество агентов и язык, на котором они говорят, это является как бы частью постановки задачи, что мы обязательно должны, так сказать, делать искусственный интеллект для работы в какой-то социальной среде. Вот. Или же все-таки наличие языка, оно является некоторым условием. Вот этого AGI, хотя бы внутреннего языка, хотя бы для того, чтобы он сам с собой разговаривал. 

S01 [01:22:18]  : Вот смотрите, если мы говорим про одного агента и не говорим, что он там работает в коллективе других агентов, то как бы странно требовать от него наличия внутреннего языка. Зачем ему делать некоторую вот эту структуру, грубо говоря, вот эти сценарии формировать? Если он в целом и так может это замыкание между сенсорикой и моторикой достаточно эффективно делать, ему этот уровень обобщения с определенной привязкой к каналу передачи сообщений не нужен. одному агенту. Естественно, возникает эта необходимость только в том случае, когда у нас есть несколько агентов. Мы можем сказать, что меру задачи, когда агент сам обучается, как в пинг-понге играть, как в «Атари» играх, обучается набирать очки, и другие агенты ему для этого не нужны. Но если мы опять-таки говорим про некоторую звезду, к которой мы стремимся, то есть про AGI, то мы обязательно должны его ограничивать. Грубо говоря, наличие других агентов – это его ограничения для того, чтобы он проводил определенный уровень абстракции и делал интерпретацию своих решений. Грубо говоря, если нет других агентов, нам не нужно выходить за рамки нейронной сети. Мы будем эту нейронную сеть наращивать, наращивать, наращивать, и в целом она как-то будет справляться с задачами. Нам не нужно из нее делать интерпретируемое решение, потому что нет других агентов, некому рассказывать об этом интерпретируемом решении. 

S03 [01:23:44]  : Можно тогда вопрос? Извиняюсь, если пытаюсь уже дискуссию строить. А если предположить, что вообще наличие среды и коммуникационной среды и тех, кому мы должны объяснять свои решения, изобретая для этого какой-то язык, Это, вообще говоря, является условием для того, чтобы действительно иметь возможность формировать структуры знаний, высокие уровни абстракции, и для того, чтобы действительно вот этот вот самый AGI возник. То есть, может быть, если у нас не будет с кем общаться и кому рассказывать свои знания на вот этом языке, У нас никогда и не возникнет возможности к абстрагированию, и мы не сможем вообще решать задачи в широком наборе свет, а мы будем всегда вот на уровне рефлексов. 

S01 [01:24:37]  : Все правильно, да. Я вот именно это и хотел сказать. Спасибо. 

S03 [01:24:43]  : Вопрос от Владимира Смолина. На каком уровне осуществляется локализация информации? 

S01 [01:24:51]  : Хороший вопрос. Глубо говоря, это тот уровень иерархии, где мы говорим о том, что у нас уже есть отдельный компонент и где есть знаки. На самом деле, в нашей модели мы этот уровень делали плавающим, динамическим. Например, мы это хорошо реализовывали в планировке пространственных действий, когда у нас была операция абстрагирования и конкретизации. Говорит, что у нас набор признаков, которые характеризуют пространственное соотношение объектов, не связывается с знаком, когда мы не рассматриваем этот кусок пространства как отдельную сущность. И для нас они просто служат как признаками для того, чтобы распознавать или оперировать с сущностями, которые больше масштаба занимают. И на самом деле для семиотического агента это должен быть динамический уровень. Грубо говоря, это динамический уровень рефлексии. Мы должны уметь означать вплоть до некоторых элементарных сенсорных актов. Опять-таки, если в какую-то там философскую парадигму проходить, то, грубо говоря, мы можем включить в список действий сознательных даже биение нашего сердца, грубо говоря. У человека, возможно, есть такая возможность. Это как раз вот этот динамический уровень того, где мы можем оперировать знаками. Он, естественно, должен быть динамический. 

S03 [01:26:21]  : Спасибо. От Евгения Витяева вопрос. Каким методом обнаруживаются причинно-следственные связи? 

S01 [01:26:29]  : Спасибо. Хороший вопрос. Пока мы это делаем вот с таким статистическим подходом, грубо говоря, вот у нас есть прецеденты в нашей клаузальной матрице, если у нас нету отрицательных примеров того, что такой набор свойств всегда следует за таким набором свойств, мы говорим, что есть причинно-следственная связь. Вообще, мы пробовали интегрировать в этот наш механизм, мы даже описывали такой в одной из наших статей алгоритм, по интеграции рассуждений в стиле DSM. Есть такой анализ формальных понятий, как некоторые частные случаи общей DSM-системы. Мы его интегрировали для того, чтобы выделять причинно-следственные связи на множды произношенных. 

S04 [01:27:15]  : А вероятности вы используете или не используете вероятностей? 

S01 [01:27:18]  : Сейчас мы используем вероятностный подход. DSM нам хорошо интегрировать не получилось. Там нет вероятности. В DSM нет вероятности? Да, там нет. Поэтому мы такой статистический подход, когда у нас эмпирическую вероятность подсчитываем. 

S04 [01:27:38]  : Но в этом случае вы могли бы использоваться некоторым нашим результатом, что наиболее точное обнаружение причинных связей, там некоторым специальным семантическим вероятно основным выводом нужно делать, причем так, чтобы предсказания были непротиворечивыми. Если бы с этим еще один вопрос, вы же предсказания делаете, а вот как в системе функциональных систем Олокина, вы эти предсказания проверяете непрерывного времени? чтобы проверять, что они не просто сделаны, но и вы как раз проверяете, что все ваши предсказания выполнены в процессе действия. 

S01 [01:28:12]  : Да, конечно. У нас, например, генерация внутреннего вознаграждения за достижение по цели, она как раз происходит тогда, когда мы проверяем соотношение выполненности. Я не зря говорил про акцептор результата. Это как раз та информация, которую мы сравниваем с поступающим потоком сенсорным для того, чтобы определить, генерируем мы отрицательный или положительный вознаграждение. 

S04 [01:28:36]  : Тогда я хотел бы вам выразить большую благодарность за ваш доклад. Математически много всяких новостей, но он основан на фундаментальных работах Леонтьева, Анохина и многих других, в частности знаковой системы. То есть, у вас не просто искусственный интеллект, у вас на самом деле антропоморфный искусственный интеллект. Это правильно? 

S01 [01:29:00]  : Это правильно, Евгений Евгеньевич. Мы с вами постоянно в таком или ином контакте находимся. Благодаря вам я и про модели вероятностного вывода с точки зрения интерпретации функциональных систем познакомился. В каком-то смысле ваши работы позволили нам к текущей системе прийти? Да, антропоморфный, конечно. Я с самого начала говорил о том, что мы придерживаемся мисциплинарного подхода, и я считаю, что человек и теории, которые описывают его, они должны служить некоторым базисом для построения теорий второго уровня, то есть математических моделей, старающихся это формализовать. 

S04 [01:29:50]  : Хорошо, спасибо большое. 

S03 [01:29:51]  : Евгений Евгеньевич, у вас еще вопрос был про откуда берутся каузальные сети, но я так понимаю он отвечен уже, да? Он отвечен, да. Так, еще есть вопрос от Бориса Новикова, значит я не совсем помню контекст. Критик, кто это и как он действует? 

S01 [01:30:07]  : Актор и критик – это достаточно стандартная парадигма в обучении с подкреплением. Критик – это часть архитектуры обучения. Вот как раз генерируем предсказания нашего вознаграждения и сравниваем с тем, какое вознаграждение получили. Если это расхождение достаточно большое, мы генерируем некоторую поправку для актера, который генерирует определенные последовательные действия. То есть, когда мы с точки зрения нейросетевого подхода, это на самом деле некоторая поправка в функцию потерь для актов. 

S03 [01:30:50]  : Спасибо. И еще вопрос от Бориса. Знак определяется для заданного сообщества агентов? 

S01 [01:31:00]  : Имя знака определяется для заданного сообщества агентов, структура значения согласуется для группы агентов, структура смысла и образа индивидуально для каждого агента. 

S03 [01:31:12]  : А тогда у меня вопрос тоже, так сказать, уточняющий. А если у нас есть среда распределенных агентов, да, они, наверное, это же среда агентов, в общем, распределенная, они как-то, наверное, по бродкасту общаются друг с другом, а как они вообще договариваются, что, так сказать, вот этот вот, что вот там, этот знак – это про строительство башни, а вот этот вот знак, там, допустим, про объезжание препятствия. Как вот они договариваются? 

S01 [01:31:38]  : Очень хороший вопрос. На самом деле, пока в наших работах есть такое направление, мы до сих пор до него не добрались, это так называемый лингвистический игр автоматов. Это как раз некоторая такая итеративная игровая схема того, как мы согласовываем названия для той или иной сущности. Несколько работ было 5 лет назад, где, грубо говоря, Агенты договаривались именовать определенный набор признаков. Это некоторая итеративная процедура. Ее можно формировать в виде некоторого протокола коммуникации и рассматривать с точки зрения теории. Но, к сожалению, в наших работах мы до реализации не добирались. Мы просто говорим, что это согласование среди агентов, оно некоторым таким правилам задается. 

S03 [01:32:32]  : То есть вы им даете словарь, грубо говоря, да? 

S01 [01:32:36]  : Да, мы даем словарь, имена сразу же всем известны, но свою структуру, сенсорную или акторную, они строят автоматически. Например, планировщиков, когда мы работали при разработке нашего планировщика, мы давали даже агентам фрагменты сценарной сети. Я рассказывал про то, что мы ее можем пополнять автоматически из текстов. Грубо говоря, если у нас прошла такая процедура, то мы можем эту базу знаний подгрузить агентам, и они используют уже ее согласованные варианты. Естественно, там уже все будет согласовано. правильно генерировать свою структуру смыслов и образов для того, чтобы составлять планы при работе с этой информацией. 

S03 [01:33:25]  : Спасибо. Вот ещё вопрос. Там вот в какой-то момент вы говорили про извлечение информации из текста. Вот. Я, честно говоря, не совсем понял. Там речь идёт просто уже не о роботах, а об извлечении информации из текстовых документов, так сказать, в рамках какого-то другого проекта? Или по тексту имеется в виду некоторый псевдотекст, что вот поток знаков — это некоторый такой Узловно говоря, текст, который описывает некоторый поток ситуации, событий, которые мы должны анализировать. 

S01 [01:33:57]  : И то, и то. Задача связана с планированием поведения роботов. У нас есть описание ситуации на так называемом переделье языке, у нас есть процедура граундинга, грубо говоря, по определенным правилам грамматики составленного описание ситуации мы генерируем структуру значений. С другой стороны, у нас есть проект, который называется Когнитивный ассистент для здоровья и сбережения. Там мы как раз используем разрабатываемые в течение 20 лет системы ассоциационно-реляционного анализа текстов для автоматического формирования этих сценариев. Это мы используем для того, чтобы формировать картину мира ассистента, который будет мотивировать своего пользователя выполнять определенные Ну, скажем так, зарядку там, например, или следить за своим здоровьем, правильно питаться. В общем, вот такую подсистему делаем для одного из наших заказчиков. 

S03 [01:35:01]  : Спасибо. Так, вот здесь вот много этих самых комментариев, что типа доклад супер. Большое спасибо спикеру, я пропускаю. Но передаю вам вопрос. Как сильно могут измениться условия, чтобы ранее описанные действия продолжали соответствовать с формированным ранее метадействием? Повторите еще раз, Антон. Как сильно могут изменяться условия, чтобы ранее описанные действия продолжали соответствовать сформированным ранее метадействиям? Это Владимир Смолин задал доклад. Владимир, может быть, уточните, если непонятно будет. 

S01 [01:35:38]  : Да, Владимир, попрошу уточнить, я не совсем понял вопрос. 

S03 [01:35:46]  : Владимир, вы нас слышите? 

S01 [01:35:48]  : То есть, может быть, это имеется в виду, насколько у нас есть метод действий, насколько операционный состав изменчив. 

S00 [01:35:53]  : Вообще, в целом... Меня слышно? Никак, микрофон выключил? Я слышно, да. Действия всегда немножко вариативные, и когда мы описываем действия, то мы описываем какое-то их подмножество, которое меняется от условий выполнения, от предметов, с которыми они осуществляются. Вот насколько эти метадействия определяют широтоохват этих описаний метадействий, тех действий, которые они определяют? 

S01 [01:36:22]  : Это хороший вопрос. У нас это моделируется структурой стратегии для каждого действия на определенном уровне. Естественно, что вариативность этого операционного состава у нас ограничивается тем набором действий, которые у нас есть на нижнем уровне иерархии. Как я уже говорил, у нас была попытка эту иерархию определять автоматически, то есть, грубо говоря, ограничивать область действия стратегии нижнего уровня, вот эту вариативность определять. Но, к сожалению, у нас только для узкой задачки получилось это сделать. В итоге получается, что на определенном нижнем уровне иерархии у нас набор действий, которые могут быть, проверка условий или эффектов, она все равно ограничена. Пока в тех экспериментах, которые мы делали, например, для MineRL, она у нас была ограничена. То есть вариативность ограничена. Я понимаю, что, наверное, для реальных биологических систем это тоже в каком-то смысле так и есть. Для реализации определенного моторного действия мы, естественно, можем выбирать только определенный набор поддействий. Но, наверное, он, скажем так, в стиле теории деятельности, строгие его рамки не должны определяться перечисления. Грубо говоря, условия и эффекты действия, то есть условия, в которых мы применяем, они, конечно, вариативны. Грубо говоря, у нас набор ситуаций, в которых мы можем определить можно выполнить это действие или нет, оно классом определяется. То есть это мы умеем. Но вот, грубо говоря, состав действия он все равно из какого-то граничного множества выбирается. То есть вариативность есть, но ограниченная. Вот так вот, если кратко. 

S03 [01:38:08]  : Спасибо. Вопрос от Бориса Новикова. Вы работаете с психологами и с философами? 

S01 [01:38:17]  : Наверное, только с психологами. У нас в команде именно когнитивные психологи. Я, если честно, плохо представляю, как работать с философами. С ними можно обсуждать, а не работать что-то. Работать с психологами мы как-то научились за эти 15 лет. Даже у нас есть совместные проекты с нейрофизиологами, правда, которые немножко других принципов придерживаются. С нейрофизиологами всегда очень сложно работать. Когда хочется какую-то модель им предложить, они всегда как-то отказываются от этого. А с философами мы можем только дискутировать. Я как-то выступал на таком семинаре по поводу… В МГУ есть хороший семинар по философским основаниям искусственного интеллекта. У нас была хорошая очень с ними дискуссия. Как ее использовать в работе, сложно сказать. 

S03 [01:39:14]  : Вопрос от Юрия Прокопчука. Что такое кошка в вашей модели? Кошка? Кошка в кавычках. Юрий Прокопчук где-то увидел кошку. 

S01 [01:39:29]  : Кошка, естественно, это знак в первую очередь. Для всех из нас с вами это знак, у которого есть имя «кошка», у которого есть определенный сенсорный образ у каждого из нас с вами, который включается в том числе и сенсорный образ самого слова «кошка». Есть некоторые сценарии, у меня с вами есть определенный согласованный набор этих сценариев. Мы кошку обычно гладим, кормим. Кошки улыбаются, когда она встречает нас дома. Но это правда про собаку больше, чем про кошку. Зачем мне нужна кошка? Для того, чтобы мне было не скучно вечером. У кого-то из вас другая цель, с которой вы кошку заводите. У кого-то причина, почему он завел кошку, это чтобы жена не ругалась, например. 

S00 [01:40:25]  : Разные могут быть причины. 

S01 [01:40:26]  : Вот это смысл этой кошки. Вот это и есть понятие о кошке. 

S03 [01:40:31]  : Спасибо. Так, здесь доклад супер. Спасибо, очень хороший доклад. И вопрос от Бориса Новикова. Могут ли промежуточные цели ИИ обесценить для человека достижение конечной цели? Проблема контекста. 

S01 [01:40:49]  : Сложно, я вот не совсем понимаю. На самом деле, мне кажется, что значит могут обесценить? Я, если честно, не совсем понимаю. Мне кажется, не стоит видеть угрозу в этом смысле. Я расцениваю с точки зрения исследования, я вот такими этическими аспектами как-то не сдаюсь. Не знаю, может, это не про этические аспекты, а про что-то другое. 

S03 [01:41:16]  : Борис, поясните, пожалуйста. У нас не получается. Борис, мы вас не слышим. Борис, мы что-то странное слышим. Ну да, что-то странное. Борис, не получается. Так, давайте я по вопросу Бориса задам. По поводу объясненности. Разве человек всегда может объяснить свои действия? 

S01 [01:41:45]  : Например, игрок в теннис. Ну, в целом, я думаю, нужно разделять. 

S03 [01:42:00]  : Борис, от вас что-то очень странное звучит. Борис, у нас какие-то очень странные звуки выходят. Можно попробовать отключить инудитизм. Ага. Так, да-да, значит, еще раз вопрос. Так, вопрос повторяю. Да, значит, по поводу объяснимости. Разве человек всегда может объяснить свои действия, например, игрок в теннис? 

S01 [01:42:27]  : Ну, смотрите, надо отделить потенциальную возможность, что человек, такое существо может объяснить свои действия конкретным индивидуумом. Взять конкретного индивидуума, конкретного студента Васю, он вообще мало что может объяснить. А если мы скажем уже достаточно зрелого человека, который пожил, опыта набрался, он уже больше может объяснить. Это некоторый динамический такой уровень объяснения. В целом мы можем, наверное, взять достаточно человека с хорошим уровнем рефлексии, который хорошим образованием обладает. Естественно, что он большее количество своих действий может объяснить. Но я согласен, что мы можем выбрать достаточно определенный низкий уровень абстракции, грубо говоря, вот такие моторные действия, которые очень сложно поддаются определенному объяснению. Грубо говоря, мы отдергиваем, например, руку от горячего предмета, это чисто замыкание дуги рефлексивной. Но опять-таки я предполагаю, что… В целом, наверное, можно натренировать свои рефлексивные возможности, которые нам позволят даже при определенном уровне созерцательных возможностей такие действия объяснять. Возможно, можно сказать, что есть какой-то необъяснимый уровень, но опять-таки его очень сложно провести. Нельзя сказать, что эти можно объяснить, а эти нельзя. Это тот самый динамический уровень означивания, про который я говорил. В целом, наверное, есть какое-то дно, ниже которого мы не сможем ничего объяснить. Можно каких-нибудь буддийских монахов спросить, добрались они до этого дна или нет. Вот я не могу вам сказать утвердительно. Я просто оперирую тем, что это некий динамический уровень. Для определенного человека есть потолок. Он не может объяснить определенный набор действий. Ему не хватает возможностей саморефлексии. У кого-то этот порог ниже, у кого-то выше. Понятно, что здесь нужно говорить не про уровень абстракции, а в целом про некоторый набор объяснений причинно-следственной связи, которые мы наблюдаем. 

S03 [01:44:50]  : Вот по этому поводу Борис Новиков пишет. Проблема подсознательного поведения человека. Кора и мозжечок. 

S01 [01:44:58]  : Ну да, есть такое как бы разделение. Понятно, что когда малыш там рождается, у него есть определенные паттерны в мошечке. Конечно, они есть. И можно сказать, что они уж точно на знаковый уровень никогда не выводимы. А вот с точки зрения культурно-исторического подхода, все, что мы потом сворачиваем, интерьеризируем и так или иначе переводим из коры в мошечок, в целом когда-то в коре было. И потенциально в целом. Почему мы не можем это вытащить обратно? Это на самом деле такой дискуссионный вопрос, но я согласен, что навряд ли нужно придерживаться какой-то конкретной точки зрения. Хороший вопрос по поводу динамического уровня. Но я согласен, что для каждого индивидуума есть необъяснимые действия. С этим, я думаю, мы можем согласиться. 

S03 [01:45:50]  : Спасибо. Что думаете об AI safety? Как проблемы AI safety адресуются в ваших работах? 

S01 [01:46:01]  : Просто, если я не ошибаюсь, safety – это вообще такое широкое понятие. Оно такое и философское, и этическое с одной стороны, а с другой стороны есть и его прикладной аспект. Прикладной аспект мне очень понятен. Например, есть safety RL. То есть мы должны обучить нашего агента, особенно это в коллаборативных средах, должно учитываться для того, чтобы он выполнял свои действия таким образом, чтобы не навредить оператору. Например, конвейеры есть, когда происходит сборка каких-то деталей совместно человеком и манипулятором. И вот мы должны наложить ограничения на процесс обучения такой, чтобы этот манипулятор не задавил этого человека, грубо говоря. Вот это понятие сейфти я понимаю. Когда мы говорим про этический аспект, то есть в целом про то, что мы должны нашу систему искусственного интеллекта строить таким образом, чтобы она не навредила другому человеку, грубо говоря, при законах робототехники. В каком-то смысле это тоже ограничения на процесс построения и обучения, но их достаточно сложно формализовать. Я понимаю AI safety, когда мы можем эти ограничения формализовать, таким образом можем использовать их в работах по построению нашей AI-системы. В целом они мне понятны. Но есть какие-то этические моменты, которые неформализуемы принципиально. В целом мы не сможем сказать, чтобы AI-система вела себя честно. Вот такое ограничение я не представляю пока на текущем уровне, как можно было бы ее задать, чтобы мы обучали свою систему, чтобы она была честной. 

S03 [01:47:43]  : Мне сложно что-то сказать. А вопрос от Бадулина Николая. Вы все работы делаете по заказу или есть инициативные работы? 

S01 [01:47:52]  : конечно, инициативные. То есть вот я говорил, что у нас есть в нашем центре проект РНФ РФФИ, это все принципиально инициативные, фундаментальные проекты. Часть прикладных работ в области робототехники мы делаем по заказу. 

S03 [01:48:08]  : Спасибо. Игорь Пиваров, у вас вопрос. 

S02 [01:48:12]  : Добрый вечер, просто не удержался, чтобы лично задать вопрос и лично сказать, что прям замечательный доклад, спасибо огромное, слушал с огромным удовольствием. Вопрос такой, а как вы решаете задачу Exploration vs Exploitation? то есть исследование мира против уже исследования по закрепленным траекториям, в особенности учитывая, что в вашей архитектуре естественным образом какие-то наработанные траектории уже к знакам привязываются, то есть они в каком-то смысле уже получают некую жесткую привязку и агент соответственно будет ходить всегда по понятным траекториям и не будет уже не будет ничего нового пробовать. Как решаете. 

S01 [01:49:02]  : Я бы не сказал, что привязка к знакам – это строгое. Мы только что обсуждали динамический уровень. Знаки у нас все-таки на каком-то уровне появляются. Я очень хочу важный момент сказать. Грубо говоря, жесткая привязка и локализация на каком-то уровне происходят. На более низком уровне, когда мы, например, говорим про нерастевые стратегии для реализации действий, что особенно актуально для обучения с подкреплением, естественно, что там нет никакой жесткой привязки. Там мы вполне можем использовать классические методы случайного эксплорейшна, но это очевидный момент. Хороший, эффективный эксплорейшн – это выделение под цель. Очень хороший этот момент, связанный с различными моделями Curiosity, то есть такой любознательности. Это на самом деле общая задача выделения по цели. Агент в среде должен выделить по цели, достижения которых он будет назначать себе некоторое вознаграждение. Эти по цели мы можем выделять таким образом, чтобы более эффективно позволить агенту исследовать среду. То есть, грубо говоря, по цели попадать в те состояния, в которых он редко попадал, или в те состояния, которые он не может предсказать. Эта генерация по цели, мы про нее говорили. В нашей ФА, в генерации действий, мы отдельным пунктом выделили генерация по цели. Эта генерация по цели может осуществляться на основе внутреннего сигнала вознаграждения. Вот этот внутренний сигнал вознаграждения можно генерировать на основе каких-то отдельных модулей, например Curiosity модулей. На этом уровне здесь нет ничего фиксированного. 

S03 [01:50:57]  : Извиняюсь, был на мьюте. От Николая Бадулина. Наш стартап MechsBIOS управляет движением через Embedded Motor Control Systems и нам интересно по токам и углам предсказать выход из строя, например, редуктора или подшипника. Вам это интересно? 

S01 [01:51:16]  : Мне почему-то кажется, что это хорошо будет решаться классическими методами машинного обучения. Я не думаю, что это очень сложная задача. Я бы не сказал, что нам интересно было бы ей заниматься. Мне кажется, что это даже не исследовательская, а инженерная задача. Спасибо. 

S03 [01:51:38]  : от Егора Чурилова. Судя по докладу, данная архитектура работает с ситуациями относительно небольшого уровня обобщения 4D-объекта и поведения. Есть ли планы по расширению и применению метода в предметных областях более высокой размерности, где агент оперирует не объектами, а, например, категориями, не их обозначениями в машинах формальных логик, как существующие резонеры, именно как конструктами, полученными из обобщения собственного embodied-опыта? 

S01 [01:52:16]  : Таких задач мы еще не решали. Как я правильно понял вопрос? Чтобы наша задача требовала оперирования не какими-то низкоуровневыми абстрактными понятиями, привязанными к конкретным объектам действительности, а более сложными ситуациями или абстрактными понятиями, высокого уровня абстракции. Таких задач кроме когнитивного ассистента мы не занимались. В когнитивном ассистенте возникают знаки, которые последуют нам достаточно длинные сценарии и ситуации. Грубо говоря, ситуация болезни, или ситуация свадьбы, или ситуация покупки автомобиля. С такими ситуациями такого уровня абстракции мы работаем. с более высокого уровня абстракции мы задачами не работали. 

S03 [01:53:08]  : А можно вот тогда сразу вопрос, вот я не знаю смотрели вы мой доклад или нет, значит там который где-то летом был как раз по продолжительной ситуации, вот в вашем аппарате Как вы себе представляете с точки зрения той же самой казуальной аналитики моделирования на уровне семантики и на уровне графов знаний, которые вы используете? Как вы моделируете протяженное событие, исход которого нужно предсказывать, исходя из цепочки предшествующих событий, которые произошли в определенной последовательности? Как вы описываете это? 

S01 [01:53:48]  : Для нас то, что вы говорите, это некоторый обобщенный сценарий. Он может быть разветвленный сценарий, но для нас это сценарий. То есть у нас есть вот эта каузая сценарная сеть, которая использует этот сценарий и в процессе планирования, когда мы можем подбирать некоторые прецеденты или перебирать выполнимые метадействия, которые из себя представляют эти сценарии, мы используем эти сценарии. 

S03 [01:54:13]  : То есть у вас конструкты для описания этих сценариев есть, правильно? 

S01 [01:54:18]  : Вот это ключевое ядро этой сценарии нашей сети, которая значения моделирует. 

S03 [01:54:23]  : Спасибо. От Сечеркина Александра вопрос. Есть ли ваши наработки для МайнРЛ в свободном доступе? 

S01 [01:54:34]  : Да, мы вот эту нашу статью по нашей архитектуре сейчас опубликовали в журнале Cognitive System Research. Там есть ссылка на наш репозиторий, он в целом открыт, можно смотреть, пользоваться. Для тех, кто хочет в этом году поучаствовать в соревновании, мы всем выложили наше решение. Мы в этом году в нем не участвуем, но будем рады, если кто-то воспользуется, будет развивать этот наш подход. 

S03 [01:55:01]  : Какие видите следующие майлстоны на пути развития вашей архитектуры? 

S01 [01:55:07]  : Вот это хороший очень вопрос. На мой взгляд, у нас сейчас достаточно сильно проседает вот эта связка планирования рассуждений. То есть вот когда я говорил про задачу VQA, то мы сейчас ее реализуем для очень простого датасета. Это клевер называется, где у нас есть различные объекты определенной формы, это на самом деле генерируемый датасет. Есть намного более интересные датасеты, это так и называется VQA, где очень реалистичные изображения из реального мира с хорошими сложными вопросами. они требуют более сложных моделей рассуждений. У меня там был слайд, мы реализовывали четыре обобщенных процедуры рассуждения, которые моделируют индукцию и дедукцию. Но более сложных цепочек нам пока не получается составить. И это, на мой взгляд, следующий майлстон. Грубо говоря, это решение более сложных VQA задач. Следующий майлстоун – это моделирование рефлексивного поведения. Когда мы составляем план поведения нашего агента, Он использует некоторые фиксированные heuristics по выбору, по отсечению пространства поиска. Когда мы решаем задачу планирования, когда у нас различные варианты постановок переменных возникают на нашем сценарии. то агент использует фиксированную структуру знака эвристики. Есть знак эвристики, у которого есть определенная процедура, которая оперируется с получающимися сценариями. Эвристика фиксированная, она дана агенту изначально. знания того, что, грубо говоря, чувство закона бритва Акама, что не нужно плодить в сущности лишние меры, но понятно, что по идее это должен быть тоже обучаемый механизм. И вот на самом деле это процедура обучения на мета-знаниях, то есть когда мы говорим о том, что у нас есть такая-то процедура оперирования нашими знаниями в процессе построения плана. И вот следующий майлстоун был бы именно реализация таких процедур. Понятно, что их можно в архитектуре нашего асимметического агента реализовать текущими средствами, но требуется некоторая модификация. То есть, грубо говоря, мы должны посмотреть как связка сценарной сети и акторной сети в данном случае должна работать. И, наверное, третий майлстоун касается построения архитектуры управления. Я говорил о том, что мы на нашем мобильном роботе Husky сейчас строим архитектуру решения задач навигации до объекта. Следующий milestone – это будет выкладывание в общий доступ вот такой архитектуры управления, грубо говоря, такой фреймворк, который использует наш высокоуровневый планировщик, использует некоторые регуляторы для отработки низкоуровневых действий и наши модули слабого компьютерного зрения в общий доступ. Вот это следующий milestone, я бы так сказал. Два таких фундаментальных ресерча, а это такой более прикладной. 

S03 [01:58:33]  : Спасибо. Можно ли эту знаковую систему описать в виде языка и какова грамматика этого языка? 

S01 [01:58:42]  : Да, это хороший вопрос. Вообще, в целом, это на самом деле хороший вопрос, ответ на который бы показал, какая экспрессивная возможность нашего языка. Мы не делали в явном виде такую попытку. По сути, я для себя этот вопрос всегда задавал как надо создать язык программирования, для знаковой картины мира, грубо говоря. Таких попыток не было, но это очень интересный теоретический вопрос. Я его в Майлстоунах не добавил, наверное, с некоторой оплошностью, но вообще, грубо говоря, Те элементы архитектуры, которые у нас есть, нам достаточно языков общего назначения, чтобы их реализовывать. Я уверен, что как только мы перейдем к некоторому мелостону, который касается рефлексивного поведения, мы сразу натолкнемся на некоторые ограничения существующие. Тогда будет подзадача по разработке своей грамматики, своего языка. 

S03 [01:59:52]  : Спасибо. Извините, я не могу не удержаться от реплики для Дмитрия Салихова. Мы с ним как-то обсуждали вопрос разработки фреймворка для тестирования AGI. Я пытался высказать такую мысль, что на самом деле нам нужен язык. для выражения любых знаковых картин мира. И все тесты, самые разные тесты для всех возможных AGI можно писать на этом языке, описывая всевозможные ситуации. То есть нам не обязательно нужно для того, чтобы тестировать AGI, нам не нужны микрофоны, нам не нужны колонки, нам не нужны механические сенсоры, нам нужен просто знаковый язык. с помощью которого мы сможем описывать все возможные ситуации, в том числе, связанные там со зрением или там с осязанием. Ну, вот, так сказать, после того, ну, понятно, да? Следующий вопрос. 

S01 [02:00:42]  : Другое дело, что вот создать такой язык, это как бы, мне кажется, примерно то же самое, что и GI создать. 

S03 [02:00:48]  : Ну, вот благородная задача. От Бориса Новикова еще вопрос, парочка вопросов у нас еще осталось. Как у вас определяются границы применимости данной модели? 

S01 [02:01:02]  : В целом, мы нашу концепцию с точки зрения AGI рассматриваем. Мы бы хотели, чтобы эта архитектура, которую мы предлагаем и которую мы потом специализируем для решения конкретных задач, чтобы она была максимально широкой. Понятно, что те milestones, которые я назвал, они сейчас являются некоторыми препятствиями для того, чтобы мы реально широкий набор задач могли бы решать. Грубо говоря, не могу на этот вопрос ответить честно. От Бориса всегда такие сложные вопросы поступают. У меня такое ощущение, что он к философам тяготеет. 

S03 [02:01:42]  : Там уже прошло обсуждение ядерной войны, которую создаст искусственный интеллект или наоборот, которую он помешает создать. Вопрос от Дмитрия Салихова. Что не хватает в вашей архитектуре для полного АГИ? 

S01 [02:02:04]  : На мой взгляд, таких моментов можно много назвать, давайте я просто один назову. Когда мы говорим про моделирование потребностей, и с этим связано моделирование эмоций, Это всегда какие-то слова. И вот мы когда говорим, что у нас есть модель такой-то потребности или модель такой-то эмоции, они на самом деле вообще никаким образом не реализуют вот эту «кваля». Именно с точки зрения Танони, когда он говорит «кваля». Не знаю, как… Надеюсь, коллеги, которые на многих семинарах были, они примерно представляют, что это такое. Какими бы мы не оперировали символами, как бы мы не говорили, что у нас есть какие-то процедуры генерации активности, распространения на сети. Вот это схватить квали, вот это потребности, которые мы можем, корни ее искать где-нибудь там в ДНК. Вот это, наверное, ключевой момент, который нам не может позволить сказать, что эта система – это истинный джайв со всех точек зрения. Я это рассматриваю с точки зрения человека, который придерживается эмбодит-подхода, для которого очень важно совмещение процедур мышления и работы субстрата. Это связка с потребностной точкой зрения, то есть, грубо говоря, как нам в субстрате, например, в том же компьютере, который отличен от реального человека, реализовать эту потребность по-настоящему. 

S03 [02:03:37]  : Вот это вызов. А вот у меня тогда сразу встречный вопрос, а потом будет развитие этого вопроса от Владимира Смолина. Хорошо, мы говорим имбадит. Нам нужен имбадимент. А вот возьмем Стивена Хокинга, который общается исключительно с помощью языка с окружающим миром. Вот не можем ли мы с помощью универсального языка создать некоторый универсальный имбадимент? И в этом универсальном эмбадименте создать AGI. И вот, собственно, вопрос от Владимира. А теперь, как вы соотносите возможность создания универсального языка с необходимостью граундинга и эмбадимента? 

S01 [02:04:19]  : Я уже повторюсь, что мне кажется, что создание этого языка эквивалентно построению системы AGI. Я не могу сказать точно, что мы принципиально можем решить эту проблему. Исследования, которые мы ведем, мы на самом деле ведем не с точки зрения того, чтобы построить систему AGI, а ответить на вопрос, вообще принципиально ее можно построить или нет, где вот эти пределы. Тех инструментов, которые мы сейчас используем, которые мы разрабатываем, может быть принципиально невозможно такие инструменты создать, чтобы и такой язык построить, и собственную систему UGI. Поэтому, когда мы говорим про принципиальную возможность, я не могу на нее сказать утвердительно или отрицательно. Это открытый вопрос. 

S03 [02:05:04]  : Спасибо. Просят дать оценку, когда будет создан AGI с распределением вероятности. То есть, скажем так, распределение вероятности создания AGI по шкале времени. 

S01 [02:05:20]  : Это неблагодарные оценки, понимаете? Это распределение вероятности. Мы эту гауссиану или распределение студента можем как бы… Бессмысленно. Понимаете, в каком-то смысле этот научный прорыв вообще непредсказуем. Я думаю, что достаточно много сейчас усилий предпринимается. Очень многие люди думают по этому поводу. И я уверен, что если в ближайшие несколько лет мы существенного продвижения в этом вопросе не получим, то снова будет некоторое охлаждение. Все любят говорить про эти волны зимы искусственного интеллекта и так далее. Это естественный процесс. Нельзя все время напрягаться, напрягаться, напрягаться. Всегда какое-то расслабление наступает. И у нейронов, и у физических людей, и в коллективах это всегда так. Я думаю, что если в ближайшие, грубо говоря, в перспективе пяти лет мы существенного прорыва не получим, то будет снова охлаждение достаточно сильное и новая зима искусственного интеллекта. общего искусства. 

S03 [02:06:29]  : Александр, большое вам спасибо. Так, вот, ну и последний вопрос, да, значит, чтобы на позитивной ноте. Будет ли у AGI юмор? 

S01 [02:06:39]  : Конечно будет. 

S03 [02:06:42]  : Спасибо. Давайте поблагодарим Александра за прекрасный доклад. 

S01 [02:06:48]  : Коллеги, всем спасибо. Было очень приятно с вами сегодня провести вечер. Очень хорошие вопросы. Всем здоровья. 

S03 [02:06:56]  : Спасибо. Большое спасибо. До свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
