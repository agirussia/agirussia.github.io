## 15 октября 2020 - Антон Колонин - Структуры Данных и Языки для Общего Искусственного Интеллекта, часть 1 — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/2-1iinCBgsg/hqdefault.jpg)](https://youtu.be/2-1iinCBgsg)

Суммаризация семинара:

Семинар посвящён вопросам общего искусственного интеллекта (General AI), его языка и структурам данных. В центре внимания находятся когнитивные архитектуры и их способность к общению в рамках одной формализма. Обсуждается возможность построения универсального искусственного интеллекта с использованием различных кирпичиков (модулей), таких как нейросетки и системы типа NARS, Discovery или OpenCock.

Основные тематические блоки:

1. Общий искусственный интеллект и его язык:
   - Обсуждается вопрос о языке общения искусственного интеллекта с другими искусственными интеллектами и естественными.
   - Упоминается возможность общения модулей искусственного интеллекта друг с другом.
   - Подчеркивается важность понимания структуры памяти и сообщений между модулями.

2. Структуры данных для ОИИ:
   - Рассматривается вопрос об эффективных и универсальных структурах данных для создания систем общего искусственного интеллекта.
   - Обсуждаются структуры данных в контексте когнитивных архитектур.

3. Когнитивные архитектуры и их взаимодействие:
   - Внимание уделяется когнитивным архитектурам и их способности к общению в рамках одной формализма.
   - Упоминается необходимость понимания структуры памяти и сообщений между модулями.

4. Модели и сценарии:
   - Обсуждаются процессы и сценарии, связанные с искусственным интеллектом.
   - Поднимается вопрос о том, как модели искусственного интеллекта воздействуют на окружающий мир.

5. Оптимизация ресурсов и достижение целей:
   - Рассматривается задача оптимизации с точки зрения использования ресурсов и достижения целей.
   - Обсуждается возможность автоматического выбора оптимальных сценариев.

6. Сознание и подсознание:
   - Вопрос о сознании и подсознании рассматривается в контексте двухуровневой системы.
   - Подсознание описывается как подсистема, быстро реагирующая на стимулы и прогнозирующая действия сознания.

7. Антология и семантический граф:
   - Обсуждается понятие антологии и её роль в контексте формализма.
   - Вопрос о необходимости различных уровней в антологии поднимается.

8. Кирпичики и формализм:
   - Упоминается возможность построения универсального искусственного интеллекта из кирпичиков с единообразной архитектурой.
   - Обсуждается идея использования антологии для создания кирпичиков с единообразной структурой.

Итог:
Семинар затрагивает широкий спектр вопросов, связанных с общим искусственным интеллектом, его языком и структурами данных. Особое внимание уделяется когнитивным архитектурам и их способности к общению, а также вопросам сознания и оптимизации ресурсов. Дискуссия показывает сложность задачи создания универсального искусственного интеллекта и необходимость глубокого понимания всех аспектов, включая антологии и семантические графи.



S03 [00:00:32]  : Итак, давайте мы начнем. Сегодня модерацию мне будет помогать вести Игорь Пивоваров. И начну я с того, что То есть, вообще, целью этого доклада было, с одной стороны, как-то отреагировать на некоторые важные для меня вопросы, которые я услышал на предыдущих семинарах. И эти вопросы, прежде всего, касались того, что такое язык интеллекта искусственного общего, на котором говорит либо этот самый искусственный интеллект с другими искусственными интеллектами, а также естественными интеллектами, которые его окружают. А также... Аж, возможно, на этом языке различные модули этого искусственного интеллекта говорят друг с другом. И эти модули могут быть соединены в некоторую структуру вроде Society of Mind Марвина Минского или в виде архитектуры, которую рассказывал Сергей Шумский. Ну и кроме того, что когда мы говорим о языке, на котором общаются различные модули мы, Также говорим о том, что эти модули, наверное, могут иметь какую-то общую память или какие-то частные памяти, но между этими частными памятями может происходить какой-то обмен информацией. И вот какова структура этой памяти и какова структура сообщений, которые Так, извиняюсь, запись идет, да. И какова структура сообщений, которые пересылают эти модули друг к другу? Это, в общем, про структуры данных. И тоже важный вопрос, который обсуждался там на части семинаров и за пределами этих семинаров, это вот каковы именно эффективные и достаточно общие и универсальные структуры данных, которые могут быть использованы для создания систем общего или универсального искусственного интеллекта? Ну и по ходу дела тут же это все оказывается связано с так называемыми когнитивными архитектурами, которые тоже пришлось затронуть. Ну и по ходу мне захотелось тоже вот на некоторое понимание, которое по всем этим вопросам возникло, увязать со своими собственными разработками и с разработками моих коллег, которые я здесь тоже Я попытался представить. Причём в результате получилась достаточно большая история. Я студентам, когда я её рассказывал позапрошлой неделе в общей сложности, у меня получилось 4 часа всего. Но это было на английском. В полном объеме, естественно, это безумие пытаться это здесь рассказать. Видео я выложил на английском, желающие могут посмотреть. А здесь я буду это все пытаться делать максимально конспективно, перескакивая через вещи, которые могут быть здесь большинство очевидно. И буду делать паузы с тем, чтобы можно было бы где-то на каких-то важных смысловых блоках провести обсуждение. Ну и может получиться так, что на самом деле все не войдет в один семинар, и поэтому, значит, отдельно я воспользовался тем, что Максим Вишневский попросил свой доклад вынести, перенести на попозже, и в освободившийся слот я пока, так сказать, условно записал продолжение сегодняшнего доклада. Если вот половина примерно не войдет, то вторую половину можно будет заслушать. и обсудить через три недели. Итак, начнём с двух важных определений, чтобы понимать, не потому что я считаю, что эти определения правильные и призываю всех им следовать. Вот эти два определения, которые будут на этом и следующем слайде, они нужны для того, чтобы просто понимать, В каком мире я живу, то есть, каков мой базовый терминологический аппарат, соответственно, исходя из чего я делаю все свои построения и выводы. Итак, общий искусственный интеллект. И вообще общий интеллект, неважно, искусственно или естественно, определяется согласно некоторой синтезированной, синтези-синтетическому определению нескольких людей, значит, Бена Герцель и Эпи Ванга я знаю более 20 лет, я работал с ними. Соответственно, Бен Герцель определяет общий интеллект, как способность достигать сложных целей в сложных средах. Что такое сложная среда? Это среда, где много всяких факторов, где много разных трудностей и опасностей, которые надо преодолевать на пути своих целей. Их может быть больше или меньше, соответственно, среда будет более или менее сложная. Но и в этой среде могут быть тоже сложные цели. Сложные цели подразумевают, что цель может быть составная. Сначала мне нужно догнать зайца, а потом мне нужно его успеть съесть, прежде чем кто-то другой у меня этого зайца отберёт. И при этом мне еще нужно, догоняя зайца, чтобы съесть самому, мне нужно еще одновременно избежать того, чтобы кто-нибудь меня еще и поймал вдобавок и не съел более крупный. Соответственно, вот мы пытаемся достичь этих комплексных сложных целей в сложных средах. При этом пейванг добавляет к тому, что при этом мы должны иметь дело с ограниченными ресурсами. Ограниченные ресурсы подразумевают, что у меня ограниченное время жизни для того, чтобы оставить потомство. Соответственно, я должен вовремя обзавестись с детьми, иначе просто останусь без детей по ряду физиологических причин. Или я должен найти еду раньше, чем сдохну от голода. Тем более, я должен найти источник воды раньше, чем она у меня кончится. И для того, чтобы там совершить переход через пустыню, я должен идти по ночам, экономно расходуя ту маленькую бутылочку с водой, которую я набрал в предыдущем оазисе. Ну и Шейн Лэг, с которым, кстати, тоже мы работали вместе с Бённ Бёртселем в Вебмайнде 20 лет назад. Правда, я сам с Шейном не пересекался лично, поскольку уже тогда все начиналось удаленно. Шейнлег добавляет, что эти сложные среды могут быть разные. То есть, научившись, допустим, ходить, человек может взять, сесть в автомобиль и научиться водить автомобилем. А после того, как он научился автомобилям, в какой-то момент он может встать на доску и поехать по снегу. А потом он может взять в руки кайт и научиться на этой доске кататься по воде. Соответственно, общий интеллект подразумевает способность адаптироваться к самым различным средам. Ну и последний хвостик этого определения, он возник, я не помню точно, кто его предложил, по-моему, это был Альберт Ефимов на последней фокус-группе по EGI в Сбербанке в конце прошлого года. Он предложил уточнить, что все вот это вот все, оно осуществляется с минимизацией рисков. Тут с этим можно спорить, потому что я могу сказать, что минимизация рисков – это часть достигания сложных целей, то есть я должен как-то минимизировать потери ресурсов, должен максимизировать снижение вероятности достижения этих целей. Мне понравился этот хвостик, потому что он указывает на то, что вся эта задача общего интеллекта Она может рассматриваться как задача многопараметрической оптимизации. И чем больше параметров, тем на самом деле более общий интеллект. И чем меньше параметров, тем более этот общий интеллект является узким. И что здесь важно, это то, что в общем случае, с точки зрения следующего термина «сознание», про которое мы тоже будем сейчас говорить, наличие сознания, общего интеллекта в общем не является необходимым. И с этим соглашаются многие исследователи, включая Джорджа Шабаха, с которым мы регулярно пересекаемся на AGI-конференциях. И согласно положению о том, что общий интеллект не обязательно должен обладать сознанием, Говорит о том, что, к примеру, мы можем представить себе философского зомби, который в силу своей внутренней организации и когнитивной архитектуры способен будет построить космический корабль, прилететь на нем на Луну, рассчитав туда траекторию каким-то образом, не осознавая того, что он это делает. Там погулять по Луне, починить сломавшийся двигатель, отремонтировав сломавшийся двигатель при посадке. залететь, вернуться обратно на землю. И все это абсолютно в неосознанном состоянии, как, допустим, лунатики в состоянии бродить по улицам и по карнизам крыш, а люди в состоянии вести связанную речь и говорить какие-то слова. И это никак не связано с теми сновидениями, которые они видят, так сказать, осознанно. То есть, человек утром просыпается и говорит, что ему там снились горы, а жена ему рассказывает, что он во сне выкрикивал какие-то математические формулы. Итак, что же все-таки такое сознание, если оно нужно? для общего искусственного интеллекта. Моё положение такое, что я не уверен, что оно для общего искусственного интеллекта нужно, но я считаю, что с сознанием интеллект будет эффективнее, и почему, мы это увидим на следующих слайдах. Но вот сейчас давайте сфокусируемся на том, что такое сознание. Я думаю, что данное определение сознания не противоречит пониманию многих участников. И данная формулировка «сознание», она мною взята не с потолка, не из пальца, я ее сам не придумывал. Значит, она синтезирована из того, что я услышал от Евгения Евгеньевича Витяева, с которым мы последние годы достаточно плотно работаем вместе. И вторая часть этого определения, она исходит от другого уважаемого человека, с которым мне никогда не довелось работать. Но это вот человек, которого я очень уважаю, это Владимир Лефебра. И в одной из последних книжек Владимира Лефебра о том, что такое одушевленность, он оперирует такими понятиями, как сознание, одушевленность и наличие свободы воли, ну, в каком-то смысле, значит, он их местами, они, как это называется по-английски, там звучат у него interchangeable. То есть, он под текстом, как я прочитал эту книгу, речь идет об одном и том же. Что в итоге мы определяем как сознание? Это способность строить модели окружающей среды на основе своего прошлого опыта. При этом эти модели являются предсказательными, потому что они позволяют предсказывать будущее сценарии развития тех ситуаций, в которых оказывается агент, обладающий сознанием. Это вот часть формулировки, как я ее услышал от Евгения Евгеньевича Витяева и переложил на свои слова. А вот следующая часть определения – это вот то, как я воспринял то, о чем пишет Владимир Ефебров. Это то, что мы мало того, что можем построить предсказательную модель среды, мало того, что мы можем на основе этой предсказательной модели среды строить сценарий будущего, мы еще и можем сознательно принимать решения для того, чтобы направить поток событий по тому сценарию, который нам нужен по каким-то причинам. Под «нужен» подразумевается, что в конце какого-то из этих сценариев лежит пресловутая комплексная цель, или в конце каждого сценария лежит некоторое количество достижимых целей, и мы задачей оптимизации смотрим, при каком сценарии мы потратим наименьшее количество ресурсов и достигнем наибольшее количество сложных целей. И после чего мы осознанно говорим, мы будем делать вот так, или мы не будем делать вот так, а будем делать как-то по-другому. И тут я уже сразу отвечаю на вопрос, который был у Николая Рябичевского. Попробую на него ответить. Вопрос Николая Рябичевского был в том, что, к примеру, когда он ведет машину, Как я услышал, Николай, вы меня можете потом поправить, что он делает это неосознанно. Но, тем не менее, это достаточно сложная функция. И, предваряя следующий слайд, где как раз про это будет все более подробно, я могу привести следующее рассуждение. Предположим, я первый раз вижу машину. И мне там мама или папа или инструктор рассказывают, что для того, чтобы поехать, нужно открыть дверь, сесть в машину, посмотреть в зеркало заднего вида, вставить ключ, нажать на педаль сцепления. Потом при нажатой педали сцепления перевести ручку в положение нейтраль. Потом, значит, начинать нажимать педаль газа и отжимать педаль сцепления, ну и так далее. Потом на первую передачу, как мы переключаемся, потом как мы разгоняемся. То есть нам рассказывают некоторую программу, и мы эту программу осознанно выполняем. Мы говорим себе, так, вот сейчас зеркало посмотреть, так, сейчас эту ногу, значит, левую ногу давлю, правую отпускаю. Потом, значит, начинаю давить левую, отпускать правую или там наоборот, я не помню. И когда мы вот эту вот программу, так сказать, символьную, написанную на некотором языке, в рамках некоторой онтологии движения на транспортном средстве, мы эту программу освоим, Мы можем прекрасно управлять автомобилем, мы можем садиться в машину, разговаривая по мобильному телефону, прижатому к голове плечом, зажимать, зажигать мотор, выжимать сцепление, давить на газ, отжимать, отпускать сцепление, трогаться и все другие дела. И ехать дальше по трассе, разговаривая по телефону или с друзьями в машине. И все это делается уже неосознанно. И вот с точки зрения вот этого определения, после того, как мы осознанно освоили какой-то навык, он, в принципе, уходит в сферу неосознанного действия. И мы можем осуществлять это действие подсознательно, а сфокусировать свое внимание на каких-то других вещах. Но при этом, предположим, мы вот едем по трассе, все хорошо, но вдруг за очередным поворотом справа на дорогу начинают выбегать дети толпой, с левой стороны на дорогу начинают выбегать бабушки толпой. значит, сверху начинают там сыпаться, например, гуси и садиться на дорогу, а навстречу, значит, по левой стороне едет, значит, автобус с ДПСниками, моргая сиреной, а по правой стороне мне в лоб, значит, едет, значит, машина скорой помощи, предвкушая, как она сейчас будет, значит, разбираться с последствиями ДТП. Вот. И, значит, конечно, если я еду очень быстро в этой ситуации, то я ничего не успею сделать, и что-то нехорошее произойдет. Но если я, как бы, эту ситуацию предвижу заранее, то я, опять-таки, включаю некоторую программу. Первым делом я говорю, значит, своим собеседникам в машине, там, ша. Или заткнитесь. Или я бросаю телефон на пол и смотрю в заднее стекло, чтобы понять, что если я начну тормозить резко, не въедет ли мне кто-то взад. Если там никого взаду нет, значит дальше я начинаю оттормаживаться. При этом оттормаживаясь, я фокусирую свое внимание на руле, чтобы меня не занесло. Это если, так сказать, я никогда в такой экстренной ситуации в жизни раньше не бывал. А если за рулем будет человек, который, допустим, месяц прошел курсы экстремального вождения, он в такой ситуации вполне может оттормозиться совершенно неосознанно. и при этом может сохранить возможность говорить по телефону с друзьями. Опять-таки, все зависит от того, насколько определенный навык или определенное действие или определенная когнитивная или поведенческая программа отработана агентом, значит, она может выполняться либо неосознанно на тех уровнях, которые они проходят через фокус нашего внимания, либо осознанно, когда мы анализируем ситуацию и и выполняем ту или иную программу действий, принимая решения на каждой строке, выполняя, грубо говоря, свое действие под дебаггером. И явно нажимая «next», «next», «next», «next», контролируя результат каждого выполнения в окошке с значением 2 ребенка. Ну вот, если это все окончательно гиперболизировать, предположим себе вот такую картинку, это некоторый сферический конь в вакууме, который лежит на поверхности Луны, и какая-то внешняя сила его пинает. И вот он поднимается в воздух, начинает лететь по гиперболической траектории, в какой-то момент он осознает, что если, согласно его предыдущему опыту, если он ничего не сделает, он упадет на землю, ему будет больно, а если он включит имеющийся у него антигравитационный двигатель, то он никуда не упадет, он улетит в космос и станет сферическим единорогом в вакууме, а не сферическим камнем. Но для этого нужно принять осознанное решение в момент Т. Другой пример, скажем так, из той области, с которой, наверное, многие мало здесь сталкивались, но, тем не менее, это реальный пример того, что называется lifelong reinforcement learning with global feedback. То есть, обучение в течение всей жизни. Этому можно научиться даже если, то есть, до тех пор, пока вы не страдаете деменцией. Сейчас, секундочку, включу full screen. 

S02 [00:19:02]  : Если физическая сила здесь совершенно не нужна, все, что здесь нужно – это координация и желание научиться. 

S03 [00:19:07]  : И вы можете это освоить, пока у вас голова работает. Значит, проблема здесь в чем? Что этому невозможно научиться, не глядя на того, кто это умеет, не просто вот в рамках «try and fail», потому что здесь, в принципе, отсутствует, что называется, локальное подкрепление или локальный фидбэк. Данное движение можно выучить только двумя способами. на самом деле, вариантами одного и того же способа. Способ первый. Имея большой опыт, либо большие физические знания о гидродинамике, движущейся по воде на скорости доски и аэродинамике, летящего под управление строп воздуха и кайта, вы можете составить программу. программу того, как данное движение вы можете выполнить успешно. Движение заключается в том, что вы едете в одну сторону, прыгаете в воздухе, там разворачиваетесь на 360 градусов, а приземлившись, едете уже в другую сторону. Значит, рассчитав эту программу, вы можете в режиме дебаггера эту программу исполнить. То есть, вы даете себе команду, допустим, оттолкнуться двумя ногами, потянуть правой рукой. После того, как вы зафиксировали, что эта команда исполнена, вы говорите себе, теперь я толкаюсь левой ногой и тяну двумя руками, ну и так далее. И при этом, если, допустим, на каком-то этапе исполнения этой программы что-то пошло не так, если что-то случилось хорошо, то никакого положительного подкрепления не будет, потому что это все происходит очень быстро. А если что-то пошло не так, то получается очень жесткое отрицательное подкрепление, которое может вообще отбить любое желание продолжать эти эксперименты дальше. Поэтому здесь очень важно избежать этих самых сбоев по ходу выполнения программы и всё-таки максимально чётко управлять её исполнением, чтобы достичь успешного завершения. А когда вы уже получаете успешное завершение, тут у вас уже случаются эндорфины, полное счастье, что вы остались живы и продемонстрировали свою ловкость и умение. Это первый способ. Второй способ отличается тем, что вы эту программу не составляете, исходя из своего опыта и знания, и образования, а эту программу вам рассказывает инструктор, или вы ее читаете в книжке, или тот же самый инструктор на видео в Ютьюбе вам это все показывает и рассказывает по шагам, и медленно разжевывает за медленной съемки, когда куда тянуть и какой ногой толкаться. Ну и, значит, важным является то, что когда мы вот такую вот программу, неважно, значит, само трогание или с места в автомобиле с ручной коробкой, или, так сказать, выполнение вот этого трюка на кайте, когда мы это делаем, когда мы учимся этому, мы действуем сознательно. То есть, эта программа выполняется как последовательность поведенческих актов, проговариванием, того, что мы сейчас делаем это, мы сейчас делаем это. Вот. Это может быть визуализировано, да, то есть я могу себе представлять эту последовательность действия, я могу мысленно или вслух ее себе проговаривать. Вот. Но при этом я использую некоторый условный, скажем так, язык, который опирается на некоторую онтологию, на некоторый лексикон и некоторая грамматика. Причем язык – здесь понятие условное. Внизу вы можете, например, видеть, как эти слова могут быть записаны на языке предикатов, где истинность каждого из этих предикатов говорит о том, что данное действие производит. «Push right leg» означает, что в этот момент толкается левая нога, а «look right» означает, что в этот момент голова смотрит направо. И слова, они обязательно должны быть словами какого-то русского языка. Если, например, вы создаете робота, который должен будет делать тот же самый трюк, то у него вместо левой ноги может быть порт номер один, который включает один сервопривод, а вместо правой ноги у него может быть порт номер два, который включает другой сервопривод. Ну вот, здесь как раз иллюстрируется то, как может выглядеть процесс обучения, что мы получаем негативную поддержку на каждом этапе, где мы сделали что-то неправильно. А если когда мы все сделаем правильно, мы получаем положительный фидбэк. И вот, пожалуйста, пример того, что мы подразумеваем под онтологией, лексиконом и грамматикой. То есть, вот то, что мы видим сейчас на экране – это один из возможных сценариев поведения некоторого субъекта или агента, называемого спортсмен, в достаточно маленьком мире, то есть, что называется «small world». На самом деле, это недалеко от реальности, потому что есть такие люди, которые называются дауншифтеры, которые сдают квартиру своих родителей в Москве, а сами живут где-нибудь во Вьетнаме или на Шри-Ланке, и ничего не делают, кроме как не учат новые трюки, которые здесь написаны. И вот все эти трюки, они описываются вот этой маленькой антологией, то есть это вот такой маленький мир, который описывает поведение этого человека. Там нет театров, там нет покорения снежных гор, там есть только правые-левые ноги, правые-левые руки и кручение головы направо и налево. В рамках этой маленькой онтологии можно составить там практически неограниченное количество различных трюков, которые вот эти люди составляют. И что важно при этом, это то, что после того, как вот один отдельный такой трюк, он собирается вместе, то после того, как человек успешно выполнит вот эту последовательность действий 100 или 200 раз, у него этот трюк уже делается на подсознании. Но после того, как каждый вот из подобных трюков начинает делаться на подсознании, человек уже может начинать делать связки. как фигуристы, да? Фигуристы, когда выполняют… или там сноубордисты, да? Если кто-то видел соревнования сноубордистов на трубе, человек, значит, с бешеной скоростью вращается в воздухе в разные стороны, держа себя за разные части тела и доски, а комментатор очень быстро проговаривает те элементы, которые этот сноубордист сделал. Так вот, каждый этот элемент, он вначале был выучен сноубордистом отдельно, а потом он ввязался в цепочку, и дальше программа, которую сноубордист или кайтсерфер выполняет на международных соревнованиях, программа уже составляется не из правых рук и левых рук, а составляется уже из названий элементов, там какой-нибудь сэндвич, там фронт ролл, бэк ролл, и вот они идут в определенной последовательности, и уже вот это вот более высокого уровня программа является когнитивной или поведенческой программой. Значит что, я не буду останавливаться на этой онтологии, я надеюсь, что все здесь всем понятно, что тут есть стрелочки, которые обозначают «is a relationship», например, «look», «pull», «push» и «bend» – это экземпляры сущности типа действия, а «left» и «right» – это экземпляры или наследники сущности типа direction. Дальше тут есть такие отношения, как аргументы, то есть время и субъект действия являются аргументами экшена, то есть у нас любой экшен привязан ко времени, вот идет пунктирная стрелочка, ну а дальше разные экшены связаны с различными типами сущностей. Лук связан с дирекшеном, пулл связан с рукой, push связан ногой и bend тоже связан с ногой. Ну и, соответственно, у нас есть антология, которая описывает этот маленький мир, есть лексикон, который, по сути, описывает namespace или пространство имен этой антологии. Тот лексикон, который мы используем, напоминаю, что вместо У нас может быть порт номер один, вместо right leg у нас может быть порт два, left hand – это порт три, а right hand или пол четыре, и это все может быть какими-то переменными. Дальше у нас есть определенная грамматика, то есть каким образом мы эти команды формируем для того, чтобы отдать себе или для того, чтобы сообщить их от инструктора, к примеру, ученику. Ну вот, например, в терминах БНФ мы можем сказать, что предикат, вот в том виде, в котором он написан ниже, он записывается как глагол или имя предиката, объект, и дальше adverb, где adverb – это просто используется для индикации времени, а объект – в качестве индикации того порта или того сервопривода, который нам нужно привести в действие. Ну и, соответственно, мы могли бы написать это все в другой нотации, то есть мы могли бы написать это на лиспе, и тогда бы семантика была другая. Открывающаяся скобочка, верб, потом пробел, потом объект, потом еще один пробел, потом отверб, потом закрывающаяся скобочка. У нас онтология та же самая, пространство имен то же самое, но грамматика у нас лисповская. Ну а здесь примеры того, как мы можем использовать разные онтологии и разные системы и способы соединения событий в рамках решения одной и той же задачи. В верхней строчке видно, что мы используем двухместные предикаты, и left leg, и right hand – это у нас отдельные сущности, или отдельные унарные предикаты. Во втором примере мы говорим, а у нас не будет отдельных унарных предикатов для каждой отдельной правой и левой ноги, мы будем говорить так, что у нас есть понятие правая, есть понятие нога. И на самом деле, что важно, что используем ли мы первую строчку или вторую, во многом определяется тем внешним миром, с которым мы имеем дело, или с той проекцией внешнего мира на те органы чувств, которые у нас есть. так сказать, каналы связи, через которые мы на этот мир можем воздействовать. То есть, к примеру, если у нас устройство, управляющее вот этим вот роботом, которому мы приделываем интеллект, имеет, допустим, там порты, значит, отдельные порты на каждую конечность, вот, то тогда будет верхняя строчка. А если управление этими конечностями определяется через порты left и right, и нога, и рука, и, так сказать, значением этих портов уже в итоге где-то там внутри, в железе, определяется, то ли дело идет о правой руке, то ли о левой ноге, вот так в этом случае будет вторая строчка. Тогда нам не нужны отдельные сущности right hand и left hand в онтологии, но тогда нам нужны трехместные предикаты. То есть, у нас аргументом предиката Пуш будет правая или левая, нога или рука, ну и, естественно, время. Причем обратим внимание, что в последовательность действий соединить эту программу в единую последовательность тоже можно несколькими способами. И это тоже зависит от онтологии, и от грамматики, и от некоторых принципов того, как мы эту онтологию и грамматику увязываем в последовательные программы. Первый способ на первых двух строчках – мы просто вводим понятие такого аргумента, как время, и вводим предиката greater. И если у нас первая тройка действий привязана к времени t2, а вторая тройка действий привязана к времени… если первая тройка к времени t1, вторая тройка к времени t2, то мы дополнительно можем сказать, что T2 больше, чем T1, а T3 больше, чем T2, а T4 больше, чем T3. Вот, соответственно, у нас выстроилась программа через те же самые предикаты. То же самое во второй строчке. А вот в третьей строчке мы занимаемся тем, что мы не вводим отдельного вообще предиката для обозначения последовательности, и вообще у нас нет такой сущности времени в антологии. Но зутан у нас есть такое замечательное отношение, как бифор. И с помощью предиката before и логических предикатов end мы можем строить на самом деле программы, используя так называемую higher order logic или higher order networks. То есть, high order говорит о том, что мы связываем не отдельные, так сказать, нольместные или унарные предикаты, а мы связываем иерархию предикатов. То есть, обратите внимание, во-первых, мы говорим, что есть некоторый набор предикатов push right leg, push left leg и push right hand, которые объединяются в некоторую единую сущность через конъюнктивный оператор end. или предикат end. И вот есть вторая группа. А дальше мы вот эти две группы end объединяем бинарным предикатом before, который говорит, что вот сначала вот у нас вот это вот всё, а потом вот у нас вот это вот всё. А потом вот это вот всё то, что было после первого, оно становится тем, что оказывается перед последующим. Ну и так далее. И мы уже другим способом увязали это всё, значит, в одно и то же. Ну и как, значит, хорошо сказал Алексей Егоров, по-моему, в обсуждении, что, в общем, мы можем использовать бесконечное количество различных имён, namespaces для того, чтобы это всё описать, и мы можем использовать бесконечное количество грамматика для того, чтобы всё это описать, и мы можем разными способами увязывать их Вот другой пример того, как мы можем вольно поступать с теми структурами данных и языками, которыми мы можем это все описывать. Вверху представлено то, как мы описываем всю эту картину мира и действия в ней с помощью двухместных предикатов. А ниже описано то, как мы это делаем с помощью… причем, обращая внимание, в верхнем ряду у нас все двухместные предикаты, они именованные. То есть, на самом деле, верхняя часть, она может быть описана с помощью RDF-триплетов или храниться в Triple Store какой-нибудь, используя терминологию Semantic Web и любую приличную графовую базу данных. А вот нижняя часть, значит, я думаю, что отражает примерно то, как устроено все внутри системы Николая Робчевского. Он меня поправит, если это не так, немножко не так или совсем не так. Но вот если бы я делал то, как я понял то, что он делает, я бы сделал это примерно так. Я бы сказал, что у меня вообще нету типов и предикатов. С точки зрения графового базы данных, у меня нету типов связей. У меня все связи неименованные, граф у меня не размеченный. И все связи бинарные. И для того, чтобы сделать некоторое единое действие, я могу его группировать только через некоторые условные неименованные вершины, но эти вершины могут быть условно именованы как какие-то переменные. То есть для того, чтобы сделать действие push-write-lag в момент времени t1, я просто делаю предикаты, которые увязывают эти все элементы, аргументы с некоторой вершиной а. А если я хочу сделать push-left-clack в момент b, то то же самое, вот некоторая вершина b. Ну и, соответственно, у меня компактная запись из триплетов превращается в менее компактную запись из пар. Ну и для тех, кто знаком с революционной алгеброй и с нормализацией баз данных, станет легко понятно, что внизу мы имеем предельно нормализованное представление, а вверху мы имеем некоторое динормализованное представление. А если бы мы сделали бы эти предикаты трехместными, у нас еще более динормализованное представление было бы. Теперь давайте посмотрим, как мы ещё можем усложнить такое представление знаний о действиях в окружающем мире. Я сразу поясню, что здесь, вот в этом примере, присутствуют только действия. То есть, здесь отсутствует реакция, восприятие реальности с тем, чтобы мы как-то на эту реальность могли еще и реагировать. Это сделано исключительно для простоты, то есть, с точки зрения тех же самых предикатов мы можем описать те состояния, которые испытывает объект или субъект по ходу выполнения этой программы. Итак, в верхней строчке то, что записано, написано с точки зрения некоторой, скажем так, булевой логики, где мы либо обязательно тянем правую руку, либо мы ее обязательно не тянем. Если мы правой рукой планку не потянули, то все плохо. Причем плохо всегда. А если потянули, то все хорошо и тоже все хорошо всегда. А вот в нижние два варианта они допускают, что все эти «потянуть», «посмотреть», «надавить» имеют некоторую вероятностную природу. Например, если мы посмотрим на левую сторону, мы увидим, что данная запись подразумевает, что если мы правой рукой не потянем в этот момент, то всё стопудово будет плохо. А если мы не будем толкаться правой ногой, или не будем толкаться левой ногой, то плохо будет только в 30% случаях. А в 70% случаях будет хорошо. То есть, на самом деле, получается, что толкаться ногами тут как бы и не обязательно. А тут не обязательно рукой тянуть, а тут не обязательно направо смотреть. То есть, лучше, конечно, это делать, но, в принципе, может пронести и без этого. При этом это можно записывать двумя способами. Вот, например, в системе NARS, про которую будем говорить, если успеем сегодня, если нет, то уже в следующий раз. понятие пресловутой вероятности, оно как бы вынесено в отдельную категорию языка. То есть, предикат, он выписывается отдельно, а, собственно, вероятностная оценка или неаксиметическая оценка логической силы данного действия, она выносится в отдельную грамматическую структуру, которая не связана со структурой предиката. А вот в языке, значит, товарища Майкла Нилера, с которым мы как раз вот эту всю историю буквально на протяжении прошлой недели обсуждали в Фейсбуке, у него, значит, нет отдельного, у него, значит, язык премис называется, и в этом языке премис у него не предусмотрена отдельная вероятность. Он говорит, а если нужна вероятность, пусть вероятность будет частью предиката, а типа inference engine он уже разберется, где у вас там аргумент, имеющий смысл – время, а где аргумент, имеющий смысл – вероятность. Разные подходы бывают. Теперь перейдем к теме того, хотим ли мы использовать нормализованное представление или денормализованное представление. Вот как бы все пространство тех решений, которые мы можем принимать. С левой стороны у нас имеется схема, когда у нас просто простые неразмеченные связи. просто бинарные, нетипизированные предикаты. Кроме стрелочек и вершин у нас в базе данных вообще ничего нет. Это очень круто, очень гибко, не нужна вообще никакая онтология. Главное, чтобы мы одни и те же явления в окружающей реальности в разных случаях описывали, используя одни и те же принципы соединения этих стрелочек. Но есть одна проблема, что с точки зрения вычислительных ресурсов это очень неэффективно. Я в свое время писал подобную систему 25 лет назад. она прекрасно работала, можно было описать все, что угодно на свете, но когда начинало что-то работать, то компьютер просто вырубался, потому что нельзя было такой объем информации в таком виде переварить. И тех, кто занимается всерьез какими-то сложными системами на Трипл сторах, даже когда мы имеем дело с типизированными связями, то есть когда у нас не бинарные отношения, а тернарные, триплеты, знают, что если у нас начинается количество хопов при инференсе больше пяти или шести, то большинство систем известных начинают просто ложиться мрачно. С другой стороны, у нас по сути имеются доменные онтологии, которые очень легко могут быть реализованы не обязательно на графовой базе данных, а они реализованы могут быть в том числе на революционных базах данных, где у нас разные действия имеют разные типы, соответственно, для разных типов действий или для разных типов влияния окружающего мира у нас различные, значит, арности, различное количество аргументов, различные смыслы этих аргументов, где-то время есть, где-то времени нет, где-то у нас руки, где-то у нас там глаза, вот, соответственно, мы это можем хорошо разложить по табличкам в SQL на базе данных и хорошо оптимизировать, вот, но опять-таки, значит, если нужно что-то, так сказать, ввести какое-то новое знание или изменить существующее знание, научиться ездить на машине после того, как мы научились ездить на велосипеде, то у нас возникают большие проблемы. Нужно переколбашивать базу данных, переписывать весь код, который работает с исходными запросами, и все делается плохо. Ну и, наконец, в середине находится пространство решений, которое на самом деле широкое между Свобода маневра между правым и левым, она достаточно большая. Вот здесь находятся системы типа Cycle Duga Linata, которая возникла еще больше 20 лет назад. Freebase, про которую тоже дальше будем говорить, которая возникла где-то 15 лет назад. А там Space OpenCog, который тоже возник 15 лет назад. Эти системы предполагают следующее, что мы можем построить некоторую базовую онтологию, которая описывает некоторые фундаментальные понятия, фундаментальные предикаты, типа наследования, последования, слова. символ, знак, время, причинность, обусловленность, part of, part of speech. И вот с помощью вот этих базовых констрактов мы уже можем собирать и пересобирать на дету различные доменные онтологии. И большинство современных графовых систем знаний, они построены где-то как раз в середине вот этого диапазона. Теперь, предположим, мы хотим построить систему искусственного интеллекта вот на такой базе данных, где у нас все знания о существующем мире и все действия в рамках этого существующего мира описываются с помощью некоторых предикатов. На сегодняшний день мне известны три системы, которые делают это, скажем так, на промышленном или около промышленном масштабе. неаксиматическая логика Нарс и Ванга. Значит, сейчас ей занимается Патрик Хаммер, которого можно увидеть в фейсбуке. Вот я его только сегодня отмечал в нашей группе со ссылкой на айпишки вот этой одной на Аксиматик Резонинг Систем. Значит, система с открытым кодом, можно брать и пользоваться. Дальше, система Евгения Евгеньевича Витяева, с которой мы работаем, это Logical Prediction System Discovery, тоже на сайте Евгения Евгеньевича можно посмотреть много информации по этой системе. На данный момент код закрыт, но некоторые демки можно посмотреть в открытом коде. Ну и, наконец, система Ben-Gerza лесотоварищей, это Probabilistic Logic Network в OpenCog. Система NARS и PLN во многом похожи, потому что они обе используют понятие compound truth value и не хранят весь лог событий, который имеется в системе, и за счет этого там можно достичь некой экономии памяти. А система Евгения Чеветяева, она работает, оперирует со всем доступным ЭВИДОСом, значит получается несколько больший расход памяти, но зато получаются более точные и достоверные логические выводы. Ну и общим у этих систем является то, что существуют базовые четыре логические операции, которые в терминах той или иной вероятностной модели, которая принята в этой системе, осуществляют четыре вида ризнинга. Первая операция – это revision, когда множество последовательных повторяющихся событий укрепляют единую связь. То есть, если во всех медицинских записях плохое питание приводило к ослабленной иммунной системе, значит, мы делаем стопроцентный вывод, что плохое питание приводит к ослабленной иммунной системе. Дальше у нас deduction – это оптимизирующая логическая операция, которая позволяет цепочку событий связать, заменить в одну связь, и за счет этого мы можем быстрее делать логические выводы и принимать решения, а не делать вывод по всей цепочке возможных причин и следствий. Ну и, наконец, две логические операции, которые уже имеют скорее роль именно вероятностного моделирования при выборе альтернатив. Обе имеют слабую силу, это когда либо мы на основе общие исходные предпосылки у двух событий, делаем вывод, что эти события связаны, это индакш, индукция, либо абдукция, когда мы на основе общих предпосылок для некоторой конечной посылки делаем вывод о причинно-следственной связи между исходными предпосылками. Это абдукция, наименее надежная логическая операция. Ну и следующий слайд как раз показывает, что делают товарищи Пейванг с Патрик Хаммером и Бен Герцелем, с Алексеем Потаповым и командой в той ситуации, когда у нас есть большое количество различных фактов по одному и тому же поводу. Но разные факты и разные связи могут иметь различную подпитку с точки зрения evidence или с точки зрения своей доказательной силы. То есть, у нас могут быть события, которые являют большую связь, например, вот здесь следующий пример, что плохое питание в 9 случаях из 10 приводит к ослаблению иммунной системы, а ослабление иммунной системы в 90 случаях из 100 приводит к инфекции. Как бы вероятность, грубо говоря, условная вероятность, в том и в другом случае получается 90%. Но уверенность в том, что эта вероятность оценена достоверно, она разная. В первом случае 9 из 10, оценка надежности, оценки данной вероятности, она маленькая, соответственно, confidence is low, а во втором случае оценка достоверность в определении этой вероятности, она достаточно большая. Соответственно, если у нас низкая вероятность, она тоже может быть либо с высокой уверенностью, либо с низкой уверенностью. Ну и чтобы не было путаницы, вероятность – это не называется вероятностью, это называется силой логической связи, а confidence – это уверенность в этой логической связи. И сочетание силы и уверенности называется составная… compound truth value, не знаю, как на русский перевести. Ну вот, наверное, в этот момент уместно сделать короткую паузу, потому что дальше я перейду к когнитивным архитектурам. Если есть какие-то важные вопросы, то я готов на них ответить, прежде чем ехать дальше. 

S01 [00:47:45]  : Значит, Антон, тут в чате разгорелась целая уже дискуссия разная, и я бы сказал, что здесь там две или три ветки этой дискуссии. Первая часть была как раз про определение сознания. Это, конечно, очень правильный ход в начале доклада сдать определение сильному искусственному интеллекту и сознанию. Это гарантированные вопросы. Тут были комментарии от Болиса Новикова. 

S03 [00:48:21]  : Я предлагаю, можно у меня встречное предложение? Давайте комментарии оставим на потом, потому что иначе мы застрянем, если вы согласны. 

S01 [00:48:29]  : С одной стороны я согласен, с другой стороны Антон, но вы же делаете определение, правильно? И причем, на мой взгляд, весь остальной доклад в целом не связан с этими определениями. как бы не вытекает из них логически и можно было бы не делать но это мне так кажется но вот у меня как бы скорее вопрос такой по поводу вашего определения по сознанию а где там собственно сам субъект Вот в определении сознания, которое вы дали, способность строить модели предсказательные мира и действовать каким-то желаемым из них, Собственно, мне кажется, в сознании ключевым моментом является это отделение себя от мира. И не просто строить модель мира, а модель мира строится вокруг себя. Есть мир, а есть я. И без этого все модели бессмысленны. 

S03 [00:49:32]  : Игорь, я не буду с вами спорить. Как я уже сказал, определений может быть много хороших и разных. Я это определение здесь делаю для того, чтобы перейти к тому, чтобы сфокусироваться на внутреннем языке. которым мы используем. Если в антологии агента есть понятие «моя рука, моя нога, чужая рука, чужая нога», и он имеет способность отличать свою руку от чужой ноги, то это На самом деле, вот, значит, про этому поводу как раз есть хороший аппендикс книжки Лефебра «О одушевлённость», и он как раз проводит там границу между сознанием и самосознанием. То есть, если мы выделяем себя как единицу общества, то тогда мы обладаем, то тогда это является некоторым дополнительным качеством, которое мы называем самосознанием. В терминах того терминологического аппарата, которым я оперирую, сознание можно заменить, скажем так, способностью к контролируемому действию. И, соответственно, если у субъекта или у агента есть возможность сохранить внутри себя модели, Есть возможность накапливать информацию и строить эти модели. Как это выглядит с точки зрения когнитивной архитектуры, как раз будет дальше. И есть способность предсказывать будущее на основе того опыта, который он получил в недавнем прошлом и аппроксимировать, предсказывать возможные сценарии. И если он в состоянии принять решение, и выполнить по выполнению той или иной когнитивной программы, то вот в этом случае она обрадует сознанием. То есть, в каком-то смысле можно сказать, ну, собственно, не в каком-то смысле, а вот на следующем слайде это написано, что сознание – это способность управлять своей деятельностью как некоторой последовательностью инструкций, которая выполняется осознанно. 

S01 [00:51:39]  : Вот рабочее определение. Здесь, смотрите, у нас есть развилка. Я боюсь, что если мы сейчас пойдем в эту сторону, в сторону определения сознания, то мы, мы, мы... Я готов поспорить, Борис Новиков явно готов поспорить. И это правильно, это правильно. Это меняется темой доклада. Борис, Борис, но это, на самом деле, для этого доклада, в некотором смысле, как бы, в некотором смысле, автор... Чтобы снять спор. 

S00 [00:52:03]  : Это не определение. а толковый словарь, и тогда все становится понятно. Вот на этом языке есть такой толковый словарь. Этот толковый словарь не удовлетворяет требованиям к формальным определениям, и не надо. 

S01 [00:52:23]  : Давайте мы отдельно проведем на эту тему семинар и поговорим на тему того, что такое сознание с разных точек зрения, но не здесь. А здесь ограничимся конструктивным комментарием Антона, что это было нужно для того, чтобы дальнейшее описание вести. И вот в дальнейшем, мне кажется, здесь первым и, по-моему, таким у нас очень ключевым был вопрос как раз Бориса Новикова по поводу вот там, когда вы перешли, Антон, к антологиям, сейчас, где это, где это, где это, сейчас, секунду, по поводу что эта антология описывает модель ситуации, а не сам процесс. Вот, Борис, мне кажется, это прям ключевой вопрос. Вы его задайте голосом, пожалуйста. 

S00 [00:53:18]  : Значит, процесс очень сложный. Там есть ветер, волна, освещенность и бог знает что еще. Состояние организма. Сытый, голодный, сильный, слабый и так далее. Есть модель, где всего лишь рассматривается, что есть рука, две руки, две ноги и возможность или тянуть, или давить, и больше ничего. И вот тогда это антология, то есть словарь модели, а не описание самого процесса вот этого, как это называется, вайтсёрфинг или как он там называется, когда на парусе 

S03 [00:54:02]  : Отвечаю. Авторитетно заявляю, поскольку на видео и на фотографиях изображен я, что в данном процессе, можно называть его процессом, можно называть его скриптом, можно называть его сценарием, можно называть его некоторой бизнес-логикой, как это опять-таки недавно обсуждали. Так вот, здесь здоровье, ветер, волна, неважно. Реальность такова, что это как бы все на фоне. То есть, для того, чтобы сделать вот это, нужно только то, что описано на картинке. Остальное, оно может влиять, но оно не критично. Сейчас секундочку, я закончу ответ. Теперь по поводу процесса. Опять-таки, моим рабочим определением процесса, с которым можно соглашаться или не соглашаться, давайте рассматривать это как элемент толкового словаря, В моём понимании процесс – это последовательность некоторых состояний. Так вот, если у нас сначала есть состояние 1, потом состояние 2, потом состояние 3, потом состояние 4 – это всё процесс. которые увязаны, причем процесс в данном случае описывается не явно через значение переменных времени, а вот здесь процесс описывается явно через три связи типа before. 

S00 [00:55:29]  : – Совершенно верно, только это процесс в модели, а не в реальности. – Конечно. – В модели самые главные слова можно пренебречь. 

S03 [00:55:41]  : – Конечно. 

S00 [00:55:42]  : А дальше уже описывается, значит, внутри модели истинно ложно, а для модели правильно-неправильно. 

S03 [00:55:52]  : Ну, можно так сказать, да я не буду здесь спорить. 

S00 [00:55:55]  : Вот. И если вы ограничиваете модели, то мы можем работать в логике. Если мы хотим работать с реальностью, то мы должны оценивать модели по критерию практики. 

S03 [00:56:10]  : Согласен, согласен, да. То есть, если мы хотим, так сказать, то есть, я же специально беру упрощенный пример для того, чтобы, то есть, этот пример не для того, чтобы показать, значит, как в суде происходит в настоящем. Я просто хочу показать, что один и тот же процесс можно записать по-разному, в разных грамматиках, в разных терминах, в разных, значит, размерностях предикатов. 

S00 [00:56:34]  : Да, но не один процесс тот же процесс, а одну и ту же модель. Так реальность бесконечно сложна. Модель может быть простая, может быть сложна, но все равно проще реальность. 

S03 [00:56:52]  : Я предлагаю, по этому поводу, был мой семинар, значит, два месяца назад, где я как раз и рассказывал, в чем разница между процессом и сценарием. Вот в терминах того доклада, то, что вы называете моделью, это сценарий, в терминах, в моих терминах, а то, что вы называете процессом, это процесс в моих же терминах. Но это мы уже обсуждали, это другая тема. 

S01 [00:57:20]  : Антон, мне лично кажется, что этот вопрос ключевой. Я тоже понимаю, что это описание процесса, что это описание модели процесса. Из этого простого примера хорошо видно, что слова, которые мы используем, они тоже описывают не реальный мир, а некую нашу модель мира. Нога, волна. Это мир куда сложнее и разнообразнее. Вопрос Бориса Новикова разворачивается в два серьезных вопроса. Во-первых, можем ли мы говорить о сильном искусственном теле, об общем искусственном теле? о могущественном искусственном интеллекте, если он будет оперировать очень упрощенными моделями. В этом смысле, в этих антологиях, как их ни строй, они всегда будут очень упрощенными. И я не могу согласиться с вами, что здесь Бизнес-процесс описан правильно, потому что нажать ногой... Ну, я, например, на серфинге езжу или на сноуборде. Я прекрасно понимаю, что слово «нажать ногой» может в реальности расшифроваться тысячей разных способов и ощущений. И один комментарий такой. На самом деле, имеют ли эти онтологии вообще отношение к сильному искусственному интеллекту? напрашивающийся здесь вопрос я здесь пока вот все равно не вижу вот этого субъекта вы определили сознание как некий конструктивный для дальнейшего важный пункт но я здесь пока вообще всего этого не вижу здесь есть ну хорошее описание процесса а где здесь вот кто-то борис это задавал там написал где здесь цель но я думаю что вот речь шла именно тоже про это про то как где здесь тот кто действует 

S03 [00:59:30]  : Значит, на первый вопрос по поводу процессов и сценариев. Опять-таки, вот это все обсуждалось на семинаре два месяца назад. У меня есть эти слайды в конце этой презентации, и если мы до них дойдем, на них можно будет остановиться подробнее. На второй вопрос по поводу субъекта. Во-первых, несколько слайдов вперед, есть некоторая иллюстрация того, что такое субъект в терминах когнитивной архитектуры, и каким образом антологии сложные распадаются на более высокие. Мне кажется, что для того, чтобы про это говорить, нужно проехать дальше. 

S00 [01:00:14]  : Но про цель это уже субъект. Просто в определении говорилось, что мы работаем с целями. 

S03 [01:00:22]  : Игорь, мне кажется, что для того, чтобы на эти вопросы отвечать, нужно просто продвинуться дальше. 

S01 [01:00:28]  : Хорошо, давайте дальше. У нас есть еще вопрос от Александра Соколова. Вы стали на каком-то слайде говорить о знаниях. а в начальных определениях про это ничего не было сказано? 

S03 [01:00:40]  : Если бы я все пытался определения ввести, которые обсуждаются с Романом, то, я думаю, мы бы даже до сюда не дошли. Поэтому все вводить определения я осознанно не стал. Я предполагаю определение знания сейчас не трогать. Я могу что-то сказать, но я предлагаю не отвлекаться. 

S01 [01:01:04]  : Тут просто целое в чате буря обсуждения идет. Не имеет смысла все зачитывать, и здесь не столько вопросов, сколько народ комментирует ваши Давайте, мне тоже кажется, может быть мы зря отвлеклись на вопросы в этом месте. 

S03 [01:01:21]  : Нет, на самом деле нормально, важные какие-то вещи продвинулись, давайте пройдем тогда дальше. 

S01 [01:01:25]  : Единственное, что я хотел от себя, но как модератор сегодняшнего обсуждения, Антон, все-таки мы как бы это... Я понимаю, что мы же не студенты, поэтому вы меньше… Я бы не делал столько упора в какие-то технические вопросы, типа таким образом записать или другим образом записать. Ну, мы верим. Давайте тогда попробуем ускориться. 

S03 [01:01:49]  : Соответственно, если посмотреть на ту историю, про которую я сейчас говорю, с точки зрения, во-первых, Марвина Минского, и его понимание архитектуры, который написан в книжке Society of Mind, или того, что пишет Дэниел Кенниман про thinking fast and slow, можно произвести следующее рассуждение, что, с одной стороны, когда мы чему-то учимся, то мы хорошо и быстро обучаемся на маленьком наборе данных, но для того, чтобы принимать решение с этим маленьким набором данных, записанным в виде некоторых символьных представлений или в виде некоторых логических или поведенческих программ, мы не можем делать это достаточно быстро. И это как раз тот самый режим thinking, когда мы thinking slow, но в состоянии это с одной стороны объяснять другим, а с другой стороны в состоянии это воспринимать другим. То есть это вот уровень narrative stories и trans frames. и состояние пикчер-фрейм, то есть, пикчер-фрейм – это состояние, транс-фрейм – это событие или переход из состояния одного в другое, а narrative stories – это скрипты, процессы, сценарии или бизнес-логики, которые объединяют эти состояния и переходы. Это тот уровень, на котором мы оперируем некоторым условным языком в терминах некоторых условных антологий. И по мере того, как мы этими навыками обладеваем, в человеческом мозге способность оперировать в соответствующих обстановках или окружениях, она, как пояснили в группе сегодня Юрий и Олег, переходит в мозжечок, и дальше управление когнитивной поведенческой деятельностью осуществляется на ассоциативном или на подсознательном уровне, прозвучало слово «подсознание», то есть то, что происходит вне нашего сознания и вне управляемого или осознанного контроля нашей деятельностью под мысленным дебаггером. И здесь у нас происходит, что называется, thinking fast, то есть быстрое мышление, но если мы хотим научиться чему-то на этом уровне без явного символьного знания, которое нам сообщают учителя или инструктора, нам нужно набить себе очень много шишек, или для данной нейронной сети нам нужно дать очень много данных. Но тем не менее, если мы себе представим некоторую базовую когнитивную архитектуру, у которой наверху лежит некоторый семантический граф, который может исполняться, где может осуществляться логический вывод, а внизу у нас лежит нейронная сеть или некоторая совокупность нейронных сетей, мы имеем место с вертикальной нейросимвельной интеграцией. И если дальше попытаться сформулировать некоторый образ универсального агента или субъекта, который в состоянии оперировать в некотором мире с некоторой сложностью, я отвечаю на ваш вопрос, Игорь, по поводу того, где у нас универсальный интеллект. Я специально ввел рабочее определение общего искусственного интеллекта, где говорится о сложных средах, сложных целях и разных средах. Соответственно, если у нас среда очень несложная, цели не очень сложные, ресурсов очень много, вот, и мы, так сказать, научились, наш агент в состоянии это всё осваивать и жить в этом, существовать в этом мире, выживать в этом мире, то у нас получается достаточно узкий или не очень общий искусственный интеллект. Но чем богаче у нас среда, чем больше у нас элементов фонтологии внешнего мира, которые отражаются на наши органы чувств, тем сложнее эта среда становится и тем более общим интеллект нашего агента в итоге оказывается. Значит, если мы разберем так сказать, не воображаемую архитектуру этого агента, то мы можем увидеть следующие уровни хранения данных и некоторые базовые функциональные компоненты, которые с этими данными что-то оперируют. В основе вот этой модели лежит, в частности, теория функциональных систем в интерпретации Евгения Евгеньевича Витяева, описанная вот в ссылаемой ниже статье. То есть, первое, что у нас есть у агента в некотором графе предикатов, которые описываются с помощью тех структур, про которые мы будем говорить дальше, это то, что может называться базовыми ценностями. или тем, или наоборот базовые неценности, то есть это то, что мы хотим либо избежать, либо чего мы хотим добиться, и это может быть либо прошито в нас от рождения, так сказать, и быть элементом, так сказать, железной части нашей архитектуры, либо это могут быть некоторые исходные данные, которые, так сказать, некоторый супервайзер прошивает в наш биос, вот, и они, собственно, используются для принятия решений, для тех самых осознанных принятия решений, которые осуществляет наш агент. Дальше, если мы посмотрим вниз, значит, есть некоторый лог наблюдаемых событий или observed evidence, это история всего, что мы наблюдаем в этом мире, значит, аннотирована таймстемпами, например, мы в какой-то момент времени видим, наблюдаем войну, А дальше лог событий, по сути, запись тех действий, которые мы выполняем. То есть, если какое-то действие записывается в Direct Action Log, то оно транслируется в движение соответствующих акторов, которыми агент обладает, ну и в данном случае мы на войну можем реагировать, например, любовью или, например, другой войной. Ну и, наконец, на основе тех Входов, которые мы получаем, и выходов, которых мы получаем, и их истории, хранящихся в наших логах наблюдаемых событий и исполняемых действий, мы, собственно, храним некоторые модели мира. После чего у нас, так сказать, могут рассматриваться два механизма. Один, как называется, предиктор, который на основе наблюдаемых событий и, значит, Direct Detection, наверное, тут должна быть стрелочка, ее, к сожалению, нет. делает, строит модели окружающей реальности. И у нас есть также решатель или приниматель решений, который на основе построенных моделей, значит, берет, observe evidence, на основе того, что произошло недавно, значит, строит предсказания будущего, сопроставляет возможные сценарии развития будущего с теми базовыми ценностями, которыми данный момент обладает, ну и принимает решение, собственно, что мы делаем для того, чтобы в будущем максимально удовлетворить поставленную цель. Подробности здесь можно долго на эту тему этой картинки рассуждать, но я перейду дальше и приведу пример реализации, собственно, вот такой вот модели такого агента в упрощенном мире Игры Atari. Я думаю, все знают эту игру. На PC она называлась Arkanoid. Это одна из игр OpenGM. Задача заключается в том, чтобы, имея возможность либо держать ракетку на месте, либо двигать ракетку вправо, либо двигать ракетку влево, не давать шарику стукнуться о землю. если шарик отразился от ракетки то все хорошо он потом там еще наверху может разбивать всякие препятствия если шарик упал на землю то вам больно и вы проиграли данный раунд Ну и, собственно, дайвную реальность можно описать, на самом деле, двумя способами. Один способ – это как раз по поводу того, можем ли мы сложные модели мира описывать с помощью простых моделей. Можно описать это все с помощью бинарных предикатов. точнее, одноместных предикатов, где каждый пиксел на экране, который наблюдает агент значения наличия или отсутствия шара в соответствующем пикселе, это будет либо 0, либо 1. А можно упростить. И, соответственно, положение ракетки тоже. Положение ракетки мы можем дискретизовать самым конечным набором возможных положений ракетки. Если ракетка находится в каком-то месте, то значение соответствующего предиката будет единица, а во всех остальных – ноль. Но мы можем это дело упростить, мы можем свести это все, на самом деле, к некоторым функциям. Допустим, X – положение ракетки от момента времени, Y – положение меча от момента времени. Ну и, собственно, реализовав такого простого агента с помощью простого кода, который здесь можно посмотреть, мы можем достаточно быстро научить его решать эту задачу ситуационным методом, то есть вначале он ничего не знает о том, что наступает на вход, Делает случайные действия, получает либо отрицательную, либо положительную обратную связь, но со временем он научается, какие действия удовлетворяют за хардкорным у него целям. получение счастья и избегание неудовольствия, и, так сказать, он уже дальше никогда не ошибается. Кстати, я забыл сказать на предыдущем слайде, у нас есть еще такой элемент, интересный элемент, как компрессор, который отвечает за то, чтобы нам хватало ресурсов, да, и как раз вот то, на чем В частности, фокусируется в своих работах Артур Франц. То есть, чем занимается компрессор? Он может делать две интересные вещи. Во-первых, он может сжимать наши модели. То есть, например, если он обнаруживает, что один и тот же сценарий повторяется много-много-много раз и приводит либо к успеху, либо к неудаче, он может почистить память, заменить все эти экземпляры этих сценариев. элементарных на один обобщенный сценарий, и в этом виде это будет больше модель, чем реальность, чем некоторый процесс. То есть, в терминах моего предыдущего доклада он может на основе множества записей процессов построить некоторые абстрактные сценарии, обобщающие эти процессы. Но что очень интересно, вот этот компрессор, он также может дополнять систему базовых ценностей. То есть, если, например, у нас есть там на предыдущем слайде цель быть хэппи, то есть, если мы хотим всегда быть хэппи, мы можем в какой-то момент обнаружить, что для того, чтобы быть хэппи, нам нужно делать лав. И в какой-то момент компрессор может на самом деле просто поместить лав в разряд базовых ценностей сам, и тогда нам будет проще всегда принимать решения, нам нужно будет просчитывать свои действия только до того момента, когда мы делаем лав, и не дожидаться, предполагая, что дальше все будет хорошо. И это будет записано на уровне уже базовых ценностей. На самом деле, вот эту когнитивную модель агента можно еще дополнительно усложнять социальными взаимодействиями. То есть, у меня есть версия этого слайда в другом старом докладе и в нашей совместной с Евгением Евгеньевичем работе. Здесь я про это обсуждать не буду. Но, в общем, модель именно социальных взаимодействий, социального поведения, она может быть несколько усложненной моделью такой. Дальше мы перепрыгиваем через то, что такая многоуровневая архитектура может быть описана именно с точки зрения архитектуры более различных уровней абстракции и различных уровней детализации. То есть, если взять пример того, что Одну и ту же ногу на доске можно надавить большим количеством раз. Или то, что, как Марвин Винский пишет, что агент по строению башни состоит из агентов добывания кубика и укладывания кубика, агент добывания кубика состоит из агента на нахождение кубика и хватания кубика, а агент хватания кубика состоит из еще множества других агентов. У нас есть возможность построения различного числа иерархий, которые будут зависеть от той среды и тех взаимодействий, которые мы осуществляем. Мы можем строить на основе вот таких вот кирпичиков, где каждый кирпичик можно представить себе некоторым базовым агентом, который реализует ту логику, про которую я рассказывал перед этим, но на своем уровне. То есть, если мы занимаемся с распознаванием, допустим, фич какого-то животного, если мы хотим определять наличие хвоста, глаз и ушей, мы работаем, грубо говоря, с пикселами. И из пикселов у нас собираются уши, хвосты, шерсть и когти. А на следующем уровне У нас исходными фичами или предикатами являются уже целые уши, хвосты и когти, из которых мы собираем объектов, целых котов. То же самое с буквами. Из трюхов мы собираем буквы, из букв мы собираем слова и так далее. Ну и что важно, что здесь у нас, если мы говорим про архитектуру агента, у нас Идёт как поток сознания сверху вниз, так мы и управляем этим потоком снизу вверх, то есть мы управляем поведением тех агентов, которые должны осуществлять распознавание входящих сигналов. задавая им некоторые пресловутые базовые ценности. То есть, если мы хотим, допустим, выделять на фотографии котов, то мы программируем, даем указание агенту по выделению, объявляя фич, говорим ему, что нужно выделять уши и хвосты. А если мы хотим того же самого агента заставить выделять, допустим, автомобили, то мы должны дать ему в качестве базовых ценностей заложить ему выявление, допустим, колес и зеркал заднего вида. Ну и то же самое, такую же иерархию и взаимодействие различных агентов разного уровня и разной специализации мы можем представить при управлении действиями. То есть, на разных уровнях абстракции у нас могут быть агенты, которые пишут слова, которые рисуют котов, которые произносят эти слова. Значит, если мы возьмем отдельный когнитивный тракт, ответственный, допустим, за определенный вид активности, то восприятие и генерацию действий также можно разложить на различные уровни, где на каждом уровне у нас будет идти преобразование, скажем так, входной онтологии одного вида в выходную онтологию другого вида. Значит, поясню еще раз, что под онтологией Мы здесь подразумеваем, может быть, здесь термин не очень удачный, но все-таки, когда мы говорим о монтологии, мы говорим о некоторой математической сущности, мы говорим не о некотором, так сказать, дереве понятий или словаре и в некоторых отношениях, которые связаны между ними, а о некотором наборе переменных и области определения этих переменных и внутренних связей между значениями этих переменных, которые описывают эту реальность. То есть, допустим, если у нас есть агент, отвечающий за чтение символов, то у него на входе, допустим, при распознавании каждого символа, у него на входе 256 предикатов, отвечающих за наличие черного или белого цвета. А на выходе у него 23 тысячи предикатов, которые говорят о наличии того или другого символа. То есть, у нас идет преобразование сложности из одной формы в другую. Это происходит как при восприятии, так и при генерации действий. Значит, ну вот, к примеру, о том, что у нас при как восприятии действий, так и при генерации действий могут происходить взаимное, как это называется, граудинг, взаимная привязка этих самых предикатов, предикаты более высокого или более низкого, смотря с какой стороны мы посмотрим на это уровня, могут собираться из, скажем так, предикатов различных модальностей. То есть, например, на каком-то уровне мы собираем фичах цвета в рамках зрительного восприятия. Точно также различные частоты мы собираем в звуке на уровне аудиального восприятия, но потом на каком-то уровне у нас различные модальности начинают помогать друг другу. и глядя одновременно на идущего кота и читая табличку, висящую, которую мама держит над ним в руках, что это кот, и при этом мама говорит, что это кот, а кот еще и мяукает, у нас в результате вот такого перекрестного опыления различных модальностей возникает некоторый синтетический символ, синтетическое понимание ходящего и мяукающего кота. Ну и мы можем тоже сказать, что на каждом уровне у нас идет переход из одного пространства предикатов в другое пространство предикатов, из одной математической модели в другую математическую модель, из одной онтологии в другую онтологию. Здесь пример того, как мы можем смотреть на те же самые нейронные сети с этой позиции в рамках того, что я бы называл горизонтальную нейросимвольную интеграцию. То есть, если вертикальная нейросимвольная интеграция подразумевает, что у нас высокоабстрактное символьное представление мира строится поверх распределенного нейросетевого представления мира. Это значит, у нас была вертикальная интеграция. Здесь у нас горизонтальная интеграция. Если мы имеем некоторую нейронную сеть в виде неразмеченного графа, мы можем извлекать знания из этой нейронной сети и представлять их в виде размеченного графа. А получив эти знания в виде размеченного логико-вероятностного графа с левой стороны, мы их можем потом загружать обратно в новую нейронную сеть и продолжить ее тренировку с этого места, или мы можем извлечь знания из определенного представления системы, которая, допустим, натренирована распознавать котов, собак и лошадей. Извлекаем это знание, получаем некоторое логическое представление лошади, а потом загружаем это логическое представление лошади в свежую нейросеть и дальше доучиваем ее, причем еще вручную верифицируем, что понимание о том, что такое лошадь правильное, что если мы видим, что одним из атрибутов лошади является зеленая трава, то мы можем это знание на символьном уровне удалить, чтобы случайно корову не приняли за лошадь только потому, что корова стоит на зеленой траве. И вот такое очищенное знание в символьном или лингвистическом представлении мы можем загрузить в нейронную сеть и дальше рабо-доучивать эту нейронную сеть, допустим, специализировать ее для распознавания лошадей различного вида. То же самое мы можем сделать и с NLP. На эту тему у меня есть отдельный доклад. Я на это не буду останавливаться. Здесь я это все пропущу. Здесь, наверное, можно сделать еще одну паузу. Если есть какие-то вопросы, то можно либо перейти к дискуссию, а все остальное вынести на следующий семинар, либо после дискуссии, если останутся силы, продолжить. 

S01 [01:22:11]  : Отлично. Тут как раз уже тоже народ пишет, что уже от онтологии ушли куда-то дальше. 

S03 [01:22:19]  : Мы к ним и под к ним. Дальше в следующей части будет речь уже, собственно, о структурах представления эндкотентологии и о языках описания этих структур. Но это можно отложить на потом, а сейчас перейти к обсуждению. 

S01 [01:22:34]  : Так, ну давайте мы действительно вопросы Тут, честно, было очень много разных комментариев. Коллеги, давайте, если есть вопросы, вы напишите еще раз в чат, я тогда буду сейчас по очереди отдавать. А я хотел бы еще раз вернуться все-таки к вопросу по поводу модели, по поводу онтологии, которая как бы описывает модель процесса и вот связки с этим AGI. ну вот и игра Atari вот на которой слайчас это же как бы это нереальность это простая ну очень простая игрушка я сам кстати сейчас ее там программируют нашу модель шумским и там на самом деле не три действия даже не два действия а шесть они, хитрые ребята, они затруднились сильно, там каждое действие как бы задублировано, есть еще пустое действие, в общем там полный хаос, но неважно, это я так просто комментарий. Я к тому, что все-таки как, насколько ценно, насколько вообще, Антон, ценно оперирование антологиями для построения сильного искусственного интеллекта. Не кажется ли вам, что если мы оперируем этими антологиями как некоторыми понятиями, описывающими в лучшем случае модель реальности, в лучшем случае очень хорошую модель реальности, это всегда будет некое ограничение которые не некие костыли, которые как бы мы изначально накладываем на этот потенциально сильный общий искусственный интеллект. 

S03 [01:24:13]  : У меня есть три ответа на ваш вопрос, сейчас постараюсь их не забыть. Первый ответ на наш вопрос. У нас на семинаре, по-моему, Алексея Егорова обсуждался тезис того, что сильно искусственный интеллект невозможен, потому что у нас есть МФЦ-проблема, которую мы не можем решить. Как бы это математическое определение. Соответственно, все, что мы можем сделать, это использовать тот самый задачный подход, который развивает Евгений Евгеньевич и который он представлял на своем докладе. И про который, я надеюсь, будет рассказывать Дмитрий Иванович Свериденко через две недели. В терминах этого задачного подхода, как я его понимаю, опять-таки, Евгений Евгеньевич и Дмитрий Иванович могут по-разному понимать, поскольку они его авторы, но я это понимаю следующим образом. что в терминах задачного подхода сильный искусственный интеллект – это интеллект, который, получив на вход некоторую антологию в математическом значении этого слова, а не в значении этого слова, которое используют товарищи, которые запрограммируют RDF, UE или Semantic Web. То есть, получив антологию как некоторую математическую модель мира, как некоторое множество переменных, некоторое множество предикатов, которые имеют между собой иметь определенные отношения, и переменных, которые могут иметь определенное значение. Так вот, получив эту картину мира, И даже получив не эту картину мира, а получив некоторый поток сенсорной информации и возможность реагировать на этот поток сенсорной информации некоторыми моторными воздействиями, если агент в состоянии обучиться этому в одном, так сказать, в одной антологии, да, в кавычках, и потом ему дать возможность поместить его в совершенно другую новую среду, то он тоже может в этой новой среде обучиться уже в совсем других условиях. При этом, если эта новая среда будет в чем-то напоминать предыдущую среду, если какие-то паттерны событий и реакции на действия агента будут повторяться, то он этому научится быстрее. Так вот, чем больше таких сред агент может освоить, чем быстрее он будет адаптироваться к каждой новой среде, тем более общим его искусственный интеллект является. Это первый ответ на ваш вопрос. Второй ответ на ваш вопрос. Значит, нужно ли ему вот эти вот онтологии? Я не уверен. То есть, как я сказал опять-таки в самом начале, я допускаю, что философский зомби, не обладая ни сознанием, ни онтологией, ни способностью проговаривать самому себе команды, может быть, он может научиться строить космический корабль, долетать до Луны, терпеть там аварию, чинить значит двигатель не возвращаться на Землю обратно с пробами космического грунта. Может быть, не знаю. Но мне кажется, что те ситуации, где обучение происходит без глобального фидбэка, обучение возможно именно только за счет построения когнитивных программ и исполнения этих когнитивных программ осознанно под управлением дебаггера это раз и два способностью социальной коммуникации и и передачей вот этого бесценного опыта, да, вот если какой-то агент каким-то чудом догадался, значит, что нужно, значит, когда шар летит вправо, ракетку двигать вправо, да, вот если он освоил это знание, то он этим знанием драгоценным с помощью вот этих вот самых символов, да, так сказать, и знаков, так сказать, и грамматик, с помощью которых символы и знакы увязываются друг с другом, он в состоянии этим знанием, значит, поделиться со товарищами, и тем самым повыжать выживаемость социума. И вот здесь мы как раз подходим к теме коэволюции интеллекта, языка и социума. И с этой точки зрения, безусловно, представляется, что возможность оперирования своими действиями на символьном уровне в терминах каких-то онтологий, грамматик и словарей, оно позволяет как повысить выживаемость вида, так и ускорить обучение через коммуникацию как между внешними агентами, так и внутри тех агентов, которые описаны у товарища Минского. 

S01 [01:28:50]  : Окей, хорошо. Микола Рабчевского, да, был комментарий? 

S05 [01:29:00]  : Ну, у меня, в общем, есть, да, комментарии, причем сразу много. Во-первых, вот в части сознания. На мой взгляд, рациональный подход к этому делу выглядит таким образом. О сознании можно говорить только в том случае, когда есть разделение на сознание и подсознание. Но точно так же, как, скажем, говорить о левом и правом, можно только в том случае, если у нас есть билатеральная конструкция тела, а если мы возьмем морскую звезду с пятью лучами, то термин левый и правый теряют смысл в ней, непонятно, что это означает. Двухуровневая система, когда есть сознание, подсознание или надсознание, подсознание, выглядит логично и повсеместно используемо в природе, ну, у высших животных, как минимум. Таким образом, когда подсознание, представляет собой подсистему, которая быстро реагирует известным образом. Каким образом? Она после того, как получает верхний уровень, инициирует некое действие, она пытается угадать, что потребуется делать на следующем шаге. То есть подсознание пытается прогнозировать действия сознания, прогнозировать действия, инициируемые сознанием, и его выполнять, если такой прогноз имеется. Это позволяет сознанию играть роль тренера, вот того самого тренера, который тренирует невральные сети на больших данных. То есть данными в данном случае будут последовательности действий, которые диктуются сознанием. Их обобщение, мы видим, что когда подсознание видит, что есть высокая вероятность повторения какого-то действия, то он его делает, если нет другой команды от вышестоящего уровня. А вышестоящий уровень получает возможность отвлечься от мелочной опеки за действиями и, так сказать, выполнять то, что касается планирования действий с учетом назначения системы, общих целей и так далее. Второй момент – это по поводу онтологии и семантического графа. Похоже, что в данном случае под онтологией понималось нечто предопределенное и константное. Может быть, я не прав, тогда меня нужно поправить. 

S03 [01:32:45]  : Можно сразу Николая поправлю тогда? Да. Значит, смотрите. Опять-таки, если Евгений Евгеньевич здесь и слышит меня, может быть, он еще поправит мою поправку, как я понимаю онтологию в контексте всей этой истории. Под онтологией подразумевается модель того управляемого поведения, с которым сталкивается данный агент. Либо это агент, который существует в реальном мире, человек или робот. Либо это модуль некоторой многоагентной архитектуры. Допустим, агент Бринка Блок в составе агента Билта Тауэр. Каждый агент имеет некоторые сенсоры. некоторые моторы. То есть, допустим, у нас агент, то есть, если у нас агент для игры в Atari на квадрате, допустим, 10 на поле, допустим, 50 на 10, то у него есть антология, состоит из 500 предикатов, где каждый предикат соответствует некоторому пикселу. Их можно проявлять. То есть, будет 500, 1, 2, 3, 4, 5 и до 500 предикатов, которые будут соответствовать значению некоторого пиксела. И у него будет три предиката, один который будет обозначать связанными с актерами, где один предикат будет обозначать движение ракетки вправо, Другое – движение ракетки влево, а третье – стояние на месте. Это совокупность переменных и возможных действий на эти переменные. Там в одном из слайдов, дальше в презентации можно посмотреть, есть такая концепция reinforcement learning, которая описывает мир через флюенс. То есть, все возможное состояние мира описывается через множество состояний, где каждое состояние – это некоторое значение переменной, которое может меняться во времени. и имеет определенное число возможных значений, вот каждая такая state variable обозначает fluent. Так вот, собственно, совокупность флюентов, которые мы воспринимаем, и тех флюентов, которые являются нашими действиями в ответ на возможные стимулы, это по сути является антологией, то есть это чисто математическая абстракция. 

S05 [01:35:28]  : Спасибо, я понял. Ну вот в связи с этим, вся эта информация о том, что есть, скажем, три действия возможных и о том, что есть вот сколько-то возможных ответов на запрос о том, а где находится сейчас шарик? Оно может быть помещено в этот самый семантический граф, как его часть, которая определяет, так сказать, текущую вещь, текущую конструкцию робота, задачи, чего угодно. Второй момент, вот насчет семантического графа, и речь шла о том, что предикаты в той или иной степени соответствуют семантическому графу или могут быть представлены в нем. И тут есть два таких очень принципиальных момента. Во-первых, в тех случаях, когда граф имеет ребра, которые никак не помечены, в отличие от вершин, которые могут быть помечены именами сущности и другими вещами, он чем хорош? Существенную роль играют понятия аналогии. И мы можем искать на семантическом графе ситуации, похожие на аналогичные данным. И в этом случае речь идет о том, что мы сравниваем все возможные подграфы соответствующего размера в поисках идентичных, в смысле идентичных по структуре. В тех случаях, когда отношения являются метками у вершин, метками у ребер, мы теряем возможность использовать алгоритмы поиска идентичных подграфов, потому что структура графа перестает быть единственно ответственной за А в тех случаях, когда мы отношения делаем вершинами графов семантического, мы получаем возможность искать любые аналогии. Еще один момент. Вот в примерах, которые были приведены. Неявно описывалась ситуация, когда предикаты, которые описывают те или иные вещи, для того, чтобы составить цепочку действий, упорядочиваются, исходя из неких принципов, либо добавкой времени, сортировкой по времени и так далее. Но в принципе любая последовательность может быть представлена как набор отношений между парами соседних элементов. И похоже, что в данном случае именно этот подход используется, но он катастрофически прожорливые в смысле вычислительных ресурсов. Поэтому, скажем, в тех разработках, которые я делал, последовательности всегда хранятся именно как последовательности и не конструируются на лету каждый раз. Кроме того, вот в этих предикатах на самом деле глагол – это фактически функция с несколькими параметрами, а последовательность действий – это программа, которая заключается в выполнении этих функций или, как иногда их можно назвать, операторов. И самая простая и логичная запись, хотя не всегда понятная, наверное, заключается в том, чтобы использовать постфиксную запись, или то, что называется обратной польской записью, когда идет серия аргументов, а за ними идет имя функции. Скобок нет, это самая короткая запись. А количество аргументов определяется тем, что мы знаем для данной функции сколько она их требует для данного оператора. Единственное, что нам нужно знать, это возможность определить, какой элемент в цепочке символов в программе является оператором, а какой нет. И эта информация может быть спрятана в семантическом графе и легко оттуда достается. Ну вот, третий момент, если я не ошибаюсь в числе, касается использования вероятностных величин в обучении, в планировании и так далее. Дело в том, что есть абсолютно неизлечимая неприятность, связанная с вероятностями. А именно, если мы просто наблюдаем за окружающей средой и никак не действуем на неё, то мы можем определить хорошо статистические характеристики вероятности того или иного. Хотя это может требовать достаточно большого времени. Если мы начинаем воздействовать на среду, и смотреть, что из этого получается, то это искажает эти характеристики и становится непонятным, так сказать, насколько они полезны в этой ситуации. то время как бинарная ситуация, когда что-то может случиться или что-то не может случиться, она остается в общем достаточно стабильной. Причем вот эта ситуация, когда мы храним только информацию о том, может или не может что-то случиться, она в общем Еще и упрощает естественное вычисление, поскольку не нужно тянуть эти и думать, как нам оперировать с вероятностями, особенно когда там вот есть сила, доверительность и так далее. И при этом все работает. И я бы хотел еще сразу коснуться вопроса о том, вот Игоря Пивоварова затронутым, как отделить себя от среды. Если речь идет об активной системе, когда входная информация, есть отклик на команду сенсора, проверить, получить подклик, то когда мы чувствуем себя двумя сенсорами сразу или чувствуем только одним, они позволяют достаточно легко отделить себя от среды. И в этом смысле мне кажется, что система, которая способна обучаться и имеет достаточно количества сенсоров и является именно активной системой, она не должна иметь проблем в конструировании понятия «я» и «среда». Просто за счет того, что если она учится, пробуя делать то и то, и другое, и третье, просто имея набор тех элементарных действий, которые есть, и конструируя из них более сложные последовательности действий. То есть она может не называть это я или не я, но различать эти две ситуации она будет. и это и будет ответом на вопрос. 

S01 [01:45:22]  : Можно я прокомментирую? Я с этим не согласен, но предлагаю это не обсуждать. Последний пункт, он является автопиком для сегодняшнего доклада, он очень интересный, я с удовольствием его отдельно пообсуждаю. Антон, а вы, пожалуйста, по поводу первых трех выскажетесь. 

S03 [01:45:38]  : По поводу всего абсолютно, что сказал Николай, я полностью согласен, никаких возражений нет, по-моему, прекрасное дополнение к тому, что я сказал, по крайней мере для меня, в моей картине мира. Я бы только хотел прокомментировать немножечко про то, что Николай сказал, что одно дело, когда мы строим модели, не пытаясь воздействовать на окружающий мир, а другое дело, когда мы пытаемся еще и на эти модели воздействовать. Вот, с одной точки зрения, значит, мой комментарий начинается теперь. С одной точки зрения, если, значит, речь идет об обучении, допустим, тому, ну, как ходить, да, вот ребенок учится ходить, да, Ну, если он неправильно там двинул ногой, то он просто упал. Поэтому, если у нас ребенок... Вот у меня сын учился, когда учился ходить, мы всю комнату застелили матрасом мягким. Матрасами и одеялами. И вот он пытался как-то справиться с окружающим пространством. И очень быстро научился ходить. Потому что падать было не больно. Неприятно, но не больно. А вот если, например, мы пытаемся методом reinforcement learning научиться правильно собирать не ядовитые грибы, то тут, в общем, если один раз ты ядовитый гриб съел, то ты больше уже про это никогда не узнаешь, что ты его съел, потому что тебя уже не будет. Вот, и ты не сможешь исправить свою ошибку. И вот, собственно, одна из моих гипотез заключается в том, что как раз способность передать информацию о том, значит, что такое хорошо и что такое плохо, и в явном виде, в символьном виде, значит, выгружать знания из одних агентов, и загружать их в других агентов, это знание, во-первых, ускорило эволюцию человека как такового, во-вторых, стимулировало развитие языка, чтобы можно было более разнообразные и более сложные онтологии передавать с помощью знаковых систем. В-третьих, эта невозможность развивать сложные картины мира и обрабатывать сложную информацию, еще и оформлять ее в виде каких-то структурированных сообщений, это, в свою очередь, задействовало в эволюционном плане, простимулировало эволюцию по усилению тех зон мозга, которые за это отвечали. те виды, которые могли лучше сообщать, посылать более качественные, структурированные сообщения, удерживать более глубокие и широкие антологии относительно таких мозгов, они получили эволюционное преимущество над носителями других мозгов. И как раз это подсказывает, что скорее всего, не имея возможности передавать знания между агентами внешними или внутренними в системе, оно существенно ограничивает возможность системы по достижению того, что мы называем общеискусственным интеллектом. 

S05 [01:48:54]  : Коротенький комментарий к тому, что Антон сказал. Важность языка, в общем, не вызывает сомнений, но нужно иметь в виду, что, в общем, два момента. Во-первых, то, что передается языком оно, несомненно, имеет символную форму внутри. И второй момент. Альтернативой, которая была изначально, всегда имела место и имеет место не только у людей, а у животных тоже, является передача информации путем наблюдения за тем, что делают другие. А поскольку результат одинаковый, то это свидетельство того, что визуальная информация, не будучи формально языковой, она на самом деле тоже сводится к символьной, потому что И если нам говорят, что вот этот гриб ядовитый нельзя есть, или мы видим, что кто-то съел и умер, она, в общем, интерпретируется абсолютно одинаково. И научиться водить автомобиль, и это показано, кстати, инцидентами в Штатах, которые достаточно часто встречаются. когда дети уезжают на папином автомобиле, при том, что их никто не учил специально ездить и не рассказывал, как это делать. А просто они, наблюдая за тем, как происходит, повторяют эти действия. 

S03 [01:50:43]  : Нужно просто запретить законодательно машины с автоматом. Пусть все ездят на ручной коробке. 

S05 [01:50:51]  : Больше того, не только с автоматором решены, а запуск автомобиля, нажатие двигателя, нажатие на кнопочку. 

S01 [01:51:00]  : Так, коллеги, давайте мы сейчас пошли совсем в дискуссию. Значит, у нас есть два комментария. Антон, ну коротких только прямо. 

S03 [01:51:12]  : Во-первых, то, что сейчас изображено на экране, наблюдением не обучается. Я специально привел этот пример, что наблюдая за человеком, делающим этот трюк, этот трюк научиться делать невозможно. Это первое. И второе, многие вещи, на которые Николай указывал, они будут как раз в продолжении этой презентации через три недели. 

S01 [01:51:33]  : Все, я слушаю. Давайте так, у нас есть два вопроса. Борис Навиков там уже не один вопрос даже написал, но он был первым, кто по камере там сформулировал. И Юрий Бабуров. А дальше, может быть, мы... Дальше можно уже, если у нас будет время, еще к дискуссии прийти. Борис, давайте, вам слово. 

S00 [01:51:50]  : Вопрос такой. Если аутология естественного интеллекта, как мне представляется, надо различать деятельность культурную где есть со-знание, то есть совместное знание. Люди обмениваются своими знаниями через символы. И деятельность организма, которая, как правило, не сознательная. А в регулировании работы печени сознание, в общем-то, почти не контролируется. За очень редкими исключениями, когда мы лекарства принимаем. Поэтому надо различать, и для организма это чаще всего мы учимся подражанием, как и животных. А вот в культуре мы действительно имеем дело с символами. И отсюда все-таки желательно узнать мнение Антона, автора, о онтологии естественного интеллекта. антология агента величина постоянная или переменная? Если переменная, то как меняется? 

S03 [01:53:05]  : Ну, значит, я не буду говорить о том, о чём думает печень, и в каких терминах нервная система печени общается со спинным мозгом и мозжечком. Тут я не знаю. Может быть, там есть какая-то неявная онтология и какая-то система предикатов. Не буду утверждать. Но у естественного интеллекта, осознанного, А онтология, безусловно, есть, и она определяется вот тем знанием, той средой, в которых объект живет. Например, в онтологии эскимосов есть там 20 разных видов снега, различных видов по понятию для снега, но только одно для песка. А у бедуинов только одно понятие для снега, значит, и 20 различных видов песка. Но, так сказать, Если бедуин с сознанием о 20 видах песка и одном виде снега приедет в Мурманск и поживет там пару лет или станет оленеводом, то его онтология дополнится знанием о том, как выживать в условиях пурги, как ходить по насту, как ходить по пухляку. И это ответ на тот вопрос, является ли онтология переменной. Если мы берем антологию формальную с точки зрения тех графов, в которых мы ее можем записать, неважно, что ли это неразмеченные графы, как Николай предлагал, либо это размеченные графы, как в трипл-сторах все это хранится, мы просто добавляем ребра в этот граф. Вот, с вершинами. А если мы что-то забываем, потому что нам это в жизни не нужно, ну мы просто удаляем эти ребра и вершины из этого графа. 

S00 [01:54:45]  : И как изменение онтологии регулируется онтологией? Или чем-то другим? 

S03 [01:54:52]  : Вот это очень интересный вопрос. Я бы его, значит, либо не стал вообще обсуждать, потому что это выходит за рамки, либо обсуждил бы в следующий раз, но если очень коротко. Значит, в В принципе, я допускаю, что мы можем запрограммировать вот эти функции. То есть, на самом деле, в терминах той системы, которая здесь нарисована, мы полагаем, что компрессор, предиктор и десайдер работают с некоторым графом. А то, что этот граф имеет некоторую ту или иную онтологию, им, в общем, глубоко неведомо. Они работают с вершинными ребрами. И то, что они, значит, удаляя, перемещая там, значит, удаляя какое-то ребро или добавляя какое-то ребро, на самом деле меняют модель, да, но им это неведомо, они не знают, что это модель. Значит, эта модель, она может быть понята только тем, кто, так сказать, расковыряет, достанет этот граф, значит, и посмотрит, что у него внутри. И в этом смысле моя гипотеза заключается в том, что в принципе вот этот компрессор, преддиктор и десайдер, они могут быть захардкожены. запрограммированный, запрограммированный на каком-то языке программирования, там на C, на Assembler, на Python, вот, и работать с некоторыми универсальными графами. Это вот одна гипотеза. А вторая гипотеза, которая мне тоже нравится, вот, Более того, она экспериментально проверена. Заключалось в том, что мы в том числе функционал вот этого компрессора и предиктора и десайдера, вообще всего, чего угодно, можем тоже написать с помощью некоторой антологии, да, сказав, что вот у нас есть вершина типа переменной, у нас есть вершина типа функция, у нас есть там связь между вершиной и переменной, которая означает аргумент функции. И мы можем писать программы просто в виде графов, И, меняя этот граф, представляющий собой программы, мы будем менять логику любых процессов, которые исполняются этой системой, в том числе некоторых базовых методов, алгоритмов построения моделей, принятия решений и сжатия этих моделей для более компактного и эффективного представления. 

S01 [01:57:16]  : Все, коллеги, Борис, Борис, мы не успеваем, давайте мы сейчас, у нас есть еще вопрос от Юрия Бабурова, мы потом, после ответа на все вопросы, те, кому интересно, могут еще остаться и там закончить. Юрий, давайте, у вас там два вопроса. 

S04 [01:57:31]  : Значит, да, ну давайте вначале с маленького, с маленькой ремарки, значит, корреляция не равно каузации, поэтому не доверяйте вероятностным моделям, и любое появление невероятности воспринимайте в модели со скептицизмом. Почему это может быть не так, какая там вероятность, является анекдот про академика, который будет по четным академикам, а по нечетным рыбу ловить. Он одновременно не будет никогда и рыбу ловить, и академикам. Вот, хотя вероятность вроде бы 50%, 50% должно быть 25%, да? Вот, значит, поэтому, ну и теперь обобщим этот вопрос более глобально. Какие части опыта, знаний, действий, поведения агента мы не можем описать с помощью онтологии? Ну или может, можем, но не стоит этого делать. 

S03 [01:58:34]  : Смотрите, с моей точки зрения, опять-таки, онтология в данном случае имеет смысл не программирования на РДФ и ОВЛ, а имеет смысл математический. Это некоторая система предикатов. И формально я не вижу, почему мы не можем описать, допустим, всю матрицу возможных состояний доски или игрового поля с помощью предикатов, ответственных за наличие или отсутствие у него мяча. А если мы имеем дело с распознаванием сцен, допустим, мы хотим построить сцену распознавания образов, то мы просто на матрице, по которой идет восприятие, на каждый пиксел Этой матрице повесим три предиката, ответственных за насыщенность красного, зеленого или голубого по шкале от 0 до 1. тоже оценка. А дальше вопрос эффективности. То есть, если мы понимаем, что система, допустим, логического вывода типа NARS, где вот тут она у нас есть, у нас же есть система NARS, которая с предикатами работает. Вот система NARS, значит, где-то, по-моему, уже чуть ли не 5 лет назад, значит, Патрик Хаммер выкладывал пример, как NARS решает вот эту задачу Atari Breakdown, ровно в том виде, в котором ее DeepMind решил еще на 5 лет раньше, по-моему, лет 10 назад они ее решили. Нет, меньше. Ну, короче, после DeepMind, Иван Косотоварищ это сделали, но это очень жестко, то есть ресурс тратится немеренно. Соответственно, я могу предположить, что с точки зрения вертикальной нейросимвельной интеграции я допускаю, что какие-то низкоуровневые функции типа распознавания текстур шерсти или шкуры или дорожного покрытия лучше делать нейронными сетями. Мне кажется, что в рамках существующих вычтительных возможностей можно распознавание асфальта или пушистости шкуры делать на уровне нейронных сетей. А вот объединение, допустим, ушей и хвостов в кота, а колеса и зеркал в машину, мне кажется, делать уже правильнее с существующими вычислительными возможностями на уровне именно, скажем так, логикой вероятностных моделей, но не аксиматической логики. Тут не обязательно, хотя, Юрий, речь идет о вероятностях, вот ни одна из этих систем, которые тут показаны в чистом виде, не работает. Если строго говоря, сюда можно добавить еще системы, основанные на Баясовском вероятностном выводе, Но их здесь нету, потому что я просто с такими системами работал. А вот все эти три системы, ни одна из них не работает с вероятностью в чистом виде. У Евгения Евгеньевича система по определению работает с причинно-следственными связями. первый ответ на вопрос. Но все-таки цель данного доклада, вот забегая вперед в часть, которую, видимо, придется обсуждать в следующий раз, мы будем пытаться понять дальше, какой все-таки элементарный кирпичик можно взять для построения некоторого AGI светлым будущим с тем, чтобы любой уровень вот этой вот пресловутой когнитивной архитектуры был устроен одинаковым образом, и чтобы мы, грубо говоря, из одних и тех же типовых элементов собирали любой сложности когнитивной архитектуры, а не строили их по такому принципу, что вот наверху у нас там система NARS, да, или там система OpenCog PLN, А внизу у нас там GPT-3 или BERT, а между ними, значит, самое большое количество кривых и уродливых костылей, которые их как-то прибивают в другую руку. Вот как бы цель этого доклада – это именно попытаться, какие у нас могут быть унифицированные структуры, которые позволят единообразно строить когнитивную систему сверху до внизу. Может быть, это неправильный подход, может быть, тем более с точки зрения существующих моей вычислительных возможностей, Это одна из возможных ответов. 

S04 [02:03:00]  : Ну да, тут как раз нюанс в том и заключается, что в какой момент, какой бы мы кирпичик ни взяли, в какой момент это развалится. Чтобы понять это заранее, до того, как мы кучу потратим времени, строя из этих кирпичиков модели. Мне кажется, на этот вопрос важнее ответить. 

S03 [02:03:19]  : Да, но сейчас же по-разному пробуют. То есть, вот НАРС попробовали использовать сверху донизу. То есть, там вся иерархия предикатов, она описывается в терминах одних и тех же связей. Вот один пример. Другой пример, вы, наверное, знаете, есть статьи, где пытаются как раз с помощью некоторых костылей сбивать семантику распределёнными представлениями при выделении сущности из текста. Ну, вот другой пример. То есть, это вот как раз поле для экспериментов. 

S01 [02:03:55]  : Но на вопрос-то, Юрий, я так и не понял, Антон, ответа. Вот он спросил, а есть ли какие-то вещи, действия агента? Формально нет. 

S03 [02:04:07]  : Математически я не вижу, почему нет. В практике, имеющихся вычислительных возможностей, скорее всего, низкоуровневые операции лучше описывать с помощью существующих нейросетевых решений, а более высокоуровневые – с помощью нейронных сетей. Но это, опять-таки, зависит от вычислительных возможностей и от поставленной задачи. 

S01 [02:04:36]  : У меня там был комментарий, который вырос из того, что сказал Борис Новиков, про то, что есть ли онтология естественного интеллекта. И вот сейчас этот вопрос, Юрий, они у меня как бы так, они все в одну сторону. И я вот для себя сейчас понял, что лично я, видимо, в силу моих личного восприятия, у меня есть несколько пониманий слова «онтология». И в зависимости от того, в каком понимании слушать, Значит, вот этот доклад и то, что вы говорите, можно воспринимать так или иначе. Я у вас тоже услышал несколько пониманий этого слова «онтология». Во-первых, как я услышал, для вас онтология — это, в первую очередь, некий математический формализм, позволяющий создавать некую базу знаний, пока мы не говорим о том, что в ней внутри. Как мы записываем предикаты, вероятность, невероятность – это как раз то, что определяет модель этого агента, и мы еще пока не знаем, что будет в этой модели. Это одно прочтение. Второе прочтение – это, собственно, уже сформированная некая онтология, понятие. Предположим, наш агент в этой игре от Арии побегал, там все изучил, все поля, и значит у него там есть мячик здесь, мячик там, ракетка здесь. Это как бы некий набор его антологии. Это некая его антология понятий. Но есть еще один слой, он между ними. И для меня, кажется, важно вот именно эта часть. Антология как формулирование этих понятий. То, что вы сказали про Бедуина и про Чукчу, что у Бедуина 20 видов песка, в его антологии, в его картине мира 20 слов условно, 20 понятий которые отражают разный песок. Вот это формирование антологии, оно как раз, на мой взгляд, ближе всего как раз к вопросу про то, что и Борис Новиков говорил, и про то, что я думаю, что как только мы делаем некую как только мы делали некую антологию как математический формализм, мы сразу создали некие ограничения для того, чтобы дальше что-то записывать. И вот дальше, как этот сенсорно-моторный поток мы будем облекать в объекты этой антологии, Вот это для меня остается неким, ну как бы неким таким, некой загадкой, что в моем понимании вот те антологии, которые обычно рисуют и которые, собственно, у вас нарисованы, вот если я на свой естественный интеллект этот применю, у меня знаете, это ощущение, как бы разницы между знаниями и распечаткой знаний. Вот у меня есть некие, как бы, набор знаний, вот допустим того, что я сейчас там пытаюсь сформулировать, даже то, что я говорю сейчас словами или же если выложу это в форме некого слитного текста, это как бы некая распечатка текущего моего как бы это выразиться, не знаю даже чего, понимание, которое, на мой взгляд, не есть антология, есть распечатка, но мое понимание не есть антология. Мое понимание, как бы, Тут вот есть что-то более зыбкое, более глубокое, и связи там не линейные, а какие-то более такие. Вот если я пытаюсь это как бы выложить, вот вам рассказать словами, или я вот попытался там слитный текст изложить, или вот вы, Антон, формулируете, вы распечатываете это, и тем самым это превращается в некую антологию. Это, мне кажется, как раз то, про что Николай Рабчевский сказал, что это вот нечто статичное, что он увидел нечто статичное. И как только мы это изложили, оно сразу стало вот этой распечаткой. Как оперировать с тем, что на самом-то деле должно быть внутри, оно не должно быть некой распечаткой, оно должно быть чем-то, это скорее просто такое, ну пока, не знаю, наблюдение, размышление, рефлексия от того, что я слышу. Это даже не то, что вопрос, это просто скорее мое ощущение сейчас. 

S04 [02:09:08]  : Вспоминать современных моделей, да, как раз, как раз эта диктомия тоже есть, прослеживается, не из простивых моделей. Они же работают и с текстом, и работают с какими-то внутренними представлениями, которых текст вообще никак нормально не выразит. 

S01 [02:09:24]  : Кстати, да. У нейросеток, у них вот эта своя условно понятийная какая-то модель, она есть, фичи эти, например, но она не формализована, то есть ее нельзя никак формализовать, она много богаче. 

S04 [02:09:39]  : Эмбэддинги чаще называют, пространство эмбэддингов. 

S01 [02:09:42]  : Ну да, им бедненькое слово не очень нравится. Ну да, ну наверное, да. 

S03 [02:09:49]  : Антон? Смотрите, во-первых, здесь не дуализм, здесь, скорее всего, даже энализм, потому что можно на это смотреть под разными углами. С одной точки зрения, если мы будем смотреть на онтологию, так сказать, как на нечто статическое, то у нас можно выделить, как минимум, три уровня. Значит, один уровень – это модель окружающего мира. Это, скажем так, некоторое множество абстрактных столов, абстрактных ног, абстрактных рук, абстрактных поднятий некоторых рук. То есть, это вот некоторый абстрактный уровень. Это вот некоторая модель, которая здесь на слайде показана справа. А дальше у нас есть более низкий уровень, который работает с конкретными объектами, встречающимися в рамках этой абстрактной модели совершенно конкретные столы, совершенно конкретные ножки, совершенно конкретные ручки и совершенно конкретное поднятие рук над столом. Вот. Да, еще глубже. У нас есть, так сказать, вообще-то, так сказать, структура именно уже, которая привязана, так сказать, к тем сенсорам, моторам, там, пикселам, значит, которые, так сказать, сборки которых формируют образы этих самых конкретных совершенно столов и конкретных ножек или там, так сказать, конкретных пикселов, конкретных точках. И это вот три уровня. На самом деле есть еще четвертый уровень, который правее. Это уровень метамодели. Это уровень оперирования с такими сущностями, как класс, атрибут, наследование, обладание свойством. Вот, которые, собственно, может быть, и которые... Вот у меня есть на эту тему отдельный доклад. То, что я называю фундаментальной онтологией, фундаментальные онтологии или на уровне метамодели позволяют строить базовые онтологии. или модели, которые вот здесь вот представлены в зеленом блоке. Это вот одна перспектива, так сказать, статическая, сверху вниз. А есть еще перспектива, та, Игорь, вот про которую вы говорили, с точки зрения распечатки-нераспечатки, вот та картина мира, которая у меня есть сейчас, да, вот то понимание антологии которое у меня есть сейчас, и которое я тоже распечатываю сейчас, оно на самом деле отличается от того понимания онтологии, которое я буду, допустим, использовать при разговоре с студентом про то, как программировать Semantic WEB с помощью разметки формализма схема ORG. Потому что там у нас будет только два уровня – зеленый и фиолетовый. А другие уровни там просто не нужны и даже вредны, и думать о них не надо. То есть, это гораздо более общечастный случай. Сейчас, когда я разговариваю с вами, у меня есть определенная задача. У меня есть задача о том, как рассказать о том, как попытаться некий универсальный формализм использовать для строительства некоторого универсального кирпича для построения системы универсального искусственного интеллекта. которые будут иметь однообразную архитектуру, вроде той, которую Сергей Шумский показывал на презентации, что у нас есть много-много кирпичиков, много слоев этого самого Наполеона, и произвольным образом, определенным образом соединяя слои вот этих пирогов Наполеона, мы будем собирать разные когнитивные архитектуры. То есть, если я хочу сделать каждый кирпич построенный единообразно, вот я, так сказать, использую такое вот абстрактное математическое понятие антологии и делаю распечатку своей внутренней антологии, так сказать, вот в антологию данного доклада. А если я делаю другой доклад, где студентам рассказываю, что такое схема ОРГ, и как с помощью ее делать, писать там РДФА-разметку на веб-страницах, я использую другую распечатку в другом контексте. И в этом смысле любое знание, оно контекстуально. То есть, если я катаюсь на лыжах по снегу, у меня работают немножко одни рефлексы, а если я катаюсь на лыжах по песку, то немножко другие. все определяется контекстом. 

S01 [02:14:10]  : И мне в этом смысле кажется, что ключевая как раз вот вопрос, который Юрий Бабуров задал, ну то есть он не вопрос, а комментарий такой был в конце, что вот, что как раз надо думать над тем, как устроены эти кирпичики, из которых мы складываем, то есть грубо говоря, а можно ли Возможно ли сложить из этих кирпичиков, из этого формализма, строится этот General AI или не строится? То есть, та онтология, которую вы сейчас рассказываете, у вас есть впечатление, что из нее можно построить General AI? 

S03 [02:14:46]  : Значит, у меня два ответа на этот вопрос. Во-первых, если у нас будет очень много вычислительных ресурсов, как у мозга, например, то мы сможем каждый кирпичик построить из одних и тех же нейронов. искусственных нейронов или искусственных предикатов, или искусственных схем, микросхем, логики вероятностного вывода. Если у нас будет много вычислительных ресурсов, если у нас будет мало вычислительных ресурсов, то мы, возможно, будем каждый кирпичик строить по-разному. В кирпичиках нижнего уровня у нас будут нейросетки, а в кирпичиках верхнего уровня у нас будут системы типа NARS, Discovery или OpenCock. А вот, и тем не менее, общаться между собой кирпичики смогут в рамках одного и того же формализма, одной и той же системы предикатов, где, при описании фич, определяя собираем их в объекты, у нас будут определенные правила того, как мы формируем эти сообщения на при передаче агрегированной информации с одного уровня на другой при соединениях между любыми кирпичиками. То есть, два варианта. 

S01 [02:16:02]  : Согласен. Так, ну что, коллеги, мы уже времени 8.15. Мы можем, если есть еще пору в Пороховницах, тут есть еще явно у Бориса Новикова вопросы, можем еще какое-то время продолжить или можем сделать официальное закрытие сегодняшнего для тех, кто уже убегает? Антон. 

S03 [02:16:27]  : Если нет каких-то горящих вопросов, я предлагаю сделать перерыв на три недели. И пока не все разбежались, я делаю, обращаю вас внимание, что следующий семинар будет проходить на электронной площадке компании TrueBrain. И поэтому, значит, нужно, и ссылка будет другая. Поэтому следите за новостями, или подписывайтесь на событие на таймпаде, потому что будет другая ссылка на другой Zoom. Отлично, хорошо. 

S00 [02:16:57]  : Ссылка будет в Фейсбуке? 

S03 [02:17:00]  : Я и в Фейсбуке, и в Телеграме, и на таймпаде новую ссылку поставлю. 

S01 [02:17:06]  : Отлично, давайте тогда на сегодня закончим. У нас был еще один вопрос про предложение из чата, мне кажется, правильное. Чат был сегодня прям такой живенький очень. То есть, на мой взгляд, Антон, ваш доклад спровоцировал массу обсуждений. Это лучшее, что может быть вообще от доклада. И было предложение чат сохранить. Так что давайте мы сейчас, прежде чем там выйдем, попробуем, ну как-то скопировать, я надеюсь, что это возможно, сохраним его и потом его куда-нибудь там положим. Потому что там свои были параллельные обсуждения, крайне любопытные. А так всем огромное спасибо. Антон, вам огромное спасибо за доклад. Когда есть вопросы, есть обсуждения, есть живая мысль, это значит доклад своей цели достиг. Даже если не все согласны. А так не бывает никогда. Так что, коллеги, всем огромное спасибо, давайте попробуем сохранить этот чат. Давайте мы с вами независимо попытаемся это сделать. 

S03 [02:18:02]  : Всем спасибо, всем до свидания, мы с Игорем сейчас будем бороться с чатом, спасать чат. 

S01 [02:18:09]  : Если, кстати, вот я что-то даже не уверен, это вообще как бы здесь механизм-то... 

S00 [02:18:13]  : Выбрать все и копировать, все очень просто. 

S01 [02:18:17]  : А я не нашел выбрать все. 

S04 [02:18:20]  : Там есть где три точечки, там есть сейф чат, но это у меня он в маке есть. 

S00 [02:18:30]  : В разных операционках по-разному. 

S03 [02:18:39]  : Вот у меня маг, как вы это делаете? Вот у меня три точки, три точки вы где нашли? А, вот, вот. Вот, сейф-чат, вот сейф-чат. 

S05 [02:18:48]  : У меня сохранился. И куда он сохранился? Она говорит, где-то в файл. 

S01 [02:18:56]  : А, да, у меня тоже сохранился в виде текста. Вы нашли, куда он сохранился? Да, да, да, он просто в папку download сохранился и все. 

S04 [02:19:07]  : Давайте я как файл в группу пришлю просто в Телеграм. 

S01 [02:19:10]  : Да, да, да, прекрасно. 

S03 [02:19:12]  : Все, и в Телеграм и в Фейсбук тогда пожалуйста тоже. 

S01 [02:19:17]  : И, Антон, на редкость живая тема про сознание субъекта и прочее. Я жду и не дождусь, когда Роман наконец там сделает этот семинар. Он там сказал, что он к Ай-Джорни что-то завален докладом и никак не в силах. Но прям я вижу, как народ рвется на эту тему поговорить. Явно тема очень живая. 

S03 [02:19:42]  : Хорошо. Всё. Спасибо, коллеги. Да, всё. 

S01 [02:19:45]  : Всё. Спасибо огромное. Счастливо. Спасибо. 

S00 [02:19:46]  : Особенно за классику. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
