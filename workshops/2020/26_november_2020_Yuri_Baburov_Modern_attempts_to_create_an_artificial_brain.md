## 26 ноября 2020 - Юрий Бабуров - Современные попытки сделать искусственный мозг — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/2Yi0NkCovSM/hqdefault.jpg)](https://youtu.be/2Yi0NkCovSM)

Суммаризация семинара:

Семинар обсуждал современные попытки создания искусственного мозга, с акцентом на проблемы и перспективы в области искусственного интеллекта (AGI). В частности, были затронуты следующие ключевые моменты:

1. Проблемы интеграции: Участники обсуждали отсутствие полной интеграции с конференционной системой AGI, что требует независимой регистрации для участия в секции AGI.

2. Ограничения времени: Спикеры подчеркивали важность соблюдения временных рамок для докладов, указывая на опыт предыдущих семинаров, где докладчики успешно укладывались в 5-минутные слоты.

3. Альтернативные подходы: Юрий поделился своим опытом в области нейросетей, отметив, что альтернативные технологии пока не позволяют решать сложные задачи для большого количества правил, хотя успешно работают с простыми задачами.

4. Сравнение алгоритмов: Был приведен пример сравнения различных алгоритмов в рамках проекта по Supervised Language Learning, где использовались BERT, Minimum Splendid Parser и МСТ-парсер. Выяснилось, что BERT, хотя и требует значительных ресурсов и времени, приносит лишь незначительный выигрыш по точности.

5. Производительность и ресурсы: Юрий обсудил, что некоторые алгоритмы требуют значительно больше вычислительных ресурсов, чем другие, и что производительность может сильно варьироваться в зависимости от задачи.

6. Генерализация и обучение: Был затронут вопрос генерализации нейросетей, их способности учиться на широком спектре данных и применять полученные знания к новым задачам. Обсуждалась проблема катастрофического забывания и необходимость длительного обучения для достижения генерализации.

7. Сравнение с человеческим мозгом: Участники семинара отметили, что нейросети могут быть хорошим симулятором для человеческого мозга, однако они очень медленны и не могут постоянно доучиваться при появлении новых стимулов.

8. Проблемы параллелизма: Юрий упомянул, что нейросети плохо параллелизуются, что является проблемой не только для искусственного интеллекта, но и для человеческого мозга.

9. Разработки Юрия: Юрий рассказал о своих разработках, включая обучение системы распознавания речи, которая показывает результат в топ-5 систем на русском языке, и о работе с документами, где применяются комплексные методы, включая нейросетевые.

10. Предложения по AGI: В конце семинара был обсужден план Николая Бадулина по созданию AGI как комплекса из нейросетей разной топологии и плотности для разных уровней задач.

В заключение, семинар подчеркнул сложность и многоаспектность задач, связанных с созданием искусственного мозга, и важность дальнейших исследований в этой области.



S02 [00:00:00]  : Всем привет. Мы поговорим сегодня про современные попытки сделать искусственный мозг. Точнее, этот доклад планируется в большей части как обзорный по различным современным технологиям и подходам к общему искусственному интеллекту и решениям интеллектуальной задачи. Начну я с простого сведения, с блока вводного. И просто очень быстренько пробежимся сейчас по некоторым, чтобы у нас была общая основа, разделяемая, чтобы потом уже говорить о подробностях. Мы хотим сделать искусственный мозг как инструмент, который умеет повторять то, что делает человеческий мозг. Но, пожалуй, то, что делает человеческий мозг, можно поделить на несколько разных аспектов. То есть он умеет как-то работать с внешней информацией, человеческий мозг. Человеческий мозг умеет обучаться накапливать знания и навыки, умеет думать и решать задачи. умеет управлять собой внешним механизмом. И, соответственно, если мы один и тот же мозг в этих аспектах проинтерпретируем, просто обращая внимание в первую очередь на этот конкретный аспект, у нас получатся разные представления. которые сводятся к разным текущим системам, некоторые из которых даже уже воплощены. То есть вот робот-поисковик, например, уже у нас есть, какой-нибудь там Google Яндекс. Внешние знания они вполне себе как-то интерпретируют, уже пытаются предсказать, что вас заинтересует в интернете. Также они могут на некоторые вопросы уже отвечать. С другой стороны, если мы посмотрим, как происходит дело с накоплением знаний и навыков, то здесь у нас все похуже обстоит дело, но про это мы подробнее поговорим чуть позже. Если мы будем говорить, продумать и решать задачи, Робот умеет решать задачи в небольшом пространстве, но проблема в том, как нам эти задачи для робота сформулировать в небольшом пространстве. Большей проблемой является понимание задачи, формулировка задачи, нежели, собственно, решение задачи для робота. Если мы будем дальше говорить про четвертый аспект управления приборами и манипуляторами, то опять же у нас есть пример, когда роботу не надо решать какие-то сложные задачи, он должен только вести человек, робот-автомобиль, и опять же тогда становится все проще. Но тем не менее, в более сложных случаях, когда врачу надо и думать, и делать, то тут прогресс еще покромал. Теперь подробнее поговорим, почему нам какие-то задачи решать получается, а какие-то задачи решать не получается. Но для начала еще чуть-чуть в видах интеллекта подразберемся. У нас есть то, к чему мы хотели бы прийти, построить AGI, который умеет решать задачи не хуже человеческого уровня и умеет решать принципиально разные задачи. И у нас есть AI, технология узкого искусственного интеллекта, которые умеют решать задачи на уровне, сравниваем с человеческим, но умеют решать какие-то а задачи одной предметной области домена или какого-то одного вида деятельности. Картинки распознавать, а конкретнее, например, распознавать картинки только кошек и собак, отличать кошек от собак. Вот на такой вот узкой задаче нами уже достигнута точность 99%. Или, например, решатель кроссвордов, когда у нас для каждого слова формулируется текстом описание этого слова, а он подбирает от словаря нужное слово, для каждого слова подбирает, по описанию подбирает, чтобы это слово подходило в нужной клетке. В общем узкие задачи он умеет решать и теперь свойства, которые позволяет искусственному интеллекту, точнее технологии, обобщаться на домены на разной предметной области и на разные виды деятельности называется генерализация. То есть это же свойство отражено и в названии General Intelligence, свойство обобщаться. Соответственно, если же мы посмотрим про то, именно про повторение человеческого мозга, то эти Модели, которые делаются для повторения этого узкого или общего искусственного интеллекта, они основываются на разных свойствах мозга, или на верхнеуровневых блоках мозга, или на нижнеуровневых схемах. кто-то пытается даже до уровня атомов строить модели отдельного нейрона, как он точно работает. Соответственно, хотелось бы в общем надеяться и думать о том, что 

S01 [00:06:25]  : что действует. 

S02 [00:06:45]  : Что нам бы хотелось повторить. весь мозг как целое с помощью какой-то единой технологии. Но на самом деле не факт, что это возможно, если мы уже рассмотрим какой-нибудь уровень повторения до верхнего уровня блоков, мы эти модули можем реализовывать совершенно по-разному. Главное, чтобы у нас между этими модулями были какие-то взаимосвязи, которые позволяли нам осуществлять взаимодействие модулями, осуществлять управление модулями. Ну, например, внимание. То есть ничего же не будет хорошего, если мы будем смотреть на двух человек, будем слушать одного человека, но смотреть при этом на другого человека. Точнее человек так может и может делать, но при этом точность ухудшается. То есть некоторый нужен механизм, Мы смотрим на того человека, который говорит, и получаем дополнительную информацию от других органов чувств. Получаем информацию о том, как движутся у него губы, какое у него расположение лица, какая мимика у него, как он руками двигает, и от этого мы точнее понимаем, что он говорит. Также мы понимаем контекст, в котором он это говорит. Соответственно, по поводу попытки воспроизвести нейрон до уровня атомов, была попытка от IBM. исследовательский проект, часть их исследовательского проекта по исследованию мозга и повторению человеческих нейронов, в котором они строили действительно очень полное взаимодействие, то есть систему не просто даже дифференциальных уравнений, а систему еще и симуляции, полностью симуляции прохождения сигналов внутри нейрона и между несколькими нейронами внутри нейрона. Соответственно, понятно, что именно до атомов нереально, но вот на уровне ниже нейрона намного ниже нейрона, до движения нейромедиаторов по нейрону, до вот этих пузырьков. Вот такие модели есть. Соответственно, когда мы пытаемся эти модели как-то сшить, то у нас может быть какая-то общая система внимания. И какие-то модели, которые как-то повторяют или чем-то похожи на модульную систему человеческого мозга. Чем-то похожи, потому что точное повторение, конечно же, приводит к проблеме скорости низкой. То есть, чем ниже у нас модель, тем хуже у нее скорость. Я вам дальше буду говорить про вертикальные алгоритмы Хокинса 2012 года. И вот они как раз медленнее, как раз это уже сказывается. Значит дальше. Поэтому подобный модульный подход, он в целом является прорывной идеей для построения общего искусственного интеллекта. То есть если нам удастся сделать действительно модули какие-то и сделать еще систему какую-то между ними интеграцию, делать управляющие какие-то модули, то в целом у нас получится что-то похожее на общий искусственный интеллект. Притом, последний пример, на самом деле это иллюстрация одного из модулей. Часто говорят, что компьютер не способен на распознавание причинно-следственных связей. На самом деле компьютер вполне способен понимать и распознавать причины следственных связей. Просто есть та же самая проблема с датасетами, проблема с тем, чтобы учить конкретно, решать эту конкретную задачу. И вот здесь как раз пример причинно-следственной связи, то есть вопроса для причинно-следственных связей. В целом, я думаю, это вполне можно оформить как модуль, В следующий раз, я думаю, как-нибудь поговорим о том, как может выглядеть подобная модульная система для человеческого мозга, для общего интеллекта, повторяющего человеческий мозг. И одним из модулей вполне может быть как раз модуль, который определяет, что хотел Джон в данной ситуации. когда он плудился над своей тарелкой для кружка школьной самодеятельности. Вот. Так, значит, идем дальше. Значит, дальше идем. Теперь, да, что касается диплеников. Почему построить общий искусственный интеллект сложно? На самом деле эта проблема происходит с любой сложной задачей, которую решает человек. Мы легко умеем решать алгоритмические задачи, когда компьютеру нужно описать конкретную последовательность действия. И когда у нас количество правил растет, которые нужно применять в разных контекстах для решения этой задачи, то сложность задачи начинает нарастать. На самом деле, я бы сказал, что есть универсальный способ оценить сложность задачи. это оценить через то количество правил, которые нужно построить для правильного решения этой задачи. Имеется ввиду для класса задач, для индивидуальных задач. И в целом мы как-то умеем решать задачи, где правил мало. Но как только правил у нас становится миллион, то сразу возникают проблемы, потому что мы плохо умеем эти задачи решать, очень плохо. Также мы не умеем решать задачи быстрой адаптации к новым правилам, когда новых правил тоже много. Но когда правил мало, в общем-то мы такие задачи умеем решать. Поэтому задачи, какие-нибудь поиска пути в лабиринте, они решаются каким-то универсальным абсолютно алгоритмом. И какие-нибудь задачи типа поиска обезьянной пути решения проблемы, как достать банан, тоже решаются компьютером тривиальным образом. Главное для этого надо, чтобы у нас было построено какое-то абстрактное представление, где вот эти задачи типа поиска пути к банану, они уже имеют не так много вариантов. Или же можно строить правила какие-то в этом мире, но этих правил не очень много. Соответственно, проблема планирования как правило не сложная. Давайте посмотрим какие-нибудь другие задачи, которые посложнее. Например, задача расстановки переносов, которую изначально Кнут утверждал, что в целом не сложная задача для компьютера. но потом потребовалось несколько лет для того, чтобы ее нормально решить на английском языке, конечно. Вот она заключается в чем, что нам нужно расставить переносы для того, чтобы слово переносить на следующую строчку в каком-то месте, потому что у нас ширина строчек ограничена, и нам хотелось бы чуть больше текста вместить. Казалось бы, тут правило простое. Ну вот находим гласную букву, переносим где-то перед гласной буквой, ну и после гласной буквы. Но есть контрпример. Если переносим после гласной буквы, если дальше есть согласная, то там одно правило, если там другие буквы, другое правило. Вот здесь, например, контрпример. Слово подвздошное. Хотя, в принципе, допустимый такой вариант. Здесь вот эти правила очевидные, наслоги, что после гласной буквы или перед согласной не работают. Соответственно, эта задача более сложная, примерно ее можно оценить в 5000 правил. А если факторизовать эти правила по использованию гласных на согласных, выделив в один класс гласная буква, а в другой класс согласная буква, то в целом можно где-то 100 классов правил описать эту задачу. подход к решению подобной проблемы. Человеком в целом сведется к тому, что человек будет составлять слова каких-то слов, которые правильно распознаются, которые неправильно распознаются, в смысле в которых переносы правильно и неправильно определяются. То есть мы придем к той же задаче, что человек составляет поэтому датасет уйдет, там у него есть правильные ответы, неправильные, он свой алгоритм тестирует, добавляет какие-то правила, правила там не работают или там работают где-то с ошибками. После чего он матерится в очередной раз, там уже в десятый и сотый в очередной раз переделывают правила, говорит «и так сойдет» и сдается на это. Ситуация усложняется, когда правил становится больше. Например, задача «поиск города в тексте». В целом городов не так много, если в России городов меньше 10000-12000, соответственно решается составляющая городов. То есть фактически у нас правило получается следующее. Если город находится в списке, то это город. Если слово находится не в списке, то это не город. Но здесь есть контрпример. Вы знаете, что есть такой город Тога. Точнее не город, а страна. Или город. Есть такой город Владимир. что Владимир бывает и не города. То есть у нас появляются уже контрпримеры и исключения из правил. И, соответственно, требуется снова вспоминать нам, что в естественном языке все сложно, и вот эти правила каким-то образом кодировать. естественного языка. Как минимум, нужны правила синтаксического анализа, которые позволят по соседним словам определить, какая это часть речи, с какими другими словами она связана, и впоследствии определить, в каком значении это слово используется. Если мы будем дальше расширять задачу, например, на поиск географических названий в целом, то у нас все станет еще хуже. У нас словарь уже начнется, будет составлять где-то миллион записей и будет намного больше ошибок. И уже у нас появится такая проблема, что мы даже не знаем. То есть в России-то мы знаем вроде бы все города. А вот здесь, ну там каждый месяц добавляется по тысяче новых названий, а там 500 старых названий пропадает. Переименовываются там города или что-то еще с ними происходит. Соответственно, мы даже не можем в принципе все названия добавить в слова. Значит, мы будем в результате искать какие-то правила, которые будут более общими. Например, мы можем смотреть, значит, поехал куда-то. Поехал куда-то, значит, куда-то возможно это географическое название, если оно с большой буквы записано. И у нас появляются контекстные правила, и количество возрастает в перспективе как раз до всего языка. То есть ровно та же система, что и распознает весь язык, работает со всем языком. Ровно эта же система может решить такую узкую задачу, как поиск нервов. Но здесь есть, конечно, способ схалявить, но про это чуть позже. Другая задача. Это синтаксистский анализ, это как раз задача еще более крупная в этом плане. Это когда целиком надо не только города искать, но и искать все части речи, всех слов в тексте и все связи всех слов с другими словами. Значит, вот 100 правил описывает 80% грамматики. В целом, Алексей Рядозубов, который говорил, что его система повторяет свойства человеческого мозга относительно парсинга, синтаксического анализа, его система вот что умела делать. Построил бы он систему на подобных технологиях, которая бы описывала 10К, правил нет, не построит. И уж тем более, если мы говорим о еще более сложных системах описания грамматики до деталей процента, до последних процентов, то там количество правил уже запредельное. вот подобные даже вот эти правила, их уже нельзя, то есть 10 тысяч они не влезают, они где-то на уровне от 10 тысяч до 10 миллионов, на уровне 1 миллиона уже редкость таких правил, там отдельный парсинг. Ну да, я с ним беседовал, система Рядозубова, которую про которую он рассказывал, которая занимается работой с грамматикой языка. Это вопрос Антон Холонин задает. Откуда вы знаете, что делал система РИДАЗУ? Вы видели ее результат. Система анализа грамматики русского языка, которую он показывал, которая работала на основе правил и которую в дальнейшем хотел обобщать, вот эта вот система, которая направила была построена, она была на уровне от 100к до 10к. А систему уровня до АОТ, например, у них было упрощение, у системы АОТ, которая была в 2000 году и про которую недавно говорили в группе, у нее было такое упрощение, что она считала именными, вначале выделяла именные группы, То есть, если будет здесь написано «Поехал красивый город Владимир», то она выделит вначале красивый город Владимир, а потом уже будет из этих именных групп зависимость внутри расставлять. Эта система прекрасно ломается, Вот внутри именной группы на самом деле есть несколько разных сущностей. Красивый город, даже не знаю какой пример привести, очень легко ломается, когда вот здесь несколько разных сущностей, все из существительных и прилагательных. В результате они обошлись меньше, чем 10К правилами, описали большую грамматику, но получили вот такие вот крайние случаи. И при том сходу такую систему уже не учили. То есть там нужно уже другие применять технологии. Я про систему АОТ говорю. которую недавно упоминали в чате. Вот Эдуард упоминал участие свое в этой системе. И, собственно, проблемы которые при синтаксическом анализе возникают, в основном это проблемы, связанные с неоднозначностью разбора. Я вот приведу один очень простой пример. Я буду есть суп с другом и суп с хлебом. Суп с другом. Я с другом. Это однородный. Ну, не совсем одноразовое предложение. В общем, я с другом – это люди, а я суп с хлебом вместе. Группировка по-разному происходит, синтоксические связи будут разные. И, в принципе, мы можем как-то упростить. сводить отношения в основном. Вот здесь мы понимаем, что надо, возможно, выделять одушевленные предметы отдельно, возможно, нужно выделять одушевленный класс отдельно. Также в языке слова, относящиеся к емкостям, у них немножко другая модель управления. Ну, емкости в общем смысле, там, я... в кармане и в доме разные значения немножко, в рюкзаке, в стакане. Связанные с болезнями другие предлоги используются. Можно выделить для существительных вот такие, для других частей речи какие-то другие можно выделить. Можно выделить где-то 50 синтаксических классов таких, которые не совсем части речи. И тогда как-то мы данную задачу частично упрощаем, но все равно возможны неоднозначности на других уровнях, и все равно у нас остаются сложности. И, соответственно, дальше полноценная задача до сих пор не решена. И это типичный пример, такое происходит абсолютно в любой задаче, которую мы пытаемся решать какими-то компьютерными методами. Справляется ли с этой задачей человек? На самом деле тут очень сложный вопрос. Потому что в случае, когда у человека есть подсказки, он, конечно, с ней справляется лучше. И, возможно, проблему компьютера зачастую, что его спрашивают, просят это делать без подсказок, а людей то же самое просят делать уже с подсказками. То есть они намного больше знают про окружающий мир, про то, что происходит, какой-то контекст обсуждения чего-то уже есть. но тем не менее проблема остается. Если говорить про технологии, которыми пытаются решать все эти задачи, то примерно везде возникает одна и та же ситуация. Здесь еще не нарисованы евристические методы, к сожалению, которые ведут себя, в общем-то, примерно близко к традиционному машинленингу. То есть то, что здесь описано. Тут количество данных. Это необходимое количество тех размеченных данных, которые мы располагаем, которые нам помогут решить проблему. а performance — это, соответственно, качество на задаче. Чем больше у нас данных, тем все алгоритмы работают лучше. Но дело в том, что ни один традиционный алгоритм сейчас на сложных задачах не работает лучше, чем нейронные сети. То есть практически во всех задачах Люди просто их имеющуюся систему обучения переделывают на нейросети и при тех же входных данных получают буст качества. Достигается ли это каким-то хаком нейросетей? В общем-то нет. Есть профессор Тишбин, который убедительно доказывает Я потом ссылку скину в отдельную группу, которая убедительно доказывает, что нейросети на самом деле они способны решить наилучшим образом проблему с любыми данными. До этого существовали другие оценки качества работы нейросетей и классических алгоритмов machine learning. Но он, в общем, показал, что нейросети стремятся к тому, что при наличии тех же количеств данных нейросети являются наилучшим решателем задач. Конечно, при наличии у нейросетей бесконечного количества, ну не бесконечного, а большого количества слоев и чуть-чуть других еще ограничений. Вот здесь для примера, опять же, это качество решения задачи, первое приближение к качеству решения задачи. Тут чуть-чуть другой график. зависимости x от y, то есть они способны выучить сопоставление x от y наилучшим образом при наличии большого количества данных. И чем больше сеть, тем лучше она учится. При этом с зависимостями тут все сложно. Нейросеть в этом плане обладает своим недостатком. 

S01 [00:34:19]  : Сейчас я попробую как раз воспроизвести тот участок. Видим, где оно движется. 

S02 [00:34:33]  : Хотя, может, я его и не буду воспроизводить. А вот он пошел. Смотрите, это плоскость, которая говорит о том, что эта нейросеть знает про исходные данные, про распределение исходных данных. А это как она предсказывает target класс. Насколько она предсказывает правильное значение, то вертикально. а по горизонтали насколько хорошо она знает исходные данные при этом. То есть что делает нейросеть? Она выучивает на всех слоях, то есть то, что выучивает последний слой закономерности на 100% уже давно выучила. Это предпредпоследний слой. Они выучивают правильное значение, которое нужно выдать на выходе, но при этом они подстраиваются под данные таким образом, что они начинают игнорировать все большую часть входного пространства, то есть они начинают замечать во входном пространстве только те точки, которые способствуют классификации, правильной классификации, и абсолютно игнорируют все те остальные свойства, которые менее важны для классификации. Это как раз есть то, за что нейросети критикуют то есть они действительно учатся лучше других алгоритмов, но при этом они это делают за счет того, что они подстраиваются под те входные данные, которые им дали, под тот датасет, который им дали. За счет того, что они лучше с ним разбираются, с конкретным датасетом, они хуже хуже знают все остальные контексты. То есть это та же известная проблема, которая называется экстраполяция. Я вам приведу классическую картинку про экстраполяцию. Вчера у девушки было ноль мужей, сейчас у девушки один муж. Понятно, что дальше количество мужей у нее будет расти. По одному мужу в день. Лучше заказать сразу 50 свадебных тортов. Эта проблема с экстраполяцией возникает естественным образом в нейросетях именно за счет того, что нейросети подстраиваются под конкретные данные. Можем ли мы эту проблему уменьшить, нивелировать ее? В целом, эта проблема характерна для всех алгоритмов, которые работают с данными, в том числе и с алгоритмами, когда человек эти данные как-то адаптирует для компьютера. и строит какие-то алгоритмы. То есть это общая проблема, она таким образом не решается, но мы можем данные подавать не в том виде, что вот вчера, сегодня. Мы можем данные передавать в таком виде, что мы знаем, что завтра тоже будет один, послезавтра будет один и так далее. То есть данные должны описывать весь мир. И вот здесь мы приходим к проблеме как раз генерализации снова. И у меня был опыт обучать нейросети, которые обладают генерализацией. И что я вам скажу. Что в целом... Что в целом... Что в целом... Генерализация работы... Про генерализацию... Генерализация у меня была вот здесь... Вот... В целом генерализация работает. То есть если мы будем нейросеть учить не только кошечкам и собачкам, а будем учить всему, то она действительно научится и кошечкам, и собачкам, и всему остальному. Если же мы будем учить ее только кошечкам и собачкам, то немножко она уже научится всему остальному. Немножко. Дальше нам останется уже добавить меньше данных с другими видами, там зверюшек, там чего угодно, чтобы распознавание работало. То есть нейросеть способна генерализовываться, но, есть одно но, ее надо для этого снова долго учить. причем ее надо учить как на исходном датасете, так и на… то есть ее нельзя доучивать просто на датасете с новыми, вот мы там начали пингвинов и павлинов распознавать, нам теперь нужно. Если мы будем распознавать пингвинов и павлинов, она начнет забывать про кошечек и собак. Эта проблема называется catastrophic forgetting, катастрофическое забывание. И эта проблема характерна и для людей в общем-то тоже, но в меньшей степени. Что еще про нейросети можно сказать как про ровную технологию? Ну, на самом деле для многих многих областей мозга получены результаты, что нейросети и мозг похожим образом решают задачи. То есть нейросети в принципе могут быть неплохим симулятором для человеческого мозга. Есть лишь одна проблема – нейросети очень неслабые. Хоть они и хорошие, Но в целом они на текущей архитектуре, пока что компьютерной, которая нам доступна, очень медленны. Да, удалось ускорить рассто их вычисления с приходом видеокарт, но все равно все остается медленно. Поэтому мы не можем постоянно там доучивать при появлении каждого нового стимула зрительного. 

S01 [00:41:49]  : Сейчас расскажу. 

S02 [00:41:52]  : Поэтому мы не можем одновременно их... Так, давайте сделаем перерыв одну минутку. Вы подумайте. Вопросы пока что до этой части. И вот в том числе как раз попробуйте подобрать аргументы, похожи ли нейросети на мозг как грубые модели или не похожи. Было бы интересно их обсудить. парочку каких-нибудь аргументов, чтобы более предметно об этом разговаривать, а потом я расскажу про катастрофу Фаргетина и катастрофу Ремемберта, или как с помощью нейросети действительно выучить и кошек, и собак, и птичек, и рыбок, в чем расскажу сразу два способа. Перерыв на одну минуту. Я просто болею немножко, мне надо. У меня вода закончена. Пойду за водой схожу. Так, ставлю звук пока на паузу. Видео на паузу. Так. Да, можете, может пока кто-нибудь поговорить, обсудить, предложить какие-нибудь варианты. 

S05 [00:43:19]  : Ну, я, собственно, свой вопрос вот про катастрофик фагеттинг vs. катастрофик ремемберинг поясню. Значит, здесь обозначается такая ситуация часто, что не всегда фагеттинг это плохо. То есть, если, к примеру, нам нужно хорошо научиться какому-то виду деятельности, где нам нужны навыки, противоречащие какому-то нашему прошлому опыту, то в этом смысле как раз полезно бывает забывать то, что мы знали раньше. И каков может быть некоторый общий механизм, какой-то универсальный механизм, который позволяет мозгу или человеческому организму в целом, включая его мозг, балансировать между тем, что что-то нужно забывать, а что-то нужно наоборот помнить. Даже когда мы приобретаем новые навыки. Отличный вопрос. 

S02 [00:44:21]  : Он обычно описывается как проблема металлернинга, в том плане как система, которая способна быстро обучаться чему-то, намного быстрее. Подхода тут два. То есть получается с металлинингом, действительно, подхода получается три. Значит, вариант номер один. У нас есть база данных, которые есть кошечки, собачки, картинки кошечки и собачек, картинки пингвинов и павлинов. И мы теперь, то есть мы знаем, что если мы будем учиться теперь дальше только на переливных и павлинах, мы немножко подзабудем про кошечек и собачек. Если, конечно, будем учить всю сеть, потому что, ну вот я как раз рассказал профессор Тишбе, профессор Тишбе нам рассказал, почему это происходит. Он как раз рассказал, что происходит. Нейросеть целиком пытается оставить те нейроны, в которых какая-то информация есть. Причем чем увереннее этот нейрон предсказывает, данную информацию, тем с большей вероятностью он останется в таком виде, а чем менее уверен он эту информацию выдает, тем больше вероятность что его поменяют на что-то другое. А учитывая, что другой информации нам сейчас не поступает, а поступает информация только про пингвинов и павлинов, мы забудем про те нейроны, которые были важны для распознавания кошечек и собачек. Про те правила нейросети мы забудем. Соответственно, что можно сделать? что можно сделать, чтобы этого не происходило. Во-первых, мы можем учить только одну часть нейросети. То есть мы учим половину нейросети, новому все остальное не учим. Есть наставание предполагать, что дофамин в мозге занимается как раз именно это. То есть он подбирает коэффициенты обучения для мозговой нейронной сети, уже человеческой, но таким образом, чтобы училась только маленькая часть и таким образом не происходило забывание всех остальных данных. Далее, какие другие способы есть? Ну, тривиальный способ. Мы можем учить не только пингвинов и павлинов, а когда у нас есть теперь пингвины и павлины, мы старый датасет с кошечками и собачками не выкидываем, а учим теперь и кошечек, и собачек, и пингвинов, и павлинов. И в результате с одной стороны происходит более хорошее, распознавание и кошечек, собачек, пингвинов и павлинов с другой стороны, а все остальные классы, которые были кроме кошечек, собачек, пингвинов и павлинов, те все же немного забываются. Поэтому все подходы, основанные на метках и на классификации, у них всегда есть выбор. Или мы распознаем несколько классов и сеть учится на них хорошо, но начинает постепенно ошибаться и всех только к этим классам перечислять. Или же мы учимся на большем числе классов, а нам требуется более крупная нейросеть, чтобы их просто запоминать, чтобы все правила хранить на промежуточных слоях. И одно из двух, то есть если мы оставляем старую нейросеть поменьше, то качество у нас падает, или же у нас качество растет, но растет и время обучения, потому что нам требуется более крупную сеть и больше информации у нас теперь для запоминания есть, которую мы больше раз прогоняем. Вот такая у нас дилемма есть. И вот в общем-то эта дилемма, она вот в традиционной пайплайне классификации она не решается никак. Но есть другой пайплайн и есть другое решение проблемы. И имя ему, одно название для него это эмбейдинги, Другое название для него – это энкодер-декодер сети. То есть нейросеть учится следующему. Она учится теперь не напрямую предсказывать метку, а она учится научится находить произвольные соответствия, всякие разные, между входными и выходными данными, причем входные данные — это наша информация, а на выходе может быть очень много разных данных. Например, вариант один — multitask learning, который называется. когда мы учим сразу сеть нескольким задачам, и в результате за счет этого она на исходной задаче начинает работать лучше. То есть у нас кроме исходных меток есть другие задачи. Но при этом, опять же, нужна сеть побольше. Кроме multitask learning есть и другие похожие механизмы. Например, мы можем место входа ставить тот же вход или какую-то там часть входной картинки. Если мы ставим тот же вход, только зашумленный, это называется denoising autoencoders. Autoencoder 1 в данном случае. Если же мы ставим картинку, например, по одной части картинки учимся предсказывать. Теперь берем одну сетку и делаем из нее две сетки. Такие сетки называются сеанские. И вот первой картинке мы даем первую часть картинки input fragment 1, вторую часть картинки мы даем второй сети, такой же, здесь веса одинаковые. И теперь мы просим, говорим, что нам без разницы, что ты будешь выводить на выходе, главное, чтобы это было похоже, когда эти части из одной картинки, и не похоже, когда эти части из разных картинок. И нейросеть тогда учится общему представлению этих объектов. Вот эта технология нынче называется self-learning. Хотя до этого тут есть больше десятка разных названий. Самоно и Сиамские сети, и это называется метрик Леонин, потому что это метрика близости этих объектов. В общем, по-всякому. это называется. Главная суть в том, что нейросеть в такой ситуации учит... вот мы можем даже не знать, что вот это такое, но нам важно то, что сеть выучила вот это. Сеть выучила какое-то внутреннее представление мира, в котором она умеет отличать и представлять вот эти объекты. То есть это что-то похоже на то, что у нас в голове возникают какие-то образы при виде объектов реального мира. И возможно это похоже на то, что происходит при мышлении, когда мы слышим разные слова, то какие-то внутренние возникают понятия, которые отражают в том числе смысл используемого слова. Эта технология очень широко используется нынче в NLP, хотя пришла она как и многое другое из картинок а в картинках это используется, например, для face recognition. То есть когда мы распознаем лицо, у нас на выходе это как раз вектор из 128 значений, которые находятся внутри венбендинга. Венбендинг их там бывает и больше, там их бывает 512 значений. Но после этого мы берем и пользуемся классическим методом понижения размерности и выделяем 128 более уникально. и говорим, что вот это вот наши внутренние понятия, которые возникают при виде лица в нейросети. И нейросеть обычно таким образом различает лица лучше людей. Я не знаю, кажется ли это для вас шокирующим или банальным, но вот это так. Нейросеть из смогла запомнить из миллиона лиц и различать действительно лица с точностью 70%. Остальные там просто многие похожие есть. И таких вот более-менее уникальных там как раз порядка 60-70% наверное. Часть еще на чуть-чуть угадала, возможно. Случайным образом еще процентом 10. Ну а остальные она не может изучить, потому что там есть несколько похожих, она просто не знает кого. Случайным образом не угадывает. Угадывает только на 10%. Та же технология используется и в NLP. И, соответственно, вначале она делалась просто на словах, тогда это называлось embeddings, word embeddings. После чего эту же технологию стали делать уже на представлениях контекста, когда стали решать задачу как раз в роли фрагментов. Стали фрагменты текста, и она по фрагментам также предсказывает похожесть фрагментов. Вот давайте я вам схему покажу электры, которая в плане архитектуры, наверное, 

S01 [00:56:29]  : будет как раз подобным представлением. 

S02 [00:56:44]  : Электра решает какую задачу. Она случайным образом какие-то слова маскирует, После чего первая часть нейросети учится восстанавливать эти слова, а вторая часть учится угадывать, понимать, правильны ли эти слова или неправильны. За счет этого эта нейросеть учится в четыре раза быстрее, чем просто нейросеть, которая просто только предсказывает слова. MLM – это как раз маскет предсказывания маскированных слов. Соответственно, подобные сети способны делать эмбэдинг, который действительно отражает у слов какие-то смысловые значения, и оттенки смысла, и контекстные значения этих слов. Вот там внутри него получается, то есть не снаружи, а внутри него. Соответственно, мы просто отрезаем половину нейросети и используем его как получатель нашего внутреннего представления, нашего эмбэдинга. Собственно, вот это как раз прорывная технология в целом и пока что никакая другая технология не способна для больших задач объема всего языка справиться именно с пониманием контекста. Если мы посмотрим теперь на конкурс Superglue. Не знаю, русский взять или английский. Английский возьму. Вот, то benchmark называется. А, ну, собственно, надо было посмотреть на нее. то мы видим, что здесь нейросети, которые работают именно на этих принципах. То есть сначала мы учим эмбэдинга, потом мы учим вторую нейросеть, на основе этого эмбэдинга уже решать конкретные задачи. И вот здесь более простые методы, Это с embeddings, просто по словам, не контекстными. Вот он вот в конце списка. Ну а, соответственно, методы, не основанные на нейросетях, основанные на каких-то там правилах, на чего угодно, что напишут программисты, они будут вообще-то на нуле. Потому что тут действительно выбраны уже сложные задачи. Например, сюда входят задачи типа… тут, к сожалению, сложно не посмотреть. Ну вот я про виноград-схема-челлендж. Это когда он поставил чемодан на стол. или нет он уронил чемодан потому что он был скользкий и вопрос кто скользкий чемодан ну и там мужчина уронил чемодан потому что он был скользкий и вопрос кто скользкий мужчина или чемодан но в данном случае ответ не столь однозначен как можно было бы изначально подумать вот но в общем конечно так не говорят что про человека, что он скользкий, говорят, что у него рука скользкая. Поэтому если сказано было именно так, что он скользкий, то, конечно, имелось в виду чемодан. И вот такая задача, на самом деле, она очень сложная, потому что она требует как раз вот эти вот все миллионы правил применять. в начале для того, чтобы понять в каких контекстах слова используются, какие это слова, то есть вот эти выделения, будьте уверены нейросеть внутри проходит вот эти выделения. нейросеть внутри проходит вот эти вот фазы выделения синтаксического анализа в виде как раз внутри embedding все это и семантического анализа, только она это делает сразу с учетом миллиона правил, которые закодированы в нейросети, а не тысячи правил, которые программист закодировал вручную. И в общем-то из эффективных систем мы пока что не знаем ни одной системы альтернативной дипленингу, которая бы позволила решать подобные сложные задачи с таким большим количеством правил. И это правило достаточно универсальное. Тут есть задачи типа чтения фрагмента текста и потом вопроса, что это за человек, про какого человека речь, если упоминается несколько человек. Задача выбора определения пола по фрагменту. с которым зачастую не справляются люди, у которых английский язык не нативный. Они зачастую не справляются, когда там есть подсказки какие-то о том, какой пол у человека. Им надо определить, про какого пола человека В общем, альтернатив пока нет. Но вот сейчас мы поговорим про альтернативы. Какие возникают альтернативы и что люди пытаются делать. Соответственно, мы были рады использовать что-то другое, чтобы построить какой-то альтернативный искусственный интеллект на каких-то других принципах. Но пока что нет даже этой альтернативы, которая бы решила даже какие-то простенькие задачи. Поэтому мы не можем ее обобщить. А вот нейросети при этом, они обобщаются, они действительно обобщаются. За счет большого обучения, прочитал не меньше миллиона книг, но тем не менее оно работает хоть как-то. Разберем альтернативу. Вообще говоря, у нас пока что непонятная ситуация. Если вам удалось сделать более удобную лестницу, это не значит, что вы можете построить лестницу до Луны. Это отлично всегда отражает наш прогресс в области искусственного интеллекта. Мы каждый раз делаем какой-то шаг, но до Луны пока что нам все еще далеко. Но, тем не менее, шаги уже большие. Вот, соответственно, вот это я проговорил еще чуть-чуть, вот я про это уточнил, договорю. Значит, supervisor learning задача. Это значит изначальная задача, когда у нас были метки. И хорошо, когда у нас есть много меток, точнее, самих типов меток мало. примеров данных с метками много, тогда мы можем построить очень хорошие правила, которые будут для этих меток работать. Нейросеть построит правила лучше, чем другие алгоритмы. Но если у нас задача сложнее, например, сразу нам метки неизвестны, то вот здесь возникают проблемы. Для этого есть отличный мем, который я всегда повторяю в такой ситуации. Но можем ли мы сделать то же самое без меток? И здесь предложено было два подхода. Соответственно, Супервайз и Клёнин, когда у нас меток нету, и вот собственно это то, что происходит на первом этапе, сейчас сетей, которые делают супервайзинг Ленин. Они вначале делают он супервайзинг Ленин просто потому, что у нас есть много данных без меток. А потом они учатся и решают уже конкретную задачу, уже имея несколько всего меток. целевых. Например, задачи типа классификации обращений, нейросеть, очень хорошая нейросеть, которая научилась на большом количестве данных без мета, она решает со 100 примеров единиц данных с качеством 80-90%, в то время как в сети без этих данных нужно сотни тысяч единиц данных чтобы решить ту же самую задачу. То есть выигрыш как раз в тысячу раз. И возможно это и есть как раз тот самый механизм, который происходит у человека и который позволяет ему решать практически любую задачу с небольшого числа примеров. Ну очень же просто. Он взял и научился вначале на огромном количестве реальных жизненных примеров. с помощью вот этого self-learning, который на самом деле относится к unsupervised learning, после чего он это unsupervised learning применил, и теперь у нас натренированы есть внутренние embedding в разных отделах мозга, и мы их теперь применяем для того, чтобы очень быстро научиться решать какую-то новую задачу. Нам хватает буквально ограниченного числа примеров. Обычно приводят примеры с изображениями. Кроме того, что нейросети учатся лучше с предтренировкой, они же лучше обучаются и потом, даже при наличии того же количества меток, они все равно учатся лучше. Если распознавание картинок на ImageNet дает вам без предтренировки 75%, то та же самая сетка с предтренировкой на большом количестве других картинок без меток даст уже вам точность 80-85%. То же самое происходит и со звуком. Есть для английского крупный корпус на 60 тысяч часов и нейросеть на нем обученная. Она побивает те очень сложные нейросети, которые годами придумывали люди, когда мы тренируем и доучиваем с метками всего на сотни часов. Она же способна и лучше обобщаться на другие языки. Вот эта тренировка является каким-то вот таким универсальным механизмом, который позволяет как раз нам получать какое-то представление мира, которое потом использовать уже для совершенно разных задач. При том, за счет того, что новых примеров вот здесь много, немного, доучивание небольшое, и поэтому у нас не происходит уже катастрофе к Фаргете. Мы просто все данные, все нейроны не исправляем, мы исправляем только вверху чуть-чуть нейронов для конкретной задачи. Но иногда нам и этого недостаточно, и мы прибегаем к reinforcement learning, когда у нас меток все равно нету даже немного, а есть только в конце. Результаты там наградили нас или поругали. Для этого есть специальные механизмы, но в общем-то сейчас они по большей части сводятся к тому, что мы просто за прошедший интервал времени вводим нейросетки, которые делает супервайзер Леонид Штрафов. То есть если нам сейчас плохо, нас наказали за всю игру, мы проиграли или там не знаю, то мы, значит, за все шаги игры нейросетки говорим, что этот ход был плохой, этот ход плохой, только вот чем дальше, тем говорим он менее плохой был. То есть последний ход, наверное, был наиболее плохой, а перед этим ход был чуть-чуть лучше, но все же плохой, ну и так далее. И вот к этому сводится классический алгоритм reinforcement learning. Есть алгоритм чуть-чуть более продвинутый, которые теперь делают следующее. Они обучают внутреннее понимание качества ситуации. То есть в супервайзе к Леониду нам известно качество ситуации, ход хороший или плохой. То есть мы сами знаем, ход хороший или плохой мы сделали, но просто мы его сделали, а потом только мы поняли, что он плохой. И тем самым мы еще лучше научили нашу сеть мозгу знать, какой ход хороший, какой ход плохой. То есть почему-то она в том случае просто не сработала, но теперь она будет работать лучше. И вот когда мы выделяем для reinforcement learning вот этот модуль качества ситуации, у нас сразу качество reinforcement learning сильно повышается. И у нас получаются алгоритмы типа альфа-зеро и альфа-го, которые выигрывают человека в шахматы, в шашки, в го, в старкрафт. Доту, во что угодно. Правда, обучение для больших игр у нас занимает примерно 100 компьютеров и пару месяцев и 5 миллионов баксов, но в общем-то схема рабочая. И это для каждой задачи. Если у старкрафта с новым патчем чуть-чуть поменялись правила, когда там кто, на какое расстояние может стрелять, то качество вот такой системы просядет, конечно, поэтому надо, конечно, обучать систему на разных версиях старкрафта, на разных играх и так далее. Тогда у нас получится универсальный игрок, который может не так хорошо играть в старкрафт, но будет хорошо уметь играть, хорошо уметь делать что угодно. Таким образом, примерно, это есть гипотеза о том, что подобный алгоритм является каким-то универсальным, и способен заменить человеческий мозг. Ну, конечно, при условии, что кто-то нам пока что будет готовить данные, кто-то нам будет их в правильном виде подавать. И что касается правильного вида, конечно же, нейросеть будет плохо работать, если у нас данные будут подаваться в исходном виде. Поэтому давайте-ка мы на вход этой нейросети будем подавать как раз вот этот тот самый эмбэггинг, из энкодера-декодера, про который мы говорили раньше. То есть мир мы кодируем теперь эмбэдингами и на эмбэдингах мы уже учимся. И в итоге у нас уже получается какая-то универсальная такая архитектура и надо проверить. Возможно наша новая более удобная лестница. способны дотянуться значительно дальше. Не факт, что получится до Луны, конечно, но надо попробовать. Ну вот она очень дорогая такая лестница пока что. Поэтому кто-то работает над тем, чтобы делать более удобные лестницы, а кто-то работает над тем, чтобы те лестницы, которые у нас есть, делать более доступными. И здесь примерно получается достигать сжатия и улучшения в 100 раз, в 10-100 раз с небольшой потерей качества. То есть, если вот этот вот AlphaZero для Go, значит, работал на 100 компьютерах, и на этих 100 компьютерах он, значит, побивал чемпиона мира, то, скорее всего, версия на одном компьютере уже с downscaling на 100 раз, он будет похуже немножко, но среднего специалиста по Go она будет уже выиграла. То есть не любители даже, а уже у хорошего игрока. И то же самое происходит примерно во всех областях, то есть одновременно люди строят более более хорошие технологии и одновременно идет обратный прогресс, когда мы те модели, которые есть, у нас улучшаем и ужимаем. Но вот с ужатием пока что все плохо, особенно плохо пока что с ужатием для текста. Ужатие для текста едва ли ужимается в 10 раз без потери качества. Поэтому вот здесь есть такая вот к человеческому мозгу претензия, что ли, Возможно, что мозг человеческий такой большой, что тебя так сложно повторять на компьютер. Был бы ты поменьше, язык был бы у нас попроще, более регулярный, более простой, мы бы все равно решали свои задачи, возможно, но при этом было бы проще это все повторить. И действительно, если мы говорим про каких-нибудь обезьян или там ворон, то вот ворону удавалось обучить, не знаю, кажется, порядка сотни понятий, так или иначе, вот она способна была понимать, можно было ей передать смысл. Вороны же чуть-чуть могут там и говорить, и действовать по-разному. А у обезьян порядка 600 слов, по-моему, рекорд принадлежит. И обезьянь 650, по-моему, слов она знала. Различала 650 слов и могла их в усеченной форме говорить. Но обезьяны обычно говорят не слова целиком, а только слойно. Потому что им тяжело уже. Потому что речевой аппарат для этого не приспособлен. Поэтому понимать они способны больше, чем говорить обычно. Ну вот тут такая эволюция. Человеку надо было больше говорить, более сложные вещи. Более сложные вещи понимать. И произошла такая эволюция артикуляционного аппарата и мозга. Так, значит, про основного конкурента мы поговорили, да? То есть, да, действительно, более крупные сети действительно генерализуются по доменам. Я все это прошел с распознаванием речи, то есть мы учили распознавание речи, там вот есть два больших домена. Распознавание речи, когда человек у микрофона сидит, там какие-нибудь аудиокниги начитывает, И когда человек через телефон с кем-то разговаривает в более шумном окружении, с плохим качеством связи, пытается чего-то добиться. И другое еще качество звука. И вот нейросеть, обученная на одном домине, она действительно генерализуется на другой. не очень хорошо, правда, но генерализуется. А всего чуть-чуть данных другого домена достаточно, чтобы нейросеть гораздо лучше уже понимала новый домен. То есть происходит одновременно и выучивание меток, и генерализация вот этого внутреннего эмбеддинга, доучивание его для нового представления. То есть новое представление уже учить надо в 10-100 раз меньше. Таким образом, если бы мы третий домен добавили, иностранный язык, нам бы нейросеть тоже не пришлось бы учить с 0, мы бы тоже учили ее меньше. В области NLP сетям скармливают 100 языков, они начинают с каждым новым языком. Мало того, что они новый язык изучают, они еще и старый начинают немножко лучше знать. Ну и новый язык, то есть намного лучше знать, чем если бы с нуля обучали нашему языку. То есть проблема только одна, что если нейросеть у нас размера с GPT-3, то доучивать ее абсолютно нереально, поэтому придумали другой метод, который называется как раз вот этот вот Few Shots Learning, когда нейросети просто ставят задачу дополнить предложение, и в качестве образца дают несколько примеров правильных предложений, как дополнялись. Она на основе того, что миллионы текстов видела, где в виде списков или как-то иначе вот эти вот последовательности данных выражались, она в этом формате, как другие входные данные, ставит нужные данные. У нее нет памяти и невозможно ее научить этой памяти, но есть какие-то вот эти вот эмбэдинги, какая-то часть мозга, условно говоря, есть. Возможно ли другие части мозга с таким же качеством повторить? Увы, не получается, потому что в основном у нас нет такого количества данных. Здесь мы подали все книжки мира и все интернет-страницы. мира и научили. А с другими данными обучения, если мы будем учить, как ребенок учится ходить, учится осознавать мир, то нам потребуется ждать намного больше, чем обучить этого ребенка. Вероятно, ребенок намного раньше пойдет в школу, чем эта сеть чему-то вообще научится. в том плане, что десятилетия и столетия, вероятно. Потому что я убрал вот этот слайд, ну не слайд, вот эту часть, и не говорил про то, что проблема заключается в том, что нейросеть плохо параллелизуется. То есть это же проблема есть и у человеческого мозга. Вам две головы, конечно, лучше, чем одна, но всего лишь немного лучше. Любой менеджер это знает. Когда они решают одну задачу, они работают примерно как один человек, чуть более умный. Зарплату нужно платить уже двоим. 

S05 [01:21:11]  : Юрий, извиняюсь, у вас какой план? То есть мы можем как-то продвинуться к подведению итогов? 

S02 [01:21:20]  : Да, сейчас минут еще, вообще минут 20 изначально еще было. Но если мы не укладываемся, я немножко короче уложусь, еще минут за 10-15. Потому что у нас есть тут несколько конкурентов. Значит, первый конкурент, в общем-то, это технология, основанная на локальных хэшах, которая заключается в том, что мы смоделировали нейросеть мухи, И примерно Хокинс к той же идее пришел, что у нас есть какие-то клетки, которые тоже как-то суммируют сигналы, только это суммирование у них происходит не как у нейросети с обучением, а случайным образом, то есть связи задаются заранее, и тогда в зависимости от данных у нас на этом слое сеток на этом слое сети возникнут какие-то уже неоднородности. То есть у нас автоматическим образом сформируется эмбеддинг. Заметьте, мы ничего не делали, мы вообще не учили сеть, у нее все равно есть эмбеддинги. Эти эмбеддинги работают хуже, конечно, чем одоученные эмбеддинги. Эти эмбеддинги, их нужно больше. То есть, 2000 клеток им соответствует примерно 100 нейронов нейросети. Но, тем не менее, простые задачи – это нейросети. Почему я называю нейросети? Потому что в нейросетях этот метод тоже внедряют. Он называется random projections, случайные проекции или рандомные проекции. Метод случайных проекций. Можно ли делать таким образом многослойные нейронные сети? Ну, вообще говоря, уже многослойный трудновато делать, но, тем не менее, один слой задачу уже решает. Если посмотреть по качеству, то вот задача Amnist, которую нейросеть решает на 99% многослойная и на 90% однослойная, таким алгоритмом решается где-то порядка на 50%. всего лишь таким алгоритмом. Но тут чуть-чуть сложнее, на самом деле, сделано. То есть мы выбираем еще к лучших. И вот ровно то же самое Хокинс говорит в своей работе 2012 года. Quartical Learning Algorithms. Квартикальные алгоритмы обучения. То есть там ровно описана вот эта же технология. То есть она работает плохо, но ее как-то чуть-чуть объединили не с нейросетью, а как-то улучшили ее. Получили точность на уровне 50%. Но на самом деле тут есть еще один подход, который редко когда пробуют. Когда данные такой сети, их надо подавать избыточным образом. То есть надо подавать не один вход каждый раз, а по 10 раз подавать каждый вход. даже по 100, и вот здесь вот у нас клеток не 2000, а миллион, тогда мы приходим как раз к той самой модели, про которую рассказывал Алексей Рядозубов. Да, эта модель, соответственно, работает, она покажет на уровне 80-90 или даже чуть больше процентов, то есть она будет примерно достойна нейросеть более-менее более-менее повторять. Ну, чуть хуже, может, 85-90. Но, соответственно, сюда надо добавлять дообучение, потому что вот эти эмбэдинги, они непонимабельны пока что. Но, тем не менее, эта технология Random Projection сработает. Недостаток лишь в следующем. Вот эта технология требует примерно в 100 раз больше вычислений на текущем железе. Если железо поменять, или как вот Хойкинс сейчас выпустил видео, где они предлагают считать это на FPGA, где вместо полного матричного умножения мы можем оставлять только часть связей, а во-вторых мы можем быстро делать поиск максимальных срабатываний, то он утверждает, что плохую нейросеть, которая плохо решает задачу, которая тестируется, эта технология повторяет, полностью по качеству, но при этом она даже в 5 раз более компактна. То есть здесь мы можем большую часть весов убрать, здесь не так много связи останется, вот эти будут более широкие, но в целом она будет решать 5-10 раз более быстрее. более быстро, на FPGA. То, что плохо по ней Россия справляется. Недостаток то, что обучения нет опять же. Если мы добавляем обучение, добавляем перестраивание вот этих штук, до перестраивания, то здесь начинаются проблемы. Но вот здесь нет этого механизма. Но в целом оно работает. И есть некоторое основание считать, что человеческий мозг даже в общем-то основывается на этой технологии. Проблема только в том, что она в сто раз менее эффективна, когда речь идет про обучение и про повторение этой технологии на обычных компьютерах. Вот такие дела. Но, тем не менее, в некоторых случаях удается, даже получается. Но если мы говорили о том, что нейросеть еще можно в 100 раз сжать, то есть при этом она в 10 раз ускорится, то получится примерно то же самое, что и то же самое по скорости примерно, наверное, и получится. Только проблемы с обучением. То есть, соответственно, если мы построим железяку, которая подобную технологию с перестроением нервных связей делает, то возможно мы просто таким образом повторим человеческий мозг. И как бы ничего сложного здесь не надо. То есть вот части, которые отвечают за распознавание, за построение вот этих вот embeddings мы точно повторим. А для второй части мы всегда можем использовать нейросеть. Ну, в общем-то, там тоже вопрос о том, как эту нейросеть перевести в подобное представление. То есть, возможно, таким образом проблема интеллекта как раз и решится. Но вот недостаток такой, что кремниевые чипы у нас уже есть давно, а вот подобные технологии разрабатывать сложно. И здесь есть две таких технологии. где-то вот здесь две есть в общем есть две попытки первая Первое – это действительно построить чипы, в которых есть реальные нейроны, которые как-то так обучаются. Второй вариант – повторить нейроны уже на других технологиях типа мемристоров. И там можно будет нейрон делать не тысячи транзисторов, а нейрон делать всего лишь пятью-десятью элементами. И это даст нам гораздо большую плотность, потому что данная технология требует большой плотности упаковки, потому что здесь требуется много элементов. И поэтому на FPGA у нас не влезет большая нейросеть, на самые даже крупные. крупные системы и на нейросетевые блоки. Нейросетевые блоки пока что есть на 10 000 нейронов примерно. Одна микросхемка. В то время как искусственная нейросеть гораздо быстрее. Надежда есть на это. Ну а в последней книге Хокинс по сути предлагает свою же систему, предлагает, только теперь он ее пытается уже в виде модульного подхода, пытается уже понять, что делать дальше с этой системой, как ее применять. Пока что разбирается только в модулях карты, как я понял, общая система у него по-прежнему. 

S01 [01:31:16]  : Посмотрим, будем следить. 

S02 [01:31:20]  : Это примерно все, что я хотел вам рассказать про общий искусственный интеллект. Про проблемы, связанные с дипленингом, я кратенько рассказал. Это механизм, когда мы не пытаемся строить какую-то особую систему. для искусственного интеллекта, а пытаемся делать какой-то модульный подход и пытаемся из имеющихся технологий сделать искусственный интеллект. И, в общем-то, если у кого-то есть альтернативные варианты, как сделать не на текущих технологиях общий искусственный интеллект, то, конечно, хотелось бы послушать, но пока что на альтернативных технологиях не получается решать сложные задачи для большого количества правил. получается решать простые задачи. Люди говорят, вот, да, значит, на нашей технологии можно все делать, вот, и мы имеем ровно вот эту проблему, которую я вначале показал, что вот у нас мало данных и вроде бы у нас есть качество лучше, но потом возникают проблемы для более сложных задач. Все, спасибо за внимание. Теперь, значит, вопросы, если есть. 

S05 [01:32:31]  : Юрий, спасибо. Кроме как в самом конце я не видел, чтобы было много вопросов, в основном комментарии. Сейчас давайте я быстренько пробегу. Значит, у меня один первый вопрос был. Вот про то, что Рядозубов 80 процентов, это вы с ним сами общались непосредственно или вы просто… Да, я с ним сам общался. 

S02 [01:32:54]  : Ну то есть я знаю, на каких, скажем так, ту систему на правилах, которые он строил. По ее поводу я общался. Я знаю, в каких местах уже были проблемы. И эти проблемы примерно соответствуют количеству 100 правил. От ста до тысячи правил. Оценка ваша. То есть, это не Рядозубов вам дал эту оценку, а вы, исходя… Да, это оценка… Нет, я… Примерно он и говорил, что тоже у него там порядка, не знаю, тысячи правил. Нет, а про проценты? Про проценты. Про проценты, да, это моя оценка, но дело в том, что я тоже строил подобную систему лет семь назад, шесть. подобную систему на правилах и я оценивал как раз, оценивал какое число, какое примерно качество можно добиться разным количеством правил. То есть я сравнивал разные версии. У меня еще была система вероятности, ну да, у него тоже вероятность. Это когда правила еще, когда мы выбираем, а не не каждый раз выбираем одно из правил, а когда мы выбираем комбинацию правил, которая даст нам наибольшую вероятность парсинга предложения. 

S05 [01:34:22]  : Хорошо, спасибо. Следующий вопрос у меня был. Я задам его, отталкиваясь от того, что мы сами делали на Supervised Language Learning в проекте. И там мы сделали Supervised Language Learning по строениям автоматическим грамматик тремя способами. Один из способов был BERT. Вторым способом был Minimum Splendid Parser. и МСТ-парсер так называемый. И третий способ был вообще некоторая эвристика, которая просто складывала и считала статистику по биграммам. И получилось следующее, что, грубо говоря, если мы берем, считаем статистику по биграммам и потом из этого пытаемся строить грамматические модели, то все обучение занимает полчаса, но accuracy получается 40%. Если мы берем, ну или там 50 неважно, то есть какая-то величина. Если мы берем, считаем Mutual Information и Minimum Spanning Tree Processor прогоняем, то это считается 12 часов и Accuracy там получается на 10% больше. Допустим, было 50, осталось 60. А когда мы берем BERT, то BERT тренируется 2 месяца, а выигрыш получается на 1%. Вот это к чему вопрос? К тому, что, значит, как вы вот этот график совершенно верно вырисовали, значит, как у нас performance. Это performance по accuracy. А что у нас, как у нас дело обстоит с производительностью? То есть, насколько вот, грубо говоря, зелененькая требует больше вычислительных ресурсов, чем красненькая? В три раза или в десять? 

S02 [01:36:19]  : даже в сотни раз бывает больше по ресурсам. Есть алгоритмы, которые требуют по каждому примеру пробегать всего один раз и так далее. нейросеть за счет разбиения вот на две эти фазы, мы получили то, что да, вот первая часть Берта тренируется два месяца, но вторая часть Берта тренируется, вот эта вот, которая нейросеть маленькая уже, которая решающая, она уже тренируется, даже не час, она минуту тренируется, если у вас, например. Это, конечно, зависит от задач. Да, она тренируется больше, но нет экспоненциального роста и отличия. Вместо этого еще очень все зависит от задачи. В таком плане, что задачи бывают разные по сложности. И на простых задачах действительно вот этого выигрыша нет, но расход ресурсов есть большой, то есть для них действительно дата отражает complexity, сложность задач на самом деле. И если вы берете простую задачу типа, не знаю, даже части речи поставлять тексты, то более простые алгоритмы, более простые нейросети, они уже позволяют достигать точности 95-96%, а более сложные наберти дают всего лишь 1% выигрыша. А в каких-то задачах типа нера аналогично. То есть мы можем построить нейросеть, которые быстрее Берта 10-100 раз, другие алгоритмы, которые будут примерно такие же по качеству или чуть хуже всего. Даже вот мы вообще возьмем словарь и тогда у нас будет для задачи поиска городов на скорость там вырастет тысячу раз. Но это все зависит от количества правил. от сложности задачи. То есть, если задача сложная, тогда у нас традиционные алгоритмы начнут качественно ухудшаться. Если у нас задача была простая, то действительно, то мы можем избежать вот этого затраты ресурсов. И когда мы просто не можем, и вот альтернативы нет, соответственно, Чему я всех призываю, когда думать о том, что есть альтернативные какие-то алгоритмы общего искусственного интеллекта, а как у вас на простых задачах хотя бы справляется система. Во-вторых, если вот вы построите график возрастания сложности, ну то есть вдавайте задачи разные по сложности и смотрите, как ваша система с ними справляется. Если вы наблюдаете, что на простых задачах ваша система справляется, это еще ни о чем не говорит. Потому что она вообще потом не будет работать. 

S05 [01:39:23]  : Спасибо. Вопрос от Алекса Бура. За счет чего нейросети умеют решать задачи? В чем фишка? В чем подъемная сила нейросетей? 

S02 [01:39:34]  : Это эмбейдинги. Причем эти эмбейдинги… у нас в курсе нейросети есть простая задача мы берем вот этот вот MNIST и пытаемся его вначале реализовать, решить с помощью простого алгоритма machine learning получаем точность порядка 20% потом мы другой алгоритм не предлагаем, но другой алгоритм какой-нибудь предлагаем machine learning получаем точность, допустим, 50% Потом применяем нейросеть и получаем 80-90% на сольную нейросеть. На многослойных получаем 98-99%. Теперь мы вот этот вот эмбеддинг Он для задачи распознавания вот этих цифр 10 простой. Но теперь, если мы посмотрим, что вот эта сложная нейросеть выучила, она выучила у нас уже какую-то иерархию фич. И именно backward propagation нейросети позволила ей выучить эту иерархию фич. То есть эмбеддингов одного уровня нам не хватило, хоть нейросети училась наилучшим образом. а эмбеддинги с пяти уровней уже выучили задачу хорошо. Соответственно, вот эти вот эмбеддинги, когда друг на друга наслаиваются, они позволяют нам как раз решать более сложную задачу. Именно вот это и метод backpropagation, который позволяет эффективно эти эмбеддинги друг с другом сопрягать и учить, это и есть подъемная сила нейросети. У альтернативных методов, например у Кокинса, пока что придуман метод, которым мы можем без учителя на примерах выучиться решать первую часть задачи, вот эмбеддинг одного слоя. Для эмбеддинга нескольких слоев тоже придумано решение, а более трудозатратные на классических компьютерах, возможно. То есть, возможно, это общая схема, то есть она характерна не только для нейросетей и как раз это общее решение любой проблемы, что такие строители многоуровневые были. Но для нейросетей, безусловно, backward propagation как наиболее эффективный способ построения вот этого многослойного комбайнинга, это их как раз подъемные силы. 

S05 [01:42:07]  : Спасибо. Вопрос от Александра Соколова. А почему вы говорите здесь об обучении, а не о запоминании? Я, честно говоря, не понял вопрос. 

S02 [01:42:17]  : Вот как раз если мы говорим про генерализацию, то вот мы понимаем, что между обучением и запоминанием разницы нет. Если нейросеть генерализуема, то есть вот эти вот embeddings у нас сформировались многослойные, то они не только одну задачу умеют решать, но и другие косвенно тоже научились решать. Например, в нейросетях для зрения вначале выделяются те же палочки, что и у человеческого мозга на первом слое и так далее. На втором слое уже какие-то кусочки лица условные и так далее. 

S05 [01:42:55]  : Спасибо. А вот здесь есть комментарии, которые я бы сформулировал как вопрос. Вы согласитесь с тем, что метод обратного распространения ошибки моделирует работу дофаминного контура мозга при формировании условных рефлексов? 

S02 [01:43:09]  : Нет, я с этим не согласен, потому что такого биологического механизма пока что никто не нашел. То есть о чем можно говорить вместо этого? Можно говорить о том, что А в мозге есть модули, которые учатся без обратного распространения ошибок, но дофаминовый механизм говорит, какому модулю сейчас доучиваться, а какому не доучиваться. Как раз ровно о том, как вы на схеме рисовали про глобальный фидбэк, про локальный глобальный фидбэк. 

S05 [01:43:43]  : Вопрос снова от Александра Соколова. Вы учите нейросеть запоминать? 

S02 [01:43:53]  : Мы учим нейросеть запоминать, и на основании этого она потом решает задачи. Но, конечно, задачи бывают разные, разных планов. И, возможно, для задач плана сознательно нужен какой-нибудь другой алгоритм. который используется в reinforcement learning, там же не просто нейросеть запоминает, а над ней есть какая-то конструкция. Иногда конструируют несколько нейросетей в какую-то конструкцию. И вот эта конструкция — это не просто одна нейронная сеть, у нее уже другие свойства. В случае с альфа-зеро там есть еще перебор, обычный переборный алгоритм. То есть это уже не нейросетевой алгоритм. Но этот перебор основывается на той информации, которую дает нейросеть. Нейросеть оценивает, какой ход хороший, какой плохой. А дальше мы уже перебираем вглубь ходы и выбираем тот ход, который даст нам наибольший результат через 5 ходов. 

S05 [01:45:01]  : От Евгения Витяева вопрос. Даже кошка, зайдя в новую комнату, в первую очередь обследует эту комнату, используя небольшое множество данных, а потом уже действует в ней уверенно. Нейронные сети так могут? 

S01 [01:45:22]  : Но у меня на самом деле более общий вопрос. А нейронные сети вообще способны создавать некоторые модели объектов, модели окружения, модели образа мира, то есть действовать на основании моделей, а не на основании правил? 

S02 [01:45:36]  : Да, сейчас как раз горячая тема как раз вот это вот world-based reinforcement learning. Это reinforcement learning, а нейронные сети и deep learning. Реинфорсмент ленин при этом использует нейронные сети. 

S01 [01:45:55]  : А дипленинг? 

S02 [01:45:57]  : Дипленинг – это технология нейронных сетей, так и называется дипленинг. 

S01 [01:46:02]  : Я понимаю, что это технология нейронных сетей. Они образы и модели объекта строят? 

S02 [01:46:08]  : Если способы использования нейронных сетей рассматривать, то у нас получится supervised learning, unsupervised learning и reinforcement learning. Это типичные способы. То есть задача метрик леарнинг, вот Ходосямские вот эти вот сети, она скорее тоже unsupervised леарнинг относится. Соответственно, world-based reinforcement learning, мы используем нейронные сети, но используем их своеобразно используем, то есть используем предсказание нейросети по тому, как действовать в данной ситуации, и на основании него уже с перебором или без перебора принимаем решение. А нейросеть основывается на какой-то модели мира. Например, в Старкрафте в качестве модели мира используется карта, которую видит робот-миникарта, и используется для каждого юнита, который есть там характеристики его жизни, то в каких координатах он находится, что он делает и так далее. 

S01 [01:47:15]  : Но каждый ему дается или он сам внутри себя ее строит? 

S02 [01:47:20]  : Можно было бы строить, в этом плане авторов вот этого решения, которое побивает людей StarCraft обвиняют в нечестной игре. Там было два нюанса. Первый нюанс был в том, что мини-карта у них подавалась поначалу вся, и он мог видеть то, что происходит в другом месте карты, а человек этого не видел. Но они потом научили версию, где компьютер видит только ту часть мини-карты, которую человек видит. И там нейросеть используется с внутренним запоминанием прошлых ходов. И эта нейросеть сама переключается по участкам миникарты, она их сама запоминает, где что происходит, и переключается между теми местами карты, где там происходит сражение, где строить надо сама. То есть она построила такую модель мира, которая позволяет ей помнить, где что происходит, где что надо проконтролировать, где что надо сделать. 

S01 [01:48:15]  : Да, хорошо, что это нейронная сеть, но это не диплеонинг. 

S02 [01:48:18]  : Диплеонинг – это другая технология. Ну как это другая? Диплеонинг – это общее название для всех технологий с нейронными сетями. Да. Гипплеомин, потому что многослойная нейронная сеть, поэтому она называется ГИП. Вот и все. 

S05 [01:48:36]  : Ну ладно, понятно. Спасибо. Юрий, еще вопрос о нейронных сетях. 

S03 [01:48:42]  : Момент. Все-таки давайте не запутываться. Добрый вечер. Дипленинг относится не только к нейронным сетям. Нейронные сети это как бы алгоритма, и дипленингом и глубокой нейронной сетью принято называть, когда у этой сети много слоев, и за счет этой послойной структуры в каких-то глубоких слоях появляются как раз то, что вы называете имбединги, то есть некоторые Не только нейронные сети, просто вы немножко сужаете. 

S02 [01:49:16]  : Согласен, тут есть один нюанс, не совсем нейронные сети, Но все же, пожалуй, консенсус сошелся на том, что алгоритм backpropagation для технологии дипленинг все-таки, наверное, нужен. То есть, когда делить, проводить вот эту границу, где дипленинг, где не дипленинг, тут вопрос именно многослойность, но вопрос, останется ли обратное распространение ошибки или алгоритм без обратного распространения ошибки тоже называть дипленинг. И вот тут вот на самом деле непонятно. То есть разные исследователи называют по-разному. Кто-то обобщает так, что любые многослойные технологии. Кто-то обобщает, что те с обратным распространением ошибок. А если мы оставляем обратное распространение ошибок, то кроме нейросетей там останется несколько альтернативных механизмов, которые, в общем-то, тоже можно назвать модифицированными нейросетями. Вот. Ну, очень близки. Ну да, альтернатива. То есть, например, мы можем брать вот этот Каминс на выходе и действительно все будет так же работать, как Хокинс показывает, что в этом случае у нас робостность сети, робостность вырастет, то есть она будет более устойчива к помехам и к шумам. Вот называть ли это уже нейросеть, у которой на выходе стоит Каминс, называть ли это уже нейросетью, это уже тоже вопрос. Если это нейросеть, тогда кучу других технологий тоже можно назвать нейросетями. Конечно, понятно. Вот эта граница действительно нечеткая, здесь немножко неправда. Всего лишь немножко, мне кажется. 

S05 [01:51:07]  : Спасибо. Вопрос, объединённый от нас с Игорем Пивоваровым. Исходя из того, что вы сказали, лично ваше мнение, что нам нужно для того, чтобы сделать прорыв в области, в сторону EGI, либо нам нужно всё-таки подождать, когда у нас появится более мощное железо, чтобы на нём выполнять более большие или более хорошо построенные нейронные сети глубокие, либо все-таки нам нужен какой-то новый неизвестный пока алгоритмический подход, который может быть даже на существующем железе или там гораздо более скромном железе, чем есть сейчас, позволит решать вот те проблемы, которые мы пока не можем решить лучше, чем это делать. 

S02 [01:51:52]  : Значит так, если какой-то альтернативный подход есть, то его никто даже не запатентовал. В том плане, что подходов без обратного распространения ошибки, их много, но никому не удалось пока что на сложных задачах показать, что они сравнимы хотя бы с теплёными. То есть здесь мы ожидаем конкурентов в этой области, ожидаем в том числе Хокинса с его новой итерацией, алгоритмом. Но вот пока что непонятно. Поэтому нам остается единственное. Остается ставить пока что на нейронные сети. И нейронные сети, тут движение в двух направлениях происходит одновременно. Кто-то делает более крупные нейронные сети, но там железо растет. Пока что есть задел железный, и мы можем примерно в два раза улучшать железо. То есть само железо улучшает 100% на 10-20, но мы можем более эффективно его упаковывать для дипленинга, поэтому получается как будто бы мы его в два раза увеличиваем каждый год. Но это скоро остановится. Эта ситуация скоро закончится, потому что мы уже близки. Второй вариант – параллелизовать. Если параллелизовать вычисления, то можно действительно, и этим занимаются последние пять лет, можно научить более крупные нейросети. Но здесь есть два лимита. Первый – поскольку нейросеть, нейросетевое движение, вот это вот, слои друг по другу подстраиваются и подстраиваются под данные. Когда данных много, сразу подается, они подстраиваются медленнее. Поэтому за счет параллелизма, когда мы пытаемся больше данных одновременно параллельно градиентным подходом продвигать, у нас обучение происходит медленнее. Но для больших задач не так медленнее, как для маленьких задач. То есть для маленьких задач, типа распознавание речи, Батч сделать порядка сотни или тысячи единиц звука, это уже примерно предел. Тем более для классификации звуков вообще делают еще меньше батч. Где-то там сотни, тогда оно работает лучше всего. Но если у нас несколько ведюшек, нам хочется на каждой ведюшке, чтобы было по сотне батч, потому что иначе ведюшка начинает медленно считать. Мы этот батч увеличиваем, а скорость падает, поэтому падает общая скорость обучения. И, соответственно, тысяча видюшек, раз в десять медленнее, наверное, работает, чем одна видюшка, на больших задачах. Большие задачи типа текстовых, где параллельно можно разные слова учить языка. Если на картинках это хуже параллелится, но на текстах параллели до миллиона в батче элементов, на картинках десятки тысяч параллелят. На звуке больше тысячи уже тяжело параллелит. Соответственно, здесь тоже ограниченный рост возможен. Соответственно, одна железяка у нас не улучшается, скоро перестанет улучшаться. Количество железяк мы тоже не можем сделать больше, потому что это тупо дорого. 1 Ватт железяки стоит деньги. Раз в 10 мы еще скорость увеличим и все. Придется искать какие-то другие способы или же мы вдруг построим Искусственный интеллект, который начнет самообучаться и начнет строить более компактные решения, подбирать правила более эффективно, чем люди, на порядке более эффективно, чем люди. Причем он будет это делать индивидуально для каждой задачи, но все равно будет это делать очень эффективно. И это будет альтернативный подход. Как раз Евгений Щитяев предлагает подобный способ обучения правилам, который позволяет действительно более эффективно выучить правила, чем нейронные сети. Только как бы нам вот этот подход теперь отскейлить нормально на большие объемы параллельно обучаемых правил и одновременно обучение распознавать правильные действия в шумной обстановке. Подходы, в принципе, есть, которые эффективность раз в сто действительно поднимают по сравнению с нейронными сетями. Надо, чтобы они большие задачи еще решали. Вот тогда есть шанс. Ну а с нейросетями, берут нейросеть, у которой есть все связи, потом у нее 90 или 100 процентов, 99 процентов, извините, связи обрезают, оставляют вот этот один процент, она в качестве теряет один или два процента. Ну, чуть-чуть еще там доделывают. Оптимизируют это, значит, чтобы оно считалось не на флоатах, а на интах. За счет этого еще там в пару раз скорость выделяют. И таким образом получают там от 10 до 100 раз рост по сравнению с изначальной нейросети. То есть при обучении, для обучения тоже есть подобный способ на бинаризованных весах учиться. Просто он пока что обычно работает хуже, чем хотя бы на 8-битных весах. Но теоретически можем даже бинаризовать веса, как предлагают в разреженных сетях это делать. За счет этого теоретически мы можем уменьшить раз в 100 требования к железу. Но это, пожалуй, тоже предел. 

S05 [01:57:58]  : Спасибо. Еще последний вопрос от меня. Просьба компактно ответить, чтобы осталось другим вопрошающим. Вот, значит, по поводу transfer learning и interpretability, explainability. Можете ваше отношение рассказать? Во-первых, нужен ли нам транспорт learning, как говорит товарищ Лекун? Или мы без него можем обойтись? Если нужен, то какой? И интерпретабилити, эксплэнабилити. То есть, нужно ли оно? И вообще, оно возможно или нет? 

S02 [01:58:32]  : Давайте по первому вопросу скажу. В общем-то, по первому вопросу я вот как раз рассказывал, как оно работает. Да, когда мы решаем одну задачу, натренировали embedding вместе с нейронной сетью, мы можем оставить вот этот вот декодер под новую задачу, тогда это будет у нас transfer learning называться. мы можем кусок этого декодера или весь декодер выбросить, оставить только embedding, тогда это тоже будет называться transfer learning на самом деле. Таким образом, действительно, этот способ позволяет затрачивать. Вот эту задачу, если на обучение нейросети требуется в 100 раз больше ресурсов, нежели на ее дальнейшее сжатое, уже в сжатом виде использования, то, соответственно, мы здесь экономим коэффициент 100 только на этом. И экономим еще на том, что за счет этого эмбэдинга нам нужно в 100 раз меньше данных. Соответственно, есть надежда, что мы примерно до уровня человека дойдем, и что в человеке все дело просто очень хорошо на тренированных эмбэдингах в разных зонах мозга. 

S05 [01:59:52]  : То есть по transfer learning вы поднимаете просто передачу имбидингов, да? 

S02 [01:59:59]  : Нет, не просто эмбеддинг, а эмбеддинг вместе с куском сетки, конечно. Но эмбеддинги здесь есть на разных слоях. На самом деле этих эмбеддингов здесь штук 10 на каждом слое, здесь их штук 10 на каждом слое. Какие эмбеддинги мы возьмем, от этого тоже зависит, как новая задача решится. На каком слое мы нейросеть отрежем и новую голову присобачим. 

S05 [02:00:27]  : Хорошо, ну а интерпретабилити и экспланабилити тогда? 

S02 [02:00:31]  : Интерпретабилити и экспланабилити у любой системы, основанной на правилах, есть проблемы с воспроизводством этих правил. То есть, если задача у нас этих правил нужных миллионы построить, то да, нейросеть какие-то правила построит лишние, но, к сожалению, нет ни одного эффективного алгоритма эти правила, убрать ненужные правила и оставить только нужные. То есть эти правила, они не по порядку идут. Если мы нейросеть по виду правил проведем, то есть примерно так тысяча нейронов у нас на слое, а тысяча нейронов одного слоя соединяются с тысячей нейронов на другом слое, значит это у нас получается миллион связей. Это миллион правил. Если сумма x1 плюс x5 плюс x10 больше определенной величины, тогда делать то-то. Но больше я упрощаю добинаризацию. Если больше, то там результат один, если меньше, то результат другой. Можно считать. И вот это вот набор правил, то есть получается, что в реальных нейросетях этих правил порядка 100 миллионов. С помощью прунинга мы чуть-чуть ухудшаем качество сети, от них 99% правил избавляемся, все равно у нас остается больше миллиона правил. Какие-то из этих правил, да, неправильно нейросеть в каких-то частных случаях что-то неправильно делает. Какие-то основные правила, наоборот, они естественные и есть куча работ, которые изучают эти правила и показывают, что они действительно похожи на правила, которые действительно нужны в данной ситуации. Но у нас нету какого-то искусственного интеллекта пока что, который бы эти 10 миллионов правил перебрал и оставил бы из них тысячу, которые там дальше бы очень хорошо работал, там все остальные бы убрал и переписал бы их в таком виде, который бы был принимабелен человеку. И человек тоже с этой задачей не справится. Поэтому вот что есть, то есть. И то же самое происходит с любым абсолютно алгоритмом. То есть это вот алгоритм построить сто миллионов правил, а потом убрать не нужно. работает намного лучше пока что, чем алгоритмы, которые правила добавляют по одному. То есть есть подходы, которые на нейросетях также делают, то есть которые на нейросетях добавляют нейроны со временем, добавляют слои со временем и таким образом обучают. Но эти алгоритмы просто менее эффективны, они достигают того же самого, но тратят просто больше сил. 

S05 [02:03:25]  : Так вот у нас есть два вопроса и комментарии от Игоря Пивоварова. Значит первый вопрос еще остался от Владимира Смолина. Не знаю насколько он содержательный скорее. личного характера. Юрий, понятно, что вы сегодня ставили свои задачи сделать обзор ситуации. А вы можете на двух словах сказать про свои собственные разработки? Что вы сами делаете в области AGI и какие у вас планы и перспективы? 

S02 [02:03:59]  : Смотрите, прямо сейчас я не могу сказать, что я что-то делаю конкретное. У меня были несколько разработок, несколько попыток. Я обучал, например, систему распознавания речи, которая показывает результат в топ-5 систем на русском языке. попадает каким-то там подзадачам и в топ-1 попадает. Соответственно, это вот как пример задачи большой уже, которая решается с нейронными сетями, где альтернативные подходы как раз не сработали. никак не работает. Как пример, задач поменьше. Я регулярно работаю со всякими NLP задачами. Я решаю задачи, например, сейчас работаю, занимаюсь работой с документами. В этих документах нужно выделять всякие разные разные элементы, начиная с дат и заканчивая какими-то сложными. И там приходится применять комплекс разных всяких методов, и нейросетевых, и не нейросетевых, как раз с целью обеспечить и качество высокое, и высокую скорость работы. и устойчивость к ошибкам еще. Ну вот, в общем, если добавить еще устойчивость к ошибкам, то есть допустить то, что на входе текст немножко поковерканный, плохого качества, то сразу все технологии, основанные на правилах обычных, перестают справляться нормально. И остаются только нейронные сети. Если же мы решаем какие-то задачи попроще, даты можно регулярными выражениями разбирать или адреса на 95% решать регулярными выражениями. 

S05 [02:06:16]  : Спасибо. Как вы отнесетесь к предложению Николая Бадулина строить AGI как комплекс из нейросетей разной топологии и плотности для разного уровня задач? 

S02 [02:06:30]  : Да, я за этот подход, потому что я просто не вижу альтернатив. Более того, берутся нейросети для разных блоков и еще каким-то образом добавляются туда и нейросетевые и другие альтернативные механизмы, например, так как в reinforcement learning сделано, сверху какие-то другие альтернативные механизмы, которые этой нейросети вместе скрепляют. Пока что здесь происходит борьба между двумя типами людей. Первые считают, что уровень хозяина должен быть тоже нейросетью, то есть нейросеть должна рулить другими нейросетями. А другой тип людей говорит, что это должны быть классические модули, и данные должны внутри передаваться в виде каких-то понятий, каких-то символьных структур. символьно-понятийных, а нейросети должны уже работать с конкретным вводом-выводом, с чем-то там еще. Так это и объединяет средину системы. Но пока что без нейросети в любом случае не обойтись. 

S00 [02:07:53]  : Я немножко, если позволите, прокомментирую. Вот у меня дочь обучается дизайну. Вначале она делает эскиз, берет карандаш и рисует. Потом она берет, допустим, краски, расцвечивает. Затем она садится за компьютер и начинает по пиксельной или векторной диаграмме рисовать картинку. То есть я вам описал фактически обратную задачу к той задаче поиска, которую вы идете от пикселов. то есть объединяя попиксельно в какие-то палочки, потом кружочки, потом цвета присваивая, и вытаскивая смыслы из пикселов. Так вот, с моей точки зрения, я занимался методом конечных элементов. Мы всегда строили в начале узлы. потом их соединяли дугами, какими-то сегментами, потом на них навешивали массу, то есть смыслы навешивали. Я пришел давно уже к выводу, что типология вот этих навесок, она ограничена. Понимаете? Вот, ну, законы физики, возьмите, их там определенное ограниченное количество. Когда вы распознаете текст, вот есть такой тест шикарный, там первая буква написана в слове, вторая и последняя, а внутри написана всякая фигня. А мы понимаем, что написано в этом тексте. То есть нужны какие-то опорные базовые вещи, потом эти базовые вещи должны заменяться некими связями, а потом смысл навешиваться. Когда вы анализ ведете, надо в обратном направлении, в начале смыслы, ну вы же вот правильно говорите, вы анализируете текст, вы же анализируете зрение в тексте. 

S02 [02:09:44]  : Да, а теперь вот давайте я вам расскажу, как устроена нейросеть внутри для NLP. модель Transformer, на которой как раз основывается последний прогресс. Значит, грубо говоря, пусть 10 слоев, 20, не знаю. Значит, на первом слое у нас неростевое представление первого слова в первой ячейке, во второй ячейке неростевое представление второго слова, потом третьего слова, четвертого, пятого, шестого и так далее. Итак, представление всех слов предложения. На втором слое нейросеть смотрит уже результаты первого слоя по каждому слову и более того, она эти связи от каждого слова к каждому простраивает. и просчитывает. То есть мы получаем, что у нас действительно строится эта вот иерархическая модель, но она строится как раз внутренним образом в нейросети, то есть мы ее не контролируем, но тем не менее выясняется, Это модель, если взять из нее первые несколько слоев, они хорошо решают задачи, определение части речи и так далее, то есть какие-то более простые задачи. Значит, если взять слои с десятого начиная, то она уже максимально ориентирована на то, чтобы решать задачи как раз прикрепления слов друг к другу синтаксического анализа. Но при этом они внутри содержат как раз и вот эти вот свойства, а внутренние другие, то есть они их не теряют. То есть вот эти вот эмбейдинги, они как раз вот эта вот модель эскиза и всего прочего, они как раз в каком-то плане повторяют для предложения. вначале строят упрощенное понимание, что каждое слово значит в предложении, потом более сложное понимание, что каждое слово в предложении значит, потом еще более сложное. Если мы можем заглядывать в этот embedding, мы можем для него построить нейросети, интерпретирующую. которая будет как раз решать вот эту задачу на выходе, строить синтаксический анализ или морфологический анализ, или семантический какой-то анализ, или решать уже какую-то целевую задачу на основе вот этой информации. То есть ровно это же и происходит. А в другом мире, в мире RL, reinforcement learning, популярностью пользуется горячая тема не только model-based, но и иерархический REL, когда у нас есть два модуля REL, две нейросети. Первая нейросеть делает какое-то там тактическое, какие-то такие тактические действия, а над ней есть вторая нейросеть, которая осуществляет что-то типа стратегического руководства. И если посмотреть уже, что выучивают, нейросеть пониже, нейросеть повыше, то как раз они примерно и выучивают, опять же, вот это иерархическое представление задачи, как на текущие дела. И, соответственно, у той нейросети, которая ниже, там в эмбэггингах и будут какие-то более практические вещи, типа «двинуть рукой», «двигать ногой». А у нейросети выше будет что-то типа «прийти в такую-то ячейку», «к тому-то», значит, и так далее. И графически РЛ тоже как раз использует такую стратегию. Ну и в целом как раз очень хорошо такую модель использовать. Дальше есть еще третье применение. То есть у человека же эти модели все еще развернуты по времени. Просто когда мы распознаем картинки, да, но мы за неделю там кое-как можем на нескольких видюшках научить модель картинок. Хорошую, очень хорошую. Когда дело касается видео, нам надо еще и в сто раз больше этих картинок. И уже время становится большое. Поэтому пока что с этим тяжело. Но, тем не менее, есть подходы, два альтернативных подхода. Один подход, который так же, как мозг строит эмбеддинги, который зависит от эмбеддинга прошлого во времени. И другой подход, который не зависит от эмбеддинга прошлого во времени, а просто работает как будто бы прошлого эмбеддинга у нас не было. То есть строит, независимо решает для каждого кадра проблему. И вот дело в том, что показано, что эти два подхода эквивалентны в общем-то, только в некоторых случаях первый учить проще. а в каких-то случаях второй учить проще. Ну, конечно, если у нас у нейросети, ей не поступает какой-то внутренней информации, которая там от даты зависит. То есть, если мы в нейросеть подаем просто информацию о 100 последних единицах данных, то это эквивалентно тому, что нейросеть 100 раз сама запоминает эти данные. Ну и как-то это вместе. То есть оба подхода работают, но первый несколько раз проще обычно учить, когда мы ей сразу подаем 100 единиц данных. Поэтому второй подход редко уже в последнее время используется. То есть они называются как раз convolutional neural networks и recurrent neural networks. И проблема, то есть recurrent, конечно, больше похоже на мозг, Но их тяжелее учить, они склонны… Извините, можно я, так сказать, чтобы нам вписаться? Извините, я вас не слышу сейчас, но это у меня проблемы со звуком. 

S05 [02:16:02]  : Да, Юрий, слышно меня? 

S02 [02:16:03]  : Сейчас я по этому договорю, давайте уж. 30 секунд то, что я хотел сказать про иерархию, а потом мы вернемся к тому, что… переключил на колонки но надеюсь сейчас понять не будет сейчас надеюсь он переключится так 30 секунд, что я хотел сказать. Есть подход как раз для рекуррента нейронных сетей, который заключается в том, что на разные слои подаются не все данные, а только данные каких-то промежуточных моментов времени. И этот подход как раз тоже позволяет учить разные эмбеддинги. Эмбеддинги, которым подается каждый кадр, они выучивают какие-то более конкретные вещи. А те эмбеддинги, которым подается информация больше, более протяженных интервалов времени, им проще выучить долгие зависимости. Это общая проблема выучивания долгих зависимостей, которая таким образом как-то частично решается. Это третья аналогия с эскизом и постепенным построением. То есть эскизы и реализация более детально и менее детально развернуты по времени, которые выучиваются за счет подачи разных данных. 

S05 [02:17:44]  : Спасибо. Вот короткий вопрос еще, мне кажется, важный от Ивана Родина. Скажите, у вас есть какие-то известные решения по multimodal learning? Мультимодальное обучение? 

S02 [02:18:01]  : По multimodal learning есть решение, когда по картинкам учат тексты и по текстам учат картинки. И вот тут, кстати, хотелось бы идею Романа Душкина прокомментировать чуть-чуть совсем. То есть это известная проблема как раз в multimodal learning, из-за которой его редко пока что используют. Это то, что когда мы учим, там на столе стоит чашка, то он отдельно учит образ чашки, образ стола. Вот интерпретация нормальной для объединения чашки и стол, вот с этим обучением пока что плоховато. То есть оно обучается и возможно на видео оно бы обучилось лучше. но пока что она обучается плоховато. Поэтому, когда говорят, что найди человека с сотовым телефоном, она ищет человека, рядом с которым у другого человека в руке сотовый телефон. Это очень типичная проблема, и это именно проблема multimodal learning, когда у нас мало данных. Возможно, если бы было больше данных, они были бы более то было бы лучше, но пока что вот поэтому учат одномодальные сети и вот пока что нормальных связывать не умеют. То есть учат нейросети для перевода из одного пространства в другое. У них вот такие проблемы очень часто наблюдаются. Роман хотел учить, чтобы нейросеть интерпретация находила там шляпку гриба. Если в кадре несколько грибов для интерпретации решения по одному грибу, она, скорее всего, будет находить шляпку какого-нибудь другого гриба. И вот передача вот этого, из текстового представления, уже нету этой информации, текстового представления о том, про какой гриб речь. Но если мы туда добавим информацию о том, про какой гриб речь, а гриба слева, например, то я приводил ссылку на работу, где как раз показывал, что нейросети такое, конечно, выучивают. Но надо нам весь текст, который есть, каждой пометке сделать, что вот этот гриб был слева, про него речь. Тогда нейросети более хорошие закономерности выучат. То есть пока что вот эта проблема наблюдается. Пока у нас хорошего ввода данных нет из человеческого мира в компьютерный мир, то все плохо. с обучением внутри. Если у нас появится какой-то способ. В связи с этим, да, хотел сказать, что очень большой прогресс был достигнут еще очень интересным трюком. Мы берем большую нейросеть. Эта нейросеть учится, вначале тренируется, учится всему. А потом мы из этой нейросети просто даем ей данные на разметку, обучаем ее конкретные задачи, а потом даем данные на разметку. На основании этой разметки мы учим вторую уже маленькую нейросеть. Так вот, эта вторая маленькая нейросеть показывает результат они зачастую не намного хуже, чем большая нейросеть. При этом она работает быстрее и компактнее, чем пруниная большая нейросеть. Но при этом мы можем накормить ее большим количеством данных, которые было не достигнуть вручную. Потому что мы использовали небольшое количество данных и использовали трансферлер. Таким образом, например, на том же синтаксическом анализе, где доступно 100 тысяч единиц данных, мы можем натренировать нейросеть поменьше на основе нейросети побольше, которые скормили 100 тысяч данных, и при этом получим результат Лучше, чем бы мы просто маленькую нейросеть на этих данных накормили, и лучше, чем большую нейросеть на этих данных накормили бы по общему соотношению производительности и скорости. Спасибо. Игорь, вам слово. 

S03 [02:22:47]  : Добрый вечер еще раз. Я хотел сказать такую вещь, Илью. Спасибо, что вы сделали попытку сделать такой обзор. На мой взгляд, вы сильно свалились в частное обсуждение нейросетей, что обидно. люди делятся, на мой взгляд, с точки зрения категоризации исследователей или типа мышления на тех, кто придумывает новые модели или инструменты, на тех, кто их развивает и на тех, кто их активно использует. Все-таки, когда мы говорим про подходы и про разные способы. Нужно больше концентрироваться не на том, что сейчас активно используется, а на том, что... на том, наоборот, чего оно не делает. И искать способы, как делать то, что оно не делает. И по поводу нейросетей я вам еще скажу. ну как физик, теоретик, учившийся биофизике, нейросетями занимающийся с середины 80-х годов, нет, 90-х. то, что я приврал, в середине 90-х годов. Нейросеть в сегодняшнем виде, как мы ее используем, это просто модель зрительной коры. Серьезные улучшения, которые, ну, сперва были пресектроны, потом серьезные улучшения, которые Ликун сделал с этими Convolutional Networks, это просто содрано со зрительной корой. Поэтому, которая сейчас прекрасно используется, Они прекрасно решают задачи распознавания, классификации, потому что они сняты с того кусочка мозга, который блестяще это делает. Точка. На этом точка большая. Все остальное, безусловно, они делать не умеют, потому что они не для этого создавались. В мозгу задачи поведения, мотивации, постановки целей, планирования, совершенно другие структуры используют. И я, честно говоря, с большим разочарованием смотрю на людей, которые берут работающую в одном домене модель и пытаются ее во все возможные домены приспособить. Ну, как бы, смотреть-то на это можно, но доклад про это делать нам это прямо не стоит. Просить безусловно замечательный инструмент, замечательный для своих задач. Молоток это замечательный инструмент. Крайне сомнительно с помощью него исследовать звездное пространство. Сомнительно, хотя он прекрасный инструмент для своих задач. Тезис мой такой. Не нужно все сводить к нейросетям. Это хороший инструмент. Мы как сообщество, здесь собираются люди в этом чате, которым всем не надо рассказывать про такое, что нейросети. И прекрасно понимаем, где их ограничения лежат. Интересно слушать про то, где лежат гонимцы. не работают эти существующие архитектуры, что можно сделать по-другому. В этом плане есть модели другие, например, то, что делает Евгений Евгеньевич Витяев. На самом деле не так уж и мало разных других подходов. Другой вопрос, что действительно пока не хватает сильных вычислительных ресурсов и прочего. Но я вас призываю к тому, чтобы шире посмотреть на эту картинку. Раз вы этот доклад будете еще делать потом на AI Journey, я надеюсь, что вы его там переработаете, но просто не упирайтесь в нейросети, это определенный класс алгоритмов, у которого есть область применения своя, в рамках которой он работает хорошо, но на этом все. И большинство людей, я вам так скажу, я как физик, как человек изучающий мозг достаточно давно, стопроцентно вам скажу, что нейросеть в сегодняшнем виде, то что принято называть нейросетями, Невозможно задать какую-то мотивацию целенаправленное поведение. В сегодняшней модели нет ничего для этого. Ноль. Понимаете? Ноль. это сделать можно, долго, гигантскими ресурсами, как есть у Google, IBM, строить модели нейрона, там не знаю, если денег много, то нужно. Но мы здесь должны быть про другое. Мой поинт, что мы здесь как сообщество пытаемся, ну как бы обсуждать какие-то альтернативные истории. Вот Это именно комментарий, потому что он такой… не в порядке критики, а в порядке точки зрения. Нужно попробовать разные позиции занимать. Вы очень глубоко погружены в этот нейросетевый мир. Мне кажется, это вам не идет на пользу. 

S02 [02:28:02]  : Вы зря так считаете. Давайте я уже отвечу. Во-первых, я считаю, что про нейросети поговорить нужно было, потому что никто про это до сих пор не поговорил. Во-вторых, про ограничения нейросетей я прекрасно и очень много рассказал. В-третьих, во многих местах, где нейросети с чем-то не справляются, я вам честно сказал, что альтернативных моделей, которые бы с этим справлялись, просто нет. Я бы рад был упомянуть альтернативные модели для решения других сложных задач, а не прототипы, которые вроде как работают, но чуть поглубже не работают. 

S03 [02:28:56]  : Не согласен. Вы опираетесь на публикации, на то, что известно. 

S02 [02:29:05]  : Смотрите, для решения некоторых конкретных ситуаций я сам строю альтернативные модели. Я не пользуюсь готовым. Я временами нейросети как-то изменяю, соединяю с другими. классические машинленинг методы я тоже использую. Я очень хорошо знаю ландшафт методов для решения разной задачи. Я допускаю, что где-то там люди придумали какие-то методы альтернативные, которые которые где-то есть. Хорошо, но как тогда я про них узнаю, чтобы про них рассказать? Значит, про мои альтернативные методы. Вот, в общем-то, я считаю, что можно воспроизвести другие зоны коры. Ну, скажем так, я не считаю, что нейросеть сама по себе воспроизводит мозг человека, во-первых. Хотя некоторые корреляции с тем, что там нейросеть работает, там очень похоже. Одна часть связи в мозге, это я говорю, одна часть рецепторов и спайки там очень похоже работают. Да, безусловно, я даже не упомянул спайковые сети. в докладе сосредоточился больше на нейросетях, в основном именно потому что про нейросети как основного конкурента действительно надо рассказывать много. Спайковые нейросети есть, в которых есть те же проблемы со скоростью, из-за чего мы их не можем пока что применить для решения больших задач. Не получается. Есть отдельные исследовательские коллективы, которые пытаются там отдельным железом там или как-то все преодолеть. Пока что не получается. Мы не можем поверить, не можем сказать, насколько они работают. Да, может быть, они хорошо работают. Может быть, лучше нейросетей. Пока что не можем сказать. Значит, дальше. Вот там, где альтернативные методы какие-то есть и работают, я их упоминал везде. Какие-то зоны коры есть, которые не работают нейросетями, в том плане, что не работают нейросетями с обратным распространением ошибки. хотя биологический алгоритм обучения, он чем-то похож на распространение ошибки, просто упрощенный немножко. Но другое. В целом я мог бы согласиться, но тогда для большинства из этих областей можно придумать какой-то механизм, Какой-то альтернативный алгоритм действительно, но я вижу это так, что есть модульная система, большинство из модулей в которой будут нейросети, 90% и большая часть вычислительной сложности будет в нейросетях, может даже 99%. Да, будут какие-то другие модули, какие-то другие алгоритмы, типа перебора или чего-то, взаимодействия или какие-то алгоритмы, но я не вижу каких-то больших других сложных алгоритмов отдельных и каких-то других механизмов, в том числе в мозге, которые бы работали принципиально по-другому и были бы критичны. То есть, да, у нас есть механизм подкрепления, который другой в мозге. Да, какие-то механизмы по-другому могут работать, но в целом я вижу вполне, что их можно симулировать какими-то другими алгоритмами, но это совершенно не критично. 

S05 [02:33:00]  : Хорошо, Юрий. Спасибо. Алло, да, спасибо. В общем, я думаю, что у нас наконец появился семинар, на котором обозначился некоторый, так сказать, некоторый дифференциал различных позиций, и нужно будет с этим что-то делать. Ну, в общем, так даже интереснее дальше будет работать. 

S02 [02:33:21]  : Я всегда с удовольствием обсуждаю альтернативные варианты, нейросетевые. Ну, покажите рабочие хоть один. 

S05 [02:33:29]  : Хорошо. Коллеги, всем спасибо за участие. Юрий, спасибо за просвещение кровавых подробностей современных нейросетей. До новых встреч. Да, значит, следующий четверг мы все встречаемся на AI Journey. Ну, а через две недели на прежнем месте. 

S03 [02:33:51]  : Другая ссылка будет. Что? Другая ссылка будет. 

S05 [02:33:56]  : Ну, я вот как бы в раздумчивости, то ли мне ссылку на iJourney забить вместо ссылки на Zoom в таймпаде, либо просто все самостоятельно зарегистрируются на iJourney. 

S02 [02:34:07]  : Мне кажется, вам придется регистрироваться. 

S05 [02:34:11]  : Да, в любом случае придется регистрироваться, то есть полной интеграции с конференционной системой AGI у нас пока нет. Поэтому, если кому-то интересно, то секция AGI будет в первый день AGI как раз в следующий четверг, но это нужно совершенно независимо регистрироваться и там своя система конференц-связи будет какая-то. 

S02 [02:34:37]  : Я скажу еще в завершение, что он там будет на 15 минут, там много вообще не рассказывать. Там чуть-чуть будет. 

S05 [02:34:47]  : Ну да, там и мой цикл из двух семинаров будет в течение 20 минут. 

S03 [02:34:53]  : Коллеги, прошлый семинар показал, что если докладчика поставить в сжатые условия, 5-минутные, то даже самые знающие докладчики ухитряются в них уложиться. Поэтому тайминг ограничивающий спикера в докладе — это прекрасно. Надо укладываться в 15 минут, тогда все будет хорошо. Ладно, спасибо огромное. 

S01 [02:35:14]  : Спасибо, всем счастливо. До свидания. До свидания. 







https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
