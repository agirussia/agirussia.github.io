## 17 декабря 2020 - Артур Франц - Обобщение машинного обучения — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/T5rW5FjjcVg/hqdefault.jpg)](https://youtu.be/T5rW5FjjcVg)

Суммаризация семинара:

Суммаризация семинара


Вступление

Семинар посвящен обобщению машинного обучения и обсуждению подходов к созданию общего искусственного интеллекта (AGI). Спикер Артур Франц представил свой подход, основанный на трех элементах: психологическом правдоподобии, теоретических гарантиях и инженерных успехах.

Основные тематические блоки


1. Психологическое правдоподобие
   - Обсуждение связи результатов машинного обучения с человеческим разумом.
   - Использование когнитивной психологии для понимания когнитивных способностей.

2. Теоретические гарантии
   - Приведение примеров сильной теории, таких как индукция Соломонова и универсальный интеллект Кутера Айкси.
   - Обсуждение теории инкрементного сжатия как попытки найти эффективную аппроксимацию.

3. Инженерные успехи
   - Рассмотрение алгоритма William, использующего теоретические наработки для демонстрации интеллектуальных способностей.
   - Приведение примеров работы с сенсорной памятью и ренормализацией для распознавания временных регулярностей.

4. Проклятие размерности
   - Обсуждение проблемы сжатия данных без потерь и необходимости использовать сжатие с потерями.
   - Приведение примера сжатия визуальных данных с использованием сверточных сетей.

5. Эффективность вычислений
   - Обсуждение примеров, таких как игра "крестики-нолики", и их обучения.
   - Проблемы с большим пространством вариантов и прогнозы на будущее.

6. Сжатие без потерь
   - Критика идеи сжатия без потерь в реальных задачах.
   - Прогнозирование и воздействие на поток данных.

Вывод

Семинар показал, что создание AGI требует комплексного подхода, включающего психологическое правдоподобие, теоретические гарантии и инженерные успехи. Обсуждались проблемы сжатия данных, проклятия размерности и эффективности вычислений. Спикер Франц подчеркнул важность математического языка для выражения и размышления об интеллекте, цитировал Марвина Мински и призвал к дальнейшему изучению алгоритмической теории информации.



S04 [00:00:02]  : Артур, пожалуйста. 

S01 [00:00:05]  : Хорошо, здравствуйте. Меня зовут Артур Франц. Я первый раз участвую у вас тут на этой встрече. Спасибо за приглашение. Мне приятно будет рассказать. о нашем подходе здесь в целом к общему искусственному интеллекту. Там анонсировано было обобщение машинного обучения, но я так подумал, раз времени все-таки достаточно, я расскажу в целом про все. Ну не про все, но, скажем, сделаю такой обзор в целом нашего подхода здесь. И под конец тоже Немножко о себе. Я получил образование в Германии, встретив по шестой год. Я физик вообще-то по образованию. Потом защитился в Frankfurt Institute for Advanced Studies, это тоже Германия, во Франкфурте. нейросетевые модели когнитивного развития в младенчестве было темой. В связи с этим много прикосновений было с когнитивной психологией и нейронными сетями того времени. Потом с 2017 года до с партнером основали OCOM, Odessa Competence Center for Artificial Intelligence and Machine Learning, где старался развивать свой подход к искусственному интеллекту. Думаю, об этом уже с шестого года, наверное, серьезно, а активно работаю с четырнадцатого года. Вот. И так. Я бы сказал, что подход обоснован на трех таких элементах. Трёх основ, скажем так, на трёх китах. Я хочу рассказать немножко о психологическом правдоподобии, как он относится именно к результатам, которые мы знаем о человеческом разуме из когнитивной психологии. Потом о теоретических гарантиях этого подхода. Немножко расскажу про индукцию Соломонова, про универсальный интеллект Кутера Айкси, если кто-то еще не слышал или просто напомню. И потом, как мы постарались развить эту теорию дальше с помощью теории инкрементного сжатия. И в третьей части расскажу про William, как мы называем это алгоритм, который использует теоретические наработки для того, чтобы продемонстрировать некоторые интеллектуальные способности в широком диапазоне средств. Ну и потом выводы. Вот такой вот план. Значит, вообще когнитивные способности, как мнение вам говорит, они очень широкие, очень разнообразные. Можно решать проблемы, распознать образы, классифицировать, обучаться, креативность и так далее. Это все относится к самым различным областям когнитивной психологии. И вот тут я преследую некоторую гипотезу, как сжатие данных, как объяснение различных когнитивных способностей. К сожалению, это, конечно, проверка такой гипотезы. должны делать ученые-психологи. И тут, к сожалению, есть всего несколько статей, но это не сильно продвинуто. К сожалению, в психологии много микротеорий, разбитых на самые различные части, и мне кажется, что сжатие данных может быть очень перспективным, проверить. вот для того что в качестве введения я решил обсудить несколько таких основных результатов общей психологии и чтобы вам донести как я думаю вообще об этих образах мышления о том что происходит в человеческом разуме Вот собрал несколько примеров, скажем так. Классический гештальт принципе организации, восприятия, изображения. Видим принцип близости. Как зрение группирует объекты? Группирует по две линии, допустим. Психологи ввели, ну есть такой отдельный принцип, принцип близость. Мы группируем то, что близко друг к другу. А принцип сжатия, это альтернативное объяснение. Может говорить, ага, кластеризация, почему можно Потому что если есть центр кластера, вместо того чтобы N точек описывать, их координаты, для того чтобы описывать большие числа, нужно много памяти, описывать много надо. А вместо этого, вместо N больших точек, которые формируют кластер, мы описываем одну точку центра кластера и разницу между этого центра кластера и этих точек. А это уже будут маленькие числа. А так как длина описания натурального числа растет лаборифмически с величиной числа, значит, маленькие числа будут тратить меньше длины описания, чем большие числа. Таким образом, кластеризация – просто частный случай сжатия. И вот эти вот линии, которые в картинке изображены, будут кластеризироваться и без отдельного такого принципа. Проблема с этими принципами, что для других случаев надо придумывать другие принципы. Вот, например, в квартире изображения В показано, если крестики друг друга похожи внешне, то мы их тоже вместе группируем. 

S04 [00:07:02]  : Артур, извините, вы слайды пока переключаете или нет? 

S01 [00:07:07]  : Я переключаю. 

S04 [00:07:09]  : Мы не видим, у нас почему-то один слайд. вы изображили я вижу я вижу открытый не фулл скрин то есть я вижу линейку слайдов где указатель на первом слайде вот и вот так вот сейчас сейчас сейчас видно изображение сейчас пятый слайд сейчас пятый слайд я просто формат презентации переключился поэтому 

S01 [00:07:37]  : Ну ладно, тогда буду вот так показывать, наверное. Вот так видно? 

S04 [00:07:41]  : Нормально, да. Сейчас пятый слайд видно. 

S01 [00:07:44]  : Хорошо, хорошо. Другой пример, где видно в изображении Б, крестики группируются вместе и кругляшки группируются вместе. Человеком он это воспринимает. Но тут тоже не обязательно вводить отдельный принцип схожести. Можно сказать, ага, если мы один раз опишем крестик и пререфлицируем его несколько раз, тогда длина описания наша будет короткой. И короче, чем если мы в одну группу засунем и кругляшки, и крестики. А тогда она будет указывать, где какой и так далее. Это будет просто более объемно. В изображении С принцип хорошего продолжения, мы это воспринимаем как две линии, которые пересекаются. Но почему нельзя это воспринимать как линию АС и ТБ? может быть тоже вот так же может быть, правильно? Тут тоже можем сказать, кривизна линии это тоже некоторый такой параметр, если она в узком диапазоне меняется, то нам не нужно для каждой этой точки указывать кривизну. Мы можем сказать, эта кривизна будет в узком диапазоне, Надо указывать, конечно, для полного описания, но мы будем меньше битов тратить, если мы знаем, что она в узком диапазоне. И таким образом можно рассматривать этот случай тоже как частный случай сжатия. И так далее можно проходить. Давайте другой пример возьмем. Вот один из вопросов, как мы распознаем буквы, допустим. Буквы можно… есть вот так template-based perception, значит, можно подумать, что у нас какой-то такой образец, темплейт готовый Если мы видим букву А, мы как-то совмещаем, мячем наш образец и табу, то изображение, которое подходит через глаза. Или конкурентная теория, мы можем распознавать по признакам. и сопоставляя эти линии, создаем букву. Можно это рассматривать тоже как частный случай сжатия. Если у нас много разных букв, которые состоят из из похожих элементов, из похожих признаков, скажем так, горизонтальных, вертикальных и так далее, то потратим меньше памяти, если мы запомним эти признаки, и каждую букву будем потом композиционно составлять из этих признаков. А если, допустим, у нас мало разных букв или вообще в целом изображений, они много сильно похожи друг на друга, Ну, может быть, например, лица. Всегда есть два глаза, нос и рот. И тогда более экономно, с точки зрения памяти, сохранить некоторый такой фиксированный образ, потом мячить каждое изображение. И получается, переход от репрезентации, основанной на признаках, к репрезентации, основанной на вот этих вот образах, моделях, тоже может быть прогнозированным принципом сжатия. Это можно проверить, психологи могут пойти и проверить эту гипотезу. Вот следующий пример. Классический пример, это классические результаты из когнитивной психологии. Выяснили, что мы распознаем тела животных или вообще объектов в целом, как композиция разных геонов, таких вот геометрических, цилиндрических форм или других геометрических форм, которые мы друг с другом составляем. Это было экспериментально установлено, что вот такая композиционность есть, это мы знаем, в искусственном интеллекте проблема композиционности. И тут тоже мы можем задать вопрос о разделении разных частей тела. Как это может быть связано с сжатием частей объекта. Вот если мы посмотрим на шею жирафа, допустим, если верхняя часть шеи это цилиндр, назовем X, а нижняя часть Y. то x и y это будут данные, у которых много общей информации. А раз много общей информации, зачем их отдельно описывать друг от друга? Лучше их конкредитировать, вместе сложить и описать их вместе. Получается, что описание объекта Оно оптимально тогда, когда мы части объекта, у которых большая взаимная информация, когда мы их группируем в одно описание. И таким образом получается сегментация объекта на именно те части тела, которые нам кажутся действительно отдельные друг от друга. С помощью калмогоровской сложности мы можем это просто выразить как КР, это означает калмогоровская сложность, длина программы, кратчайшей программы, которая описывает XY. Если мы вместе описываем отдельно от Z, это будет меньше битов нам стоит, чем если мы X отдельно опишем и YZ вместе. И такой принцип можно действительно использовать. Давайте следующий пример. Ну вот, если у вас есть карта, значит, когнитивно-топографические карты в разуме, да, как мы карту здания, допустим, репрезентируем в уме? Вот сначала, когда человек в новой среде пошел, попал в новое здание, ему надо ориентироваться. Если он за мной, по-моему, ты в другую, то он, скажем, такой маршрут, карту маршрута запоминает. Он запоминает, я сначала выйду здесь, потом налево, прямо, пойти направо, и вот такой вот маршрут лево-право он запоминает. А если он уже долго в здании находится, ему надо с разных точек передвигаться, тогда он уже запоминает топографическую карту, то есть вид сверху, скажем так, и где он может уже с помощью этой топографической карты вычислить, как дойти с любой точки до любой другой. И этот переход тоже можно предсказать принципом сжатия. Зачем нам сначала запоминать всю карту здания, если мы только по одному пути идем? Тогда просто выгоднее и экономнее пройти по запомненному маршруту и все. А когда много разных маршрутов, тогда уже маршрут тысячу разных маршрутов запоминать человек уже ему трудно и удобнее ему запомнить топографическую карту, это будет ему стоить меньше битов в памяти. Я хочу это контрастировать как это с объяснениями, которые даются психологами, например. Здесь вот я вычислил такое объяснение, что топографические карты, они подчеркивают пространственную информацию, а карты маршрута подчеркивает информацию действия, то есть когда мы что-то делаем. Действие против пространства – это довольно такое очень размытое вообще-то определение или объяснение. И тоже это объяснение не может какие-то другие результаты в экспериментах объяснить. нам объяснить именно почему человек в каких случаях выбирает ту или иную репрезентацию. Тут можно рассказывать о многих других примерах. Вот, например, широко распространенные схемы, значит, когнитивные схемы. Это некоторые, ну как можно себе представить, Слотов и свойств, скажем так, у дома. Как выглядит дом, схема дома. У него есть четыре стены, окна, крыша и фундамент, может быть. И вот какой-то прототипичный дом является содержанием схем, когнитивных схем. И конкретные дома потом уже сравниваются с этими типичными домами. Это мы тоже можем рассмотреть как частный случай кластеризации. Если у нас есть некоторый типичный дом, как центр кластера самых разных домов, если мы запомнили его, то нам не нужно уже запоминать, как выглядят самые разные дома. Мы можем сказать, ага, в основном они выглядят так, более-менее. Вот если нам нужны детали, если там я агент недвижимости, я могу себе позволить больше памяти уделить запоминанию разных типов домов и архитектур. А другой человек, который с этим не связан, у него будет более грубое описание. Он воспринимает такой вот сжатый центр кластера. У одного может быть больше кластеров, у другого меньше, но кластеризация помогает сжать такое разнообразие. Потом, например, как мы вспоминаем что-то, ну, наверное, буду здесь углубляться. Вот более простой пример. В английском языке нерегулярное множественное число. От нога – foot, вообще-то feet нерегулярное, но дети когда изучают, англоязычные, в англоязычной среде, когда растут, они сначала регулярно обобщают. Кажется, называется over-extension, если я не ошибаюсь. Значит, foot на foots. И это, конечно, тоже более экономно, когда мы можем найти правило, которое обобщает одинарное число к множественным числам. И потому что нерегулярные формы требуют отдельного запоминания, и это опять требует больше памяти. Сначала мы пытаемся понять мир, сжимаем по максимуму, и потом уже выводя из этих правил, из этих программ, которые мы в голове репрезентируем, разные формы слов, Но потом, когда мы уже можем себе больше уделить памяти, мы можем запоминать что-то типа нерегулярных форм. Другой пример. что короткие слова, они во всех языках более часто встречаются. В русском языке я, он, не, а, вы. Вот такие короткие слова из одного или двух букв очень часто встречаются. И почему это так? Ну если мы хотим минимизировать длину сообщения, длину текста, то это как раз Source Coding Theory. Из теории информации нам говорит, что если у вас элементы часто встречаются, то им нужно уделить более короткий код. построили потом коды Хафмана, арифметические коды, которые опираются на эту теорему и как раз минимизируют длину описания таким образом. Вот. 

S00 [00:21:56]  : Или можно 

S01 [00:21:58]  : задаться вопросом, почему существует местоимение, пронованс, если я правильно вспоминаю, на русском языке. Ну, а зачем повторяться, говорить Иван Иванович каждый раз, если можно первый раз его упомянуть и потом использовать местоимение он. таким образом длина сообщения значительно укорачивается это тоже вот один из примеров ну короче можно приводить много разных примеров я действительно проработал целый учебник таких вот примеров и для меня звучит правдоподобно что мы можем принцип сжатия выдвинуть как объяснение Причем такое просто дисциплинарное объяснение когнитивной психологии. Как вы видите, я привожу примеры из восприятия, из репрезентации знания, из внимания, там был пример. и тестирование гипотез самых различных сфер когнитивной психологии можно, скажем так, покрыть и попытаться выдвинуть такую unified, общую теорию когнитивной психологии. Но это, конечно, был бы сильный размах. Я осознаю, что это пока лишь так вот на пальцах, скажем так, я это передаю. Это серьезный, огромный труд, который психологи должны проверить сами, насколько эта теория имеет шанс на то, чтобы она подтвердилась. должны проверить эту гипотезу. Но я это вам рассказал для того, чтобы как-то наглядно это нести, как я в целом думаю о разных аспектах человеческого разума. Давайте перейдем к теоретической основе. Оказывается, У меня эти мысли уже добыли давно, но оказывается, что действительно многое уже разработано в теории, которая подтверждает вот этот подход интеллекта как сжатие информации. Тут в основном индукция Соломонова, информацию, то вы получаете оптимальный предвиктор, вы можете оптимально прогнозировать. И потом Маркус Хутер пришел и создал теорию универсального интеллекта и внутри него формулировал агента Айкси, который показывает интеллект в смысле, что он может в широком диапазоне сред достигать цели. Но это в каком-то смысле такой, я бы не сказал очевидный, но можно понять, если у вас есть оптимальный предиктор и он лучше всех других предикторов предсказывает, что будет в будущем, выбирать те действия, с которыми вы сможете достигать ваших целей. И, к сожалению, с этим агентом Айким много разных проблем. Преимущественно, что вообще само сжатие, неформулированный алгоритм. Как именно осуществлять алгоритмические сжатия? И тут, я считаю, мой главный вклад в это развитие, это разработка теории инкрементного сжатия, где данные могут сжиматься по шагу. Об этом расскажу чуть позже. В принципе, об этом я только что рассказал, я отталкиваюсь способность достигать цели в широком диапазоне сред. Ну конечно нужно сказать с ограниченными ресурсами, но это я думаю само собой разумеется. Сейчас у меня два слайда про, вообще-то один слайд про универсальную индукцию. Напомню индукцию, если у вас есть последовательность каких-то чисел, минус 1, 3, 7, 11, как они будут продолжаться. Мы можем разные функции придумать, просто 4 всегда добавляется или какой-то сложный полином. И как принцип Окома гласит, объяснение... Не надо делать больше предположений, чем необходимо. Формально Колмогоров разработал, конечно, свою... Калмогоровской сложности на его основании целая алгоритмическая теория информации. Калмогоровская сложность определяется таким образом. Мы выбираем машину Тьюринга, опорную машину Тьюринга, универсальную. Или вообще она может быть не универсальная, но чаще всего берем универсальную. И берем минимальную программу P. минимальной длины, которая запускается на этой машине Тьюринга и которая выдает данную строку x. Это будет колмогорская сложность строки. На этом основании Соломонов развил теорию универсальной индукции. Тут очень вкратце вам расскажу, она гораздо шире. Но если рассматриваем последовательность нулей единиц x от 1 до t, то Соломонов снизу полумера. Но это такая большая деталь. Она говорит, что для любой последовательности нулей и ниц какая априорная вероятность, что мы ее увидим. Если эта последовательность состоит из нулей, то априорная вероятность будет больше. А если она случайная, то она будет меньше. И мы это видим из этого определения. Значит, идет сумма по всем программам Q, которые запускаются в универсальной машине и которые выдают X. И с весом 2 в степени минус длины этой программы. И мы видим, что доминируют, конечно, самые короткие программы. И можно показать, что Это априорная вероятность M. Она с точностью мультипликативной константы совпадает с выражением 2 в степени минус полумагородской сложности fx. Это просто, чтобы наглядно понять, что действительно очень много веса придается коротким программам. И тут можно показать, что Если взять условную, это вероятность MXT при условии того, что мы увидели раньше, и XT мы тут подразумеваем, что это правильно прогнозировано, значит XT равняется правильному значению в последовательности. то вот эта бесконечная сумма, которая на левой стороне видна, то она будет конечной. Не буду вам сейчас эту математику рассказывать, там довольно элементарные операции. Что это значит из матанализа? Что у нас предел вот здесь, t для бесконечности, m стремится к единице. И честно вам скажу, я вот когда первый раз это увидел, у меня довольно так челюсть отпала, я был удивлен. Ну что мы видим тут перед нами, это вот в двух строках, в трех строках описание оптимального предиктора, который любую вычислимую последовательность будет прогнозировать идеально в пределе. И при том, что этот предел сходится очень быстро. Вот что удивительно. Кстати, Антон, моя мышка тут видна, если я что-то показываю? Видна, хорошо. 

S04 [00:31:43]  : Да, видна. 

S01 [00:31:44]  : Ага, да, я вас видел, как вы киваете. И она значит быстро сходится, это здесь не доказано, это дополнительные теоремы. Но вот это вот меня очень удивило и поразило, честно говоря. На практике в искусственном интеллекте мало кто придерживается или учитывает последствия. Но в чем последствия? Последствия, что в определении MX тут ведь 2 в степени минус L. Значит, очень серьезно наказываются большие программы. Значит, если мы используем в любом методе искусственного интеллекта, который особенно машинного включения, который хочет прогнозировать что-то для тестовой выборки, допустим, то ему нужно очень постараться использовать маленькую репрезентацию. Если мы стоим нейросеть с миллионными параметрами, то это очень много. Нужно постараться меньше параметров. Я тут Америку не открою, что нужно постараться строить более худые сети, что нужно использовать регуляризацию, дропаут и так далее. Это все знают, что тем меньше у нас репрезентации, тем меньше степень полинома. то тем лучше обобщает систему. Это-то все знают, но мало кто знает, как мне кажется, насколько все плохо, если мы не будем стараться сжать действительно. Потому что 2 в степени минус L – это вероятность успеха, делите пополам за каждый потраченный бит. Это очень серьезно, это экспоненциальный штраф, penalty. И вот это меня удивило. А следующий ход мысли это, ну а как же это может быть иначе? Это ведь бесконечная сумма и она должна быть иметь конечное значение, если у вас будет, у вас же бесконечное количество программ, которые этот х выдает, тогда если вы не будете, если у вас каждый член этой суммы будет слишком большой, то у вас не выйдет конечное значение всей суммы. Бритва Оккама является не просто каким-то философским принципом, а математической необходимостью, и причем серьезной необходимостью, с очень сильным штрафом на длину. И вот тут закрадываются уже мои подозрения, что все эти проблемы с оверфитингом учения или сейчас в нейросетях с out of distribution generalization, что нейросети плохо экстраполируют, хоть и хорошо интерполируют данные, что это связано именно с этими аспектами. Ну ладно, пойдем дальше. Вот значит индукция Соломонова действительно строит оптимальный предиктор и доказано тоже, что не существует другого предиктора, который сходится быстрее, который прогнозирует лучше, чем априорная мера Соломонова. И Маркус Хутер взял эту меру и построил вот такой агент Айкси, как я уже рассказывал. Сначала он опирается на фреймворк агента, это значит агент в каждое дискретное время выдает действия и получает наблюдение и реворт. Тут нет никаких предположений. Это самый общий фреймворк для reinforcement learning Как формализуются агент и среда? Агент это машина тюринга и среда это машина тюринга У них есть свои рабочие ленты и у них есть входная и выходная лента Входная лента агента одновременно является выходной лентой среды Как мы видим, среда нам дает пару, каждый момент, reward и observation, выигрыш и наблюдение, агент и действие. Это и так они по кругу делают. Не думайте, что это только формулировано для детерминистических сред, это действительно обобщается и на вероятностные среды. И вот здесь мы видим агента Айкси. Как вы видите, справа находится априорная мера Соломонова. И что мы здесь видим? Тут есть сумма по всем программам. Опять штраф минус LQ. И все программы, которые с помощью действий, которые мы делали в прошлом, до сегодняшнего, до актуального действия АК и до будущего АМ. Мы рассматриваем. Значит, действия прошлого мы знаем, а по всем будущим действиям мы перебираем. И вот мы берем один из таких примеров, один из этих примутаций, и спрашиваем, с помощью какой программы КУ и этих действий мы можем на универсальной машине вычислить прошлое, то, что мы видели раньше, прошлые наблюдения и выигрыши, и потенциальные будущие наблюдения и выигрыши, которые мы, конечно, тоже не знаем. Мы их тоже всех перебираем. Вот. И таким образом мы вычисляем, скажем, Все программы, которые приведут к самым различным будущим и выигрышам во всевозможных действиях. И мы можем задаться вопросом, но какие программы будут самыми короткими? Конечно, те программы, которые вычисляют будущее, которое не несет много дополнительной информации. Если мы смотрим на белую сцену, и всегда эта белая сцена будет дальше, то мы можем написать короткую программу, которая воссоздаст это будущее. А если мы будем рассматривать будущее, в котором все пиксели перед глазами перемешаются случайным образом, тогда нам придется описывать его длинной программой Q. и априорная его вероятность будет маленькой. Значит, вот такой вот агент, он берет эту априорную вероятность и умножает на сумму ревордов, которые он рассматривает, для того, чтобы иметь value function, ценность вот этого будущего и этих наборов действий. И все, что потом случается, это максимизация. Он максимизирует expectancy max, по этому value. Вот один простой пример. Допустим, мы хотим построить, использовать AXE для того, чтобы сыграть в крестик и нолике, и тогда пространство наблюдения будет черточка, это значит пустое поле, крестик и нолик. В девятой степени значит мы все комбинации рассматриваем. Значит одна такая позиция крестик и нолик будет Реворды могут быть, допустим, такие. 0, если ничего не случилось, такое. Минус, если проиграл. Плюс, если выиграл. Минус 100, если я сделал нелегальный ход. Как мы здесь видим, крестик поставил на нолик. И плюс 100, если противник сделал нелегальный ход. И вот действия могут быть из множества от 0 до 8. И как мы видим, действия 4, 1, 1. И вот в примере мы уже видим, что количество будущих, которые в крестиках Моряков допускаются, это кардинальность этих множеств действий, наблюдений и выигрышей. Девять действий. три в девятой степени это вот это вот возможных наблюдений и умножить на количество ревордов и это количество возможностей в совокупности. А если мы еще смотрим в будущее, хотя бы посчитать несколько ходов вперед, надо это еще в степень горизонта взять. Ну и конечно быстро становится очевидно, что это будет решить задачу реального восприятия и зрения, то это будет тем более большое число. И как с этим вот справиться? Тут уже не буду вливаться в детали. Айкс и так вот работает, и как я уже сказал, он достигает максимального уровня интеллекта. И хорошее в нем, что у нас это первая точная математическая теория интеллекта, можно сказать. мы наконец-то можем, у нас есть возможность, вместо бесконечных философских дискуссий и ссор, спор, перейти к, скажем, к строгой математической работе и задать точные вопросы. Хорошо, давайте мы возьмем эту теорию и разобьем ее теперь, постараемся сделать аппроксимацию, которая будет эффективно работать. Кокутер говорит, он считает, что концептуальную проблему он редуцировал на вычислительных Ну, это, конечно, я бы так сильно не замахивался, это, конечно, смелое заявление, но прогресс действительно существенный. Ну, какая вообще проблема в целом? Во-первых, она невычислима, требует бесконечных ресурсов, но можно подумать о вычислимой аппроксимации. И, что я считаю существенной большой проблемой, она не описывает, как вообще сжимать данные. Потому что мы видим здесь правило Соломонова и нам нужно находить короткие программы, но теория нам не говорит как. И вот сейчас я вам расскажу как мы продвинулись в этой проблемы и разработали теорию инкрементного сжатия. Несколько месяцев назад вышла статья в Information Sciences, 20 страниц, математическая статья, которая показывает свойства этой теории. Раньше была маленькая публикация, а здесь много В чем основная идея? У нас есть последовательность или что-то, что мы видим. В математической точке зрения это просто набор чисел. И когда мы обычно что-то описываем, Мы обычно описываем какой-то там предмет, у него есть форма, цвет, местонахождение в пространстве и так далее. И человек так и говорит, да, ну вот это стакан, он выглядит прозрачно, он в цилиндрической форме, он находится там перед столом или на столе. Сразу интуитивно понятно, что эти свойства, которые мы передаем, они независимы друг от друга. Форма не зависит от цвета. Местонахождение в пространстве не зависит от предыдущих описаний. Так вот, идея в том, что мы берем данные, изображение этого стакана, и проецируем, и отделяем от него признак описания его увеличенной Size Specification. И остальное проецируем в остаточную, Residual Description, остаток. И вот этот остаток мы дальше берем и описываем форму. И отделяем это описание из этих данных и так далее. Потом мы выделяем цвет, потом выделяем местонахождение. И получается у нас описание как набор этих спецификаций, набор этих признаков. Получается кратчайшее описание, как интуитивно нам кажется, будет просто набором этих признаков, но может быть еще какой-то остаток останется. Вот. И... Это сейчас вот только так вот на пальцах, на примере признаков объекта, но можно это тоже гораздо шире рассматривать. Например, как нам решить проблему проклятия размерности, если мы решаем проблему. Часто человек находит какие-то свойства проблемы. на шахматной доске он понял ага только на белых полях может быть решение допустим и он уже сузил пространство поиска и только на этих полях ищет и вот когда человек решает проблемы именно вот так он наблюдается что он так себя ведет и получается он Он сам находит свойства. Свойства не жестко запрограммированы, как в узком искусственном интеллекте. И одновременно он тоже сужает, скажем, он сужает проблему для самого себя. Он изначально рассматривает широкий спектр задач, он может решить, но этот Можно рассматривать эту теорию как попытка решить проклятие размерности. Это центральный вопрос для AGI, как мне кажется. Значит, что тут делается более конкретно? Если мы возьмем универсальный поиск, у нас есть последовательность, и у нас есть кратчайшее описание k от x, ну, перебор всех программ, которые воссоздав x, будет потребовать перебор 2 в степени k от x программ. Ну, даже еще больше, потому что короткие, более короткие нам тоже надо перебирать. Ну, примерно одно и то же выйдет. Это, конечно, очень большое число. А тут, что я предлагаю, у нас есть последователь STIX. Мы ищем пару функций f и обратной функции f'. которые осуществляют проекцию на остаточное описание R1. И с единственным условием, что это описание R1 плюс функция F1, их длины будут короче. И следующий раз мы делаем то же самое и так далее. Это можно сказать И более детально, в чем цель? F-звездочка – это кратчайшая программа, машина тюнинга, которая может присвоить длину, ее можно описать, и длину в битах. мы ищем кратчайшую машину тюринга и одновременно дескриптивное отображение f' звездочка, тоже кратчайшее, таким образом, что x не меняется и что мы достигли хотя бы какого-то сжатия, хотя бы на один бит надо сжать. Вот это цель инкрементного сжатия, как раз мы делаем такую трансформацию наших данных, которая будет хотя бы чуть-чуть короче. И у нас остается остаток R, вот здесь вы видите. Одно из первых результатов это, что F-звездочка сама по себе не сжимаемая. Если мы берем кратчайшую машин тюнинга, то есть признак, как мы это называем, то она будет сама по себе не сжимаемая. То есть невозможно найти программу, которая на выходе выдаст эту описание этой машины Тюринга, и которая будет короче, чем сама эта машина Тюринга. Значит, это само собой разумеется в некотором смысле, потому что кратчайшую программу нельзя сжать. Это одна из основных теорем в колмогоровской сложности, потому что если бы кратчайшую программу можно было бы сжать, можно было бы еще найти еще более короткую программу, и тогда это была бы не кратчайшая. Примерно такая же логика, что касается признаков, а не в целом. Признак это просто частичное описание, а не полное описание. Это хорошо, тут мы уже готовы, нам не надо F звездочку сжимать. А что касается residual description, вот этого остатка, можно доказать, что описание икса разбивается на две части. Как справа в изображении видно, F и R, звездочка и R. Это наглядно показано, что описание пары F звездочка и R примерно одинаковой длины, как и кратчайшее описание х, и примерно одинаковой длины, как и кратчайшее описание звездочки r по отдельности. Это значит, что у них нет взаимной информации. Если мы по отдельности сжимаем друг от друга, и это все равно, что их сжимать вместе, значит, они друг от друга ничего не знают. Это, можно сказать, мы проецировали, вы проецировали какую-то часть информации. И получается, что мы как будто от пирога, скажем так, отрезали просто кусочек. И можем сжимать остаток. Это очень хорошо, потому что нет ответвления как-то. У нас есть всегда один шаг, линейная вот такая вот цепочка. И это тоже означает, что мы не можем не зациклиться, а backtracking не надо. Не может случиться, что мы так сжимаем, сжимаем, сжимаем, приходит момент, где опа, мы не туда пошли, надо обратно назад и по-другому что-то делать. Такое тоже не может случиться, потому что тут нет взаимной информации. Ну как это интуитивно можно понять? Если бы признак и остаток содержали бы взаимную информацию, тогда признак можно было бы сделать еще короче. Потому что, ну, признак и остаток, они вместе воссоздают X. Если они содержат взаимную информацию, ну, тогда можно его сделать еще короче. Потому что, ну, там редудантность просто есть. Можно обойтись без редудантности. Да? Это же в теории все. Значит, кратчайшая будет, не будет содержать эту редудантную информацию. Вот. И... В принципе, этот слайд вроде сложно выглядит, но на самом деле тут посыл несложный. Если вот в черном квадрате эта информация, которая в X находится, если X равняется F от R, F и R воссоздают X, значит, X находится в union, в слиянии этих множеств. И первая теорема доказывает, что они не пересекаются. Вот это поле уходит. Следующая теория показывает, что нет лишней информации, что мы, делая этой проекцией, мы не придумываем какое-то что-то лишнее, что не содержится в ИКСе. Таким образом, они все помещаются в ИКС, а следующее – это не сжимаемость признака. логарифму. И получается у нас действительно по информации в иксе, и мы тут кусок отрезали. И это можно теперь итерировать. R мы сделаем с R то же самое, что мы сделали с иксом. И у нас получается этот пирог разрезается на разные куски, и мы репрезентируем хромогородскую сложность икса, не сжимаем его уже остатками. Вот. И получается вот главный результат, что это вот только что, что я сказал, и отсюда именно мы можем ожидать ускорения. Каким именно образом? Вот если мы сравним неинкрементное сжатие, тогда надо искать 2 в степени колмогоровской сложности, программу надо перебрать. А инкрементное сжатие у нас, мы нашли такое разбиение алгоритмического пространства. И за счет этого разбиения время поиска, оно получается вот такое вот. Значит, мы должны два в степени длины признаков программ перебрать, чтобы найти признаки. Там уже их должны перебирать как-то в теории. И тут получается сумма. Потому что мы каждый признак один за другим ищем. У нас нет этого бэктрекинга. то у нас время поиска получает суммы в степени этих длин признаков. А в неинкрементном у нас произведении. И таким образом, инкрементное сжатие гораздо быстрее, чем инкремент. Это просто математически высказано то, что интуитивно вообще-то должно быть понятно. Тот факт, когда мы находим разбиение пространства, то мы можем действительно быстрее искать. Это именно вот тот момент, который позволяет более быстрый поиск. Так вот. Там в теории есть еще ряд других результатов, но у меня уже нет времени их обсуждать. Об основных я рассказал. И сейчас существенный вопрос. На практике-то это работает, это может все хорошо, теория хорошая, может быть это как-то звучит правдоподобно с точки зрения психологии. Но как на практике-то это все построить? Мы же все равно не будем перебирать машины Тюринга. И над этим мы работали последние несколько лет, года три, кажется, уже. Построили алгоритм Вильям. Что это такое? На данный момент он вообще-то быстро меняется. Раньше это были деревья, такие программы, деревья из операторов. Таким образом строили программу на функциональном языке программирования. На данный момент это двудольный направленный ациклический гиперград. Двудольные, потому что есть ноды, которые содержат значения и другие ноды вершины, которые содержат операторы. Он направленный и ациклический. А гиперграф, потому что внутри каждого оператора может сидеть такой же опять граф. И получится, допустим, есть функция, которая нам помогала хорошо при сжатии, и мы можем ее переиспользовать, таким образом, в качестве оператора для построения других графов. И вот. И мы взяли там ряд операторов в питоне, таких стандартных, и построили алгоритм, который вот такие вот графы строит из них. И используя, конечно, то, что нам показывает теория, мы стараемся инкрементно сжимать. Значит, что мы стараемся делать? У нас есть данные в какой-нибудь список, допустим. Мы строим вокруг него такой вот граф, который можно инвертировать. И на листьях этого графа появляются другие значения. Если их дефолтное описание по умолчанию будет короче, чем дефолтное описание исходных данных, то мы сжали немного. Если мы сжали, мы продолжаем поиск уже внизу. продолжаем сжимать листья. Сейчас в будущем более наглядно в следующих слайдах объясню. Ну вот тут, например, простые примеры. Список из единиц, там 0, 1, 2, 3, 4 и так далее. Какие-то строки, списки, массивы тоже можем, в принципе, любые наборы данных на этом функциональном языке, значит, никакие декларации у нас нет, простой функциональный язык. И находит описание на этом языке. И мы можем найти описание листьев, описание этого графа и посмотреть, сжалось ли тут что-то или нет. пример, потому что много поменялось с тех пор. Вот у нас список сначала 11, потом 12, 13, 15 повышается и тут восьмерки повторяются. И сначала вот он находит такое дерево, где он понимает, ага, тут 11 от 0 до 6 индексов повторяется. А остальное я оставлю на потом. Значит он он сжал какой-то фрагмент. Это и является признаком, да. Признак он какой-то фрагмент или какую-то часть, какой-то аспект сжимает. Вот. А потом следующий шаг он взял восьмерочки вот от индекса 14 до 19, сжал эти восьмерочки, понял, что они повторяются. И вот остался такой остаток. И потом он понял, что еще один Функция Range сжимает вот эту вот повышающуюся последовательность и остаток он еще короче стал. И таким образом остаток становится короче и короче. И в совокупности это уже дерево глубины 6. И оно может быть таким образом найдено гораздо быстрее, чем если перебирать все деревья глубины 6. Вот. Так. Другой пример – это вот сжатие вот таких вот простых геометрических фигур и изображений. Они даны как список из tools, можно сказать список из координат этих точек. Откуда сейчас, к сожалению, у меня нет здесь этой программы, которая ее описывает. Я на примере этих изображений хотел бы опять обсудить несколько аспектов. Вот такой вот домик справа, он сжимается. Лучше всего, если вы разделите его описание на части, но не какие-то части, а делаете отдельное описание для каждой стены, и для крыши. Если будете стенку резать где-то посреди, тогда у вас описание не будет кратчайшим. Если вы композиционально вот так вот составите эти части описания. И это я уже вот с примером шеи жирафа наглядно, надеюсь, описал, почему это оптимально с точки зрения сжатия. И интересно, что если вы сжимаете оптимально, у вас фрагменты описания вы получаете, которые почему-то по какой-то загадочной причине отображаются на слова из языка. Естественно, из языка. Стена, крыша. И это такое... Эффект, который, например, в нейросетях не возникает, а фрагменты описания в нейросетях, они запутывают разные части изображения, запутываются в каком-то сложном таком описании. И таким образом интерпретабельность страдает. Но если вы сжимаете оптимально, у вас получается, как оказывается в разных случаях, интерпретабельное описание. И я не буду утверждать, что это всегда так в общем, но это такое вот наблюдение, которое заставляет задуматься. И заставляет задуматься, может быть, в этом лежит решение вопросов интерпретабельности искусственного интеллекта. Вот пример, такой простой пример самоулучшения билима. Дело в том, что это же алгоритм для сжатия танка. А для того, чтобы Алексей использовать, нужно его привинтить к reinforcement learning. Нужно определить какие-то реворды, что такое, какие действия могут быть и наблюдения. Я это действительно сделал и теперь может алгоритм решать какие-то задачи активно. И вот я попробовал такой маленький примитивный пример самоулучшения. Вот алгоритм хочет сжимать, но допустим он не может справиться с этим, ему надо какой-то параметр оптимизировать. Часто мы вручную кодируем или берем из библиотеки какой-то алгоритм градиентного спуска, широкого распространения. Но одна из философий нашего подхода, что никакие эвристики мы не встраиваем, никакие ноль, ничего специфического не встраиваем. А что если мы сделаем так, что вот этот Айкси вместе с Вильямом сможет помочь самому себе сделать жахи? Значит, ревортом будет какой-то сигнал, я сжимаю теперь больше или меньше. Это будет выигрыш, а действием будет параметр на шаг вперед делаю или на шаг назад повышаю или понижаю параметры. И вот в таком простом примере он находит, ага, если я иду всегда направо, до определенной точки, сжатие улучшается, потом я останавливаюсь. И он находит это решение. И получается, он сам себе помог оптимизировать один из параметров решения проблем с жатием. Вот такой вот маленький пример. Другой результат – это что Вильям играет в крестики-нолики, и при этом мы его для этого не программировали. каким образом он это делает. Вот, значит, у нас есть позиции на первой строке. И как вход, значит, данные, которые он получает, это список из списков из строк длиной единицы. Значит, вот тут вот этот список из девяти значений, там везде черточка, потому что везде поля пустые. А тут посреди х, потом здесь нолик появляется, потом еще один х и так далее. Этот список из списков можно сжать, потому что тут много регулярности. Если я поставил куда-то крестик, он в следующем позиции, он там появится. И действительно, он довольно быстро находит программу. ReduceSetItem, начиная вот с черточками, и потом делаю ходы на четвертое поле ставь крестик, на первое поле ставь нолик, на седьмое поле крестик, на пятое поле нолик. Вот. И чередую крестик-нолик таким образом. И это делает функция Reduce, использует этот оператор. То есть это айтем для того, чтобы вставлять это кумулятивно, вот эти вот значения. И таким образом Вильям может понимать, ага, если я здесь буду удлинять вот этот вот список ходов, он не знает, что такое ход, просто какой-то вход для функции, которую я нашел. Если он там будет вставлять другие числа, то он может прогнозировать или рассматривать различные ходы в будущем, себя или противника. Единственное, что я действительно вручную встроил, это отображение позиции на реворды. Вот это я встроил. А значит, таким образом, William может сказать, ага, для любой будущей позиции он получает реворд. Исходя из реворда, он уже, так как он присоединен к KX, он запускает Xpectimax и вычисляет будущие ходы. Ну и делает тут разумный ход, ставит здесь в угол и получается вилкой выигрывает. Вот такой вот пример. Давайте перейдем к примерам машинного обучения. Я обещал рассказать об общении машинного обучения. Как оказывается, что Различные методы машинного обучения можно рассматривать как частный случай сжатия. Это, к сожалению, редко рассказывается об этом, к сожалению, студентам, когда они изучают методы машинного обучения. Может быть, редко это осознается, но можно рассмотреть следующий пример. очищает какие-то выбросы. И тут вот список из букв А, и тут где-то буква Б. И что находит Вильям? Вильям находит такую программу, где он говорит, давайте повторим 26 раз А, и тут будет чистый список из А, и на индекс 18 ставим букву Б. Почему он это делает? Потому что это сжимает наши данные. Почему это сжимает? Что нужно нам делать, чтобы описать эти данные? Нам надо описать значения в листьях 26, а, b и 18. Как я уже сказал, для описания целых чисел длина описания растет логарифмически. и поэтому для того чтобы писать числа 18-26 много битов не надо и отдельные буквы описывать тоже много битов не надо и именно поэтому описание значительно сокращается и у нас compression rate Давайте рассмотрим пример линейной регрессии. Можно было бы сказать, а как это сделать без оптимизации? У нас нет тут отдельного оптимизационного алгоритма. Как вообще можно воссоздать что-то похожее на машинное обучение, где везде есть оптимизация? Так вот, сейчас расскажу. мы берем вот такой вот набор данных, x распределен равномерно между минус 10 и 9 с ошибкой тут нормально распределенной и 2x плюс 18 по сути надо вычислить. Виляму дается для сжатия набор y и набор x два максима. И вот dl это длина описания на description length в битах. Ну и не смущайтесь, что они там не целые. Целый тут по 2000 битов для y, 1300 для x. Ему все равно, что там x, что там y. Все данные, которые ему дают, он просто сжимает. Значит, что он делает в первом деле? описывает Y в качестве 1 плюс остаток. Он отнял по сути единичку. Почему сжатие улучшается 0,4%? Потому что остаток содержит более маленькие числа, чем изначально Y. А так как длина описания логарифмически растет, значит, молотон, чем меньше числа, тем меньше длина описания. Вот. И вот красной черточке выделил, скажем так, прогноз. То, что делает Ильям Вильям, прогнозирует эти точки, вот сейчас горизонтальные линии на этом этапе сжатия. В следующем этапе он говорит, о, давайте двоечку отнимем. Хорошо, как красная линия поднялась. Потом 4, потом 16. И вам может показаться, что я тут запрограммировал, что он постоянно удваивает. Нет, он просто использует те числа, которые у него уже есть. Ему дается единица, больше у него нет права использовать другие числа. Иначе он будет забегать в пространство высокой размерности. И его встретит проклятие. Если он воссоздал из единицы двоечку, он использует эту двоечку и потом он двоечку умножает друг с другом и четверочку умножает друг с другом. Он только использует те ресурсы, которые он сам мог воссоздать для того, чтобы найти описание, которое заземленная в ничего. Это сейчас, может, скриптическое выражение, но... Короче, тут можно много чего об этом рассказывать, но он старается использовать только то, что у него есть. И, значит, он нашел 16, а теперь думает, о, давайте я отниму х, от остатка, и таким образом у нас получается описание x плюс 16. Получается вот такая вот красная линия. Это тоже опять сжимает, потому что ему не нужно отдельно описывать x и y, он их встроил в один граф, поэтому они взаимосвязаны. Взаимосвязь между x и y именно то, что осуществляет это сжатие. До того они были отдельные. Что он потом делает? Он еще раз отнимает x. Вот тут получается такой вот зашумленный x. Правильно, по сути это 2x. x плюс x плюс шум плюс 17. И тут он заменил 16 на 17, потому что можно же прибавить единичку. Он использует все различные операторы, которые которые ему даны. И получается, тут уже красная линия, он уже близок к оптимуму, и в последний шаг он 17 заменяет на 18, и у нас получается идеальное прогнозирование этих точек. Это очень простой пример, никого не впечатлит, выполнения регрессии. Но стоит заметить, что здесь нет отдельного какого-то алгоритма оптимизации. И тоже не оптимизируется, минимизируется какое-то квадратическое отклонение и так далее. Вот пример классификации. Допустим, у нас есть набор иксов, опять массив, и для каждого икса у нас true или false, два класса. Они распределены так справа, по цветам видно. Ну и по сути, если ему разделить это посередине, была бы успешная классификация. Тут я добавлю, что дискретные массивы можно описать описывая индекс пермутации. Допустим, есть тут два true и много 13 вот этих false или в целом длина 13, то есть можно рассматривать количество пермутаций вот этих вот элементов, их всех перенумеровать, перечислить. И индекс этого вот перечисления, оно описывает же весь массив. И таким образом, в том случае, когда мало этих true, но много false или наоборот, Тогда действительно такое описание гораздо короче получается. С индексом пермутации у нас короче описание, когда у нас действительно дисбаланс между количеством true и false. И это он использует. Что он сначала делает? Он отнимает единичку и сдвигает вот этот вот график. Налево отнимает двоечку, четверочку и сдвигает распределение в центр. И следующим шагом он от результата сравнивает с единицей и получает прогноз. Прогноз получается, что слева от этой черточки меньше единицы. Это будет true, остальное будет false. XOR – это некоторое… Некоторое можно рассмотреть как булевое сложение. Получается здесь prediction error и ошибка. маленькая по сравнению с оригиналом, потому что тут мало ошибок, мало значений true по сравнению с количеством false. Таким образом, тоже с помощью сжатия решается вот такая простая проблема классификации. Вот следующий пример дерева решений. Тут, в принципе, похожий аргумент выдвигается. Тут есть три класса. Вот в классическом примере три типа цветов. Cetoza, Versicolor, Vitunica. И если мы скажем, ага, если они отличаются шириной листка. Давайте мы рассмотрим все цветы, у которых ширина листка меньше единички. И тогда выделяется только только ситоса, а другие в другом классе, в классическом дереве решений. Только в дереве решений минимизируется Gini coefficient, а у нас в целом описание минимизируется. И он находит вот такое вот описание, он сравнивает их с единичкой и с помощью оператора insert разделяет массив на ситосы и на остаток. Как видно вот здесь. И так как тут везде только буква С, только ситоза, их описание такого массива падает. Ну ладно, не будем даваться деталям. Тут можно еще другие примеры приводить. Кластеризация, коллаборативная фильтрация, максимум лайклику. Давайте уже придем к завершению. Тут вообще-то можно было бы много рассказывать. И вообще-то цель – аппроксимировать Айкси, вот этот вот агент, при этом учитывая психологическое такое правдоподобие. Как я вот рассказал, что в теории у нас есть продвижение, на практике у нас есть тоже продвижение сжатия, но хотелось бы вам дать впечатление, как можно дальше продвигаться в будущем. Такой набросок roadmap для AGI в этом подходе. Я об этом уже рассказывал в 2019 году на AGI-конференции, теоретический аспект этой работы. Приглашаю вас пересмотреть это видео, там много интересных деталей. просто в общих чертах рассказать именно о психологических аспектах. Как именно психологические способности, когнитивные способности относятся именно к формулировке Айкси. И как это вообще относится к математическим, алгоритмическим необходимостям, которые нужно решить, задачам, которые нужно решить. для того, чтобы сделать Айкси эффективным. Это же было бы интересно, если мы сделаем Айкси эффективным, и там выпадывают действительно разные когнитивные способности человека в идеализированном каком-то форме. Ну вот, если вы посмотрите на Айкси, мы уже говорили, что нужно бритва ОКОМа, что индуцировать короткие программы. Но полное описание, у меня все было сжатие без потерь, а в идеале мы не можем себе позволить сжатие без потерь, мы не можем запомнить всю нашу историю, даже в сжатом формате. Нужно сжатие с потерями. Ну, к счастью, шум и сигнал не содержат друг от друга информации. По определению шум не содержит информации. А как я уже аргументировал, если вы оптимально сжимаете, даже без потерь, у вас описание разбивается на две части. Получается, сигнал и шум автоматически разбиваются в вашей репрезентации. Они не запутаны, как неверный сигнал. И тогда вы просто, чтобы из сжатия без потерь получать сжатие с потерей, выбрасываете шутки. Или выбрасываете то, что для вас нерелевантно. Это вообще нетрудно, поэтому сжатие с потерями выпадает как частный случай с сжатия без потерь. А потом шаг третий. Локальность. Мы ищем регулярности только в узком пространственном временном отсеке. Мы не можем себе позволить ездить в другую галактику для того, чтобы искать регулярности. Потом мы не перебираем все будущие. Шаг четвертый. Потому что это слишком много стоит. Мы не можем перебрать все, что может потенциалить, все, что мы можем увидеть до конца нашей жизни, мы не можем перебрать. Но для этого тоже есть решение, это в этом докладе рассказывал, что вы же уже нашли описание прошлого. И вы можете, а у вас монотонная машина Тюринга. Машина Антона, машина Тюринга может дальше просто не останавливаться. Если она не останавливается, она будет выдавать самое вероятное будущее. Это аргументировал в том докладе. И вы можете, вместо того, чтобы перебирать всевозможные будущие, вычислить самые вероятные развития будущего из ваших описаний. И таким образом вы можете планировать. Что касается восприятия, я вам уже рассказывал. Что касается мышления, допустим, тут вовсе не нужно использовать формальную логику. мы часто делаем для построения AGI-систем. Тут есть альтернативные логики, например, базовую simulation-based logic, Perceptual Symbol Systems называется. Она опирается на то, что мы можем делать дедуктивные выводы, просимулируя ситуацию в голове. Что будет, если я толкну стакан, то он упадет. Мы можем просимулировать это в голове или внутри системы и измерить результат. И, конечно, нам нужно иметь способность обобщить это каждый раз, когда я толкаю стакан. Но это индуктивное мышление, это как раз для этого вся система и построена. Это индукция. Как раз для этого она хорошо расположена. Вот так я смотрю на процессы мышления без формальной логики. Потом, если вы хотите делать прогнозы будущего, у вас вот программа Q, она описывает все ваше прошлое, вычисляет все прошлое. Но вы не можете себе позволить запускать программу, которая вычисляет все ваше прошлое, даже с потерями, для того чтобы спрогнозировать какой-то фрагмент вашего будущего. Тут будет более оптимально, если ваша память прошлого будет фрагментирована. И фрагментация описания – это как раз возникновение кусочков таких знаний, то, что мы обычно называем знанием о какой-то части нашего мира. Не в целом какое-то однородное описание, а какая-то часть нашего мира будет таким фрагментом. Если у нас есть эти фрагменты, можно ссылаться на них как на явную память. Ну а что, например, с неявной памятью? Неявная память, как, например, моторная память. Мы знаем, как на фортепиано сыграть какую-то пьесу. Мы давно уже не играли, но моторная память помнит. Это, по сути, моторные команды в высокой размерности, которые цепляются друг за другом. Если вы два больших числа, которые вместе всегда возникают, и часто возникают, тогда source-calling-theory, вам говорит рекорд-код Фа-Хафмана, вам лучше езжать вместе. И таким образом, что-то, что часто возникает, вы этому придаёте короткий код. Если это возникает вместе, вы будете вместе и живы. И таким образом, так можно объяснить неявную память, потому что тут длинная цепочка из высокоразмерных данных, которые друг с другом сцеплены. Оно не гибкое, как явная память, как декларативная память, но зато оно хорошо сжатое. Она помогает в тех случаях, где много повторяется, та же самая последовательность действия, это восприятие часто повторяется, и тогда такой формат сжатия будет оптимальным. И это получается, так стоит делать, если мы вообще хотим научиться ездить на велосипеде и другие сложные моторные задачи. Следующий аспект, например, почему у нас есть сенсорная память. В течение одной секунды мы можем сказать все, что попадает в глаза, у нас находится в этой сенсорной памяти. Ну, потому что для того, чтобы сжимать пространство, временные аспекты, нам не только пространство нужно, какой-то скриншот нашего восприятия. Но нужно и временная регулярность воспринимать. Что-то находится на том же месте. Но для того, чтобы это воспринять, вам надо записать, как видеозапись, хотя бы чуток. Насколько ваша сенсорная память хватит. Это же сильно размерные данные. И в этом именно алгоритмическая причина, для того чтобы временные регулярности распознавать и сжимать уметь, вам нужно сенсорное отдание. Потом пункт 10. Ренормализация. Я это в том докладе, это техника из физики, которая позволяет понизить размерность AX, из которых результат которого можно рассматривать как механизм внимания. Не буду сейчас в это вдаваться, это целая отдельная работа, но можно это так действительно толковать, и это тоже интересное развитие. Ладно, я уже потихоньку перехожу в свое время. Как вы видите, различные аспекты когнитивных способностей человека можно рассматривать как частный случай работы Айкси, если мы можем заставить его работать эффективно. В этом направлении можно двигаться и с теоретической точки зрения, до источника зрения инженерии. Это именно то, что мы пытаемся делать. Подхожу к концу. Мы тут постарались построить систематический подход к AGI, который основывается на трех аспектах. Психологический реализм или правдоподобие. На сильной теории. и пока еще скромных, но каких-то инженерных успехов в построении реальной системы. Теорию обзора сделал универсальные индукции и инкрементное сжатие как попытка найти эффективную аппроксимацию И это действительно можно рассматривать как попытку решить проклятие размерности. В конце я бы хотел сказать, закончить цитаты уже покойного Марвина Мински, большого мыслителя, И в своем последнем публичном выступлении он сказал, что всем стоит изучать алгоритмическую теорию информации, что все об этом изучить и до конца жизни над ней работать. Это, конечно, он с юмором, шуточку. Но я думаю, наполовину тут действительно доля правды. Я вижу в этом математическом языке наконец-то язык, математический язык, на котором мы можем выражать и в котором мы можем мыслить об интеллекте. На этом все. Спасибо за ваше внимание. 

S04 [01:34:00]  : Артур, спасибо большое. Очень интересно. 

S01 [01:34:09]  : Да, пожалуйста, есть вопросы. 

S04 [01:34:10]  : Мне эта история очень нравится. Я, кстати, в 2004 году первый раз... Кстати, вот я вот всё забываю спросить каждый раз, когда мы с вами пересекаемся. Мы совершенно случайно в 2004 году не делали похожий доклад по, так сказать, именно где сжатие. ставится в основу интеллекта. В 2004 году в Новосибирске случайно не делали этот доклад? 

S01 [01:34:42]  : В 2004 году я был студентом физики. 

S04 [01:34:45]  : Я просто запомнил, что первый раз эту идею услышал в чьем-то докладе в Новосибирске. Это Иршовская была конференция проблемы системы информатики. Не помню, кто это был. По-моему, какой-то был русский человек, но я даже забыл его фамилию. Не помню, из штатов он приезжал или наш был. Эта история мне запомнилась. 

S01 [01:35:06]  : Понятно, что я не придумал это все, но прожатие этой идеи уже давно существует и теми или иными людьми разрабатывается. 

S04 [01:35:17]  : Хорошо. Значит, вот у нас тут вопросы есть. Во-первых, вопрос личного характера. На чем вы специализировались по физике? 

S01 [01:35:29]  : Специализация была astrokein-teilchenphysik, значит это астро-ядерная и физика частиц. У меня была общая теория относительности, вот в этой сфере я работал, потом дипломная работа была уже. по нелинейным химическим сетям. Ну, в целом, да, астроядерная и так далее физика. 

S04 [01:36:05]  : Спасибо. Так, потом вопрос ещё тоже от Бабарыкина Евгения. На него, правда, по-моему, Вы ответили, что когда Вы рассказывали про кластеризацию, что кластеризация – это сжатие с потерями. А как же сжатие без потерь? Ну, по-моему, это Вы уже рассказали, что у Вас сжатие с потерями. 

S01 [01:36:23]  : Ну, кластеризация, если отбросить разницу между центром кластера и точке, тогда это сжатие с потерями. Если не отбрасывать ее, если вы шум воспринимаете как часть описания, то у вас сжатие без потерь. Да, я ответил на вопрос. Получается у нас шум автоматически выделяется как отдельный фрагмент описания. вы можете его оставить или выбросить, это уже на ваше рассмотрение. 

S04 [01:36:54]  : Спасибо. Дальше снова вопрос от Барыкина Евгения. Если я правильно понял, то мы выделяем признаковое пространство, и уже оперируя в этом пространстве, мы тем самым осуществляем сжатие. То есть получается, что объект мы описываем не координатами в вифклидовом пространстве, а признаками. 

S01 [01:37:15]  : Я искал этот вопрос. Если я правильно понял, то мы признаковое пространство и уже переразлили. Что-то я не понял. Если я правильно понял, то мы признаковое пространство. Выбираем? А, выделяем, понял. Нет, признаковое пространство находится на самое широкое пространство. Это набор всех машин тюринга. Вы можете их перечислить. Машины тюринга перечислимы. Для описания машины тюринга вы можете взять индекс этого перечисления. Для индекса вам нужен логарифм, чтобы описать этот индекс. У вас 1-to-1 map. этих машин тюринга к битовым строкам конечным. Получается длина машин тюринга получается длиной этой строки. Мы никак не ограничиваем пространство признаков теории. 

S04 [01:38:25]  : Спасибо. Мой вопрос. Там у вас был слайд, где вы на него ответили, вроде как отвечали, но можете еще чуть-чуть попытаться. У вас получается, что предиктор, он эквивалентен сжатию. Вот так ли это действительно? То есть можем ли мы сказать, что у нас задача построения идеального предиктора, она эквивалентна задаче идеального сжатия? 

S01 [01:38:53]  : Вот в одну сторону это точно так, если вы сжимаете оптимально, то у вас будет оптимальный предиктор. В обратную сторону я предполагаю, что это тоже так, но я не знаю доказательства. Но вы в любом случае всегда можете комментариями заполнить программу и ее искусственно удлинить, правильно? И таким образом у вас будет программа прогнозировать, но не быть кратчайшей или короткой даже. Вы можете всегда ряду надобностей запомнить. Я очень подразвиваю, что это будет так. Я еще не встречал случаев, где есть преддиктор, который не сжимает. которые не задержат каких-то очевидных. 

S04 [01:39:41]  : Да, то есть, я вот по-другому сформулирую вопрос. Я полностью согласен, что наличие эффективного сжатия является необходимым условием для предиктора и искусственного интеллекта. Достаточно даже. Да, но с другой стороны, мне кажется, что наличие предиктора не является достаточным условием для существования искусственного интеллекта, а сжатие не является достаточным условием для построения предиктора. 

S01 [01:40:13]  : Вы, кажется, перепутали. Сжатие как раз достаточно для постановления предиктора. Если сжатие, то предикция. Но сжатие, может быть, не является необходимым для предикции. Из предикции я не видел теоремы, из которой следует сжатие. Вы берете предиктор и как-то доказываете, что длина описания этого предиктора должна быть короткой. Вот такого рода теории я не видел. Но я предполагаю, наверное, это так. 

S04 [01:40:53]  : Сергей Терехов вопрос задал. Параметров может быть много, но информационная нагрузка каждого невелика. Нужно минимизировать суммарную информационную нагрузку, а не число параметров. Как быть с примерами generalization under overparametrization? Я тоже не очень понял. 

S01 [01:41:14]  : Информационная нагрузка. Да, я понимаю. Он имеет в виду, допустим, если у меня много параметров, но они все одинаковые, допустим, информационная нагрузка. Количество информации, которая совокупность таких параметров содержит, будет небольшой. Вот это он имеет в виду. То есть нужно минимизировать суммарную информационную Ну, вообще, если у вас слишком много параметров, то они имеют склонность быть очень разными, если вы их не заставляете быть одинаковыми. Но если вы их заставляете быть одинаковыми, тогда у вас есть программа, которая говорит, Запиши одинаковый вес в нейросеть в каких-то местах. Тогда ваше описание тоже будет короткое. Что нужно минимизировать? Суммарную информационную нагрузку нужно минимизировать. Число параметров минимизировать это частый случай минимизации информационной нагрузки. Иногда вы можете сказать, ладно, я оставлю число параметров большими, но информационную нагрузку сниму. Можно присверточные нейронные сети так рассматривать. Можно сделать вид, что там не окно, которое проезжает через вход, а где действительно все веса есть, но они одинаковые. Если веса все одинаковые, вы вот этим окном в сверточных сетях, вы как раз заставляете их быть одинаковыми. Это форма сжатия, которую вы просто жестко встраиваете в нейросеть, потому что вы хотите использовать, что наше визуальное пространство что признаки, их, скажем, характер признаков не зависят от их местонахождения в пространстве. Вот это вы используете. Это просто одна специфическая регулярность, которая в каких-то визуальных задачах верна, а у других она не будет верна. 

S04 [01:43:38]  : Спасибо. Дмитрий Садихов, вопрос. Даю руку. 

S00 [01:43:47]  : – Здравствуйте, Артур, здравствуйте все. 

S01 [01:43:49]  : – Здравствуйте. 

S00 [01:43:50]  : – Наконец-то я вас послушал, ваш доклад. Почти ничего не понял, но хотя бы послушал, потому что модерация не предполагает нормальное прослушивание, к сожалению. Вопрос у меня по эффективности вычислений в абсолютных цифрах. Сколько заняло обучение в крестике нолике? Пробовали ли вы игры с большим пространством вариантов, ну не знаю, там пять вариантов, например, или какие-то более сложные вещи? И если не пробовали, то какой прогноз? 

S01 [01:44:25]  : Ну вот эти крестики-нолики, он находит программу и решение там за секунду или что-то на моем обычном ноутбуке. Тут нет никакой тренировки, да, потому что нет оптимизационного алгоритма, по сути, ну кроме самого эквивалентного нажатия. 

S00 [01:44:43]  : Ну я неправильно слово, наверное, использовал, да, у вас не тренировка, у вас выбор оптимальной программы, но все-таки, получается, там, где пространство вариантов большое, там и, соответственно, ну, расчет этой программы должен быть, поиск этой программы должен быть большим. 

S01 [01:44:58]  : Ну вот я показал, программа состоит из нескольких операторов, я уже не помню сколько он перебирает, но это небольшие числа, чтобы их найти. По времени он меньше за секунду, чем за секунду справляется. А что касается вопросов, пробовал ли я другое, кристики нолики 4х4. Нет, не пробовал, но я знаю, что Я не встраивал размерность поля вручную, поэтому он должен справиться с 4х4 и 5х5. Спасибо. 

S04 [01:45:49]  : Вот еще, Артур, вы заговорили про язык. Структура языка предполагает некоторую компрессию. По сути, явную компрессию. Ну вот, а сам язык, вот с точки зрения, если мы берем, так сказать, там тему AGI или тему агента достаточно высокой сложности, работающего в достаточно сложной среде, вообще вот появление языка, он как-то с точки зрения фундаментальности сжатия как качества интеллекта объясняется или язык это просто побочный эффект связанный с необходимостью социализации и напрямую вот именно с интеллектом как сжатием не связан? 

S01 [01:46:34]  : ну честно говоря язык это такая сфера в которой я меньше всего разбираюсь у меня такой некоторый предрассудок Что именно второй пункт, который вы сказали. Сначала идет сжатие, а язык для необходимости коммуникации. И я понимаю, что там идут дебаты, language for thought, длинная философская история. И пока мне кажется, что, как я об interpretability говорил, что если вы сжимаете оптимально, то фрагменты вашей программы очень хорошо отображаются на слова или на какие-то концепции. Может быть, даже лексикальные концепции, lexical concepts. И вот это вот поразительный такой эффект. Как мне кажется, может быть, действительно я ошибаюсь, что когда мы используем язык для для коммуникации, для того чтобы перенести информацию другому человеку, то у нас есть предположение о том, что он знает, и мы передаем резидуум некоторым, остаток. То, чего он еще не знает. То есть, я говорю, что чашка находится на столе, я предполагаю, что он знает, что такое чашка, что стол, что у нас общая пространство и так далее. То есть, что он уже описал пространство, в котором мы находимся или в котором я нахожусь, а не он. Уже с некоторой точностью у него есть описание этого пространства. Но у него есть некоторая информация, которая ему не хватает. И мы, может быть, вычисляем разницу между тем, что мы знаем, и тем, что мы предполагаем, что знает наш собеседник. И вот эту вот алгоритмическую разницу мы с потерями переносим. И вот так вот образуется, в крайней мере, часть языкового поведения человека. Спасибо. Да-да-да, ну это вот такая вот маленькая мечта моя, ставить видео, в какой-то момент разговаривать с человеком о таких обыденных вещах, что там на столе стоит, в каких-то там объектах, задавать вопросы и действительно разумно об этих простых вещах говорить. Ну это не только моя, об этом мы все мечтаем. Вот и я надеюсь вот таким путем к этим прийти. Действительно вот если он будет разбивать, первые шаги будут тогда, когда он начнет действительно разбивать объекты на разные части, тогда можно уже автоматизированно отображать это на язык. Хотя бы на существительный пока. Потом он может уже понимать, что там Квадрат это частный случай прямоугольника. И тут тоже уже идет отображение на язык, потому что программы очень похожие. Один раз два параметра фиксированы, другой раз нет. И таким образом о других объектах тоже. 

S04 [01:50:03]  : Спасибо. Вопрос Сергея Терехова. Как быть с отжатием плохих, зашумленных, нерелевантных и неправильно обработанных данных? Это проблема уровня Exploration-Exploitation. Проблема релевантности. 

S01 [01:50:23]  : Ну, во-первых, проблема с шумом. Значит, сжатие отделит шум. Вам, получается, нужно искать описание, прогноз, так, чтобы разница между прогнозами и данными была шумом, и чтобы вы их могли отделить. Как я уже говорил, сжатие будет отбрасывать шум. А что касается нерелевантности, тут уже идет... помимо сжатия дополнительно reinforcement learning, еще дополнительно, значит, у нас есть реворды, которые в системе говорят, это важно, а это неважно. И тут я вот в моем докладе, на котором я ссылался, на нашем окомском YouTube-канале, можете найти 2019 года Toward Analytics Approximation, кажется. доклад, там рассматривается реанимализация, то есть техника истерической физики, которая позволяет понизить размерность AIC. И для того, чтобы откинуть нерелевантные данные, вы делаете трансформацию данных, называется coarse graining, огрубление данных, таким образом, чтобы информация о ваших ревордах осталась инвариантной. Значит, у вас есть x, вы отображаете его в более короткий y, таким образом, чтобы информация x о ревордах была одинаковой к информации y о ревордах. Это с помощью шененовской информации. Короче, это отдельный кусок работы с ревордами, с релевантами. Сжатие с учетом релевантной информации. Это отдельная теоретическая работа, которую предстоит еще сделать. На этот путь я начал идти, но еще сильно далеко не продвинулся. Но я думаю, по этому пути надо дальше будет идти. 

S04 [01:52:37]  : Артур, вы дали ссылку на канал. Это на ютьюбе называется АКАМ Одесса, да? 

S01 [01:52:42]  : Да, верно. 

S04 [01:52:43]  : Я там кинул ссылку в чат. Хорошо, спасибо. Вопрос еще от Сергея Терехова. Здесь нет выпуклости. Существует комбинаторно много разбиения на сжимаемые элементы с различной длиной суммарного кода. Пример. Две несжимаемые последовательности из минус единицы и о единице. Каждая по отдельности несжимаема. Но в сумме они дают последовательность из нулей. Значит, в общем коде одну из этих последовательностей можно просто отбросить. Как инкрементальный процесс может гарантировать короткую длину общего кода? 

S01 [01:53:22]  : Две изжимаемые последовательности из минус один и плюс один. А, методик случайно как-то чередуется. с одинаковым количеством минус единиц и единиц, я так понимаю, чтобы в сумме была единица. Вот. Одну из этих последовательностей можно отбросить. Так, почему ее можно отбросить? 

S04 [01:53:57]  : Сергей, может, поясните? 

S01 [01:53:59]  : И почему? Какого общего? 

S02 [01:54:04]  : Можно, да? 

S01 [01:54:05]  : Да, пожалуйста. 

S02 [01:54:06]  : Артур, ну раз уж дали мне микрофон, во-первых, спасибо огромное вам за доклад. И одна секунда, я действительно, поскольку я со статистической точки зрения подхожу, а не с алгебраической, вот как вы, да? действительно вопрос вопрос сжатия и обобщение это ключевое ключевое место уже в течение там наверно с самых начала так сказать там стратегические теории там он всегда там обсуждался конечно конечно да и есть результаты о предикторах которые оптимальны по жатию но это результаты не алгебраические вообще теория калмогоровская, она же алгебрическая теория. 

S01 [01:54:42]  : Вы имеете в виду шахтановскую теорию информации. 

S02 [01:54:45]  : Да-да-да. А вот в теории информации такие результаты есть, и действительно это... А по поводу вот чего. Есть очень много невыпуклых задач. Таких задач, где отдельно каждый шаг сколь оптимален он бы ни был, или несколько первых шагов, которые могли бы быть оптимальными, они на самом деле не приводят к тому, что решение всей задачи является оптимальным. Ну задачи о рюкзаке и так далее. И в частности, вот совсем банальный пример, это вот эти две последовательности. Ну вот мы берем последовательности две, то есть два очень сложных объекта, не сжимаем. Каждый из них алгоритм скажет, что я не могу его сжать, программа равна самой последовательности, ничего лучшего я придумать не могу. Но если я их сложу, то я получу 0. Это означает, что оптимальный код полной суммы этих двух последовательностей, он такой. Вторая последовательность равна 0 минус первая. Это на одну из последовательностей я могу просто выкинуть. 

S01 [01:55:38]  : В смысле полной, полной суммы? Оптимальный код чего? 

S02 [01:55:42]  : Оптимальный код этих двух последовательностей как компаунда, как объекта, состоящий из двух последовательностей. Оптимальный код такой. Нужно взять одну из последовательностей как код, потому что она ненужна. А вторая не нужна, потому что маленькое утверждение. Она равна просто 0 минус первая последовательность. Так вот такой оптимальный код возникает только если решать задачу сразу для двух последовательностей. Но его нельзя получить инкрементально, решив сначала сдачу для одной последовательности, а потом для другой. Это просто квинтэссенция простого примера, когда мы имеем дело с невыпуклостью. я вот там в чат послал ссылочку есть даже такой большой вы имеете ввиду вот одна последовательность один минус один один минус один другая вторая строго строго обратно ей строго обратно начинаете сжимать алгоритм сжимает одну говорить не могу сжать записываю в память неизмененной Жена другую тоже не может сжать, записывать в память неизмененной. И поскольку он никогда не видел задачу целиком, вплоть до самого конца, когда задача уже целиком сформулирована, то он не видит оптимального решения, которое равно просто 0 минус одна последовательность. Это генетическая проблема. Если бы не эта проблема, то вы были бы абсолютно правы. Никакое машинное обучение не нужно было бы обсуждать. И оно действительно простое тогда, когда задача выпукла. То есть когда она может быть решена по координатным способам или она может быть инкрементально решена оптимизацией отдельных кусков. Но как только задача не такая, то вы возвращаетесь к исходной комбинаторной проблеме. Артур, извините, я сейчас договорю и отключусь, чтобы просто не тратить потом время. Я просто хочу вас поддержать на самом деле. Это я не потому, что я вам какую-то занозу там вставляю. Я хочу вас поддержать вот в каком плане. Очень много задач, которые важные, практически ценные, полезные и так далее, не содержат вот этой самой пресловутой комбинаторной сложности. И для того, чтобы создать удачную систему, которая хорошо ведет себя с точки зрения поведенческой, демонстрирует интеллектуальные свойства, там и так далее многие вещи, можно просто наплевать на эти комбинаторные сложные задачи и двигаться. Просто сказать, а мы не будем их рассматривать. И с практической точки зрения вы получите в принципе вполне себе нормальную хорошую работающую систему. В этом смысле это вопросы скорее таки профессиональные, что Не все задачи таким образом могут быть решены, вот собственно суть утверждения. Но это не значит, что нужно ломать голову и обязательно биться о самые сложные задачи. 

S07 [01:58:16]  : Спасибо огромное вам, я отключаюсь, чтобы вам не мешать дальше. 

S01 [01:58:24]  : Хорошо, спасибо, действительно, все ссылочки киньте, я посмотрю. Насколько я вас правильно понял, вы начинаете решать задачу и потом дополнительный кусок. информация приходит и потом задача меняется. Тут действительно задача инкрементного сжатия не так была поставлена в проблему, где дополнительная информация не добавляется и такие проблемы не возникают. Ну да, да, я посмотрю дальше на вашу ссылку и потом смогу более грамотно ответить. 

S04 [01:58:57]  : Спасибо. Мой еще вопрос есть. Вы говорили про то, что качество сжатия зависит от разбиения. Но у нас одна и та же проблема. Она может быть представлена разными наборами данных в зависимости от их обстоятельств. Грубо говоря, берем тестовую выборку, разбиваем на подвыборки. И в каждой подвыборке может быть свое распределение параметров. Разные наборы данных могут приводить к разным разбиениям и по-разному сжиматься. На первых шагах у нас могут быть разные параметры, которые являются критическими для разбиения. И тогда получается, что у нас каждая модель оверфитится по-своему и у нас нет генерализации. Потому что когда мы начнем эти модели стыковать, они будут несовместимы. У меня есть такое ощущение, что мы в итоге можем получить тот же самый оверфитинг и отсутствие генерализации, как и в нейронных сетях. Как в этой ситуации быть? 

S01 [02:00:05]  : вы имеете ввиду допустим набор данных и мы их разбиваем и фитим допустим линейной регрессии например и тогда получается если вы разбиваете данные там где они действительно меняются на этом стыке, если вы так их разбили тогда у вас будет оптимальное сжатие. И тогда будет у вас оптимальный прогноз, потому что на этом отрезке одна модель действует, на этом отрезке другая модель действует. Если вы разобьете где-то неоптимально, где-то посередине, тут или тут, то для этой крыши вам нужна будет отдельная модель, для этих отрезков еще отдельная модель. Когда у вас будет описание длиннее и оффорфитинг у вас будет, конечно, будет слишком много разных параметров. Не уверен, ответил ли я на вас вопрос, но само разбиение является уже задачей для сжатия. 

S04 [02:01:17]  : Спасибо. Игорь, пожалуйста. 

S03 [02:01:23]  : Да, добрый вечер еще раз. Артур, огромное спасибо за доклад. Я с огромным удовольствием послушал. Прям очень интересно и очень последовательно и методично. Огромное спасибо. Мой вопрос-комментарий, он относится уже к последней части доклада. к вашим вот когда вы говорили про карту прогноза там типа пункт четвертый прогнозирование вот но Я, по-моему, говорил, что мы с Сергеем Шумским делаем некую модель Шумского. Она тоже в основном про сжатие. То есть я в этом смысле... Мы тоже занимаемся условно, так сказать, машинообучением, основанным на сжатии, но оно просто по другим принципам, но это не так важно. Но в этом месте там есть как бы тонкая вещь. Видимо, я так иду, может быть, на шаг впереди того, что вы делаете. ну еще сперва скажу, что сжатие без потерь как бы на самом деле в реальной жизни не нужно. в реальной жизни для реальных задач можно сжимать там с большими потерями и все нормально работает. но вот что точно не работает это прогноз такого рода. Потому что то, что вы рассказывали, неявно подразумевало ситуацию, когда ваш агент смотрит на поток данных и никак на него не воздействует. И тогда предсказание является абсолютно правильным. То есть если я сижу на потоке данных, вылавливаю из него паттерны, 100%. Но как только вы пытаетесь сделать агента, который влияет или точнее на которого среда влияет и который сам пытается влиять на среду то такой прогноз оказывается уже не работающим ну как пример вы показывали там значит этого ну игру христики нолики и там мы там тоже проходили а значит я сейчас там мой текущий там этап это опана и джим и мы там не сопровождаемся в джиме и в частности я там вот играю в пинг-понг а ну не я мой марки вас видим а у меня марки значит он играет и проблема в том что есть агент который против него играет как бы все время поэтому наиболее статистически вероятный прогноз любого движения это проигрыш просто потому что если я как бы просто игра и просто запоминаю все что происходило и сжимаю это и просто пытаюсь предсказать что будет дальше то самый вероятный прогноз это что я проиграю ну Марти проиграет, а нужно искать варианты, в которых он наоборот выиграет. И они статистически не как раз мизерные. потому что статистически таких событий в прошлом было значительно меньше, чем мне бы хотелось. И вот тут возникает просто новый момент некий. Он связан с тем, что здесь сжатия уже недостаточно. И тут возникнет проблема эксплуатейшн, эксплорейшн, как у всех. В общем, она стабильная. И вот, собственно, мой вопрос. да и еще одна там проблема состоит в том что реварды отдаленные я так понял что вы когда играли там в крестики нолики с этим аксисом акси вы делали ревард как бы на каждом шагу и 

S01 [02:05:16]  : Да, там реворд на каждом шагу будет. Он будет нулевой, если там ничего не случится. Ну как, вообще, выигрыш, если он выиграет, плюс один, если проиграл, минус один. 

S03 [02:05:28]  : нелегальный ход делает, то минус 100. я бы тоже начинал с такого же, что как бы реворды на каждом шагу, но в реальной жизни проблема в том, даже в простой модели типа open edge, что как бы реворд отдаленный всегда, ну шагов на 50 хотя бы, а то как бы там ну вообще он может быть в пределе сколько угодно, отдаленный типа шахмат. И здесь ваша модель тоже, к сожалению, попадет в... Решать. Проблема и задача. Просто надо подумать. Но я к тому, что это... Я думаю, что это не совсем предсказание. Вот, собственно, вопрос мой. Я правильно понимаю, ну, как бы, ситуацию? Или вы что-то делали, чего я не... Отчего я не уловил? 

S01 [02:06:28]  : С точки зрения теории, тут не существует никаких проблем, потому что даже если реворд отдаленный, я могу всегда перебирать все комбинации до конца жизни, если у меня нет ограничений на ресурсы. И также, если у меня среда противопорствующая, то это тоже не проблема, потому что в Экспекте Макс превращается в Мини Макс, это уже Кутер показал, и действительно агент может играть оптимально таким образом. Но проблема, конечно, на практике, вы правильно говорите, и я не стану утверждать, на данный момент все решено. Инкрементное сжатие тоже проходит без каких-то проблем в теории. На практике нужно будет трансформировать систему на более низкоразмерную. То есть проблема отдаленных ревортов, я думаю, должна решаться так, что мы будем абстраироваться от маленьких микродействий, микросостояний на какие-то макродействия. В ping pong, допустим, давайте передвинем эту штуку на правую часть экрана. Или какие-то макродействия, макропланы. И в таком низкоразмерном пространстве реворд уже не будет отдален, если его достаточно огрублять. И тогда уже тупой поиск найдет решение. Проблема в этом отображении, с высокоразмерного в низкоразмерное такое макропространство. И я думаю, тут опять помогут техники реанимализации и Information bottleneck. Это действительно нужная, это дополнительная работа, которую надо сделать. Но я пока не тороплюсь в эти сферы. Я понимаю, что после того, как Альфа-Зиру выиграла чемпиона по ГО и по шахматам, крестики-нолики не очень впечатляющие. Но я стараюсь не торопиться в пространство высоких сложностей, идти в шип и сначала построить нормальное, хорошее сжатие. А потом мы будем работать над трансформацией в более низкоразмерные пространства для того, чтобы справиться с высокоразмерными реалиями настоящей жизни. Таким образом будем пытаться с этим работать. Но Вы совершенно правильно откладываете это. Это важные вопросы, которые надлежат решать. 

S03 [02:09:33]  : в любом случае очень здорово и правильно двигаетесь и первый шаг это просто отойти пока от ревордов на каждом шагу и делать условно реворды только там в конце игры и ситуации картинка уже кого-то поменяется немножко она ухудшится несколько даже в поле 3 на 3 там все равно на несколько шагов Спасибо, Артур. 

S04 [02:10:01]  : Спасибо. Артур, еще парочка вопросов от меня. Во-первых, про Open GYM. Я так понял, что вы до Open GYM еще не добрались, по той же причине, про которую вы сказали, что вы фундамент строите пока. Open AI GYM. Open AI. Да, OpenAI GYM. Не понял, GYM? Вот этот вот OpenAI проект, GYM, где там всякие игрушки. 

S03 [02:10:32]  : Это как раз среда для виртуальных агентов, уже готовые. Вы своего агента туда подключаете, а он отрисовывает все пространство и дает все реворды. Очень хорошая, удобная штука. 

S01 [02:10:42]  : Я просто не слышал об этом. 

S04 [02:10:44]  : Я кину потом ссылку. И второй вопрос. То, что вы говорите про эффективность сжатия. Вы как-то связываетесь с эффективностью энергопотребления? 

S01 [02:10:57]  : С эффективностью чего? 

S04 [02:10:58]  : С эффективностью энергопотребления. Вот это определение по пионку, что интеллект – это не просто способность решать задачи в разных средах и сложные цели в сложных окружениях, а еще и в условиях ограниченных ресурсов. То есть, не является ли сжатие как раз способом минимизации потребления энергоресурсов и ресурсов? 

S01 [02:11:24]  : Да, да, конечно. Это как раз один из важных элементов, что, как я называю, не лезть в пространство высокой размерности, когда осуществляю поиск. Если надлежит перебрать все комбинации нулей единиц длиной 20 допустим, то это не стоит делать, это пространство высокой размерности. Стоит перебирать программы и параметры к этим программам, которые воссоздают И если их перебирать, тогда сначала будут возникать простые последовательности. Все будут там, ну и все единицы, или 0, 1, 0, 1, такие вот. И это как раз будет подходящий bias, такой сдвиг, кажется, по-русски, в направлении более простых и поэтому априорно более вероятных решений. Это как раз сжатие, которое помогает в поиске. 

S04 [02:12:31]  : Спасибо. Я, кстати, кинул ссылку на OpenAI Gym в Zoom. Следующий вопрос от Бабарыкина Евгения. Сжатие не повлечет ли за собой потерю обобщающей способности нейросетей? 

S01 [02:12:49]  : обобщающей способности нейросетей. Смотря как рассматривается обобщение нейросетей, я тут различаю интерполяцию и экстраполяцию. Мне почему-то кажется, что трудно вообще говорить об обобщении, если нет экстраполяции за пределами распределения входных данных. Мне трудно представить, что с нейросетями можно где-то двигаться в направлении AGI именно по этой причине. Вот можно простой пример взять. У вас есть круг. У круга есть определенная асимметрия. Если вы будете подгонять какой-то класс функций, которые не содержат описания круга, как корень, квадрат, сумма квадрата, а атом поленом, допустим, У полинома он будет интерполировать хорошо в какой-то мере, а потом будет экстраполировать плохо. Если понижать размерность полинома, то рано или поздно он сломается и вообще будет плохо прогнозировать. И таким образом я воспринимаю работу в то, что будет случаться в нейросетях, если вы будете понижать размерность. Но рано или поздно она полагается и будет все хуже и хуже. Это просто последствия того, что класс функций, который вы выбрали для аппроксимации данных, не подходит к данным. Этот класс функций не содержит ту структуру, которая находится в данных. Она не содержит те симметрии, я наверное сейчас расплывчато выражаюсь. Но класс функции должен быть достаточно широким для того, чтобы находить симметрию регулярности, которая находится в данных. Если он для этого не способен, то возможно только аппроксимации. В нейросетях, как известно, чем лучше вы хотите аппроксимировать, тем больше должна быть сеть. Это как раз свойство свойства, которого мы не хотим. Мы хотим четкое описание. Если вы описываете круг как корень из сумм квадратов, тогда уже неважно сколько точек будет на круге, у вас будет точное описание, но оно не будет возрастать с требованием повысить точность. Я думаю, это важный аспект, который часто игнорируется. Нужно задать вопрос, а класс функций, которые я аппроксимировал, он содержит рептуар регулярность, которую я хочу описать, или не содержит? Если нет, то как бы не избиваться, он не справится с задачей. Интерполяцией не стоит обольствоваться. 

S04 [02:16:14]  : Спасибо. У нас практически кончились вопросы. Здесь, правда, пара ремарок есть. Может быть, вы прокомментируете. Александр Балдачёв пишет, что похоже на физический принцип наименьшего действия. Можно эффективно применять, но сам собой он ничего не объясняет. Просто вычислительный метод. Бабарыкина Евгения отвечает, почему не объясняет. Всякая динамическая система стремится к состоянию с минимальной потенциальной энергией. 

S01 [02:16:47]  : Во-первых, я в части, где об общей психологии когнитивной говорил, как раз есть амбиции выдвигать этот принцип в качестве теории мышления человека, человеческого разума. И как раз тут, я думаю, много потенциала для того, чтобы объяснить именно поведение человека. Может быть, я неправильно понимаю вопрос. Может, имеется в виду с инженерной точки зрения объяснить, как построить систему. 

S04 [02:17:27]  : Александр Балдашев, прокомментируете ваш вопрос или ответ получили? 

S05 [02:17:33]  : Хорошо. Добрый день. Большое спасибо за доклад. Хороший пример вы привели по поводу мышления. То, что да, действительно, мы всегда можем в любой деятельности, скажем, мыслительной деятельности, в результате, в конечном итоге, показать, что у вас принцип работает, что был получен результат с наименьшим размером алгоритма, но по сути это всего лишь то же самое, как и в физике принцип наименьшего действия. Мы можем траекторию отследить, что да, траектория удовлетворяет этому принципу. Но при этом что произошло? Что двигалось? Куда двигалось? Зачем двигалось? Никакого объяснения мы здесь не получаем. Так и в вашей ситуации, что действительно результат удовлетворяет. Но что за результат? Он одинаково будет годиться и для достижения, скажем, сходить в магазин, оптимально совершить покупки, и одинаково для решения какой-то научной задачи, и для, скажем, юридических вопросов. Здесь объяснение на уровне именно объяснительном, семантическом. Скажем так, здесь нет никакой семантики. В принципе нет и быть не может. 

S01 [02:18:53]  : Насколько я вас понимаю, что вы требуете, что настоящее объяснение должно быть... говорить о конкретном феномене. 

S05 [02:19:06]  : Давайте еще раз поясню на принципе естественного отбора. То есть мы говорим, что принцип естественного отбора обеспечивает, объясняет нам эволюцию, природную эволюцию, биологическую эволюцию, но при этом сам принцип не накладывает никаких ограничений. Что бы ни произошло, будет происходить в результате принципа естественного отбора. И когда мы спросим, будем проводить какой-то эксперимент, что в результате естественного отбора получится? Мы не знаем. Обязательно получится то, что соответствует принципу естественного отбора, но предсказательной и объяснительной функции у естественного отбора нет. 

S01 [02:19:50]  : Я не эксперт по теории эволюции, но, насколько я знаю, есть и прогнозы, как и в любой нормальной науке, которые потом проверяются и подтверждаются экспериментами именно в теории эволюции. В принципе, минимальное действие — это minimal action, я так понимаю, в переводе. Ну Лагранжан, принцип Лагранжан. Ну да, потом Лагранжан ведь функция следует, она вычисляется из минимизации действия и функция Лагранжа уже потом Ну да, но именно в этом и сила унификации, общего объяснения. Я думаю, хорошая теория должна быть способна объяснить самые различные феномены. К этому и стремится физика, объединяя электродинамику, механику и так далее. Именно к этому все строение физики 20 века и до того и шло. В этом идет сила, я думаю, потому что она может на стыке пересечения бывших теорий тоже выразить прогноз. Именно свойство спрогнозировать именно как раз и является силой этих теорий. И я не хочу сжать на тот же уровень теории и физики, потому что последние значительно дальше продвинуты, но самое намерение, я думаю, стоит одобрить, потому что они для психологии бы дали бы такой который можно и опровергнуть, а который можно и проверить, и подтвердить, и который сможет широкий спектр финансов. 

S05 [02:21:57]  : Я думаю, опровергнуть нельзя будет. Почему? Обязательно подтвердится. Допустим, что ваш принцип верен, тогда его проверить нельзя, иначе он не научен. То есть нельзя поставить эксперимент, в котором бы достижение цели было, скажем, при максимуме, а не при минимуме. Это то же самое, как и Гранд-Жан. Вот ваш пример с разными научными теориями обобщения – это хорошо, но, скажем, принцип наименьшего действия, Из него нельзя вывести разницу между статистической механикой, квантовой механикой, электродинамикой. Он работает везде, из него не получится никакой дифференциации. Когда мы говорим о применении какого-то принципа в психологии или в мышлении, этот принцип должен задать какое-то разграничение, где он работает, где не работает. А он получается такой универсальный, но он всегда будет работать. 

S01 [02:22:56]  : Ну вот я привел пример с топографическими картами и с этими картами маршрута. Принцип сжатия бы как раз сделал прогноз, ну если люди действительно сжимают, то рано или поздно они будут переключаться с карт маршрута на топографические карты. И если будет выявлено, что большинство людей всё-таки начинают с топографических, а потом переключаются или наоборот, то вот уже опровержение, по крайней мере, для этой сферы психологии. 

S05 [02:23:33]  : Хорошо, спасибо. Самое главное, что принцип наименьшего действия где-то в этой русле лежит, именно в своем всеобъясняющем таком направлении. Спасибо. 

S04 [02:23:50]  : Спасибо. И у нас последний вопрос от Евгения Витяева. Евгений Евгеньевич, пожалуйста. 

S06 [02:23:56]  : Да-да. Доклад очень интересный, и все расписано довольно подробно и хорошо. Но у меня в конце концов возник такой вопрос. Вот те примеры, которые вы приводили в самом начале, они описываются в разных антологиях. Вообще, так говоря, задача IDI должна описываться в разных предметных областях, и в разных антологиях. Для того, чтобы эти задачи свести к определению определенного алгоритма и определенного сжатия, нужно в этих антологиях сначала сформулировать эти задачи, закодировать их таким образом, чтобы можно было потом применить алгоритмы сжатия и найти нужные программы, Но в этом случае мы получаем, что у нас сама программа само сжатия отрывается от антологии. А нельзя ли все-таки для того, чтобы реализовывать EGI в достаточно общем виде, нельзя ли применить процесс сжатия внутри самих антологий? То есть предполагаю, что мы сжимаем информацию, в терминах самих антологий, в терминах тех моделей предметных областей, где работают определенные специалисты. И в этом случае, если мы будем сжимать эту информацию в ихних терминах, мы, с одной стороны, будем это делать, в том числе, неинтерпретируемо для них, и в том числе, в этом случае, нам не нужно делать дополнительное кодирование, которое должен делать специалист, а он это делать не может. То есть, если такая проблема, и планируется ли перенести способ кодирования и построения программ изжатия, который был бы применим в разных предметных областях, применительно к разным онтологиям. 

S01 [02:25:40]  : Не уверен, понимаю ли я, что вы имеете в виду онтологию. Разные профессионалы специализируются в разных сферах деятельности. 

S06 [02:25:47]  : В разных переменных областях, где по-разному совершенно, в разных терминах, в разных языках, по-разному описывают эти задачи. 

S01 [02:25:55]  : Во-первых, когда я говорил о языке описания, я имею в виду, конечно, формальный язык, язык программирования. 

S06 [02:26:04]  : Онтология – это и формальный язык. 

S01 [02:26:08]  : Вот тогда я вас не понимаю. Если вы говорите о конкретных профессионалах, там плотник описывает свою сферу деятельности по-другому. 

S06 [02:26:19]  : Врачи описывают больничные мести. Антология – это формальный язык, в котором описывается система терминов данной предметной области. В этой системе терминов конкретной предметной области описываются их конкретные задачи. Так вот, для того, чтобы применить к их конкретной задаче, в частности некоторым из тех, которые вы приводили в самом начале, нужно из их антологии эти задачи закодировать, чтобы иметь возможность для них устроить сжатие с помощью алгоритмов. Но вопрос такой, а нельзя ли сжатие пытаться делать сразу в антологиях, сразу в этих родительских языках? Это существенно бы расширило область применимости процесса сжатия. И более того, если бы он это сжатие проводил в термах антологии, оно было бы более интерпретируемо. 

S01 [02:27:11]  : Да, думаю, понимаю. Ну, тогда вам придется для разных этих антологий строить разные системы и разные языки использовать. Там возникнет проблема, как между этими антологиями будет коммуникация, как это интегрировать вместе. И я думаю, эта проблема не проще, чем то, что я пытаюсь сделать. Получается очень много разных сфер деятельности. 

S06 [02:27:46]  : В этом случае мы возвращаемся к коренному вопросу – EGI. Он действительно общий, он действительно универсальный. Если он действительно универсальный, он в состоянии приспособиться к разным онтологиям, к разным языкам. Если он уже не универсальный, тогда нам нужно делать свои отдельные алгоритмы в каждом языке, в каждой онтологии отдельно. 

S01 [02:28:07]  : В этом как раз сила математической формулировки Айкси, что она определяет один класс функций, это перечислимый снизу полумер, это очень широкий класс. и в этом классе доказывает оптимальность, что агент может себя интеллектуально вести оптимально в любой из этих сред. 

S06 [02:28:39]  : Нет, это все здорово и хорошо, но дело в том, что у меня как раз подозрение, что даже вот эту технику, ее можно перевести в различные онтологии, в различные Есть еще понятие конструктивной модели. Что делается в конструктивных моделях? В ней кодируется модель, которая может использовать разный язык разной предметной области. Так вот, есть ли возможность вашу технику применять к различным конструктивным моделям вне зависимости от их сигнатуры языка? Тогда о сохраниться универсальной встречается. 

S01 [02:29:13]  : Вы можете для разных языков формулировать, допустим, инкрементное сжатие? Мне непонятно, какую пользу это принесет. Для того, чтобы это было интерпретировано для профессионалов в этом языке? 

S06 [02:29:29]  : Нет, для того, чтобы понять, насколько универсальны идеи. Действительно ли они совершенно универсальны? Мне все-таки нет. 

S01 [02:29:37]  : Но это же уже доказано в математических теориях универсального интеллекта, что он универсальный. 

S06 [02:29:42]  : Нет, это доказано для конкретного языка, а фактически вопрос сводится к тому, чтобы это было применимо к совершенно разным языкам, разным предметным областям. 

S01 [02:29:52]  : Ну это у нас же универсальность вычислений, поэтому можно переключаться с одного на другой язык и оплачивать для переключения всего лишь константу. Он так и так с точностью до константы этот выведен, и поэтому он для всех языков универсальных. 

S06 [02:30:11]  : Нет, в этом-то и проблема. Тогда нужно строить достаточно универсальный язык. Причем это можно делать через определенную нумерацию конструктивных моделей. Есть достаточно универсальная нумерация. Но тогда нужны разные модели, по-разному делать для них нумерацию. Для этих нумераций по-разному ставить задачи, поиска в них сжатия. Но в этом случае, для того чтобы действительно HDI был наиболее общим, тогда нужно в тот язык, который вы используете, и в ту теорию, которую вы используете, где разработан универсальный язык, включить в него в том числе разные способы конструктивизации моделей. 

S01 [02:30:54]  : Вы имеете в виду перечисление этих машин тюринга, что можно по-разному перечислить, или что опорная машина может быть… Выбор опорной машины… Вы об этом, наверное, говорите, что оно неоднозначное. 

S06 [02:31:07]  : Ну, опорная машина, то есть есть как бы универсальная конструкция, но это немножко другой вопрос. Все-таки вопрос остается к применимости, к разным антологиям, к разным предметным областям. Как это можно делать? 

S01 [02:31:25]  : Ну, не уверен, что я точно понимаю, что вы имеете ввиду, я как-то не вижу Скажем, я был бы рад, если бы можно было построить систему, которая умеет делать то, что умеют делать все. Common sense knowledge. И уже применение к разным специализированным каким-то областям – это уже последующий шаг. Пока мы не достигли даже этого, даже то, что любой 7-летний ребенок умеет, мы даже этого не достигли. 

S06 [02:32:01]  : Ну хорошо, понятно. 

S04 [02:32:03]  : Хорошо. Коллеги, всем спасибо. Больше всех спасибо Артуру. Там еще был вопрос по поводу презентации. Буду ли есть возможность получить презентацию, Сергей Стерихов спрашивает. Во-первых, Артура Франца можно в Фейсбуке найти и у него спросить. Артур, если вдруг слайды доступны, то можете либо мне скинуть. 

S01 [02:32:27]  : Да, я слайды могу опубликовать или вам скинуть. Фейсбук я могу переслать в любом случае. Да, давайте вам скину и вы опубликуете. 

S04 [02:32:41]  : Хорошо. Спасибо. 

S01 [02:32:44]  : Спасибо вам за вопросы. Действительно интересные вопросы. Я был действительно рад выступить, рассказать. 

S04 [02:32:55]  : Хорошо. Все, Артур, спасибо. Коллеги, всем спасибо. До новых встреч. Да, спасибо. До свидания. 









https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
