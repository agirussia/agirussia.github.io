## 27 августа 2020 г. - ADAM на пути к AGI - Сергей Шумский - Семинар AGI
[![Watch the video](https://img.youtube.com/vi/Alh9IMKpIPQ/hqdefault.jpg)](https://youtu.be/Alh9IMKpIPQ)


Суммаризация семинара:

ТЕМА
Семинар по развитию искусственного интеллекта (ИИ) и обсуждению подходов к достижению цели искусственного гениальности (AGI), включая философские и методологические аспекты.

СУТЬ
Ключевые концепции семинара включают:
- Обсуждение и анализ различных подходов к ИИ, в том числе нисходящего обучения и подходов, основанных на символах.
- Приведение примеров использования символьной программы для обучения элементарным движениям, таким как катание на каяке, и то, как эти элементы могут быть только обучены в комплексе.
- Философский и методологический анализ подходов к ИИ, включая важность символов и непрерывных движений, а также стратегические цели операционной системы для роботов.
- Рассмотрение вопросов об общественных и социальных аспектах развития ИИ и его влияния на жизнь человека.

ДЕТАЛИ
Технические аспекты семинара включают:
- Разбивка сложных программ на элементы и обучение через фиксацию определенного числа элементов и попытку увязать их в динамике.
- Обсуждение идеи DeepMind по использованию Reinforced Cloning для оценки предыдущих позиций на основе выигрыша в конце игры.
- Сопоставление подходов к ИИ, где компания Мифишная рассматривается как сторонник нисходящего обучения, в отличие от подхода, предложенного на семинаре, который предполагает локальное обучение в каждом слое без передачи ошибки через все слои.

РЕЗУЛЬТАТЫ
Основные достижения семинара включают:
- Понимание того, как символы и непрерывные движения взаимодействуют и как они могут быть использованы для достижения AGI.
- Анализ вопросов философии и методологии ИИ и их влияния на общества.
- Обсуждение перспектив и потенциальных проблем, связанных с внедрением ИИ в различные аспекты жизни.





S05 [00:00:02]  : Так, коллеги, запись пошла. Сергей, вам слово. 

S11 [00:00:10]  : Да, спасибо. Ну, я еще раз всех приветствую. Ну, давайте тогда я перейду к презентации и буду рассказывать уже по худоделу. Сейчас мы восстановим показ экрана. Так, все пошло. Ну, давайте теперь я перехожу к презентации. Видно всем? Слышно? 

S05 [00:00:44]  : Слышно, да, и сейчас видно слайд. 

S11 [00:00:47]  : Все, хорошо. Ну, давайте тогда начнем. Значит, вот тут вот картинка, она призвана намекнуть на то, что на нашем пути к искусственному интеллекту мы все находимся в роли творца, готового вдохнуть душу. своего Адама. Ну вот я хочу рассказать про своего Адама сегодня. Это про наш проект, который недавно начался в лаборатории когнитивных архитектур Центра науки технологии искусственной интеллекта ФИИ-3. И в этой лаборатории, ну собственно созданной под этот проект, она призвана разрабатывать новые архитектуры, на основе реверс-инжиниринга принципов работы мозга. То есть мы хотим подсмотреть основные принципы обработки информации в мозге и переместить их на робота. Мотивацией, конечной целью нашей деятельности является создание новой операционной системы, потому что все мы понимаем, что мы находимся на пороге новой эры, эры роботов. Роботы представляют из себя новый тип компьютерного железа, и под этот новый тип нужен новый тип операционной системы, потому что внешняя операционная система, вообще внешняя архитектура компьютерная формированная, она затачивалась всегда на то, чтобы а исполнять программы, заложенные в память компьютера. Происхождение этих программ неважно. Какой-то творец, какой-то человек заложил эту программу, и операционная система должна ее исполнять. А роботы будут в совершенно другом положении. Они будут полезны только тогда, когда они будут активны и самостоятельны. И вот эта вот несамостоятельность подразумевает, что они должны сами решать, что им не делать, в каждый момент времени, в каждую миллисекунду, основываясь на том, что они видят, слышат, умеют и понимают об этом мире. Запрограммировать все это совершенно невозможно, как мы это теперь понимаем, и поэтому роботам надо будет учиться так же, как дети учатся. Жить в этом мире, понимать физические законы, понимать законы социальные, понимать, что людям нужно, и жить в этом мире людей. Не ввиду роботов, которые будут... Ну, так называемые сервисные роботы, которые сейчас только появляются, а не те роботы, которые стоят на конвейере и делают какую-то заранее заданную программу. Не ввиду роботов, которые будут жить способны действительно сильно изменить нашу окружающую сферу и повысить эффективность экономики. Так вот, эта операционная система, она должна будет быть нацелена именно на процесс обучения. Ну, как сейчас видит сообщество наше, это должно быть reinforcement learning, ну, может быть, в каком-то там своем подвиде, как и MERS reinforcement learning, мы сейчас не будем вдаваться в подробности, Важно, что это должна быть архитектура достаточно общая, потому что у всех роботов будет свой набор актуаторов, свой набор сенсоров, ну и вот буковка R здесь это сигнал подкрепления, reinforcement. Каким-то образом он будет доноситься роботам, насколько хорошо они поведения для окружающих. И нам нужна будет система, которая на основе только вот этих данных, произвольного набора сенсоров, произвольного набора актуаторов, воспитывает в роботе некоторое поведение, полезное для окружающих. Имеет смысл чтобы эта операционная система была у всех одна, чтобы она была модульная, чтобы роботы могли обмениваться не только информацией, но и знаниями, то есть некими кусками, модулями. Эти модули бесшовно подключались бы к данной психике и расширяли ее возможности, как сейчас мы делаем, закачивая всякие приложения в наши мобильные телефоны, ну, также в будущем, там, пересекая, скажем, границу с нашей, там, роботом-собачкой, у нее автоматически подкачаются соответствующие модули, там, если мы едем во Францию, скажем, французский язык, соответствующие гиды, и она сразу же превращается для нас и в переводчика, такой девайс, который всегда с нами и который наш. Ну, это просто один штришок из того, как это все должно выглядеть. Ну, все это выглядит очень коммерчески привлекательно. Возникает естественный вопрос, почему это до сих пор не создано? Что нам мешает? Ну, вот об этом, собственно, и пойдет речь. то пытаюсь сформулировать, как я вижу, основное препятствие созданию искусственной психики. И поскольку мы сосредоточились на этом основном препятствии, значит, наше видение решений, ну, и перспективы того, куда дальше развивать и как можно двигаться в этом направлении. Ну, начнем с искусственной психики. Почему ее еще нет? Ну, во-первых, Явно мы подошли к созданию искусственной психики, потому что нынешняя революция глубокого обучения — это фактически моделирование низших областей психики. Можно сказать, что сенсорно-сенсомоторные области психики, мы имеем модель в наших глубоких нейросетях, они умеют переводить. образную широкополосную формацию, символы и обратно. И теперь, естественно, следующий шаг – это моделирование более высоких областей психики, то есть когнитивных способностей, способностей нас размышлять и планировать свое поведение. Ну, нельзя сказать, что это направление новое, оно очень даже старое, и в рамках традиционного искусственного интеллекта когнитивные архитектуры появились где-то в 70-х годах, после того, как первые 15-20 лет развивался в основном когнический интеллект. Но потом, когда были осознаны его ограничения, то исследователи созрели до того, что неплохо бы поучиться и у мозга, и посмотреть, как устроено мышление человеческое. И вот тогда получила развитие мысли, которое формилось в направлении когнитивной архитектуры, что неплохо бы объединить знания биологов и инженеров и создавать такие действующие модели психики, которые психологи могли бы использовать в своих исследованиях для объяснения психологических экспериментов и паттернов поведения животных и людей. А специалисты по искусственному интеллекту могли бы расширить возможности своих прикладных систем. Тогда уже начинались И, в общем-то, в принципе, вот это направление когнитивных архитектур проходит в основном по категории экспертных систем. Всего вот по последнему обзору большому 2020 года за 40 лет создано порядка 50 таких когнитивных архитектур, которые сейчас в активном использовании. Было создано больше. сейчас используется. Ну, из них две. Тут я привел наиболее популярные и, по крайней мере, известные. Это те, которые больше тяготеют в сторону биологии. Это АКТ-Р и архитектура СОП, созданная под руководством одного из пионеров искусственный директор в Нью-Йорке. Кстати, обе архитектуры начинались в Карниге и Милане, такая родина когнитивных архитектур. В недавней статье 1917 года соавторы Солох предложили стандартную модель мышления, в которую они попытались объединить все основные идеи агнитивных архитектур, против которых, можно сказать, никто не возражает. То, что общее, что все объединяет, все существующие агнитивные архитектуры, ну, может быть, не все наиболее, но наиболее представительная часть из них. И вот этот рисуночек, который здесь изображен, это из их статьи, ну, и видно, развития этой области. Мы видим, что внизу есть два блока восприятия и управления мотором, т.е. сенсомоторные блоки. Можно сказать, что их можно сегодня представить в виде глубоких нейросетей, потому что мы можем не только распознавать образы, но и генерировать их. Вспомните дипфейк, и технологии и подобные. Нижние блоки переводят образную информацию в символную и обратно, а вот высшие блоки, то есть высшие когнитивные функции, они в основном, правда, когнитивная архитектура, они имеют символную природу. Есть концепты, которые представлены некоторыми символами. Эти концепты связаны некоторыми связями. И эти связи можно изображать кодиграфом или гиперграфом. И на этим гиперграфе идёт возбуждение одних концептов и других концептов, архитектуре находится рабочая память, которая представляет на себя активные области мозга, и по мере того как активность по мозгу распространяется, это отражается в том, что в рабочую память как бы эффективно входят некоторые элементы декларативной памяти, то есть факты, которые заполнены, ну в основном это кара, и процедуры действия над этими факторами, которые обычно атрибутируют к подкоркованным структурам, ну, пациентам. Ну вот, в целом, всё выглядит так. И надо сказать, что вот этот вот рисуночек, он не очень сильно отличается от рисуночка, наверное, стал тут его приводить, статьи 1983 года. То есть, вообще говоря, за 35 лет развитие этой области, она ушла вперед не очень сильно по сравнению, скажем, за 8 лет развития глубокого обучения. Глубокое обучение развивается гораздо стремительнее и может похвастаться гораздо большими успехами, чем вот это. направление когнитивных объектов. И причину этого я вижу в том, что когнитивные объекты, как я уже говорил, это фактически экспертные системы. У экспертных систем есть прожденный порог. Их мощность и сложность этих моделей прямо пропорционально затраченному человеческому труду. Все эти правила, которые лежат в декларативной памяти и процедуры, они рукотворные. Соответственно, сложность этих моделей ограничена. А вот исследовательская программа, предложенная ГИБДД, она идет другим путем. Это стремление перенести успехи глубокого обучения, то есть перенести успехи на пути моделирования, распознавания образов в модели восприятия из первых принципов, которые достигаются, на высоковыражениях символьных мыслей. То есть идея этого состоит в том, чтобы вручную не создавать никаких правил, никаких процедур, а сделать так, чтобы так же, как в глубоком обучении, эти правила и процедуры рождались автоматически, и чтобы они были достаточно сложны, чтобы воспроизводить символьное мышление. Ну и надо сказать, что на этом пути они достигли больших успехов. По крайней мере, ни одна из когнитивных архитектур не выиграла у людей ни в бой, ни в шахматы. А вот Альфа-Серова выиграла, сочетая глубокую интуицию глубоких нейросетей и планирование, взятое из арсенала обычного искусственного интеллекта, старого доброго искусственного интеллекта. То есть выглядит это так, что есть, сейчас я попробую нарисовать, есть нейросеть глубокая, которая переводит образную информацию, то есть это очень большое количество возможных ситуаций на доске, в очень небольшое количество ходов, несколько сотен, ну и оценок этих ходов, ну и оценку позиций. Вот эта вот глубокая интуиция и помогает дальше просчитывать все дерево варианта, обрезая, ну то есть помогает бороться с комбинаторным взрывом. тем, что рассматривается на каждом шаге только наиболее хорошие ходы, но и просматривать можно до какой-то глубины и там останавливаться, имея оценку позиции. То есть интуиция у сети глубокая, но она распространяется, к сожалению, только на один ход вперед. А дальше мы должны пробиваться через вот этот, можно сказать, Комбинаторный взрыв. Этот взрыв частично направленный, конечно, за счет того, что обрезаются боковые ветки. Но, тем не менее, это комбинаторный взрыв. И на каждом шаге приходится производить вот этот комбинаторный взрыв. Ну и, как итог, мы имеем ту сложность обучения, трансформируют, тренировалось примерно тысячи террафутов. Понятно, что такой способ обучения он применим только для виртуальных миров, где можно ускорить время в миллиарды лет, в миллиарды раз, но он не применим для реальных роботов, реальной жизни. Ну а с другой стороны, человек-то мыслит по-другому. Наш когнитивный тип вот этот вот когнитивный цикл, так называемый, это доли секунды. И мы не просматриваем вперед на секунду, просчитывая десятки долей секунды. Мы совершенно по-другому планируем свое поведение. Мы можем спокойно планировать неделю, не просматривая вперед То есть человек думает так, что у него есть какой-то замысел крупный, то есть у него есть интуиция на всех масштабах, и он ее применяет последовательно. Сначала группа планирует, что ему нужно, потом, по мере того как он подходит к очередному этапу, он планирует, как это Он гораздо более экономный, он понятный по-человечески, и, в общем-то, он-то и используется обычно в системах планирования в обычном искусственном интеллекте, но только все вот эти вот ходы, они рождаются человеком. Я считаю, что центральная проблема при создании правоспособной психики работы заключается в том, чтобы найти способ обучения иерархии действий, подобно тому, как мы нашли способ обучения иерархию признаков в глубоком обучении. Ну и вот следуя, я тут приведу цитату Стивана Парасева, что в настоящее время все существующие методы иерархического планирования опираются на изменения человека в иерархии абстрактных и конкретных действий. Мы еще не понимаем, какие иерархии могут быть получены путем обучения. Вот это, я считаю, центральная проблема. сосредоточились на решении этой центральной проблемы. К тому, как ее предлагается решить, я сейчас, собственно, и перехожу. Предлагается учиться гуморно. Дело в том, что глубокое учение, можно сказать, что оно в каком-то смысле моделирует зрительный порог мозга, то есть вот это заднее части мозга, где обработка идет послойно, информация передается от слоя к слою, но она идет такой волной, постепенно выделяет более более крупномасштабные признаки. Но планирование поведения происходит в передней части мозга, и происходит оно по-другому, потому что передняя часть мозга устроена по-другому, схемотехника мозга устроена по-другому. То есть там коралл активно работает с подкорковыми базально-олигархами, с подкорковыми ядрами, и образует очень крепкую связь, и те возмущения, которые бегут по горе, они как ассоциативная пора, ассоциации разбегаются в разные стороны, а покорковые ядра, они направляют эту активность в нужную для организма сторону, то есть они как бы дирижируют активностью горы, и активно вовлечены в выработку поведения, в отличие от задней части мозга. Поэтому, когда мы говорим о моделировании поведения, то мы должны скорее вот ориентироваться на эту архитектуру. Это называется костико-стриатная система, потому что, ну, стриатум — это полосатое тело, это самая большая часть лазерной гаммы, где принимаются решения о том, что полезно, а что не полезно. Если посмотреть на схемотехнику, то мы увидим слева, что любой участок коры в передней части мозга, он соединен такой контуром обратной связи самим с собой, проходя через триадон, ну дальше полигон, таламус, и возвращается в то же место. И этот контур, он может быть как усилительный, так и наоборот, тормозящий. Решение о том, насколько хорошо вам предложено это решение, принимает триадон, поскольку сюда входит еще множество множество информации из других частей мозга, из гиппокампа и из задней части мозга. И важно, что все эти контуры, они связаны не только иерархией, то есть любое движение, оно сначала зарождается в виде мотивации, планирования, ну наконец, мелкомасштабная моторика, она в примоторной и моторной областях обрабатывается. Таким образом, здесь мы видим явную иерархию, и вот эту иерархию мы и хотим отобразить в виде архитектуры. Вот здесь вот другой рисуночек, другой работы, где отражена очень хорошо схемотехника, что показано, что имеется с десяток примерно иерархических областей, и связи между ними, они фактически То есть каждый уровень иерархии устроен однотипно. В коре буду располагать шесть слоев. Каждое участок коры получает два типа сигнала. Сверху – это предсказание того, что будет. И снизу – это реальный сигнал. И вот здесь приведена работа недавняя, мы виделись с автором, где очень подробно описывается эта схемотехника предиктивного обучения в мозгу, но в Карле. Таким образом, каждый участок Карлы стремится предсказать поведение неживлящего участка и стремится минимизировать ошибку этого предсказания. Карл все время учится минимизировать ошибки. Ну а соответственно она, все вместе эти области коры, то есть все вместе кора строит модель мира предсказательную, которая предсказывает, что будет в мире. А вот здесь вот подкорковые структуры, они максимизируют другую функцию, они максимизируют сумму удовольствия, сумму подкреплений, которые они получают из гормоновой системы. Таким образом, мы видим явную такую структуру закономерную, которую мы и хотим отразить в виде компьютерной архитектуры, отвлекаясь от всех биологических деталей. Ну и вот такая архитектура, которую я назвал контролом. Она изображена вот здесь, на этом рисунке. На этом слайде мы остановимся поподробнее, поскольку мы, собственно, здесь и есть. Это главный слайд презентации. Здесь основная идея и предложенная архитектура, она показывает. Ну, во-первых, что это? Это есть набор слоев. Первый слой. Дальше не нарисовано, таких слоев может быть сколько угодно. Это вполне аналогично тем слоям в обычных нейросетях, которые мы имеем в глубоком обучении. Чем больше слоев мы сделаем в нашей сети, тем более мощная будет ее поразительная способность, интеллект. При этом все слои работают по одним и тем же правилам, так же, как в нейросетях. То есть, поняв, как работает один слой, мы поймем, как работают все остальные. Давайте мы сначала берем все остальные, и я расскажу, что из себя представляет один вычислительный слой. Потому что он сам по себе тоже представляет у себя управляющую структуру, систему управления, которая на вход получает вектор. О, это observations, то есть сенсоров. А, это сортуаторов. Ну и есть еще один выделенный сигнал. подкрепление, которое обрабатывается отдельно, это соответствует подкреплению наступленной системы. И вот, получив на вход этот вектор, на выходе система выдает прогноз этого вектора на следующий шаг. Поскольку мы, на самом деле, актуаторами контролируем полностью, то прогноз актуаторов это и есть. Это и есть следующее действие. А вот прогноз последствий наших действий может не совпасть. И поэтому, если он совпадает, то мы даем дополнительное подкрепление, здесь вот я показал, сравнивая сравнивая следующее состояние системы с предыдущей. Если оно совпало, значит, мы правильно предсказали, и это надо поощрить. Тем самым мы доберемся чего? Вот это вот дополнительное подкрепление просто добавляется к внешнему подкреплению. То есть внутреннее и внешнее подкрепление складывается, и нам не нужно никакого дополнительного способы обучения. У нас есть один базовый способ обучения. Ну, тот, который осуществляется в базальных ганглиях с помощью наполненных сигналов. Просто мы себя внутренне подкрепляем каждый момент, когда мы угадываем, что будет. Потому что внешние подкрепления, они редкие. Вы играете в шахматы, но подкрепление вы получите только, когда вы играете в партию. Но учиться на редких подкреплениях тяжело и неправильно. А вот если вы постоянно учитесь предсказывать, то вы повышаете свое поведение. Теперь что происходит? между этими событиями, то есть как происходит планирование поведения в каждом слое. Первое – это кодинг. То есть мы векторную информацию, производную, переводим в символную. Это не один символ, а это вектор символов. Потому что одним символом вы, конечно… символ – это информация с небольшим разнообразием, несколько десяток, и вы не можете таким образом описать ситуацию. Но если вы вернете несколько символов, скажем, за десяток, то вы уже получите 10 десяток разнообразия, и этого вполне хватает для того, чтобы оцифровать внешний сигнал. Дальше вы можете работать с дискретными сигналами, и с последовательностью этих символов работает парсер. Парсер делает, что он склеивает поступающие символы и составляет из них осмысленные паттерны символов. Это аналогично тому, как из букв составляются слова. При этом он использует семантическую память, которая считает, сколько раз за каким-то паттерном следует следующий паттерн. И каждый раз эта последовательность усиливает семантическую память, ассоциацию на память. И, соответственно, это используется паттерном для склеивания символов. Таким образом, символы последовательно склеиваются и получаются нумерзлые слова. И каждое такое слово, их нужно запоминать в памяти тематической. Мы знаем, что мы из тридцати букв составляем несколько сот тысяч слов, и мы их все помним в памяти. Ну и вот аналогично Аналогичная, видимо, механика используется и для планирования поведения. Поскольку Кора, она везде одинаковая, где-то она работает со словами, а где-то она работает с такими паттернами поведения. Но теперь, если мы знаем контекст текущего момента, зная статистику симметрической памяти, мы можем предсказать, а что будет, какое следующее слово последует из... может быть, следующее. Но поскольку здесь речь идет не о текстах, а о поведении, то, вообще говоря, мы не просто пассивно смотрим, какие слова там могут быть, а мы направляем, в общем-то, свою мысль, И поэтому в плане находится функция полезности, функция ценности, которая прикреплена для каждого паттерна. Ну и планер из всех возможных кандидатов выбирает того, которого он считает наиболее достойным, то есть приносящим наибольше пользы. Ну и дальше по одному символу он передает его в депозер для исполнения. Вот собственно и все. Таким образом, вот такая однослойная, один слой, он вполне может управлять поведением каких-то там, то есть представляет собой модель таких несложных мозгов, которые работают на одном временном масштабе. Теперь ключевой момент, как сделать эти мозги произвольно сложными, то есть как сделать переход с одного слоя на другой. Как только мы сделаем переход с одного слоя на второй, значит, что мы сделали по индукции переход на все остальные слои. И, соответственно, мощность такой управляющей системы Система возрастает сразу в бесконечное количество раз. Вот здесь вот ключевой момент — это так называемое семантическое кодирование. То есть как передать наверх вот тот паттерн, который мы обнаружили это есть некоторый набор символов, а кодер у нас работает с векторной информацией. Решение, оно известно, оно уже очевидно, фактически у нас ведь есть матрица, ассоциативная матрица ассоциации, то есть сколько раз какое-то следующее действие следует за за данным паттерном. И вот строку этой матрицы мы можем передать строку и столбец соответствующий. Если мы соединим в один вектор и передадим на следующий слой, то мы передадим фактически контекстный вектор, который говорит, а вот это действие в каком контексте обычно совершается. Обычно оно совершается перед таким-то и после таким-то. И если у нас есть действия, которые обычно совершаются в таких же контекстах, то вполне логично, что эти действия имеют, так сказать, один и тот же смысл. Ну, для примера, вы встречаетесь с препятствием, вы можете обойти его справа, можете обойти его слева. И вот эти паттерны обхода справа и обхода слева, они, ну, наверное, встречаются более или менее равновероятно в одних и тех же ситуациях. И поэтому эти паттерны имеют один и тот же семантический вектор, и имеют один и тот же, говоря, смысл, смысл обхода препятствий. И этот вектор, который будет кодером следующего слоя, транслирован в некий символ новых, более высокого порядка, этот будет символ тематический символ того, что за действие, какую группу действий представляет этот символ. Потому что это есть переход многого. То есть каждый символ соответствует, объединяет в себе очень большое количество паттернов низшего уровня. Ну, соответственно, на выходе со следующего слоя мы получаем тоже набор возможных паттернов, которые представляют из себя задумки, планов, которые говорят фактически низшему слою, что вот на твое усмотрение, ну вот, вот такие вот, выбирай что-то из этих. И дальше планер выбирает то, что соответствует ситуации, То есть то, что еще не вышло из парсера, те символы, которые поступили в парсер, но еще не поступили наверх. Таким образом получается, что сверху спускается иерархия плана, которая рождается на самом верху. И каждый следующий слой он адаптирует план более высокого уровня той ситуации, которую он видит перед собой на своем масштабе времени, и находит способ реализации не более адекватной текущей ситуации, но и вплоть до низшего уровня. Ну вот, собственно, и все. То есть получается, архитектура, которую явно в виде учитывает иерархию, и осуществляет иерархическое планирование, при этом мы ничего не кодируем руками. То есть все, что задается человеком, это задается размерностью этих символов, то есть количество модулей в этом кодере, какие-то алгоритмы парсера, какие-то алгоритмы планера, но они все одинаковые на всех слоях, И в той или иной мере там отражают те алгоритмы, которые у нас в мозгу, либо те, которые мы придумываем лучше. Здесь есть много степеней свободы, но общий план, общая архитектура, общая идея этой архитектуры, Это связано с мозгом, потому что предыдущая картинка совершенно не напоминает предыдущую картинку, где было нарисовано какие-то структуры мозга. Симбольное кодирование легко себе представить. Мы все знаем, что кора состоит из колонок. Эти колонки образуют гиперколонки, Каждая колоколка, зажигаясь, она начинает тормозить своих соседей. И получаются такие карты Кахлонина. Их хорошо видно в первичной зрительной каре, их нашли в моторной каре. И, судя по всему, это общий принцип работы кары. То есть кара состоит из многих таких маленьких карт Кахлонина, где каждая такая карта содержит небольшое количество, несколько десятков, колонок, и каждая такая колонка осуществляет фактически кластеризацию поступающих к ней сигналов. Она куда-то смотрит, эта гиперколонка смотрит в какую-то, ну, либо наружу, если это первичная кора, либо на другие области мозга, и кластеризует все сигналы. Вот здесь он показан на рисунке, что вот, скажем, голубая гиперколонка она касторизовала поступающие сигналы следующим образом. Зеленая гиперколомка касторизовала их уже по-другому. Вообще говоря, понятно, что каждая из гиперколомок смотрит не на весь, не на всю картинку, а на какое-то пространство. И поэтому каждый свой взгляд на информацию, выходные вектора, и поэтому все эти простерилизации, они разные. И если мы их наложим друг на друга, то мы получим n в степени k ячеек, на которых разбивается векторное пространство, и, в общем-то, при вполне скромных цифрах, скажем, если мы возьмем семь таких, ну, то есть вот центральную гиперколонку и шесть окружающих ее, 7 колоночек, и в каждую будет всего лишь 30 колоночек, ну как бы 30 букв в правительстве, то мы получим разнообразие 10 на 10, ну это примерно столько, сколько человек вообще видит у нас за всю свою жизнь. То есть этого за глаза хватит для того, чтобы работать внешней информации, поддерживать ее осмысленным образом. Вот, кстати, здесь вот приведена статья, рисуночек из статьи Покинса, где он показывает, что такие инвариантные разреженные коды, они хороши именно тем, что они инвариантные, потому что каждая киберколомба, она, ну, имея там несколько десятков всего лишь там, разнообразия, то каждый такой вот символ, каждая ячейка этой сети кластеризации, она очень большая. Настолько большая, что она объединяет в себе очень такие общие понятия, ну скажем, как будто здесь нарисовано, что там нечто на четырех лапах. Но, поскольку каждая кластеризация происходит со своей точки зрения, то каждая такая вот иперколонка, она свои аспекты учитывает, и в итоге вполне себе конкретная собака может быть и характеризована всего лишь несколькими, скажем так, с символами, да, и она будет определенно однозначна. А при этом каждый из этих символов носит очень такой общий характер, поэтому мы эту собаку будем узнавать в любом положении, в каком бы она там ни крутилась, ни вертелась. Подобно тому, как помните, есть игра «20 вопросов», По 20 вопросам можно отгадать любой предмет новой вселенной, поскольку 22 в степени 20, то есть каждого вопроса тогда нет. 20 в степени 20 это миллион всего слов, у нас языки меньше, чем миллион, поэтому их хватает для того, чтобы отгадать любой предмет. Теперь относительно последовательности. Вот тут очень важный момент, который хотел бы подчеркнуть. Каким образом в мозгу кодируется последовательность? Я не знаю, но есть гипотеза. Эта гипотеза стоит в том, что вот часть из тех колонок, гиперколонок, которые, то есть Решение состоит в том, что, скажем, одна гиперколонка продолжает кодировать символы, а вот окружающие ее гиперколонки, они смотрят уже не наружу, а вовнутрь сами на себя, и таким образом кодируют последовательность символов, которые возникают. То есть в центральной области возникает последовательность, какая-то лапочек, которая там зажигается, а в окружающей области они, как рекурентная функция, каждую такую последовательность кодируют уникальным образом. Таким образом, такой рекурсивный модуль, как я его называю, он вполне, если он есть в Корее, он вполне может кодировать последовательности. Таким образом, что получается, что в Корее есть энцимоторные части, которые смотрят друг на друга вот такими плотными пучками длинных аксонов, и есть ассоциативные области, где большая часть связей локальная, а какие-то там, меньшая часть, она Имеет длинные героини. Подразумевается, что архитектура гип-контрол состоит из двух таких слайдов. И она сосредоточена в тех областях коры, которые строены таким образом. Интересно, что в недавней книге Она придумала очень интересный способ подсчёта нейронов в мозгу, очень дешёвый. То есть вместо того, чтобы сканировать с микронным разрешением и считать под микроскопом, делается очень просто. Мозг режется на куски, взбивается в миксере и потом растворяется. Всё, кроме якра, отделяется в центрифуге и примечается метками фосфорицирующими. Соответственно, потом это все разбавляется литрами воды, и в каком-нибудь миллилитре подсчитывается количество ядер, которое, собственно, равно количеству нервов. Таким образом, очень дешево удалось исследовать мозги Причем не только, не просто мозги, вот отдельно горл, отдельно, значит, жучок там отдельно, там центральные части базарной банды для очень новых видов. И мы получили фактически вот такие вот электрические кривые, на которых стал понятен очень интересный факт. то я раньше не знал, что, оказывается, мозг приматов устроен не так, как мозг остальных млекопитающих, а именно количество нейронов в коридоре мозга на порядке выше у приматов, чем у остальных млекопитающих. И вообще, если бы архитектура нашего мозга 30 килограмм, а не полтора килограмма, как у нас. И это, в общем-то, выделяет нас среди всех прочих. И, как написано в этой книжке, что у приматов количество геронов пропорционально, в коре пропорционально массе коры, а у остальных млекопитающих пропорционально И это можно объяснить. Если предположить, что, скажем, у приматов большая часть связей в Корее локальная, тогда отростки, аксуны, которые занимают основное место короткие и, соответственно, количество нейронов пропорционально объемам коры. А вот если у вас основная часть нейронов в коре имеет длинные аксоны, ну то есть аксоны, которые сравнимы по длине с размерами коры, тогда у вас должна быть вот такая зависимость 2 в 3, то есть нейроны как бы лежат по границе. Это очень косвенное, но все-таки свидетельство в пользу той гипотезы, о которой я рассказываю. Мы можем даже оценить, в общем-то, как физики, а сколько таких мы были в Москву. Может быть, если вот эта картинка правильная. Но если картинка правильная, Ну, базовый размер одной колонки — это примерно 0,1 мм квадратного, ну, 300 на 300 мкм. Вот. Если взять, что гиперколонки — это порядка десятка колонок, в модуле порядка десятка гиперколонок, ну, а в слое, соответственно, порядка десятка. Больше и не нужно. модулей, то мы получаем, что один слой такой архитектуры соответствует примерно одному квадратному сантиметру пары головного мозга. А всего у нас там две тысячи квадратных сантиметров с чем-то. То есть несколько тысяч слоев такой архитектуры, в принципе, может уместиться в мозгу. Ну, понятно, что есть порядка сотни таких агентов, каждый из которых имеет порядка десяти этажей и может планировать что-то свое на довольно длительные промежутки времени. То есть вспоминается модель Минского Society of Mind, что мозг состоит из множества агентов, которые взаимодействуют между собой. И, в общем, когда я говорю об архитектуре типографии, то это, скорее всего, не сама архитектура, до которой мы еще должны нащупать мозг. А это какой-то принцип, организующий принцип, который может быть там воплощен. Ну вот, здесь на этой картинке показано, что чему соответствует. К озеру соответствуют, соответственно, центральные области вот таких молвелей. И там котируются символы, окружающие части коры. там же хранится синоптическая провинция в связях между этими яблочками. Ну а планер, соответственно, расположен в базальных данных и здесь показан. Интересно, что мы можем разрезать в произвольном месте вот эту вот иерархию и разделить ее на две части. Почему? Потому что, поскольку мы предсказываем, то и этот выход из этого слоя, где мы разрезали, он поступает на вход, то, прервав связь с внешним миром, мы все равно замыкаем верхнюю часть этой арахии само на себя, и она начинает жить в своем собственном воображении. То есть мы, фактически, это и есть модель абстрактного мышления, когда нижняя часть работает сама по себе, вы выглядите друг другом, не сознавая, что при этом решаете какую-то задачу в своем воображении. Так сказать, модель абстрактного мышления. Переходя, наконец, к заключительной части, Давайте подытожим, что так вот предложена некая архитектура, которая способна объяснить и обеспечить довольно сложное мышление, как мышление, так и управление поведением. к искусственному интеллекту. То есть мы прошли сенсорный интеллект и стратегический интеллект на игровой с этим же сортом и показал свою эффективность. Ну и следующий шаг, если на предыдущем шаге искусственные нейросети добивались поставленных целей, а цели ставили им из-за них, то Новый шаг – это самостоятельная постановка целей. То есть целям надо обучаться, так же, как и планирование их реализации. А что остается тем, кто обучает эти нейросети? Я считаю, что мы должны будем перейти от машинного обучения к машинному воспитанию. Это целый класс задач, которые до сих пор еще не осознаны. Но поскольку мы знаем, что дети учатся под руководством взрослых, и формировать их картину мы должны целенаправленно. Что-то подобное должно быть. Какие-то куриторы для работы с роботом в лейк-хоспитале. программный адапт, который шифровывается в адапте Deep Autonomous Machine. Понятно, что можно по-другому что-нибудь придумать, но суть в чем, что код очень компактный оказывается, поскольку вам фактически надо писать лишь один слой, а не просто рекурсивно вызывать другие слои в тот момент, когда нужно. И каждый слой работает там в своем трейдере самостоятельно, обмениваясь информацией в тот момент, который нужно. И все в целом, они осуществляют вот такое оптическое управление. Поскольку все это началось недавно, то мы встали в начале пути. И здесь вот я привел первый писк нашего Адама. Должна быть какая-то там мышка-дрозофила в каждой науке. Некий набор мышек-дрозофил в теории управления, он приведен на сайте OpenAI.gin, где собраны такие задачки, начиная от очень простых и кончая гораздо более сложными, для управления вот этими искусственными мозгами. Мы взяли самую простую, естественно, для начала, баунтинг-кар. Задача состоит в том, чтобы закатить тележку на гору, при том, что у нее не хватает мощности заехать на эту гору. И она должна найти решение сама. Решение состоит в том, чтобы выскочить на гору. За каждый тик дается наказание. Ну, чтобы ускорить достижение целей, надо наказывать за промедление. И вот здесь вот по оси ординат расположено наказание, там минус 134, минус 132. Ну и видно, что происходит постепенное обучение. И скорость достижения флага потихонечку уменьшается, при том, что здесь, как я сказал в первых писках, это одномодульная система с одним образом. То есть это еще никакая не иерархия, это просто тестирование. Тестирование одного модуля всей граффити-системы. Теперь хотел поделиться, что дальше. Поскольку мы находимся в самом начале, нам, собственно, надо прописать этот путь. И у нас есть исследовательская программа, которую я хотел поделиться, в основном, да, и которая базируется на фейерверском принципе. Если я чего-то не могу создать, значит, я чего-то не понимаю. И поэтому мы считаем, что нам надо, нам, это уже сообщество, создавать действующие модели мозга, поскольку мозги разные, от мозга мышки до мозга человека, то создавать их сектам, исследовать их поведение на разных когнитивных задачках, ну и потихонечку создавать ядро для операционной системы роботов, одновременно понимая, как с этим И я считаю, что эта исследовательская программа не только для инженеров, она и для нейробиологов, она и для психологов, ну и, конечно, для программистов. Такой получается программа, объединяющая усилия на этом пути поймем, как работает человеческий мозг. И только на этом пути, скорее всего, мы можем это понять. Ну и вот последний слайд, моя презентация. Чем, собственно, эта исследовательская программа отличается от того, что есть, чтобы суммировать. Вот смотрите, традиционный искусственный интеллект, но в лице он подходит, устремится понять и смоделировать алгоритмы мышления. Но поскольку моделировать их руками, то сложности мы возьмем нейросайенс, ну, в лице, скажем, проекта BlueBrain, Марка Грамовского, где подход, наоборот, вызов, то есть понять, моделировать устройство мозга, то мы увидим, что это тоже затык, потому что, ну, невозможно разобраться в предвкушении всех этих аксонов и дендритов, которые он пытается смоделировать. А даже если он умеет смоделировать, то там вообще за этим деревьям не просматривается лес, а просматривается архитектура, зачислительная архитектура мозга. Поэтому я считаю, что правильный подход, машин интеллигенция, машин леунинг плюс артифишиал интеллигенция, это понять архитектуру и проектное обучение. А вот сами, безумно сложные алгоритмы поведения и алгоритмы мышления, их понимать не нужно, поскольку они могут содержать те самые сотни миллиардов параметров, скажем, модель GPT-3, которых никогда не разобраться. Но мы, понимая архитектуру, понимая, откуда возникли эти алгоритмы, понимая, как на них можно влиять, через обучение. Только таким образом мы сможем приблизиться к пониманию нашего отношения. 

S05 [01:02:25]  : Ну вот, я закончил. Давайте теперь приведу режим вопросов и ответов. Сергей, спасибо большое. Коллеги, кто хочет задать вопросы, у нас с правой стороны есть чат. Вот, и в чате можно записываться в очередь на задавание вопросов. И у нас там уже есть вопрос от Дмитрия Сальхова. 

S03 [01:02:42]  : Сергей, спасибо за решение. Да-да, я слушаю. Очень интересная архитектура. Слов Игоря Кривоварова о прошлом выступлении. Я говорю об этом, потому что похоже на мои предыдущие. Немножко другое, совсем не озадачивающее. Может быть, Игорь Кривоваров хотел приземлить Как ваша архитектура сможет работать с натуральным языком? 

S11 [01:03:57]  : Хорошо, я начну со второго тогда. Собственно, вот эта вот модель, она родилась из моего предыдущего проекта, который назывался «Волин», который как раз работал с языком. Но отсюда, собственно, вся терминология. Буквы, морфемы, слова и так далее. И вот это вот... ключевой момент, переход в семантическое кодирование, оно пришло, собственно, из моего понимания того, как мозг работает с языком. Поэтому я считаю, что модель будет работать с языком хорошо, и, скажем, ну, там, конечная цель — это чтобы она разговаривала, чтобы она генерировала тексты. Ну, TPT-3 показывает, что, в принципе, генерация человекоподобных текстов решаемая задача, поскольку она это уже делает, но она то, что называется, мысль не держит. То есть это есть поток сознания. А вот такая архитектура Deep Control должна привести этот поток сознания в некую осмысленную плановую деятельность. Я считаю, что разговор – это такое же поведение, как любое другое поведение, разговорное поведение. Вы ведете разговор, у вас всегда есть модель того, куда вы хотите попасть, как этого достичь, и вы выбираете пути, и это иерархически происходит от какой-то компенсации высоких смыслов, где-то на высоких этажах, до выбора слов на более низких этажах в Ираке. Я считаю, что эта модель описывает именно работу с языком, она родилась из работы с языком. А что касается первого вопроса, то, ну смотрите, здесь ситуация, наверное, Я вижу ситуацию примерно такая, что нам надо сделать линукс для роботов. Линукс для роботов нельзя сделать силами одного, двух, трех, четырех, даже пяти человек. Можно сделать еду, возможно, какую-то принципиальную. Понятно, что уже видно, что она будет компактная. И вот этим как раз интересно заниматься. Вокруг этого ядра всегда будет очень большая обвязка, и чем больше эта обвязка, тем больше возможности этой операционной системы для жизни в реальных устройствах, для управления реальными роботами, чтобы там роботы играли в футбол, допустим, под управлением этой системы. Для этого надо кучу всего сделать, пройти некий путь. Этот путь должно проходить, я вижу так, что должно быть много команд, которые идут. Наверное, мы сделаем после этого архитектуру опенсорсной и привлечем как можно больше членов комьюнити к ее развитию. 

S05 [01:07:20]  : Сергей, спасибо. Алексей Егоров 

S04 [01:07:27]  : Огромное спасибо за доклад, это вообще говоря уникальная возможность так живую обсудить все эти вещи. И ужасно. Очень нравится идея. Опять полная система роботов. У меня есть три вопроса, я их последовательно задам, если вы не против. Вопрос номер один. Вы рассказывали о том, что в вашей системе, в вашей архитектуре существует некоторый язык, который с одной стороны имеет возможность быть интерфейсом к векторному представлению данных, с другой стороны, на уровне обработки смыслов является языком, которым можно заниматься прогнозированием и формированием моделей. Вопрос такой, это один язык или будет несколько языков? Если это будет один язык, как вы видите его устройство? 

S11 [01:08:37]  : А вот что вы под языком понимаете, я немножко не понял. 

S04 [01:08:43]  : Под языком я понимаю тройку. То есть, с одной стороны, наличие алфавита, ну, грубо говоря, какой-то онтологии, которая имеет и коррекционное пространство, и имеет, как бы, лица, и имеет сигнатуры. Есть правила обработки, и существует, как бы, система репрезентации каких-то нагривок. Ну, я так выглядываю. 

S11 [01:09:10]  : В этой трактовке я считаю, что должен быть один язык. Просто потому, что области коры, они самоподобны. То есть кора устроена более-менее одинаково. И это значит, что тех алгоритмов, которые заложены в любом ее участке, они более-менее одинаковы. И этого хватает, по крайней мере, для человеческого мышления. Так что я считаю, что надо идти по пути самому простому. Все этажи самоподобны, но понятно, что какие-то из них могут быть очень большие. Я же говорил, что это модульная архитектура. И мы можем на низших этажах делать, скажем, много модулей, на высших – мало, или наоборот. Здесь надо еще понять, оптимальные размеры этих слоев, а также, понятно, что это должен быть, скорее всего, это должен быть там не одна такая слоев, а много слоек, каждая из которых решает какие-то свои задачи, а потом верхние слойки собирают результаты нижних слоев. То есть это должна быть какая-то такая именно архитектура, как архитектура зданий. И мы здесь фактически в самом начале пути, и здесь какая-то архитектура будет, какая-то будет. Я думаю, что она будет интересна. 

S04 [01:10:42]  : Спасибо. И это замечательно, что вы ответили про самоподобие, потому что у меня второй вопрос как раз про это. Дело в том, что вопрос об архитектуре, он является ключевым, безусловно. И здесь вопрос о том, что вы два раза в своем докладе затронули тему фрактальности, но не стали акцентировать на этом. Я понял, что это как бы позиция определенная. У меня вопрос по поводу фрактальности. Дело в том, что вот это самоподобие, да, Она как бы предполагает, что должен быть либо единый паттерн представления, либо единое правило такого представления, потому что в противном случае это невозможно реализовать инженерно. Что вы думаете по этому поводу? 

S11 [01:11:32]  : Я думаю, что единое правило, и в общем-то я могу произнести это слово в фрактал, вполне себе. И мой последний вопрос. В связи с тем, что вы предлагаете слойную архитектуру, 

S04 [01:12:05]  : фактически каждый слой имеет свой набор решателей, да? Ну и вообще, в принципе, можно представить, что эта архитектура совершенно свободно интегрирует в себя, ну, я не знаю, там, Baez, какие-то решающие деревья, какой-нибудь Convolutional и так далее. Такая-то на уровне именно решателей, обладающими интерфейсом с этой стеной. Но! Она имеет слойность, и, как вы сейчас сказали, эта слойность, она, в принципе, самоподобная. Вопрос такой, что вы думаете о подходе AutoML, и как вы вообще соотносите возможность использования технологии AutoML в вашей организации? 

S11 [01:12:48]  : Ну, я, честно говоря, небольшой специалист в технологии AutoML. Есть ли там какой-то единый принцип, который... То есть понятно, что там идет подборка неких гиперпараметров. И эту подборку можно тоже осуществлять разными способами. И генетически программированными, как мы и другие. И в этом смысле, есть ли вообще такая наука как AutoML, которые есть какие-то базовые принципы, я не знаю. 

S04 [01:13:30]  : Большое спасибо. 

S05 [01:13:33]  : Сергей Алексеевич, спасибо. У нас Андрей Ковтуненко. 

S10 [01:13:40]  : Коллеги, добрый день. Сергею спасибо за прекрасный доклад. Особенно часть про планеты мне понравилась, но возник ряд вопросов у меня. Вы начали обзоры по когнитивным архитектурам, а потом затронули про DeepMind подход, что сложность должна сама себя построить в нейросети, обучаясь. И вы сказали, что ввиду того, что это ресурсоприемная задача, неочевидная, то есть она неприменима к инженерному исполнению для каких-то задач. Но вот у меня вопрос выник. Вот к чему большинство нет? Вы сейчас сказали про мета-алгоритм. То есть алгоритмическая сложность, она конечна для описания модели. Вот вы предложили мета-алгоритм там слойный, иерархический, ну как бы это верхний уровень, нижний уровень это там гиплерный. Вы считаете это методологически верным относительно гип-майнда или нет? Вот, это первый вопрос. Второй вопрос сразу же хотел бы задать. Вот вы описали планер, который у нас накапливает какую-то предсказательную инерцию, потом, притом, там есть как бы, ну, вы это называли, если я правильно понял, иерархический слой, Ну, где контексты обобщенные, они там делают какой-то прогноз, который раньше сбывался. Вот я не понимаю, почему, почему вот подход этого планера не применить к нижним слоям? Вот просто в вашей модели получается то, что она не рекурсивна от начала до конца. Вот это меня смущает. У моего коллега предыдущего я упомянул, что фрактальность процесса мышления должна быть соблюдена, так как сам мета-алгоритм должен быть максимально простым и, соответственно, устраивать фрактальность. У вас тут, получается, две части. Нижняя — deep learning. иерархическая слойка. Вот просто почему я задаю этот вопрос, я сам разрабатываю точно такую же модель, соответственно, один слой в ваших терминах я исполню полностью, но он у меня рекурсивный от и до, там нет вот этих нейромодулей, как вы сказали. И вот еще один вопрос, если позволите. Получается, вы говорите, что это будет модульная архитектура, вот, поверх вашей иерархической, там, слойки, да? Но ведь при подключении, ну, короче, кутриво говоря, при подключении такого модуля, вот эта иерархическая слойка, она будет также обучаться этому модулю, ну, что он есть, что он подключен. Чтобы полностью обучиться этому модулю, тоже, там, ну, будет какое-то количество времени затрачено. Это я к чему говорю, то что архитектура у вас не рекурсивна изначально. Если вы поняли о чем я спросил, прошу ответить. 

S05 [01:17:19]  : Сергей, пожалуйста, звук включите себе. 

S11 [01:17:25]  : Так слышно, да? 

S06 [01:17:26]  : Да. 

S11 [01:17:29]  : Я, наверное, неправильно не донес все-таки основную вещь. Все-таки каждый слой работает одинаково, абсолютно. Там нет никакого слоя типа 1, 2. 

S10 [01:17:41]  : Да, то есть все слои… Нет, вы как бы упомянули, вы упомянули в том, что у нас, если я правильно понял, нейросетевой слой там приводит у нас символы, а символы потом уже работают с вашей моделью, так? 

S11 [01:17:59]  : А, в этом смысле, да. То есть нейросетевой слой, это имеется в виду пастеризатор, да? 

S03 [01:18:03]  : Да, да, да. 

S11 [01:18:05]  : Ну, пастеризатор, да, он на каждом уровне работает одинаково. 

S10 [01:18:11]  : Нет, я просто... Просто почему бы вам? Вот вы прекрасно описали планер, но он Вот если продуматься, он работает как нейросеть сам по себе. Просто там надо нормализовать данные. Не важно какой сигнал подавать, я вот сейчас с текстом работаю. Потому что это максимальный эмоционный поток. Вот, и у меня вот просто на тексте голый планер в вашей терминологии, там нет никаких нейронных, кроме самой планеры. 

S11 [01:18:50]  : Ну, для текста это не нужно, для первого слоя текста это не нужно, поскольку он уже, значит, в BDC выступает, да? А вот для второго уже, там, идущих слоев, там, нужно все-таки, потому что у каждого слова не один смысл, а множество смыслов. То есть его надо базировать не именно семантическим вектором, который потом дискретизируется в такой семантический символ. То есть там Примерно так, как я рассказывал. Кодер нужен для того, чтобы переводить лептак в символ. Парсер нужен для того, чтобы из символа склеивать последовательности. А планер нужен для того, чтобы из этих последовательностей выбирать Следующий член этой последовательности ориентировался на те знания, на контекст. Каждый член, каждый из четырех этих модулей функционально необходим. И, в общем-то, его можно реализовать разными способами. Но вот именно архитектурно они друг друга именно поддерживают и дополняют. 

S10 [01:20:32]  : Непонятно, как можно без какого-то из них обойтись. И первый вопрос я напомню. Вы считаете методологически верным, Ваш подход в отличие от Дипмайна? 

S11 [01:20:48]  : Я считаю, что отличие вот такое, что в Дипмайне есть глубокая нейросеть, где нет никаких обратных связей, есть вход и выход в этом нейросети, а в промежутке множество этажей, и только потом с верхнего этажа отнимаются ответ, и этот ответ используется для планирования. А к моему подходе планирование гораздо более примитивное, на каждом шаге, на каждом уровне, но оно производится на каждом слое. То есть каждый слой этой архитектуры, он более сложный, чем слой теплёнки. Теплёнки это просто отображение функции. Один слой отображает функцию другого слоя. А здесь у нас нет вложенных функций, а есть взаимодействия между собой в обе стороны. Каждый слой одновременно предсказывает, что будет на нижнем слое, получает от него рядный ответ и обучается локально. То есть там нет передачи этой ошибки через все слои. Обучение локальное в каждом слое, поэтому оно еще более комфортно. Скажем, модели языка мы не обучались. 

S10 [01:22:27]  : Спасибо вам за ответ. Я в целом, в целом за вашу архитектуру согласен. Спасибо вам за ответ. Спасибо за лекцию. 

S05 [01:22:37]  : Сергей, спасибо. У нас Владимир Смолин вернулся с вопросом. Владимир, пожалуйста. 

S08 [01:22:45]  : Да, конечно, у меня есть слишком много вопросов, чтобы я их задал. Я всегда удовольствием общаюсь с Сергеем Александровичем. Иногда с некоторым интересным слышу. В принципе, какую-то аналогичную структуру я вам пытался рассказывать. С одной стороны, хорошо, что какие-то идеи он исторически развил в свою сторону. С другой стороны, может быть, плохо, что из того, что я рассказывал, он многое не воспринял или ему не понравилось, это я уж не знаю. Ну, во-первых, я хочу немножко защитить DeepMind, что, конечно, там у них однослойное вроде бы отражение, но все-таки вот сама идея Reinforced Cloning, она состоит в том, что выигрыш мы получаем в конце игры, но на основе этого выигрыша мы предыдущие позиции тоже учимся оценивать. И вся вот идея Reinforced Cloning, что на каждом шаге, мы уже имеем оценку этого шага, и мы на каждом шаге учимся эту оценку, во-первых, статистически накапливать и ее улучшать. То есть, когда доигрываем до конца игры, мы все предыдущие оценки, как бы, ну, кругу говоря, свои поправляем, насколько они были верны. Вот. Ну, в принципе, я так понимаю, что здесь в основном компания Мифишная, и она, как бы, ну вот, с Романом Викторовичем Душкиным, как Астридеологов, на мой взгляд, не знаю, может быть, я ошибаюсь, значит, она все-таки сторонник нисходящего подхода. То есть символы — это все, значит, если мы без символов что-то сделаем, то этого как бы не будет. Ну, значит, мое отношение к этому, что это несколько наивный подход, ну, естественно, с другой стороны, Предчувствую возражение, что это как раз их подход не наивный, а мой подход наивный. Ну, как бы, взгляды могут быть разные. Вот. Ну, вот, собственно, упомянутый, значит, Сергей Александрович Джефф Хокинс, который там с его HTM, который Hierarchical Temporal Memory, вот, она, как бы, вот эти их рассуждения про, значит, комбинации из разных карт, что они дают очень много, Ну, вот, это образец наивных рассуждений, чтобы это было понятно, что, значит, когда у нас, значит, вот всего там 20 бит в регистре, или там 64 бита в регистре, то, значит, вот у нас вроде комбинаций получается очень много, а там всего 64 бита, Значит, 64 бит – это логарифм от числа комбинаций, которые мы там можем изобразить. То есть те комбинации, которые у нас получаются от этих символов, их меньше, чем мы можем отобразить, экспоненциально, значит, меняют. То есть от тех комбинаций, которые взять, нужно взять логарифм, что обычно забывается сделать, в том числе Джеффу Хоттинсон, и тогда нужно сравнивать количество бит. символы, как бы, они нужны и полезны, и я вот десятого постараюсь рассказать, что да, конечно, это как бы основа человеческой деятельности, общение там символиное, вот, но, значит, когда вот мы выполняем какие-то простые действия, не знаю, идем пешком, там, прыгаем, едем на велосипеде, я вас утверждаю, как бы сказать, вас уверяю, вы не сможете объяснить, как вы это делаете словами, Вы можете попытаться объяснить, но это будет сложно. Но более того, если брать более высокого уровня деятельность, всякая идея, высказанная словом, она, скажем так, является ложью. То есть мы пытаемся что-то объяснить, но, во-первых, мы неправильно объясняем, что мы хотим объяснить, а уж то, как нас понимают, это совсем другое. То есть, естественно, вот то, что я сейчас говорю, значит, вы меня не так понимаете, то, что Сергей Александрович сказал, вы тоже не так его поняли, как он хотел понять. Более того, он, значит, своими словами сказал не то, что он хотел, значит, нам донести. Вот, естественно. Вот. То есть, как бы символьная функция нужна для общения, но она, вот на мой взгляд, не является основой. То есть основой все-таки являются все действия, которые выполняем, и их надо иерархически организовывать. И вот мой подход в том, что надо действия архетически организовать, а не их символиное описание. Оно, конечно, имеет значение, но именно для общения, а для самой деятельности организации это не так важно. Говорилось о том, что символному подходу последние 35 лет прогресс есть, но он небольшой. А глубокому обучению за последние 10 лет прогресс колоссальный. Ну, с этим вряд ли кто будет спорить. И все как бы понимают, почему этот прогресс. Потому что отошли от символного подхода к глубокому обучению. Там обучение не символное. Там никаких символов к глубокому обучению нет. Что, собственно, Сергей Александрович и признает. Я надеюсь, мы не будем с этим спорить. И именно на этом пошел большой успех. И дальнейший успех, я согласен, если я уже рассказывал давно эту идею Сергея Александровича про уровень обработки, данные, но они должны быть не символьные. И это мое основное расхождение. Я не буду там утверждать, Я прав, Сергей Александрович не прав, или Сергей Александрович прав, а я старший барист, как многие думают. Но разница в подходах именно в этом. Я сторонник того, что мы живем в непрерывном мире, выполняем непрерывные действия, и наша нервная активность направлена на эти непрерывные действия. А символы нам нужны, мы должны формулировать, но они нам нужны для общения. А, собственно, самодеятельность, она вот, конечно, должна быть иерархически организована, прогнозируемая, то есть проактивность там должна быть, мы должны, значит, сознание, о чем мы будем говорить, там, 10 числа, оно как раз связано с тем, что мы планируем свои действия, прикидываем, к чему они приведут, все это, как бы, вот это усвоит. Средства домоделирования, конечно, должны быть иерархически организованы, но, значит, Мой подход такой, что основой являются непрерывные действия разного уровня, а символи им соответствуют для общения. Сергей Александрович идет таким путем, что символы являются основой, а физической деятельности это нет. По крайней мере, революционно это было не так. Понятно, что бактерии, черви с лягушками, никакими символами особо не думают. Может быть кому-то это непонятно, может кто-то считает, что у бактерий есть какая-то симбольное мышление, я не знаю. Но мое такое все-таки мнение, что от непрерывных движений более высокого уровня пришли к симбольному общению. А собственно мышление у нас на самом деле не симбольное. То есть мы можем думать, стихи сочинять, символы для общения, но основа нашей деятельности она все-таки непрерывная. А если вы думаете, что вы можете рассказать, как вы рулите велосипедом, то я вас умоляю, что я вам расскажу, что вы ошибаетесь. Вы рулите им не так, как вы думаете. Простая пример. Ну, собственно, я еще много чего могу рассказывать, но, наверное, я уже всех отомил. Спасибо. Если Сергей Александрович хочет что-то мне ответить, я буду рад послушать. 

S05 [01:29:50]  : Сергей, если есть ремарка, звук включите. 

S11 [01:29:58]  : Есть много путей к вершине. Посмотрим. Пусть каждый идет своим путем. Это прекрасно. 

S05 [01:30:12]  : Коллеги, тут у меня два вопроса было, но, правда, у меня тоже есть небольшая ремарка, значит, раз Владимир взялся защищать Джеффа Хокинса, ой, точнее, DeepMind, я вот по поводу символов тоже пару слов скажу. Во-первых, у меня создалось впечатление из доклада «Сергей, поправьте, так это или не так», что когда мы говорим о символах, мы говорим о символах с точки зрения слоя, а не с точки зрения архитектуры в целом. То есть я так понял, что то, что на, грубо говоря, втором слое является символом, на третьем слое является входом. И если мы возьмем всю стопку слоев, то то, что мы называем символами, оно будет где-то наверху. А те символы, которые возникают где-то в промежутке, они символами для слоев верхнего уровня являться не будут. Вот это вот такая ремарка. Сергей, я правильно понимаю? Или это я, так сказать, додумал? Нет, это все правильно. 

S11 [01:31:12]  : Каждый символ работает символом только в своем слое. На верхний слой выходит, поскольку семантическое представление, оно от морфологического совершенно не зависит. И поэтому там рождаются свои символы. То есть алфавит у каждого слоя свой. И словарь песни тоже у каждого слоя свой. Просто на каждом более высоком уровне он все более абстрактный и абстрактный. 

S05 [01:31:42]  : Спасибо. И, Владимир, кстати, вот если вы не смотрели по этому поводу, посмотрите предыдущие семинары, где Алексей Рядозубов рассказывал. Там, в общем, я вижу очень огромное перекрытие с тем, что Сергей рассказывал. Вот. И второе тоже ремарка насчет велосипеда. Я вот просто по своему собственному опыту, совсем можно сказать свежему, я сейчас учусь кататься на кайте, выполняю сложные элементы, то есть там нужна очень сложная моторная схема поведения и обучиться этим элементам через интуицию, через движение, через динамику на уровне Т.е. там вся эта программа разбивается на элементы, и более того, что выучить эти элементы по отдельности тоже невозможно, это можно выучить только в комплексе, но через постоянную построение символьной программы с фиксацией определенного числа элементов и попытки увязать в динамике эти элементы между собой, только через так, через вот такую вот программную символьную последовательность можно выйти на то, что ты в конце концов Будешь выполнять эти элементы в целом. То есть, в этом смысле, когда ситуация становится больше, чем просто баланс на велосипеде, мне кажется, без символьного обучения нельзя обойтись. Но у меня вопрос другой, как раз по поводу символов. 

S08 [01:33:11]  : Я говорил о том, что я так понимаю, что я общаюсь с компанией из идеи нисходящего обучения. То есть символы – главное, а вот эти непрерывные движения – это как бы вторично. Я, безусловно, согласен с тем, что с символами мы общаемся, и если вам без символов пытаться объяснять, просто демонстрируя, как это делается, вы не поймете. То есть вам объясняют из каких последовательных простых движений все это состоит. Вот. Я не хочу сказать, что я вас убежу. Вы, конечно, верите в то, что символы главные и, значит, как сказать, веру. Вот так вот два слова совершенно невозможно поколебить. Вот. Но, значит... Если, значит, последовательность символов я могу прочитать и выучить, не действуя, то, значит, сколько бы вам ни рассказывали, как нам надо учиться на кайте, это как бы очень интересное движение, пока вы на кайт не встанете, физически это не попробуете, никакая последовательность символов вам не поможет. То есть действия, они к символам, вообще говоря, не сводятся. То есть символы вам помогают какие-то действия направить, но попробовать будет обязательно. Если вы, значит, теоретически все это видите, а потом станете скайтом, ну извините, значит, результат вы примерно знаете сами очень хорошо. 

S05 [01:34:27]  : Мы сегодня в полтора часа в телеграмме обсуждали тему символ-граундинг, поэтому я с вами полностью согласен. Собственно, вопросы, и вопросы как раз именно по коммуникации. Сергей, скажите, вот вы в самом-самом начале говорили, что роботы будут общаться друг с другом и обмениваться между собой знаниями. У вас есть какие-то соображения по поводу того, на каком языке будут общаться роботы? И будет ли это тот же самый язык, на котором роботы будут общаться с людьми, или друг с другом роботы будут общаться на одном языке, а с людьми на другом? 

S11 [01:35:08]  : Хороший вопрос, но это уже из области утрологии, ну, можно, значит, пофантазировать. Ну, во-первых, во-вторых, они будут, конечно, способны разговаривать, в этом смысле общаться друг с другом на человеческом языке будет возможно, но вряд ли это правильно, потому что, ну, мы просто зажаты вот своим, вот, несколькими десятками пяти секунд, которые мы можем через которую мы можем общаться, скорость общения через язык, она очень медленная. И при наличии совершенно сетей современных 5G, когда вы можете 100 гигабит передавать, то вообще ограничивайте десятки бит в секунду, Но это глупо. Они могут передавать целые модули. Они могут обмениваться обученными модулями, обмениваться кусками психики, как бактерии обмениваются кусками генома. Если бактерия передает набор генов, то принципиент получает поведение и программу поведения в готовом виде. Ему не нужно проходить всю эту эволюцию заново. И вот я считаю, что такая возможность у роботов имеется, а для человека она закрыта. Понятно, что, скорее всего, роботы будут использовать этот backdoor и общаться между собой моделями, а не словами. И это общение будет организована, видимо, как какой-то язык. В свое время Microsoft, по-моему, предлагал такой мета-язык, мегасистему, когда бизнес описывается какими-то правилами, и можно тогда кусками бизнес-процессов обмениваться. Но вот это не пошло, а на уровне роботов это может пойти вполне. То есть вполне может быть некий мета-язык, который позволяет говорить не словами, а кусками психики. И как бы передавать мысли в готовом виде. То есть решить трудную проблему сознания методом передачи куска сознания непосредственно. Для нас это недостижимо, поскольку у нас такой хардвер. Мы зажаты вот этими несколькими десятками бит в секунду, которые мы способны воспринимать в виде языка. 

S05 [01:38:02]  : Спасибо, Сергей. И второй мой вопрос. Когда вы говорите об архитектуре, с одной стороны вы показывали картинку, где показана архитектура мозга, как различные модули взаимодействуют друг с другом. С другой стороны, да, есть Минский, у которого есть агенты, и эти агенты в процессе взаимодействия друг с другом учатся распределять свои функции. С третьей стороны, вот у нас есть, допустим, та архитектура, которую вы хотите создать вы. и здесь у меня возникает вопрос вот этого специализация вот этих вот так сказать кусков пирога да то есть предположим каждую моду это вот некоторый кусок многослойный пирога который отвечает за какую-то функцию так вот на за нарезку этого пирога и соединение вот этих вот кусков пирога друг с другом, предполагается, будет отвечать создатель или архитектор, или же мы предполагаем, что просто вот мы создаем такую большую кучу слоев, а как они потом кластеризоваться будут на куски, это уже будет зависеть от динамики взаимодействия с окружающей средой. Ну или, так сказать, у нас может быть, скажем так, с фабрики выходить пирог не специализированный, но в зависимости от того, какую задачу нужно решать, там на самолете лететь или там урожай собирать на поле, архитектор будет вот этот вот пирог резать на правильные пропорции. 

S11 [01:39:35]  : Тоже хороший вопрос. Я его закольцую, наверное, с первым вопросом, потому что AutoML. Когда имеется такая архитектура, фактически это есть предпосылка для того, чтобы AutoML автоматизировать. Нарезку вот этого пирога можно тогда алгоритмизировать каким-то образом и перебирать его Ну действительно вот механически как-то. Кто-то будет исходить, может быть, из каких-то других соображений. Ну то есть это такая конструкторская роль. Работа конструктора, она во многом такая очень творческая. Какие там идеи придут, я не знаю. Ну, здесь, конечно, простор для фантастики. 

S08 [01:40:33]  : Спасибо. Если можно, я этот простор быстро соединю. Можно? Ну, давайте, хорошо. Значит, простор в чем состоит? Может быть, я о вас так плохо думаю, но вы, значит, живете в парадигме символьной обработки информации, которая есть в процессоре. То есть он же работает с битами, это символы и, соответственно, натуры. И машина дура. Значит, ей какую программу заложишь, она такую и делает. Заложили хорошую, она делает хорошую программу. Заложили плохую, она плохую не спрашивает, значит, надо делать, не надо. Вот есть программа, она ее выполняет. Вот. Значит, человек, он не так. Ему сказали что-то делать, а он думает, а стоит ли? Вот. Вот сейчас прошел у нас семинар. Ну, я, допустим, отходил, там у меня и другое восприятие. Вот. Но все остальные, надеюсь, все прослушали. Но поверьте мне, что у каждого восприятие, значит, того, что было сказано, свое. Более того, говорилось, что общение роботов может быть очень быстрым. Да, конечно, оно может быть быстрее, чем у человека, но приводит такой пример, что робот может за один день прочитать все книги, которые вообще за историю человечества было написано. Но если он их прочитал с целью записать в свою память, вообще без проблем. Но если он их перерабатывает, чтобы как-то преобразовать в действие, то это как бы другое. То есть мы, допустим, в детстве читали какую-то книгу, потом в школе ее проходили, и сейчас возьмем прочитать. Наше восприятие одной и той же книги, где буквы у буквы все то же самое, оно совершенно разное. Поэтому каждый робот, у которого не вот такая машина-дура, которая выполняет символную программу, а работает в реальном мире с непрерывным содержанием, она символную информацию соотносит со своими реальными действиями каждый раз по-разному в зависимости от своего опыта реальных действий. Поэтому вот эта простота общения, она хороша для компьютеров, которые там вот эта вот система оси семиуровневая разработана, она на самом деле нигде не реализована полностью, там обычно пяти-четырехуровневое взаимодействие, оно замечательно все работает, и действительно для символьных машин это все хорошо. Но, значит, если мы готовим сильный искусственный интеллект для реального мира, там вот это общение будет не столь простое, значит, передача информации. Скорость общения человека можно превзойти и на много, но вот это представление о том, что мы там можем залить всю информацию про весь мир, которая содержится во всех книгах, и более того, представление о том, что все знания об этом мире содержатся в книгах, оно неправильное. От того, что вы прочитаете очень много книг и не будете ничего делать, ваши знания будут чисто книжные. Есть такой хороший термин. Книжные знания, которые к жизни имеют посвенное отношение. Можно книжки почитать, а потом начать эти знания пытаться воплотить в жизнь. И без опыта они в жизнь не воплотятся. Вот эта проблема, которая тоже будет у роботов. при общении, поскольку, значит, если вот эта многоуровневая структура, она не стандартизована, а у каждого набирается автоматически в процессе общения, значит, с миром. И это как бы желательно, потому что если мы скажем, что вот это вот правильно, а дальше развитие не нужно, то развитие остановится. Вот. Ну, соответственно, вот, как бы сказать, вопрос не такой простой, как бы сейчас попробовал нам рассказать Сергей Александрович. Может быть, конечно, он упростил Ассам Сепов, просто для нашего, для облегчения нашего наивного понимания. Вот. Но хотелось бы обратить внимание, что все несколько сложнее. 

S05 [01:43:46]  : Спасибо, Владимир. У нас есть вопрос у Бориса Новикова. 

S01 [01:43:52]  : Антон, можно я прошу прощения? Я сделаю маленький комментарий. Сергей Александрович совершенно не хочет противостоять этого напору Владимира. Один маленький комментарий. Владимир, у меня ощущение, что вы не совсем правильно понимаете или не совсем правильно услышали Что имеет в виду Сергей, когда говорит о символах? Я, может быть, даже что-то пропустил, поскольку я отходил. У вас большой поток текста. Дайте я попробую немножко сформулировать. Когда вы на обычную нейросетку, у которой там куча входов и дальше есть множество слоев, и, допустим, мы анализируем котиков-собачек или машины, то потом в конце, ближе к выходным слоям, появляются так называемые фичи. Вот эти фичи — это некие признаки машины. Ну, допустим, условно, фича — колесо, фича — боковое зеркало или фича — пикап или какая-то. Вот каждый из этих фич является символом, не написанным никем. Это не слова, это некоторое упрощение исходной информации. По-другому скажу. Перед нами бесконечный мир с огромным количеством непрерывных движений. Но мы его анализируем и обрабатываем конечным количеством нейронов, которые тем самым как-то дискретизируют это пространство. Вот то, о чём говорит Сергей, мы говорим о том, что всю бесконечность внешнего мира мы внутри дискретизируем в некоторой комбинации. И вот эти комбинации являются некоторыми внутренними символами. Ну, условно, их так удобно называть. Это не буквы, это никакой не язык. Это просто для упрощения. Но мы используем там слово «символ», оно удобно. 

S08 [01:45:49]  : Ну вы так не напрягайте. Я говорил о том, что я даже те биты, которые обрабатывает обычный процессор, я их тоже считаю символами. 

S01 [01:45:56]  : И в этом смысле, Владимир, здесь нет никакого движения, нисходящего сверху вниз. Я вообще не знаю, о чем речь, где там Роман Душкин, идеолог какого-то нисходящего сверху вниз движения. Понятия не имею. Здесь есть движение снизу вверх, когда у вас есть поток непрерывных данных, который, как бы, сворачивается, дискретизируется и получаются некоторые маленькие компактные последовательности, то, как бы, Сергей дальше говорит, это парсеры. Парсеры это обрабатывают и на каждом слое получаются, как бы, еще более компактные последовательности, иерархические по времени, потом они спускаются обратно и разворачиваются обратно в мир непрерывных действий. Здесь нет никакого, как бы, нисходящего потока абстрактных символов, которые все задают. Как раз идея вся очень физически понятна. Непрерывный мир кодируется, дискотизируется в очень такие компактные представления. В них идет обработка, а дальше они разворачиваются обратно. Вот я ссорю за... Я не могу, но Сергей никак не хочет это комментировать. Сергей Александрович, извините, если я... Я полностью солидарен с тем, что ты усказал. 

S08 [01:47:00]  : У нас очень много вопросов. 

S05 [01:47:02]  : Давайте мы дадим слово другим. Владимир, давайте вы на следующем семинаре еще расскажете. 

S01 [01:47:16]  : Вот я просто отмечу, что... Давайте мы дадим доклад, и пусть он расскажет. 

S05 [01:47:20]  : Да, да. Вот я, кстати, удивлен, значит, обычно на семинарах Борис Новиков качает головой, значит, из стороны в сторону, что он не согласен. А вот сегодня я вижу, он в основном кивает головой, поэтому мне очень интересно, что он будет спрашивать. Борис, пожалуйста, звук только включите. 

S07 [01:47:36]  : Здравствуйте. Участников меня слышно? Спасибо докладчику за очень интересный доклад, но у меня к этой теме интерес немножко другой, чем у большинства присутствующих, а именно философский и методологический. Это обычно, с моей точки зрения, главный стратегический вопрос, в любой деятельности, а что есть хорошо и что есть плохо, применительно к результатам этой деятельности. Какие стратегические цели у этой деятельности стать. Здесь было сказано докладчично, что стратегическая цель операционной системы для роботов. Правильно я понял. Им что роботы должны быть полезны. Первый вопрос. Кому полезно? Себе или человеку? Если человеку, то какому? Второй вопрос. Откуда и как в этой модели берутся функции предпочтения или отбора вариантов? Какой вариант лучше, какой хуже? на всех уровнях. И, соответственно, вот психика, говорилось о психике робота, все-таки, с моей точки зрения, это не функция мозга, а функция организма. И деятельность психики не сводится к организму, а есть еще социальные деятельности, то есть деятельность в обществе. И, соответственно, роль общества как учителя, где все сводится к биологическому благополучию организма. Есть феномен самопозеркования на войне и так далее. Это второй образ. И если мы делаем психику для роботов, то какой у роботов будет критерий прохождения? что для робота. 

S11 [01:49:53]  : Критерий чего, я не расслышал? 

S07 [01:49:54]  : Критерий практики. У человека познание регулируется в конечном случае, через культуру, ну, критерий практики. Но, поверьте, у меня второй критерий, вы не разумеете. По практике этого связано. Самые важные списки, а не промежуточная стимульная обработка. 

S11 [01:50:25]  : Хорошо, давайте я попытаюсь ответить по порядку. Вот это reinforcement learning, оно в некотором смысле абстрактно по отношению к тому, а что это за сигналы подкрепления. Все зависит от них. Как они будут задаваться и кем они будут задаваться, такой будет результат обучения. И в этом смысле это очень правильный вопрос. И целая книжка Стюарта Рассела, которую я цитировал, посвящена этому. Чему будут учиться роботы и как заменить три закона робототехники Азика Азимова на три закона робототехники, где основная мысль в том, что роботы должны максимизировать нашу пользу. То есть все сигналы подкрепления должны идти от нас, от людей. И тогда не будет никаких тех парадоксов, о которых писала Эсик Азимов Потому что, ну понятно, когда есть там третий закон, что он должен еще и себя сохранить, то они будут противоречить и так далее. То есть роботы будут воспитываться в обществе, и вообще в этом смысле они будут, имея вот эту скучную психику, мы получим ситуацию очень близкую к тому, что ну просто есть вот другие существа с похожей на нас психикой, но, в общем-то, другой, конечно, да, но с которыми мы вместе делаем какую-то работу, а именно вот то, что называется экономикой, да, то есть есть некое разделение труда, что-то делают они, что-то делают мы, мы постоянно общаемся, понятно, что делается это во имя каких-то ценностей, эти ценности тоже надо знать, И роботы должны будут ориентироваться в физическом мире, и не только в физическом мире, но и в мире социальном. И они будут постоянно решать то, что называется обратное обучение с подкреплением. То есть они должны будут восстанавливать нашу функцию болезненности, которая у нас есть, которую мы, собственно, тоже толком сами не знаем. Мы же не знаем, какие наши мотивы любимые. Они просто есть, мы как-то поступаем. Но судя по нашим поступкам, можно как-то реконструировать то, что нами движет. И это тоже будет одним из способов обучения. Так что здесь мы попадаем в ситуацию, когда у нас есть смешанное человекомашинное общение, смешанное человекомашинное общество. И мы должны найти место комфортное и для нас, и для них. И получить какой-то такой социальный симбироз. Я не говорю, что это будет просто. Я считаю, что это будет очень сложно. И, возможно, это будет некий такой экзамен для человечества. Но это будет интересно. 

S07 [01:53:46]  : А роботы предполагаются универсальные, как люди, или специализированные, как машины? 

S11 [01:53:56]  : Нет, ну уже видно, что они будут разные. Это мы просто видим, что есть дроны, есть пылесосы, есть доставщики, там, не знаю, пиццы какие-то, а есть еще человек подобные, есть собаки, которые бегают. Жизнь показывает, что роботы будут очень рады. 

S07 [01:54:19]  : У разных животных разные операционные системы. Разные мозги, разные организмы. Наверное, тогда и операционные системы роботов должны быть специализированы. 

S11 [01:54:32]  : Вот очень удобно будет, если они будут одинаковые, потому что тогда возникает гораздо больше возможностей для организации вот этого коллектива. 

S07 [01:54:42]  : Да, но когда резко снижается надежность, любой вирус отравит сразу все тропы. 

S05 [01:54:52]  : Согласен, это проблема. Борис, спасибо. Давайте дальше двигаться. У нас Виталий Мильке хотел задать вопрос. Виталий, пожалуйста. 

S02 [01:55:03]  : Здравствуйте, Сергей. Добрый вечер. Приветствую. Я хотел бы, как в практике из Кембриджа, вернуться на пару шагов назад и сразу По практическим вопросам. Понятно, что AutoML — это сильно ограниченная среда и ограничена теми environments, которые там запрограммированы. Я хотел бы сначала два вопроса задать, а потом один, после того, как вы ответите. Практически. Понятно, что критерии истинные. Проверка любой гипотезы — это практика. Каким образом все это практически проверить? Вы на какой практической стадии реализации, то есть программирования, вот вашей идеей, вашей гипотезы, которая есть, и было ли она там вами, вашими аспирантами, в вашей лаборатории уже сделана? И возможно ли существующих, понятно, что это нужно сделать как можно более дешевыми способами, Возможно ли использовать существующие фреймворки, которые мы все знаем, TensorFlow, PyTorch и так далее, встроить, взять оттуда что-то. Понятно, что они на низком уровне достаточно быстро интегрированы с хардом, чтобы быстро решать эти задачи. То есть, возможно ли использовать вашу гипотезу, программируя это на существующих фреймворках, и если да, то оценивали ли вы тот хард, который требуется для этого действия? Во все вопросы идет практическая реализация, на какой уровне это находится. Потом задам еще один вопрос. 

S11 [01:56:39]  : Ответ такой. Стадия очень ранняя. Но, скажем так, на самом деле это не первая стадия, потому что, как Игорь уже рассказывал, где-то пару лет назад уже начали делать такой, значит, прототип, который тоже работал и тоже загонял машинку, и сейчас он у Игоря развивается, по-моему, он уже там играет в ping-pong, вот, но, значит, здесь просто силы очень ограничены, там, один-два человека, поэтому, как бы, следующий шаг был такой, что создали лабораторию. Здесь мы пошли с самого начала, потому что я считаю, что не нужно использовать существующие фреймворки, потому что здесь надо так же, как при создании Ядра Линукса, отвлечься от всего, что было создано до этого, и на новых принципах создать оптимальную архитектуру, которая под эти принципы запрочена, на каком-то высоком уровне. Потому что нет смысла тащить весь этот багаж в библиотек, которые здесь не имеют никакого смысла и не релевантны, а надо создать свою компактную библиотеку, релевантную к этой архитектуре. 

S02 [01:58:15]  : Я немножко, честно говоря, не согласен с вашим подходом, потому что с точки зрения как это прямая, это не самый быстрый путь достижения цели. Можно как бы использовать те существующие здесь платные уже, как бы, возможности доступа к карду от существующих привозков, чтобы что-то показать, потом получить, соответственно, финансирование, и потом уже делать послужить фирмам. 

S11 [01:58:44]  : Ну, вот тут, вот тут присутствовал, я смотрю, Сережа Терехов, и он как-то мне рассказывал, он набирал в свою лабораторию, когда персонал, то у него был критерий такой, неумение программировать на бетоне. Я с ним в этом смысле согласен. Потому что даже опыт работы в моей лаборатории, когда я написал коды, а студент переписал его. Я сейчас не имею доступа к вычислительной технике, так получилось. Я написал код в дворце, он его переписал в очередной среде, она его запустила. Но он это сделал быстро, и он питонщик. А потом пришел очень грамотный программист с большим стажем, сишный. И мы пишем на Джулия, чтобы потом... Ну, по некоторым причинам. И он написал уже свой год, абсолютно не похожий на мой, но как бы в стиле C-шного программирования, даже, я бы сказал, в стиле функционального программирования. оказался гораздо более устойчивым, гораздо более красивым и проверяемым с точки зрения тестирования, чем код, который был написан быстро, цветущий. Вот. И я считаю, что подход должен быть всё-таки такой, что не нужно хвататься за всё, что было сделано. Всё, что было сделано, было сделано для какой-то своей цели. Если у нас цель отличается от этого, то надо подбирать новые средства. 

S02 [02:00:52]  : Понятно. Подход понятен. Я думаю, чтобы не занимать время, мы с вами потом поговорим об этом? Конечно. Раз варианты есть. Следующий вопрос, который я хотел задать, достаточно быстрый. С вашей точки зрения, нужно ли какой-то initial learning делать для этой системы, то есть условно загонять набор релевантных научных статей, допустим, если это по физике, значит по физике. по астрономии, значит, по астрономии, или же просто начиная с чистого листа, условно, сделать это, чтобы это было не ноль, как бы, какой-то рэндом заполнить это все, и пусть они там сами обучаются по типу, по типу альфа-зеро. Вот с вашей точки зрения, как это, понятно, что точно вы ответить не можете, но тем не менее, как будет? 

S10 [02:01:45]  : Чексты тут, как бы, ну... 

S11 [02:01:51]  : Но все институты не очень релеванты, поскольку речь идет об управлении поведением. И управление поведением вполне можно начинать с чистого листа. Но понятно, что мы, с другой стороны, всегда можем результаты предыдущего обучения передавать следующему поколению в каком-то виде, чтобы не повторять всю эту историю. Но сама по себе архитектура, естественно, с чистыми мозгами, и у него есть какой-то загрузочный модуль, который начинает посылать случайные сигналы на все актуаторы, и он начинает смотреть, что получается. Вот он дергает ручками-ножками своими, что меняется в мире, и младенец родился и начинает Ну, понятно, что не каждый робот так будет делать. Зачем? Когда робот уже обучен, то мы можем готовый психику залить и продавать уже готовый, да? Ну, а он будет там, да, пытаться чему-то в процессе жизни. 

S02 [02:03:00]  : Это понятно, да. То есть, а первое, самое условное первое, там, Адам, да, как вы говорите, он должен быть инициатором, или все-таки в него залить надо что-то? С чистого листа. Спасибо. Спасибо. Интересно. 

S05 [02:03:15]  : Спасибо. У нас следующий вопрос Владимира Соколова. У Александра Соколова, извиняюсь. Александр, пожалуйста. 

S12 [02:03:25]  : Да, ничего страшного. Слышно меня? Да-да-да. У меня пару вопросов коротких. Я буду по одному задавать, если можно. Вопросы на понимание. Правильно ли я понимаю, что вы проектируете свою архитектуру структуры, интеллекта, под осуществление процесса принятия решений? 

S11 [02:04:00]  : Да, правильно. Отлично. 

S12 [02:04:05]  : И поэтому, может быть, у вас ваша архитектура должна отличаться, видно, что она отличается от той архитектуры, которую сейчас у нас считается передовой, потому что их архитектура сделана под другой процесс. Вот процесс узнавания некоторого объекта по признакам. 

S11 [02:04:38]  : Именно так, да. И я так и считаю, что они решают просто другую задачу. И под другую задачу нужны другие средства. 

S12 [02:04:47]  : И под другой процесс, да. Я почему сейчас акцентируюсь на процессах, потому что я вот в этой группе пытаюсь для себя, ну и для других, может быть, выписать перечень тех интеллектуальных процессов, которые должен осуществлять интеллект. Искусственный или естественный сейчас осуществляет, неважно. Я вот задавал этот вопрос, пока никто на него не отвечает, приходится мне самому. Итак, получается, что мы в качестве интеллектуального процесса можем фиксировать процесс вот этот, Узнавание некоторых объектов по признакам – это один. То есть интеллект должен этот процесс осуществлять. Второй процесс, который вы занимаетесь и под него делаете архитектуру – это процесс принятия решений. О чем? О каких-то планируемых действиях. То есть это уже не о признаках каких-то кошечек и собачек, а о действиях, и поэтому вы говорите поведение. А поведение это то, что презентирует нам принятые решения. То есть некоторый интеллектуальный процесс протек, и потом он в деятельности это решение реализуется. Вот вы там описывали замысел, планы. Правильно я вас понимаю. Тогда еще один маленький вопрос. Правильно я понимаю, что тогда под обучением в подкреплении надо понимать, ну если вот вы занимаетесь именно этим процессом и архитектурой для этого процесса, надо понимать обучение этого интеллекта именно осуществлению этого процесса. 

S11 [02:06:36]  : Ну да, принятие решений, да, и обратное следствие принятием решения. 

S12 [02:06:41]  : Ваш интеллект должен осуществлять именно этот процесс. Он должен быть обучен этому. И вы даже обратите внимание, что он должен самостоятельно принимать решения. Ну как вот мы люди, мы же как бы самостоятельно принимаем, так и вы. Обучение как бы вот по содержанию будет сводиться именно к этому. То есть обученный робот это тот, который научился самостоятельно принимать решение. Да. Правильно? Правильно. И последний вопрос. Могу ли я так вот это обучение этому процессу как обучение получению знаний по содержанию. То есть, грубо говоря, нельзя принять некоторые идеи, если ты не можешь получить, образовать или построить какое-то знание. 

S11 [02:07:56]  : Да, конечно, на каждом уровне накапливается своя память, и это и есть знание. 

S12 [02:08:02]  : Ну да, какие-то знания откладываются где-то в память. Ну все, тогда у меня нет больше вопросов. Значит, я вас правильно понимаю пока. 

S05 [02:08:11]  : Александр, спасибо. Короткая ремарка. По поводу процессов я почти наверняка уверен, что вот в той статье, которую я докладывал на своём семинаре, почти все эти процессы выписаны. Поэтому я потом вам кину в группу ссылку, и вы можете ещё раз посмотреть. Если там вы считаете, что каких-то процессов не хватает или, значит, всё-таки вы спрашиваете не о том, то просьба отнестись. 

S12 [02:08:40]  : Да, хорошо, спасибо. А там есть эти два продукта, которые у меня сейчас... Что-что? Есть там эти... Там есть эти два процесса, которые я сейчас назвал? 

S05 [02:08:49]  : Вот, там есть список процессов, которые я вижу, за исключением там, может быть, одного или двух, про которые я тоже на докладе говорил тогда. Ну, давайте сейчас не будем отнимать время. Мы их отнесем, спасибо. Да, хорошо. Значит, у нас последний вопрос у Сергея Терехова. Добрый день, слышно меня? Здорово. Слышно себя? 

S09 [02:09:30]  : Я отчасти хочу продлить вопрос Бориса Новикова, но только в другую плоскость. Вот эти роботы, вот эти системы, их станет очень много, они будут проникать во все аспекты жизни, то есть это, значит, экономика, это означает, что это производственный новый способ производства, то есть это воспроизводственный контур, который должен их воспринять, этих роботов. Там потребуются скорости, нельзя будет дожидаться, пока они там медленно будут все там адаптироваться, дожидаться и так далее, и поэтому обмен кусками готового интеллекта становится ключевым, и в этой связи такой вопрос. Поскольку на разных слоях все слои архитектуры, они в общем-то одинаковые, они как бы воспроизводят друг друга, но языки на всех слоях разные, то возникает такая вещь, что вот в этом ринксе обязательно должен быть либо какой-то эсперанто, какой-то центр перевода куска интеллектов с одного языка на другой, Либо вопрос вот какой, почему нужно обязательно иметь разные языки на разных уровнях? Да, я понимаю, что они адаптируются с разной скоростью, но дело в том, что вот те вектора, перекрестья, так сказать, столбца и сточки, которые вы отправляете наверх, да, они, в общем-то, универсальны, и можно сделать карту Кахулина, условную карту Кахулина, просто большой, но работающие на одном языке. И тогда куски этой карты Кахона, во-первых, можно будет индексировать, искать. Во-вторых, их можно будет вырезать и вставлять в другие карты Кахона. Их можно будет продавать. Какие-то из них будут более ценные, какие-то менее ценные. Возникает экономика. Возникает способ, которым эта штука может быть воспринята каким-то контуром производственным, какой-то экономической системой. Спасибо большое ещё раз, если можно, прокомментируйте. Если это большой слишком вопрос, то можем как-то потом его дальше... Сергей? 

S05 [02:11:38]  : Так... По-моему, мы Сергея потеряли. 

S09 [02:11:47]  : Сергей, вы нас... Антон Германович, а пока Сергей подключится, а вот можно вас попросить тоже мне прислать вот эту статью, он по e-mail напомнил... А вы в группе есть в AGI Russia? Нет, я в социальных сетях не участвую никогда, я просто по e-mail попрошу вас, вы сможете... Да, хорошо, у вас есть мой e-mail? Да-да-да, я пришел. 

S05 [02:12:05]  : Хорошо, вы мне напишите тогда, я вам вышлю. Да-да-да, спасибо. 

S09 [02:12:10]  : Борис, а может быть, Борис Новиков ответит на этот вопрос? 

S05 [02:12:14]  : Да, ну давайте тогда мы без Сергея, так сказать, продолжим дискуссию пока тогда. Борис, пожалуйста. 

S07 [02:12:24]  : Значит, по вопросу обмена. Вот у нас людей человеческие есть такой феномен как культура. Он, собственно, и занимается обменом кусками моделей и алгоритмов поведения. Но культура феномена очень сложная, и чтобы она имела устойчивое развитие, там должно быть нужна модель такая, аналог естественного отбора в биосфере. То есть должны быть мутации, и их, естественно, То есть новые идеи, большинство из которых пустые, никуда не годятся и вредны, но, естественно, отбор отбирает то, что полезно, и это закрепляется в культуре. То есть то, что говорил докладчик, мне представляется аналогом культуры для сообщества робота. И вопрос, как эта культура робота в пользу соединена с культурой человечества. Но главный вопрос тут, на мой взгляд, это согласование интереса. Может ли быть культура без сознания, сознания без самосознания, а самосознания без собственных целей выживания себя и своего вида. Вот если робот образует свой аналог биологического вида, то человечеству придется очень плохо. И человечество должно этого не допустить. Поэтому нам нужны специализированные роботы, но не универсальные. 

S09 [02:13:59]  : Понятно. Спасибо большое. Огромное. Ну вот, наверное, еще тут имеет... Меня, наверное, не слышно? Слышно, да? Наверное, имеет еще тут ситуация такая, что если мы понимаем, чем эти роботы будут амбидиумтся, то мы это можем проверить. То есть мы можем взять... Ну это я согласен, да, да, да. 

S05 [02:14:37]  : А вот Сергей подключился. Сергей, можете повторить вопрос свой для Сергея? 

S09 [02:14:43]  : Серёжа, ты не слышал мой вопрос? Давай я попытаюсь переформулировать, а ты меня поправишь, хорошо? 

S11 [02:14:50]  : Ну ты услышал, да? 

S09 [02:14:53]  : Ага, хорошо. 

S11 [02:14:55]  : Я кусочек слышал. Я так понял, что ты говорил, что можно сделать из вот этих вот кусочков карт Кахонина, некие слова, нарезать их по кусочкам и обмениваться вот этими кусочками. 

S09 [02:15:26]  : Ну да, потому что это очень быстро, это быстрое ускорение сразу. Если мы готовы Брюс Хаймс можно отмениваться, то для экономики. 

S05 [02:15:32]  : Ну и Сергей, еще я услышал вопрос, что зачем нам каждый индивидуальный язык на границе каждых двух слоев? Почему мы не можем сделать единый язык для всех слоев, на котором они будут общаться? 

S10 [02:15:45]  : Да, как раз хотелось. 

S11 [02:15:49]  : мы можем себе представить это как торт «Наполеон», и вот этот слоеный пирог мы нарезаем кусочками, и вот этими кусочками уже торта мы можем обмениваться, потому что тогда там идут высокоуровневые понятия вместе со всеми низкоуровневых понятиями, которые они там граммуют, то, что называется. на которых они основаны. И тогда можно будет обмениваться вот именно кусочками пирога, а не кусочками слоев. Не кусочками вот этого слоеного теста, а кусочками готового пирога. Я считаю, что вот это будет более продуктивно. Но рынок, о котором ты говорил, он вполне возможен. 

S09 [02:16:39]  : Ну потому что если мы не будем изначально думать об этом, то это как бы повиснет, это просто не ляжет в укладку какой-то. 

S05 [02:16:50]  : Хорошо. У нас еще была ремарка или вопрос Бориса. Борис, пожалуйста. 

S07 [02:16:58]  : Значит, вот было, уважаемый господин, рассказано о воспитании робота. А как бы спекуляции? Человеки очень разные, и субкультуры разные, и сообщества разные. И пока высказанием людей, спекуляцией, культуре человечества приводил состояние. Так, и что существует? Роботы? 

S11 [02:17:39]  : Это большая проблема, и, собственно, я считаю, что когда я говорил, что человечеству предстоит просидеть экзамен, я это имел в виду, потому что если делать роботов с нашим нынешним уровнем агрессии в обществе, то, в общем, нам не поздоровятся. Но дело в том, что тут же не мы решаем, тут военные решают, и они первыми поплатятся за те преимущества, которые дают роботы. Поэтому это на самом деле дело всего общества, как снизить градус агрессии в мире и каким способом Можно создать среду, где люди умеют договариваться между собой не с позицией силы, а с позицией того, что и офисы целы, и волки сыры. Это гуманитарная проблема, это не только техническая. Тут я с вами абсолютно согласен. 

S07 [02:18:48]  : На вас, глядя в искусственные телословия, показали, что агрессия – это необходимый элемент психики и культуры, необходимый для развития. Изначально книжки «Астронавты» трудно вспомнить. Попытались изъять агрессию и из этого ничего не выяснилось. Поэтому посылки с агрессией присутствуют в этих книжках. Вы знаете, есть... Вы, по-моему, игнорируете момент врожденности, что мозг нечистый есть, и организм нечистый. В момент врождения появляются определенные навыки, которые потом развиваются в течение жизни. 

S11 [02:19:47]  : Да, но вот есть там Назаритяна книжка про то, что есть закон социо-культурного баланса, он его называет. 

S07 [02:20:08]  : Все оружие и орудия управлялись человеком, чтобы поддерживался социо-культурный баланс. А если будет саморазвивающийся искусственный интеллект, то он не будет контролироваться человеком, и есть большая угроза, что социо-культурный баланс будет нарушен. 

S11 [02:20:27]  : Угроза есть, я согласен, но дело в том, что он все равно будет развиваться. Мы не можем остановить этот процесс. 

S07 [02:20:34]  : Это не надо, не надо такого фатализма. Вот я проводил на Уолоке, в круге Ай-3, с чумами дыры. Есть такая интегрированная научная задача, синтезирующая землетрогазы, которые может землю погладить. Мы, я надеюсь, этим землетрогазом. Может быть, и есть. Хорошо, Борис, спасибо. Я не думаю, что тут можно каким-то образом ограничить хотя бы тишину. Но я думаю, что можно. 

S11 [02:21:08]  : Вот планирование тепловека было запрещено, а Китай сделал, например, вне обстоятельств тепловых тюремных прав. 

S01 [02:21:25]  : Борис, сложность сегодняшней жизни состоит в том, что это уже факты. Мы находимся в мире, где уже существуют и работают. В качестве примера я могу сказать, что Два года назад были слушания в Американском Сенате, когда накрыли программу агентства национальной безопасности, пентагоновскую программу под управлением АНБ, в рамках которой они автоматическим образом уничтожали боевиков в Пакистане, в Сирии беспилотниками на базе сигналов мобильного телефона. Ну послушайте, послушайте, я разбирался в теме, в отличие от вас. Я правда, я сейчас не вспомню название, у меня память плохая на название, но принципы все помню, я могу сбросить потом ссылку. Анализировались паттерны мобильных телефонов переговоров. Это достаточно просто. Строится граф и кто с кем разговаривает. И вычислялись потенциальные террористы. Те, кто общался с террористами. И потом, когда такие телефоны засекались в определенных местах, где было скопление нескольких таких телефонов, по ним беспилотник наносил автоматический ракетный удар. Было убито порядка 1100 человек. Это факт. Как бы это не угроза, это реальный факт, который был. Никакой человек там не участвовал. Собственно, скрылась эта история именно потому, что стали разбираться, каким образом, и у них слушания были, и какие были доказательства. Я к чему? Мы находимся в очень сложной и уязвимой области. С одной стороны, я целиком разделяю ваши опасения, уже много лет об этом думаю. И там в нашем сообществе, в российском, очень мало дискурса, обсуждения того, зачем мы вообще это делаем. Хотя на Западе его много больше. И там есть яркие фигуры, которые эту позицию занимают. Ну типа Илона Маска, например. Или там Рэй Курцвелла. А у нас, ну как бы с этим хуже значительно. Я бы сказал, что, на мой взгляд, хорошую позицию выразил Константин Анохин, который у нас, кстати, был на встрече на этой, но он ее покинул какое-то время назад. На конференции Open Talks I у них было обсуждение Статины Черниговской в конце, и он очень красиво сформулировал, как мне кажется, эту идею, что мы должны заниматься изучением сознания того, как он устроен, и механизм работы мозга для того, чтобы у искусственного интеллекта, который мы сделаем, не было этого сознания, чтобы оно не появилось, предотвратить его, потому что с точки зрения человечества, как вида, мы здесь не выиграем. Но надо понимать, что бессмысленно обсуждать идею, но это конструктивный подход. А бессмысленно обсуждать идею, как-то это остановить. Я, во-первых, над этим думал года два, понял, что это невозможно. Весь мир уже прыгает с крыши, к сожалению, и мы не можем этого... Я не могу с этим согласиться. 

S07 [02:24:56]  : Более того, я уже несколько лет занимаюсь реализацией этого высказывания Аносина. У меня есть статья. о предварительной записке «Общая теория сознания». Она у Вагита несколько раз была упомянута. И в конце есть раздел специфического, настоящего исторического момента в истории человечества и искусственного интеллекта. И там подформулированы две задачи. Тактическая, международная соглашение о запрете роботов, которые самостоятельно принимают решения о поражении людей, вот как это в Сенатское слушание. Это пыталось осудить, насколько я понял, с ваших слов. Может быть, запретят нас, кто и надеется. А стратегическая задача — допускать разумность роботов, но не допускать их живости, чтобы они не превратились в аналог биологического вида. А конкретно международное соглашение на основе организации типа МАГАТЭ и жесткий контроль, чтобы воспроизводство роботов обязательно включалось в цепочку человека, чтобы роботы не воспроизводили сами себя и не могли эволюционировать в физическом теле. В крайнем случае, если они будут только в интернете, Если отключить весь интернет, человечество станет очень тяжело жить, но оно не вымрет. Жили там веками без интернета, и вот такое сильное превосходство. Отключили интернет, и разрушился этот искусственный интеллект. А вот если они будут иметь тело, и эволюцию мозгов намного быстрее, чем у людей. Вот тут человечество будет хуже. 

S05 [02:26:52]  : Спасибо, Борис, коллеги. 

S07 [02:26:53]  : Компьютер придет значительно быстрее, чем у людей. 

S05 [02:26:58]  : Борис. 

S07 [02:26:58]  : Не так опускать соединение эволюционирующих мозгов с телом робота ненавидит человек. 

S01 [02:27:07]  : Слушайте, как философ я с вами согласен, но Сергей прав. Определяют же военные во многом. То есть, здесь сейчас делать... Нет, не так, нет. 

S07 [02:27:16]  : Ну, есть исторические примеры, я их изучал. Например, матч всех бомб. Обсуждалась термоядерная бомба, там... не в 50 там не готово, а в 200 не готово. Ученые сказали, что от нее может начаться цепная реакция, и Земля может взорваться. В земле может начаться, в земной коре. Ее не сделали и делать не будут, я убежден по принципам техногуманитарного баланса. Если осознать угрозу универсального интеллекта, его неконтролируемый эволюции, то и я убежден, что и это можно не делать. Так же как и всякие другие супервоенные штучки, которые там генетические вирусы, которые одну расу уничтожают, другую не уничтожают. Пока это то ли возможно, то ли нет, еще неизвестно, но таких этих разработок запрещают. 

S05 [02:28:25]  : Борис, спасибо. Коллеги, давайте еще. У нас Владимир Смолин давно хотел высказаться и Николай Рябичевский тоже уже тянет руку. Владимир, включите, пожалуйста, звук. 

S08 [02:28:45]  : По первому кругу, а по второму я готов еще подождать. 

S05 [02:28:50]  : Давайте просто недолго уже, потому что мы уже два с половиной часа. 

S08 [02:28:53]  : Александр Соколов говорил о том, что современные сети глубокого обучения никаких решений не принимают. В общем, у алгоритмистов есть такое предубеждение, что наши алгоритмы принимают решения, а нейросети Нет, это, значит, на мой взгляд, заблуждение, что на самом деле даже, значит, когда осуществляется какое-то распознавание, это, значит, принятие решения. Просто решение мы принимаем обдуманно и необдуманно. Если взять тот же пример с Альфреда Голова или Алиса Зерова, допустим, Она тоже может этот анализ продолжения не осуществлять. Она может играть прямо на основе ассоциации. Вот есть позиция, какой ход лучше, и его осуществлять. Прикинули, сколько это будет в шахматах по разряду. Где-то кандидат-мастера, мастер спорта. Если среди нас участников семинара гроссмейстеров нет, то вот таким путем, без обдумывания позиций, Альфа-0 у всех выиграет. Потому что понятно, что кандидат-мастера, если встречается с наивным шахматистом, выигрывает в одню арту. Но, значит, если она обдумывает свои ходы, их продолжение, результаты, выбирает из разных вариантов хороших ходов, которые у нее есть, то она выигрывает у чемпиона мира. И это как бы значительно более сильное достижение. Вот. В принципе, значит, нейронные сети, хочу сказать, они все-таки принимают какие-то решения промежуточные, то есть цель им ставится извне, значит, что, значит, собственно, вот тот же Рассел обсуждает в своей книге, что для создания сильного искусственного интеллекта создавать такие устройства, которые не сами ставят, в смысле, которые не из внеста получают цель, а, значит, находят ее сами. И, в принципе, он согласен с тем, что на основе нейронных сетей можно создавать такие системы. Но поскольку он сам алгоритмист, он тоже не понимает, как это делать, но это отдельный вопрос. По крайней мере, он приходит к такому мысли, что, в принципе, это возможно сделать. Ну, у меня есть какие-то свои позиции, но сейчас, конечно, я не буду рассказывать. Это по поводу того, о промежуточных и глобальных целях, которые достигает сеть СОСТИ. Если мы умеем строить промежуточные цели, то построение глобальных целей от строения промежуточных целей не сильно отличается, просто оно немножко сложнее, но не принципиально. Теперь по поводу опасности строения сильного искусственного интеллекта. Я, конечно, согласен со всеми рассуждениями и Рассела, Остальных, кто тут сегодня рассказывался, это большая проблема, но обычно на эту тему рассуждают состоятельные белые господа, которые довольны устройством общества и считают, что общество у нас хорошее, а вот машины, которые придут, они его могут поколебать. На самом деле беда с тем, что общество-то у нас не очень. Состоятельные белые господа, конечно, хорошо там живут, им нравится это общество. А в целом есть ряд проблем в этом обществе. И я бы завел этот тезис несколько дальше. Что человечество выделилось из животного мира тем, что оно очень давно создало суперинтеллект. То есть любая организация, которая создана человеком, это, собственно, некоторое объединение небольших интеллектов, которые вместе создают суперинтеллект. И вот управлять этим суперинтеллектом мы, на самом деле, не научились. То есть вот эти все организации, которые в нашем обществе есть, они работают на себя. То есть они, там, неважно, военные они, там, профсоюзы, там, не знаю, какая-нибудь там Росгвардия, команда президента, они, ну я уж про корпорации не говорю, они работают на себя. И мы не научились, значит, управлять этими, значит, суперинтеллектами, чтобы они приносили нам пользу, а не приносили пользу себе. Вот, чтобы, значит, говорить о том, что вот мы будем создавать какой-то сверхинтеллект, который будет приносить остальным пользу, Надо все-таки и эту сторону рассматривать. А как нам научиться? В принципе, у Рассела есть некоторый аналог того. Он, правда, очень слабо развивает эту идею, но какие-то мысли у него к этому появляются. Вот эти принципы, на которых хотелось бы ему организовывать искусственный интеллект, чтобы он был полезен человечеству, хорошо бы эти принципы применить к организациям. Но пока что, по крайней мере, по моим наблюдениям, это не удается. И, скажем так, от организации, конечно, есть какая-то польза, но она сограничена. И последнее замечание, что, конечно, польза определяется как раз вот этим самым естественным отбором. То есть пока есть много стран и много корпораций, то все как бы хорошо за счет того, что если где-то что-то идет плохо, там, где пользы от действий больше, значит, она начинает экономически и социально выигрывать страна. И, соответственно, те страны, где сильно очень зажимают население или, наоборот, дают им слишком большую свободу, там, соответственно, они отбивают мира. То есть, первейшая борьба за предотвращение катастрофы – это, собственно, такая простая идея, как сохранение многополярности мира. То есть, если сохранить многополярность мира, то это уже снимет ряд, скажем так, опасностей. Простое замечание. Ну, я ещё много чего могу рассказывать, но основное, да, что хотел сказать. 

S05 [02:34:04]  : Спасибо, Владимир. Николай. 

S00 [02:34:09]  : Добрый день. У меня два очень коротких замечания. Во-первых, термонядерные бомбы очень высокой мощности не делают не потому, что боятся физических последствий, а по совершенно другой причине, потому что несколько зарядов меньшей мощности дают гораздо большее разрушение, чем один большой. Поскольку площадь разрушения зависит от мощности, но не линейно, а как минимум как корень квадратный, то нет смысла увеличивать мощность. Второй момент это Опасность суперинтеллекта, в принципе, существует, но, во-первых, время, которое потребуется для того, чтобы он действительно стал суперинтеллектом по сравнению с лучшими человеческими образцами, довольно длинным будет, и будет время как бы адаптироваться к этому. А во-вторых, исключение, то есть подключение человека к важным решениям типа вот стрелять или не стрелять, оно не является решением на самом деле. Потому что формально всегда, ну вот в этой ситуации, о которой говорил Игорь, достаточно, чтобы все было как и раньше. Автомат обнаруживает, принимает решение, но перед этим он делает звонок оператору, который нажимает кнопку, при этом у него нет времени на достаточно серьезный анализ. Он просто формально подтверждает, если нет. И третье замечание. Появление животных не привело к исчезновению растительности. Появление млекопитающих не привело к исчезновению низших форм. Появление человека не привело к исчезновению низших млекопитающих. Поэтому совершенно неинчевидно, что появление интеллекта более сильного, чем человек, приведет к тому, что исчезнет человек. Все развивается по принципу Это, кстати, некая экосистема. Человек не может жить без растений, человек не может жить без бактерий, даже без вирусов не может жить. Поэтому вполне резонно считать, что в том далёком будущем, когда этот интеллект появится, такого уровня, как описан сейчас, он не сможет жить без человека или, по крайней мере, ему будет удобнее жить вместе с людьми. 

S08 [02:37:38]  : У меня всё. Можно, я скажу, я не могу. Ну, значит, прогноз современный, значит, появление сильного искусственного интеллекта 2025-й год, чтобы это было понятно. Вот. То есть это далёкое будущее, не все из нас доживут, конечно, но вот пять лет осталось. Соответственно, хороший пример есть у Рассела. Как известно, лошадь в истории человека, она была очень долгая. И Рассел приводит такой пример, что где-то в начале прошлого века две лошади друг с другом беседуют, что как бы много было... Они, значит, вот изобрели двигательное возгорание, повредит ли это нам? Другая лошадь говорит, ну, помнишь, там плов изобрели, телегу изобрели, еще что-то изобрели. И нам находилась работа. И, как перед разом, лошадям в 20-е и 30-е годы прошлого века нашлась работа. Они пошли на корм другим животным. Они не совсем исчезли, но какая-то часть осталась. Их используют в цирке, детей катают. Я не хочу сказать, что это обязательное решение, которое, в смысле, обязательная перспектива, которая будет у человека. Можно и нужно бороться с такой перспективой, но ожидать, что само с собой всё рассосётся, это, на меньше мере, наивно. 

S05 [02:38:52]  : Николай, можно я, так сказать, два слова тоже оставлю, потом вы, и давайте, наверное, уже, если у Сергея не будет возражений, мы подведем итог. Значит, насчет предсказаний. Ну, я, как сейчас, что называется, помню, 20 лет назад Бен Герцель утверждал, что через пару лет все проблемы будут решены. А в прошлом году осенью была фокус-группа Сбербанка, где специально человек, я не помню кто, делал доклад, и там говорил, что был произведен опрос компетентной аудитории по поводу именно того, когда наконец. И разброс получился действительно от нескольких лет до 80 лет, по-моему, или даже до 100 лет. То есть, в общем, медиана получается где-то лет 50. Поэтому нас ждёт, я думаю, много интересного и неожиданного в неопределённое время. Николай, пожалуйста. В звук включите только. 

S00 [02:40:01]  : Я хотел сказать ровно то, что вы уже сказали. Предсказание скорой разработки. Вот я слежу за сферой искусственного интеллекта где-то с конца 60-х годов. Вот. Включая первую волну, включая этот хайповый проект Японии по созданию интеллекта этого нового. И прогнозы всё время есть, и они, как правило, вот в районе от 5 до 20 лет, но в течение этих 50 лет они просто отодвигаются, не укорачиваются. 

S05 [02:40:44]  : У меня всё. Как у ахилла с черепахой. Сергей, вы скажете что-нибудь в заключение? Уже по времени мы перешли все аргументы. 

S11 [02:40:47]  : Мне просто кажется, что естественным образом назревает некий семинар по социальным последствиям искусства и телек, потому что это вызывает бурные эмоции. 

S05 [02:41:17]  : Если Игорь не будет возражать. 

S01 [02:41:20]  : Я целиком знаю отдельный семинар. Более того, такой семинар уже не существует в философии. Иногда бывает, но там уже сложно. Поэтому надо... Хорошо. 

S05 [02:41:29]  : Ну, Игорь, может быть, вы возьмётесь быть застрельщиком? Да-да, давайте сделаем, конечно. Хорошо. Ну, спасибо тогда коллеге всем. До свидания. Спасибо огромное. Всего доброго. Всем пока. 

S02 [02:41:41]  : До свидания. 

S09 [02:41:41]  : Всем счастливо. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
