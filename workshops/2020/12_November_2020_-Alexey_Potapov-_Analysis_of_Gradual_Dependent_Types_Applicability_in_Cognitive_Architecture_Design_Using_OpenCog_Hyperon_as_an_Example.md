## 12 ноября 2020 - Алексей Потапов - Анализ применимости градуальных зависимых типов в дизайне когнитивных архитектур на примере OpenCog Hyperon — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/qIeAxhKZhyU/hqdefault.jpg)](https://youtu.be/qIeAxhKZhyU)

Суммаризация семинара:

ТЕМА:
- Анализ применимости градуальных зависимых типов в архитектурных проектах OpenCog Hyperon.

СУТЬ:
- Приведение специфичной темы для анализа: индивидуальные зависимые типы в дизайне коммуникативных архитектур, таких как Охонкок и Гиперон.
- Обсуждение релевантности темы за пределами наработок, включая возможность обсуждения и применения вне проекта.
- Краткий обзор OpenCog, включая концепцию Atomspace и базовые узлы и связи в нем.
- Обсуждение проблем инференса в нетипизированных системах и необходимость значительных усилий для их реализации.
- Приведение замечаний относительно концепции типа и узла, вопрос о возможно отказе от этих понятий и редуцирования гиперграфов к упрощенным графам.

ДЕТАЛИ:
- Анализ работы на мета-уровне в Хиппероне и на не мета-уровне в Идрисе.
- Различия в языках программирования и ограничения зависимых типов (например, отсутствие возможности ввести типы типов).
- Обсуждение возможности реализации гиперона на Идрисе и открытости вопроса.
- Пример использования и проверки типов в OpenGem AI и разработка теоретических основ для реализации этих концепций на языках программирования зависимых типов.

РЕЗУЛЬТАТЫ:
- Оценка потенциала унификации различных подходов к программированию в рамках единой концепции и мета-языковых абстракций.
- Выявление ограничений зависимых типов и соответствующих методов работы с ними.
- Обсуждение глобальной цели проекта по исключению необходимости полного перебора и поиска более эффективных методов обработки и представления знаний.

Практическое применение:
- Разработка инференса контролирующих механизмов для обработки цепочек вывода в LATAM space, что включает pattern mining и определение общих правил для направления вывода.
- Обсуждение и анализ проблем оперирования типами в проекте и поиск решений, включая отказ от использования понятий типа, узла и графа, что позволяет редуцировать гиперграфы к упрощенным графам с неозначенными рёбрами.




S01 [00:00:04]  : Здравствуйте, коллеги. Сегодня у меня такая достаточно специфичная тема анализа индивидуальных зависимых типов в дизайне коммунитивных архитектур, например, Охонкок, Гиперон. Просто Антон как-то какое-то время назад предложил сделать доклад по 

S00 [00:00:24]  : гиперону, это новая версия OpenCOM, которую мы с нуля на предыдущий момент протестируем в нашей команде. 

S01 [00:00:32]  : Хотелось бы про нее рассказать, но поскольку она на достаточно раннем этапе прототипа сейчас находится, как-то систематически обозревать ее пока что проблематично, а вот некоторые интересные аспекты, наверное... Алексей, у вас звук пропадает. Сильно пропадает? 

S03 [00:01:00]  : Вот как-то волыми, то есть, то совсем нету. 

S01 [00:01:03]  : Но, к сожалению, у меня что-то с интернет-соединением сегодня в целом не очень хорошее. 

S02 [00:01:11]  : Такое ощущение, что это микрофон, наверное, в компьютере, и вы головой поворачиваете. 

S01 [00:01:15]  : Нет, я головой не поворачиваю. Ладно, попробуем продолжить, как есть. Мне кажется, что данная тематика может иметь какое-то значение за пределами наших наработок, поэтому интересно было бы ее, в принципе, обсудить. Поскольку не все знакомы с OpenCog, но кто-то может быть знаком, я сделаю очень кратенький обзор некоторых частей OpenCog, которые релевантны данной теме, потому что это и то, что нас мотивировало заниматься гипероном, и, собственно, связано с темой доклада. Итак, самой базовой частью OpenCog является Atomspace, это метаграфовая база знаний. В ней есть узлы, это что-то типа concept note person или predicate likes и так далее. Узлы отличаются по именам, есть связи. там связь может быть между как двумя узлами, скажем inheritance-link, concept-node-band, concept-node-person, и также может идти между узлом и связью, или между связью и связью, например, relation-link, predicate-node-likes, ListLinkConceptNodeBand, ConceptNodeAGI. То есть здесь EvaluationLink связывает PredicateNode и ListLink. И линки, связи отличаются по тому, какие узлы они связывают. То есть они в данном случае не имеют собственных имен, имеют только типы, так же как и узлы. Типы — это некие дополнительные метки, по которым идет индексация атомов. Атомы — это узлы и связи. И в таком совсем нулевом приближении можно просто считать, что Atomspace хранит набор выражений. На самом деле эта штука более хитрая, там идет дедубликация идентичных подструктур, то есть любой concept person будет, вот если условно говоря в коде у нас он встречается в разных местах много раз, то в самом атомспейсе это будет единственный концепт-нод Person, к которому будут просто идти разные связи. Также и сами связи атомы типа Линки они дедуплицируются, если связь объединяет два идентичных атома, то это будет одна и та же связь. Она в атомспейсе будет присутствовать в единственном экземпляре. Это делается через incoming и outgoing сеты. В итоге узлы и связи оказываются одной и той же сущностью, просто у там узлов появляются дополнительные имена, у связей outgoing set не пустые, а у узлов incoming set не пустые. Хотя никто не мешает нам иметь связи на связи, иметь связи между многими атомами сразу, поэтому во внутреннем представлении это именно метаграф, хотя он фактически изоморфин, просто лесу выражений, но это важный технический момент, потому что, скажем, если кто-то работал с графовыми базами данных, такими как dGraph или Neo4j, то вот если попробовать некоторые вещи, которые реализуются в AtomSpace и на них, окажется, что там это делается все менее эффективно, в некоторых случаях более труднопредставимо, и вот это метаграфовое представление является весьма мощным, но в рамках текущего доклада нам вообще говоря это не важно, мы можем просто рассматривать Atomspace как некий контейнер для списка выражений. Хотя повторюсь, что на уровни практического использования. Это, может быть, существенный момент. Следующий важный компонент OpenCog, также очень базовый, это pattern matching. Сопоставление с образцом, можно даже сказать конкретнее, это сопоставление подграфов. Вообще говоря, pattern matching решает проблему изоморфизма под графов, что в принципе является тоже мощным, но вызывает какие-то свои трудности, но не суть. У нас есть некие особые типы связей, которые позволяют нам формировать выражения, там, getlink и bindlink, которые могут включать в себя особый тип узлов переменные. И соответствующее выражение, скажем, getlink, будучи выполненным с помощью pattern matching, оно приводит к извлечению из нашего метаграфа подграфов, которые обладают такой структурой, обладают заданной структурой и находят связывание для свободных переменных в, скажем, get-link. При этом одни и те же переменные могут входить в разные части графа этого образца и они должны найти связывание в одном и том же подграфе. помимо этого, паттерн-матчинг допускает некую логику, специально интерпретируемую, то есть если у нас, скажем, есть end-link, это не означает, что именно этот end-link должен присутствовать в нашем графия в нашей базе знаний. Вместо этого у нас есть два независимых условия, которые должны выполниться одновременно. То есть мы можем найти три подграфа, удовлетворяющих данному образцу, если мы их одновременно найдем. то, соответственно, мы успешно выполним связывание наших переменных, что, в принципе, не сильно отличается от запросов в графовых базах данных с точностью до некоторых важных, но нерассматриваемых в рамках данного доклада технических деталей. bindlink на текущий момент там введен, по-моему, matchlink или querylink, я не помню, который немножко другой семантикой обладает, но я уже привык к bindlink, он выполняет такую операцию, как переписывание графов. Точнее говоря, он не столько переписывает найденный граф, сколько формирует новый граф. Скажем, такой bind link у нас обладает неким списком переменных. Можно обратить внимание, что переменные могут быть типизированы, то есть мы можем явно указывать, что некоторая переменная является узлом или атомом типа predicate node, другая переменная также является predicate node, и если у нас встретился implication link от одной переменной к другой, и если там предикат от первой переменной истинен, то соответственно мы можем добавить в нашу базу знаний запись, что другой притикат от этой же переменной истине. Скажем, например, если мыслить знать существует и Декарт мыслит, то Декарт существует. И простым запуском bind link через pattern matching мы можем получить такое следствие, оно будет добавлено в нашу базу знаний. На этом все не ограничивается, с этого в общем-то все начинается. Дело в том, что помимо того, что PatternMatcher выполняет поиск подграфов с заданной структурой и решает также задачу переписывания или дополнения графов, он также выполняет некоторые типы узлов за хардкоденной семантикой. Скажем, у нас могут быть узлы типа numberNode, которые соответствуют числам, classLink соответствует операции сложения, greaterThanLink соответствует операции больше. И, соответственно, когда мы исполняем этот граф, то мы в ответе получаем в качестве value, я уже не вдаюсь в технические детали, что есть кроме атомов еще и значение в атомспейсе, мы в качестве протоатома получаем значение истина. вплоть до того, что мы можем использовать какие-то лямбда-линки для определения фактических функций, и мы можем дальше Define SchemaNode обертывать в ExecutionOutputLink, подставлять какие-то значения. и вычислять данную функцию под какими-то аргументами, то есть фактически мы получаем язык программирования, можно сказать, что расширяющий паттерн матчер, можно сказать, что внутри паттерн матчера, тут как посмотреть, то есть фактически вот важный момент заключается в том, что вот эти вот get и bind линки, они являются также частью атомспейса, то есть это просто особый тип линков, который имеет особую интерпретацию при исполнении. мы, в принципе, можем как иметь, скажем, greater-than-link внутри bind-link, так и просто исполнять greater-than-link сам по себе. Раньше, вообще говоря, многое было захардкодено в самом паттерн-матчере, поэтому можно было сказать, что интерпретатор атомиза просто был внутри паттерн-матчера. Сейчас, в принципе, там очень многое вынесено в execute метод самих атомов, поэтому можно сказать, что pattern matcher – это часть атомист-интерпретатора, который знает, как исполнять get-линки и bind-линки. Но суть в том, что есть фактически Atomis как своего рода язык программирования, который надстраивается над или расширяет паттерн матча. Он как язык программирования слегка ущербный, но это немного другой вопрос. следующий очень важный компонент OpenCode, который уже отличает его от и графовой базы данных, и от, скажем, функциональных языков программирования, раз уж мы здесь лямбда-линки использовали, это появился чуть позже, то есть, вообще говоря, там исходно была у Бена Герцеля концепция probabilistic logic networks для выполнения рассуждений, которые бы там объединяла и байосовский вывод, когда этот байосовский вывод технически возможен, и упрощенный какой-то вывод, вплоть до, скажем, фазе лоджик, когда у нас нет достаточных знаний или ресурсов для того чтобы делать полный байосовский вывод и common sense reasoning и так далее вот но фактически оказалось что PLN это просто особый конкретный набор правил, а все можно очень сильно обобщить и сделать такую штуку как унифицированные машиновые правил. Суть работы унифицированной машины правил в том, что она объединяет запросы к паттерн-матчингу или к интерпретатору атомиза в цепочки. причем она исходно может отталкиваться, скажем, не от getlink, не от bindlink, как это стоило бы ожидать просто от движка графовой базы данных, а просто от некоторого выражения, которое, в частности, также может иметь свободные переменные, которые мы хотим связать с некоторыми значениями. Как я говорил, BindLinks это абсолютно такие же атомы, как и все остальное. Они могут также находиться в Atomspace, в нашем метаграфовом хранилище, в контейнере. И вместо того, чтобы исполнять BindLink напрямую в целях извлечь графовой базы какую-то информацию, мы этот bind link можем поместить в саму базу. И то, чем занимается Unified Rule Engine, это по заданному запросу он пытается найти последовательность который этому запросу удовлетворит. Таким образом, мы фактически получаем рассуждение. То есть у нас могут в Atomspace храниться какие-то предметно-специфичные правила. Например, если нечто квакает и ест мух, то это нечто лягушка. И если нечто лягушка, то оно зеленое. И, скажем, какие-то правила вида, что предикат квакает от концепт-нода Фриц истина. предикат «Есть лягушек, как откат самцов, но до фриц истина», то запрос к Unified Rule Engine такого вида, то есть кто зеленый, приведет к тому, что Unified Rule Engine найдет цепочку правил подстановок, которые с учетом имеющихся фактов в нашей базе данных, позволят вывести тот факт, что фриц зеленый. То есть вполне себе получаем что-то наподобие пролога, хотя и с многими интересными дополнительными отсветами и отличиями. Здесь я опять же не говорю про то, что К атомам в OpenCog привязываются некие значения, values, которые по некоторым свойствам отличаются от атомов. Они не индексируются, они более легковесные и так далее, подвержены большим изменениям. И мотивация введения этих велиусов, опять же, заключалась исходно в этой пробабилистике коджип-нетворкса, которая манипулировала с значениями истинности, там вообще они исходно четырехкомпонентные были, хотя на практике двухкомпонентные чаще используются, помимо вот этих вот truth values там также были введены attention values, в конце концов это все обобщилось просто до values, которые привязываются к Atom. Я сейчас опять же не говорю про вероятностный логический вывод про значение истинности, которые также имеют большое значение для некоторых надстроек над Unified Rule Engine, в частности вот этих probabilistic logic networks, реализованных конкретный набор правил для Unified Rule Engine, это все тоже важно и об этом просто надо обязательно упомянуть, если вдруг кто-то не знает, что такое в принципе есть, но он в рамках текущего дата это не так существенно. Вообще в опенкоге там много чего другого есть. Экономик, attention networks, которые позволяют распределять ресурс внимания между атомами и openpsi, которые реализуют на очень абстрактном уровне концепцию Йошибаха по устройству мотивационной системы. Другое, что делает, там еще есть интересные вещи, связанные с эволюционным программированием, все это делает OpenCog достаточно такой суммурной системой, но весьма интересной в плане возможностей. Мы сейчас сосредотачиваемся на этих главных компонентах, это PatternMatcher с Atomism и Unified Rule Engine. В рамках Unified Rule Engine мы можем идти дальше и от предметных правил, которые фактически представляют собой императивные законы переписывания графов, мы можем их заменить тоже на декларативное знание, то есть bind-линг заменить на implication-линг, ввести какое-то общее правило типа modus ponens или там что-нибудь в этом роде. тогда уже Unified Rule Engine будет находить под данные общее правило конкретные записи в Atom Space и чейнить их между собой. Это уже будет совсем похоже на Prolog, Reasoning и так далее. как бы мы все-таки там не зря решили разрабатывать новую версию OpenCog с нуля, потому что там много разных причин, кумулятивно для этого было, но Опять же, в рамках данного доклада я бы хотел на нескольких остановиться. Это то, что запросы к PatternMatcher не атомарны, фактически проблема изоморфизма подграфов она полная, а запросы к UnifiedRuleEngine они тоже блокирующие, то есть это можно было бы как бы чисто технически решать там как-то в параллельном потоке запускать unified rule engine и так далее Но в целом это выглядело бы как там очередной костыль. Очень мне хотелось бы решать задачу управления агентами в масштабе реального времени. Рассуждения делать надо тоже меняющимся по ходу рассуждений знаниями, то есть, грубо говоря, когда шахматист сидит и играет в шахматы и как бы усиленно думает над каким-то ходом, если вдруг, я не знаю, ударом молота разбивают шахматную доску, то он не продолжит сидеть и думать до тех пор, пока не найдет идеального хода, он, наверное, что-нибудь другое предпримет. То есть у нас вот этот вот резонинг, он осуществляется все-таки на динамически меняющемся атомспейсе, если уж проецировать это на OpenHoc. И этот процесс не блокирующий. Если шахматист сидит и рассуждает над кодом, Ну, конечно, может быть такая сверхглубокая концентрация, что его вообще никто и ничто не отвлечет, но это скорее исключение. Если к нему кто-нибудь подойдет и попросит озвучить то, над чем он сейчас думает, он это сможет сделать. То есть процесс рассуждений, он не замкнется. это не какой-то такой черный ящик со входом и выходом, это открытый процесс. И одна из мотиваций заключалась в том, чтобы как раз разбить процесс рассуждений на минимальные шаги, которые реально можно было бы считать атомарными. То есть, которые бы выполняли за гарантированное время и объединялись бы в цепочки, которые бы можно было как угодно прерывать, как угодно комбинировать, как угодно менять контекст. Интересно, сейчас Бен нашел некоторые статьи про футуморфизм и так далее. которые процесс интерпретации программ разбивает на такие вещи, это в принципе очень близко соотносится с тем, над чем мы думали, когда вот такой декомпозированный интерпретатор-резонер продумывали в рамках гиперона. Суть в том, что вот эти вот атомарные запросы к хотелось бы действительно сделать за какое-то фиксированное что ли время, чтобы их можно было реально считать атомарными, чтобы мы не думали над тем, что надо вот обязательно что-то параллельно иметь Ну, как я говорил, Atomis как язык функционального программирования обладает достаточно большими изъянами, то есть хотя там есть вот все эти лямбда линки и так далее, там есть какие-то аналоги ифов и рекурсии, хотя тоже какие-то они недоделанные, фактически там не реализовано ничего похожего на замыкания, поэтому семантика атомиза как функционального языка программирования просто не полна. Если бы мы захотели, например, реализовать автоматическое дифференцирование в виде просто набора последовательных правил переписывания выражений, даже это вызвало бы какие-то странные трудности. Есть другие аспекты. В атомизе есть типы атомов и PatternMatcher даже позволяет указывать эти типы атомов для более эффективного сопоставления. По этим типам атомов делается индексация в самом Atomspace, но там достаточно проблематично. Там есть C++ API, который в принципе позволяет добавлять типы атомов в рантайме. но типы атомов там не являются объектами первого класса, то есть если у нас там есть какой-то отдельный тип атома TypeNode, который позволяет просто указывать тип, мы не можем взять и сказать, что этот атом вот такого-то типа не можем в самом атомизе самом атомизе мы не можем ввести новый тип атома. то есть если сравнивать атомиз с хаскелом, то паттерн матчинга в атомизе есть и он имеет отличие от паттерн матчинга в хаскеле, но на самом деле они очень родственны. в хаскеле все построено на обобщенных алгебраических типах данных. И у программиста-пользователя есть возможность просто в коде вводить новый тип данных и надстраивать над существующими типами новые. В Atomizy эти возможности просто отсутствуют. И операции по работе с типами, они крайне ограничены. Там вроде как есть signature-линки, которые позволяют указывать структуру графа. но никакого вывода над типами нет, то есть фактически SignatureLink просто указывает, как в нашем подграфе, какого типа атома в нашем подграфе. Она не позволяет, например, вывести тип аппликации какой-то там defined schema node, то есть заданной функции, к какому-то аргументу. Ничего такого нет. Но это одни из наиболее релевантных к данному докладу ограничения. Были и другие аспекты. То есть, несмотря на положительные моменты. с вот атомизм есть такая некая неудовлетворенность. ну вот например мы там хотим вычислить значение факториала. мы там пишем какую-то, скажем, define-схема ноду, которая будет у нас задаваться через лямбда-линку. Как я сказал, ифа как такового нету, можно там думать про какие-то другие способы, но это неважно. И вроде как это почти бы работало, если бы там были ифы, были коджи и так далее. Это можно выразить через unified rule engine. Это принципе хорошо выражается, то есть мы говорим, что просто fact number 0 к number 1 reducible, там можно или это через предикат вывести, или ввести новый тип атома, неважно, и у нас могут быть там bind-линки, что если у нас n-1, factorial от n-1 то значит мы можем сказать, что и факториал от n будет сводиться к n умножить на x. где x соответственно из premises, из условия этого bind link должен следовать. и в принципе если мы unified rule engine дадим вывести к чему сводится factorial от 5, он выведет. в этом есть определенная сермяжная правда. то есть на самом деле выполнение Вот таких вот функциональных программ это есть не что иное, как детерминированный резонинг. То есть у нас просто получается детерминированная цепочка правил подстановки у нашего Unified Rule Engine. Просто нет других альтернатив, кроме как подставлять один и тот же bind link до тех пор, пока мы не дойдем до такого конкретного факта. Как гиперони в прототипе, который мы начали недавно разрабатывать, мы, соответственно, сразу пытаемся объединить рассуждения с функциональным программированием. Мы рассуждения рассматриваем просто как недетерминированное функциональное программирование. У нас запросы, в отличие от базового OpenCog, они могут содержать переменные как в базе знаний, так и в самом запросе. мы можем, ну это такой условный синтаксис, он просто локально рабочий, это не значит, что он таким останется. У нас, скажем, может даже на самом деле прототип он немножко другой, это больше для визуализации так взял, в прототипе там скобочек чуть побольше. скажем, у нас может быть запись такого вида. factorial от n равняется n на factorial от n минус 1. и в отличие от императивного функционального программирования, оно хоть функционально, но на самом деле все равно императивно, если мы не идем в зависимые типы, про которых мы сейчас будем говорить, то мы бы просто выполнили factorial от 5. Здесь мы на самом деле делаем запрос. Вот у нас есть factorial от 5 и чему он будет равен. Мы сопоставляем два данных графа, мы находим связывание n к 5 и x к результату этого связывания, то есть у нас получается, что x просто должно быть равно 5 на factorial 5 минус 1. Дальше интерпретатор просто говорит, ну, значит, надо найти дальше, чему равно это выражение, и делает следующий запрос к паттерн-матчингу. То есть мы видим, что, ну, это, в общем, наверное, общеизвестно, что функциональная программа – это просто последовательность запросов к паттерн-матчингу получается. Ну, здесь это можно назвать унификацией, потому что это сопоставление с образцом, с переменными с двух сторон, и получается выстроение последовательности таких правил. У нас есть возможность добавлять grounding атомы. Честно говоря, даже не знаю, как это термин в русском языке правильно использовать. вот как мы говорили, в Atomizy есть PLUS-линки, там NUMBER-ноды, GREATER-THAN-линки. вот интересно, что в OpenCoke Atomizy есть понятие grounded schema node и grounded predicate node, которые просто их выполнение как бы делегирует свое выполнение в внешней процедуре. там есть байдинги к питону, к хаскелу, к базовой схеме, собственно к самому C++ тоже есть. то есть grounded schema node может просто говорить вот вам ссылка на функцию реализованную там в каком-то референсном языке, запускайте и вычисляйте. Интересно, что многие типы атомов в атомизе реализованы не как grounded schema nodes, но имеют в точности этот смысл. мы в гипероне решили провести как бы четкую границу мы все вот такие вот загранженные атомы реализуем как не ядро атомиза, а гиперон, а как внешние функции. То есть у нас нет в ядре атомиза, атомиз гиперона greater-than-link какого-то, у нас есть возможность просто связать со значком больше конкретный кусок кода, там на C или на питоне, который будет это вычислять. Соответственно, здесь будет просто связывание этого значка умножить с куском кода, который вычисляет умножение. И мы custom можем вводить в наших модулях какие угодно то есть мы объединили в принципе концепцию вот этих вот захардкоденных типов из атомиза с ground schema нодами в одну сущность и предоставили возможность пользователю свободно эту сущность использовать. Чтобы вычислить там факториал пяти, нам нужно соответственно либо какие-то куски кода на референсных языках которые будут вычислять там плюс-минус умножить либо представить это на более базовом каком-то уровне в стиле арифметики пиано, как это часто делается в языках с зависимыми типами, об этом чуть позже, но это не очень практично, поэтому здесь это представлено просто как вычисление встроенных функций плюс-минус умножить. то есть мы видим, что исполнение функционального кода вполне естественно делается через чейнинг того же самого паттерн матчинга. И в равной степени мы можем вполне сделать и пример с лягушкой. Мы можем сказать, что frog от x равен квакании от x и поедании мух от x, и сказать, что crocs frees true, if flies тоже true, и дальше сделать вот такой вот запросик. например, Haskell этого не позволяет, потому что он не позволяет делать двухсторонний паттерн матчинга с переменными соотношениями с обеих сторон. а вот если мы такую фичу, особенность добавим в наш язык, то нам никто не помешает смешать такой более пролог стиль что ли с функциональным стилем и запрос green от x равняется frog от x даст нам просто за счет простенькой цепочки паттерн-матчинга связывание икса с фрицем. то есть мы сначала попытаемся Извиняюсь, запрос вот такой, это не запрос, это правило. Попытаемся сделать такой запрос, то мы поймем, что чтобы получить здесь true, нам нужно сунифицировать frog.x с true, и это будет тот же самый x, что и здесь. поэтому мы возьмем и попытаемся смачить наш frog at x с нашей базой мы обнаружим что frog at x надо смачить вот с этим потом мы попытаемся ну у нас end опять же может быть или там заграунденной функции которая просто берет там два true и возвращает true или мы можем даже ее записать также в виде таких уравнений что true and true равняется true, например, это не представляет проблемы. вот дальше мы croc от x замачиваем с вот этой записью и найдем возможное связывание x'а с фрицем, это мы замачиваем с этим, найдем возможное связывание x'а с фрицем, поймем, что эти связывания совпадают и скажем, что если у нас x связывается с фрицем, то все выражение может быть сунифицировано со всей нашей базой знаний. Получаются своего рода рассуждения, но это скучные рассуждения, потому что, как я сказал, рассуждения становятся интересными, когда у нас есть недетерминизм. Вот простенький пример того, что можно сделать ну, в частности, на текущем прототипе гиперона с как бы недетерминистскими рассуждениями. Мы просто говорим, что бин может быть равен нулю, бин может быть равен единичке, а дальше у нас есть функция, которая просто порождает список из бинов, ну, заданные длины. Здесь мы решаем проблему суммы подмножеств. Мы говорим, что у нас сумма подмножества двух пустых списков равна нулю. Паттерн матчинг автоматически делает деконструкцию. У нас пока нет никаких типов. у нас есть просто графы, но pattern matching делает автоматическую деконструкцию этих графов на компоненты, с которыми мы можем дальше работать. если у нас на вход поступает один граф с такой структурой, другой граф с такой структурой, то мы говорим, что все у нас выражение это там x умножить на b плюс сабсумма от хвостов. и дальше мы что можем сделать? мы можем построить такой запрос сабсума от некоторого конкретного списка, ген от троечки, то есть это небольшой факт, но тут длина просто списка равна 3, в принципе можно даже было... то есть фактически мы спрашиваем, а какой бинарный список, который отмечает нам индикаторная функция не знаю, который отмечает нам элементы массива или списка, которые мы хотим взять dust в сумме 10. И вот эта вот программка, она работает, то есть она делает pattern matching с этим, она там разбивает этот список на хвост и голову, то есть x у нас троечка, хвост такой-то, и она мачет ген 3 с вот этим вот хвостом. Для этого что происходит? В смысле, сначала она вызывает ген n, она мачет n с троечкой и вызывает фактически недетерминированную нулярную функцию bin. которая может вернуть нолик или единичку, и в итоге она просто в данном случае генерирует все варианты, все возможные бинарные строки листы длины 3 и находит среди них тот, который дает нам в качестве вот этой вот суммы, мы на нолике, на единичке умножаем компонент этого, списка дает в сумме 10 и дает нам ответ. То есть в принципе мы таким сравнительно простым способом получаем своего рода reasoning, то есть именно перебор вариантов. Конечно у нас глобальная цель не ограничиться тупым полным перебором, понятно, что это не масштабируется, и сейчас мы говорим больше про язык как внешний способ представления, а вот внутренности, они самые интересные, что у нас будет в качестве inference engine служить, то есть здесь можно добавлять и вероятности, легко сделать из этого обычное функциональное вероятностное программирование, но можно добавить что-нибудь еще. Вообще говоря, одна из мотиваций всего этого была именно добавление логики в вероятностное программирование, когда мы начинаем с некоторого выражения, которое мы можем логически упростить до того, чтобы начать сэмплировать значения переменных из нашей генеративной модели. мы не дошли, чуть-чуть далековато, и это требует более хитрых мета-языковых абстракций, про которые я сегодня говорить не буду, но вот как концептуально выглядит в принципе симпатично, то есть мы в рамках одного формализма, в рамках одной концепции можем получить и просто функциональное программирование, можем получить и в данном случае недоделанное вероятностное программирование или рассуждение в стиле пролога и так далее. Мне кажется, что такая унификация достаточно мощная, имеет какие-то потенциально мощные следствия. Но тем не менее, чего у нас пока не хватает и о чем сегодняшний доклад – это типы. Мы в рамках концепции надстройки над паттерн-матчингом без проблем можем добавить вывод на типах. Скажем, у нас может быть общее правило, что если там что если у нас f имеет, скажем, такой тип, причем здесь двоеточие и стрелочка это просто символы, они не несут никакой захардкоденной семантики в гипероне. это просто символ, которым мы назначаем какие-то правила переписывания. то есть если у нас f удовлетворяет такому условию и x удовлетворяет такому условию, то значит выражение fx будет удовлетворять такому условию. это тоже работает, мы можем в гипероне вообще никак дополнительно не вводя, не описывая двоеточие и стрелочку, что скажем reverse это string, string равно true и hello это string равно true, тогда reverse hello будет с запросом типа будет давать ground будет давать связывание t в типе string, то есть не составит проблемы сунифицировать это выражение с этой программой, с этой базой знаний таким образом, чтобы мы подставили это выражение и сюда подставили там одно другое, получили в итоге что т должно быть связано с string, чтобы удовлетворить этому выражению. То есть вроде как можно вот поверх этой концепции без дополнительных каких-то элементов реализовать вывод на тип. На самом деле это, к сожалению, не до конца правда. но это уже более тонкий момент, и мы над этим работаем. да мы тут чем нам это может ну кому-то может не понравится тем что мы на самом деле вместо типов фактически вводим двоеточие как предикат то есть у нас есть функция которая берет что-то на вход и возвращает тру на выходе при желании мы можем обращаться к самим bind link напрямую у нас Вот это, вообще говоря, очень важный момент с точки зрения базового OpenCog Atomizer – это то, что вот эти вот запросы к паттерн-матчингу являются частью самого AtomSpace. Если вы на Haskell захотите переиспользовать паттерн-матчинг, у вас просто не будет средств для того, чтобы к нему напрямую обращаться. То есть вы будете загнаны просто в синтаксис этого языка, и, скажем, вам будет сложно ввести какие-то элементы, новые элементы языка, которые будут использовать этот pattern matching как-то по-другому. ну например скажем вести зависимые типы на хаскеле вам придется просто много ходить и паттерн матчинг не получится нативно расширить. в атомизе этот бандинг он есть сразу и все делается через него вы можете напрямую обращаться к паттерн матчингу это мощное мета языковое средство то есть вы фактически работаете не на уровне языка сразу на уровне мета языка и в гиперонии в принципе нам это конечно очень нравится мы тоже это хотим поддерживать хотя в общем мы не очень хотим чтобы программисту-пользователю надо было регулярно пользоваться такими эзотерическими вещами, но при желании, если не хочется, например, чтобы правила над типами оформлялись в форме предикатов, То есть функции с равно, потому что равно это все-таки такой специфический символ, который говорит интерпретатору гиперону о том, что результат надо счейнить дальше. У него есть особый такой смысл. Его переиспользуем здесь, чтобы фактически также выполнять чейнинг вывода, точнее говоря, type checking. то есть мы можем подставить это выражение и применить его к следующей функции. Нам хочется, чтобы интерпретатор автоматически его применил. Для этого и слушать это равно, но мы можем хотеть, чтобы равно, точнее говоря, вот это двоеточие, определение типа, было на одном уровне с функциональным вот этим выражением, и чтобы нам не надо было переиспользовать равно для этого, мы можем напрямую обращаться к возможностям паттерн-матчинга, и это в принципе является достаточно интересной вещью, но здесь возникают свои трудности. Итак, нативно на текущий момент типов в Deeperoni нет. Их можно вводить через возможности Pattern Matching, как просто надстройку, но это может вызывать некоторые трудности. И в этой связи возникает еще один интересный момент. Есть такая штука как зависимые типы. Не знаю много ли людей знакомы с такими системами как Агда, Ибрис, Кок. это системы, которые в основном используются как proof assistants. они настраиваются над обобщенными алгебраическими типами, добавляют туда очень интересную особенность, которая позволяет фактически делать рассуждение. Опять же, атомизм не содержит типы как объекты первого класса, в том смысле, что мы не можем их вводить, но нам не составляет проблем передать тип как аргумент в функцию или сделать что-нибудь в этом роде. В Haskell мы не можем передать тип как значение, вот зависимый тип это как раз об этом. И в этом смысле нам бы не хотелось терять эту гибкость манипулирования с типами, которая вроде как есть в Atomium, но которая недоделана и которая отсутствует в таких что ли, языках широкого назначения функциональных, как Haskell, SML и так далее. Поэтому возникает вопрос, нельзя ли обратиться к вот этому формализму зависимых типов, нельзя ли языки с зависимыми типами использовать для вдохновения, для ответа на вопрос, надо ли ввести зависимые типы в наш гиперон. Я сейчас поговорю немножко про зависимые типы, опять же, потому что не все, наверное, про это слышали, чтобы дальше уже поговорить более конкретно, как они соотносятся с тем, что есть в Atomis и OpenBG. Обычные обобщенные алгебраические типы, которые есть в Haskell, они позволяют нам задавать типы суммы, типы произведения, а также параметрические типы. Мы, скажем, целые числа можем определить как z или как s, применённых к z. увлечет возможность реализации арифметики Piano над этими типами, или тип список можем определить либо как nil, либо как cons, значение некоторого любого типа и списка этого же типа, то есть мы получаем как бы рекурсивный тип. В языках с зависимыми типами мы можем добавлять типы как аргументы функции и как значения возвращаемые функции. Например, в Idris есть тип type, и мы можем, например, написать функцию из singleton, которая будет из bool работать в type. Например, если у нас значение bool true, то мы возвращаем тип not, а если значение false, то мы возвращаем list not. у нас либо единичное значение, которое не обернуто в список, либо список, и у нас может быть функция, которая, скажем, возвращает значения разных типов, что в Haskell можно делать только через тип суммы и обертывать все это в очередной тип. То есть у нас здесь на выходе может быть тип, определяемый вот этим вот предикатом. То есть если у нас на входе true, то это будет значение типа not. Если это false, то это будет значение типа список. И, например, нам не составляет труда написать функцию, которая будет возвращать или нолик, или пустой список. То есть у нас результирующий тип этой функции самой зависит от входного значения, что в принципе может быть весьма удобно. Более того, сами типы могут быть индексированы значениями, то есть они могут быть не параметризованы другими типами, а индексированными значениями. Например, классический тип, индексированный значением таких языках, это Vect. Он индексирован значением над, которое обозначает размер списка. Соответственно, у нас nil имеет тип Vect Z a, где a это, опять же, произвольный тип, он там будет матчиться при объявлении соответственно конструктор конс он формирует из объекта типа а и вектора размера к и типа а вектор размера к плюс один а и например мы можем сделать безопасные извлечения элемента вектора, который я тут не описал, тоже стандартный тип Fin n, который имеет смысл любое число натуральное от нуля до n. вот у нас будет индекс, который на вход получает значение типа fin n, получает значение вектор n, а на выходе возвращает значение типа a, и соответственно абсолютно как обычный индекс для обычного списка, он деконструирует список на голову и хвост, и если элемент списка нулевой, то мы возвращаем голову. Если нам нужен следующий элемент списка, мы рекурсивно вызываем индекс с аргументом минус один и хвостом списка. То есть здесь вместо finN и вектора мог бы быть просто над, n и list. и выглядело бы это практически так же, тут были бы просто чуть-чуть другие конструкторы Z и S, и он бы по единичке вычитал из первого аргумента, и когда бы первый аргумент дошел бы до нуля, вернул бы голову списка в противном случае рекурсивно бы вызвал на единичку меньшего значения от списка. но здесь используются другие типы. И что интересно, если мы попытаемся вызвать такой индекс, скажем, для значения, которое соответствует типу вектор, скажем, 5, не знаю, int, попытаемся его вызвать с аргументом 6, в качестве первого аргумента с значением 6, то он просто не протайпчекается, то есть на этапе компиляции он скажет, что типы не соответствуют, потому что он сможет автоматически проверить, что там fs fs fs fs fs fz является типом fim5, а у нас вектор 5 int, то есть у нас на этапе компиляции произойдет проверка выхода за границу массива, что является классическим примером. силы или прелести зависимых типов в программировании. То есть у нас есть возможность хранить прямо в типе, например, размер массива и на этапе проверки типов определять, детектировать выходы за границы массива. Зависимые типы очень естественны с точки зрения представления знаний, потому что такую штуку как 25-этажный дом мы вполне можем представить как экземпляр типа N-этажный дом, проиндексированный значением количества этажей. Или люди, рожденные до 2000 года. Это конкретно тип, это множество объектов, которые мы можем каким-то образом описать. И очевидно, что мы можем это представить как экземпляр того типа, проиндексированного годом. Каким-то и описать в терминах зависимых типов. То есть люди мыслят таким образом. когда описываем какой-то тип объектов, мы часто эти типы объектов индексируем значениями. Это существенно выходит просто за обобщенные алгебрические типы данных, и это как раз в точности соответствует зависимым типам. И можно даже утверждать, что рассуждения это вывод над зависимыми типами, хотя, может быть, это что-то более широкое, но сторонники данного подхода будут говорить, что, может быть, этого и достаточно. То есть мы часто определяем типы, индексированные значениями, и вот это в точности про зависимые типы. Что дальше интересно? Почему это приводит к системам помощи в доказательстве теорем? Потому что определение типа можно трактовать как декларативное утверждение. А экземпляр этого типа фактически является доказательством его непустоты. что является доказательством истинности этого утверждения. Ну вот, опять же, классический пример, скажем, мы можем определить тип равенства, который берет два значения, и у этого типа будет единственный конструктор, который позволяет сказать, что одно равно другому. вытряси или в каком-нибудь другом языке с зависимыми типами. но да, к сожалению, надо было уже тут примерчики какие-то привести. мы описываем тип переменной. вот у нас, скажем, переменная есть tu plus tu. мы описываем тип этой переменной как 2 плюс 2 равно 4. это тип, потому что здесь равно-равно, чем-то там проиндексировано двумя значениями. в качестве доказательства этого утверждения мы просто предоставляем конструктор этого типа. почему это работает? потому что это выражение нормализуется уже на этапе канцеляции, то есть мы берем его пытаемся вычислить, оно нормализуется к четверочке, получается что четверочка равно четверочке, это работает. Но этим все не ограничивается, опять же, с этого все начинается. Мы можем, например, в качестве типа использовать функциональный тип. Скажем, у нас есть функция, которая на вход получает целое число, возвращаемое значение у нее обладает вот таким вот хитрым типом почему бы и нет то есть в качестве выходного значения у нее выступает результат индексации этого типа равно-равно по вот этому значению и по этому значению и фактически вот эту вот штуку надо читать как что для любого натурального n, 0 плюс n равно n и собственно это опять же элементарно доказывается просто потому что у нас плюс Zn редуцируется в N за счет определения функции плюс. Это просто. Сложнее, если мы попытаемся записать вот такое выражение. то есть для любого n, n равняется плюс nz. Почему это сложнее? Потому что для первого случая у нас есть вот такая вот запись, а для этого случая такой записи нет. То есть если мы просто функционально попытаемся применить к некоторому n плюсик, то он будет выполнять вот эту строчку. Он, скажем, пятерочку S, S, S, S, Z будет деконструировать, превращать в S плюс остаток. и так далее, и так сделает пять раз, пока не придет к тому, что вместо K останется Z, вместо Y у нас тоже Z, он получит Z и в итоге сконструирует опять же SSSS Z. то есть у нас, понятное дело, при попытке вычислить 5 плюс 0 вместо 0 плюс 5 произойдет рекурсивный разбор выражения пятерочка в стиле арифметики пиано на составляющие. что любопытно, то что нам выполнять эту рекурсию не нужно, Чтобы доказать это выражение, нам достаточно просто-напросто предоставить функцию, полную, которая обладает нужным типом. Соответственно, мы просто пишем, что class.reduce z от z равняется ref. Это работает, потому что у нас в индексированном n-типе вместо n подставляется z, получается z равняется plus plus z. Это нормализуется, опять же, в z равно z, рефл type-чекается. То есть рефл type-чекается вот с этим типом, когда n равно z. А дальше, когда n не равно z, мы просто говорим, что class.reduce от st, а у нас конструкторов типа nat других и нет. равняется некоторой хитрой функции, которая, ну вот в идрисе 1 тут фигурные скобочки, означающие имплицитный аргумент в идрисе 2, они вообще говоря круглые, то есть функция предоставляется в явном виде, она говорит, что для любого a равного b выполняется, что f от a также равняется f от b. В принципе очевидное для математики подтверждение, которое также можно доказать, просто предоставив соответствующую функцию. Мы говорим, что чтобы сконструировать кейс для classReduceSetSK, мы должны воспользоваться этой функцией и применить ее к classReduceSK. В каком-то смысле это матиндукция, но хитрость в том, что тут никакой рекурсии не происходит. Мы просто предоставляем экземпляр данного типа как общую функцию, тайпчекающуюся с этим типом. то есть у нас два случая для NNATO, это Z и SK, значит у нас других случаев нет. Для Z мы говорим, что это просто рефру, а для SK мы говорим, что это вот такая штука. Что она там дальше вычисляет, даже неважно, мы можем быть уверены, что она будет вычислять то, что нужно. Тут есть интересные моменты с тем, как это на самом деле работает, то есть это тоже работает через унификацию, паттерн-матчинг с определениями типов. Я не уверен, успеем об этом чуть-чуть подробнее поговорить или нет. Это вот в полном виде как раз проявление изомархизма Карри Хорварда. То, что у нас типы являются ничем иным, как теоремы, а экземпляры этих типов являются ничем иным, как доказательством этих теорий. И если у нас типы не функциональные, это выглядит немножко скучно, а вот когда типы функциональные, начинается самая веселуха, потому что фактически программный код является доказательством некоторого нетривиального утверждения. Дальше следует вопрос. У нас есть типы как теоремы. Мы над ними не то чтобы рассуждаем, потому что мы в принципе ручками пишем доказательства в виде кода, но можно представить, что Наше рассуждение есть не что иное, как рассуждение над типами. Возникает вопрос, а что, все нужно выражать через типы? Все ли декларативные знания, над которыми мы думаем, надо выражать через типы? То есть у нас очень хорошо декларативные знания выражаются через типы. И что, рассуждения мы тоже должны делать как вывод над этими зависимыми типами? Это интересный вопрос, потому что здесь у нас возникает вот такая вот дилемма. Мы на примере нашего прототипчика гиперона видели, что рассуждение можно представить как выполнение недетерминированных программ со свободными переменными. А сейчас мы видим, что рассуждение это конструирование экземпляров типов, то есть фактически конструирование кода соответствующего данному типу. если мы сконструировали такой код, мы доказали наше утверждение, что есть как бы суть декларативного ризма. то есть возникает как будто бы не то чтобы противоречие, но вот такая дуальность. как это дальше совместить? И сейчас мы чуть-чуть поговорим о том, как совместить эти парадигмы. Давайте попробуем на примере гиперорона. решить вот эту задачку с class.reduce, то есть без всяких типов, что бы мы могли сделать. Мы бы могли просто сказать, что если у нас есть подграф, где справа и слева стоит одинаковый x, то это true. будет это работать? 2 плюс 2 равно 4 в гипероне. да, будет из коробки, потому что 2 плюс 2 также зарядится в 4. точнее говоря, мы сначала вот эту вот штуку ну вообще сначала или потом это тоже вопрос в порядке вычислений, не суть. мы смачим x с 4 и x 2 плюс 2, мы попытаемся дальше редуцировать 2 плюс 2, редуцируем его в 4, убедимся что один и тот же x может стоять справа и слева, значит результат интерпретации всего этого выражения будет true. Дальше, допустим, мы введем PLUS ZY равно Y, PLUS SK от Y равно S PLUS SK от Y. Опять же, нам никакие типы пока не нужны. Мы просто это вводим как символные выражения, описывающие какие-то соотношения между цепочками символов, не более того. То есть у нас есть графы, мы их там переписываем, матчем и все дела. Дальше мы просто в гипероне берем такой запрос. n равняется zn. Что он сделает? Он сматчит. n с x, для исполнения этого запроса интерпретатор добавит тут равно x, x он смачит с true, но это уже детали, этот другой x он смачит с n, plus zn он смачит с x, и дальше он поставит вопрос, а можно ли редуцировать или унифицировать plus zn, так чтобы он превратился тоже в N. Он этот плац ZN пойдет сюда, плац матчится с плацом, Z матчится с Z, N матчится с Y, в итоге получается N. То есть вместо Y мы N подставляем. Получаем, что N равно N, невзирая ни на какие типы там и так далее. Но вот если мы попытаемся вот это выражение паттерн-матч, сунифицировать, выполнить, то тут опять же возникнут примерно те же самые хитрости, как и в Idris, когда мы пытаемся написать кодик, удовлетворяющий данным типам. вот что мы сделаем мы опять же n с матчем с иксом пластин з с матчем с иксом попытаемся средуцировать пластин за дамы пойдем сюда либо n смачивается с этом и з мачется с игреком и тогда получится з и з у нас и слева и справа стоит и мы получим, что класс zz равняется true при n равном z, то есть мы найдем связывание для переменной n в z, для которой эта величина будет матчаться с true. но есть и другая возможность, то есть мы рассматриваем это как минимум терминированное вычисление, мы класс nz можем смачить вот с этой штукой, значит n у нас смачится с sk, z смачится с y, и значит получится вот такая вот величина, то есть мы сделаем трансформацию нашего графа, получив вот такой вот результат. И получается, что все будет хорошо, если k дальше смачивается с z. То есть если мы дальше вот эту внутреннюю скобочку смачиваем с этой вещью, то у нас получится, что все выражение, вот это все выражение равно true, при n равном SZ мы доказали, что при n равном SZ мы тоже можем получить true и так далее до бесконечности, то есть если мы попытаемся из коробки применить гиперон вот к такой задачке, он нам просто выдаст true, true, true, true, true, true, true при связывание hen равно z, n равно sz, n равно ssz и так далее, что в принципе выглядит достаточно логично, но не совсем то, как мы хотели. А почему мы не можем получить то, что получается в Idris? То есть мы в Idris без выполнения какой-либо рекурсии просто на type-чекинге доказали утверждение в общем виде. ну потому что мы не говорили вообще говоря что n это not, то есть у нас n может быть чем угодно мы можем n смачить там с концептнодом person если у нас такое будет или там с ben или в общем с чем угодно поэтому в общем виде это утверждение и нельзя доказать если мы не вводим никаких ограничений и тут мы понимаем что типа вообще говоря хорошая штука мы можем пытаться это вот как мы раньше описывали в явном виде проэмулировать, введя просто в своем собственном атомисте первом коде символ двоеточия, может быть это даже сработает, если постараться, либо же просто ввести типы как захардкуленные и сказать, что вообще говоря у нас все переменные обладают какими-то типами, мы можем их матч смотреть только в рамках этого типа, и тогда у нас N как тип NAT будет обладать только двумя конструкторами Z и SK, и тогда у нас просто будет ограниченная возможность из чего выбирать, тогда мы можем рассуждать над типами в целом, то есть мы можем рассуждать не над экземплярами типов, как здесь происходит в линейке терминированных вычислений, мы сможем рассуждать над типами самими, если мы рассуждаем над самими, то не обязательно выполнять эту рекурсивную функцию с получением каких-то результатов. То есть тип — это общее утверждение, и если мы хотим доказывать что-то в общем виде, вообще говоря, неплохо бы и не пользоваться. Давайте посмотрим, как одно, в принципе, мэпится в другое. Вот мы в гипероне, И в OpenCode приводили пример с фрицем, который квакает, ест лягушек, ест мух, вообще он лягушка и зеленая. Как это представить в типах? Ну это элементарно. Мы можем ввести тип критча, у которого два конструктора, мы можем ввести тип квакет, который из критча делает тайп, у него будет конструктор critProp. то есть он будет конструировать единственное значение, фактически конструктор типа получается фактом. Мы можем интерпретировать конструктор типа как известный факт. Это неудобно с точки зрения когнитивных архитектур представления знаний, чисто синтаксически, потому что мы все должны писать в одном месте, но концептуально это вполне подходит, то есть конструкторы типов — это конкретные факты, а типы — это сущности и общие коллекции, и утверждение о них. Например, мы можем сказать, что если нечто зеленое и есть мух, то это лягушка в виде конструктора типа лягушка, то есть у нас есть типа лягушек, тип лягушка, который в проиндексированном типе крича, и у нас есть конструктор этого типа, который фактически говорит, что если мы о чем-то можем сказать, что оно квакает, ест мух, то это лягушка. Как это будет выглядеть? Мы говорим, что фриц зеленый, и в качестве доказательства просто предъявляем цепочку конструкторов. У нас есть известный факт, что фриц У нас есть известный факт, что в Fritz есть мух, мы используем эти конструкторы. У нас есть FrogRule, который говорит, что если A квакает и A лягушек, то и мух, то и лягушка. И есть тип Green. Опять же, у нас могут быть базовые факты о том, что нечто зеленое, и тогда тут будет дополнительный конструктор, который будет утверждать, что нечто зеленое. Но у нас есть общее правило, которое говорит, что если A лягушка, то A зеленая. И мы фактически в качестве доказательства того, что Fritz зеленый, Предоставляем цепочку конструкторов. Рассуждения. Мы рассматривали в гипероне проблему суммы под множеством, которая там работала из коробки. Как это представить на языке зависимых типов? у нас будет тип, индексированный числом, например, интом, матом, не важно, и список, скажем, интов. И дальше интересно, мы должны, поскольку мы в рамках такого типа можем описать некоторую переменную как тип, индексированный конкретным значением и списком, мы дальше должны построить цепочку конструкторов, которые бы говорили, что мы свою задачу решили. И здесь нам приходится говорить, что мы задачу решили, если у нас на вход поступает нолик и нил, потому что сумма пустого списка равна нулю, или то, что мы пропускаем некоторое значение, то есть у нас будет конструктор, который на вход получает недоделанный список IS и формирует более полный список IS, фактически он X пропускает. Или он берет X и тогда он говорит, что мы из частичного решения получаем полное решение, то есть если у нас s-x и xs это решение, то и sx объединенный с xs это тоже решение, потому что мы x взяли Как это работает? Это также работает через паттерн-матчинг, на самом деле. То есть у нас есть определение типа, у нас есть цепочка конструкторов, а дальше мы берем и начинаем паттерн-матчинг при проверке типа. То есть вот у нас сначала снаружи идет скип. поэтому мы берем и матчим вот это вот выходное выражение, которое мы должны на выходе получить с типом, да, у нас троечка матчится с s, пятерочка матчится с x и хвост матчится с xs. и в итоге мы деконструируем это выражение и говорим, что нам нужно вот остаток смачь со всем остальным, то есть мы получаем что x3, x5, xs, 1, 2 nil и дальше надо вот это последующее выражение смачить с остатком, то есть stake take done, то есть мы берем вот этот subset solution 3.1.1.2 и мачем его stake take done дальше рекурсивно. Take у нас вот такой имеет вид, мы уже s смачим с 3, x смачим с 1, xs смачим с 2 nil, и они сматчатся, в итоге у нас получится уже выражение s-x, то есть двоечка, два двоеточия, дветочия nil, которые мы должны сматчить уже дальше с takeDone. То есть это тоже работает через pattern matching, только в другую сторону. в итоге что мы видим мы видим что на самом деле конструкторы это просто-напросто метки для паттерн матчинга вот в таком примере да а типа это группы меток которые ограничивают сопоставление мы там не сильно удаляясь от текущего прототипа гиперона, это не реализовано сейчас на концептуальном уровне. Мы можем просто сказать, что вот у нас есть функциональный код. который мы уже видели, который мы трактуем как недетерминированный функциональный код. Мы просто назначаем вот этим кейсом паттерн матчинга метки И тогда, когда мы говорим, что subset solver 3.5.5 это 5.2.1.1 вместо того, чтобы вот этот ген использовать, который перебирает нолики и единички, умножает одно на другое и складывает, мы просто говорим, а давайте возьмем вот этот фактически след выполнения программы нашей и получается, что мы сначала рекурсивно выполняем tick, потом take, потом take, потом done. Конструкторы типов это просто-напросто метки в недетерминированных функциональных программах. Мы находим мостик, связывающий вот эти два представления о reasoning, о рассуждениях как о недетерминированных вычислениях и как выводить типов. Очень хорошо все связывается. Тип оказывается множеством метод паттерн матчинга, который нам ограничивает то, что с чем мы матчим. Мы это тоже уже начинали видеть. когда рассматривали этот пример, если бы у нас N был исходно на том, а это что? это просто множество методов паттерн-матчинга. у нас N тогда можно было бы сматчить с Z и N можно было бы сматчить с SK, с двумя конструкторами, и мы бы тогда уже могли получить общую функцию, то есть мы бы все кейсы могли бы проработать и доказать это. то есть у нас тип — это множество метод, ограничивающих pattern-matching-подставление, а конструкторы типов — это метки этих сейсов для pattern-matching. Конечно, всё этим, к сожалению, не ограничивается, всё не так просто, потому что есть некоторые хитрости и тонкости, когда мы переходим к рассмотрению функциональных типов. То есть вот в этих случаях мы с вами видели решение конкретных задач как просто цепочки конструкторов. Вот мы смотрим на это proof — это цепочка конструкторов типов, все прекрасно. Здесь proof — тоже цепочка конструкторов типов, несмотря на то, что это NP-полная задача, а это как бы рассуждение над знаниями. Но когда мы смотрим сюда, то тип у нас есть, у нас есть экземпляр типа, а где здесь цепочка конструкторов, она скрыта внутри самого Идриса, внутри самого языка, потому что у нас есть функциональная аппликация, для которой нет имени конструктора, она тут не явно присутствует. у нас есть собственно сама стрелочка, которую мы не определили как конструктор типа, а вообще говоря, надо бы, если там выходить на мета языковой уровень, у нас что хуже того есть pattern matching, то есть фактически вот эти вот два выражения мы бы должны были представить как графы, как вот иерархическое такое, дерево конструкции, а в Идрисе этого не видно, то есть тут вот эти вот конструкторы функциональных типов, которые пишут в самом языке, соответственно Здесь нам придется в явном виде выделять, скажем, конструктор apply и какой-то bind. То есть у нас конструкторы функциональных типов — это на самом деле метки уже метаязыковых проектов. и тут есть лямбда-абстракция, стрелочки, есть аппликация, и что самое хитрое, есть само сопоставление с образцом. Получается, что мы сопоставление с образцом должны выразить средствами сопоставления с образцом. Но, к счастью, в атомизе у нас вот эти вот средства паттерн-матчинга, они как бы присутствуют в самом языке, то есть мы фактически хотим это программировать не на самом языке, а когда на нет языке. Типы как ограничения. Так, у меня как-то сильно затянулось по времени, давайте чуть-чуть, чтобы устроиться. Типы как ограничения. Мы говорили, что здесь n может быть ограничен конструкторами, характерными для НАТО, вполне это выглядит хорошо. Давайте вот другой такой пример рассмотрим. Он может быть чуть-чуть некорректный в некоторых местах, но он очень показательный. Мы пишем такую программку. Опять же, в рамках гиперона на текущий момент у нас преимущественно есть какие-то символы, кастомные, не за-хардкоденные, и мы из них составляем графы и матчим эти графы. вот у нас есть, скажем, правило, что чтобы сделать x, если y делает x, мы стартуем y. и вот просто в таком прямолинейном виде пишем, что to dry равняется make air wet, to wet равняется make air dry. дальше humidifier makes air wet true и ventilation makes air dry true. и дальше мы делаем просто такой запрос to dry. то есть у нас мы должны при запуске этого запроса интерпретатор поставит to dry равняется какому-то x и попытается понять какому. что получится что он скажет ну надо сделать make airwet да это нормально это просто дальше он такой ну надо сделать make airwet он будет make airvet равняется такому-то опять он смачит make с make, x с airvet это в порядке вещает нормально и дальше вот результат он смачит вот с этим выражением где в качестве x подставит airvet получится такое выражение, что в принципе логично. То есть если y makes airwet, тогда стартуем y. Вроде как хорошо матчится humidifier сюда, makes airwet сюда, это выражение возвращает true, значит мы должны стартануть Humidifier. То есть это чисто так в стиле символьных манипуляций. Выглядит хорошо и прекрасно, что мы в такой свободной форме можем этим пользоваться. Но тут возникает одна хитрая вещь. Мы Y можем смачить с Humidifier, MakeSRW с MakeSRW. Прекрасно, но мы на самом деле Y можем смачить с Make, а x можем смачить с makesAirWet и получим просто бесконечную рекурсию. У нас здесь будет внутреннестица повторять makesAirWet и так далее. То есть это сразу не видно, но унификация на уровне графов это такая общая штука, что если у нас тут есть переменная, она может быть сопоставлена с этим графом, а эта переменная может быть сопоставлена с этим графом, то почему бы и нет. конечно, этот пример решается разными способами. просто если мы уберем эти скобочки, то он уже не сможет граф с двумя элементами сопоставить с графом с двумя элементами. это решается, но на самом деле здесь мы видим, что надо бы вводить все-таки типы, и типы как ограничения должны работать очень хорошо. Если мы просто скажем, что у нас humidifier и ventilation это не знаю как их обозвать, мейкеры какие-нибудь, и в нашем запросе здесь также укажем тип для x, или может быть даже этого уже и не надо будет делать, ну или вот здесь вот для y используем, y это тоже мейкер, то мы автоматически сузим нашу зону паттерн матчинга до этих двух величин. и все будет работать без всяких внезапных сопоставлений и бесконечных рекурсов. Наш мозг просто автоматически отсеивает такие вещи, мы их не замечаем, потому что для нас это очень естественно, мы понимаем на нашем смысловом уровне, что y здесь должен быть чем-то таким и он должен матчить make здесь, а make и y не должны матчиться, потому что у них просто разные типы. здесь никаких типов нету, здесь просто есть произвольные символы, переменные графы, и они матчатся как хотят. соответственно Типы как ограничения для паттерн-матчинга представляются весьма мощной штукой, если их нативно встраивать в язык, то это может быть просто более изящно, чем если их реализовывать поверх какого-то базового синтеза. Да, я, наверное, уже скажу за время, может даже не чуть-чуть, но вот хотелось бы еще немножко рассказать про градуальные типы. мы уже говорили, что вот такая штука, она, конечно, выглядит неплохо с точки зрения того, что мы используем типы и конструкторы типов, они становятся зависимыми от значений для представления знаний, это выглядит достаточно естественно, но здесь есть ряд неудобств, когда мы это рассматриваем с точки зрения системы помощи доказательству TRM. У нас все функции должны быть общие, у нас нельзя вводить знания по ходу дела, То есть мы работаем в рамках фактических предположений о замкнутости мира. Мы не всегда можем знать эти типы, чем в OpenCode, мы можем просто запихнуть в какой-нибудь список все и все, не очень захотясь о том, как описать, к какому типу все это относится. Также в OpenCode мы можем просто составить произвольный граф из маркированных узлов или метаграфов. И это очень удобно, типа мы там сильно ограничиваем. А в рамках AGI, систем на основе знаний, это особенно существенно, когда мы начинаем делать какие-нибудь мета-рассуждения, рассуждения над рассуждением, когда мы сами программы конструируем. Иногда типа это хорошо, потому что они позволяют отсеивать тоже неправильные, семантически неправильные программы, были интересные. работы, например, про генетическое программирование, где сами программы в зависимых типах указывались и это позволяло мутации делать корректно и все там совсем соотносилось. но если мы, скажем, возьмем просто какой-нибудь диалог с пользователем и пользователь может сказать все что угодно. это что угодно должно вроде как в разные типы может преобразовываться и делать это в рамках функционального программирования, либо вообще это в монады завертывать, а разные монады между собой не композируют. в общем, кто пытался хотя бы вероятностное программирование на Haskell реализовать, знает, что это боль. и часто, ну либо нам просто приходится вводить тип, который все и вся объединяет, либо там пользоваться просто нечистыми средствами. Градуальные типы, они позволяют объединить лучшие из двух миров, то есть они позволяют в предельном случае сделать все динамически типизируемым, и проверки типов выполняются в рантайме, или сделать все строго типизируемым, и проверки выполняются статически на этапе компиляции. Просто путем введения типа вопросик и некоторыми правилами вывода над типами, когда у нас этот вопросик есть. Градуальные зависимые типы позволяют это сделать очень гибко, потому что мы этот вопросик можем поместить куда угодно. Мы можем поместить его в качестве индекса, например, у нас может быть Vect, мы можем в качестве a поставить вопросик, тогда у нас будет вектор, скажем, длины 5 из элементов неизвестного типа, мы можем вместо n поставить вопросик, тогда у нас будет вектор неизвестной длины, скажем, из умцов. и так далее. Пример, скажем, у нас есть какие-то люди, у них есть дни рождения, и у нас есть тип Олды, который позволяет нам с использованием двух конструкторов утверждать, что один человек старше другого. Соответственно, если у одного человека год рождения раньше, чем у другого, то он старше, если у них года рождения одинаковые, тут y1, то он старше, если у него там месяца рождения больше. И в Идрисе это работает, скажем, вот эти вот вещи протайпчекаются, скажем, по году тайпчекинг не происходит, потому что этот конструктор не сматчится с вот этими вот burst1, burst2 типами. ByMonth пройдет. И вот когда мы берем и добавляем градуальные типы, то мы можем сказать, что, ну вообще говоря, нам не обязательно знать месяц рождения. Если у них годы разные, то у нас мы можем сконструировать типы Older и type-checking пройдет на этапе компиляции. Если годы одинаковые, то byYear type-checking не пройдет, а byMonth пройдет проверку на этапе компиляции, но может не пройти на этапе выполнения, потому что здесь мы уже будем задавать какие-то конкретные значения при инициализации. то есть градуальные зависимые типы в этом смысле оказываются очень и очень гибкими. К сожалению, пока эта концепция встречается только в рамках очень упрощенных языков, таких proof-of-concept, но они показывают интересные результаты, в них отделяется нормализация на этапе проверки типов, от вычислений на этапе выполнения. И нормализация осуществляется приближенно с гарантированной разрешимостью. Ее нельзя осуществлять неприближенно, потому что это поставит проблему эквивалентности, которая просто будет неразрешимой. можно делать приближенную нормализацию, которая будет нам отсеивать вот такие варианты, то есть как бы если у нас какие-то вещи неизвестны, в смысле какие-то вещи не совпадают, то проверка проходит и все, не проходит и все хорошо, и наоборот проходит и все хорошо. при этом на этапе выполнения вычисления уже точны, то есть когда конкретные значения, то уже вот этой вот приближенности нет, но при этом эти вычисления могут уже расходиться и могут возникать ошибки динамических типов, то есть в этом примере этого нет. В примере там есть вектор int, например, и вектор string. Если мы там поставим вопросники вместо int и string, а на этапе выполнения попытаемся компетенировать два вектора разных типов, то уже на этапе выполнения станет понятно, что type checking не проходит. то есть возникнет ошибка динамических типов. Вот что интересно, вот эта приближенная ассоциация градуальных зависимых типов, она соответствует паре непротиворечивой логике, что, в принципе, также интересно в контексте баз данных распределенных. В общем, это уже совсем отдельная тема для обсуждения. соответственно, ну, некоторые выводы, что ли, то есть типы для представления знаний, в частности, градуальные зависимые типы. Само программирование в типах вообще не вполне удобно для... мощностью и, в общем, как мы видели, базовая теория, она не дает ризминга как такового, она дает возможность проверки теорем, конечно, проверки доказательств, конечно, в КОКе, в АГДЕ, а там есть дополнительные средства, которые Идрис немного на другом просто сфокусировал, но в целом мы можем сказать, что базовая теория зависимых типов, она не отвечает на вопрос, как осуществлять вывод типов. Вообще говоря, он просто не разрешим в общем мире. Но вот как модель вставления, чтобы навести порядок в системах представления знаний, Штука, в принципе, неплохая. То есть она дает формальную модель, в терминах которой можно рассуждать, как мы представляем знания. То есть у нас уже не будет какой-то такой каши, которая характерна для системы представления знаний, выросших из практических вещей. У нас будет четкая математическая модель стоящая за этим. Градуальные типы позволяют приближенно проверять непротиворечимость при неполных знаниях, что вообще прекрасно. Вот чем там, например, тот же OpenCoke Atomiz не очень хорош, то то, что там вроде как есть какие-то типы, но абсолютно нет typecheck. То есть мы там пишем в Atomiz, условно говоря, какую-то программку, ну она грузит в граф что-то, а будет там выполняться это или не будет, там мы можем эволюцион линку вместо предикат нода дать что-то другое, это правильно, это неправильно, то есть это как бы абсолютно не определено там с такой семантикой проблем. Вот на части это условлено спецификой проблем рассуждений, в частности в условиях необходимости, но в целом градуальные зависимые типа от этого вполне могли бы, наверное, спасти, чтобы на этапе подгрузки в базу мы могли проверять пары, непротиворечивость на нашей системе. типы расширяют возможность рассуждений, то есть да, у нас рассуждения могут рассматриваться как недетерминированные вычисления, но типы добавляют к этому четкое понимание того, как рассуждать в общем виде, то есть не над конкретными значениями, а над над коллекциями этих, множествами этих значений. В этом смысле мы активно сейчас смотрим на возможность использования градуальных зависимых типов для внедрения в наш прототип. Собственно, это исходно планировалось, просто все одновременно, конечно, учесть и внедрить сложно. Спасибо за внимание. 

S03 [01:51:04]  : Алексей, спасибо большое. У нас, конечно, не так много времени осталось на вопросы, но давайте попробуем начать. Так, я, наверное, свои вопросы тогда пропущу, оставлю их на конец. Значит, от Дениса Буздалова. В образце могут быть свободные переменные, как в обычных языках программирования с паттерн-матчингом? 

S01 [01:51:37]  : Ну, собственно, я об этом упоминал. OpenCode в базовом паттерн-матчинге там переменные присутствуют в запросе. Там в принципе существовал такой недоработанный dual link, который наоборот брал запрос без переменных и матчил его против под графов базы знаний, которые могли содержать свободные переменные, но, во-первых, этим мало кто пользовался, он был недоработанный из-за этого, но в целом он как раз соответствовал чему-то типа паттерн-матчинга в функциональных языках программирования. А в прототипе гиперона, как я говорил, у нас с обеих сторон могут быть переменные. Это очень важно с точки зрения унификации разных процессов вычислений и рассуждений друг с другом. 

S03 [01:52:47]  : Спасибо. Дмитрий Свериденко вопрос. Допускаются ли циклы в графах и как с ними работает паттерн-матчинг? Алексей? 

S01 [01:53:06]  : Да, я пытаюсь. Смотрите, в атомспейсе получается так, что циклов, наверное, не может быть в принципе. потому что там просто другая модель представления. там у вас некоторые... сейчас... у вас У вас ссылка, связь, он дедуплицируется по тому, какие элементы он объединяет. И вы как бы физически не можете написать такое выражение, которое будет включать ссылку, скажем, на саму себя или на другую ссылку, то есть у вас есть там два узла, вы можете там написать связь линку, ноду, который будет в своем outgoing сети содержать эти два узла, вы можете написать другой link Atom, который в своем outgoing сети будет содержать эту линку. В принципе, таким хаком Если залезть внутрь через имеющиеся API, можно, наверное, поместить ссылку на Atom внутрь его же собственного outgoing set. И, честно говоря, я не уверен, как pattern matching будет в этом случае работать. Я думаю, что это не очень предусмотрено. Поэтому тут, конечно, стоит понимать, что эти метаграфы в Atomspace с одной стороны в чем-то более общие, чем обычные графы. Они допускают связи между многими атомами сразу. но они при этом в принципе не предусматривают и через внешние API не допускают самой возможности формировать циклические какие-то структуры, поэтому по большому счету правильнее было бы все-таки интерпретировать что хранится в атомспейсе как не некое представление изоморфное лесу, то есть набору деревьев, просто у этих деревьев часть подеревьев не дублицированы, поэтому они как бы срастаются. А такие произвольные графы там как раз не представляют, то есть мы в принципе не можем написать там граф, где у нас будет три вершины А и там они будут как-то циклически связаны. Но в этом как бы отдельной надобности не было, то есть косвенно это наверное можно эмулировать, но вот нужно брать конкретный пример с конкретной задачей и уже думать над тем, как это представить в опенкоге и что с этим делать. 

S03 [01:57:11]  : Но при этом я правильно понимаю, извиняюсь за уточняющий вопрос, что деревья – это деревьями, но у нас один лист в принципе может принадлежать нескольким деревьям. 

S01 [01:57:21]  : Да-да-да, я и говорю, что они срастаются за счет дедубликации. Но вот если говорить про гиперон, то у нас в принципе там концепция абстрагирования от конкретной имплементации. То есть вот эта вот метаграфовая имплементация с дедупликацией, она очень интересная и эффективная в ряде случаев, но как бы на уровне методов обработки она там ничем не отличается от работы просто со списком выражений. Отличается только большей эффективностью выполнения запросов, большей эффективностью хранения информации. Вообще у нас там исходно было такое квазиформальное представление о потомспейсе как о функтере, то есть это контейнер в теоретическом категорическом смысле, который может иметь натуральные естественные изоморфизмы к другим там функтором то есть мы можем скажем список деревьев свободно там трансформировать в метаграф и обратно вот и мне кажется что с циклическими графами тут просто нет изоморфизма но над этим просто надо отдельно как бы у нас просто не было таких задач, где сами знания следовало бы представлять циклически. 

S03 [01:59:07]  : Спасибо. Вопрос от Дмитрия Свериденко. Как и чем оптимизируется перебор при построении и реализации цепочек переписывания? В прологе это сечение, а что у вас? 

S01 [01:59:20]  : В гиперонии сейчас ничего, потому что мы только начали над ним работать. как бы это как раз интересные вопросы, к которым мы приближаемся. В OpenCog там есть Нил, он автор Unified Rule Engine. и последние годы он активно работает над inference control механизмами, то есть там сами цепочки вывода представляются в виде подграфов в LATAM space, над ними выполняется pattern mining и находятся какие-то общие правила того, как направлять этот вывод. Я в деталях так глубоко не вникал в это, чтобы что-то более конкретное сказать по этому поводу. 

S03 [02:00:18]  : Спасибо. Вопрос от Николая Робчевского. Не проще ли проблему оперирования типами решить отказом от понятия типа, узла и графа, и рёбер соответственно, редуцируя гиперграф к directed graph with unlabeled edges? 

S01 [02:00:37]  : И да, и нет. Собственно, об этом на самом деле доклад был, правда это внятно и четко не прозвучало. Вообще, когда мы начали думать над проблемами OpenCog, одна из проблем была в том, что есть типы атомов, и люди часто вводят какие-то кастомные типы для каких-то конкретных предметных областей. Например, ресторан Node. ресторан-нод чили-пицца. почему это ресторан-нод, почему это не там концепт-нод чили-пицца, который inherited от концепт-нода ресторан, то есть это можно в виде самого графа записать, то есть вроде как достаточно просто иметь одного типа атомов, ну при желании двух там, если хочется чуть-чуть проще это делать, да, это там линки и ноды, вот, и все типы можно описать просто внутри самого графа, то есть у нас будет какой-то там нод под названием type и к нему будут идти линки от других нодов. И казалось бы, а почему нет, то есть зачем вводить лишнюю сущность, если в самом unlabeled метаграфе это вроде как описывается. Ответ тут не совсем однозначный, но, во-первых, просто ради удобства. то есть ради эффективности и удобства, когда у нас есть введенные какие-то типы, мы по ним заранее можем индексировать, вместо того чтобы писать сложный запрос к паттерн-матчингу, что это является таким-то типом, а это будет подграф, который нам отдельно надо искать, это является таким-то типом, это еще один подграф, который надо искать, и это можно сделать. Но это потребует гораздо большего обхода нашего графа, а здесь у нас все разложено по полочкам. Вот у нас есть такой-то тип, мы сразу идем в индекс этого типа и оттуда извлекаем гораздо эффективнее все, что нам нужно. То есть это компактнее, это эффективнее, но это такой сугубо прикладной ответ, который меня тоже не полностью удовлетворяет. И мы в моем докладе, например, видели, что вообще говоря, все типы можно описывать как предикаты. То есть на самом деле, если тип это теорема, то это логическое утверждение, это можно просто представить как функцию, которая там возвращает true. и возникает вопрос, действительно, зачем нам типы, если у нас есть предикаты или что-нибудь в этом роде. Ответ заключается в том, что type-чекинг в языках, зависимые типами, он гарантированно завершается. То есть мы можем сказать, что у нас есть выделенная подсистема, к которой можно обратиться, которая там делает, что нужно, и там есть конкретный алгоритм того, как это делать. то есть там если мы возьмем какой-нибудь, я не знаю, лямбда-куб, то у нас есть не типизированное лямбда-исчисление, а есть другая грань этого куба, когда мы над типами можем делать тюринг полный вычислений и разницы между ними никакой нету с прагматической точки зрения. А вот если мы берем какие-то промежуточные варианты, то разница появляется. То есть у нас появляются конкретные средства inference, которые обладают конкретными полезными свойствами, которые мы можем использовать в нашей системе. То есть, скажем, type checking на самом деле в языках с зависимыми типами превращается просто в проверку решения задачи. почему бы не выделить это в отдельную полезную сущность. И она везде нужна, и будем ее использовать. Поэтому с точки зрения чисто представления знаний, ну да, наверное, это избыточно. То есть без этого, в принципе, можно обойтись. Но с точки зрения инференса, это очень мощная полезная штука, которую реализовать в нетипизированной системе потребует массу усилий. Наверное, такой ответ. 

S03 [02:05:49]  : Спасибо. Еще от Николая замечание или вопрос. Если тип – это множество сущностей, то каждая сущность – отдельный тип, и тип есть синоним сущности. 

S01 [02:06:02]  : Ну, знаете, это тоже достаточно интересный аспект. Если мы повнимательнее посмотрим на тот же Idris, ну или на другие языки с зависимыми типами, то там есть выделенный тип. В Cokie это prop, в Idris это type. И мы можем Я не знаю, давайте... Ну, любой пример. Вот, мы можем сказать, что бездай это там что-то-что-то, что угодно, стрелочка в type, но мы не можем сказать, что, скажем, я не знаю, там... student это стрелочка в person, то есть это не типы высших порядков, то есть здесь нет субтипизации, мы не можем определить один тип как подмножество другого типа. Здесь есть один за hard кожаный тип типов, Есть просто одноуровневые все другие типы. Они взаимодействуют между собой алгебраически, функционально, но у нас нет возможности ввести какие-то типы типов в языках с зависимыми типами. Это как раз ограничение, о котором я говорил. Мы не можем с ними делать вообще все, что нам заблагорассудится. Да, и когда мы, например, у нас есть какой-то набор типов и мы хотим обернуть их в другие типы, вот говорят, что, например, есть тип сумма, и мы можем сказать, что у нас Я не знаю, люди это мужчины или женщины. Это неправда. В зависимых типах у нас, когда мы говорим, что вот, скажем, здесь верхняя строчка, допустим, тот был бы date of human равняется man или woman. Man или woman будут не типами, они будут конструкторами типов. И, к сожалению, мы не можем вот это такое тоже неявное, не очень удобное ограничение, которое лично мне не нравится, когда мы рассматриваем типы как зависимые типы по способу представления знаний, мы не можем прямо сказать, что один тип является объединением двух других типов, нам косвенно приходится это делать через конструкторы. Да, через конструкторы мы можем завернуть один тип, другие типы, но они будут именно через обертки какие-то делать. К сожалению, тут есть такие ограничения, что ли, но именно эти ограничения делают type-checking, например, вычислимым. 

S03 [02:09:25]  : Спасибо. Замечание или вопрос, скорее замечание от Дениса Буздалова. Есть ощущение, что сравнивается действительно работа на мета-уровне в Хиппероне и на не мета-уровне в Идрис. Тем временем для Идриса существуют средства метапрограммирования, причем на самом же Идрисе. Называется Элаборэйшн. 

S01 [02:09:53]  : Согласен. но тут как бы не было сравнения Геперона с Идрисом. Тут был анализ именно чистых зависимых типов самих у себя. В Коке есть, скажем, тактики, которые делают какую-то помощь в резюнинге. В Агде есть свои дополнительные вещи и в игре всегда есть возможности программирования. А вот это в рамках доклада просто не анализировалось, не такая представилась. 

S03 [02:10:41]  : Спасибо, вопрос от нас. 

S01 [02:10:44]  : Просто чуть-чуть добавлю, что тот же Бен, например, он ставил вопрос о возможности реализации гиперона на Идрисе. Этот вопрос по-прежнему остается открыт. Если сложилось впечатление, что я в чем-то критиковал Идрис, это не совсем так. 

S03 [02:11:08]  : Спасибо. Вопрос от нас с Игорем Пивоваровым. Как с точки зрения архитектуры вы видите приложение OpenCock Hyperon к решению задач типа самообучения играм из OpenGem AI? или распознаванию лично видео. Я поясню вопрос, поскольку он от меня исходит. Есть, я помню, слайд известный из одной из презентаций Бена, который я тоже использую. По-моему, в прошлой четверг я даже его показывал, где показана вот эта самая иерархия. от мета-графа, где на верхнем уровне иерархии у нас взаимоотношения между столами, стульями и людьми, которые их двигают, а на самом нижнем уровне у нас конкретные RGB-каналы, конкретных пикселов, которые визуализируют эти столы и стулья на конкретных фреймах видеопотоки. И все это вписывается в метаграф. Это вот один вариант. да второй вариант который я могу предположить что где-то на каком-то уровне у нас возникают там grounded схема нот как я понимаю в терминах opencog и уже собственно эти grounded схема нот работают там внутри себя с пикселами там и с видеофреймами два варианта может быть какие-то еще есть вот вы это сейчас как видите с точки зрения архитектуры 

S01 [02:12:29]  : Да, спасибо за вопрос. Как я в самом начале сказал, мой доклад не будет про весь дизайн гиптерона в целом, потому что, во-первых, он как бы все еще далек от какой-то кристаллизации, во-вторых, это бы заняло крайне много времени, и на самом деле один из существенных, может быть, один из почти главных или близких к этому моментов в нашем, в частности, желании делать гиперон и отчасти в его текущем дизайне, но чуть в меньшей степени, это как раз то, как в OpenCode реализованы grounded схема ноды и так далее. Мы в рамках OpenCog прилично работали с нейросимвольной интеграцией и продвинулись в этом неплохо. модульные нейросети реализовали в OpenCog, то есть там Reasoning на лету конструировал модульную нейросеть и обучался end-to-end, то есть сигнал проходил от выхода с вот этой вот сконструированной в результате ризнинга сети ко входу и там все это обучалось, мы там добавляли возможность делать тот же PLN, probabilistic logic network, с обучаемыми правилами, с обучением truth values через backpropagation и так далее. Но несмотря на то, что нам многое из этого удалось, оставались разные моменты, которые нас не удовлетворяли, там вот эти вот grounded ноды оставались неполноправными жителями. Мы ввели там свой grounded object node, который технологически был более пригоден в частности для встраивания нейросетей, но этот grounded object node, например, не попал в главный репозиторий OpenCog и остался в сингнетовском форте, но это тоже отдельный вопрос. Остались там разные люди, и мы в частности, но далеко не только мы, многие наши разные коллеги делали обучение, например, графовых embeddings, но все это делалось как такая пристройка, что ли, коконкоба. И вот было желание все это нативным образом учесть в дизайне гиперона. Не скажу, что это сделано уже, но какие-то части из этого сделаны. Например, вот я упоминал, что у нас Вообще говоря, есть четкое понимание того, что многие вещи, которые в базовом OpenCog являются hard-coded типами атомов, являются по сути дела grounded типами, grounded символами. И мы это в явном виде сделали в OpenCog, то есть в гипероне сейчас не представляют проблемы. например, ввести в Atomspace grounded символ, который будет соответствовать какой-то нейросетке, и когда интерпретатор будет обращаться к выполнению этого символа, он будет обращаться к какому-нибудь PyTorch. То есть это сделано на менее костыльном уровне, но это так, тоже чисто технический момент. С другой стороны, вот этот вот декомпозированный интерпретатор OpenCog'а, гиперона, он как раз был мотивирован задачей управления агентами, в частности в контексте reinforcement learning. И сейчас рассматривается в рамках Проект TroyGI, в частности, демонстрация, разработка гемы, того, как на гипероне будет обучаться майнкрафтовский агент, достигать разных целей. И там вот эта вот идея модульных сетей, на лету генерящихся через резонанс, то будет из статической области визжоу-квестченансферинга, перенесена на именно область агентов, то есть там нейросетки будут выступать в качестве скиллов отдельных, а ризнинг символьный со стороны гетерона будет дергать то один скилл, то другой и передавать сигнал подкрепления в зависимости от тех целей, которые он сейчас текущий момент времени пытается достичь. мы к этому приступаем пока, то есть я не скажу, что там что-то сверх интересное уже сделано, но по крайней мере вопрос прорабатывается. есть некоторые идеи в базовом опенкоге это было бы сделать весьма проблематично, там вообще агенты на текущий момент управляются через OpenSci модуль, который в общем и с ризнингом дружит достаточно косвенно, то есть там вот такая недоделанная все-таки согнитивная синергия что ли между разными очень интересными, но недостаточно самостоятельными модулями. Поэтому, в принципе, это будет делаться в рамках примерно такой же нейросимвольной интеграции, как мы делали в OpenCode, пока остается все-таки Открытым вопрос, какова роль будет графовых имбеддингов во всем этом деле, этот вопрос пока не удается до конца прояснить, потому что у нас вот с Сергеем Шаляпиным, например, там полгода назад были очень интересные идеи о том, как тренировать мэппинги из натурального языка в, собственно, атомизм. И мы это там даже делали, например, управление умным домом, то есть там просто человек в естественном языке говорил какие-то вещи, и они транслировались прямо в атомизм команды, и это было очень гибко. То есть человек может сказать «хочу, чтобы в комнате стало ярче», или «включи свет», или «зажги лампочку», и это все приводило к одной команде включить свет. Но пока это остается очень, к сожалению, не хватает на все время, недоработанные вопросы. Такова роль будет графовых импеддингов в гипероне. К сожалению, очень хотелось бы это подетальнее продумать, но тут действительно очень-очень много аспектов, которые одновременно приходится учитывать и держать в голове, а на уровне имплементации, конечно, их все сразу не учить. В сторону нейронных сетей, контроля агентов, в том числе не просто OpenGM, но даже Minecraft. Сверх того, что делается в MineRL мы хотим сделать, в этом направлении мы двигаемся. 

S03 [02:20:58]  : Спасибо, Алексей. Игорь, вы что-то хотели добавить? 

S02 [02:21:07]  : Да нет, я ответ понял. У меня, честно говоря, ощущение, что что, ну пардон за прямоту, но как бы вы тащите эту старую архитектуру как бы в новую задачу и никак не дойдете до решения задачи, потому что ну как бы надо еще дотащить эту старую архитектуру. 

S01 [02:21:30]  : Вы старую архитектуру не тащите. Что вы называете старыми и какие новые архитектуры вы можете привести в качестве примера? Нет-нет, давайте вы произнесли конкретное высказывание, я очень хочу получить ответ на свой вопрос, иначе ваше высказывание не стоит ломаного гроша. 

S02 [02:21:53]  : Ну это правда, оно не совсем корректно звучит, старое не в смысле в данном случае не в смысле плохая, а в смысле... Я как раз на следующий семинар посвятить обсуждение этих архитектур и разных аспектов с этим связанных. Просто у меня ощущение, что в целом то, что вы рассказываете, это отличная архитектура для решения определенного типа задач. Типа, действительно, некие построения системы рассуждений, антологии, графовые базы данных и так далее. И для этого я не сомневаюсь, что оно будет работать хорошо, хотя вопрос про то, каким образом оптимизируется вычисление, он правильный. Я программировал на правилогии в свое время. когда там весь этот перебор идет, у тебя вроде так пять строчек кода бывает, а работать оно может очень долго, реально. Но тем не менее для этого класса задач это пригодно. Но вот для класса задач управления агентом у меня ощущение, что все вот это как бы в целом не очень нужно. 

S01 [02:23:10]  : Но это ваше решение, и оно неправильно, потому что возьмите, скажем, в Майнкрафте попробуйте натренировать хоть какую-то там нейросетку, или я не знаю, что вы имеете в виду, но я не знаю, там, скажем, на то, чтобы она обсидантом была. Да, я очень долго буду смеяться, как вы это сделаете без символиного ризмка, просто очень будет смешно. 

S03 [02:23:39]  : Мне кажется, что последние минуты это хороший повод продолжить разговор. Да, верно. 

S02 [02:23:47]  : У Алексея была блестящая презентация, в этом смысле она как раз ставит этот вопрос. Здесь разные точки зрения. 

S01 [02:23:59]  : Игорь, я хочу еще раз подчеркнуть, что моя презентация была на очень конкретную тему. Я не пытался обозреть архитектуру гиперона в целом. Возможно, это вызвало какое-то недопонимание. 

S02 [02:24:17]  : С моей стороны. Да, вероятно, да. У меня нет никакого, никоим образом там, вы блестяще рассказали эту историю, я все целиком понял, ну вот то, что вы рассказывали. Просто вопрос, который там был про связку с Рейлем и с агентами, я понимаю, что вы про это сегодня не рассказывали, а мы видим это, ну я в частности сам там домыслил. Интересно будет посмотреть, как вы это сделаете. 

S03 [02:24:43]  : Ну вот да, то есть коллеги, всех приглашаю в следующий четверг поговорить про когнитивные архитектуры. Алексей, спасибо огромное. Спасибо всем участникам за терпение, за внимание. До встречи. До свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
