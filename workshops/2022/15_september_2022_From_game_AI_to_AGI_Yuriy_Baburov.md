## 15 сентября - От игрового ИИ к AGI - Юрий Бабуров — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/jq7obz3s47I/hqdefault.jpg)](https://youtu.be/jq7obz3s47I)

Суммаризация семинара:

Семинар затронул различные аспекты искусственного интеллекта, в частности, вопросы, связанные с игровым интеллектом и архитектурами агентов. Основная тема заключалась в том, как можно начать с игрового ИИ и добраться до создания агента общего интеллекта (AGI), а также в методах обучения и взаимодействия различных компонентов искусственного интеллекта.

Участники семинара затронули тему о том, как деятельность в игровой ситуации может сводиться к сумме максимального реварда и как это направлено на определенные цели обучения. Были обсуждены идеи о кривонинге и о том, как различные части искусственного интеллекта оцениваются победой, то есть суммарным ревардом.

Особое внимание было уделено когнитивным архитектурам и их способностям к обучению и развитию. Сравнивались подходы к обучению искусственного интеллекта, в том числе через реализации нескольких нейросетей, которые работают вместе. Также обсуждалась возможность обучения искусственного интеллекта выполнению множества задач, включая шахматы, GO.

Были освещены и другие вопросы, такие как использование игровых сценариев для обучения искусственного интеллекта, включая упражнения с языковыми моделями и различные стратегии, такие как StarCraft и Dota. В контексте обучения и работы искусственного интеллекта, были затронуты такие темы, как классы эквивалентности, дискретное обобщение и реализация динамических состояний и действий.

В общем, семинар предоставил ценную информацию о том, как разрабатывать и обучать искусственный интеллект, используя различные подходы и методы, и подчеркивал множественность возможных решений задач в этой области.








S02 [00:00:04]  : Коллеги, всем добрый вечер. Я сделаю небольшой анонс для тех, кто видит и смотрит нас первый раз. У нас есть вот такой вот сайт сообщества. У нас есть группа во Вконтакте. группа в Фейсбуке, который признан экстремистской организацией на территории Российской Федерации, и у нас еженедельно проходят семинары, анонсы которых всегда даются на одной и той же странице, и на каждый семинар нужно регистрироваться отдельно по ссылке в конце страницы. Вот здесь выбирается и осуществляется регистрация. Но все семинары записываются и публикуются на канале CyberEI. Ближайшие семинары у нас через две недели Сергей Шумский будет рассказывать свою работу с Игорем Пивоваровым про архитектуру агента на основе моделирования функций человеческого мозга. Это через две недели будет, а на следующей неделе у нас вместо семинара будет конференция международная по Biological Inspired Cognitive Architectures. которое будет происходить в Мексике. Соответственно, у кого много денег и кто находится в Европе или США или не спит по ночам на территории РФ, он может в этой конференции поучаствовать. Кстати, наш доклад там будет эту конференцию открывать, которую мы делали около месяца назад. А сегодня у нас Юрий Бабуров расскажет про то, как нам от игрового ИИ перейти к AGI. Юрий, пожалуйста. 

S04 [00:01:59]  : Всем добрый день. Сейчас мне еще секундочку подобрать пример. ну что начнем включаем шаринг экрана скажите видно ли слайды да, все видно. значит, сегодня мы говорим про то, как мыслят конструкторы игровых интеллектов и Можно ли начать с игрового ИИ и сделать в итоге AGI? Давайте начнем. Мы поделим игровой интеллект на 2 разных штуки, о каждой из которых поговорим. Вначале мы поговорим об имитационном искусственном интеллекте, игровом интеллекте. Что такое имитационный игровой интеллект? Это интеллект, который добавляется в игру, чтобы игроку было интереснее, но при этом который не опирается на модель игрового мира, а вместо этого обладает каким-то запрограммированным, иногда говорят заскриптованным поведением. Но, тем не менее, есть много очень интересных примеров, когда такой игровой интеллект все равно является полезным. И людям, которые мало знакомы с компьютерами, которые мало знакомы с тем, как это все сделано, могут воспринимать такой интеллект как вполне себе интеллектуальную штуку. Ну, например, самый дурацкий, самый простой пример. Вот запрограммируем врагов в змейке, которые будут двигаться случайным образом. тем не менее, если мы будем играть в змейку, то эти враги нам будут мешать, мы должны на них не натыкаться, мы должны с ними как-то взаимодействовать, нам сразу становится интереснее, появляется ощущение, как будто с нами играют другие игроки. или же можем запрограммировать компьютер, который будет играть в дурака без всяких усложнений, просто пытаться ходить всегда младшей картой из имеющихся, и когда пытается отбиться, тоже берет и кладет самую младшую из карт всегда. в целом получается уже неплохая стратегия, которая позволяет играть в эту игру с ощущением, как будто ты играешь с другим человеком. есть такие игры более простые, которые так устроены, которые так можно играть. но это самые простые примеры, а вот в более сложных играх игроделы придумывают более сложные Давайте попробуем понять, относится ли этот алгоритм к имитационному искусственному интеллекту или он сделан по-другому, чтобы научиться отделять то, что нам не нужно. а нам не нужны как раз вот такие вот алгоритмы, которые ничего не знают о мире. вот, например, вот в игре сталкер, Сталкер Чернобыль или в той же версии, другие персонажи, которые похожи на главного героя, такие же сталкеры с мешками за спиной, значит, ходит как-то по карте, то есть его вначале встречаешь в одном месте, потом он в другом месте на карте, иногда он идет вместе с тобой по дороге. но игроделы утверждают, что они создали искусственный интеллект, который, соответственно, играет сам тоже вместе с пользователем в игру. Ну, конечно же, в данном случае это не так. И главное ограничение – это то, что у него очень мало возможных вариантов. То есть мы просто берем для этого агента также делаем выбор случайного варианта, то есть он может, ну вот что-то ему в голову пришло, он взял пошел там в другое место, он знает в какое место он должен прийти, значит дорога расписана для него и вот в общем-то от врагов змейки ничем не отличается данная ситуация, которые двигаются там случайным или там каким-то подобным образом. то есть главное ограничение таких имитационных ИИ, они перестают работать, как только у нас начинаются открытые карты, начинаются какие-то более сложные взаимодействия, поэтому говорят, что они заскриптованы, то есть у них есть набор определенный. поведений, которого они придерживаются. Тем не менее, наиболее удачные примеры могут неплохо обманывать человека. Вот, например, Евгений Гусман притворялся 11-летним подростком из Одессы, поэтому он не хотел отвечать на вопросы человека. Вместо этого говорил, да, я про это ничего не знаю, я просто обычный подросток и таким образом. То есть уходил в ту часть мира, в которой подобное поведение, имитация разумности, будет казаться интеллектуальной. Поэтому, собственно, я его и называю имитационный. Он имитирует разум, но при этом совсем им не является. Также имитировала разум давным-давно и Элиза Витсенбаума 1968 года. То есть она, по сути, человек говорил, Мне там не нравится, не знаю, погода. Лиза перепразировала. А как? Что именно вам не нравится в погоде? Или там, а как именно вам не нравится погода? И таким образом постоянно задавала вопрос к тому, что говорит пользователь. И пользователю казалось интересно общаться с таким ботом. Более того, он создавал даже иллюзию понимания. что он интересуется тем, что у человека происходит и так далее. Но этот искусственный интеллект ничего не знал, ничего не запоминал, ничего не знал про то, что на самом деле происходит, а просто задавал вопросы и заставлял человека раскрывать больше того, рассказывать. Сам ни на один вопрос ответить не мог. Хорошо. Другой пример. В гонках роботы-машинки соревнуются с человеком. Наверное, многие подумают, что… роботы-машинки, они как-то смотрят на карту, как-то оценивают траекторию движения, как-то придумывают, какая у них текущая скорость, как обогнать человека или как друг друга обогнать. Но на самом деле в большинстве гоночек, наверное, в 99% этих гоночек все устроено гораздо проще. Есть такое понятие waypoints. На русский это нормально не переводится, поэтому буду пользоваться английским термином. На карте нарисовано направление движения в виде кусочков линий или стрелочек, иногда с пометками необходимой скорости на этом участке. Все, что делает робот, он старается двигаться как можно ближе к этой стрелочке, если он вдруг ушел в сторону. соответственно, если у него скорость большая, на стрелочке указано сбавить скорость, то сбавляет скорость и наоборот. если на стрелочке указано разгоняться, то если на стрелочке ничего не указано, это и значит разгоняться, то он, соответственно, разгоняется. и такой робот может двигаться очень быстро. вообще, если вы смотрели какой-нибудь из фильмов про гонки, то там, где описывают, как тренируются гонщики, они и тренируются. тем, что они запоминают трассу с точностью до каждой выщербинки асфальта, что именно на месте этой выщербинки через 10 сантиметров после нее надо начинать торможение. И тогда получается наименьшее время прохода этого поворота сложного участка. То есть, по сути, задача в гоночках делится на две. Первая – построить оптимальную траекторию, неважно каким методом она может быть уже заранее построена. И второе – проход по этой траектории. Так вот, проход по траектории, уже построенный оптимальный, он не сильно-то и сложный. Это не является интеллектуальной задачей. И таким образом создается неплохая, тем не менее, имитация. имитация интеллекта. При этом бывает, например, ситуация, когда, может быть, вы пробовали в гоночке встать ровно на этой траектории оптимального движения компьютера и посмотреть, что будет происходить. будут происходить два варианта. первый вариант, если не заложено уклонение от человека. в разных играх разная механика ударов, штрафы на удар и так далее. если не реализована механика уклонения, то просто бот начинает биться с человека сзади. вместо попыток обгона сбоку. если сделано уклонение, то они начинают всячески странным образом уклоняться, биться об стенки при этом и так далее. то есть как раз демонстрирует то, что они двигаются по этим вейп-поинтам. возьмем теперь еще один пример. В игре Doom или каком-нибудь другом шутере монстры бегут на человека и стреляют в него. Но бегут на человека, чтобы быть ближе, чтобы в него точнее попасть или чтобы его там располовинить какой-нибудь своей секирой или какими-нибудь своими монстр-конечностями. Что при этом происходит? Для этого не требуется какого-то сверхумного алгоритма, требуется просто координаты человека. Робот-монстр или существо не видит человека. Оно вместо этого просто знает свою положительность на карте, знает позицию человека, просто разворачивается в нужную сторону и движется в сторону человека. И стреляет также на то положение, где человек был. Поэтому в большинстве игр, если вы будете просто бегать кругами, вас ни один монстр не попадет. Они не будут там ни с упореждением стрелять и так далее. но тем не менее это позволяет демонстрировать очень увлекательный игровой процесс в тех же играх типа Doom. Чем отличаются Игры, где тот же Doom, но в варианте арена, когда агенты, противники тоже такие же персонажи. Там тоже, как оказывается, есть несколько траекторий. Есть, например, траектория движения за аптечками. Есть траектория движения за поиском человека. То есть робот берет, выбирает одну из нескольких траекторий для движения и по ней двигается. Никакого интеллекта при этом, конечно, нет. Соответственно, эти алгоритмы мы разобрали. Соответственно, имитационный искусственный интеллект может и позволять в каких-то случаях сделать мир, оживить мир. но тем не менее он ничего не знает про мир игры. Это, конечно, плохо. Ну и в основе кодирования этого жесткого скриптового алгоритма лежит аваристический метод, который, возможно, здесь не подходит. Значит, по первой части, если какие-то вопросы есть, давайте, пожалуйста, задавайте. 

S02 [00:15:48]  : С нетерпением ждем перехода во второй. Есть какой-нибудь искусственный интеллект, который не имитационный, а который действительно видит человека? 

S03 [00:15:56]  : Юль, я только хотел немножко добавить одну фразочку о том, что существует тип управления под названием программное управление. То есть это управление без обратной связи, когда траектория или годограф вот как бы уже семейство траектории задана и система просто движется программно вот таким программным способом управлялся корабль юрия гагарина тогда не было обратной связи поэтому в общем эта штука применяется вполне себе в некоторых случаях она и может работать вот но нет обратной связи как ты правильно отменить сергей об уран об уран не знаю про Гагарина знаю, потому что почитал в книжке, называется книжка «Управление на земле и в небесах», как-то так вот она называется. Но после Гагарина уже все остальные были с обратной связью. Первые были в Востоке, то есть математики считали, что не можем обеспечить обратной связи, и все сосчитали от начала до конца, все там эти 108 минут, 110 минут, все были посчитаны программно. так что он летел без обратной связи вообще. извини, Юра, я прошу прощения. 

S04 [00:17:05]  : да, все правильно. так очень часто делают аппараты. или делают без обратной связи, или делают с триггерами. то есть есть какие-то переключатели состояния. то есть, например, у нас топливо закончилось, мы отбросили ступень. или там какое-то время прошло, мы отбросили ступень. 

S05 [00:17:30]  : Можно? 

S04 [00:17:30]  : Пожалуйста. 

S05 [00:17:32]  : Вот эти эмоционные и такие задачи решает выиграть? 

S04 [00:17:39]  : Решает задачи, решает такую задачу, что Если у нас мало вычислительной мощности, то мы можем во многих играх сделать неплохого противника, который будет демонстрировать в чем-то интересное поведение, с которым уже можно соперничать. 

S05 [00:18:09]  : То есть они имитируют человека противника? 

S04 [00:18:14]  : Да. 

S05 [00:18:16]  : Если они решают свои задачи, то почему их нельзя назвать интеллектом? 

S04 [00:18:22]  : Безусловно, их можно назвать интеллектом. Также и человек, работающий на конвейере, он тоже работает заскриптованно, да, у него тоже есть последовательность действий, которую он старается сделать. 

S05 [00:18:34]  : Вот именно. 

S04 [00:18:36]  : Вот, безусловно, все можно назвать, любой процесс можно назвать интеллектом. Любой алгоритм в таком случае. Но нас все же интересуют другие интеллекты. 

S05 [00:18:52]  : Есть определения, какие интересуют, какие не интересуют, или это по вкусу. 

S04 [00:18:58]  : Я как раз и разделил. Имитационный искусственный интеллект ничего не знает о мире игры и, соответственно, не может осуществлять планирование в мире игры, но, тем не менее, может демонстрировать поведение, похожее на данные, на интеллекты, которые знают о мире игры, не обладая при этом знаниями. Поэтому получается имитация. Имитация такого поведения. Поведение другого человека или имитация поведения противника. Но при этом самого мыслительного процесса нет. Спасибо. Хорошо, тогда переходим ко второй части. Значит, теперь симуляционный искусственный интеллект. Теперь, когда мы разобрали варианты, как делать не нужно, разберем единственный оставшийся вариант. Мы должны использовать модель мира для формирования поведения. У данного подхода есть один очень большой недостаток, из-за чего он не сильно распространен в играх. Он требует симуляции мира, при том достаточно неплохой симуляции. И вместо того, чтобы выбирать просто следующий шаг, он требует какого-то планирования. Он требует того, чтобы мы в пространстве этих состояний игры делали какие-то варианты шагов, смотрели, что будет в следующей ситуации, и таким образом как-то отбирали, как-то формировали оптимальное поведение. Это тот алгоритм человеки, которым многие восхищаются. планирование и разумная деятельность, основанная на планировании. Но, соответственно, проблема в том, что симуляция мира должна быть действительно хорошей. Например, если в игре есть выстрелы и пуля летит со скоростью 10 метров в секунду или 100 метров в секунду, то мы не можем запускать пулю в нашей симуляции с другой скоростью, потому что в этом случае она в игрока попадет в другой момент времени. То же самое касается даже простых игр типа бильярда. Если мы рассчитываем модели с ударения шаров, мы должны достаточно неплохо рассчитать, как эти шары будут друг с другом взаимодействовать. И искусственный интеллект, который играет в бильярд, должен учесть в конкретной этой игре в бильярд, как именно шарики тормозятся об стол, как шарики, можно ли их подкручивать или нельзя, и меняется ли от этого их траектория. Какая механика отскока, с какой скоростью, с какой упругостью они отскакивают от бортов, на сколько их скорость уменьшается. Вот. Ну, там еще мягкость может учитываться. И вот эта вся симуляция мира, она в больших играх, сложных играх становится просто огромной проблемой и большой сложностью. И, соответственно, если мы не хотим Для начала мы пока не будем обсуждать, что мы будем делать, если мы не хотим симулировать мир. Пока что мы говорим о том, что надо симулировать мир. Мы это делаем. Мы это неплохо делаем, с точностью достаточной для того, чтобы решать задачи в этом мире. И тогда, что нам остается в этом случае? В этом случае наш основной алгоритм – это перебор ширину пространства симуляции. Почему не перебор глубину? Потому что мы можем иначе зайти в какой-то неоптимальный вариант решения и потратить все доступное нам для шага время, рассматривая только это решение, потому что вариантов в глубину может быть много. и все можем не рассмотреть, поэтому основным является поиск ширину, поиск каждого варианта на небольшую глубину, но тем не менее в каких-нибудь походовых играх это может быть 3-5 ходов. Соответственно, основной способ, как это можно сделать, мы делим мир на возможные варианты, возможные варианты действий, и в рамках этих вариантов действий мы пробуем разные шаги. Мы попробовали один шаг, другой шаг, смотрим, что после этого получилось. Получилось у нас добиться какого-то хорошего состояния или нет. Если получилось добиться хорошего состояния, мы запоминаем эти шаги. перебираем также другие варианты и в итоге у нас получается самый лучший результат, которого можно добиться за 4 шага или за 10 шагов. мы этот вариант выбираем и делаем первый шаг по нему. Дальше, возможно, ходит другой игрок или там еще что-то происходит, но дальше мы снова повторяем алгоритм. Из нового состояния мы снова запускаем этот же алгоритм примерно на ту же глубину и пытаемся более точно теперь запланировать следующие шаги. Этот алгоритм побеждает во всех игровых соревнованиях по искусственному интеллекту. во всех тактических и стратегических. но вопрос такой, возможно ли улучшение каких-то данного алгоритма, потому что у этого алгоритма достаточно много неприятных ограничений, из-за которого его трудно применять. значит, он требует дискретного количества возможных действий на каждом шаге и требует неплохого алгоритма скоринга конечного состояния, то есть по-хорошему требует эксперт. получается в скоринге недалеко уходим от вот этих вот наших эвристических методов, потому что мы заранее говорим, что вот этот шаг в принципе он будет хороший, потому что состояние изменится к лучшему, то есть мы оцениваем это состояние, вот эту оценку состояния мы должны как-то запрограммировать. и должны соответственно саму симуляцию на ней не облажаться, потому что иначе... есть интересный пример такой. сделали в игре в гоночках увеличение скорости машинки, точнее, меньшее торможение, если перед ней находится другая машинка. Ну, мы знаем, сопротивление воздуха меньше, потому что этого воздуха, собственно, меньше, потому что другая машинка нам помогает. Иногда это называют воздушный пузырь. То же самое происходит при движении около стенки. При движении около стенки у нас немножко меньше сопротивления воздуха, потому что справа поток воздуха, если мы у правой стенки, меньше. Интересно, что данного торможения практически не наблюдается в реальной жизни, но тем не менее в играх этот эффект часто преувеличивается. И поэтому была забавная история с тем, что один водитель, не формулы один, другой какой-то гоночного соревнования, двигался ближе к стенке в ситуации, когда он мог двигаться по центру или еще где-то. Его спросили, почему вы двигались ближе к стенке. Говорит, потому что играл в какую-то компьютерную игру ближе к стенке, было немножко быстрее. Я подумал, наверное, быстрее. Это о том, что неправильные симуляции ведут нас к неправильным действиям, неправильному планированию. Есть и более жестокие примеры, когда ошибка в симуляции приводит к тому, что на деле, например, мы запланировали, что у нас оружие перезарядится через 5 шагов, но неправильно оценили, а оружие перезарядилось через 6. Мы через 5 шагов подошли к противнику, нажимаем на выстрел, а выстрел не срабатывает. Противник нас застреливает, и мы проигрываем. ну вот соответственно хороший симулятор нужен, и это еще одна боль данного алгоритма, потому что этот симулятор нужно программировать, соответственно мы не можем научиться играть в произвольную игру, нам надо было программировать симулятор, мы не программируем алгоритм, мы вместо него используем перебор, но нам приходится программировать симулятор и нам приходится программировать сплоринг. То есть работы стало больше, а не меньше. Как можно улучшать данный алгоритм? Рассмотрим разные идеи. Во-первых, можно добавить приоритеты. Например, если в шахматах при ходе происходит шаг, то мы знаем, что вариантов ответа будет один всего. не один, но намного меньше. надо будет двигаться королем, уходить от шаха или брать атакующую фигуру или ставить заслон какой-то от шаха. ходов меньше. поэтому мы можем такие позиции приоритизировать и глубже их рассматривать. у нас появляются какие-то позиции, которые интереснее, чем другие. какие-то состояния, какие-то ситуации, которые интереснее, чем другие. Их мы лучше анализируем. Некоторые говорят, что возможно это происходит во время сна, то что организм перед пробуждением нам подсовывает какую-то неприятную ситуацию, в которую мы можем попасть, чтобы мы и с утра ее проанализировать. с большим произведением, потому что она вроде как неприятна. как мы можем улучшить перебор в игровом? Мы можем лучше оценить приоритет текущей позиции. До этого я говорил, что текущую позицию надо программировать, например, как оценивать текущую позицию в шахматах и как учат оценивать шахматную позицию любого новичка. говорят, вот считай сколько стоят твои фигуры, вычитай из этого сколько стоят чужие фигуры, получаешь то насколько позиции у тебя хорошие. превосходство по материалу в шахматах. Если мы ладью поменяли на коня и слона вражеского, то у нас немножко улучшилась позиция, потому что мы... оценка позиции улучшилась. И дальше алгоритм устроится... алгоритм перебора теперь строится на основе того, что мы можем выбирать из тех позиций, которые будут на следующих шагах, только позицию, только наилучшую, если мы делаем свой ход, или наихудшую, если мы делаем ход противника. вот этот алгоритм называется minmax алгоритм, и в общем-то этот алгоритм был популярен много лет и с ним, с этим алгоритмом выиграли даже чемпионы мира. то есть вот такая вот оценка текущей позиции плюс симуляция плюс min-max алгоритм только с некоторым еще отсечением, связанным с приоритетами. то есть если мы оцениваем, значит, если мы находим какую-то позицию лучше, более интересную, мы ее там глубже анализируем. но на самом деле на оценку может влиять в шахматах. могут влиять разные факторы. например, вот сейчас попробую включить другую. в принципе это у меня браузер был. давайте посмотрим например вот на эту позицию. с одной стороны по материалу видно доску шахматную? видно да? вот, например, смотрите, вот вроде у обеих сторон одинаковое число фигур, то есть по два слона, по два коня, значит, пешек одинаково 1, 2, 3, 4, 5, 6, 7. 1, 2, 3, 4, 5, 6, 7. Всего одинаково. Но, тем не менее, посмотрите, насколько плохо стоят фигуры у черных и насколько то, что они не могут двигаться. Если фигура не может двигаться, то какая разница, есть фигура или нет, если она вообще ничего не может сделать. Вот, например, черный слон, куда он может двигаться? Сюда под пешку, тогда его сразу пешка съест. Сюда под пешку и сюда под пешку. значит конь может двигаться вот сюда, а больше никуда не может двигаться. ладья может двигаться сюда, но туда не двигаться. смысла нет никакого. сюда под пешку двигаться не может. то есть мы видим то, что вроде бы по количеству материала у нас стороны равны, но тем не менее тем не менее у черных несколько фигур как будто не играют вообще таким образом ну соответственно ну кто-то кто-то должен истеречь конечно там вот этот конь например стережет чтобы держать вот этого коня но тем не менее в целом там один конь там три фигуры стережет и в общем-то здесь в этой позиции перевес в сторону белых при равном материале. и вот такая манера игры, при которой мы достигаем лучшей позиции, лучшей оценки, это как раз стратегический уровень игры в шахматы, на котором только уже мастера игры уже работают. новички мыслят о том, что как что-нибудь там съесть, как там больше материала приобрести. И это как раз другой уровень планирования совершенно. на чем он может основываться? во-первых, он не может основываться на статической оценке позиций. потому что если мы позицию оцениваем просто по количеству фигур, то здесь получается равная позиция. но здесь у белых фигуры лучше стоят. получается нам надо в оценку позиций закладывать то, насколько хорошо стоят фигуры. Это уже достаточно является сложным программированием, но для победы даже над мастерами этого уже не обязательно. Конечно, достаточно просто быть очень быстрым компьютером, который перебирает миллионы вариантов в секунду, даже сотни миллионов, и запоминает их. Но, тем не менее, в играх посложнее. Как раз вот эта позиционная оценка становится уже основной. вернемся к презентации. значит получается нам надо сделать более умную оценку текущей позиции. для этого что мы сделаем? значит мы возьмем натренируем нейросеть оценивать текущую позицию. на основе кучи примеров, но позже про это поговорим. значит дальше. где наша формула? Куленин, идея в чем состоит, то что мы строим оценку будущей выгоды как не просто то что, точнее наоборот, мы в том, что мы можем оценивать прошлые шаги на основе того, победили мы в игре или нет. То есть в играх типа шахмата на самом деле у нас есть очень редкая обратная связь, которая заключается в том, что мы или выигрываем, или проиграем, ну или ничья. Из этого мы извлекаем оценку нам нужно понять, хорошо ли мы ходили или плохо, и нам нужно научиться оценивать ситуацию в игре. соответственно, Q-Learning — это алгоритм реинфорсмент-ленинга, который позволяет оценить текущую ситуацию на основе будущей выгоды, возможной как максимум будущей выгоды, и наоборот. соответственно, считаем производные по нему и делаем градиентные спутники. и таким образом мы получаем предсказания текущей выгоды как раз для прошлого шага или прошлых шагов. но сейчас подробнее про это поговорим. дальше. как еще улучшить перебор? для начала будем имитировать человеческое поведение. Будем предсказывать наилучший человеческий код данной позиции. У нас есть огромная база накопленных человеческих действий при игре в шахматы. И будем называть данный компонент, данную функцию policy function или, соответственно, нейросеть, policy нет. Со временем этот компонент будет через кулемен учиться. значит, что оценивает policy network, он говорит в данной ситуации, что вот этот вот ход у него оценка полезности 0.9, а вот этот ход у него оценка полезности минус 0.1, а вот этот ход у него оценка полезности минус 1, то есть этот ход вообще категорически нельзя делать, а тот, который плюс 0.9, наоборот, очень хороший ход, его нужно делать. но теперь мы идем дальше. мы не делаем первый попавшийся ход, а вместо этого... давайте для начала просто пока что делаем самый самый хороший ход в данной ситуации. продолжаем про то, как лучше оценивать текущую позицию. текущую позицию на основе кулининга мы можем считать по усредненной оценке побед и поражений, возникающие из данной позиции. если мы в текущей позиции проиграли, наверное текущая позиция была плохая. но безусловно по одной игре судить нельзя, а по десятку, по сотне игр уже можно оценить текущую позицию. Но чем дальше мы находимся от момента победы или поражения, тем меньше уже вклад этих побед и поражений на оценку. Соответственно тем оценка текущей позиции меньше. Соответственно нейросетью научимся считать оценку текущей позиции и эту компоненту будем называть валюнетом. value network помогает нам определить, вот мы находимся в данной ситуации, значит пришли ли мы к хорошей позиции или плохой. и таким образом выбрать наилучшую позицию всех возможных вариантов. значит, лучше вот здесь мы проговорим дальше. теперь усложняемся еще дальше. вместо того, чтобы предсказывать лучший человеческий ход или предсказывать через Куленин лучший ход, тот ход, который привел к победе в большем числе вариантов, вот такого-то хода соотношения будущих побед и поражений 70 к 30, значит оценка будет 0,4. как-то оценили. вместо того, чтобы выбирать лучший человеческий ход, давайте будем делать теперь следующее. будем рассматривать ходы по порядку. но начинать с наилучшего хода и уже никогда не доходить до наихудшего хода. то есть вместо этого мы в шахматах возможно там вариантов 30 ходов, вместо этого мы будем рассматривать всего там топ 5 ходов наилучших нет, не 300, скорее до 300 доходит вариантов ходов. каждая фигура на несколько полей может ходить как минимум. 10 фигур на 5 или 10 полей. пешки конечно 1-2 могут ходить. получаем 50-100 вариантов. вместо этого будем выбирать только топ-5 вариантов каждый раз, их рассматривать, обходить в ширину дальше. из каждого этого варианта, из каждого из пяти, на следующем ходу снова будет 5 вариантов наилучших ходов. теперь уже за противника, а потом снова за нас. таким образом мы снова сделаем наш перебор, наш min-max в пространстве симуляции. для оценки того, насколько хорошая получилась позиция, мы будем использовать вариметр. полученный алгоритм называется альфа-гон. он же AlphaZero. Это тот самый алгоритм, который при человеческом ELO рейтинге в 2700 набирает ELO рейтинг в 5000. то есть он человека, вот каждые примерно 200 очков рейтинга – это победа уже 2 к 1, шанс побед, ну даже не 2 к 1, наверное, уже 3 к 1 шанс побед, то есть разница по LRating логарифмически в 2000 очков – это вероятность 99% что компьютер выйдет. и всему этому мы научились всего лишь научив две функции. первая функция, которая предсказывает ход, а вторая функция, которая предсказывает текущее состояние по этой модели мира. но не будем забывать, что у нас мир был небольшим, ходов там было много. Вариантов мало. А что если у нас теперь мир, в котором нет дискретного количества вариантов ходов, а вместо этого есть непрерывные варианты ходов? То есть мы можем выбрать любой из этих непрерывных вариантов ходов. Более того, у нас может быть не одна непрерывная компонента, а их может быть штук 20 или 100. У нас может быть робот, у которого может быть штук 20 конечностей. штук 20 суставов, и мы можем для каждого сустава задавать какое-то движение мышцами, которые тоже могут быть недискретны. Соответственно, от ситуации, когда у нас есть много кнопок, и мы умеем на каждую кнопку нажимать, мы переходим к тому, что вместо кнопок у нас теперь есть эмбеддинг. то есть у нас теперь есть представление текущего возможного кода в виде теперь многомерного пространства возможных ходов. И мы можем учить как раз это многомерное пространство в виде эмбеддинга с помощью нейросети. Как минимум для него можно предсказывать наилучший каждый раз ход. в рамках текущей задачи, конечно, можно чтобы не одну задачу решало много, предсказывать наилучший ход в каждом состоянии и, соответственно, таким образом обучать роботы движения. Ну а какой эмбейдинг взять и какие? какие выбрать варианты движения нужно выбирать, то есть если мы хотим почесать нос, то значит мы решаем одну задачу, то есть у нас есть какой-то модуль верхнего уровня упланирования и есть более низкий уровень, который уже у нас выбирает вот этих адресов для действия по этому полюсе нет. То есть мы получаем чуть более сложную схему, то есть добавляется еще несколько ходов, но тем не менее, как видите, мы здесь описали два компонента, таким же образом можно продумать штук 5 разных компонент, каждый из которых будет чем-то полезным и реализовывать какую-то нейросетевую функцию, и которая будет улучшать улучшать поведение. Таким образом получим искусственный интеллект, вполне себе обучаемый и вполне себе разумно себя ведущий. Но доберемся ли мы до универсального интеллекта, надо попробовать. такое сделать. но многие уже пытаются двигаться в данном направлении. так, ну вот в общем-то идеи в целом я рассказал. значит, давайте теперь послушаем вопросы, а потом попробуем подумать, что дальше можно сделать. 

S02 [00:47:31]  : Хорошо, Юрий, спасибо. 

S04 [00:47:33]  : Потом еще примеров показать разных. Как раз подобные интеллектуальные алгоритмы основаны на нейросетях. Какие интересные открытия мы благодаря ним, например, сделали, и как эти открытия свидетельствуют о том, что искусственный интеллект все-таки разумный получается в какой-то степени. 

S02 [00:47:59]  : Юрий, спасибо. Вот вопрос, во-первых, есть от Владимира Фролова. Относится ли поведение противника человека к модели внешнего мира? 

S04 [00:48:13]  : Смотрите. К модели внешнего мира относятся все, что мы посчитаем нужным, но как правило относятся все. дело в том, что просто для шахмат модель мира разделяется на две разных модели или на три разных модели, на три разных компонента. и за счет этого мы получаем просто более быстрый, более эффективный алгоритм. но никто не говорит, что так именно надо делать, можно делать по-другому. то есть можно считать, что компьютер будет частью модели мира, но тогда получается, что поскольку модель мира не планирует, то есть разница в чем получается. если мы считаем, что у нас противник часть модель мира, то получается, что противник тупой. он не умеет планировать, он всегда выбирает лучший ход данной позиции, которому его подсказывает его policy function. а вот если мы уже сделаем выделим вот этого противника из модели мира в какую-то отдельную штуку, мы, например, можем поставить как люди вопрос, а что противник сделает в ответ на наше такое-то действие. То есть это симулирование, симуляция мира на какой-то момент времени, в какой-то обстановке. вот это вот как раз вот это свойство позволяет человеку планировать игру с противником. с более умным противником. с противником человека. 

S00 [00:50:13]  : Алло, меня слышно, да? Можно я немножко расширю? Вообще это было сказано на начальной этапе рассказа, тут многое прояснилось. Но я хочу обратить внимание на такую вещь, которая наверняка очень важна. Это, например, что противник прикидывается тупым, тупым, тупым. Мы приспосабливаемся к его игре. Вот как тупой начинаем получать выигры, а когда доходит до серьезных каких-то вещей, он оказывается не тупым и запросто переигрывает этот алгоритм, который адаптировался под тупого человека, а мы уже стали умными, и мы запросто их переигрываем. Этот прием очень известен и эффективен. 

S04 [00:51:03]  : Да, конечно, игры являются одновременно и спортом, и развлечением. Соответственно, развлекательный компонент – это создать эмоциональные перепады у игрока. да, ну вот как раз данный прием отлично работает, чтобы подобные перепады создавать, а вот механизмы реализации уже могут быть совершенно разными. может быть и запрограммировано то, что мы просто переключаем в зависимости от действия игрока уровень сложности для компьютера, подстраиваемся под человек, поэтому вначале алгоритм тупит, а потом как начинает выигрывать. может быть реализован совершенно по-другому, может быть специально ограничение какие-нибудь мощности. во многих стратегических играх разные уровни сложности отличаются тем, что компьютер, какие у него в начале ресурсы и какие у него дополнительные бонусы происходят за ходом. на больших уровнях сложности у него больше ресурсов приходит на ход, теперь меньше, и за счет этого создается сложность 

S00 [00:52:16]  : На самом деле ситуация очень жизненная, она не только в играх существует, но и в реальных вопросах. И вопрос, который открыт, мне кажется, актуален, то, что компьютер просто, когда человек меняет стратегию, компьютер просто не успевает так быстро выучиться в силу того, что существующие алгоритмы, они очень медленно учатся. И поэтому человек может моментально что-то переключиться, и вот это переключение поймет только другой человек. Но интеллекту пока, мне кажется, такие вещи очень мало доступны. Смена тактики, когда он понимает, что его просто обманывали. 

S04 [00:52:57]  : И про примеры, и про тактики давайте поговорим попозже. По позже, на примере Старкрафта, ну где-то через полчасика, я думаю. 

S00 [00:53:08]  : Хорошо, спасибо. 

S04 [00:53:09]  : Нужные примеры подберем, поговорим как раз про такое. 

S02 [00:53:14]  : Хорошо, давайте тогда это отложим. Дальше у нас есть вопрос про хорошее состояние. Борис Новиков спрашивает, как определяется хорошее состояние? Откуда берутся оценки хорошести состояния? 

S04 [00:53:34]  : Смотрите, для этого существует ровно два способа. Первый способ, опять же, ну совсем его не назвать имитационный. Вот, значит, да, значит, вначале Когда мы ничего не знаем, вполне работает алгоритм, что мы считаем человеческий ответ всегда за лучший в данной позиции. Этот алгоритм позволяет научиться играть примерно на уровне человека. Иногда пониже, иногда похуже, но в общем-то уже является имитацией, но уже в другом смысле. имитация человека. является неплохим способом определять хорошие позиции. Если человек считает позицию хорошей, значит позиция хорошая. Если человек делает ход такой, значит этот ход хороший. А вот потом мы уже учимся на собственном опыте, начинаем учиться. Но для начала имитация как раз позволяет очень быстро, как еще это называют, еще это называют повторение за человеком, еще это называют, когда дети это делают, называют подражание. Значит, это подход, который позволяет не зная многого о мире и не умея хорошо планировать в окружении, просто неплохо себя вести. Соответственно, мы можем нейросеть обучить предсказание человеческого поведения и также себя вести. И, соответственно, у нас будет неплохое поведение. Можем и человеческую оценку позиций. Человек, не знаю, как учится ребенок. Если родитель хмурит брови, значит он сделал что-то не то. Не обязательно ребенок сделал что-то не то, значит положение плохое. Ребенок начинает плакать. Значит, если родители улыбаются, значит, наоборот, все хорошо, а возможно, значит, ребенок сделал что-то хорошее или другое. Тут на самом деле тяжело поначалу отличить правильное поведение от правильной ситуации в мире. Вот это разделение для имитации. для подражания является сложным моментом, но тем не менее со временем у нас вырастает вторая функция, это не только подражать, но и пытаться в модели мира самому понимать, что хорошо, что плохо, и вести себя наилучшим образом, чтобы не было в будущем плохого и наоборот, чтобы было в будущем хорошо. 

S02 [00:56:49]  : Спасибо. Следующий вопрос тоже от Бориса Новикова. Оценка – это вероятность выигрыша по выборке? 

S04 [00:57:00]  : Оценка позиции? Нет, смотрите. Оценка позиции – это предсказание. Это предсказание то есть предсказание означает, что это какая-то формула. но то, как это получается формула, за счет чего она получается? она получается за счет того, что мы даем ей примеры того, какая оценка хорошая, какая плохая. хорошая оценка, хорошая позиция – это такая, которая приводит к нашей победе через n ходов. а плохая позиция такая, которая приводит к нашему поражению. 

S05 [00:57:51]  : вручную по каждой позиции? 

S04 [00:57:55]  : нет, алгоритм нейросетью как раз можно эту формулу автоматически выводить. 

S05 [00:58:01]  : из чего? из вероятности выигрыша или как-то иначе? 

S04 [00:58:06]  : да, из вероятности выигрыша в данной позиции. 

S05 [00:58:09]  : значит все-таки это вероятность выигрыша в данной позиции? 

S04 [00:58:12]  : это не вероятность выигрыша в этой позиции, но это формула основанная на вероятности выигрыша в данной позиции. 

S03 [00:58:21]  : она должна быть эквивалентна вероятности выигрыша, потому что иначе она будет не оптимальна. 

S04 [00:58:26]  : она никогда не может быть до конца эквивалентна вероятности выигрыша, потому что, чтобы знать вероятность выигрыша, нам надо все ходы из этой позиции в глубину дальше просчитать. 

S03 [00:58:35]  : это понятно, это наша оценка вероятности. 

S04 [00:58:40]  : поэтому это оценка вероятности, это как раз предсказание, натренированная как раз на выигрышах и проигрышах для других позиций. да, понятно. 

S05 [00:58:52]  : почему на других? у нас есть выбор. 

S04 [00:58:56]  : нет, смотрите, у нас в шахматах 10 сотые позиции. мы не можем для каждой позиции предсказать хорошая у нас позиция или плохая. предсказать можем, не можем. не можем знать оценку выигрышей и проигрышей для данной позиции. поэтому мы натренировались на 10 степени позициях предсказывать, но для данной позиции мы не знаем, выиграем мы или проиграем, но мы можем предсказать. считаем ли мы, что мы выиграем или проиграем, исходя из данной позиции. 

S05 [00:59:30]  : а как предсказать? 

S04 [00:59:33]  : тренировать формулы нейронной сети, в которой мы знаем ответ в 10-й степени в вариантах, соответственно мы тренируем. тренируем формулу, которая как позиция кодируется в нейросети. мы положение каждой фигуры кодируем определенным образом на доске. точнее, немножко по-другому кодируется. кодируется одна плоскость – это положение данной фигуры 1, вторая плоскость – положение фигуры номер 2. на доске единички или ноли, то есть находится ли фигура в этой клетке. Если фигуры вообще нет, соответственно отсутствует. И так далее. Вот это все пространство подается на формулу, то есть на нейросеть, и вот эта формула нам какие-то математические действия производит с этой входной матрицей и получает предсказание. 

S05 [01:00:42]  : А эти математические действия определяются разработчиками? 

S04 [01:00:52]  : Да, возможные варианты действия определяются разработчиками. Конструкция нейронной сети. Сложение и умножение. 

S05 [01:00:59]  : нет, как оценить, эта формула задается разработчикам или она находится по обучающей выборке? 

S04 [01:01:07]  : по обучающей выборке вот этими десятой степени вариантами, которые мы реально наблюдаем то есть одна позиция сводится к другой? да, мы одну позицию учим по похожему оценке, по сути, да 

S05 [01:01:28]  : Спасибо. А вопрос можно? 

S02 [01:01:32]  : Пожалуйста, давайте. 

S05 [01:01:33]  : Задача вообще поставленная, как делать хорошие игровые искусственные интеллекты или как перейти от игровых интеллектов к интеллектам искусственным для жизненных ситуаций. 

S04 [01:01:50]  : Давайте сейчас поговорим вначале, если есть какие-то вопросы в рамках игровых искусственных интеллектов, то есть когда у нас есть ограничения на дискретное пространство шагов и дискретные ходы, а потом уже поговорим о том, обобщить это на более жизненные ситуации. 

S02 [01:02:13]  : Хорошо, тогда у меня есть предложение сейчас дать слово Сергею Терехову. У него есть рука. Ответить Сергею Терехову, а потом перейти к примерам и как раз к дальнейшему обсуждению, которое предлагается по переходу, по примерам и тактикам поговорить и про переход к настоящему ИИ. 

S03 [01:02:37]  : сейчас сергей пожалуйста еле спасибо за уже то что ты рассказал у меня вот на самом деле просто логически вопросов когда ты говоришь модель среды то ты немножко тут надо некоторое уточнение но если мы говорим например про шахматную доску то моделью среды является просто сама среда там нечего моделировать потому что там полностью наблюдаемая ситуация но только там с точностью до того, ходил ли там король перед таргировкой или нет. эту информацию надо где-нибудь на бумажке рядом записать, если она не восстанавливает ретроспективы. но в принципе модель совпадает с самой средой. если я правильно понимаю тебя, когда ты говоришь о модели среды, то ты рассматриваешь такую ситуацию. разработчик игры создает среду. Агент играющий и человек играющий находятся в равных условиях. Ни человек не знает, по большому счету, что там внутри компьютера с ним будет играть, ни агент, который с ним соревнуется. Вот в этой ситуации агенту, который искусственный, ему нужна модель среды. Если же разработчик создает этого агента прямо вместе, как говорится, из коробки, то тогда этому агенту не нужна модель среды, потому что он имеет прямой доступ к тому вычислителю, который, собственно, вычисляет среду. Ему не надо моделировать, ему надо просто ее сосчитать. То есть ему не надо ничего не предполагать, она просто ему дана. Вот ты рассматриваешь на самом деле, я так понимаю, что ты все же не можешь рассказать, естественно, за такое короткое время. Да, да. 

S04 [01:04:07]  : То есть ты рассматриваешь именно вот эту ситуацию, когда агент искусственный играет... Не то, что я рассматриваю такую ситуацию, но помните, я говорил про то, что точность моделирования среды существенно влияет на результат. 

S03 [01:04:22]  : понимаю, но если агент является частью этой среды, он полностью не осведомлен, то он побитно получает точную информацию. Ему же не надо что-то придумывать об этой среде предполагать непрерывность какой-то или что-то еще он просто если он доступ к симулятору имеет прямому прямо вот тому который наличие доступа к симулятору не означает полные знания о ситуации почему как же так ты ты агенту сообщаешь ровно то что ты сейчас покажешь на экране человека на 100 процентов абсолютно. 

S04 [01:04:54]  : это всего лишь точное делание следующего хода. но это не означает то, что мы сумеем предсказать по этому симулятору, что будет через 10 или через 100 ходов. 

S03 [01:05:02]  : непонятно, извини. если люди не меняют ситуацию, то симулятор прогнозирует полностью все однозначно. 

S04 [01:05:12]  : даже для шахмата это не так, потому что есть второй игрок, которым мы не управляем. 

S03 [01:05:17]  : вот это был вопрос к тебе входит ли второй игрок в модель мира если входит туда конечно после этого надо моделироваться 

S04 [01:05:25]  : не может входить в модель мира, потому что мы не можем все ходы за него просчитать в рамках симулятора. 

S03 [01:05:31]  : нет, я имею в виду не в смысле входит модель мира, а входит в необходимость его моделирования вместе с моделью мира. 

S04 [01:05:37]  : необходимость его моделирования в практике определяется. 

S03 [01:05:43]  : вот это вот и собственно поэтому я и вопрос тебе задаю, хочется терминологически разобраться. итак, у нас есть три участника для простоты. есть симулятор, он же компьютерная программа, которая либо вероятностна, либо невероятностна, в зависимости как захотим. Это некоторая среда. Эта среда про себя все знает. 

S04 [01:05:59]  : Среда тоже бывает детерминированная, бывает не детерминированная. 

S03 [01:06:04]  : Я об этом и говорю. Если эта среда не содержит случайных чисел, она детерминированная какая-то, например шахматы, то тогда в этой среде заранее известно, что там будет происходить. теперь есть два участника, один живой, другой не знаем какой, агент. они оба поставлены в симметричные условия, и один и другой должны что-то предположить об этой среде, построить у себя какой-то образ этой среды, промоделировать ее. и тогда тот, кто это сделал лучше и глубже, и надежнее, и быстрее, тот и выиграл. промоделировать второго участника в том числе. в том числе, конечно, игровой ситуации. то есть на самом деле ты рассматриваешь именно вот такую ситуацию, а шахматы ты привел просто для удобства. 

S04 [01:06:42]  : конечно, шахматы я конечно привел просто для удобства. да, понятно. В общем-то, может быть, недетерминированные шаги могут приводить к недетерминированным результатам. 

S03 [01:07:02]  : Понятно. Дальше понятно. Главное, когда ты говоришь, что можно построить модель, то кому нужно построить? Ответ. Тому искусственному агенту, который в этой игре находится в равных условиях с человеком. Вот ему надо построить модель среды. 

S04 [01:07:19]  : вот как раз мы в шахматах, поскольку есть только одна задача игровая – победить. поэтому у нас моделей получается, что нужно всего 2. модель противника – это модель самого себя. потому что чем лучше шахматы относятся к таким играм, чем лучше играет противник, тем точнее мы его моделируем. где камень-ножницы-бумага значит оптимальная стратегия и там все совсем по-другому. 

S03 [01:07:58]  : есть более сложные варианты, где надо моделировать. это вопрос был термологический, спасибо за ответ. 

S04 [01:08:13]  : в более простой ситуации у нас одна задача всего, которую нужно решать. у нас не переключается задача, которую мы решаем. у нас не нужно нейросети, в которой хранится текущая задача. вместо этого у нас есть Оценка этой задачи, опять же, определяется одной нейросетью. Оценка того, достигаем ли мы цели или нет. Это как раз оценка value network. И у нас ровно есть одна сеть в этом случае, поскольку второй игрок, противник, это то же самое, что и мы, то у нас есть ровно одна сеть, опять же, которая делает, предсказывает действия игрока. это полис метод. таким образом получается, что в данном случае, в случае шахмат, нам достаточно этих двух сетей. а вообще в более общем случае этих сетей получается нужно как минимум 4. нужно нейросеть, которая которая следит за тем, какая сейчас у нас задача или какая наилучшая задача сама на себя предсказывает, какую задачу лучше решать сейчас. Нужна также policy network, которая будет управляться через value network. зависит от value-network и зависит от той задачи, которую мы решаем. Value-network, в свою очередь, значением той задачи, опять же определяется от задачи того, близки ли мы к ее достижению или нет. И нам нужна для предсказания среды, для предсказания возможных ходов, в принципе, то есть можем ли мы так поступить и будет ли нам плохо сразу, то есть без рамок задачи, а вообще в целом в мире будет ли нам плохо, нам нужна для этого еще одна среда. 

S02 [01:10:05]  : То есть нужна когнитивная архитектура примерно из 5-6 нейросетей, решающих разные задачи. 

S03 [01:10:11]  : Юрий, это ты сейчас рассказал не объективную потребность, а ты рассказал некоторые способы, как ее реализовать. Вот известный способ, один из них, это способ. Это же не обязательно, что они именно вот так должны быть устроены. 

S04 [01:10:24]  : в общем-то вариантов альтернативных немного, то есть или хардкод, или же у нас есть какой-то кусочек, который будет предсказывать все дело. и вот в общем-то model-based reinforcement learning, он примерно весь к этому сводится. в разных работах выделяют 3 сетки, 4 сетки, не знаю. Это обсуждение реализации. 

S02 [01:10:56]  : Хорошо. Юрий, я предлагаю двинуться дальше. У нас еще был вопрос от Тролля. Приходил Тролль, интересовался, можно ли что-нибудь рассказать про прогнозы лотерей. Но поскольку Тролля забанили, то можно на этот вопрос не отвечать. Вот, но есть рука Бориса, но Борису, я думаю, мы позже ответим после оставшейся части доклада вместе с остальными вопросами. Давайте, Юрий, дальше двинемся. 

S04 [01:11:21]  : Да, давайте я еще на вопрос Владимира Фролова и комментарий его. Значит, про дисперсию выигрыша отвечу, что да, действительно, это правильный, очень правильный момент. да, смотрите, есть статистики, если мы считаем предсказание по какому-нибудь вопросу, то у нас в общем-то в этом предсказании фигурирует всегда средняя и дисперсия. Эта дисперсия полезна следующим образом. Если мы считаем пессимистичный, наихудший вариант, то нам нужно корень из этой дисперсии на некоторый коэффициент отнять. А если нам нужно наоборот получить наиболее вероятный из позитивных результатов, оптимистичную оценку сделать, то нам наоборот нужно прибавить дисперсию. Поэтому так получается, что дисперсия действительно участвует в оценке. То есть нам нужно не только среднее, нам нужна еще и дисперсия для того, чтобы оценить не средневероятный вариант, а то, насколько плохой может ситуация стать в среднем. Если мы сходим тем или иным образом. И вот замена функции с нейтральной функции среднего выигрыша на функцию пессимистичного выигрыша, она дала существенное увеличение рейтинга AlphaGo, AlphaZero. Спасибо. Дисперсия действительно влияет, действительно помогает, но чуть-чуть по-другому. 

S03 [01:13:18]  : Юр, ты термологически немножко все-таки запутываешь. Юр, ты запутываешь немножко. Смотри, статистическая оценка – это статистическая оценка. Ты оцениваешь от ожидания, оцениваешь дисперсию, если тебе двух этих оценок достаточно. Если более сложный закон, больше коэффициентов нужно. А то, о чем ты говоришь, например, Upper Confidence Bound, это уже способ принятия решений на основе этой оценки. То есть оценка, она есть оценка, она не предполагает какого-то ее использования. А дальше есть алгоритм принятия решений, который может эту оценку превращать в какой-то score, на основе которого принимаются решения. 

S04 [01:13:55]  : Скор, по которому принимает решение value function, он оценивает, точнее, как мы оцениваем под граф value function, мы используем lower confidence value. место среднего. 

S00 [01:14:21]  : я задал вопрос с такой позиции, что типа досчитать, какую ветку мы будем досчитывать, чтобы уточнять, если там дисперсия побольше, наверное нам как-то лучше именно ту ветку, в которой дисперсия побольше, лучше досчитывать. 

S04 [01:14:35]  : лучше досчитывать ту ветку, где больше наш выигрыш. 

S00 [01:14:41]  : это сочетание двух факторов, и дисперсии, и выигрыши. то есть мы имеем какое-то пересечение, вот если смотрим, эти дисперсии пересекаются сильно. 

S04 [01:14:51]  : мы можем их объединить в upper confidence bound. эти два фактора вместе в один, потому что по двум факторам мы все равно не можем понять лучше или хуже. то есть нам их как-то объединять надо вместе. и вот как раз на основе upper и lower confidence level мы можем их объединять в единый фактор, по которому оцениваем. чисто дисперсия не является таким фактором. то есть она одним из факторов является, но чисто по ней нельзя сказать какую ветку лучше оценивать. это вредно. 

S00 [01:15:27]  : спасибо, наверное стоит дальше пойти по теме. 

S04 [01:15:31]  : так, ну хорошо, тогда давайте рассмотрим еще какие-то примеры, контрпримеры того, которые могли бы как-то опровергнуть опровергнуть работу данной системы, например, это действительно варианты камень-ножницы-бумага только для компьютерных алгоритмов. Смотрите, в том же StarCraft у нас есть выбор того, или мы строим, или мы делаем экспансию, быстро строим, после первой базы развиваем вторую базу и третью базу. если нам кажется, что на нас противник вряд ли будет нападать в первые 7 минут, называется fast expand. Или же мы не строим вторую базу, а сразу строим воина, сами идем нападать на противника. Называется Rush стратегия. или же мы строим более сильных юнитов, что занимает некоторое время. вторую базу не строим, потому что она не сразу начинает оккупаться. строим более сильных юнитов и этими юнитами через некоторое время побеждаем более слабых юнитов противника. стратегия технического превосходства. Каждая стратегия работает против определенной другой стратегии. стратегия быстрой атаки. ее можно, если во время технологического развития найти способ защиты от первой атаки, то противник построит юнитов не очень мощные, а мы потом его обыграем более мощными юнитами. другой вариант, мы построим вторую базу, пока он будет уничтожать первую, мы разобьемся около второй базы. у нас будет больше ресурсов, мы его победим. таким образом в старкрафте насчитали штук 9-10 вот этих элементарных стратегий. ни одна из этих стратегий не лучше другой напрямую. В общем-то, в человеческом сообществе тоже можно наблюдать разные стратегии. И нельзя сходу сказать, что одна стратегия лучше другой. Этот феномен известен как равновесие Nash. Система агентов Nash, как там точно называется. я уже что-то подзабыл. мы можем победить противника, если мы знаем как он будет играть. но если мы не знаем как он будет играть, то у нас есть только вероятность определенно его победить, если он выберет тот подход, который который победит именно, если наш подход окажется лучше подхода противника. поэтому мы не можем учить одного робота для старкрафта. мы должны учить как минимум 10 роботов для Старкрафта, причем можем разными способами, генетически или просто хранить 10 разных весов для модели Старкрафта и давать им играть друг с другом. В результате происходит то, что все 10 этих моделей начинают играть лучше. но если мы оставим одну модель, которую будем все время стравливать с собой, она не достигнет высокого результата. этот момент важен, если мы говорим про такие же симуляции. в шахматах такого делать не надо. Это еще одна причина, которая усложняет эксперименты с данными технологиями, потому что нам нужно не одного бота учить, получается 10 или даже 100 ботов, моделировать целое человеческое сообщество, возможно даже, какие-то между ними взаимодействия. Дальше. дальше значит. Другие еще опыты, проведенные с игровым искусственным интеллектом, например, показали, что мы не все знали о Старкрафте. Например, выяснилось, что компьютер в определенной ситуации научился извлекать ресурсы примерно на 25% более эффективно, чем это делали спортсмены, специалисты по Старкрафту. То есть оказалось, что в определенных ситуациях можно строить больше немножко дронов. Это немножко замедляет поначалу развитие, но при определенных условиях. Они извлекают больше ресурсов, а также они могут использоваться для других задач, и построенные раньше дроны оказываются полезными. Это второй интересный вывод был. Такие выводы практически в каждой игре определяются, узнаются. Например, в шахматах. ходы крайними пешками, вот этими крайними пешками стали более высоко цениться, в том числе даже королевской пешкой, хотя если король реагирует в короткую сторону, раньше ход h2-h4 считался скорее таким более плохим, а сейчас благодаря компьютеру он считается гораздо более эффективным. он помогает достаточно часто, потому что он редко угрожает собственному королю, но во многих случаях позволяет усиливать атаку на вражеского короля. Таким образом, компьютер в процессе экспериментирования открывает более эффективные способы решения задачи, но безусловно на это он тратит огромные ресурсы. значит хорошо это или плохо в общем-то непонятно то есть человек тоже тратит много ресурсов и тоже также в различных играх у нас наблюдаются линии игроков которые позволяют в целом продвигать игру вперед еще один пример такой который позволяет оценить компьютер и одновременно посмотреть чуть-чуть с другой стороны, это специальные контрстратегии и специальные трюки. Значит, один человек попробовал высадку десанта против компьютера в том месте, где компьютер не видел. И компьютер, обученный играть с другими компьютерами, он, оказывается, эту высадку десанта в рамках этих десяти стратегий победителей не делал. И с этой высадкой десанта человек выиграл компьютер. Это входило в тот один процент человеческих побед над компьютером StarCraft. Но потом компьютер доучили. на большем количестве игровых видео, видео, точнее записи игры, там можно записывать как раз игру. И компьютер тоже иногда научился высадку десанта, а главное, он научился более грамотно противостоять высадке десанта, и высадка десанта стала неэффективной в StarCraft. Возможно, компьютер давным-давно тоже практиковал высадку десанта, но потом он научился ей успешно противостоять, поэтому лучшие стратегии перестали использовать высадку десанта, а потом компьютер забыл, как от этой высадки защищаться. А потом уже компьютер не переизобрел высадку десанта, потому что это, ну, некоторые там совсем отдельные действия, потому что надо вначале построить транспортник, погрузить туда, значит, солдат, а потом их отправить в специальное место, далеко необычные на карте, где нет защиты, где нет видимости врага. Соответственно, случайным перебором заново такую ситуацию без наблюдений за поведением людей и игроков не промоделировать. поэтому это как раз к тому, что стратегия вот такого тупого reinforcement learning, не всегда лучшая стратегия, подражательная даже на высоких уровнях игры, вносит какую-то дополнительную пользу, имеет какой-то эффект. что касается уроков, извлеченных на игровых интеллектах и на том, как они играют. Ну, а как вы знаете, на играх, на тренировке компьютеров в игру Dota построили вероятность того, что данная команда из пяти героев победит и действительно оказалось что в игре есть герои получше и похуже и более того есть комбинации героев которые лучше и хуже ну напоминаю что каждой стороне там нужно выбрать пять героев и влияют как твои герои так и герои противника тоже там есть контр игра то есть некоторые герои лучше помогают против других героев и наоборот значит должны быть там дальнобойные есть игроки есть там игроки наоборот которые там массовые умеют делать какие-то эффекты заклинания и соответственно должен быть определенный между ними баланс там определенный подходит или не подходит друг к другу соответственно это отдельная подигра который компьютер компьютер должен был научиться, чтобы эффективно играть в футбол. Это была секция про навыки, извлеченные из игрового компьютерного интеллекта, и которые нужно учитывать при построении GI. То есть то, что подражание остается полезным, даже когда компьютер очень умный, И действительно, подражание – это тот метод, которым компьютер может очень быстро и очень легко обучиться играть на неплохом уровне. Или даже проходить игру. И было показано, что робот, который может ходить, у которого много степеней свободы, если его учить подражанием, он действительно намного быстрее обучается, чем нежели собственными экспериментами по случайному движению руками, ногами, падениями и так далее. У нас есть некоторая конструкция из таких нейросеток. Рецепт построения искусственного интеллекта. Строим набор нейросеток, каждую из которых учим на определенной целевой функции, имеем определенные связи между нейросетками, которые отражают и их положение во внутренней какой-то иерархии, во внутренней мозгу компьютера. Дальше учим каждую нейросеть вначале по отдельности, возможно, на практических задачах, дальше учим их вместе, взаимодействию. Поначалу, возможно, учим методом подражания, Значит, потом приступаем уже к собственному. Включаем все-таки полную силу, они уже сами какое-то поведение реализуют. В общем, такой вот рецепт построения общего искусственного интеллекта, я предлагаю. Так, ну вот теперь третья секция, давайте по ней, может, какие-нибудь вопросы, комментарии, предложения. Так, Антон, вас не слышно. 

S02 [01:29:01]  : Извиняюсь, была рука Бориса Новикова, поэтому вот я предлагаю сейчас Борису, а потом Сергею. 

S05 [01:29:08]  : Да, спасибо. Первый вопрос. Все-таки интеллектом мы считаем некоторую агенту, которая решает уже поставленные задачи в рамках определенной модели, или то, что обладает сознанием, существует во внешней среде, создает модели, поставит задачи, а потом их решает? 

S04 [01:29:39]  : Ну, вы можете систему совершенно по-разному делить, на разные модули, поэтому ответ на ваш вопрос будет зависеть от того, как вы поделите систему, на какие модули. Поделите вы, что у нее есть модуль сознания, но будет, значит... Нет, мне представляется, что здесь есть принципиальное различие. 

S05 [01:29:56]  : Все игровые ситуации – это ситуации закрытых систем. В каком плане закрытая система? 

S04 [01:30:05]  : Старкрафт закрытая система? Кто? Старкрафт. Не знаю. Вот у нас много всяких там юнитов, которыми можем управлять, в которых есть определенные действия. Вот это закрытая система или нет? 

S05 [01:30:22]  : Да. Если нет ураганов, отключений электроэнергии, метеоритов и так далее, это закрытая система. 

S04 [01:30:31]  : А чем отличаются ураганы отключения электроэнергии от воздействия другого игрока? 

S05 [01:30:37]  : тем, что воздействие другого игрока заранее определено правилами игры, а жизнь не определена никакими внешними... Подождите, подождите. 

S04 [01:30:50]  : Вот мы подкидываем кубик, вот этим кубиком определяем, выключится сейчас электроэнергия или нет. Вот, пожалуйста, мы запрограммировали отключение электроэнергии. 

S05 [01:31:01]  : В реальности. потенциальных переменных бесконечно много. 

S04 [01:31:08]  : Я про это говорил. Я про это говорил, что есть не дискретное число шагов и не дискретное пространство. 

S05 [01:31:15]  : Все равно у вас есть трехмерное пространство или несколько элементов, несколько степеней свободы и всего несколько числовых переменных. 

S04 [01:31:27]  : Нет, может быть много. 

S02 [01:31:28]  : Борис, извините, я здесь мешаюсь, потому что, ну извините, еще лет 30 назад, я помню, была так в первых версиях Сим Сити, там и землетрясения были, и наводнения, и Годзилла приходил и небоскребы топтал. И здесь мы говорим просто о количестве переменных, количестве степеней свободы и количестве неизвестных. То есть, если считать, что количество атомов во Вселенной конечно, то там тоже нет никакой неопределенности, просто мы не можем это все обсчитать. Ну и современные компьютерные игры, их сложность экспоненциально растет со временем и они становятся все более и более стахастичными в этом смысле и движутся вот в ту сторону. 

S05 [01:32:16]  : Я про что хочу сказать, что мы строим модели выделяя существенные факторы для нашей ситуации и для наших глядачей. 

S04 [01:32:25]  : Вы строите так модели? 

S05 [01:32:27]  : Так строятся все модели. 

S02 [01:32:32]  : Хорошо, но давайте все-таки вопросы привлечь. 

S05 [01:32:34]  : Вопрос такой. Модель и задача фиксированы или нет? Или они создаются этим интеллектом? 

S04 [01:32:45]  : По-разному может быть. 

S05 [01:32:46]  : Как хотите, так и делайте. Интеллект – это то, что работает по решению заданных задач. 

S04 [01:32:53]  : Я предлагаю не соревноваться определениями интеллекта. Значит, давайте мы будем на этом семинаре вообще не определять понятие интеллект. По мне, это бесполезное абсолютно занятие, потому что Это понятие вспомогательное. Вот если мы делаем что-то, вот мы для этого определяем интеллект. Делаем что-то другое – определяем интеллект по-другому. Какой смысл определять интеллект каким-то образом без того, чтобы что-то делать? Нет никакого смысла. 

S02 [01:33:32]  : Так, Борис, все-таки вопрос еще раз сформулируйте. 

S05 [01:33:36]  : Поэтому просьба без определений. Работает на решение конечного числа задач в конечном множестве заданных конечных моделей. Или он работает физически в реальности и сам строит модели, исходя из своих целей там выживание себя своего по-прежнему сам что значит сам строит модели выделяет существенные переменные если он выделяет несущественные переменные он строит модель если он несущественные переменные выделяет он строит модель в модели всегда конечное число переменных 

S04 [01:34:23]  : Ну у человека всегда в голове конечное число переменных, у него нейронов конечное число. 

S05 [01:34:29]  : Вот именно. И поэтому каждый человек работает со своим ограниченным множеством моделей и ограниченным множеством задач. Один занимается квантовой механикой, а другой… Хорошо, Борис, вопрос. 

S02 [01:34:44]  : Вопрос. Нет, ну не по этому вопросу. 

S05 [01:34:46]  : Что рассматривается по строению моделей, описывающих реальность? Рассматривается как задача интеллекта или не рассматривается? А это часть задачи интеллекта. Работа в заданных моделях. 

S04 [01:35:01]  : Это компонент. Вот смотрите. Каждая нейросеть, она так или иначе описывает реальность. Policy function описывает реальность о том, как лучшие люди или лучшие компьютеры ходят данные. Function value оценивает реальность с точки зрения, как побеждает ли данная позиция или нет. 

S05 [01:35:21]  : Но все это в шахматной партии, или в партии ГОИ, или в какой-то другой. 

S04 [01:35:27]  : Какая разница? 

S05 [01:35:29]  : Смотрите, Борис, вы в рамках детерминистской логики, как я вижу. Что полезно будет, чтобы вас из этой логики выбить, это следующее. 

S04 [01:35:56]  : функция от задачи и текущего состояния. мы эту функцию обучаем. Теперь смотрите, вот эта задача, она может быть не дискретной, она может кодироваться 500-мерным вещественным пространством, например, и описывать в этом пространстве все задачи, которые когда-либо решают, могут и решать люди, не обязательно даже решают, а могут и решать люди. И мы можем эту функцию сразу целиком учить, без того, чтобы говорить, а если вот у нас задача такая, какая же будет у нас функция, а если у нас задача такая, вот такая будет, какая будет функция. Понимаете? 

S05 [01:36:51]  : Количество задач задано? 

S04 [01:36:54]  : Нет, нет. Бесконечное. 

S05 [01:36:58]  : А как? 

S04 [01:36:59]  : Бесконечное произвольное. 

S05 [01:37:00]  : Тогда откуда вы возьмете обучающее множество? 

S04 [01:37:04]  : Ну какие-то конкретные, случайные будут задачи, наблюдающиеся на практике. 

S02 [01:37:17]  : можно я по-другому задам вопрос смотрите вот окей мы взяли вот там вот обсуждение можно я попытаюсь вот со своей может быть другой вопросом может быть тот же самый задать и сергей извиняюсь что я влез просто вот как бы я про то же самое я про то же самое только тоже тоже по-другому хорошо ну сейчас значит у нас есть еще время смотрите У меня вот такой вопрос. То есть, как там пишет ваш, интерпретирует вас Алекс Бур в чате, что рецепт для построения AGI – это взяли много нейросеток, которые разные вещи оценивают, и их соединили. И в итоге у нас получится AGI. Вот, но у меня вот так преломляется через такую когнитивную архитектуру, значит, множество правильным образом соединенных нейросеток. Вопрос Бориса Новикова. А что будет, если мы вот эту вот конструкцию там из пяти-шести нейросеток сначала научим играть в шахматы? А потом попытаемся их научить играть в ГО. А потом попытаемся научить их чинить бачок от унитаза. А после этого, после отремонта бачка от унитаза, пойдем попытаемся поиграть снова в шахматы. Не выяснится ли у нас, что... Ну, понятно, да? Что же, это будет работать? Будет. 

S04 [01:38:38]  : Более того, это будет работать лучше, и это на практике действительно уже работает лучше для больших сеток. Только для очень больших сеток. 

S02 [01:38:46]  : Маленькие сетки должны быть такие, чтобы в них утрамбовывались разные модальности. 

S04 [01:38:53]  : Да, более того, они даже помогают друг другу. Разные знания. 

S05 [01:38:57]  : Но если рассмотреть задачу предотвратить... сближение галактик Внешний Путь и Андромеду, у вас не будет обучающей выборки и не будет решения. 

S04 [01:39:11]  : Нет, смотрите, виртуальные пространства при задаче моделирования это вполне себе часть модели реальности. Мы можем вполне себе в рамках задачи, например, взять листочек, написать что-нибудь на этом листочке, что-нибудь там решить. Это вполне себе часть реальности моделирования. То есть получается модель, которая использует другие модели. 

S05 [01:39:36]  : Таких задач можно придумать бесконечно много. Нельзя обучить нейросеть неопределенному кругу задач. 

S04 [01:39:47]  : Почему? 

S05 [01:39:49]  : Потому что он неопределенный. Всегда можно добавить задач, которые еще не обучили нейросеть. Но это все равно как натуральное число. Не существует максимального. 

S04 [01:40:00]  : Ну не совсем так. То есть нейросеть может экстраполировать по имеющимся задачам решение новой задачи. То есть не обучая всем задачам в мире, мы можем научиться решать незнакомые задачи, на которых не тренировались. 

S05 [01:40:15]  : Незнакомые из определенного подмольства. Всегда можно придумать задачи, не входящие в это подмольство. 

S04 [01:40:22]  : Нет, ну всегда можно придумать такую задачу. Более того, можно даже сразу сказать, взять просто очень сложную задачу, не обязательно из какого-то ее подложства выбирать, сказать вот решить теорию фирмы. Не решил, значит не можешь решить все задачи. Все. Это не универсальный искусственный интеллект. Все. Зачем нам это искать даже специальным методом ту задачу, которую искусственный интеллект не может решить. Вот все, просто взяли достаточно сложную задачу. Все. 

S05 [01:40:52]  : Как раз искусственный интеллект может решать определенную задачу внутри определенной модели. И это хороший искусственный интеллект. Создать модель под любую задачу, не сформулированную, это не задача интеллекта. 

S04 [01:41:14]  : Ну, вы опять свои определения просто предлагаете нам использовать. Я не согласен с вашими определениями. 

S05 [01:41:21]  : А тогда дайте свое. 

S02 [01:41:24]  : Хорошо. Борис, ну давайте все-таки мы дадим возможность еще Сергею высказаться. Спасибо. 

S05 [01:41:29]  : Да, спасибо. 

S04 [01:41:32]  : Потому что я не считаю, что то, что я дам какое-то определение, как-то поможет. 

S03 [01:41:39]  : коллеги юр еще раз спасибо за теперь уже как-то отдельное спасибо за отдельную часть значит но многие вещи действительно уже уже этом озвучили с разных сторон я на самом деле хотел маленький комментарий сделать вот какой ты конечно опять-таки педагогических целях я понимаю тебя приводишь проводишь аналогию между непрерывностью и бесконечностью то есть говоря о том, что как только у тебя что-то там какое-то непрерывное, там очень много континуума или там какое-то счетное число каких-то состояний, ты сразу из этого как бы двигаешься. но надо понимать, что сама по себе вот эта континуальность состояний, она не обязательно эквивалентна сложности игры, потому что принципиальным является те элементарные множества, в которых нужно поменять решение. то есть, грубо говоря, районы. То есть, есть огромные классы эквивалентности, которые континуальные, но конкретное положение вот в этом континуальном пространстве не важно, потому что решение в этот момент ты не собираешься менять. Вот принципиальным является сложность состоит в том, сколько раз тебе условно говоря, сколько у тебя таких районов. То есть, сама по себе континуальность постановки задачи не значит, что она сложная континуально. потому что там есть простые интересные примеры, там можно об этом говорить. Короче, я просто предлагаю тебе, видимо в разных аудиториях по-разному нужно это говорить, но континуальность самой числа переменных, в которых происходит явление и процесс управления этой ситуацией или игра в ней, это вещи необязательные, то есть может быть действительно дискретное и вполне себе довольно простое количество и классовой эквивалентности, между которыми надо выбрать. а вся среда непрерывная. 

S04 [01:43:33]  : хорошо, вот возьмем старкрафт. это дискретная среда или непрерывная? 

S03 [01:43:39]  : я к сожалению детально не знаком со старкрафтом. 

S04 [01:43:43]  : я сейчас опишу. для других тоже будет полезно. значит у каждой стороны есть до 200 юнитов. У каждого юнита есть состояние здоровья, тип и координаты. координаты дискретные, но на большом пространстве, то есть они могут быть по пиксельному, то есть близко к непрерывному. Кроме того, у нас еще есть строение. Строение не считается в числе юнитов, строение на практике штук 30. У каждого строения что-то может строить в данный момент времени. У нас есть то, какое место на карте сейчас показано. И количество еще ресурсов. Ресурсов три типа. У них числовые значения. Ресурсы добываются и тратятся. Опиши пространство решений. У нас получается порядка тысячи переменных. 

S03 [01:44:51]  : Это переменное состояние. 

S04 [01:44:53]  : А я прошу переменное решение. Для действия, соответственно, каждый юнит может куда-то двигаться. У него есть точка движения. Или же он кого-то атакует, тогда, соответственно, у него есть состояние выстрела. Выстрел сейчас устреляет, будет готов к выстрелу через какое-то время, там перезарядка идет. Вот у нас состояние действия. Соответственно, мы можем каждый момент времени, 60 кадров в секунду условно, или 30 кадров в секунду, 30 раз в секунду что-то сделать, поменять каждому юниту направление его движения. координаты или в здании что-то сделать, сказать юниту построить здание. получается до 250 элементов мы можем сказать, что мы можем делать. 

S03 [01:45:54]  : давай попробуем это в термина шахмат. у нас есть 250 шахматных фигур. но кроме того их расположение на доске у этих фигур еще есть дополнительные атрибуты там типа там энергетическая готовность к чему-то память о предыдущих состояниях там заряжено ружье не заряжено время задержки там и так далее вот действия которые я делаю я могу объединить в класс эквивалентности ну то есть вот я куда-то направил какую-то фигуру 

S04 [01:46:20]  : то есть у нас для фигуры мало того, что минимум 1000 на 1000 координат. но многие области эквивалентны. вот ты когда ее куда-то направляешь, ну допустим, да, по сути скорость у него, у него есть поворот, то есть он тратит время на то, чтобы повернуться, если он не движется в направлении, то есть по сути он может или поворачиваться или двигаться, то есть у него скорость движения может быть вперед. или же или же поворот. 

S03 [01:46:52]  : ну окей, то есть это на грани. 

S04 [01:46:56]  : с одной стороны да, у нас все дискретное, с другой стороны этого дискретного настолько много. 

S03 [01:47:03]  : это понятно. это вот количество качества. я как бы немножко не про это. я просто хочу сказать следующее. вот то, о чем говорил Борис. ну давай сначала свой вопрос задам. вопрос у меня вот какой. Вот примеры, которые ты привел, начиная от шахмата и кончая по-видимому вот этими соревнованиями, они все носят такую общую идею. Там в каком-то смысле надо победить. То есть они внутри себя содержат вот это вот нечто победить. А побеждаешь ты всегда противника. Ну то есть тебе нужно не как-то абстрактно победить, а нужно победить вот этого противника. Если ты победил всех противников, то у тебя самый высокий рейтинг. У тебя не осталось противников и так далее. То есть это такой вот интеллект, который ориентирован на достижение задачи, повышение функции оценки, то есть превосходство какое-то выраженное в каких-то скорых и так далее. И естественно из него ты привел примеры, что изучая этот интеллект, изучая его особенности, как его можно строить из-за очень большого пространства. простое, простой, так сказать, случайный там выбор потенциальных действий практически затруднен. И, значит, можно действительно вот эту высадку десанта методом случайного, так сказать, эксплоринга, так сказать, никогда и не найти. Действительно, это засмысленное время просто из-за большого количества этих самых переменных. Но то, о чем спрашивает Борис, он говорит вот о чем. Вот если функция победить, то есть получить некий скор выше скор всех остальных или выше скор того турнира, в котором ты играешь, это как бы некая такая одна мета-функция, то есть такая мета-задача набрать максимальный скор в условиях данной игровой ситуации. Это условно говоря один класс задач. А потенциально ведь могут быть задачи, не сводимые к набору максимального скорого. Например, какие-то созидательные задачи, открытие нового способа добычи энергии. Или какая-нибудь созидательная задача, поиск новой защиты от каких-то вирусов, которые на нас нападают. Или что-то еще. Про вирусы, кстати, это напрасно, это не в эту копилку. то есть когда задача не сводится в конце концов к некому скору одномерному или парочке скорингов. 

S04 [01:49:32]  : если это еще не вопрос, то давайте я отвечу на вот эту часть. 

S03 [01:49:36]  : это наверно вопрос. грубо говоря, игры с природой, вот о чем. 

S04 [01:49:41]  : вот смотрите, на самом деле, вот у нас есть куча разных юнитов, значит даже в рамках того же старкрафта. ну старкрафт будет чуть поудачнее чем шахмат, хотя можно в общем-то и в шахматах посмотреть. сейчас какую-нибудь игровую ситуацию. 

S03 [01:49:56]  : если она будет сложная, то мы ничего не поймем, а ты вот просто ее упрости до сути. 

S04 [01:50:01]  : вот простая ситуация. значит юнит строит здание, при том он сам даже умирает в процессе. значит то, что юнит строит это здание, как это помогает победить для начала? то есть он делает какое-то совсем другое действие, никого не убивает других юнитов. 

S03 [01:50:24]  : локально да, а глобально да. а глобально он работает все равно на общий скор. 

S04 [01:50:30]  : Но также и человека можно сказать, что человек глобально работает на общий скор, который заключается в том, что человек будет доволен, рад, счастлив и так далее. И в рамках этого человек будет счастлив от чувства собственной важности, когда он что-то изобретет. Вот тут как раз у чего место происходит. 

S03 [01:50:56]  : вот если у тебя вот этих переменных счастья много и потенциально неограниченное число, то что хотел тебе сказать Борис? то есть пока у тебя переменных счастья одна или две, ну то есть это победить и победить как можно быстрее или победить. у человека она одна, победить в жизни. ну окей, хорошо, но это это совсем нас далеко уведет гораздо дальше, чем определение искусственного интеллекта. я просто хочу сказать, что сложность ситуации можно описать в количестве вот этих потенциальных переменных, в отношении которых ты собираешься что-то оптимизировать. вот если пространство этих измерений хорошести открыто, то о чем тебе говорит Борис, вот тогда мы получаем задачу, когда практически невозможно собрать выборку, решая одни целевые задачи для улучшения работы в другой. Если независимо от количества переменных, которое может быть континуум, независимо от количества управлений, которое тоже может быть континуум, Но количество вот этих скоринговых осей, ну я совсем упрощаю тоже, оно конкретно, конечно, пусть какое-то там 10 даже, но оно заранее задано, то это то, что называют Борис условно говоря игровая картинка. А вот реальная картинка это когда количество этих осей открыто. количество ценностей, которые ты можешь достигать, оно открыто. Борис, я правильно примерно формулирую тот вопрос, который вы хотите? 

S05 [01:52:24]  : Правильно. 

S03 [01:52:26]  : Спасибо. 

S05 [01:52:27]  : Реальная задача всегда многокритериальная оптимизация и, как правило, неформализованная. 

S03 [01:52:34]  : Юр, только вы смотри, чтобы это превратить в вопрос, вопрос вот только следующий. Помогает ли наблюдение или экспериментирование или игра с игровым компьютерным интеллектом, в котором количество ценностных осей ограничено, помогает ли такая деятельность созданию интеллекта, которым потенциально будет работать в условиях, когда эти оси будут, так сказать, расширяться и меняться, открытое их пространство? Вот твой комментарий здесь. 

S04 [01:53:05]  : Смотрите, во-первых, Спасибо. В рамках Старкрафта, по поводу целей в начале, в рамках Старкрафта, в Старкрафте есть футбол. Знаете, как он реализован? Берется движок Старкрафта, добавляются триггеры того, что начисляются там очко, Определенному игроку, если определенный юнит загонится в определенное место за край поля, и есть юниты, которые в него стреляют, и таким образом вызывают то, что юнит начинает сдвигаться. в ту или другую сторону. Кто точнее и правильнее расположит своих стрелятелей, которые еще медленно движутся, чтобы загнать этого юнита в определенную сторону, тот победит. Это футбол. То есть у нас здесь стратегия совершенно другая, цель совершенно другая, но тот же самый используется игровой движок, то же самое игровое пространство. С одной стороны, так же и в жизни. Один и тот же движок, одно и то же игровое пространство, а цели мы можем достигать совершенно разные. Но с другой стороны, в конце концов, это все конвертироваться будет в те же самые очки или что-то. 

S03 [01:54:35]  : вот последняя фраза, вот тут и проходит демаркационная линия. ты все равно возвращаешься к следующему. 

S04 [01:54:40]  : антропоцентричность заключается в том, что вы верите в то, что вот этой конверсии не происходит и все разные случаи, разные игры, они действительно разные. 

S03 [01:54:50]  : нет, ну смотри, тут не вопрос веры, вопрос просто в том, в каких классах задачи мы можем остаться. вот я сейчас примел замечательный пример. это старкрафт плюс футбол, условно говоря. то есть там есть естественная для старкрафта метрики и плюс еще одна называется футбольная метрика. теперь это такой расширенный старкрафт, у него пространство вот этих возможных задач, которые там расширяются. но оно остается все равно определенным. когда новый человек туда входит, он ознакомлен с теми возможными целями, которые там в принципе можно достигнуть. 

S04 [01:55:30]  : вы не можете играть в футбол, не зная то, что в нем надо сделать? 

S03 [01:55:41]  : Давай очень четко различать три вещи. Первое – переменное состояние, которое мы проговорили. Управление – это действие, которое можно сделать. И вот эти целевые оси – третья сущность, не сводимая ни к переменным состояниям, ни к переменному управлению. про состояние, про управление, об этом сложности ты прекрасно все рассказал, мы с тобой согласны полностью. мы сейчас про вот те третьи переменные, целевые переменные. Вот когда ты входишь… Антон, давай, наверное, подхватывай ты, потому что я уже, наверное… Давайте, я не могу руку поднять, поэтому у меня, я как хост не лишен права поднять руку, поэтому я тут хочу чуть-чуть на Юрииной стороне выступить. 

S02 [01:56:21]  : Смотрите, значит, ну, во-первых, Я буду утверждать, что человек тоже никогда не принимает решения, исходя из бесконечного количества переменных. Работает пресловутый принцип тяжести, и в какой-то конкретный момент времени для человека что-то является более важным. В какой-то момент ему важнее размножаться, в какой-то момент ему важнее есть, а в какой-то момент ему важнее спать. И я буду утверждать, что далеко не во всех случаях человек пытается удовлетворить более чем 2-3 потребности одновременно. Это первое. И второе, что я могу легко сказать, что вот к 5-6 сеткам, которые входят в Юриную архитектуру, можно добавить еще одну сетку, которая из множества вот этих вот количество целевых функций, будет выбирать те функции, которые релевантны в данный момент. То есть, это будет как бы не Attention Focus, а это будет Goal Setting Focus. Ну и все. А если это не устраивает, сверху еще можно будет построить одну сетку, которая будет управлять сеткой выбора этих самых. В голове оно так и устроено. То есть, на самом деле, в голове у нас одни зоны мозга управляют другими зонами мозга. А теми зонами мозга, которыми управляют другие мозги, им управляют третьи зоны мозга. И между ними еще есть некоторая интерференция. Если не считать того, что мозг это приемник, и на самом деле мы просто воспринимаем некоторые сигналы из внешнего разума, которые на самом деле управляют. то есть ничего кроме нейронов конечного числа и синапсов конечного числа и возбуждений из одной коры в другую там нет. 

S03 [01:58:09]  : я согласен. в каком смысле согласен? что если ты построишь эти семь иерархий, допустим, твоих, вспомни там еще про этого мужика, который двух генералов накормил, в конце концов там нужно было после большого цепочки преобразования все-таки в конце надо было пищу какую-то принять. но если это оставить в стороне, то есть действительно научного метода, который бы опроверг твою гипотезу, что на самом деле вот эти вот целевые оси это дополнительные мета координаты и мы можем их тоже добавлять задачу, добавляя новые уровни. а если нам их не хватит, то мы следующие уровни добавим. различить как бы различить реальность и вот этот вот вот эту конструкцию многошаговую да но не представляется возможным но вот здесь бы наверное возможно мог бы встретить александр болдачок который бы сказал что а если мы занимаемся задачи там условно говоря размышления там но вот какого-то такого какой такой деятельностью которая изначально бесконечно мирно мы действительно в каждый какой-то момент находимся в состоянии доминанты мы малым числом переменных оперируем, но свободой воли мы из бесконечного числа переменных в данный момент выбираем какое-то конечное число, которым мы оперируем по разным причинам. по энергетическим, по временным, по причинам безопасности, по причинам нашего устройства биологического. это действительно да, но этот момент выбора конечного числа переменной с которым мы сейчас имеем дело из исходно бесконечного числа это особенность наша и мы это и мы это мы это действие предпринимаем и вот собственно один из вопросов такой имея модель взаимодействия игровую в которой не требуется вот этого процесса можно ли максимально продвинуться научиться чему-то полезному в реальной ситуации, в которой требуется процесс выбора из бесконечного, конечного, которое в данный момент актуально. 

S04 [02:00:07]  : Про выбор из бесконечных числа переменных я уже пару раз упоминал в рамках, например. 

S03 [02:00:13]  : Целевых только, Юр. Не переменных состояний, не переменных управлений, а целевых. 

S04 [02:00:18]  : Да, еще раз. Вместо кнопок у нас embedding. Вот у нас, пожалуйста, выборы. 

S03 [02:00:22]  : Ты описываешь пространство-состояние? Нет, Юр, ты описываешь пространство-состояние? 

S04 [02:00:26]  : Нет, это пространство действий бесконечно. 

S03 [02:00:29]  : Это дуальная переменная, пространство-состояние плюс действие. X и A, это понятно. Мы говорим пространство целей. 

S04 [02:00:36]  : Пространство целей тоже может описываться эмбеддингом и быть бесконечно-мерным. Но, безусловно, если мы будем учиться всего лишь одной-двум целям, на одной-двум целям, мы будем намного хуже играть в другие игры, в другие цели, нежели если бы мы учились на сотне. И еще лучше будем учиться, если будем играть 10 тысяч разных игр. мы еще лучше будем играть. 

S03 [02:01:06]  : так вот утверждение тех, кто как бы вот на такой пессимистической стороне, оно звучит следующим образом, что игра на любом конечном количестве целей ничего не дает с точки зрения игры на какой-то n плюс первой цели, которая сильно от них отличается. то есть нельзя перенести вот этот вот мыслительный способ игры в n плюс первую игру, играя на n в предыдущих играх, если n было зафиксировано. это пессимисты так говорят, и это не обязательно мое мнение. 

S04 [02:01:37]  : я понимаю, но давайте я отвечу уже сейчас, потому что мы долго очень... я быстро понимаю вопросы достаточно быстро, так что мы их разжевываем, и много времени уходит. 

S03 [02:01:51]  : для аудитории просто, чтобы все понимали. смотрите, 

S04 [02:01:59]  : да, значит я быстро схватываю, но и быстро забываю сейчас. 

S03 [02:02:04]  : но помогает ли n плюс первая, помогает ли n предыдущего способа? 

S04 [02:02:10]  : если вы будете утверждать, что n плюс первому способу не помогает первый n, то тогда для человека Поскольку ребенок, например, до 3 или до 5 лет умеет только в какие-то N игр играть, получается, существует какая-то игра или какое-то действие, которое он никогда не осилит. 

S03 [02:02:33]  : он осилит, но использует нечто существенно отличающееся от обычного наузькивания на предыдущие N-игры. 

S04 [02:02:40]  : например, радиосигнал из космоса, который ему подскажет как действовать. 

S03 [02:02:46]  : пусть будет так, или из генов что-нибудь вытащит изнутри, что-то такое, чего не сводится к наузькиванию на предыдущие N-игры. 

S04 [02:02:55]  : ну то есть грубо говоря вот это вот собачка как человек это делает как не знаю я не вижу физического материалистического способа как человек это может делать ну юр замечательно я тоже присоединяюсь я тоже не вижу культуру человечества он не один ну и компьютер тоже может читать описание игр там и любую культуру вот 

S03 [02:03:18]  : Борис, понимаешь, какая логика? Логика такая, что в конце концов из-за большого объема вот этих вот переменных, которые хоть и заранее заданы, но они очень велики, очень трудно различить, действительно ли Юрий прав и действительно это не более чем просто игра в очень большое количество игр и все. или же существует некое концептуальное отличие при переходе к следующей н-плюс первой игре, которая не сводится к энтому и которую мы никак не уловим в наших вот этих алгоритмах, которые по сути есть реактивные такие. 

S04 [02:03:53]  : Смотрите, эксперименты на языковых моделях пока говорят о том, что если игры не сильно сложные, если действия не сильно сложные, то обучение на n играх безусловно помогает в n плюс первой игре. 

S03 [02:04:09]  : понятно, потому что эксплоринг помогает в том смысле, что предыдущие игры дают тебе материал для эксплоринга, который ты не можешь получить просто случайными. 

S04 [02:04:19]  : нет, не только эксплоринга, и в f0 short и 1 short тоже они сильно очень помогают. 

S03 [02:04:27]  : там никакого эксплоринга уже нет и планирования. Юр, это же не теоретическое утверждение, это эмпирический некий факт о том, что… Эмпирический факт, абсолютно верно. 

S04 [02:04:37]  : Так же, как и с человеком. Почему-то Н плюс первый… У нас, наконец, появилась рука Александра Балдачева. 

S02 [02:04:42]  : Все, я сразу замолкаю. Да, а прежде чем я дам слово Александру Балдачеву, я хочу сделать одно замечание, что выбирать из бесчисленного числа вариантов мы не можем в принципе, потому что для того, чтобы выбрать из бесчисленного числа вариантов, нам нужно бесконечное время для того, чтобы загрузить эти числа вариантов в память и бесконечное количество памяти, чтобы 

S03 [02:05:11]  : Антон, качественно принципиально с тобой не согласен. Мы мыслим классами эквивалентности. Мы сразу огромные континуальные блоки отбрасываем одним махом. Мы никогда не загружаем континуум сложной информации. Наш способ обобщения приводит к тому, что для внешнего наблюдателя мы все время решаем дискретную задачу. 

S02 [02:05:34]  : Совершенно верно. Я в предыдущем своем слове говорил, что мы всегда фокусируемся на том, что для нас важно. Мы не рассматриваем все изменения. а мы берем только те, которые для нас нужны в важном контексте. 

S04 [02:05:48]  : Давайте, Александр, послушаем новую струю. 

S01 [02:05:54]  : Добрый день, Юрий, спасибо всем за обсуждение, было очень интересно. Я хочу маленькую детальку только добавить. Несколько раз пытался даже и Юрий объяснять, и здесь пытался объяснять, но как-то это все не заходит. Вот в разговорах вот таких, Я считаю, что принципиально нужно различать цель и результат. Результативное действие и деятельность направлены на достижение цели. То есть в игре есть какая-то цель – победить. В каждой, в принципе, игре. И есть куча действий результативных, которые выполняются, ну или в жизни, скажем, конкретные результативные действия. Взять что-то, перенести с одного места на другое. Я совершил результативное действие и закончил каким-то... Или, скажем, мне нужно приготовить чашку кофе. Я совершил несколько типовых действий, которые совершали не только готовя кофе. Я кипячу воду, наливаю воду, или еще что-то. Достал сахар, сливки вылил. Я мог сливки не в кофе влить, а в чай. То есть типовые действия, которые завершаются конкретным результатом. И поэтому Юрий прав именно в том, что нужно различать цель игры и результативные действия внутри этой игры. И тогда, обучившись каким-то конкретным действиям, можем применять их и в другой игре, как и в жизни. То есть мы вообще, в принципе, если мы проанализируем деятельность, действия, я в социо-ботинной онтологии этим занимаюсь, то конкретных актов, действий, которые может совершить человек, не так уж и много. Не так уж и много, они счисляются сотней, полторы, а то, может, и меньше. А дальше их синонимы, всякие частные реализации. То есть, для примера, можно передать что-то другому человеку. Передача – это конкретное действие. А можно подарить, продать, украсть. Там куча разных действий, но это уже языковые окраски различной ситуации. 

S04 [02:07:59]  : Это семантический гнездо нынче называют. 

S01 [02:08:03]  : Это, скажем так, есть актор и есть семантический сахар. Семантический сахар, который мы, ну, скажем, пример там семантического сахара тоже. Вот есть агент и клиент, да? Это совершенно фиксированные действия, которые выполняют акторы, а есть учитель, ученик, продавец, покупатель, врач, пациент. То есть язык наполнен семантическим сахаром, но количества действий не так много. И у нас получается, если рассматривать эту историю, что когда цели, цели очень мало. Именно цели в деятельности. Ну, скажем, вот есть спорт, и в любом виде спорта есть цель деятельности просто победить. Или там получить много денег. То есть, или в Вячеславе стать самым знаменитым. Цели там минимальны. Но все эти виды спорта отличаются очень друг от друга. Но какие-то элементы тренировки, Если я тренировал ноги как футболист, то я, естественно, смогу играть лучше в хоккей, что у нас и было в Советском Союзе. И, кстати, с музыкантами эта история тоже. Вот в целом музыке, может, цель одна, а вот результативных действий конкретных, которые выполняют конкретные музыканты для исполнения на конкретном инструменте, они разнятся, но все равно помогают. То есть это известно, что музыкант, научившийся на одном инструменте, в два-три раза быстрее обучается на других инструментах. Это не касается цели. Я бы даже сказал, в десятки. В десятки раз. 

S04 [02:09:43]  : Взял аккордеон, не умея играть на пианино, но умея играть на гитаре. Первый месседж – это то, что нужно различать уровень целей. 

S01 [02:09:56]  : Цель деятельности – это, скажем, в футболе у человека может быть какая-то… То есть у футбола есть некая цель, и человек в эту цель задействован. А есть конкретные действия, ну что, забить гол. Забить гол – это не цель. Забить гол – это не цель. Это результат, который необходим для реализации этой деятельности. Поэтому если я научаюсь в какой-то деятельности реализовывать конкретные акты, из актов составлять действия результативные, достигать их, и тогда я смогу, применяя деятельности, применять эти навыки. Наверное, вот так. 

S03 [02:10:45]  : у меня вопрос такой, это наверно касается все-таки близких типов деятельности, потому что все-таки вот игра на разных инструментах, ну это во-первых игра, это музыка, это некий акт и там и так далее. А вот можно ли ваше утверждение более сильно распространить, например… Александр про типы действий вообще говорил, что по сути там 100%… Нет, все зависит от уровня. 

S01 [02:11:09]  : То есть есть низкоуровневые действия, низкоуровневые действия, которые ребенок в играх обучается. И дальше он уже способен применять эти действия в различных более высокоуровневых деятельностях. 

S03 [02:11:23]  : Вот к этому все сводится, то есть мыслительная деятельность тоже она в конце концов из этого сводится. 

S04 [02:11:28]  : Вот это позиция, понятно. Низкого уровня более простых действий, более сложная мыслительная деятельность. 

S01 [02:11:35]  : И у нас нет бесконечного пространства целей. Скажем так, количество деятельностей, которые реализованы у нас на планете среди людей, не так много, то есть мы можем перечислить, ну, там, может быть, до тысячи дойдет. И у многих у этих деятельностей цели одинаковые, цели одинаковые. То есть где-то, скажем, участие человека в этих деятельностях, где-то заработать деньги, где-то слава, где-то просто наслаждение, то есть, ну, вот, цели вот этого вот этого, до чего не достигается. А результаты действий достигаются. Обучение конкретным результатам помогает. И в мыслительной деятельности тоже. Если человек научился в институте мыслить, То есть в институте в большинстве случаев не учат конкретные деятельности, инженерные, а учат мыслить. То он, перейдя тут же из инженерной деятельности, скажем, какую-то маркетингу, бизнес, он применяет свою способность мышления. То есть он научился достигать каких-то результатов, оперируя понятиями. А цель этой действий такая. Необходимо. Никакого деятельности не может быть без цели. Обязательно должна быть цель, чтобы совершить. 

S04 [02:12:50]  : Спасибо. Да, спасибо. 

S02 [02:12:51]  : Хорошо. Александр, спасибо. У меня есть один комментарий и вопрос из телеграммы протранслировать, содержать. Комментарий такой. Вот насчет того, что там разных видов деятельности. Можно ли обучиться всему на свете одновременно и влезет ли это в голову. И то, что один инструмент помогает другому. Просто вот у меня опыт этого лета, я долго не мог понять, что происходит, и потом только понял. Феномен такой. Я этим летом несколько раз менял спортивный снаряд, то есть несколько раз катался на кайте, несколько раз на кайтборде, несколько раз на вейкборде, несколько раз на кайтборде, несколько раз на вейкборде. Ничего не мог понять. Почему-то после того, как я покатаюсь На кайтборде, значит, я на вейкборде ничего, забываю, чему научился в прошлый раз и потом. А потом я просто понял, там по-разному работает тяга, по-разному работают крепления, по-разному углы атаки строятся. Теперь я понимаю, почему спортсмены специализируются только на один вид спорта. Потому что все-таки, даже когда виды деятельности близкие, все равно все когнитивные схемы прописываются в одной и той же сетке определенным образом. И когда ты переобучаешься на другой вид деятельности, они перепрописываются заново и нет возможности это как-то развести на разные сетки, как я понимаю. Ну или для того, чтобы развести их на разные сетки, нужны какие-то очень специальные системы. 

S04 [02:14:20]  : Ну да, модель полиси-нетворка очень подробная получается для одного вида деятельности и, соответственно, Она не может нормально аппроксимировать другой вид деятельности. 

S02 [02:14:28]  : Совершенно верно. Совершенно верно. Именно потому, что в силу того, что они близкие, они аверфитятся на совершенно определенный вид. Это комментарий. А вопрос здесь такой из телеграмма. Вопрос по докладу. Можно ли свести состояние и награду к другому вектору? Так ли сильно они отличаются друг от друга? 

S04 [02:14:55]  : Да. Смотрите, свести их к одному вектору можно, но зачем? То есть можно складывать количество голов в футболе и количество игроков, количество зрителей и количество софитов. в единый вектор но учиться лучше это ну как бы не помогает учиться надо значит на игре в футбол значит они не на наблюдениях за зрителями и софитами значит поэтому и также соответственно состояние действия учатся по победам и поражениям. Соответственно, если мы действия учим, то мы учим их по тому, что мы глядим эффект от того или иного действия. Состояние, опять же, мы учим по ним значит пользу того или иного состояния значит ну награды это как раз результат игры там или что это награды конкретно может две разные вещи называть наградами вот ну соответственно тоже юр но вот я вот у себя там этот вопрос занимает антон ответил но смотри ведь это же на самом деле связаны задачи 

S03 [02:16:09]  : прогнозировать свое положение пространства, то есть пространство или состояние, прогнозировать управление, прогнозировать ревард. это вопрос, который мы с самого начала обсуждали. если все сводится к реварду, то есть если цель, вся мета цель деятельности получения более максимального реварда то тогда эти все три класса переменных запросто сводятся в один вектор. ты, научившись прогнозировать все три, получаешь бонус от этого. но это при условии, что у тебя все сводится к этому реварду. если ревард из NF, то тогда да. 

S04 [02:16:46]  : ну еще на самом деле есть еще, кроме этого, состояние агента в мире, есть еще состояние мира, которое на самом деле очень большая часть вектора, в большинстве случаев. 

S03 [02:17:01]  : но качественно не меняется, просто количество изменили. 

S04 [02:17:07]  : все эти вещи важны, но они в разном месте в уравнении стоят. то есть если у нас уравнение x плюс y равно z, то их можно в едином векторе хранить, но в уравнении их вроде совершенно разные. 

S03 [02:17:25]  : уравнение можно записать в инвариантной форме, когда они все выступают симметрично, то есть это технический момент. принципиальный момент стоит в следующем, что сводится ли вся деятельность, которую ты имеешь в игровой ситуации, к реварду? если да, или к ревардам? 

S04 [02:17:40]  : не к реварду она сводится. 

S03 [02:17:41]  : она сводится к сумме максимального реварда. 

S04 [02:17:45]  : то есть к кривонингу с определенными целями обучения разных частей. 

S03 [02:17:53]  : которые в конце концов оцениваются победой, то есть суммарным ревардом. но они же в конце концов у тебя Победы оцениваются. Это тот же самый вопрос, который я с самого начала задавал. 

S04 [02:18:03]  : Да, но победы, мы же наоборот говорим, не про то, что нам победу надо оценить, а про то, что, ну да, ну это кондишенимы опять же. То есть есть просто победа, а есть победа в зависимости от состояния, победа в зависимости от нашего действия, а победа в зависимости от состояния мира. Это как раз то, что я вот описывал формулой вот здесь вот внизу. conditioning, то есть у нас была до этого функция, которая зависела от какой-то величины, например от стейта, а теперь мы ее завязали еще на другую величину, что-то типа условной вероятности получить. только здесь у нас не вероятность условная, а когда вероятность – это про плотность функции распределения, а здесь у нас функция, которая 1 или минус 1, хорошо или плохо, но тем не менее ее можно зависеть на дополнительные переменные завязывания, на дополнительные типы переменных. то есть функция win от state. можно считать вероятность, можно соответственно максимизировать max от state, получать от этого optimal state model. аналогичным образом мы считаем, значит, вероятность победы от задач можно чего угодно считать. от world, значит, optimal получаем. модель мира тоже какую-то, какую-то часть модели мира мы получаем, значит, ну и так далее. максимизируя вот эти различные компоненты, action, Optimal Action Model. 

S05 [02:19:58]  : Все верно. Два слова против моей прежней позиции. Мне представляется, что такой подход может быть очень полезен для развития методов использования машин или искусственного интеллекта. Если прочитать много задач, то возможно появится возможность переходить на мета-уровень, находить какие-то базовые принципы, по которым можно искать быстрее оптимальные решения по разным классам задач. Но только не для любой... Заранее неопределенные задачи, а по некоторым определенным классам задачи. Но такой подход, так мне кажется, может быть очень полезен. Поэтому спасибо докладчику. 

S02 [02:20:57]  : Хорошо, Борис, спасибо. Коллеги, всем спасибо. Юрий, есть какие-то еще финальные замечания? 

S04 [02:21:06]  : В чате пишут, что это не вероятности. Это ерунда. Что нужно знать о распределении, чтобы считать вероятности? Это не вероятности в том плане, что здесь нет знаменателя. То есть это не вероятность, это частоты скорее. На практике обычно это частоты, чтобы именно знаменательного не считать, который требует перебора всех возможностей состояния или всего мира. Тем не менее на практике эмпирически мы как раз можем оценить вот эти все мельчины и на основании них как раз построить модель. да, ну соответственно, а дальше нужна комбинация вот этих моделей, чтобы делать планирование вот в этом пространстве объединенным этих компаний. 

S03 [02:22:01]  : Юр, а вот последний тезис у тебя насколько он максимально звучит? то есть изучение игровых ситуаций достаточно и нам хватит его на многие десятилетия вперед, чтобы развивать искусственный интеллект, или же ты видишь принципиально какие-то другие ограничения, то есть это полезно, но не исчерпывает? 

S04 [02:22:28]  : Здесь несколько есть сценариев, которые были практически полезны. Значит, сценарии такие, игровые. Вот в StarCraft у нас 250 люнитов. Это уже стратегическая игра, в которой есть тактические моменты и стратегические моменты. Достаточно сложные взаимодействия, 250 компонентов нужно рассчитывать. Другой вариант был – это взаимодействие пяти компонентов для игры дота. Поскольку это совпало с числом пальцев на руке, потом использовали тот же самый подход для обучения одновременному действию многих пальцев и действительно получили тоже неплохие результаты. Обучение робота с пятью пальцами. Третья ситуация – это когда у нас игровое воздействие может быть только на один элемент, соответственно юнит этот один. Такие тоже примеры есть в играх. Все эти три варианта полезны, все они открывают немножко разные задачи, которые на них похожи в реальном мире. И кроме этого есть игры, всякие упражнения с языком, языковые модели. Там тоже другой тип игр. Там не игры на то, что двигаться в пространстве кого-то надо. Там другие игры. Но те игры тоже этим же математическим аппаратам успешно поддаются некоторому решению, некоторому приближению реальности к человеческому поведению. В этом плане все варианты полезны, но на практике для разного. Потому что близкие задачи, они разные. Одна задача на взаимодействие скорее, а другая задача на действие определенного одного агента. 

S03 [02:24:38]  : Спасибо. 

S02 [02:24:40]  : Хорошо. Юрий, спасибо. Коллеги, спасибо. Юрий, чтобы вы не расстраивались, что сегодня мало народу. У нас и тролли сегодня приходили, и в Телеграме народ смотрит в Ютьюбе, и там активно идёт обсуждение сейчас. Нужно ли разбивать входной поток на вектора и как структурировано сжатие информации в иерархию векторов связано с процессом обучения, можете в телеграме потом посмотреть. В общем, есть над чем подумать. И у нас тема когнитивных архитектур из нейросетей или нейросимвольных модулей будет обсуждаться через неделю на конференции Байка в Мексике, а через две недели Сергей Шумский будет рассказывать как раз свою историю игрового ИИ агента Марти с которой они делают с Игорем Пивоваровым последние достижения в этой области. Всем спасибо и до новых встреч. Юрий, спасибо за доклад и за терпение в ответах на вопросы. Всего доброго. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
