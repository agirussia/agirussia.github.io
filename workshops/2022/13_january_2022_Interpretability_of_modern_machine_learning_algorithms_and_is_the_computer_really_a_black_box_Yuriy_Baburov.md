## 13 января - Интерпретируемость современных алгоритмов машинного обучения и действительно ли компьютер -- это чёрный ящик? - Юрий Бабуров — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/w1pP_R5yZB4/hqdefault.jpg)](https://youtu.be/w1pP_R5yZB4)

Суммаризация семинара:

Семинар посвящён теме интерпретируемости современных методов машинного обучения, в частности, нейросетей. Основной вопрос, который поднимался на семинаре, - это связь между интерпретируемостью и сильным искусственным интеллектом (ИИ). Участники обсуждали возможность создания сильного ИИ, который был бы не только эффективным, но и понимаемым.

В качестве примера было рассмотрено создание простых нейросетей для решения задач распознавания изображений. Обсуждалась идея, что для обучения нейросети человеку необходимо было не только подобрать наборы данных, но и выполнить предварительную классификацию, что можно было назвать ручной работой. Однако, несмотря на это, нейросеть смогла эффективно работать и достигнуть высокого качества в распознавании.

Виктор Казаринов представил свою систему обработки изображений, которая работала автоматически и не требовала вручную подобранных наборов данных. Система была успешной в классификации изображений, и её пример был упомянут на семинаре в качестве альтернативы ручному созданию правил.

Обсуждалась также проблема интерпретируемости в нейросетях, где модели с большими батч-сайзами могут вести себя неинтуитивно, например, представляя изображения последовательно в разное время. Это было показано на примере задачи распознавания изображений, где модель обучалась на большом количестве данных и могла неправильно интерпретировать такие вещи, как повороты и искажения изображений.

Виктор также упомянул о проблемах связанных с созданием эвристических правил и о том, что иногда даже простые задачи, такие как распознавание текстов, могут быть трудными для понимания и интерпретации.

На семинаре также были подняты вопросы о том, как нейросети видят окружающий мир и как они могут быть интерпретированы людьми. В частности, обсуждалась важность понимания того, как нейросети получают компактное представление объектов и как это соотносится с восприятием человека.

В итоге, семинар подчеркнул сложность задачи создания сильного искусственного интеллекта, который бы полностью понимался людьми, и выразил надежду на то, что в будущем удастся продвинуться в сторону интерпретируемости нейросетей и понимания того, как они работают.







S03 [00:00:04]  : Коллеги, всем добрый вечер. И Юрий Бабуров сегодня нам расскажет про интерпретируемость современных методов машинного обучения и действительно ли искусственный интеллект, нейросети в современных компьютерах – это черные ящики. Юрий, пожалуйста. 

S04 [00:00:22]  : Всем добрый день. Ну, на самом деле, доклад у меня сегодня будет не очень длинный. весьма даже коротенький. поговорить, но потом зато я бы предпочел, чтобы была длительная дискуссия. как раз мы обсудили все вопросы. начнем. слетел шарик, да? 

S03 [00:00:56]  : я вижу ножку. 

S04 [00:01:01]  : Итак, вы видите кошку. Если вы не знаете, это кошка. Это кошка с нашумевшей статьи о том, что с помощью компьютера сотрудники Стэнфорда вместе с Google получили изображение кота. Но немного не так. Сотрудники обработали кучу изображений, в том числе у них выделилось изображение, вот такое вот изображение кота, обобщенное. Мы сегодня посмотрим на много обобщенных изображений, поймем, как они формируются и что это вообще такое. как это связано с современными моделями нейросетевыми. начнем с очень простых примеров. мы будем работать на двух простых датасетах. первый из которых, я сейчас примеры картинок покажу, но вы все их знаете. обратите внимание, насколько разные бывают цифры. вот, например, справа внизу это две пятерочки. они совсем друг на друга не похожи. или вот семерки бывают с палочкой, бывают без. об этом мы как раз скоро очень поговорим. а второй датасет это датасет CIFAR-10. в котором представлено 10 таких классов изображений. Их можно сравнить с цифрами, только визуальными, которые понимает даже ребенок. Правда, не факт, что он на таких маленьких картинках поймет. Собачки, котики, не всегда отличимые друг от друга. лоси, олени или лоси, сейчас посмотрим, самолеты, машины, грузовики, лягушки, птички и еще где-то были пароходы, правлей, здесь чуть ни один не попал. вот название всех классов. мы на двух этих дата сетах попробуем сделать однослойную нейросеть и заткнуть все альтернативные модели за пояс. возьмем фактически стандартный сетап batch size 1000. всего у нас изображений 55 тысяч. доступно 60 тысяч тренировочных. мы 5000 отложили, но потом на них сравниваем качество. запустили, получили такую нейросетевую модель. она обучилась, говорит, что у нее качество... хотелось бы показать как раз только результаты по качеству, не показывать пока картинки. у нее получилось качество 65 процентов, то есть она больше половины цифры уже умеет отличать друг от друга. модель эта примечательна. я думаю, что она очень наглядна. эта модель имеет всего один слой и нет никаких нелинейностей. то есть это просто нейрончики. один канал световой 28 на 28 координат, то есть 784 пикселя, 10 классов, поэтому нейрончиков у нас 10, у каждого нейрончика по 784 входа. и вот такая простенькая модель. у нас немножко получилось уже одну эпоху всего лишь картинки то есть она видела картинки по одному разу даже более того картинки у нас были слеплены вместе кучками по 30 тысяч есть одна кучка 30 и 2 кучка 25 тысяч ну в общем вот то что образы картинок на нейрончиках в модели сложились вот такие. похоже ли это на цифры? да, это похоже на цифры исходные как раз. их уже можно заметить. особенно если я сделаю поменьше. если у вас на компьютере они меньше выглядят, то уже будут различимы. но мы можем поучить чуть-чуть более умно, например, поучить немножко подольше, поучить еще одну эпоху с такими же параметрами. тогда у нас будут более различимые картинки. то есть однослойные нейросети по сути они запоминают картинки, сами картинки, и используют их для сравнения с результатом и для классификации. достаточно ли этого или недостаточно? на самом деле чуть ниже мы получим на этой сетке 91 процент качества. вот ровно одиночных нейрончиках. вот мы уже к этому приближаемся. вот мы потренировали еще три эпохи. три раза погнали через дата сет. вот у нас получились вот такие картинки. я их нарисовал немножко по-другому. я их нарисовал в другом режиме, красненьким. те значения, которые больше нуля в нейрончике, то есть те веса, которые больше нуля, а синеньким те веса, которые меньше нуля. И вот оказывается такая интересная вещь, что нейросеть сразу делает две вещи. Она не только выделяет текущий образ, но и отделяет его от конкурирующих образов. Для этого конкурирующие образы, пиксели, которые часто встречаются в конкурирующих образах, их веса с минусами. И получается как раз что каждый нейрончик одновременно выделяет свой сигнал и вычитает все побочные сигналы. Теперь поставим batch size поменьше. Это приведет к следующему интересному эффекту. у нас картинки изначально были слеплены, то есть у нас были в случае однослойной сети такие усредненные образы. а теперь эти усредненные образы будут меньше усредненных образов и больше возможностей сетке именно поучиться. А когда научится, больше всего каждый нейрончик, конечно же, видит картинок конкурентов. Их в 9 раз больше, чем целевого класса. Таким образом, нейрончик со временем учится больше вычитать конкурентов, нежели складывать собственный сигнал. И даже в тех местах, где собственный сигнал был раньше, вот тройка, вот тут четверки, остались вот какие-то клочки. на самом деле это те клочки, где очень редко бывают сигналы конкурентов. и очень часто где бывает только вот эта четверка. то же самое, но какие-то другие цифры вообще не узнать. и вот я вот этот сигнал поделил на две части. отдельно сделал положительные, положительную часть сигнала, отдельно отрицательную часть сигнала. то есть как мы видим, отрицательная часть сигнала вот здесь, например, вот здесь вот она на тройку очень похожа фоном. то есть все кроме тройки у нас идет четко в минус. а здесь наоборот выделены какие-то части от тройки, которые с другими цифрами мало пересекаются. здесь от двойки какие-то части и так далее. тем не менее вот это вот последний результат хоть у нас показывает 92 процента то есть 8 процентов картинок он неправильно классифицирует. мы не будем сейчас смотреть какие это нам неинтересно нам интереснее как раз обратить внимание как раз на вот эти выходы нейрончика и на то что их по сути вот это изображение это и есть то, на что нейрон настроен, то есть это и есть те правила, которые применяет нейрон к входной картине. 

S03 [00:10:57]  : Юрий, извините, что я вклиниваюсь, просто важный вопрос, который упростит понимание дальнейшее. Вы когда говорите однослойная сеть, это один скрытый слой или просто есть только входной слой и выходной слой, больше ничего? 

S04 [00:11:13]  : Входной слой и выходной слой – это старая терминология. они на самом деле входной и выходной слой – это не слои, а просто входной слой – место, куда приходит информация, выходной слой – место, откуда эта информация берется. То есть конкретно нейрончиков там нет. 

S03 [00:11:32]  : то есть между ними есть один слой. то есть есть вход, есть выход и между ними есть один слой, правильно? да. это то, что вы рассказываете? да. все, спасибо. 

S04 [00:11:44]  : ровно этот слой это вот как раз 10 нейрончиков, у которых есть 20 образов положительных и отрицательных. И это и есть те правила, которые он применяет в картинке. Как он их применяет? Он суммирует положительные части каждой нейрончик своей, умножая каждую единичку на то, что на картинке. Каждую пиксель. И потом вычитает вторую половинку, вот эту вторую половинку. Так же для каждого пиксельных картинок. ну или можно сразу представить, что у нас есть сразу положительные и отрицательные веса, которые умножаются на пиксели на исходной картинке. ну а дальше та картинка, у которой сумма больше всего, та и победила. то есть это и есть та самая интерпретация правил, по которым работает нейрон. замечу, что если бы мы это писали в виде языка программирования, на языке программирования не прибегая к матриксам, а просто на условиях каких-то, у нас бы для вот этих вот картинок 28х28 это бы выглядело как большое количество каких-то там или сравнений или просто сумма по большому числу значений и последующие сравнения элементов. и если бы мы записали их в виде инструкции команд для компьютера, получилось бы достаточно большое число инструкций. 784 на 10. под 10000, получается, инструкций. Плюс как-то еще сортировка. И, в общем-то, это объясняет то, почему людям тяжело было бы это сделать руками, даже для такой простой задачи. Написать вручную 10000 правил, 10000 каких-то условий, подобрать что-то достаточно сложно. Также вспомним про наши любимые эволюционные алгоритмы. Если эволюционные алгоритмы, простите, подобрать 10 тысяч параметров, то на это уйдет очень большое время. чтобы это сделать достаточно в хорошем качестве. здесь же у нас есть достаточно простая процедура, которая позволяет просто получить все эти параметры сразу. в общем-то это и есть то, чем хорошо машинное обучение и то, что оно предлагает. но при этом у этой технологии, конечно, есть свои недостатки. дальше как раз мы посмотрим более сложные примеры и попробуем очертить круг, когда мы можем извлечь какие-то правила, какие-то стандартности, а когда нет. следующая задачка чуть посложнее. здесь я получил побольше, результат 0,92. перейдем к задаче CIFAR. попробуем так же сделать. так, давайте я тогда сейчас отвечу на вопросы, если у кого-то есть вопросы. а потом мы уже перейдем к следующим интересным картинкам. 

S03 [00:15:48]  : Хорошо, тогда давайте по вопросам. Первый вопрос был мой. Это вот там у нас кошка на первом складе была. Вот вопрос по этой кошке. Эта кошка стэнфордская, гугловская, она инвариантна к повороту имасштабируемому? Так, принято. На вопрос Владимира Смолина про однослойную сеть ответили. Следующий вопрос от Владимира. Вот это упорядочивание, которое вы показываете, произведено потом для легкости восприятия или сеть сама распределяет цифры в правильном порядке по элементам? Я, честно говоря, не очень понимаю вопрос. Может быть, Владимир, вы поясните ваш вопрос? Самый главный вопрос от Владимира. Чем обеспечивается разделение по одной цифре на один элемент скрытого слоя? 

S00 [00:16:39]  : Я думаю, Юрий меня понял. Если не понял, я готов пояснить. 

S03 [00:16:45]  : Юрий, вы поняли вопрос? 

S00 [00:16:48]  : Вот они идут. Один, два, три, четыре, пять, шесть, семь, восемь. Десять элементов. Почему, во-первых, они в правильном порядке, а во-вторых, почему одна цифра на один элемент? 

S04 [00:17:00]  : Да, я понял. У меня звук был... Да, я выключил ненадолго звук, забыл его выключить. Смотрите, здесь обучение у нас Supervised сейчас. В обучении Supervised все очень просто. Нулевой нейрон учится... угадывать картинку 0, распознавать картинку 0. Первый нейрон учится распознавать картинку 1 и так далее. 

S00 [00:17:29]  : Стандартные Supervised условия — это то, что мы в одной слое даём картинке для первого элемента. Один, второй — два, второй — три. Третий — три. Там — да, а в скрытой слое, вы же показываете про скрытый слой, как там. Тоже Supervised? Куда залезают скрытые слои? 

S04 [00:17:44]  : Ну, конечно. Скрытый слой один, он непосредственно соединен с выходом. Смотрите. Где будет лучше, на доске или в ноутбуке? Хотите, пожалуйста, объясните. Я продемонстрирую. Да, время есть, конечно, много. все очень просто. смотрите, скрытый слой. давайте на доске наверное. виртуальный фон убрать. немножечко подвинуть. скрытый слой у нас всего лишь один. то есть архитектура сети выглядит следующим образом. но не буду здесь рисовать. 

S03 [00:18:39]  : Юрий, нужно прекратить шаринг тогда, чтобы мы доску видели. 

S04 [00:18:42]  : Давайте. Теперь нормально? Да, так нормально. А вот у нас входной слой. входной слой у нас там ну опять же не буду все рисовать, изображу как будто он у нас 5 на 5 выходные нейрончики выходные нейрончики подписаны это нейрончик до нуля это нейрончик выходный тройки до четверки. а теперь сами нейрончики. вот он нейрончик. вот этот нейрончик он соединен только с одним выходом. другими он тоже соединен. но в случае если нам на вход приходит если нам на вход приходит картинка вот такая с ноликом мы ожидаем на выходе для этой картинки что у нас должны быть единичка 0 0 0 0 и таким образом вот этот нейрон до него положительным всегда он единичкой служит то, что похоже на нолики. И он учится именно распознавать нолики. Ну и в результате он научается распознавать нолики. Если поступает единичка, соответственно, этот нейрончик, правильный, Вот здесь ничего не рисовать. 

S03 [00:20:57]  : Юрий, извините, если я забегаю вперед, но раз уж вы нарисовали, что от этого нейрончика идут сигналы ко всем остальным, к единичкам, двойкам, тройкам, четверкам… Нет, не идут. Не идут. А, ну так, спасибо. Не идут. 

S02 [00:21:12]  : Обрадовали. 

S04 [00:21:14]  : не идут. Просто для всех остальных сигналов у этого нейрона будет ноль приходить. Если там будет единичка, то здесь ему скажут, что ты должен выдавать для нее ноль. Там чуть посложнее, но в общем примерно так. 

S03 [00:21:37]  : Если я правильно понимаю, то у нас на самом деле, если говорить в терминах старой, как вы говорите, терминологии, то у нас входной слой или вход, если вы не хотите называть это слоем, он соединен вот с этим вашим единственным слоем по принципу все ко всем. А вот этот вот единственный слой с выходом, он соединен один к одному, правильно? То есть у нас количество нейронов в единственном слое и количество выходов, оно равно. Правильно я понимаю? Да. Правильно. 

S04 [00:22:14]  : 10 нейрончиков. Окей. Окей. Такая вот простая схема. Получается, что в этой линейной схеме нейроны учат по сути усредненный сигнал целевой минус усредненный сигнал конкурента. Не совсем так, но приближенно. Мы как раз экспериментально в этом убедились. Вращаемся. 

S03 [00:22:49]  : Так, если возвращаемся к вопросам, то вопрос от Игоря Романенко. Но обычно такие условия, видимо, вы когда про условия рассказывали, что можно запрограммировать, что Игорь пишет, что обычно такие условия вручную никто не пишет. Есть какие-то шаблоны и с какими сравнивают. А потом лишь пишут логику для того, чтобы определить границы сравнений и разбиения и картинки на тегории, в которых надо искать шаблоны. 

S04 [00:23:16]  : откуда берутся шаблоны? я беру вопрос. 

S05 [00:23:22]  : берутся какие-то шаблоны? нет, ну понятно, они вручную делаются на основании каких-то тех же тренировочных данных. 

S04 [00:23:34]  : они делаются вручную на основе тренировочных данных и что потом с ними происходит? с ними происходит обучение, как на доске. 

S05 [00:23:43]  : да-да, понятно. я не пытаюсь полностью сказать что нейронные сети плохо. я просто говорю не надо пытаться как-то говорить что нейронные сети это все хорошо. 

S04 [00:23:54]  : мы сравниваем с тем, что если бы у нас не было тренировочных данных, как бы мы это попытались делать руками? что бы мы делали? я некоторый ответ на это дам позже, но вот 

S05 [00:24:09]  : ну да, понятно, что там была бы ручная работа по определению этих границ и всего такого, но в любом случае это работало до этого. 

S04 [00:24:18]  : какой объем был бы работать? был бы гигантский объем? 

S05 [00:24:24]  : зависит, конечно, от задачи. 

S04 [00:24:27]  : даже для простой задачи? я сомневаюсь, что я руками напишу, а правила, которые с 90% точностью, вот такие картинки распознают. 

S05 [00:24:39]  : ну просто для простых задач... даже за месяц. 

S03 [00:24:43]  : Для простых задач у нас нет… Извините, я предлагаю вот в этом месте двинуться дальше. Единственное, два коротких вопроса. Вот есть вопрос еще от Игоря же, а вы ничего не путаете, это dense слой, там нет один к выходным. То есть вот, Игорь, можете прояснить свой второй вопрос? 

S05 [00:25:01]  : Ну да, просто, насколько я знаю, там зависит от архитектуры сети, но там не один к одному выход, просто зависимость выходного слоя, там просто идет активирующая функция ко всем, грубо говоря, там так же само идет один ко многим, но просто там идут весовые коэффициенты и просто для других цифр весовые коэффициенты настолько малые, что их вероятность для других цифр очень маленькая за счет активирующей функции. но это обратно зависит от слоя и от архитектуры. 

S04 [00:25:36]  : нет, там один к одному как раз, если именно рисовать нейроны тела, смотрите, нюанс только в том, что такая схема обычно предполагает, что выходы независимы, а на самом деле там стоит софтмакс, а не седьмой. то есть они друг на друга могут влиять, но по сути 

S05 [00:26:14]  : просто если там стоит выход один к одному, зачем нам подактивирующая функция, когда при активации одного нейрона у нас сразу сработает и другой? то есть как раз активирующая функция и нужна, чтобы отделить, грубо говоря, одни весовые коэффициенты от других? 

S04 [00:26:27]  : активирующая функция в том числе еще нужна для того, чтобы определить кто насколько лучше другого и что за это будет. для backpropagation как раз активирующая функция важна и от нее меняется происходящее. а так вот для цели прямого распространения она как раз не важна. кто победил, тот победил. а победил там на копейку или победил на рубль, никакой разницы. 

S03 [00:27:01]  : хорошо, спасибо Юрий. еще Виктор Казаринов, у вас есть вопрос еще? вы руку поднимали. 

S01 [00:27:08]  : меня слышно? 

S03 [00:27:09]  : да. 

S01 [00:27:10]  : Здравствуйте. Ну, у меня, в общем-то, некоторые комментарии кратики. 

S03 [00:27:17]  : Ну, давай, если кратко только, давайте. 

S01 [00:27:19]  : Да-да-да. Вот Юрий говорит, что там вручную, ну, это в продолжение, кстати, дискуссии, насчет создания вручную правил. На самом деле, совсем это не так. Если мы берем систему автоматическую, и предъявляем ей изображение, она сама строит правила. Здесь есть такая система? У меня есть такая система работающая. Я так и делал обработку изображения. 

S03 [00:27:45]  : Хорошо, Виктор, извините. 

S01 [00:27:47]  : Подождите, минутку. 

S03 [00:27:49]  : Про вашу систему мы послушаем в другой раз. 

S01 [00:27:52]  : Я не собираюсь сейчас говорить про мою систему. Я еще хотел задать вопрос. то есть вот относительно. Юрий, вот посмотрите, ваши огромные тысячные или десятков тысяч наборы – это ведь тоже самое, вручную подобранные наборы. Их нужно было человеку через себя просортировать и сделать классификацию предварительную для обучения. Это тоже работа ручная. Все верно. 

S04 [00:28:24]  : Работа ручная, но прогнозируемая, и в данном случае как раз ручная работа, которая позволила сделать высококачественное распознавание, в то время как работа по созданию евреистических правил многие годы не давала высокого качества. причем даже на этой простой задачи. а сейчас мы перейдем к более сложной. 

S03 [00:28:53]  : да, я предлагаю двигаться дальше. 

S04 [00:28:56]  : хорошо, продолжаем. поставили. теперь вернем изображение. идем к задаче нашей второй CIFAR и наблюдаем очень интересный эффект. если мы... по сути модель с очень большим батч сайзом, она что делает? она усредняет на самом деле тут не 20 тысяч получился, там получился где-то 5 тысяч, потому что 8 из 8. на 8 батчей это все поделилось. эта модель усредняет исходный сигнал и мы видим как выглядит обобщенный самолет. вот это вот синенькое скорее всего, синий самолет на фоне такого голубого бело-бирюзового неба. Обычно. Хотя это не всегда небо, как мы видели здесь. Иногда это бывает там фон какой-то, иногда игрушечные самолеты, иногда по-разному. Но часто это небо. Точно так же вот этот по центру это вот часть лягушки какая-то и внизу видимо это вторая часть лягушки. Лошадь, но тут еще плохо пока что видно. По центру что-то такое коричнево-красное. На фоне другого цвета, спереди я даже не знаю, что это такое. Видимо, какая-то часть изображения была вот такая. то есть мы видим, что такие копейки чем-то похожи как раз на средневековый образ кота. лица кота. тоже олень, что-то коричневое на зеленом фоне и птица что-то такое темненькое. и таким образом даже вот такая модель уже показывает больше чем случайный процент распознавания. распознает на 23 процента. случайное распознавание, при том что классы одинаково представлены, было бы 10 процентов. здесь мы поставили чуть поменьше batch size. уже стало 10 элементов. И мы видим, чуть-чуть начинают картинки трансформироваться. Сравните их. Чуть-чуть корабль уже больше похож на море, чем на корабль. И вообще на что-то такое меньше виден сам корабль. Также трансформируются другие. Лягушка стала ближе к своему цвету. Хотя вот здесь в следующий раз, когда еще уменьшили батч-сайзы в тренировке, у нас правила еще поменялись. вокруг птички что-то зеленое, ну и так далее. у самолета что-то голубое. и вот как в анекдоте про систему распознавания изображений из 60-х, которые уже тогда умели отличать русские танки от американских, как мы знаем, на основании того, что русские танки были сфотографированы на темном фоне, а американские на светлом. Здесь происходит примерно та же самая ситуация, что на основании преимущественно цветового анализа модели уже на 30% распознают картину. Если мы будем дальше уменьшать размер, уменьшать, увеличивать количество конкурентов по сути дела на каждое изображение, на каждый нейрон, то у нас постепенно цвета меняются. Вот это на самом деле очень похоже на зеленую лягушку, а дальше они начинают расплываться. по той причине давайте я думаю вы догадались по какой причине почему этого не происходило у нас на месте почему на месте наоборот мы уменьшали watch size у нас картинка становилась только лучше до определенного порога здесь она наоборот ухудшается И это на самом деле проблема номер один для любителей, которые самостоятельно делают альтернативные какие-то нейронные сети, какие-то альтернативные модели. Опасность номер один, скажем так. частично прав, что много схожих факторов пикселей. именно так, что заметим, что вниз эти картинки были центрированы все. эти картинки, хоть они разные, хоть единички и под разным углом, но все равно они были отцентрированы. они не ездили по ней. за счет именно этого центрирования у нас как раз получилось выделить такие четкие для них образы, усредненные. Картинки, если мы снова посмотрим на картинки этих всех животных, там и все прочее, хоть они и делаются так, чтобы центральный объект в кадре был, но мы видим вот иногда котик сверху, картинки, иногда животное сбоку где-то, что-то и так далее. В общем, они в очень разных местах находятся. И вот этот наш алгоритм, который очень классно работал здесь, 1,8%, начинает работать плохо. выдает всего лишь 33. удалось добиться только 33 процента. если же мы посмотрим подробнее на вот эти наборы пикселей, в целом цветовые пятна действительно по цвету дифференцируются. тут немножко искажены цвета, конечно, но Вот это по центру что-то похоже на лошадь, вот это зеленое что-то похоже на лягушку, а это инверсные цвета, то есть что мы наоборот. Наоборот, если мы увидим фиолетовое, то фиолетовые лягушки на самом деле бывают, но очень редко встречаются. А это закономерность. 

S03 [00:36:34]  : Юрий, извините, я не могу здесь не встрять вопрос. Вы можете еще раз продемонстрировать лошадь? Вы говорите, что вот это красное пятно похоже на лошадь. Я не вижу, что оно похоже на лошадь. Да, пожалуйста. Хоть убейте. Я не могу сказать, что красное пятно похоже на коричневую лошадь. Хоть вы убейте. Чтобы вы понимали, о чем мы говорим. 

S04 [00:37:00]  : Цвета чуть-чуть искажены, во-первых. Во-вторых, разные RG и B друг с другом немножко отвязаны. 

S03 [00:37:10]  : Вы говорите, что пятно похоже на лошадь. Вы говорите это как совершенно очевидное. Но я не вижу, что оно похоже на лошадь хоть чем-то, кроме тем, что это пятно. 

S04 [00:37:21]  : Нет, именно тем, что оно пятно, оно и похоже. Тем, что это пятно в центре. у которого есть красный оттенок. 

S03 [00:37:29]  : то есть если пятно с красными оттенками в центре, то мы считаем, что это лошадь. 

S04 [00:37:36]  : да, и наоборот, если пятно зеленое, то зеленое это не лошадь. именно на таком уровне алгоритм и разбирается на эти 33 процента. именно так он и рассуждает. То есть по сути у нас алгоритм как раз по фону, как мы говорили, по пятнам и пытается распознавать объект. И на самом деле вот такой уровень зрения характерен для самых примитивных живых существ, насекомых каких-то попроще. у которых нет посеточных больших глаз. Вот они примерно видят цветовые пятна. Правда, там есть свои механизмы улучшения четкости зрения, но о них сегодня не будем говорить. ладно, с одним слоем понятно, из одного слоя больше не выжать. вот все правила, которыми можно описать картинку как-то, чтобы выделить птицу там или что-то, их, в общем-то, их видимо нет. поэтому не только мы авристиками не справились, но и компьютер. значит, идем дальше. Добавим второй слой. С одной стороны, этим мы сети обеспечили возможность более хорошего запоминания, потому что у нее скрытые теперь по сути вот таких нейрончиков теперь 20. сайз первого слоя, а сверху над ними еще переход из 20 в 10. связь 20-10. и мы кормим теми же батч сайзами. вначале проверяем как это все работает на мнисте. на мнисте это все работает не хуже, оно так же. работает. и вот мы можем уже посмотреть на то, какие образы получились. и да, насчет Насчет умниста, насчет разноцветных лягушек, лошадей и все прочее, абсолютно верно. Если выдавать разноцветных лошадей в разных местах, то и лягушек, то система вообще ничему не научится из одного слуга. поэтому есть очень-очень простой пример. очень простой пример – это движущийся вниз. здесь я его не буду рассматривать. по сути, если мы цифры не будем центрировать, а будем их двигать по-разному, оставаясь, мы видим, что даже вот так вот, даже если цифра целиком, чтобы была видна, все равно у нас есть достаточно много места, куда ее можно сдвинуть. Но при этом распознаваемость этих цифр одним нейрончиком сильно упадет, потому что он будет размазан как вот этот котик. Глаза видны, нос и уши, но они уже сильно размазаны. И, соответственно, с двухслойной нейронной сетью уже гораздо сложнее. Когда у нас был один слой, мы могли взять выход с этого нейрона, и нам было понятно, что это и есть тот образ, на который он ориентируется. Образ сигнала и образ конкурента. С двухслойными сетями вот эти 20 выходов, это информация, которая предназначена не для выхода, а информация, которая предназначена для второго слоя. второй слой на основании этой информации уже будет делать свои выводы, пытаясь по этим картинкам, по их усредненной яркости, то есть у него по сути 20 пикселей на входе. Один пиксель это сумма пикселей вот этого нейрона, на данной картинке второй, со второй картинки и так далее. Что происходит в данной ситуации? Образы начинают друг с другом путаться. смешиваться и начинают выделяться какие-то куски. они еще не четко оформлены, иногда бывает, что выделяется целый контр-сигнал. выделение контр-сигнала, соответственно, второй слой возьмет, вычтет и получит четкий сигнал для всех цифр, что это не двойка. также вот он вот это вот вычтет, получит сигнал что-то видимо там не семерка и там не знаю что-то еще не тройка. что-то такое, что там сбоку пусто, а по центру что-то есть. не нолик, наоборот, может быть нолик. и так далее. то есть у нас какие-то постепенно начинают выделяться куски. И информация нейронной сети перестает быть интерпретирована. Точнее, она продолжает быть интерпретируемой локально для какого-то конкретного сигнала. То есть мы можем четко сказать, что да, сработал такой-то нейрон, а другой нейрон не сработал. Например, мы можем достать нашу любимую игрушку playground TensorFlow и посмотреть, что на каждом нейроне, где он считает где ноль и где единичка, на каком сигнале. здесь изображение в другой плоскости находится, в пазовой. по умолчанию, если я никуда не тыкаю, давайте включу немножко. здесь то, что нейросеть на выходе считает. то есть если мы вот эти координаты x и y подадим на вход, вот такие вот, то есть минус 3 по y и минус 2 по x. то значит для этой точки значение нейрона будет по этой цветовой схеме минус 0,7. нейрон последнего слоя у нас один. а вот для вот этой точки с координатами 0,0, здесь точки нет, но все равно мы можем посмотреть, потому что просчитан для всех сразу точек изображения и ответ. что ответ нейросети будет около плюс 0.04. два класса мы можем таким образом отличать. Для каждого индивидуального сигнала интерпретируемость есть, но при этом интерпретируем, что происходит в сети, уже невозможно. То есть у вас программа стала не просто каким-то там вычислением промежуточных данных, а потом там выбором победителя. А вычислением промежуточных данных, которые уже непонятны. потом еще вычислением промежуточных данных в втором слое, а потом просто нейросеть говорит ответ, который часто оказывается правильным. внимание, шок. это работает, но никто не может понять почему. понять на самом деле почему могут, но для этого мы сейчас посмотрим немножко более удобное представление. когда нейросети дают смотреть первым слой на сразу на весь сигнал. она сразу берет много фич. но вопрос такой теперь. каким образом мы можем улучшить вот это изображение на первом слое и что-то с этим делать хорошее, чтобы у нас фичи были интерпретированы. но не фичи. это называется у нас точнее вот эти вот штуки. это действительно у нас фичи, которые нейросеть распознает. фичи первого слоя. значит на выходе фич у нас соответственно фича или attention map. как он называется, то есть сумма вот этого пикселя усреденной 20. и вот теперь мы увеличиваем размер этого скрытого слоя, пытаясь добиться более конкретной фичи. это первое, что мы делаем. ну вот что-то похожее на 0 наверное выловили, а здесь что-то похожее на 5. можно разглядывать эти картинки. тут вообще какой-то треугольник нарисован. здесь что-то похожее на 8. есть куча методов, но вообще говоря ничего напрямую из простых методов ничего не помогает. хотя с другой стороны мы начинаем замечать, что если смотреть не на белые части, а на черные, то постепенно начинают какие-то выделяться кусочки линий, какие-то отрезки линий. вот такой отрезок, вот такой, вот такой, дырки две, здесь вот такая вот дырочка. какие-то фичи начинают выделяться, но их надо наоборот смотреть в инверсном сигнале. хотя в инверсном сигнале тоже не до конца понятно, что это такое. если мы посмотрим, что происходит в это время. что происходит в это время у нас с второй моделью а вторую модель я даже не стал считать с двумя слоями но зато потренировал еще более мелкие суммы, надеясь, что будет более четкий сигнал, и добавил еще дополнительную штучку в SDK, это регуляризация для сети, которая штрафует нейросеть за то, что у нее веса ненулевые, причем чем больше у нее вес, модулю, тем больше штрафуется квадратичный алгоритм. и линии стали гораздо тоньше, то есть фичи стали гораздо тоньше. и теперь они, такая вот смесь положительного и отрицательного сигнала, оба достаточно тонкие на единицах, похожие на соответствующий фон, и так далее. но все равно непонятно, что происходит. Идем дальше. Еще один алгоритм. Еще один алгоритм, который позволяет теории как-то улучшить улучшить ситуацию. как мы видим, распознается на 94 процента, но при этом все равно не до конца понятно, что представляет из себя фич, хотя стало вроде бы и больше фич, которые как-то похожи на цифры или комбинации цифр, но не всех цифр, а комбинации одной-двух цифр. то есть это двойка плюс семерка, видимо. Тройка. Более четкий сталь, но все равно не очень понятно, что происходит. И, наконец, поэтому мы делаем следующий шаг. Делаем, чтобы фичи были не такими большими. делаем, чтобы у нас фичи были маленькие, вот такими 8 на 8. для этого мы делаем из сети, включаем конволюционные слои. в данном случае конволюционные слои почти ничем не отличаются. единственное то, что они применяются у нас внахлёст. kernel-size 8, astride 4, то есть шагом 4 применяются, а размеры они 8. и дальше 7 на 7 обрабатывается изображение. в общем, внахлёст вот такие вот получаются элементы. если мы к ним приглядимся, мы увидим, что эти элементы выглядят теперь как различные линии различные, возможно немножко закругленные линии, возможно прямые линии, но в общем-то какие-то линии, причем двух цветов. вот здесь, например, центр против края, здесь также, но в другом направлении, здесь также, но в другом направлении, ну и так далее. то есть у нас фичи свелись разнообразным контрастным таким вот в общем то в общем то это напоминает то что у нас наблюдается в мозгу и более того не только в мозгу а начинается то что это Еще в глазу у нас есть нейроны, которые именно так обрабатывают информацию, то есть называются полярные. У них есть он- и офф-зона, то есть в какой-то зоне он положительный, в какой-то зоне он отрицательный. Только в отличие от компьютера, который на одном вычислителе может очень много делать операции одинаковых. Человек так делать не может. В секунду он может делать операции очень мало, зато у него этих элементов, которые делают операции, очень-очень много. И поэтому то, что у нас здесь представлено вот так вот фичи, вместо этого всего 33 разных фичи. У мозга это повторяется постоянно, то есть постоянно мы должны эти фичи находить и по центру картинки, и сбоку картинки, и сверху картинки, и снизу картинки. Чему это приводит? Это приводит к механизму внимания, который как раз позволяет фокусироваться на центре картинки и для этого эту картинку двигать в центр. в центре у нас очень большая разрешающая способность и в центре мы хорошо распознаем детали, а по краям мы эти детали плохо видим, то есть если вы глазом посмотрите, будете удерживать на цифре 5, вряд ли вы там цифру вот этого узнаете, там четверку от девятки отличить и вообще даже может не узнаете, но зависит от вашего разрешения экрана и от того насколько далеко от компьютера. разрешение у человека по центру есть, но такие элементы у человека есть по центру и по краям, И на основании этого компьютеры с архитектурой CNN человека обгоняют просто на порядке. По вычислительной мощности, грубой, в первичных отделах. Но обгоняли бы, если бы у человека не было воистине большое число нейронов. который позволял бы это как-то компенсировать. и получается примерно в итоге почти паритет. в итоге получается, что на небольших картинках при распознавании объектов, которые небольшие по размеру, компьютер обгоняет человека. а вот если картинка большая, на ней надо найти маленький объект, то сравнимо или компьютер уже похуже будет. потому что компьютер обгоняет в том случае, если ему надо найти все объекты, потому что человеку придется концентрироваться на каждом объекте. есть известный эксперимент, когда вам говорят сфокусироваться на баскетбольном мяче, и вы не замечаете, как по кадру проходит черная горилла, вы ее совершенно в упор не видите. Хотя горилла необычна для этого кадра, и уж явно вы ее заметили, если бы а компьютер одновременно может все объекты посчитать. это достоинство, а вот недостатки то, что фичи у нас по-прежнему не интерпретированы. хотя фичи нижнего уровня у нас теперь интерпретируемы. и возникает вопрос, что если мы теперь сделаем interactive фич? вот у нас внизу палочки из этих палочек у нас. так же как у нас там у лошади. у лошади вот это вот можно воспринимать как большую палочку значит темненького цвета со светленьким фоном. ну и так далее. и дальше уже из этих палочек у нас получается следующий уровень распознавания. и таким образом иерархично мы можем распознавать сложный объект. у этого есть в свою очередь свой недостаток, то что пока мы собираем иерархию, вот эта иерархия не знает то, что в другом месте ключевой момент для распознавания объектов данного типа, поэтому мы на всякий случай должны пытаться распознать везде все типы объектов. это приводит к дополнительному расходу мощности, причем довольно значительно. но в общем как-то модели показывают даже в чем-то сравнимое с человеком качество распознавания. то же самое сделали на CIFAR. чуть-чуть получили 42 процента распознавания. еще получили получить 435. это я сделал, показал все фичи. то есть тут 33 фичи, но каждого цвета. вот это для R, это для G, это для B. видно что кроме линий бывают еще полосы, когда несколько линий, ну и так далее. тут есть очень интересные проекты по исследованию как раз тех результатов, то есть тех фич, которые возникают на нейросетях, поэтому я не буду более подробно останавливаться на этом всем и скажу, что в общем-то а вот эта вот интерпретация объектов, как сложенных из таких элементарных пич, в общем-то человека более чем удовлетворяет, и можно сказать, что на основании этого нейросеть не черный ящик, и мы действительно понимаем, как она работает, во всяком случае, CNN. Мы действительно понимаем на каждой картинке. Сейчас попробуем поиграться с картинкой побольше и с CNN побольше. То есть на том же Safari нейросеть достигает 90% качества. То, что нейросеть достигает и больше, но там уже встает вопрос, о том, есть ли там какие-то способы пользоваться дополнительной какой-то информацией, типа подбора картинок и подбора, эволюционного подбора нейросети под эту задачу. Смотрите, какая интересная штука получается. тысячи исследователей под этот мист подобрали, подбирали, перебирали миллион вариантов этих сеток. какие-то из этих сеток показывали результат на процент на два, иногда даже на несколько процентов больше других сеток. внимание, вопрос. ведь это получается у нас, мы запустили эволюционный алгоритм по выбору лучшей сетки, и этот алгоритм дал нам дополнительный какой-то бонусный результат. вопрос в том, воспроизведется ли этот бонусный результат, если мы сгенерируем другой датасет, который будет устроен также как CIFAR, но там будут другие картинки, то есть привязались ли мы к конкретным картинкам CIFAR, тогда вот этим вот нашим генетическим алгоритмом мы искали наилучшую сеть для CIFAR. И выясняется, что действительно, да, это так и есть, и реальный процент скорее должен быть около 90, а не около 95, а вот эти 5%, это лишние, это именно подбор за счет генетического алгоритма, за счет подбора тех параметров нейросети, а их действительно можно перебирать очень много, и даже не миллион, а миллиард вариантов можно перебирать нейросеток. и какие-то действительно лучше работают на конкретных этих изображениях. такие генетические особенности есть у людей. как мы знаем, какие-то люди лучше работают с какими-то типами данных, кто-то с музыкой лучше работает, кто-то с картинками лучше работает, кто-то тексты лучше пишет или понимает и так далее. Кому-то лучше иностранные языки даются. Это тоже какой-то генетический алгоритм на обучающих данных. Сейчас давайте поиграемся с более крупной нейронной сеткой. мы что-нибудь рисуем и смотрим, что нам нейросеть выдает и что на разных слоях этой нейросети есть. то есть вот здесь у нас пока что были интерпретируемые более-менее фичи. то есть вот это как раз и есть разные фичи, как они применились в конкретной картинке. здесь у нас также. здесь у нас strike равно единице. поэтому у нас картинка, то есть видно сразу все ее элементы, и мы видим, что по сути фичи первого слоя, что они делают, они там выделяют разные, вот это выделяет явно диагональные такие элементы, вот это выделяет синеньким цветом то, что она выделяет, это выделяет вертикальные элементы, а это выделяет горизонтальные, диагональные в другую сторону элементы, это выделяет горизонтальные элементы. если мы посмотрим на то, как работает наш фильтр от нейросети, подумаем, а что будет, если мы перемножим вот эту матрицу на картинку. представим, что у нас была горизонтальная линия. здесь были единички, а краям были нолики. если мы так сделаем, то у нас получится результирующие много вот здесь единичек. значит у нас выделится у нас получится очень большое число в итоге, когда мы просуммируем эти единички. а вот если у нас была вот такая линия и перемножив ее на вот эту линию, мы получим плохой результат. более того, это области где мы отнимаем по краям, а здесь мы прибавляем. и получится, что мы может даже больше отняли, чем прибавили, но вертикальная линия не выделит или выделит негативным цветом, как в общем-то здесь обычно происходит. если мы горизонтальной линии выделяем таким цветом, то вертикальный или диагональный мы можем выделить другим цветом. это светлый, а вот черным заметно все остальное. И то же самое наблюдается на следующих слоях, только мы уже не очень понятно, что произошло дальше. Дальше происходит какое-то объединение. Там, где у нас целевой сигнал правдоподобный, у нас появляется много много единичек или много ноликов, но на самом деле мы это опять же не поймем, потому что у нас еще есть умножение, еще одно, и у нас может перевернуться циферка. угол светлый станет наоборот темным, то есть это наоборот как минус сигнал работает. и таким образом вот у нас устойчивое распознавание вот единичка, он сожглась единичкой, и вот можно посмотреть, какая единичка, куда она как пришла, где-то вот этот вот получается битик, но не битик, элементик, и вот этот вот, и вот этот, и вот этот, и черненький отвечают за единичку, если мы сейчас сотрем, нарисуем двоечку, видим, что другие какие-то элементики отвечают у нас за двоечку. То есть мы уже не можем проинтерпретировать, это уже не двухмерная информация, а одномерная. Не можем понять, что здесь находится, но, тем не менее, у нас появилось распределенное представление для этой самой информации, которая у нас есть. то есть для двоечки у нас нейтральные появились вот здесь вот нолики, вот здесь вот у нас в этом месте в этой позиции единичка стоит, вот в этой позиции единичка, в этой позиции у нас стоит нолик. вот это представление в общем-то тоже распределенное представление, оно называется one-hot representation. на русском по-моему ни одного нет. что-то пытались придумать в литературе, но я его даже не запомнил. one-hot, потому что одна единичка, остальные двойки. one-hot representation для двойки это позиции двойки, у нас единичка в остальных позициях. а вот это представление это действительно распределенное представление, причем разреженное. у нас много значений с низким уровнем сигнала и мало значений с высоким уровнем сигнала. ну а там направление вот в общем то есть теория CNN, за исключением некоторых сложных моментов, типа всегда ли они обучаются, насколько быстро они обучаются, обучаются ли они в принципе, если распознать информацию можно, и других теоретических моментов, на которые никто не знает ответа. за исключением вот этих моментов на практике все с CNN ясно. и с продолжением типа attention тоже в общем-то все ясно. вот так что вот такие дела. я думаю вот основы почему нейросети не черный ящик и одновременно почему они по-прежнему черный ящик в некоторых местах я тему думаю раскрыл вот а если а вот по-позже мы можем если время останется еще поговорить про более сложную тему, как же в других случаях выделять информацию, то есть с картинками вроде все ясно, с текстом на самом деле вот если представить, подумать, что текст тоже представлен таким же образом, то есть у нас есть единичка для слова, если это слово находится в позиции 10, вот здесь у нас единичка, если слово в словаре 10, а если у нас слово в словаре 20, то вот здесь единичка. если слово в словаре 50, то у нас вот здесь единичка. такой же one-hot представление для слов, в общем-то, и есть то, как сейчас представляются тексты при распознавании. соответственно, тогда фраза у нас будет выглядеть примерно вот так. это фраза мама мыла рамы познакомьтесь. узнаете? не очень-то узнаваемо, но тем не менее если пронумеровать позиции, то она будет узнаваема. и единственный нюанс возникает с таким представлением мы не знаем это мама мыла рамы или рама мыла. раму мыла мама. раму это знаете такое имя есть индийское. и вообще там с этой фразой связано много приколов по поводу того что все слова здесь на самом деле многозначные. «мама» тоже при изрядной доле фантазия многозначная, и слово «рама» многозначное, и слово «мыло» тоже многозначное. Поэтому ситуация еще более усложняется, но тем не менее вот этот подход, который называется Bag of Words, позволяет частично нам тоже заниматься распознаванием текстов. и, в общем-то, для своих задач неплохо работает. там, где он не справляется, можно его улучшить, можно именовать, номеровать не слова, а пары слов. ладно, не будем пока так глубоко заходить. давайте лучше я отвечаю на вопросы и попытаюсь понять действительно ли я раскрыл тему или все-таки я тему еще не полностью раскрыл? 

S03 [01:13:01]  : Юрий, спасибо. По поводу вопросов. Здесь было много комментариев и вопросов от Владимира Смолина. Я бы предложил Владимиру Смолину подготовиться и эти вопросы озвучить голосом системно. Но прежде несколько вопросов от нас с Алексом Буром и Виктором Казариновым. У меня первый вопрос. Смотрите, мы тут критиковали в узком кругу недавно разных докладчиков. а также многих докладчиков. И, в частности, была критика в адрес, к примеру, того же самого Владимира Смолина, что много рассказываются основы, а к чему – непонятно. Соответственно, в каком-то смысле у меня тоже есть критика, что вы очень хорошо и прекрасно, я считаю, рассказали основы, но я так и не понял, в чем суть защищаемых тезисов. И если я правильно понял, для себя защищаемое положение, которое на самом деле можно было бы выдвинуть в начале доклада, а потом зафиксировать в конце, это то, что если у нас нейросеть однослойная с локальным представлением, то у нас нейросеть и не черный ящик, А как только мы переходим к распределенным представлениям и многослойными сетями, у нас нейронная сеть сразу же становится черным ящиком. Что на самом деле говорит о том, что нейронная сеть – это черный ящик, потому что однослойные сети никого не интересуют, потому что они не инвариантны ни к чему вообще. То есть, просто это оверфитинг в чистом виде. Сейчас я закончу, хорошо? И смысл представляют, практически смысл в большинстве приложений представляют именно нелинейные многослойные нейронные сети. которые, в моем понимании, из того, что вы показали, являются неинтерпретируемыми. Соответственно, отталкиваясь от того, что я сказал, вы можете сформулировать то, что вы хотели донести? То есть, что вы хотели донести до аудитории вашим докладом? Какие тезисы? Какие выводы? 

S04 [01:15:08]  : Значит, тезис номер один. Да, однослойная сеть и черный ящик, и более того, однослойная сеть. это как раз возможность нам проинтерпретировать любые другие модели. они широко применяются для этой цели. каким образом? мы аппроксимируем то, что другая модель или какой-то кусок другой модели делает с помощью однослойной нейронной сети. И таким образом мы выясняем те сигналы, на которые срабатывает этот кусок сети или чего угодно другого. Все такое используется и для текстов, и для всего чего угодно. И является таким вот крутым результатом. То, что многослойные сети неинтерпретируемы, Вот, ну нет, они интерпретируемые. Мы можем интерпретировать, что это значит. Мы можем интерпретировать, как она работает. Проблема в другом. Система сложная. Человек не приспособлен для того, чтобы понимать сложные вещи. Именно поэтому. 

S03 [01:16:30]  : То есть дело для человека, оно неинтерпретируемое. 

S04 [01:16:40]  : смотрите, вот мы принимаем какое-то решение. вот у нас, допустим, мы берем известный метод, когда мы выписываем плюсы и минусы, которые последуют, если мы примем это решение, и дальше мы смотрим, чего у нас больше плюсов или минусов. как-то их взвешиваем. это ровно однослойная нейросеть. вот эти плюсы это как раз те элементы, которые мы складываем с положительным весом. минусы это те элементы, которые мы складываем с отрицательным весом. и мы принимаем вот это решение, а это и есть, как работает настоянная нервность. Мы принимаем решение. Если мы попробуем принять решение в организации, где 10 человек, каждый из которых выписывает свои 10 каких-то положительных, отрицательных плюсов и минусов решения, друг другу они их не рассказывают, даже если рассказывать, но свели они в таблицу. дальше ВОЗ принимает решение по большинству, то есть как большинство решило из них. вот мы получили двуслойную нейросеть. является ли она интерпретируема? да, вот эта таблица у нас записана, она интерпретируема, но при этом мы можем в каждом конкретном примере понять, что пошло не так или что пошло так. я не стал в это углубляться, но мы можем понять, на что нейросеть реагировала. в обратную сторону, пропустив сигнал, например, мы можем понять, чего не хватает этим трем точкам, чтобы из них получилась пятерка или двойка, как нейросеть предположила. и наоборот, что не так, что это не похоже на тройку. на нейросети. Мы можем это все сделать, но процесс становится трудоемким, и его трудоемкость как раз определяется количеством информации, которая обрабатывается. Уже в однослойной нейросети, а тем более в двухслойной, количество информации в десятки тысяч позиций и доходит до миллиардов позиций. Этот процесс просто человеком не может быть проделан, но при этом нейросеть, она как бы интерпретируема. То, что мы иногда понимаем под интерпретируемостью, это процесс немного другой. Это процесс сжатия, получения сжатого представления о тех факторах, тех основных факторах, за счет которых мы приняли решение. Но хорошо... 

S03 [01:19:34]  : давайте я попробую. спасибо. я понял. я попытаюсь вот от этой точки как раз задать мой второй вопрос. он как раз про это будет. 

S04 [01:19:40]  : давайте я последнее предложение договорю. и вот смотрите. вот я нарисую тройку. вот мы ее поделим на квадратики, на какие-то элементы. и вот внимание вам вопрос. вы хотите, чтобы вам была просто интерпретируемая модель. вот скажите, на основании какого значения в каком из этих маленьких квадратиков, пикселей, каких-то кругляшков небольших вы принимаете для себя решение, что это тройка. есть ли такой один кругляшок или два или три пикселя? их просто нету. поэтому может ли существовать одиночное решение какое-то, на основании которого вы считаете, что это тройка или что-то. нет, его нет. то есть проблема интерпретируемости сводится к тому, что существует ли такое простое какое-то простая какая-то интерполяция но там для тройки это может быть интерполяция двумя полупругами например или чем-то таким и поскольку мы можем речью компактно передать другому человеку информацию два полупруга всего два слова мы считаем что это легко интерпретировать. то есть вот идет наш AXE и метрика Калмагорова сложности алгоритма. алгоритм тем сложнее, чем он длиннее. интерпретация тем сложнее, чем она длиннее. в этом плане эта задача принципиально не детерминирована, а экспоненциально-полиномиальная. не существует алгоритма, который бы находил простое 

S03 [01:21:46]  : Хорошо, Юрий. Это понятно. Вы уже повторяете. Спасибо. Просто давайте, чтобы мы успели все вопросы ответить. Я все-таки задам. У меня практически вопрос. Он, наверное, недостижимый для того, что вы показывали. Но вот хотя бы намеки какие-то. У меня есть задача. Я натренировал сеть отличать китов от слонов. И вот я хочу спросить у уважаемой нейросети, чем отличается кит от слона. Либо кит – это много синего фона, а слон – это много зеленого фона. Либо кит – это раздвоенный хвостовой плавник с дыркой на голове, а слон – это длинный хобот с большими ушами. Вот вы можете дать какой-то намек, как нейронная сеть может дать либо один, либо другой ответ. Соответственно, нейронная сеть, которая мне даст первый ответ, я ее выкину. А нейросеть, которая даст мне второй ответ, я ее буду использовать в своей практической работе и буду доверять ей принятие важных решений. 

S04 [01:22:54]  : Ну, во-первых, мы сейчас вернемся к вопросу. какая часть стройки? 

S03 [01:23:01]  : плавник или что у этой стройки? я не программист, я пользователь. 

S04 [01:23:12]  : предположим, что существует такая компактная фича, в которой можно различить два класса или там даже конкретный пример. как эту фичу найти? очень просто. если у нас есть какие-то уже заготовленные или какие-то интерпретированные представления, например, у нас есть заготовленные представления для разных цифр в голове у человека. и если на каком-то слое это изображение похоже, его значение похоже на то изображение. похоже на тот образ нужного элемента, который у нас есть, то это значит мы можем нейросеть могла бы выдать этот элемент. То есть, грубо говоря, мы берем каждый из этих элементиков, находим для него соответствующее текстовое описание. Вот эта штука отвечает за за верхний хвостик там у единички, не знаю, так же, как хвост у кита, вот это и так далее. А дальше мы смотрим, о, вот здесь у нас единичка, а все остальные нолики. Ну, конечно, значит, единственная фича, которая была принята во внимание, значит, это хвост кита. Ну, то есть это раздвоенность хвоста. 

S03 [01:24:43]  : Как я узнаю, что это хвост кита? 

S04 [01:24:45]  : Да, раздвоенность хвоста, вот она, единичка. 

S03 [01:24:48]  : А как я узнаю, что это раздвоенность хвоста? 

S04 [01:24:52]  : Для этого вам нужно провести процедуру, когда вы даете нейросети разные элементы и смотрите ее отклик, а потом наоборот привязываете нейросеть к этим откликам. 

S03 [01:25:08]  : То есть для бизнес-пользователя это будет нереализуемо? Да, это тяжело. Возможен ли pipeline, который просто отвечает на мой вопрос? 

S04 [01:25:22]  : Да, он возможен. Он делается как раз за счет того, что... Ну вот хотелось чуть позже, если успеем, поговорить про... Одно из применений для нейросетей было клип, нейросеть, которая связывает текст с картинками. По сути, во время обучения нейросети произошло именно это. Нейросеть, одна часть нейросети, училась выделять из текста какие-то закономерности связывать с картинкой. С другой стороны, происходил обратный процесс, визуальные закономерности пытались привязаться к каким-то текстам закономерности. В результате какие-то закономерности друг к другу привязались. Если попросить удаленно рисовать вам картинку кита с раздвоенным хвостом, он вам нарисует картинку кита с раздвоенным хвостом. 

S03 [01:26:28]  : Ну то есть через граундинг это решается в конечном итоге. 

S04 [01:26:31]  : Это решается всегда через граундинг. 

S03 [01:26:34]  : Спасибо. Юрий, вы ответили на мой вопрос и, значит, хвостик к этому вопросу. Вот то, что вы говорите, Анна, как это работает с точки зрения инвариантности к масштабу и повороту? 

S04 [01:26:45]  : С точки зрения инвариантности к масштабу и повороту, ну дело в том, что у человека нет инварианта. 

S03 [01:26:50]  : масштабный поворот я понимаю но практические задачи человек решает все-таки вот у меня вот вы рассказываете она может все дворе отностью посмотрите вот какая вот эта цифра но естественно один кверх ногами 

S04 [01:27:06]  : у вас есть какой-то опыт, который позволяет определить, что это один кверх ногами. хорошо. 

S03 [01:27:11]  : у нас же семинар AGI посвящен, а не нейросетям. 

S04 [01:27:15]  : а вот это какая число? 

S03 [01:27:17]  : а это такой цифры нету. либо это девятка или шестерка в зеркале. 

S04 [01:27:24]  : а может это отраженная шестерка или девятка? 

S03 [01:27:26]  : 4 варианта. точнее два варианта. либо такой цифры нет, либо шестерка, либо девятка в зеркале. три варианта ответа сходу. 

S04 [01:27:39]  : компьютер тоже считает, что это девятка. он увидел кругляшок и говорит, что кругляшок похож на девятку и в этом месте находится наверху вся девятка. 

S03 [01:27:49]  : То есть, нейронные сети не инвариантны к масштабу и повороту. Человек тоже не инвариантен. Я понимаю. Окей, я получил ответ. Все, идем дальше к вопросам Алекса Бура. Алекс Бур спрашивает. Сменили размер картинки и взяли картинки по типу, как дальтоников проверяют на дальтонизм. Он там даже ссылку присылает. Нейросети смогут отличать цифры на тестах для дальтоника? 

S04 [01:28:20]  : Смогут, но тут скорее ситуация такая, что нейросети на маленьких картинках видят лучше человека. Да, они смогут отличать, но вот как нейросеть, которая видит лучше человека, будет реагировать? на картинку, где надо наоборот смазанно как-то усредненно что-то понять, а если ее тренировали только на четких картинках, может быть и не увидят, может быть и увидят. 

S03 [01:28:50]  : Юрий, спасибо, я дополню ваш ответ, значит был целый очень известный стартап. 

S04 [01:28:55]  : Человек при этом учится на смазанных картинках тоже. 

S03 [01:29:02]  : Ой, я дополню. Значит, был целый известный стартап и до сих пор даже, наверное, есть. Значит, стартап возглавил, отпечатковался от Ньюмен и Джеффа Хокинса. Назывался он... Так, вылетело сразу название из головы. Короче, они именно специализировались на взламывании капч. То есть, на самом деле, тесты для дальтоников – это просто частный случай того, что называется капч. И они достаточно успешно научились снимать все возможные капчи. Я потом вспомню название и скину ссылку этого стартапа. Так что, в общем, если хорошо сконструировать эти сетки и затренировать их на разных капчах, то да. Следующие вопросы дальше от Алекса Бура. Еще вопрос от Виктора Казариного. Как решается в ЦНН проблема несоответствия фиксированного размера полей фич стягиванию полей зрительных нейронов глаза? 

S04 [01:30:03]  : смотрите по сути речь идет как я понимаю о том что вот глаз видит картинку как вот он центр видит очень жирно тройки края видит тоненькими вот если он смотрит конкретно то есть это просто искажение картинки, как будто мы линзу навели на картинку. то есть центр ее будет увеличен, края будут... то есть не линзу, которая увеличивает, а линзу неправильную, которая искажает. 

S01 [01:30:38]  : можно я уточню вопрос? у человеческого глаза зрительные нейроны несколько раз, какое-то количество раз в секунду. Поля каждого нейрона, вот эти вот зрительные поля, которые выделяют центральную точечку и вокруг, они пульсируют. То есть сначала человеческий глаз почти ничего не видит, потом видит крупные детали, потом более детальные и так далее. И каждый нейрон на любом точке своего глаза. Это приводит к тому, что размеры фич в корее мозга остаются прежними, но охват в амазоне зрительного поля разного размера. Сначала большие детали анализируются, потом более мелкие и так далее. Здесь то же самое получается, но у вас фиксированный размер фичи, которая проходит, сканирует. Вот в этом проблема. И тогда можно было бы, по крайней мере, по масштабированию инвариантность улучшить. 

S04 [01:31:40]  : Смотрите, как делается инвариантность по масштабированию. Да, отвечу все-таки на этот вопрос. Давно его уже задавали, я толком не мог ответить. Делается просто многомасштабность, по сути. То есть делаются сети на несколько масштабов, которые в несколько раз обычно друг от друга отличаются по размеру. И с поворотом то же самое, Юрий, правильно? И с поворотом не совсем то же самое. С поворотом это решается в основном attention, но и это тоже. То есть немножко, чуть-чуть повернутую единичку даже сетка распознает, если мы сильно начнем поворачивать единичку. то нейросетка ее не распознает. Более того, если мы будем учить, то произойдет смешивание сигналов, потому что единичка боку может на что-то тоже быть похожей. Поэтому здесь вопрос, как выделить рамку правильного расположения объекта, вот эту вот рамку. Собственно в этом и заключается механизм attention, внимания у человека. что он не только фиксируется на элементе, но и смотрит, в каком направлении ее распознавать. 

S01 [01:32:57]  : Можно еще дополнить чуть-чуть. Человеческий глаз по определенному углу тоже имеет возможность анализировать неподготовленно на поворот. Только угол превышает какой-то порог, он перестает распознавать без подготовки. 

S04 [01:33:21]  : распознаваемость. смотрите это чем вызвано. тем что даже если мы видели всегда только вертикальные палочки, все равно мы там немножко поворачиваемся, сдвигаемся, мы видим эту палочку повернутой. очень легко увидеть, и они воспринимаются как одна и та же палочка. А вот боком смотреть, сильно боком нам приходится смотреть, чтобы эти же объекты как-то, то есть если мы не можем понять, что за объект, приходится там сильно переворачиваться. 

S01 [01:34:11]  : Давайте разделим два восприятия в человеке и в такой же системе, как искусственное. Есть первичное восприятие, есть вторичное. Вторичное – это то, что требует длительного продумывания. а вот первичная, то сразу же раз, вот типа нейросетки, сразу же и распознала. Вот у человека первичная система без подготовки, без продумывания, почему это девятка или зеркальная девятка и так далее, начинаем думать. Вот она как раз очень ограниченная, но тем не менее имеет возможность инвариантов на поворот и масштабе. 

S04 [01:34:40]  : С зеркальностью нет, это не так. А зеркально вы большую часть звука не распознаете. если вы не тренировали специально. 

S01 [01:34:52]  : я не говорю, я сказал только про поворот. 

S04 [01:34:56]  : я говорю дело в том, что голова поворачивается. вы одновременно рядом получаете единичку вот так вот и единичку немножко повернутую просто потому что вы повернули голову. и вот такой вот сигнал именно вы в среднем вы и учитесь распознавать как единичку. Именно поэтому у вас на небольшие повороты происходит срабатывание. А на большие повороты настолько вы голову не поворачиваете обычно при распознавании. И это более редкая ситуация. А во-вторых, там есть еще другое явление. Мы говорили про супервайзинг. 

S03 [01:35:46]  : Хорошо, Юрий, спасибо. 

S04 [01:35:51]  : Давайте я тут чуть-чуть договорю тоже. В случае ансамблевайза происходит то, что в какой-то момент нам вначале хочется вот эти образы, мы не знаем единичка или не единичка, но хочется вот этот образ отличать от вот такого образа. И, возможно, вот от такого образа тоже отличать. То есть они у нас должны внутри быть разными образом. Поэтому у нас формируются на большие повороты разные образы. А только потом мы уже учимся понимать, что вот такая штука тоже может быть единичка, только написанная боком. 

S01 [01:36:39]  : но есть и другой вариант. это все может быть похоже, но частично, причем сразу же инварианты отделяются друг от друга, идут параллельными каналами распознавания. 

S04 [01:36:58]  : я говорил, что инвариантом будет единичка, немножко повернутая, но не сильно повернутая. вот такой вот обобщенный образ единички. 

S03 [01:37:08]  : Хорошо, давайте дадим слово Владимиру Смолину, если у него остались вопросы. Владимир? 

S00 [01:37:19]  : У меня не то, чтобы осталось вопросов. На самом деле, этот вельбес, который Смолин взял, я, конечно, могу критиковать, что он не имеет никакого отношения к сильному искусственному интеллекту. Но это просто обращаю внимание Юрия, что критиковать другого докладчика очень просто, а сделать самому всегда сложнее. То есть у меня более технический вопрос. Вот, как бы сказать, известно, во-первых, что, собственно, у них механизм backpropagation, ну и, значит, сам к себе он не работает, но есть эти, там, dropout, там, batchnorm, нормализация, ну, еще, там, десятки пальцев можно загнуть, с которыми все начинает работать. Вот вы считаете, что это не отбросы, а это продвинутые теории? 

S04 [01:38:00]  : Нет, смотрите, во-первых, это не так. Во-первых, нейросетки без батч-норма с дропаутом одни, например, работают, длинные, и наоборот. Дропаут вообще не нужен, когда у нас много данных. а нужен только когда у нас мало данных и предотвращает запоминание нейросеткой быстро, и потом за счет этого то, что сетка плохо учится. То есть результат она не обобщает, а именно запомнила конкретные образы. Какие мы как раз видели, какие образы запоминает сетка. Батч-норм – это техника, это технический метод, который в мозгу, в общем-то, применяется. Это, по сути, подстройка под уровень сигнала. Он настолько естественный, что, мне кажется, для понимания того, как работают сети, в целом на нем останавливаться не надо. 

S00 [01:39:02]  : Тогда можете объяснить, почему вы с 2015 года стали употреблять, если он настолько очевиден? 

S04 [01:39:12]  : Понимаете, в чем дело? Сетки большие можно заставить работать без батч-норма, но нюанс такой, что у сетки может начаться 

S00 [01:39:34]  : Большая сеть, она либо гаснет, либо разгорается. Активность – это первое, что приходит в голову, чтобы этого не было. Почему только в 15-м году это начало появляться? Как вы это интерпретируете? 

S04 [01:39:50]  : Это способ именно упрощения. То есть мы могли бы подобрать эти параметры как-то генетическим алгоритмом или так, как раньше, в общем-то, и делали до 2010 года. 

S00 [01:40:01]  : Я понимаю, что меня интересовало. Но я не буду делать, не смогу. 

S04 [01:40:08]  : Там была причина другая. Почему? Большие сетки не работают. Совсем другая. Но, в общем, Просто BatchNorm позволяет нам автоматизировать этот процесс. То, чтобы мы из любых кусочков наляпали сетку и она работала. Мы могли бы сами подобрать у человека в голове. У человека в голове есть настройки, какой уровень для какой зоны коры должен быть в каком возрасте. Вот, уровень работы. И на этом определяется то, что нейросеть в голове одновременно и учится, и одновременно у нас нет постоянных эпилептических припадков и бессознательного состояния. 

S00 [01:41:07]  : Хорошо. Можно еще вернуться к вопросу, который задавал Терехов? 

S04 [01:41:10]  : Ну, как бы человек без этого живет. 

S00 [01:41:13]  : Ну, как бы сильно не смелец. И с моей точки зрения начинается, когда мы начинаем решать задачи, которые решаются статистическими методами. 

S04 [01:41:24]  : У вас есть какой-то переход в этой ступени? Смотрите, что такое статистический метод? статистический метод, когда мы берем, накапливаем где-то какую-то информацию суммированную, а потом как-то используем эту суммированную информацию. Этот процесс суммирования информации происходит во многих ситуациях, очень многих. Вот если, я не знаю, Если я руки мою, то что у меня в голове происходит при этом, это статистический процесс, там есть статистика. Есть много суммирований сигналов, в каждом нейроне происходит суммирование сигналов. 

S00 [01:42:20]  : Давайте там про теннис кошек не будем. Переход какой у вас? В чем он состоит? Что такое статистическая обработка? Есть суммирование, это статистическая обработка. Ну, хорошо, если вы не хотите понимать вопрос, я не буду вам задавать. Спасибо. 

S04 [01:42:49]  : Вы просто сами-то границу как-то проводите? 

S00 [01:42:52]  : Да, я предпочитаю вам... Как вы ее проводите? Хочу понять, я считаю, что не надо наставить. 

S03 [01:42:59]  : Хорошо, давайте двинемся дальше. Николай Робчевский, у вас комментарий или вопрос? То, что вы написали. Есть желание прокомментировать или уточнить? 

S02 [01:43:12]  : Да, это не вопрос, это даже не комментарий, а, скажем, замечание. Так что, наверное, нет у меня вопроса. 

S03 [01:43:23]  : То есть, Николай написал, что получается так, что человек объяснить свои решения, что на что похоже или нет, не может, но для того, чтобы объяснить нечто в нейросети, человек должен сравнить похожесть с фич, то есть, выполнить операцию субъективную и необъяснимую. Но человек, тем не менее, это делает. И всё-таки мы, насколько я понимаю, у нас семинар посвящён сильному ИИ, где мы должны обсуждать то, как мы задачи решаем, а сейчас, как я Вот Юрий, а сейчас я закончу всё-таки своё сообщение. То есть, Юрий, то, что я услышал, то, что задача вообще неразрешима. То есть, поскольку нейронные сети не могут на самом деле ничего объяснить, если они большие и сложные, точно так же, как человек не может ничего объяснить, то мы в конечном итоге никогда ничего сильного искусственного интеллекта не сделаем. Не совсем так. Это то, что я услышал. Возможно, я все-таки закончу, подведу к своему вопросу, который у меня есть. Вот смотрите, у нас следующий семинар будет про онтологии. Я не знаю, считаете ли вы, что онтологии нужны или нет, но мы про них будем говорить, и поэтому у меня вопрос с точки зрения того, что онтологии, наверное, все-таки нужны. И вот если онтологии нужны, каким образом? С помощью нейросети узнать, что кит – это то, у чего есть плавник и дырка на голове, а слон – это то, у чего есть четыре толстые лапы, длинный нос, большие уши и маленький тоненький хвостик. То есть, мы строим классы, у классов выявляем атрибуты, у атрибутов у классов есть свойства, у атрибутов есть свойства, мы строим некоторую систему понятий в результате взаимодействия с окружающим миром. И это одно из качеств или свойств или фишек сильного искусственного интеллекта. Вот у нейронных сетей Это есть, и если есть, то где? Потому что из того, что вы сказали, я понял, что у них этого нет и никогда быть не может, потому что это очень сложно. 

S04 [01:45:40]  : Но все же, да, возможно, я был неточен в том плане, что как-то неудачно сформулировал. А на самом деле не так. Нейросети могут объяснить. то, что происходит, и наоборот, могут компактно объяснить. Но следует понимать, что эта задача, это другое толкование термина интерпретация. Как раз я, когда материал готовил, Я осознал, что, увы, в один семинар все не войдет, и все же ликбез, вот этот вот, я посчитал, что нужен все же. Чтобы было с чего начинать разговор вообще проинтерпретироваться, то есть про внутренние представления нужно очень четко представлять. чтобы потом говорить, как на основе этих внутренних представлений может быть сделана интерпретируемость. 

S03 [01:46:44]  : Я правильно понял вашу ремарку, что вы видите смысл продолжить этот разговор уже с точки зрения того, как именно строить настоящую интерпретируемость и извлекать знания из нейронных сетей? 

S04 [01:46:55]  : У меня потенциально есть семинар, за мной зарезервированный был на 10 февраля, Я не помню, сдвинулась, не сдвинулась. Я не уверен, смогу ли я именно к 10 февраля подготовиться и придется передвинуть, но я хотел бы продолжить. Также попробовать в формате, что там 40 минут, там час я рассказываю, а дальше мы уже обсуждаем разные вещи. Именно уже поговорить про верхнеуровневые использования вот этих вот схем, связанных с нейронными сетями и с распределенными любыми представлениями знаний, которые позволяют нам доходить уже до уровня интерпретируемости в другом его значении. То есть частично на вопрос, в каком виде компьютеры выделяют информацию об окружающем мире, я думаю, ответил. Теперь вопрос в другом, как вот эту воспринимаемую ими информацию замапить, заграундить на что-то, что люди привыкли выделять. И вот там есть сразу несколько подходов, и я бы вот эти подходы как раз бы обсудил бы, и обсудил бы как раз вопросы, связанные как раз с интерпретируемостью в другом именно значении, как не доскональное понимание, что нейросеть делает, когда она распознает объект, восприятие, как получить компактное представление, скажем так, или, наоборот, по компактному представлению, как получить образ в нейросеть. 

S03 [01:48:52]  : Хорошо, да, принято. У нас как раз формируется, я вижу, традиция двухсерийных семинаров. Единственное маленькое замечание. Вы сказали, что вы рассказали, как компьютер видит окружающий мир, но мне кажется, вы рассказали про то, как видит мир сверточной нейронной сети. Есть другие способы видеть окружающий мир, может быть, не все их мы знаем. Например, насколько я понимаю, сети в Хопфилда видят окружающий мир не так, как вы рассказали. Система Discovery Витяева видит мир тоже не так, как вы рассказали. Поэтому то, что вы рассказывали, это не про то, как компьютеры видят окружающий мир, а то, как его видят сверточные однослойные нейронные сети. 

S04 [01:49:33]  : Я взял этот пример сверточной однослойной и многослойной нейросети. именно для удобства. 

S03 [01:49:43]  : Нет, мне все принято, все принято, спасибо. 

S04 [01:49:46]  : Но при этом вот отвечу и на ваш вопрос. Верно ли то, что сеть Хопфилда и там какие-то другие технологии видят мир иначе? То, что я делал supervised вариант сети, я мог построить и unsupervised вариант сети. Он был бы настолько же наглядным и даже можно сделать сравнимый по наглядности вариант и для Мниста, и для CIFAR, и так и делается сейчас. И про другие технологии тоже можно сказать, что, в общем-то, способ примерно один. Вот такой способ, как какие-то элементы мапятся каким-то преобразованием на это же представление на другом слое. И вариантов представлений, их ограниченное число, их всего-то, кто-то может считать, что всего один даже, кто-то может выделять там три подвида этого представления, но в общем-то все к этому сводится. Других вариантов просто нет. И у человека в голове, и у компьютера, и у альтернативных алгоритмов все представляется примерно одинаково. Вопрос в том, что может ли алгоритм выглядеть по-другому, который машинного обучения. Да, он выглядит по-другому, но он во многом похож. на алгоритмы. То есть алгоритмы нейросетей с первой зоной коры сравнивались ответы, которые получаются на нейронах первой зоны V1 коры и то, что выдаёт нейросеть. И получали корреляцию на уровне 95%. Что, в общем-то, говорит о том, что нейросеть и человек 

S03 [01:51:41]  : обрабатывают информацию примерно одинаково. Но всё-таки надо не забывать о том, что объём информации, которая идёт от человека к зрительному тракту, он больше, чем объём информации, которая идёт от зрительного тракта к человеку. И человек активно управляет тем, что он хочет видеть. То есть, человек подбирает параметры распознавания к тем моделям, которые он ожидает увидеть. 

S04 [01:52:08]  : Мы эту тему не касались. Да, подгонка определенная есть. Иногда это называется адаптивная резонанс, иногда этим называется совсем другое явление. Но, тем не менее, это явление, оно характерно только для зрения, оно менее характерно для других процессов мозга. Да, явления есть, но тем не менее другие явления в мозге многие тоже уже воспроизведены. Я именно хотел сфокусироваться на том, что если у вас есть система, которая работает как-то по-другому, нежели нейросеть, то, вероятно, она работает и по-другому, нежели мозг. Поэтому говорить о том, что возможно есть какое-то экзотическое странное представление, которое каким-то мифическим образом работает. 

S03 [01:53:06]  : Хорошо. Давайте мы еще зададим два вопроса, чтобы успеть завершиться в срок. Вопрос от Бориса Новикова. А для распознавания важно априорно знать, что мы распознаем? Например, числа или ветки разных деревьев? 

S04 [01:53:21]  : Вот как раз мы только что этого коснулись, что у человека есть области, которые запоминают текущий контекст. И этот контекст они подают в первые зоны распознавания для того, чтобы более качественно распознавать распознавая его предмет, во-первых, во-вторых, чтобы на нем фокусироваться, на распознавании его. За счёт этого мы можем в джунглях не терять из виду важный для нас объект, например, фокусироваться на змее, которая движется к нам. Или на добычу фокусироваться. При том, что, вообще говоря, всё меняется в джунглях вокруг. Саванне. Всё вокруг меняется. Листья движутся, трава колышется. Хорошо, спасибо. 

S03 [01:54:22]  : Уходит за тучи, выходит. Есть вопрос от Виктора Казариного и поднял руку еще Николай Робчевский. Виктор, пожалуйста. 

S01 [01:54:32]  : Я постараюсь кратенько, но вот к вопросу, к общему вопросу, какое отношение это имеет к сильному искусственному интеллекту, я попробую проинтерпретировать. Юрий, вы можете там какую-нибудь цифру нарисовать, чтобы мы были, вот эту иерархию увидеть еще раз. 

S04 [01:54:52]  : Давайте на этот раз нарисуем. 

S01 [01:54:55]  : ну хоть что. и вот смотрите, я попытаюсь это проинтерпретировать в рамках того, как я это вижу. может быть, вам это понравится, не понравится. все это вот, если мы сверху имеем вход, снизу имеем выход, это фактически некая Некий набор продукционных правил. На вход появляется это, на выходе появляется ответ. Можно ли это зафиксировать? Можно, мне кажется. То есть, если пошел дождь или предъявлена цифра 4, она фиксируется 4. Если предъявлена бабушка, значит нейрон бабушки сработает. Но в этом есть и проблема, так как у нас есть это самый нейрон бабушки, нейрон десяти цифр. Следовательно, система не настолько гибкая. И когда мы сейчас видим вот эту архитектуру на экране, она действительно фиксирована. Отсюда следует следующее. Она решает фактически, некоторые отвечают на вопрос, что представляет собой изображение предъявленное, то есть принимает какое-то решение. Так вот, это решение одношаговое, все вместе, все эти внутренние слои, они собираются в один шаг. Если предъявлена цифра 4, она на четвертом нейроне сработает как максимальное значение, там остальное меньше. Поэтому многоходовые решения, которые человеку приходится повседневно решать, сначала сделать одну, одну цель достичь. Ну или чтобы достичь большую длительную цель, надо сделать то, то, то и то. И решения эти всегда разные по длине. Здесь всегда фиксированная длина решения, один шаг. Это не умаляет эти сети, то есть мы должны отсюда взять лучшие, но это является одним из вариантов кирпичиков для построения сильного искусственного интеллекта. Только кирпичиком. Это один из вариантов. Потому что другие нейросети построены немножко по-другому. Они как раз пытаются решить проблемы, которые в этих простейших сетях, как представленных вами, есть. Еще второй вопрос, связанный со всем этим. И вы только что об этом говорили. Вот, допустим, на самом первом рисунке у вас были цифры, которые нужно распознать. Их там много. Мнистовские. И если мы другой контекст возьмем, допустим, искать крюки кранов. Некоторые крюки могут быть похожи на цифру 5, например. И получается у нас, что изобразительно, внешне, в изображении, мы никак не можем разделить классы крюков от классов пятерки. Только следующими уровнями интерпретации мы сможем это сделать. В этом тоже ограниченность вот такого подхода, который нужно преодолеть. Ну и другие, которые мы тоже обсуждали, проблемы масштабирования. Антон как раз задавал вопрос на предмет, а как же мы можем какие-то составные части у этого, чем отличается от слона и так далее. Вот посмотрите на этот же самый рисунок. Эта система не предназначена для ответа, она решает другую задачу. Поэтому, соответственно, вопросы, которые задавали, предъявляли к этой системе, она не сможет ответить. 

S04 [01:58:14]  : Но имеется в виду, что другие системы, если бы мы распознавали китов и санов. 

S01 [01:58:19]  : Нет, мы бы не смогли задать этим вопросом, чем именно отличается. Только в легкой форме, надо специальными средствами отсюда вытаскивать эту информацию. 

S04 [01:58:29]  : Был, по сути, вопрос, можем ли мы вытащить или не можем вытащить. 

S01 [01:58:33]  : И насколько это будет легко и сложно, и насколько это эквивалентно. 

S04 [01:58:37]  : Я и рассказал, каким образом это делается. 

S01 [01:58:40]  : Но вот из этой архитектуры, в той формуле, с теми методами, решили. Это нужно другими средствами, скорее всего. 

S04 [01:58:47]  : Давайте я уже начну отвечать, потому что я уже первый вопрос забыл, поэтому начну отвечать со второго, потом вы чуть-чуть мне напомните. Я как раз проиллюстрировал то, что у человека очень сложные отношения с планированием. Вот вы привыкли воспринимать человека как существо рациональное, но на самом деле в большинстве случаев его применение плана — значит, он знает, что он должен сделать действие А, знает, что должен сделать действие В, знает, что должен сделать действие С. Вот это он запоминает, а дальше смотрит по контексту. Так, в этой ситуации применимо действие А. О, я же должен был сделать действие А. Делаю его. Это, возможно, меня ближе дальше к плану сделает. По плану. И так далее. То есть он редко запоминает план, он скорее запоминает, так же, как мешок слов, запоминает, что ему нужно сделать. На этом и основан как раз звездочка алгоритмов, известная в искусственном интеллекте. который оценивает каждый раз, приближает ли данное действие, то есть при разных альтернативах, приближает ли это действие к цели или нет, выбирает то действие, которое больше приближает к цели. и позволяет таким образом за небольшое число действий, то есть мы вспоминаем, должны ли мы были сделать то-то и сего-то, и таким образом планируем. Дальше, если говорить про другое, для чего эта сеть предназначена, для чего не предназначена. Ограничение сети искусственное. Мы специально не хотим иметь дело с глючущими роботами, которые сами не знают, хотят ли они сегодня работать или не хотят. А если хотят работать, то хотят ли цифру 5 распознавать как 6 или цифру 6 распознавать как 8, просто потому что им так хочется. И мы не хотим задумываться о том, на что направлен взгляд этого робота. И не хотим, чтобы этот робот сам управлял своим взглядом. Поэтому мы фиксируем, прибиваем его взгляд к той цифре, которую мы перед ним показываем. И мы используем это действие настолько часто, насколько можем именно для того, чтобы робот был более предсказуем. Без этого тоже сети работают, но редко они из-за этого работают лучше, зато часто они из-за этого работают хуже. Поэтому статистически невыгодно так действовать. Поэтому мы предпочитаем собирать более простые системы и их как-то комбинировать, добиваться более хороших результатов. подходы, когда мы можем месяц долгую нейросеть какую-нибудь учить, и в результате она даже будет иногда работать и что-то делать. 

S03 [02:01:57]  : Спасибо, Юрий. Хотелось бы дать слово Николаю. Единственное, мы с Николаем уже обсуждали на лету в Телеграме или в Фейсбуке, я уже не помню, где тему про обнаружение длинных носов и раздвоенных плавников. И если я правильно помню, Николай высказался, что совершенно необязательно делать это эмулируя нейросети, потому что есть более эффективные способы. Но мне на самом деле просто любопытно, что в голове у человека нет же более эффективных способов. У него же там есть только нейроны, соединенные друг с другом, а он каким-то образом умудряется анализировать, выявлять хвосты, носы и уши, и каким-то образом их распознавать. Правда, тут возможна гипотеза, что это происходит через культурный слой, который в конечном итоге всё равно работает на тех механизмах, про которые рассказывал Юрий сегодня. Но я с нетерпением буду ждать следующего доклада Юрия. Он расскажет, как, может быть, это можно делать нейросетями. Николай, пожалуйста. 

S02 [02:03:04]  : У меня короткий технический вопрос, связанный с утверждением о том, что человек и нейросети одинаково организованы, и зрение человеческое вполне соответствует описанному. Для человека нет проблем в тех ситуациях, когда он видел предметы, которые представляют собой не контуры, а пятна, круги, квадраты, заполненные соответствующим цветом и яркостью. Потом, когда ему предъявляют контурные, вариант этого же изображения, у него нет проблем с распознаванием. И даже если он этого контурного изображения не видел, ну, например, человек смотрит на фотографию, некого другого человека, а потом ему предъявляют контурный рисунок, и он может достаточно уверенно определить, соответствует этот контурный рисунок фотографии или нет. У меня вопрос такой, есть ли нейронные сети, которые демонстрируют такую же возможность, то есть учатся только на неконтурных картинках, а распознают потом предъявляемые контурные картинки. 

S04 [02:04:42]  : Да, такое можно сделать. Можно сделать или есть? Ну, та же дали клип. Ну, там они тесно сплетены, я их даже иногда путаю. Клип умеет находить одну и ту же картинку совершенно разных стилей. То есть он может и контурное изображение банана распознать как банан, и анимацию банана. У нас отвалилась запись в одном виде, но вроде как в другом виде запись осталась. То это в разной стиле не проблема. Но дело в том, что даже человек, у него есть такая особенность, у него есть два основных ракурса, в которых он запоминает элементы. Потому что есть проблема неинвариантности к масштабу, поэтому люди запоминаются обычно другими людьми, двумя способами. Повторю для записи последнюю фразу. Так как люди не инвалиды к масштабу, люди обычно других людей запоминают двумя способами. Во-первых, полный рост. Во-вторых, лицо. И, соответственно, у человека формируются две подмодели внутри, видимо. Одна для распознавания человека в полный рост, вторая для распознавания лица. Смотрите, что произойдет. Вот у нас есть единичка. Мы можем ее не на этом уровне как единичку запоминать, а запоминать на каком-то внутреннем другом уровне посередке где-то эту информацию. Если у нас в следующий раз какая-то другая будет единичка, она будет вот здесь похожа. И наша память, она такая, ага, а вот с точки зрения вот этого кусочка памяти, это тот же самый объект. А если еще таких объектов будет и несколько, несколько кусочков памяти, то мы точно уже скажем, что это наверняка тот же объект. Вот так оно и срабатывает. Просто дело в том, что память у нас построена, именно рассчитана на запоминание, скажем так, сигнала предъявления. Это особенность именно памяти, а не особенность мозга в целом. И вот это достигается достаточно сложными способами, что одно предоявление временно хранится, а потом оно по всему мозгу говорится, что больше внимания обращай, если такое вот увидишь снова. 

S02 [02:08:01]  : Тут есть маленькая проблема. Если всё происходит именно так, то непонятно, зачем существуют сакады и для чего они используются. 

S04 [02:08:17]  : Тут объяснение традиционное. Следующие сакады используются Во-первых, сакады есть на нескольких уровнях. Есть микросакады, есть сакады, есть и третий уровень еще движения. Ну вот самое верхнеуровневое – это скорее движение внимания, поскольку мы не можем там большой объект сразу увидеть. картинку вот, не знаю там, если квадрат я нарисую, то вы посмотрите, вот один угол увидите, вот второй угол, увидите что-то такое вот в центре черное, потом увидите, а еще один угол, еще один угол, ага, похоже на квадрат, да? 

S02 [02:08:57]  : Ну да, то есть получается, что распознание этой картинки идёт не путём анализа одного кадра, как в нейросети, а анализа последовательности, и всё это приобретает характер процесса, а не единомоментного решения. И нейросети этого не моделируют. ни в каком виде. 

S04 [02:09:31]  : Ну, моделируют, моделируют, просто это более трудоемко с точки зрения учислительной, но на самом деле все очень просто. Вот у нас вот одно изображение, вот у нас рядом расположили второе изображение, третье, четвертое, также берем в один слой это все дело, берем и причем даже не изображение, а разность между изображениями берем, тоже кодируем. И получаем кодирование уже для последовательности. И таким образом мы распознаем последовательность. А последовательность, то есть вот у нас в одном месте… Нет, так вы же в этом случае подаете всю последовательность сразу. 

S02 [02:10:14]  : И она обрабатывается, вся последовательность сразу. А мы обрабатываем последовательность последовательно. Потому что если мы последовательность преобразуем в нечто существующее одновременно, это совершенно иная категория. Мы не можем рассматривать одновременно то, что было сейчас и то, что было раньше. А вы предлагаете вариант, когда это происходит. 

S04 [02:10:48]  : На компьютере это распознавание тоже происходит не единомоментно. Вначале мы строим одну фичу, потом мы строим вторую фичу, потом мы третью фичу строим. 

S02 [02:10:59]  : Нет, вы строите ее исходя из тех данных, которые уже все есть. 

S04 [02:11:07]  : А теперь смотрите, смотрите трюк. Так же, как мы когда распознавали одну фичу, вот у нас много информации на картинке, мы не хотим так много хранить. Мы вместо этого будем запоминать Вот это небольшое число информации, которое у нас сформировалось, или даже вот это вот. И мы можем его хранить на некоторое время для прошлых кадров. У нас такой буфер есть на несколько секунд. точнее, иерархия буферов даже. Какое-то внимание мы можем несколько минут хранить, как мы знаем, где-то несколько секунд у нас буфер. В этой иерархии буферов хранятся более компактные представления уже пить. Про что мы видим? И теперь мы можем обрабатывать последовательность уже из вот этих более компактных представлений, как будто бы они у нас есть одновременно. То есть у нас есть одновременно контекст или что-то там контактное. То, что мы сейчас, мы объединяем, получаем из этого новую информацию, потом объединяем, получаем новую снова. так одновременно накапливаем старую информацию, ну и то, что там выходит от фокуса, внимание затирает, это все нейросетями тоже эмулируется, то есть любая нейросеть, которая у вас распознает тексты, вот здесь вот если мы разместим не одну букву, а цифру А3, Нейросеть, скорее всего, будет последовательно идти вот так вот и распознавать вот такая, ага, вот здесь вот уже единица у нас сформировалась, а вот это вот двоечка. и выход ее будет тоже последовательный по времени. То есть это эквивалент к тому, чтобы мы сканером бы по строчке вот так вот почитали. То же самое по времени происходит при разведке по времени. Как будто бы у вас разные строчки появляются в одном месте в разном времени. 

S02 [02:13:29]  : Ну, хорошо. Спасибо. 

S03 [02:13:34]  : По коллеге спасибо. Заключительное слово предоставляется Владимиру Смолину. Он хотел какие-то напутствия дать Юрию. Единственное, что я предвещал, Владимир Сколин даст напутствие. Я поблагодарю Юрия за то, что наконец после длительного перерыва, по-моему, аж с доклада Игоря Пивоварова, первый раз мы за долгое время видим какие-то что-то живое и работающее. на экране, а не голую теорию. 

S04 [02:14:02]  : Проблема в том, что то, что мы видели, работает и не относится к отношению к AGI, поэтому вот хотелось бы в следующем вашем докладе именно продвинуться в сторону того, как с помощью того, 

S03 [02:14:22]  : что вы показали, можно двигаться в сторону всё-таки каких-то более серьёзных решений к нахождению хоботов, ушей, хвостов и так далее. Владимир, пожалуйста, напутствие. 

S00 [02:14:35]  : Напутствие как раз в этом направлении, что попробовать срезать вот это, что сегодня было элементарно извольно, всё-таки срезать. Первое, значит, вы как специалист в этой области, вероятно, понимаете, что не только когда все хорошо работает, но и какие-то проблемы есть при создании ЭДЖАИ. Вот хорошо бы, чтобы вы рассказали свое представление, какие проблемы нам нужно решить, чтобы дойти до ЭДЖАИ. Может быть, никаких не надо проблем решить. Может быть, просто ждать, что произойдет некоторый энергетический стык, и, собственно, создадут сильные спускнители. Вот. Третий вопрос состоит в том, что... Вы нам все рассказывали, что все прекрасно работает. Но есть работы, что это не совсем так. То есть, допустим, Дмитрий Литров исследует сети, он дает ссылки на ряд других работ, о том, что если посмотреть, насколько эффективно работают элементы в этих сетях, то эффективность оказывается не очень высокой. Но если бы речь шла о двух или даже двадцати процентах, то вообще не о чем было бы разговаривать. Но по его результатам 98% И, наконец, последнее, что с одной стороны вы рассказываете, что ваш подход самый правильный, и вот так, как вы делаете, это именно так и надо делать. Но с другой стороны вы говорите, что все, что делают остальные, это все то же самое. И тут есть некоторое противоречие. То есть хотелось бы, чтобы вы все-таки отделили вот свой самый правильный подход от всех остальных, которые, мягко говоря, не совсем правильные. Вот это тоже хотелось бы согласовывать. 

S04 [02:16:03]  : Все. Значит, давайте прорезюмируем и просуммируем. Проблемы... Я могу прислать, если хотите. Проблемы, может, на Emergent, если у вас есть время. 

S00 [02:16:16]  : Да. 

S04 [02:16:20]  : Вот, да, ну, действительно, про качество давайте поговорим лучше в следующий раз, потому что это... Я говорю о том, что это мое пожелание к следующему докладу, да. 

S00 [02:16:29]  : Это абсолютно вопрос от пожелания на следующий доклад. 

S04 [02:16:33]  : А вот про единственную правильность метода и неправильность... Могу сказать следующее. Пока что ни один альтернативный метод не показал даже в теории того, что он... 

S00 [02:16:55]  : Я не хочу с вами спорить. Вы делите самые правильные методы, которые показывают лучшие результаты. А другие всё-таки чем-то отличаются. Поскольку у вас результаты лучше, у кого-то есть результаты хуже. Это в чём отличие? То есть не сказать, что все делают то же самое, но это противоречит тому, что ваш метод самый правильный. Знаете, если ваш метод самый правильный, то другие делают как-то не совсем правильно. Вот это старайтесь нам рассказать. 

S04 [02:17:22]  : Нет, смотрите, есть нейросетевые подходы, которые... Мейнстримная нейросетевая часть. Есть альтернативные подходы, как нейросетевые, необычные? 

S00 [02:17:36]  : Вот я и прошу вас сравнить, с вашей точки зрения, чем остальные подходы, которые вам, кажется, стоят упомянуть. 

S04 [02:17:45]  : Дело в том, что пока что нет ни одного подхода, который можно было бы сравнить, который хоть что-то показывает. 

S00 [02:17:54]  : Если вы так считаете, я готов принять вашу позицию. 

S04 [02:18:01]  : Я вот показал мельком, надеюсь, из моих выводов понятно, как работает и на основе чего не работает на самом деле сетка PAN, которую показывали, Злокин рекламировал. 

S00 [02:18:21]  : Если именно сравнивать что-то, что хоть как-то работает, 

S04 [02:18:43]  : Я работаю в области распознавания речи. Вот вы где-то, вот не знаю, там что-то, там не знаю. Ничего больше не работает. Один подход. Ничего, в принципе, даже далеких конкурентов нет. 

S00 [02:18:58]  : Если вы хотя бы мне напишите, каких конкурентов... Я полностью с вами согласен, что мы расследуем, это сейчас мейнстрим. И, соответственно, то, что вы рассказываете, я ни в коем случае не хочу рассматривать. 

S04 [02:19:11]  : Напишите, каких конкурентов просмотреть. 

S00 [02:19:14]  : Ну вот хотя бы пан, который вы сравнили, что это нелегально работает. Вот вам будет всем, я думаю, интересно. 

S04 [02:19:20]  : Для пана я чуть-чуть доделаю, чтобы повторить пан в точности, но я почти его повторил в моей схеме, но и видно, в общем-то, что он... Тем более, если вы проделали какую-то работу, нам будет интересно. Примерно как распознавание со сверхбольшим батч-сайзом. Понятно. То есть, вот такая же петрушка. 

S03 [02:19:41]  : Хорошо. Владимир, я надеюсь, Ваша на пути. Коллеги, я предлагаю поблагодарить Юрия за наглядный и образовательный доклад. Но есть надежда, что мы, отталкиваясь от этого фундамента, продвинемся в сторону EGI в следующий раз. 

S04 [02:19:59]  : Дело в том, что я план написал в плане кучи пунктов, потом вспомнил, сколько занимают обсуждение и всякие моменты. 

S03 [02:20:11]  : Да. И у меня тоже есть будет короткое напутствие начать следующий доклад с защищаемых положений, чтобы понимать, к чему готовятся, и завершить его с фиксацией того, что эти положения были подтверждены и прояснены. Коллеги, всем спасибо. Юрию спасибо. Всем спасибо за вопросы и обсуждения. Всем пока. С Новым годом наступающим старым. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
