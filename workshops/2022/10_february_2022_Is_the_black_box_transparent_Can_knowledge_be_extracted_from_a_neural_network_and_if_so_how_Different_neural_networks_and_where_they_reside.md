## 10 февраля - Прозрачен ли черный ящик? Можно ли извлечь знания из нейросети и если - да, то - как? Разные нейросети и где они обитают? - Юрий Бабуров и Дмитрий Салихов — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/CTy9ASRvCcM/hqdefault.jpg)](https://youtu.be/CTy9ASRvCcM)

Суммаризация семинара:

Семинар посвящен теме интерпретируемости нейросетей. Основной акцент делается на возможность визуализации и понимания внутренних процессов нейронных сетей, что позволяет лучше понять, как они обрабатывают информацию и на основе чего делают свои выводы.

Приводятся примеры использования нейросетей в различных задачах, включая распознавание объектов, что демонстрирует их способность к обучению и адаптации. Однако поднимается вопрос о том, действительно ли нейросети "знают" или "понимают" окружающий мир, или же они просто фильтруют и ассоциируют данные без глубокого понимания их значимости.

Участники семинара обсуждают проблемы, с которыми сталкиваются при попытке интерпретировать работу нейросетей, включая сложность и необъятность внутренних механизмов, что делает их похожими на "черные ящики". В связи с этим, рассматриваются различные методы, такие как Prompt Engineering и другие подходы, которые позволяют лучше понимать и контролировать процесс работы нейросетей.

Также затрагивается тема взаимопонимания между участниками семинара, где обсуждается важность внимания к мнениям и подходам других исследователей, даже если они кажутся несовместимыми с собственными взглядами.

В заключение семинара поднимается вопрос о будущем нейросетей и возможностях их интерпретации, а также о необходимости сохранения и развития фундаментальных знаний в области искусственного интеллекта.







S08 [00:00:04]  : Да, коллеги, добрый вечер. Во-первых, я хочу напомнить, что на следующей неделе у нас происходит конференция OpenTalks AI. И я всех приглашаю там поучаствовать, тем более, что в четверг во второй половине дня у нас там будет достаточно интересная секция по AGI. А у меня сегодня был достаточно интересный разговор с модератором секции NLP. который, как бы, на самом деле подводит нас к теме нашего сегодняшнего разговора. Суть в том, что вот человек, который будет модерировать сессию NLP, он, с точки зрения AI, является конкретным пользователем, типичным пользователем. То есть, он юрист, он занимается Legal Tech, и он пришел в NLP, именно как человеку, у которого есть задачи, которые ему нужно решать. Вот, и тема, на которую мы с ним говорили, это то, каково сейчас состояние NLP с точки зрения того, куда все движется, что вот все говорят там трансформеры, все говорят BERT, вот, но когда, значит, начинаешь пытаться делать что-то практическое с трансформерами, BERT, там же PT3, возникают многочисленные проблемы, с которыми мы все с вами сталкиваемся, и, соответственно, что с этими проблемами делать. Ну, и я ему поделился своей перспективой, где, с одной стороны, вроде как представители символьного подхода говорят о том что вот что делать что делать надо брать антологии надо брать грамматики нужно все это дело описывать вот и все будет хорошо прозрачно и понятно как только вы на это опишите вот на что представители нейросетевого подхода говорят ну вам тогда нужно бесконечное число человека лет лингвистов которые все это настроят до тех пор, чтобы это у вас работало достаточно точно. А поскольку нужного числа человеколет-лингвистов нет, то никогда у вас ничего таким образом не получится. На что представители символьного подхода говорят – ага, А вот в нейросетевом подходе, чтобы получить accuracy, грубо говоря, 70% вам нужно 1 терабайт информации. Для того, чтобы получить 80% accuracy вам нужно 10 терабайт. Для того, чтобы получить 90% accuracy вам нужно 100 терабайт. а для того, чтобы получить 95% акуроси, вам нужно 1000 терабайт. То есть, у нас количество объемов тестовых данных для достижения нужной точности, оно растет экспоненциально, и в какой-то момент обнаруживается, что нам просто нет такого количества текстов в открытом доступе, чтобы обеспечить нужную акуроси. И что, соответственно, этим делать? То есть, не тот и другой подход, они не выдерживают в конечном итоге никакой критики с разных точек зрения, и что делать? И моя-то перспектива здесь достаточно простая, что если мы попытаемся посмотреть на проблему описания некоторой модели естественного языка, включая как слои грамматики, так и слои семантики, то мы с удивлением, с моей точки зрения, обнаружим, что берем ли мы нейро... Я, кстати, забыл, по-моему, сказать, что забыл расшарить экран. Так, сейчас я про эту проблему поправлю шарингом экрана. Да, я хотел зашарить экран. Вот, теперь видно мой слайд, да? Коллеги! да да да да вот видим и вот значит собственно моя перспектива такая что мы можем описывать одну и ту же информацию в разных представлениях и на точность как мы эту информацию описываем, она зависит на самом деле от структуры, от тех параметров, которые присовокуплены к этой структуре. А является ли интерпретация этой структуры нейросетевой или вероятностно семантической – это на самом деле вопрос того, как мы к этому относимся. Мы можем иметь некоторую нейросеть, которая содержит Некоторое количество информации позволяет решать задачи с какой-то точностью, и мы можем эту же модель описать с помощью того же самого одинграммара и какого-то семантического графа типа Google Graph, который каким-то образом стукуется с этой формальной грамматикой, и, имея соответствующие парсеры и резонеры, решать задачу в общем случае с той же самой точностью. И в этом случае теоретически нам никто не мешает строить некоторые решения, которые, с одной стороны, может интерпретируемую формально грамматически-семантическую модель загружать в нейросетевую модель, позволяет информацию из нейросетевой модели выгружать в символную грамматически-семантическую, и, имея соответствующие механизмы обучения, мы можем как тренировать и ту и другую систему на размеченных или не размеченных корпусах данных, так и использовать их с помощью соответствующих систем либо символьного парсинга и резонера для извлечения или анализа семантических отношений, так и системы инференса для нейросетевых моделей, на основе нейросетевых моделей. Как мне кажется, противоречия здесь нет. Вопрос в том, что в основном весь фокус сейчас исторически находится на правой стороне данного слайда. Какие-то работы ведутся достаточно независимо на левой стороне этого слайда. Ну а попытки как-то это все между собой скрестить, они достаточно фрагментарные и значимых результатов нету. И мне кажется, было бы интересно, если бы развитие определенной вот этими зелененькими стрелочками получило бы некоторое направление. Все, спасибо. Изменяюсь, что отнял время и передаю слово нашим уважаемым спикерам. 

S02 [00:06:22]  : Всем добрый день. План докладов у нас такой сегодня. Вначале расскажу свою часть доклада я. Мы поговорим о том, можно ли извлекать данные из нейронной сети и как вообще черный это или белый ящик нейросети. снова продолжаем, но немножко с другой стороны. потом Дмитрий расскажет нам про разные виды сеток, потому что частый вопрос о том, что, говоря, нейросетка понимает конкретно конкретную архитектуру, а на самом деле нейросетки очень разные, и не только нейросетки, а системы работы с данными и построения моделей, в общем случае их следует называть, или там machine learning модели. итак, ну давайте приступим. мой доклад будет составить из двух частей. и первая часть будет называться немного необычно. почему нейронная сеть это губка? я не знаю, закрывает ли зум. у вас полностью весь экран виден? да, нормально весь экран. Итак, почему все-таки нейронная сеть и эта губка? Прежде всего у нас стартовал очередной раз мой курс по дипленингу. Можно присоединяться. Желающие по ссылке пройду. Что такое губка? Губка – это нечто, что впитывает воду, как мы знаем, а потом эту губку можно сжимать и эту воду или, по крайней мере, ее часть извлекать обратно. Если мы посмотрим на нейросети, то, обучаясь, они накапливают нечто, и вот это нечто, я все-таки настаиваю на том, что это нечто, это как раз знание. Можно по-разному к этому относиться, можно разными словами называть, но суть в том, что именно то, что хранится в модели, это какая-то информация, которая помогает нам в обработке информации из окружающего мира или помогает нам в процессе мышления или помогает нам еще там в каких-то делах. Но это вот можно вполне называть термином знания. При этом обучение нейросети может быть как супервайзер, так и ансупервайзер. То есть нейросеть может накапливать знания совершенно без человеческой помощи. И давайте посмотрим на разные примеры. Я начну немножко не в том порядке. 

S10 [00:09:47]  : Повторите, пожалуйста, как вы определили знания? 

S02 [00:09:57]  : Я никак не определил знания. Я определил знания как нечто, что люди накапливают и используют. Например, деньги. 

S08 [00:10:09]  : Коллеги, я предлагаю спикера не перебивать в сегодняшнем нашем формате. Все вопросы можно писать в чат. Когда спикер предложит задавать вопросы или ответить на них, тогда можно будет сконцентрироваться. 

S02 [00:10:25]  : Конечно же, речь идет про информацию. Если это будут номера денежных купюр, то это тоже будут вполне себе знания. Значит, дальше. Вот здесь простейшие примеры нейронных сетей, которые как раз какие-то знания получают и потом их используют. Например, они на картинке могут предсказать и рассказать, где находится обувь или где на картинке находится движущийся объект. Но в более сложном случае это не просто движущийся объект, а еще конкретный движущийся там или статичный в данном случае объект, но конкретно класс. Вот как видите на картинке кошки и собаки здесь, но в одном случае мы говорим где собака, и получаем позицию собаки, в другом случае говорим, где кошка. То есть нейронная сеть, получается, у себя хранит информацию о картинке и причем одновременно хранит информацию, где кошка и где собака на картинке. То есть в какой-то степени можно сказать, что у нейронной сети есть знания о том, где на картинке кошка находится и собака. И также в других примерах мы видим. И дальше мы можем для этих примеров строить процедуру извлечения этих знаний, например, в виде того, что мы спрашиваем текстом, какой объект нам нужно получить, а получаем координаты или то место, где этот объект располагается на картинке. Как раз это извлечение информации, это то извлечение информации, которое доступно нам в случае нейронной сети. То есть мы не очень-то можем посмотреть на эти миллионы и миллиарды значений отдельных нейрончиков и весов связей, Но мы можем из нейросети извлечь все ее знания о мире, спрашивая, задавая ей вопрос по поводу каждого предмета этого мира. А вот это что? А вот это что? А вот это что? А где на картинке вот такое вот находится? В более сложных случаях мы можем также или давать более сложные запросы, или она может не только положение определять, или она может определять и карту сегментации строить, карту маски. Здесь одновременно выделен и велосипед, и гонщик. И еще в более сложных случаях она выделяет достаточно хорошее выделение переднего объекта, и более того, если мы посмотрим на вот эту работу Дина, то данная система научилась... на этой странице нет того, что надо... картинка научилась на картинках распознавать информацию и потом эту информацию представлять таким образом, что если мы посмотрим на объекты в тех кластерах, в разных кластерах, то система научилась строить кластера, похожие на человеческую кластеризацию объекта. То есть это ровно получается получается вытаскивание знаний из нейронной сети, то есть мы теперь можем спросить, а какие объекты вот такие вот есть, а можем также сказать, что вот эта вот группа картинок серенькая, значит, это у нас морские животные, покажи нам всех морских животных, или теперь классифицируй на картинках морских животных. рептилий, каких-то других, на картинках или на видео. И вот так выглядит современное как раз вытаскивание знаний из нейронной сети. Я покажу еще пару примеров немножко другого вида вытаскивания знаний, но это самый классический пример. СНЛП достаточно старенький. Когда мы вытаскиваем, вначале научили нейросеть частям речи и ролям предложений, тому, какое слово от какого зависит, и теперь нейросеть эту информацию для домового предложения выдает. То есть, с одной стороны, для нового предложения эта информация не является знанием в частном виде. Это предположение нейронной сети. Но, с другой стороны, это новая сгенерированная нейросетью знаний. Такая двойственность. Внизу пример вытаскивания именованных сущностей. то есть объектов реального мира, связанных с именами или связанных с городами. Другой пример, когда нейронная сеть обучается с одной стороны это можно назвать обучением без учителя, с другой стороны датасет у нас все же есть, и в датасете у нас есть фразы и их переводы. Нейронная сеть учится переводить предложения. И опять же мы можем, вот у нас есть знания на одном языке, мы можем на выходе получить знания на другом языке. Точно так же мы можем попросить переформулировать предложение попроще и сложнее. И даже есть пример того, что мы можем определение сделать типа параграфа просто просто задавая то, какие у нас варианты есть. Мы просто спрашиваем у нейросети каждый раз, является ли этот параграф текстом про политику, или является ли этот параграф текстом про выхлопные газы, или про повышение температуры, или про emergency, и то значение, для какого класса нейросеть скажет, что действительно этот текст проекта, то мы будем считать, что данные соответствующего класса. Таким образом мы подходим к некому новому способу извлечения данных из нейронной сети. В общем-то все это были примеры на разных предметных областях этого нового метода. Он называется, для текста в основном так называется, Prompt Engineering. Промпт это та самая фраза, которую вы даете компьютеру в качестве затравки например является ли x наша фраза вот таким то или является ли вот таким то данная фраза двоеточие пошла ваша фраза то есть нам больше не нужно не нужно программировать компьютер напрямую алгоритмы нам даже не нужно составлять датасеты, мы просто берем очень большое количество всяких разных знаний о мире, загоняем в очень большую нейронную сеть, придумываем запросы или подбираем запросы. Последний год много научных работ посвящено следующей теме, как автоматически с помощью нейросети подобрать промпт для другой нейросети, которая нам будет уже выдавать знания. Таким образом год промпт инжиниринга объявлено, в общем-то, и DECADA, и может даже и VEC, Prompt Engineering. И вот это пример чуть-чуть другого. В качестве затравки используется текст, нейросеть генерирует продолжение. Ну, в общем-то, пример не сильно-то отличается. С помощью генеративных методов мы получаем точно решаем точно такую же задачу. получаем решение точно той же задачи. извлечение данных из нейронной сети. вот это в общем-то было все про нейронные сети. ну да, есть несколько интересных нюансов, которые еще можно обсудить. давайте мы это сделаем. тут прозвучал термин дистилляция. кто-то знает что это такое? отлично. значит дистилляция знаний, это когда мы берем знание, для знания одну большую нейросетку строим, а потом эта нейросеть предсказывает нам ответы. Вот сейчас покажу в каком виде. Вот в таком вот виде предсказывает сеть ответы свои по выходам, по своим выходным нейрончикам. а потом мы учим вторую сеть уже помельче, но вот на этих вот ответах, на вот этих нужных нам классах. И в итоге мы получаем вторую нейронную сеть, которая поменьше, может быть в разы десятки или сотни раз меньше, но которая зачастую решает задачу не намного хуже какой-то конкретной практической задачи. То есть это альтернативный способ для доучивания нейронных сетей как раз делать дистилляцию знаний. И более того, современные методы, как раз в частности Дина, они используют внутри эту самую дистилляцию для дообучения. И получается, есть еще другой похожий алгоритм, на Дина, который делает тоже такую же дистилляцию. то есть вот эти вот штуки, которые на выходе вот здесь рассказаны у студента и тичера, это как раз вот эти вот самые веса. то есть выходные, которые были на картинке. и мы одновременно учим две сетки. Мы их можем объединять, их результаты, и наоборот, из студента адрес веса давать учителю и распознавать новые картинки. И оказывается, что этот подход на Supervised достигает тех же примерно результатов на ImageNet, что и Supervised алгоритм. О чём это говорит? О том, что, ну, возможно, мы повторили какое-то свойство мозга, которое позволяет ансепервайзить учиться уже с высоким качеством на тех же самых данных реального мира, на которых учится человеческий мозг. И мы, соответственно, это вторая часть, кроме промот инжиниринга, которая дает нам прогресс. давайте послушаем теперь вопросы по первой части, а потом будет коротенькая вторая часть. Может, кто-то голосом хочет вопрос задать? 

S05 [00:24:27]  : Юрий, я хочу, если нет других. Да, конечно. Спасибо большое за ведение. Я хотел вот такой вопрос задать. Вот, как я помню, в четвертом классе школы, когда учился, был такой замечательный предмет, называлось «Рассказы по истории СССР», ну тогда по истории СССР, да. А параллельно тогда же, примерно в этом четвертом классе, был такой новый предмет, который назывался «Природоведение». Это фактически на самом деле были потрясающие источники знаний. Я согласен с таким спокойным определением слова «знание» без попытки его формализации. Нечто такое, так сказать, что в каком-то смысле есть. Так вот были вот эти рассказы по истории, и было вот это природоведение. И вот тип знания, которое давали эти два предмета четверокласснику 10 лет, 11 лет они вообще-то говоря замечательно хороши были и подходили для того чтобы использовать то что находится в окружающем мире ну то есть по крайней мере как-то адаптироваться немножко так сказать себе какую-то картину мира начать формировать то есть пользоваться тем что создано в мире можно таким способом вот вопрос о том можно ли при помощи такого уровня знаний созидать что-то построить мост там не знаю там сформировать сформировать политическую какую-то таскать там понимание какой-то исторической ситуации то есть отнестись к этому как некому далее продолжаемому действию уже это сказать такому более принципиально да на основе таких знаний конечно невозможно Но это касается не только потому, что ребенок там 11 лет, его никто там не даст построить, а просто потому что форма знаний такая. Это рассказы о знаниях, я бы так сказал. Вот как вы считаете, не является ли вот то, что вы сейчас вот нам рассказываете, да? Ну не вы лично, тут ничего личного нет, это просто вы как бы отражаете в простых словах нам в общем некий мейнстрит. Не является ли это вот этим вот знанием вот того самого природовидения и предзнанием, которое хорошо, когда вы хотите потрепеть, но оно совершенно не о том, когда вы хотите что-то созидать. Спасибо большое. 

S02 [00:26:41]  : Спасибо за отличный вопрос. С одной стороны, да, на первый взгляд кажется, что эти знания поверхностные, и это знания такие детские, и это знания какие-то общего, может быть, вида, знания общего животных, растения. Но на самом деле дело в том, у человека есть два основных способа обучения. ну ладно, можно сказать три. первый способ обучения, когда он что-то делает, руками делает, со временем понимает, как лучше двигать руками, чтобы что-то сделать. Другой способ, когда человек что-то там придумывает у себя в голове, строит какие-то там конструкции и просто запоминает полученные новые конструкции. И возможно еще там разные там между ними варианты. Но в общем-то все сводится примерно к двум действиям, что или он что-то делает и научается это делать лучше со временем, притом не сразу, не моментально, и второе, что он что-то запоминает. Так вот, здесь скорее про запоминание мы говорили, в контексте того, что система медленно запоминает, как губка действительно впитывает знания о мире. Мы не говорили о той части, которая запоминает что-то делая. И не говорили о той части, которая запоминает и строит новые знания и снова их запоминает. в голове. Об этом я как раз хотел бы немножко поговорить во второй части доклада, но скажу, что такие системы есть, и эти две остальные части тоже тоже решаются, причем не сильно-то другими методами. Разве что там как раз частью с головой как раз есть еще другой метод, но о нем как раз чуть позже хотелось поговорить. 

S05 [00:29:18]  : Спасибо большое. 

S08 [00:29:20]  : У нас еще есть вопросы у Игоря Пивоварова и Евгения Геннадьевича Витяева. Игорь, пожалуйста. 

S04 [00:29:27]  : Спасибо. Юрий, добрый вечер. Вас, как обычно, интересно слушать, но вот сейчас у меня возник прям стойкий диссонанс по отношению к тому, что вы говорили. В первую очередь это связано... Вас коллега начал был спрашивать по поводу, как вы определяете знания. Я понимаю, что сложно определить знания, но знаете, вот как бы я вас слушаю, у меня Как бы этот вопрос сейчас сформулировать. В общем, у меня ощущение такое, что самый большой диссонанс во мне вызывает, когда вы говорите, что вот видите, это связь с объектами в реальном мире. Я бы сказал так. Нейросеть, которую вы показываете, накапливает данные и выдает данные. Вы можете любые данные фитировать с любыми данными. Я буду использовать слово данные, потому что оно безлико, бессмысленно, и это может быть все, что угодно. Но это не знание, потому что знаниями делаете их вы. Вот когда вы показываете эти картинки, где там нейросеть распознала собаку или кошку, видите, это вот связь с реальным миром. Нет. Нейросеть понятия не имеет, что это такое. И это как бы просто одни данные фитятся на другие. Если вы обучите ее, например, на пекинеза реагировать как на кошку, в датасете поменяете пекинеза на кошку, у нее не возникнет никакого когнитивного диссонанса. Она просто запомнит, что вот этот класс является там условно кошкой. И вот смотрите, когда вы говорите про знания и про связь с реальным миром, меня вот сейчас в вашем этом пока половине доклада, не покидает ощущение, что вот это вот сама по себе, как бы, условно говоря, собаку можно учить чему угодно там, в цирке, ну в рамках его физических возможностей, лишь бы он получал свое подкрепление. Он может там, условно, прыгать за бабочкой, а может кого-то топтать. Как научишь? Но он, по крайней мере, хотя бы делает это в реальном мире. А сеть это делает абсолютно в абстрактном пространстве. И когда вы показываете по поводу текстов, что видите, она вычленила два объекта из реального мира. Нет. Это просто отдельная операция над данными. В данных есть вот эти два слова Владимир, Владимир, Владимир. Сеть вообще понятия не имеет ни о каком реальном мире. Это никакие не знания. Вы просто знаете, мне кажется, что здесь есть существенный такой, ну не знаю, философский, метафизический какой-то вопрос. Когда вы антропологизируете эту сетку и данные, которые она выдает, вам начинает казаться, что это некоторые знания, но это некая информация, ее можно натаскать на любую информацию. И вот мне кажется, что если вот это убрать, вот про это знание и связь с реальным миром, то интонации сразу становятся проще, и тогда действительно сеть как губка. Налили в нее любые данные, вытащили из нее любые данные. но связки с реальным миром, я не понимаю, где она проводится, если не в человеке, а человек это уже как бы не нейросеть, это уже нечто другое. 

S02 [00:32:48]  : Игорь, но я скажу вы антропоцентричны. то есть вы изначально не предполагаете робота как равного. 

S04 [00:33:00]  : а вы нейросетицентричный. 

S02 [00:33:04]  : я в этом плане более объективен, скажем так. вот смотрите, вот я вам сейчас снова расшарю экран, подготовил предложение. вот скажите, вот вы видите это предложение, и что? вы теперь знаете про какую-то Анжелу из реального мира? знаниями или данными? 

S04 [00:33:30]  : я вижу текст. 

S02 [00:33:31]  : я понимаю, что на человека тоже… вы знаете, что Анжела – это имя человека из реального мира? может, робота зовут Анжела? 

S04 [00:33:43]  : Я не знаю. А врач – это робо-врач. Я не говорю об этом, что я что-то знаю. Это просто предложение. 

S02 [00:33:50]  : Для меня оно… Тогда чем отличаетесь вы, который читает этот текст, от робота, который читает этот текст и делает какие-то действия при этом? 

S04 [00:33:58]  : Тем, что я сейчас не делаю вывода, что я что-то знаю про этот текст, и никаких знаний отсюда не выйдет. Ну, хорошо. А вы делаете вывод, что если нейросеть это прочитала, а потом она поймет, что Анжела – это существительное женское имя, а врач – это существительная профессия, то, наверное, женщина пришла к врачу. Это вы делаете такие выводы поверх того, что делает нейросетка, понимаете? На самом деле, люди научили нейросеть тому, что они сами как бы умеют, За счет того, что она это оптимально фитирует, они получают похожий результат на то, что они ожидают, и мы это антропоформизировать, я не могу выговорить это слово, очеловечиваем, и как бы нам кажется, что она знает там что-то, но нет. 

S02 [00:34:47]  : Нет, кажется нам и не кажется. Я очень рекомендую рассказ Каганова «Гамлет на дне» в этом плане. Посмотреть с точки зрения робота на ту же самую жизнь. Запишу в чате. Там описаны все проблемы такие же человеческие, но в приложении к роботам. так, хорошо, ладно, давайте тогда, я думаю, ответил я на вопрос как-то. по мне это просто антропоцентричность и все, и больше за этим ничего не стоит. Ну как, разве можешь ты, робот, написать симфонию? Как это делают нормальные люди. 

S08 [00:35:47]  : Юрий, у нас уже три руки. Вопрос. Мы сейчас дадим всем рукам высказаться? 

S02 [00:35:54]  : У нас еще 10 минут есть на вопрос. 

S08 [00:35:57]  : Хорошо, тогда, значит, Евгений Евгеньевич, потом Николай Шилов и потом Борис Новиков. 

S10 [00:36:04]  : Юрий, я хотел спросить, вы все-таки черный ящик, у вас остается черный, вы его не вскрываете. Дело в том, что раньше были какие-то попытки все-таки вскрыть этот черный ящик. Были так называемые замены нейронов на правила MFN. И замена нейронов на правила MFN, оно дает некоторую, так сказать, аппроксимацию нейронной сети более-менее прозрачной. Знаете ли вы работы, которые все-таки делают черные ящики прозрачными, которые все-таки достаточно точно и ясно аппроксимируют понятными высказками? 

S02 [00:36:41]  : Единственные хорошие работы на эту тему, сейчас я вначале удостоверюсь, что загрузилась, а потом покажу ссылку. Вот сейчас примерчик найдем. Единственная хорошая на самом деле штука, которая действительно работает, я вот хотел бы подготовить, но про это дело доклад. для начала я размещу в группе практически AGI, как только до этого доберусь. не факт, что я доберусь в течение ближайшего месяца до этого. вот данную систему, данный подход, пример этого подхода ссылку дам поиграться. но вот наибольший успех достигается как раз с помощью дистилляции на линейной сетке. Это, пожалуй, единственное. То есть внутренние замены нейронов, да, они дадут нечто похожее на ответ нейронной сетки, да, будет чуть-чуть понятнее, но тем не менее там все равно миллионы, миллиарды весов, которых мы ни в жизни не разберемся. А вот приближение с помощью линейной сетки – это, по сути, ответ на вопрос, простой такой способ определения, на каких элементах нейросеть среагирует, потому что у нас теперь есть простенькая нейронная сеть, из десятка или сотни нейронов всего, которая повторяет то же самое, что и большая сеть. То есть дистилляция. сейчас остается единственным практическим способом, который применяется. Шап какой-нибудь, на самом деле это очень близко, за счет матрицы корреляции строим практически линейную модель или древовидную модель, которая объясняет поведение нейронной сети, ее как раз выход. Так же, как я говорил, что мы учимся на распределении выходных. 

S10 [00:39:09]  : Упрощение. Да, этой линейной аппроксимации. Ну тогда просто к вам к сведению. Мы хотим правила MFN сделать еще более точными и, так сказать, побелить черный ящик в белый. То есть мы проводим такие эксперименты. 

S09 [00:39:27]  : Да, да. 

S02 [00:39:31]  : Отличное как бы замечание. 

S05 [00:39:38]  : Коллеги, у Горбаня в 90-х годах был цикл работ, который называется логические прозрачные нейронные сети. 

S02 [00:39:47]  : Мы можем построить древовидный классификатор, который будет аппроксимировать нейронную сеть. Он будет нужной нам глубины, и там будут бинарные правила. Вот у нас логические правила. В чем проблема? но какая польза будет от него? сложные фичи он не сможет предсказать, потому что не хватит мощности. так же как и линейный хвостификатор не сможет сложные внутренние сети повторить. то есть одно из двух. или мы делаем нечто простое, понимаемое, или мы делаем нечто большое, но мы его уже никогда не поймем, просто оно потому что большое объемное. 

S10 [00:40:25]  : Нет, мы занимаемся только аппроксимацией, которая сделает нейрон еще более точным. То есть мало того, что она сделает его прозрачным и понятным, есть доказательства того, что полученный результат будет точнее. 

S02 [00:40:40]  : Но это в процессе эксперимента. Да, да. Non-negative matrix authorization – это вещь, да. Согласен. Для текста она по-прежнему применяется временами. Вот это круто. Спасибо. 

S08 [00:40:56]  : Хорошо. Пожалуйста, Борис. 

S01 [00:41:00]  : Здравствуйте. Меня слышно? 

S02 [00:41:02]  : Да, слышно. 

S01 [00:41:05]  : К вопросу Игоря Пивоварова. Мне кажется разумным разделять данные и знания. Я привел в чате свое предельное знание. как одна информация для системы управления агентом. В отличие от данных, как вообще какая-то информация, которая не нужна, возможно, не нужна агенту. То есть энциклопедия на полке – это данные. 

S02 [00:41:38]  : Подождите, а кто определяет, нужна она агенту или не нужна? Агент. 

S01 [00:41:45]  : Агент или кто-то снаружи. Когда агент обращается к сети, как в ваших примерах, он превращает данные из сети в знания для себя. И вот то, что у вас, по-моему, продемонстрировано, это способ именно взаимодействие агента с сетью для доступа к нужной ему информации, для превращения этой информации из сети в свои знания. 

S02 [00:42:21]  : Ну вот, Игорь, видите, вам оппонируют, говоря, что у нейросети все-таки знания, а не данные. 

S01 [00:42:29]  : Нет, я сказал ровно наоборот. Агент это кто? Нейросеть? Нет, это тот, кто обращается к нейросети. 

S02 [00:42:41]  : То есть вы тоже антропоцентрист? 

S01 [00:42:44]  : Почему? Может робот обращаться к нейросети, но у агента должны быть интересы и цели. 

S04 [00:42:54]  : Юрий, вы просто пока не слышите, действительно. 

S01 [00:42:57]  : А у нейросети, которая работает с данными, у нее нет ни интересов, ни целей. 

S02 [00:43:04]  : Ребята, ну оно опять же, ну антропоцентричность опять я слышал. У нейросети нет интереса к цели, но вы определяете есть ли у нейросети интерес. 

S01 [00:43:16]  : Если мы говорим об искусственном интеллекте, то это тоже антропоцентризм. Мы приписываем к какой-то инженерной системе свойства интеллекта, сознания, психики. То есть то, что мы перечисляем только для человека. Эти термины были определены только для человека, и мы их начинаем приписывать искусственным системам. Это уже антропоцентризм. 

S02 [00:43:43]  : Ну правильно. 

S01 [00:43:45]  : Соответственно, разница в том, что у агента есть система управления, которая на что-то нацелена. А у хранилища данных нет системы управления, кроме так... А если оно активное хранилище данных? Тогда это хранилище данных у агента, и тогда не все данные в этом хранилище нужны для системы управления агентом. 

S02 [00:44:13]  : Но у человека в голове хранилище данных? 

S01 [00:44:18]  : У человека в голове полно мусорных данных. 

S02 [00:44:24]  : В общем, вы называете что-то активным или пассивным агентом и в результате, ну то есть хранилищем или агентом, в зависимости от этого у вас или данные, или знания. 

S08 [00:44:50]  : коллеги можно можно перейти вот есть два несколько вопросов на понимание я предлагаю все-таки значит продвинуться дальше и оставшиеся время подискутировать Два вопроса есть у Евгения Бабарыкина. Я правильно понимаю, что сначала мы сегментируем наше пространство объектов первой сеткой, это учитель, а вторую, ученик, натаскиваем уже первой сеткой на классификацию. Уточнение вопроса. Я правильно понимаю, что сначала мы кластеризуем наше пространство в объектах первой сеткой, это учитель, а второй ученик натаскиваем уже первой сеткой на классификацию? Один и тот же вопрос на самом деле. 

S02 [00:45:30]  : Ну да, при дистилляции, при дистилляции мы, ну смотрите, мы могли бы учить. мы можем вполне учить сетку только классам-победителям, то есть то, по сути, какой меткой человек разметил бы картинку. Но это просто неэффективно. Если мы будем все распределение нейросетки выдавать, то есть это очень похоже на оленей, но еще немножко это похоже на траву, потому что на фоне трава, еще немножко это похоже на горную местность. то просто учиться будет эффективнее. Есть предположение, что разные области мозга как раз друг друга таким образом подучивают. Но об этом мы сейчас попробуем все же поговорить. Хорошо. 

S08 [00:46:26]  : Давайте еще последний вопрос. У меня одно понимание. Вот смотрите, вот конкретный совершенно кейс, который меня в практической стороны беспокоит. Вот я, к примеру, решаю классическую задачу сентимента анализа. В результате тренировки получаю некоторую нейросеть, которая говорит, что вот это вот новости положительные, а вот это новости отрицательные. Или она говорит, что вот в этом тексте есть сарказм, а вот в этом тексте нет сарказма. Вот, ну и вот, например, мне хочется понять, а почему она вот какую-то новость определяет как сарказм, да? А какую-то новость не определяет как сарказм. Где критерии сарказма? Вот, например, у меня есть гипотеза, что вот если в научной дискуссии кто-то начинает рассуждать об анекдотах, как Владимир Смолин, да, значит, пытается там анекдот про девушку привести, то, наверное, это не совсем уместно, да? Но вот меня интересует точка зрения нейросети. Вот как мне узнать, какие фигуры речи, какие слова, какие смыслы? То есть, что вообще нейросеть предполагает под положительным на интонации, под отрицательной интонацией, под сарказмом, под манипуляцией? 

S02 [00:47:33]  : Я улыбаюсь. Да, я понял ваш вопрос. Спасибо. Я улыбаюсь, потому что, вы знаете, я этот ответ уже озвучивал, и он достаточно забавен. И он снова сводится к промот-инженерингу. 

S08 [00:47:49]  : Давайте конкретный пример. Меня интересует решение этой задачи в промышленном масштабе. 

S02 [00:47:53]  : Конкретно. Нейросетка, значит, говорит, что текст, значит, ну, например, положительный. Теперь мы говорим сетке. А какое слово в этой фразе делает этот текст положительным? 

S08 [00:48:11]  : И вуаля, сетка называет вам слово. Хорошо. Теперь для того, чтобы мне понять, какие слова или комбинации слов являются положительными и отрицательными, я должен сгенерировать бесконечное количество промптов для того, чтобы получить эту информацию. Правильно? почему нет мы просто говорим эту фразу и спрашиваем как я не знаю нет меня не интересует нет нет это это это то что вы говорите это задача распознавания меня интересует узнать а что для сетки является положительным что является отрицательным что является сарказм меня не интересуют конкретные фразы меня интересует знания. То есть, меня интересует модель. Мне нужно, чтобы сетка рассказала, что вот, к примеру, слово анекдот в научной дискуссии, оно является, наверное, нехорошим. А слово дурак в любом разговоре, кроме русской народной сказки, оно тоже является нехорошим безотносительно контекста. Вот это мне нужно. А ведь есть еще комбинации слов. Не дурак, допустим. Не плохой. Вот мне нужно сколько? То есть, получается, задача вычислительно нерешаемая, неразрешимая, потому что нельзя сменить всевозможное количество предложений, чтобы узнать, что нейронная сеть думает по конечному числу слов и фраз. 

S02 [00:49:29]  : Но на самом деле, начну с того, почему вы уверены, что человек может решить эту задачу без перебора и действительно ответить на подобный вопрос? 

S08 [00:49:39]  : Хорошо, я понял ваш ответ. Спасибо, давайте двигаться дальше. 

S02 [00:49:46]  : Соответственно, для человека тоже есть ровно эти два варианта. Или мы у человека спрашиваем, как вы думаете, в каком месте у него есть... в этой фразе, значит, есть что-то, что делает ее сарказмом, и человек указывает на какое-то место, что мы тоже самое можем спросить у компьютера. И второй вариант, а вот скажи, а вот это вот слово делает фразу сарказмом, а вот это, как в анекдоте, когда два наркомана Значит, подходит к поезду. Давайте расскажу. Юрий, хорошо. 

S08 [00:50:13]  : Я не согласен, но я предлагаю двигаться дальше. 

S02 [00:50:17]  : Ну, хорошо. 

S01 [00:50:21]  : Предлагаю ответ короткий. Короткий ответ. Человек в разговоре всегда находится в контексте. В определенном. 

S02 [00:50:33]  : В контексте, да. 

S01 [00:50:34]  : Но мы этот контекст задаем тоже в комке. а нейросеть вряд ли находится в контексте, по крайней мере пока на набор данных, а не исходная информация для управления агентом. 

S02 [00:50:50]  : Смотрите, а мы берем и говорим, а вот, пожалуйста, расскажи нам, что сейчас вокруг происходит. И система нам генерирует контекст в виде текстовой информации. А дальше мы подаем этот контекст во вторую сетку, которая решает целевую задачу. И вторая сетка уже работает в контексте. 

S01 [00:51:17]  : Когда мне начальник на фирме спрашивает, что происходит, его интересуют задания, которые мне выдал. Она меня спрашивает. Её, видимо, интересует. Купил я что-то в магазине или там что-нибудь подобное. 

S08 [00:51:40]  : Юрий, у меня есть ощущение, что мы сейчас уйдем в достаточно длинную дискуссию. Давайте зафиксируем, что вы пока многих здесь нифига не убедили, грубо говоря. 

S02 [00:51:50]  : Давайте я попробую немножко по-другому расскажу. Расскажу вот эту идею. Вы тогда шаринг экрана отключите, если вы собираетесь доску снимать. Ага, видно ли теперь доску ремня? Вот, а замахнемся на немыслимое. Сделаем искусственный мозг из нейронных сетей. которые каждая будет решать какую-то конкретную задачу. и проделаем это достаточно быстро. с чего начнем? пожалуй мы начнем со зрения. вот у нас есть глаз. и для этого глаза мы делаем нейронную сеть. которая генерирует нам внутреннее представление информации в системе. Это место пока что не будем никак называть. Теперь возьмем человеческое ухо. Ухо я рисовать не очень умею. Давайте попробуем. Возьмем тоже нейронную сеть, которая будет генерировать информацию и складывать ее сразу в два места. Первое место будет вот такое, а второе место будет пока что тоже непонятно. Пока видно. Можете не соглашаться, но главное, чтобы концепт был понятен. Возьмем также руки-ноги. Руки-ноги. Пальцы там что-то чувствуют, что-то делают. Еще одна нейронная сетка. Вы уже поняли принцип. Значит, получаем то что есть для рук ног нам нужно на самом деле еще одно опять же место еще одно место так что осталось осталось совсем немного осталось теперь определиться добавить еще одну одну нейронную сетку потом уже понять, что вот эти вот штуки все означают. это должно было быть... ну ладно. вот так вот и вот так вот обратную сторону и вот так вот здесь еще одна нейронная сетка вот так вот пока нн ничего конечно непонятно но уже можно уже можно примерно данные конструкции добавлять какие-то нам похожие похожие названия вот смотрите вот это вот штука которая вот здесь ну понятно тут надо еще там немножко двухсторонних связей сделать Вот эта штука, которая здесь, в общем-то, это есть то, куда поступает информация о том, что сейчас человек видит, слышит, ощущает. Информация из органов чувств. Значит, это центральная точка, и у человека она предположительно представлена таламусом, значит, это у нас ну не знаю назвать ее можно назвать ее внутренней назовем, чуть-чуть шире, но назовем внутреннее состояние. вот эту вот штуку дополнительную назовем память. на самом деле примерно так человек и работает. вот эту дополнительную штуку на движение, у которой еще будет обратная связь с нейронкой, вот такая вот. И предположительно представленный мужичком будет отвечать у нас за движение. Двигательный центр. Ну там сложнее немножко, конечно. Значит, здесь вот это вот краткосрочная память. Вставлена именно так. она слуховая краткосрочная память, бустер память так называемая. Вот. И вот примерно вот такая конструкция запросто может быть реализована. Ну вот здесь еще обратную связь делать вот таким образом. и данная конструкция действительно будет успешно некоторые задачи решать, особенно если мы подучим некоторые области, например, в качестве вот этой области автором одной из работ. скомбинированный двигательный центр, вот это скомбинирование с внутренним состоянием предлагается, и с памятью еще предлагается взять для этой части… Юрий, извините, у вас нет ощущения, что мы углубились от цели? 

S08 [00:59:08]  : То есть, мы сейчас, по-моему, ушли в некоторую интерпретацию устройства нервной системы человека. 

S02 [00:59:17]  : возвращаемся обратно. вот я просто пример привожу. давайте попробуем. вот здесь вот находятся какие-то системы, гпт отвечает за верхнеуровневые. здесь еще одна настройка над движением. внутреннем состоянии, значит, за память отвечает обычная память, когда мы сохраняем какие-то куски, какие-то фразы, сохраняем в обычный буфер и можем извлекать по запросу или внутреннее состояние. Краткосрочная память хранит какие-то, опять же, можем конвертировать для удобства интерпретации все это, практически все это в текстовый вид, всю внутреннюю информацию, чтобы можно было отлаживать данную систему и работать с данной системой. Вот теперь вопрос. Такой вопрос, вопрос на самом деле очень, очень простой. Можно ли считать данную систему Если она демонстрирует какие-то там, ну пусть даже посредственные результаты совершенно, можно ли считать данную систему AGI? Или же чего-то в ней не хватает, какой-то там мистической души? для этого или же она просто должна показывать достаточно хорошо решать задачу зависит от аудитории коллеги коллеги у меня есть определенная проблема во первых у нас запланирован был еще один спикер 

S08 [01:00:52]  : Которая остается уже всего меньше часа с учетом того, что возможно дискуссия. А во-вторых, мы сейчас еще дальше удалились от темы интерпретимых нейронных сетей. Сейчас мы ушли к вопросу о том, что считать AGI, а что не считать AGI. 

S02 [01:01:14]  : Такой формулировки вопрос снимем. 

S08 [01:01:17]  : Мы как бы поняли ваш тезис, мы поняли, к чему вы говорите, вы обозначили философскую проблему. 

S02 [01:01:24]  : Эта иллюстрация была нужна все равно, потому что спрашивали то, что нейронная сетка может запоминать только какие-то простые вещи, только какие-то визуальные вещи, вот здесь какие-то простые вещи. Но на самом деле было показано и одна из ссылок пролетала в группе про то, как в комбинации сеток сделали очень нетривиальное поведение робота. 

S04 [01:01:50]  : Вот показали свои схемы, ничего ровно. 

S08 [01:01:58]  : Игорь, я попытаюсь только ответить на вопрос Евгения Бабарыкина. Евгения Бабарыкин спрашивает, как называется такая архитектура. Так вот, архитектура, состоящая из многих нейросетей, объединенных в некоторую архитектуру, называется когнитивная архитектура. То есть, есть целое направление, которое называется когнитивная архитектура, которое предполагает, что мы строим систему искусственного интеллекта из разных ящичков и коробочек, соединенных стрелочками, где коробочки и стрелочки могут быть как разными нейросетями, так и какими-то другими приборами, внешними ораклами. Но мы еще дальше тогда удалимся от темы разговора. Юрий, я предлагаю все-таки вернуться к теме интерпретируемости неровных сетей. ну вот хорошо да давайте все-таки вот еще дадим вам полчаса максимум на то чтобы закончить ваш доклад вот и у нас уже две руки и я в общем-то я закончил то есть вот этот вопрос не оставлю как раз 

S02 [01:03:03]  : Ну, в контексте интерпретируемости вы теперь, да, действительно подумайте. То есть, если вы простую сетку не могли интерпретировать, одну, как мы будем всю вот эту вот штуку интерпретировать? Ну, ответ на самом деле такой, что какая-то внутренняя ее часть, по сути, является тем, что мы у человека называем сознанием, мы можем к ней задавать вопросы. И снова, фронт-инжиниринг, ответит на вопрос, как из такой сети извлекать какую-то информацию и как эта система из мира вначале будет извлекать информацию, чтобы потом из нее эту информацию извлекать. 

S08 [01:03:42]  : Хорошо, Юрий, то есть у вас доклад окончен, да? 

S02 [01:03:45]  : Да, у меня доклад окончен. 

S08 [01:03:47]  : Тогда два вопроса еще раз на понимание. Значит, первое, я правильно понимаю, что единственный способ, который в этом контексте вашего доклада есть на извлечение информации системы, это просто предъявлять ей задачи и, исходя из того, как она решает эти задачи, делать выводы о том, что она умеет. Правильно я понимаю? То есть это промпт инжиниринг. 

S02 [01:04:12]  : если мы говорим про то, что умеет, ну как бы тестировано, любое так и происходит, а какие есть еще способы тестирования? хорошо, то есть нет, то есть я понял, другие способы... если это вопрос про тестирование, то да, если вопрос именно про извлечение знаний, то тогда мы должны в миросети просить То есть если это какой-то навык, мы должны просить его сделать, воспроизвести. Если это знание, мы должны у нейросети попросить как раз это знание, чтобы она нам 

S08 [01:04:45]  : Но вы понимаете, что это не то, что вы сейчас демонстрируете. То есть вы понимаете, что вы сейчас нам не демонстрируете никакие навыки. Вы сейчас нам передаете свои знания, мы можем с ними соглашаться или нет, но вы не демонстрируете свои навыки. 

S02 [01:05:00]  : Это просто комментарий. Давайте дальше. Навык как раз двигательному центру. 

S08 [01:05:09]  : Вот вы двигаете рукой, это вы демонстрируете навык двигания руки, но знания вы передаете другим способом. 

S02 [01:05:17]  : То есть вы тоже не считаете, что это были знания, да? 

S08 [01:05:22]  : Нет, вы передавали нам знания, но при этом вы передавали их нам, не демонстрируя свои навыки владения этими знаниями. Значит, вопрос от Евгения Бабарыкина. Вот тут я уже забыл. Уточните, пожалуйста, архитектура, просвязку ученик-учитель, у нее какое-то есть название? 

S02 [01:05:45]  : Ну, teacher-student. Также иногда называются сиамские сети. Но часто. Раньше называлось. Ну и иногда так не называется. Просто knowledge distillation говорят про это же. Ну и некоторые сети просто про это, ну как бы в названии нейросети про это ничего нет, но просто это и внутри используется. 

S08 [01:06:08]  : Хорошо, спасибо. Дальше Николай Робчевский, пожалуйста. Потом Дмитрий Салихов, потом Борис Новиков. 

S09 [01:06:18]  : Вопрос такой по поводу вот этой схемы, которую, так сказать, нам Юрий Бабуров показал. Расскажите, пожалуйста, о ходе событий. В том случае, если на вход всех сенсоров, ну, глаза и уха, подадутся ситуации, которые не встречались при обучении? Появился неопознанный объект с неопознанным звуком? 

S02 [01:06:55]  : Ну, тут типичный ответ на это. 

S09 [01:07:00]  : Люди далеко не всегда адекватно реагируют на новые ситуации, поэтому… Нет, ну это антропоцентричный ответ, а не антропоцентричный, а нейроцентричный ответ какой будет в связи с этой схемой? 

S02 [01:07:18]  : Ну хотите, что вот нейросеть, если мы ее добавим в блок эмоций, хотите, она напугается? Чем напугается? Ну как, мы добавим сейчас, смотрите. 

S09 [01:07:29]  : Что будет на выходе зрительного анализатора нейросети, когда она увидит предмет, которому она не научена? 

S02 [01:07:41]  : А что у человека? 

S09 [01:07:43]  : Мне показывают предмет… Не-не-не, нельзя для объяснения того, как действует ваша нейросеть, рассказывать, как будет действовать человек. Человек действует заведомо не так, как вы нарисовали, поэтому это объяснение… Я просто не понимаю, какие варианты ответа есть на этот вопрос. А какой ответ? Логический ответ – никак она не будет реагировать, потому что она не может распознать неизвестный объект. 

S02 [01:08:15]  : Нет, это неправда. 

S09 [01:08:16]  : А, Хаттадар, скажите мне, какой выход будет из нейросети, когда на вход будет подано нечто неизвестное? 

S02 [01:08:27]  : Хорошо, вот вы вот будете есть незнакомую еду, например? А? Вы незнакомую еду будете есть? 

S09 [01:08:38]  : Я незнакомую еду могу отличить от знакомой. 

S02 [01:08:43]  : Вот вы отличили, она незнакомая. Вы её будете есть? 

S09 [01:08:51]  : Вопрос не о том, буду ли я её есть, а вопрос о том, могу ли я отличить незнакомую еду от знакомой. 

S02 [01:08:59]  : Но вы отличите, да, это незнакомо. 

S09 [01:09:01]  : Я отличу, а ваша нейросеть нет. 

S02 [01:09:05]  : Нейросеть тоже умеет так делать. 

S09 [01:09:06]  : Как будет выглядеть ответ, когда она увидит неизвестный объект, которым она не научена? И как она научится этому объекту, если будет видеть его несколько раз? 

S02 [01:09:23]  : Но это вопрос на самом деле очень простой. Я на него долго отвечать не хочу. Почему вы считаете, что нейросеть может работать только с известными активами? Это не так? Ну, будет какой-то другой ответ. У вас для каждого сочетание. 

S09 [01:09:46]  : Смотрите, если кошка или собака увидит предмет, который она не видела никогда, она немедленно испугается. 

S02 [01:09:55]  : Не перебивайте меня, пожалуйста. Эмоции тут вообще ни при чем. Значит, вы при виде незнакомой еды не пугаетесь. вот поэтому поэтому смотрите пожалуйста не перебивайте давайте уж я отвечу значит у нейронной сети она способна не один объект отвечать она способна отвечать обычно нейросеть комбинацию объектов перед ней знакомых незнакомых и так далее для каждого объекта какая-то часть кода у него есть. для незнакомого объекта тоже будет какой-то код. код типичного незнакомого объекта. И реакция может быть такая, которая связана с этим незнакомым объектом. 

S09 [01:10:47]  : Типичный незнакомый объект – это замечательно. 

S02 [01:10:50]  : Ну так же, как у вас незнакомая еда, вы её считаете, ну да, это незнакомая еда, с ней что-то можно… Да, но дело в том, что у меня незнакомая еда означает возможность 

S09 [01:11:02]  : достаточно чётко и конкретно её описать, несмотря на то, что она незнакомая. 

S02 [01:11:07]  : Ну и компьютер может её описать, там, зелёного цвета. 

S09 [01:11:11]  : Компьютер может описать. Я говорю не про компьютер, а про нейронную сеть в том виде, в котором она сейчас существует. Расскажите мне, как она может описать? 

S02 [01:11:21]  : Вопросы по теории нейронных сетей по основам… Мы просто долго можем. Хорошо, давайте… Дима, пожалуйста. 

S06 [01:11:33]  : Да, спасибо. Мы очень сильно раскачались. Я одним словом отвечу Борису. Прошу прощения, Миколе. Это автоэнкодер называется. 

S08 [01:11:38]  : Отвечаю Юре. 

S06 [01:11:54]  : Замечательно, но работать она не будет, потому что миллион вопросов к ней, как вот это, как то, и эти вопросы явно не вмещаются в этот формат. Основная причина, потому что там нейросети, на нейросетях она работать как раз и не будет. Но схема замечательная, потому что я впервые вижу, что кто-то попытался сделать когнитивную архитектуру с применением нейронных сетей именно сборки нечто похожего на мозг. Поэтому я тебя попрошу ее сфоткать и выложить куда-нибудь, хоть в практический IG, хоть в общий чатик, и мы бы потом уже там предметно пообсуждали, потому что идей оттуда можно, в принципе, интересных наловить очень много. У меня все. 

S08 [01:12:45]  : лучше всего пришпилить комментариям к видео в группе, чтобы она там пришпилила. 

S02 [01:12:51]  : на самом деле я комментирую следующее, что на самом деле такие сети, тут ничего нового нет, такие сети на самом деле применяются на практике уже. многократно и действительно они зачастую способны обманывать человека тем, что кажется, что они умные благодаря блоку памяти как раз. То есть да, проблема в том, что мы не можем быстро учить нейронные сети, но блок памяти, в котором у нас есть возможность мгновенно запоминать информацию, мгновенно потом извлекать и также использовать эту информацию при ответе на вопрос. способна создать ощущение, что компьютер действительно понимает человека. Например, он способен запомнить имя. Говорим, да, нейронные сетки не способны на запоминание с одного раза. но такая сеть за счет того, что у нее есть блог, который хранит просто текстовую или какую-то там информацию, то есть этот блог, представьте, он ответит. 

S06 [01:13:51]  : Юр, у меня был не вопрос, это было просто предложение перенести в другой стратегии. 

S08 [01:13:58]  : Извиняюсь, давайте короткий вопрос-ответ от Бориса Новикова. 

S07 [01:14:02]  : Юрий, от вас ждет след. 

S08 [01:14:04]  : То есть, Юрий, от вас ссылки в группу, в комментарии к видео, значит, и продолжим обсуждение. Борис, пожалуйста. 

S01 [01:14:10]  : Да, два коротких замечания. Во-первых, мне очень понравилась модель иерархическая, что сначала сеть делает классификацию тех текстов или вообще входной информации по предметам областям, а потом уже более Простая сеть учится внутри каждой предметной области. Мне кажется, это очень продуктивный подход, отражающий образование и обучение людей. И второе. Что такое интерпретируемость? Вот что человек, что нейтронная сеть может дать ответ на вопрос по классификации. Это кошка, это собака, это такое-такое, значит, язык или там предложение или другое, но интерпретируемость – это, видимо, способность объяснить, почему был дан такой ответ. Но этого способности нет у человека, когда человек решает задачу, кроме самой простой применения алгоритма определенного. он не может объяснить, почему получено именно такое решение сколько-нибудь творческой задачи. Ну, например, если он делает рисунок, почему он нарисовал объект так, а не иначе? Леонардо нарисует одно, а Дали совсем другое. И вот поэтому интерпретируемость, мне кажется, должна быть применительно к нейронным сетям, такая же, как применительно к людям, то есть по испытанию результатов. Если предложено новое лекарство человекам, то непонятно, почему человек предложил именно такую форму лекарства. Но его потом долго испытывают и либо утверждают для применения, либо не утверждают. И с сетями, на мой взгляд, должно быть то же самое. А объяснить, почему сеть или человек приняли именно такую форму лекарства – это задача, на мой взгляд, невыполнимая. Спасибо. 

S07 [01:16:29]  : Спасибо. 

S08 [01:16:31]  : Коллеги, я предлагаю на этой высокой ноте подвести итог первой части и плавно перейти ко второй части. Дима, пожалуйста. 

S06 [01:16:40]  : Да, сейчас я попробую экран расшарить. Давно это не делал. Пока я тут шарю. А, нет, видимо, наоборот нужно сделать сначала. Вот, маленький дисклеймер, поскольку у меня будет немножко с другой стороны рассмотрен вопрос нейросетей. Дисклеймер, ответ и Антону, и Юре одновременно. поскольку немножко с другой стороны буду рассматривать более критичные нейросетки сейчас, чтобы не получилось так, что я прям противоречу Юре. то есть он говорил, что сеть умеет это, умеет то, а я буду говорить наоборот. я скажу как бы все чудеса Вы знаете, что сети, в принципе, давно уже работают, промышленное применение. Все эти чудеса делаются не столько нейросетями, сколько пайплайнами. То есть все-таки основа – это некий пайплайн, внутри которого в составе есть нейросети, может быть, даже не одна. И тем не менее всегда над нейросетью присутствует некая символьная обвязка, то есть попросту некий алгоритм. Простой пример – посмотрим какой порог уверенности у ответа нейросети и в зависимости от этого порога мы там или делаем какой-то fallback или передаем управление еще какой-то нейросети и так далее. это просто чтобы не было такого предметного спора о том, что нейросети умеют, а что нет. в том числе ответ на твой вопрос, Антон, это вот по поводу вот этих систем, которым нужно решать сложные задачи в юридическом домене. это все делается, но опять же, сложными пайплайнами с кучей нейросетей. вот я это все делал, так что, если что, можно потом это все обсудить. так вот, кажется, я расшарил. виден ли мой экран теперь, коллеги? 

S02 [01:18:43]  : да, виден. 

S06 [01:18:44]  : ага, ну все. Вот, собственно, я хотел пробежаться по разным видам нейросетей и показать, что не только бэкпропом живут нейросети. Разложить немножко по полочкам все это для большей ясности. Расскажу, как они обучаются, какие задачи выполняют и какие у них есть ограничения. вот, рассмотрим список сетей, которые я тут привожу, в том числе наши любимые бэкпроповские сети. не все сети здесь есть, например, байосовские. я не включил там всякие машины больсмана, потому что совсем уж времени не хватило. тем не менее, что успел, то пройдем. давайте поехали. Первая сеточка у нас сеть Хопфилда. Она из себя представляет однослойную сеть, по сути дела, с циклическими связями, где каждый нейрон связан со всеми другими. То есть она обучается без учителя. Как она это делает? есть фаза обучения, ей показывают некий образ, например, картинку, и веса связей между нейронами регулируются таким образом, чтобы нейрончики пришли в некое состояние равновесия. поскольку они все циклически связаны, они вначале очень долго пульсируют, пока не успокаиваются. когда не успокаиваются, считается, что сеть эту картинку запомнила. теперь вот видно там на картинке справа, когда этой сети предъявляют испорченный образ картинки, она его быстро восстанавливает. точнее, она подбирает наиболее близкий к этому испорченному образ готовый образ. где применяются? сложно сказать, если честно, я в жизни не видел никогда применения этих сетей, поэтому пойдем дальше. сети Кахонина. здесь уже два слоя. слой для входных данных, вот он снизу, и слой кластеризующий. то есть сеть делает кластеризацию. и эти кластеры, они образуют как бы такие регионы на поверхности этого слоя, и поэтому еще действительно называют самоорганизующимися картами. обучаются они так. подаем битовый образ на входной слой, и какой-то из нейронов получает больше активации, чем все остальные, и он становится победителем, а все остальные нейроны при этом как бы отдыхают. Соответственно, веса связи входных нейронов с этим нейронным победителем увеличивается, но не только с ним, берется еще небольшое его окружение локальное, и в этом окружении также веса усиливаются, но уже в меньшей степени. таким образом создается как бы небольшой регион активации именно для этого образа. потом подается другой образ, он создает еще один регион пластеризации, и в итоге пространство пластеров у нас наполняется. и когда оно наполнено, у нас уже каждый следующий образ, он в принципе скорее всего попадет уже какой-то существующий кластер. ну собственно вот так оно естественно тоже обучается все без учителя. применяется в жизни тоже не видел, но вот на них ссылается Владимир Смолин регулярно, поэтому будем считать что где-то они применяются хотя бы в теории. пойдем дальше. сети обратного распространения или просто нейросети. когда не используется никаких дополнительных прилагательных, то мы говорим именно об этих сетях. немножко истории приведу. была изначально модель формального нейрона, нейрона макало-капицца И она была создана уже давно, в 50-е годы где-то, но ей мешало жить то, что такие нейроны нельзя было объединить в многослойную сеть. То есть объединить-то можно, конечно, было, но вот как ее обучать было непонятно. И вот советский ученый, кто бы мог подумать, Александр Галушкин, придумал алгоритм обратного распространения ошибки. а потом джеффри хинтон его еще довел до ума. и вот после того как появился этот алгоритм, сеть стала можно составлять большое количество слоев и все это обучение наконец-то оптимизировать стало возможно. что произошло? эту модель формального нейрона, то есть по сути линейного сумматора, заменили на алгебраические операции. то есть отказались от нейрона как от конечного автомата, который суммирует значение входа и передает на выход, и заменили на математическую абстракцию. теперь, чтобы посчитать состояние нейронов на выходе, нужно выполнить скалярное умножение матрицы с входными значениями на матрицу весов связи и потом применить нелинейную функцию. что это дает? это дает возможность считать градиенты. градиент – это то, насколько нужно изменить веса, чтобы уменьшить ошибку на входе. ну и соответственно то же самое проделывается со всеми предыдущими слоями и вся сеть таким градиентами обучается. подробности я не буду рассказывать, потому что миллион материалов есть в интернете, но по сути дела произошло, что из сети нейроны все превратилось в граф алгебраических операций, вот как показано на рисунки справа, или его еще называют вычислительный граф. но зачем нам много слоев, спросите вы. вот мы потихоньку приступаем к геометрическому смыслу нейросети, поскольку сеть базовую выполняет задачу классификации, нам нужно разделить как-то входные данные на разные группы, то есть на классы. проще, чтобы визуализировать, представим, что данные двумерные, то есть каждый пример данных это два числа. и пусть это будут ягоды. допустим, одно число означает массу ягоды, другое, допустим, размер ее. вот. и теперь расположим ягоды вот так на двумерной плоскости и получим такое представление наглядное. в простейшем случае, как на этой картинке, задача решается линейной регрессией, логистической регрессией еще называют. то есть можно легко провести прямую разделяющую эти классы, а уравнение это прямое, то есть y равняется ax плюс b. можно записать в более общей форме y равняется некая линейная операция от x. но в жизни данные расположены более сложным образом. например, как здесь. и понятно, что одной прямой мы никак эти данные не разделим с приемлемым качеством. что делать? и вот тут нам как раз нужен тот самый второй слой. в алгебраической форме это будет означать, что мы теперь последовательно применяем линейное преобразование, а потом нелинейное, а потом снова линейное, а потом еще раз нелинейное. если сначала наблюдаете, то будет видно, как сейчас линейное идет, сейчас нелинейное сжатие, потом переворот и снова нелинейность. нелинейность в данном случае представлена функцией гиперболического тангенса. и в итоге получается такое удобное представление, которое опять же легко делится на классы. но что если данные еще более сложно устроены, вот как здесь. здесь мы уже не сможем выполнить такое преобразование даже с нелинейностями. нам может прийти на помощь увеличение размерности пространства. что мы делаем? мы первую нелинейность делаем таким образом, чтобы она добавляла третье измерение. видно на рисунке, что из плоскости мы делаем это в объеме. математически это означает, что мы умножаем на матрицу размера 2 на 3 вместо просто 2 на 2, как в предыдущем случае. ну и дальше мы делаем ту же самую цепочку операций и в итоге приходим к тому же самому результату. если это все цепочки операций, то спросите, а при чем здесь вообще сети? причем здесь нейроны. мне кажется, что во-первых, это дань традиции, потому что все-таки начиналось все с нейронов. обратите внимание, когда мы выучисляли все эти нелинейности, все эти функции, то эти операции, ровно эти же, нам нужно применить для того, чтобы посчитать активацию нейронов на каждом слое. вложенная операция – это, по сути, вычисление состояния нейронов. поэтому, собственно, до сих пор называется нейросеть, скорее всего. ну еще, кроме того, если посмотрим на вычислительный граф справа, который изображен, то он тоже чем-то похож на сеть. пойдем дальше. есть много непоняток и мифов о том, что такое нейронные сети и что они умеют. миф первый о том, что сети бывают рекуррентные. на самом деле это терминологическая путаница между терминами рекуррентные и рекурсивные. я просто слышал много таких споров, когда они говорят, что сети не могут быть рекурсивными, а им в ответ говорят, ну как же, есть же рекуррентные сети. так вот, действительно, сети такие есть, точнее это называется блоки, и эти блоки обрабатывают последовательность, их так называют рекуррентные блоки. и смысл в том, что сеть использует, что каждый элемент, который подается на этот блок, он при обработке использует некое скрытое состояние, которое получено от предыдущих элементов. и вот таким образом получается, что мы используем рекуррентность. но если мы смотрим на вычислительный граф вот здесь, то конечно здесь никаких циклических связей быть не может, потому что это просто функция. следующий миф о том, что сети хранят знания, про то, что мы сейчас долго обсуждали. Опять же, очень сильное мешание терминов, что такое вообще знание и что такое хранение знаний. но, тем не менее, многие из вас представляют знания примерно так, как на левой картинке, то есть это какой-то граф концептов, что-то типа антологии, и ожидают, что сетка внутри тоже хранит нечто подобное. но если мы подадим знания в таком виде, вот именно в виде графа, кстати, можно подать знания в виде графа, прямо есть такие сетки, они так и называются, графовые, Если мы подадим знание в виде графа или в виде текста, то каждый такой элемент знаний внутри превращается в точку в многомерном пространстве. По-другому это называется скрытое представление или эмбеддинг. И это превращение работает как кэш-функция в одну сторону. То есть если у нас есть такой эмбеддинг, то нет никакого способа разложить его обратно на составляющие. единственное, что можно с ним сделать, это сказать, насколько он близок в этом многомерном пространстве или далек от другого эмбегинга. что касается памяти, тоже опять же путаница терминов, просто потому что, если совсем уж по-научному, нужно назвать это параметры функции. Но это словосочетание длинное и заумное, и мы поэтому используем аналогию с памятью живых организмов. Но есть принципиальная разница все-таки. Наша память – это когда состояние сети меняется при прохождении информации по ней. А у искусственной нейросети при прохождении информации ничего не меняется, а меняется только в режиме обучения, то есть при обратном прохождении. однако есть архитектуры, где все-таки сделали память, про которую Юра немножко рассказывал. такая архитектура называется дифференцируемый нейронный компьютер. и там память представляет из себя набор слотов. то есть просто массив такой ячеек для хранения эмбеддингов. это конечно сильно не похоже на нашу память, так как у нас память прямо в сети живет. но по-другому, в принципе, сделать ничего и не получается. потому что, как вы помните, нейросеть – это просто функция. так, про наши обычные нейросети, наверное, закончили. и это спайковые или импульсные сети, которые, по сути, самые близкие к биологическим сетям по принципу работы. но на самом деле это тоже зонтичное понятие. то есть есть сети, которые обучаются с учителем, есть которые без учителя, есть которые обучаются с бэкпропом, есть которые по хебовским принципам обучаются. но если говорить прям биоподобные спайковые сети, то вместо алгебры там настоящие нейроны, которые выдают импульсы. импульсы тоже бывают бинарные или вещественные. но самое главное отличие в том, что там появляется координата времени как дополнительное измерение. что такое время вообще в контексте сети? вот пример. сеточка справа из пяти нейронов. она настроена так, что нейроны 4 и 5 срабатывают только если у нас на входе два импульса одновременно приходят. в принципе как биологические нейроны. что будет, если подать, если возбуждаются нейроны 1, 2, 3 одновременно? нейрон 4 сработает, а нейрон 5 уже нет, потому что сигнал от 4 нейрона требуется больше времени, чем сигнал от 3 нейрона, и в итоге они придут не одновременно, и все, условие одновременности не выполнится. то есть эта временная координата, она позволяет не просто определять какой-то рисунок активации, но и последовательность сигналов во времени. и на этом принципе строят обучение по принципу HEBA, а именно STDP, spike time dependent plasticity. то есть она может обучаться без учителя благодаря этому. но несмотря на все эти замечательные свойства, импульсные сети пока не нашли достойного применения в народном хозяйстве. Я думаю, потому что их применяют для тех же самых задач распознавания, что и традиционные сети, которые гораздо проще и надежнее в обучении. Последняя архитектура – это иерархическая темпоральная память. я придумал ее Джефф Хокинс и даже сделал на основании этого компанию, которая продвигает идеи в массы, называется Нумента. идея Хокинса была в том, чтобы воспроизвести информационные процессы в коре головного мозга. он выделил четыре типа процессов – обучение, распознавание, предсказание и поведение. сказал, что поведением он заниматься не будет, потому что это уже не корковая структура, а где-то там ниже, и механизмы там другие. основные фишки его архитектуры в том, что обучается без учителя, тоже многослойная может быть эта сеть, и занимается тем, что распознает образы и запоминает последовательность. как это вообще можно сделать без учителя, это уже по себе интересно. давайте разберемся. все держится на трех китах. первый это разреженное распределенное кодирование. это когда любой образ кодируется активностью небольшого количества клеток в регионе. вот видите, регион. в котором очень много клеток. из них активно, как правило, 2 процента. что дает такое кодирование? во-первых, устойчивость к шуму. то есть даже значительное повреждение исходного образа позволяет его корректно распознать. во-вторых, это позволяет делать всякие битовые операции типа и или или. для того чтобы, допустим, операцию или мы можем применять, чтобы понять, насколько два образа похожи. просто применяем битовую i и считаем, какое количество бит у нас в этом пересечении. и на этом основывается мера сходства. второй концепт – это пространственный группировщик. или spatial pooler, он выполняет кодирование плотного образа, то есть данных исходно входящих, вот в это самое разреженное представление, разреженный образ. как это работает? тоже там связи все со всеми получается между этими двумя слоями, и при подаче образа какого-то данных некоторые колонки становятся активными. вот они красным цветом обозначены. как только колонка становится активной, она начинает, включается механизм локального торможения, не давая соседним колонкам становиться активными. и таким образом возникает некий узор из активных колонок. и этот узор, вот он похожих битовых образов, соответственно будет тоже похоже. то есть они будут пересекаться. то есть по сути реализуется принцип local sensitive hashing. и третий концепт это память последовательности или sequence memory. если вот первые две штуки по сути дела еще Дональд Хэт придумал в 50-х годах, то вот это это прям придумал сам Джефф Хокинс. я нигде ничего похожего не встречал. работает он довольно таки хитро. я не буду рассказывать алгоритм. во-первых, он очень сложный. во-вторых, я сам до конца не разобрался. но вкратце так, что у нейрона есть три источника данных. fitforward – это то, что идет от данных исходных, либо от предыдущего слоя в иерархии. фидбэк – это от вышележащей иерархии, а контекст – это сигнал от других колонок в том же самом регионе. и как раз эти сигналы кодируют предыдущий элемент последовательности. то есть нейрон принимает решение о том, активироваться ему или нет, учитывая все эти три компонента. Как он конкретно там принимает решение, я так и не понял. Получается, что он такой контекстно зависимый, и благодаря этому можно кодировать любые последовательности и предсказывать следующий элемент последовательности. Ну, собственно, все про HTM. я, если честно, там тоже, получается, было какое-то бурное развитие у них, но последние три года, я смотрю, там у них нет практически никакой активности. на сайте биты ссылки, я не знаю почему, но, видимо, не нашла какого-то широкого распространения этой архитектуры, а может просто кончились деньги у Джеффа Хокинса. опять же, они же не зарабатывали на этом практически ничего. вот, ну и про бенжи. значит, он смотрит на вас с немым укором, что мы тут все по фигне обсуждаем. так вот, yoshua benjo на выступлении, по-моему, в 19 году выступление называлось from system 1 deep learning to system 2 deep learning, то есть два раза слово deep learning в этом выступлении. он предложил идею, точнее он согласился с идеей о том, что ML вообще и deep learning в частности делают то, что делает система номер один, в то время как система 2 остается нереализованной. думаю, что все вы знаете, что такое система 1 и система 2. также он сказал, что система 2 оперирует дискретными понятиями и стало быть нужны некие раздельные представления. если мы вернемся к этой мясорубке, то как раз вот эти наши все понятия, которые были на входе, смешиваются и все становится неразделимым. он говорит, что их надо как раз хранить раздельно и назвал эти раздельные представления sparse factor graph, вот, раздельный граф факторов. и сказал, что дипленинг нужно как-то двигать в эту сторону. ну, в общем, кроме того, что он это сказал, за три года пока ничего не изменилось, так и не появились никакие рабочие концепты, насколько я знаю. если что-то появилось и вы знаете об этом, то дайте знать. в общем, все. спасибо за внимание. 

S08 [01:41:50]  : Дима, спасибо. Я правильно понял, что с твоей точки зрения нейросети являются в принципе необъяснимыми? 

S06 [01:42:01]  : Сейчас я выключу демку. 

S08 [01:42:04]  : информацию из них нельзя извлечь в принципе, потому что она перекручивается через мясорубку и фарш невозможно повернуть назад. 

S06 [01:42:13]  : в целом да, но то же самое, что и в человеческом мозге. никак не можем интерпретировать наши белковые рецепторы, которые на синапсах находятся, так чтобы извлечь из этого какую-то информацию. но есть куча хаков, евристик о том, как эти знания явно извлекать. Юра частично про них рассказывал. но в принципе да, исходно нейросеть это черный ящик. 

S08 [01:42:46]  : окей. 

S02 [01:42:47]  : я только про нейрокортирование еще не рассказал, как еще один способ. но в общем-то там тоже все понятно. электроды ставим куда-то и смотрим. 

S06 [01:43:01]  : смотри, да, с помощью нейрокартины ты можешь сказать, что вот эта область отвечает за движение ноги, а вот это за говорение, но сказать, где здесь находится слово AGI, а где слово спасибо... 

S08 [01:43:14]  : Ну давайте, наверное, не будем отнимать хлеб у Анохина и его команды и рассуждать о генетически модифицированных клетках и оптоволоконных световодах, подключенных к Аре. Мы же все-таки здесь немножко на другую тему. Окей. То есть, максимум, что мы можем делать, это Prompt Engineering или электроды к голове. Коллеги, есть какие-нибудь вопросы? 

S05 [01:43:51]  : Антон, ты именно вопросы предлагаешь или комментарии? 

S08 [01:43:54]  : Если нет вопросов, можно перейти к высказываниям и комментариям. То есть, как я понимаю, вопросов нету, поэтому, Сергей, пожалуйста. 

S05 [01:44:05]  : Коллеги, я просто хотел... Дмитрий и Юрий, но я понимаю прекрасно, что вы поставили перед собой оба такую сложную задачу, как огромную научную дисциплину изложить при помощи ниточек, веревочек, квадратиков и каких-то картинок. то, чему вы посвятили примерно минуту вашего рассказа. Есть такой вот замечательный тон, он такой вот толщины. Называется The Brain Theory and Neural Networks, автор Arbib. Эту книгу вы не найдете, потому что она была издана в 95 году. Она фактически уже в энциклопедическом хэндбук виде описывает такой огромный мир нейронных сетей, способов их обработки информации, кодирования, разреженных, так сказать, с обратными связями, с неправильными связями, с ошибками, с тем, что там чему аналогично и так далее, так далее, что я подозреваю, что произошел фундаментальный просто разрыв такой уже, он уже такой гносологический. Между тем, что было создано, так сказать, осмысленно людьми, которые не продавали тогда, но у них были просто, они в институтах сидели, работали, а вы вынуждены продавать. Вот в чем проблема. Наработан такой огромный пласт, что сейчас я уже даже не вижу способа, как это сохранить. Понимаете, я вот эту книжку вам сейчас показываю, вы на нее смотрите, как на музейный экземпляр. А для нас, для поколения, которое работало уже, это были живые знания. Это было то, что мы, вот была там сеть Хофелда, которую упомянули и сказали, что вы не знаете, что с ней делать. А то, что она там вот рекурсивная, рекуррентная, как бы вот она же и с нее пошла. Была сеть Кахонна, про которую вы рассказали, так сказать, ну тоже на уровне того, что там буквально чуть ли не просто кластеры какие-то. Никто, конечно, кто создавал архитектуру тогда, в те времена, один слой не рассматривал. Рассматривались там системы с разными целевыми вещами. Одни сети кодировали для других сетей информацию. То есть это все тот огромный пласт, который Я еще раз подчеркиваю, он практически, наверное, у него только музейная какая-то вот такая связь. Ребята, которые программисты на Питоне, будут приходить в музей, видеть эти книги и продолжать изучать нейронные сети фактически на уровне учебника природоведения, на уровне вот тех самых рассказов. Поэтому просто вот когда вы там так вот между делом там отмахиваетесь, ну вот там какая-то сеть, неизвестно как ее там применять, поэтому пропусти. Вот как раз HTM не содержала вообще ничего нового. И когда Хоккинсу, я просто слышал его выступление, когда он рассказывал, пытался применить эту сеть, продать вернее эту сеть в ExxonMobil, а я сидел со стороны ExxonMobil в экспертном комитете тогда, ну просто так получилось. Он просто фактически говорил, ребята, вы давайте всю информацию, все ваши знания, которые есть, представьте так, чтобы можно было ее воткнуть в мою HTN. Но кто-то пошутил, что это царь-пушка, она стреляет очень хорошо, но только надо цель поднести к ней аккуратненько, разместить, закрепить эту цель, чтобы она не шелохалась. Потом отойти, и тогда царь-пушка ее поражает. Вот что такое HTM, условно говоря. Поэтому, коллеги, ну уж извините, пожалуйста, я понимаю, что у вас было очень мало времени, я понимаю, что нужно сжимать, я понимаю, что нужно торопиться рассказать о современных этих вот глубоких сетях, которые на самом деле ничего, никого в шаг не сделают. Но вы хоть так вот внутри помните о том, какого масштаба, масштабища были исследования, которые вот в этих огромных домах. Прошу прощения за эмоциональный комментарий. Спасибо большое. 

S07 [01:48:13]  : Спасибо. Я полностью согласен. 

S08 [01:48:18]  : Я могу только прокомментировать, что тут недавно обнаружили какие-то индейские артефакты, которые выглядят как самолеты. И если их воспроизвести в натуральную величину, они летают. Соответственно, утерянное знание древних цивилизаций. Похоже, мы находимся в той же самой ситуации. Спасибо, Сергей и коллеги. Кто-нибудь еще может сказать что-нибудь более позитивное? 

S05 [01:48:45]  : очень позитивно старался и Антон ты напрасно я очень то есть еще то есть можно еще восстановить знание еще можно восстановить я считаю что в принципе возможно для этого нужна какая-то государственная программа то есть для этого нужно прежде всего немедленно остановить работу школы анализ данных яндекса Перестать преподавать по ахинеи, которые преподают на ВМК и на физтехе. Закрыть обязательно образовательные программы на высшей школе экономики. Вот это все затормозить полностью. Закрыть эти все институты навороченные. И после этого государственную большую программу по образованию людей, начиная от фундаментальных основ линейной алгебры и так далее. Мы терем множество там и дальше-дальше уже ты понимаешь. Это сделать можно и теоретически. Я думаю, китайцы примерно по этому пути идут. Он, Игорь, так сказать, с возмущением ушел, не может терпеть слушать мою такую вещь. Ну, конечно, я слишком утрирую, чтобы там кратко это было. Но вообще-то говоря, идея вот именно так. Спасти можно и нужно. И я уверен, что это будет сделано. 

S08 [01:49:47]  : Сергей, можно вам вопрос? Да, Борис, я вижу вашу руку, сейчас дам слово. Извините, вот я как бы видел, как работают, куда идут китайцы, да? Ну, по крайней мере, два года назад я был здесь, в Ичкай. И видел, что все китайцы работают по лекалам тем, которые штампуются в Стэнфорде, но только в масштабах... Ну, также, в принципе, как это делается у нас, но только масштабы несоизмеримы. То есть, грубо говоря, на три статьи по лекалам Стэнфорда высшей школы экономики у китайцев их 300. 

S05 [01:50:26]  : Антон, это понимаешь как? Ты здорово видел, но ты видел внешнюю вещь, которая допущена на конференции. Во-первых, известно про китайские конференции, что там намеренно искажается информация. 

S08 [01:50:38]  : Это не китайская, это топовая международная конференция по ИИИ была. 

S05 [01:50:43]  : Но я просто хочу сказать, что то, что публикуется, и те люди, которые, они же как правило в кооперациях там и так далее. я сейчас говорю о том что делается условно говоря в каком там не знаю вот вот что сейчас делается там в лохите например каком или что сейчас делается например там не знаю в сандийских национальных лабораториях или что там сейчас делается внутри какого-нибудь огромного вот что там делается это никогда не будет опубликован более того не будут опубликованы не только результаты а даже тематики исследования не будут опубликованы вы понимаете? 

S04 [01:51:16]  : Ужасный автопик. Сергей, ты абсолютно... Ладно, хорошо. 

S05 [01:51:20]  : Я согласен. Принимаю, Игорь, полностью принимаю, соглашаюсь. 

S08 [01:51:23]  : Хорошо, давайте. На самом деле, интересно. У меня был вопрос. Ну ладно, давайте Борису Новику дадим вопрос. Точнее, слово. 

S01 [01:51:31]  : Я попробую примирить эти позиции. У меня в работе осознание есть параграф созерцателя людей. И есть, всегда была и есть фундаментальная наука и техника, и прикладные исследования и техника. Был Максилл, был Эдисон. И нужны и те, и другие. И не надо противопоставлять одно другому. То есть, конечно, нужны фундаментальные исследования, которые практику пока не выходит, но нужны практические наработки, которые могут быть полезными уже завтра. 

S05 [01:52:14]  : Борис, инженер должен быть грамотным. Инженер, который ведет практические исследования, должен быть грамотным. Он может не уметь доказывать теоремы, но он должен понимать их содержание. Иначе, ну меня так учили, я инженер. Понимаете? А вот когда инженер это эмпирик, который втыкает провода и смотрит работой системы или нет, то это уже близко к мракобесию, извините. Опять в топе. 

S01 [01:52:40]  : Они, конечно, должны быть грамотными, но есть работа в фундаментальной науке, которая в практику выйдет через 100 лет, а есть инженер, который знает фундаментальную науку, которая была сделана 50 или 20 лет назад и ее применяет успешно для практики. 

S08 [01:53:01]  : У меня есть вопрос, на самом деле, и небольшой комментарий. Сергей, на самом деле, в защиту Дмитрия, который, видимо, уже убежал, не выдержав, и Юрия, мне хочется сказать, что окей, книжка очень толстая, и, возможно, какие-то знания утеряны. Но с помощью этой книжки, с помощью этих знаний вроде как не удалось достичь тех технологических решений, которые на сегодняшний день демонстрируют Google, DeepMind, OpenAI. Насколько я понимаю, номера, гаишники на машинах и лица в метро распознаются теми самыми нейросетями. по тем самым лекалам, которые штампуют в Стэнфорде, а не по каким-то неизвестным работам, которые делаются неизвестно где, неизвестно кем. Это мое ощущение. Поэтому, если мейнстрим позволяет строить какие-то промышленные решения, то почему бы и не строить эти промышленные решения на основе мейнстрима. 

S05 [01:54:06]  : Но у меня есть вопрос, на самом деле... Ну, Антон, только можно, извини, пожалуйста, мои комментарии не касались лично Юрия и лично, значит, вот... Не, ну это я... Ничего личного. Я сейчас говорю фактически о целостной какой-то вещи. А номера распознают, конечно, не нейронными сетями. Вы хорошо это знаете. Никакие нейронные сети никогда не пустят на распознавание номеров. 

S08 [01:54:28]  : То есть вы хотите сказать, что для распознавания номеров ГАИ работают не нейронные сети? Конечно нет. 

S05 [01:54:34]  : Там работает паттерн матча на алгоритмы, которые проверены тысячелетиями. 

S02 [01:54:37]  : Деревья могут принять эти решения чаще. Просто потому что достаточно для простой задачи. 

S05 [01:54:44]  : Надежно, можно проверить, протестировать и так далее. 

S02 [01:54:48]  : В этом плане они не сильно отличаются. Сейчас нет. Понимаете, в чем дело? Сейчас, когда два года назад количество типов номерных знаков увеличили до 27, ну там примерно 20, то есть существенное решение усаживались. Сейчас, скорее всего, нейросети уже применяются. 

S05 [01:55:11]  : Они применяются только чтобы отказаться от распознавания. Они решают только одну задачу – апоксимализацию плотности. То есть в том месте, где нужно сказать, что не распознала система. А вот детекцию выполняют, конечно, алгоритмы, которые проверяют, которые доказательную метрологическую точность имеют. С нейросетью уже невозможно доказать точность во всем пространстве. Можно в целом какие-то оценки по крупным блокам пространства получить. А вот доказательную метрологическую точность только можно получить, если алгоритм... У меня коллеги просто занимаются распознаванием нейросети для реальных... 

S08 [01:55:47]  : нет хорошо коллеги коллеги можно я все-таки у нас осталось немного времени у меня есть предложение все-таки попытаться вернуться в тему значит объяснимости интерпретируемости нейронных сетей и у меня есть предложение высказаться всем по все-таки заявленной теме являются ли нейронные сети интерпретируемые или нет потому что как мне кажется то объяснение которое тот ответ который дал юрия но как минимум половину здесь не удовлетворил тот ответ который дал дмитрий он по моему в каком-то смысле не удовлетворил тоже существенную часть а может быть как раз удовлетворил не знаю но по крайней мере но ладно насчет у меня есть предложение высказаться вот как минимум для начала тем кто не говорил сегодня вот у меня кажется есть мнение что у Владимира Смолина и Александра Балдачева. Единственное, я попросил бы не жаловаться на жизнь, не пытаться кого-то уязвить, что он чего-то не понимает. Просто если по существу есть возможность высказаться у Владимира. Ну и потом, видимо, Александр, если вы могли бы тоже свою точку зрения высказать, было бы тоже очень признательно. Ну и дальше Николай, Сергей и кто еще захочет. 

S03 [01:57:09]  : Добрый день. 

S08 [01:57:10]  : Давайте так, Владимир, Александр, Николай и Сергей. Владимир, я вижу, уже включил видео. Я пока подключаюсь. 

S00 [01:57:19]  : Звук есть? Да, да, пожалуйста. Звук есть? Ну, собственно, как бы сказать, огорчает то, что всё очень поверхностно излагается. Может быть, конечно, общий уровень такой, и это и правильно. Я не очень понимаю. Вот я согласен с Сергеем Александровичем о том, что, в принципе, вот то, что называется «чёрным ящиком», мы на самом деле про каждый элемент и по каждую связь в этом ящике всё знаем. То есть просто нам, как бы сказать, не хочется читать толстые книжки и понимать, как все это работает. И вот если, как бы сказать, хотя бы некоторые теоремы посмотреть, как работает, то все будет значительно лучше понятно. И вот, собственно, к этому весь мой комментарий сходится. 

S08 [01:58:06]  : Владимир, вопрос. Есть ли принципиальная возможность получение информации из нейросетевой модели о том, какие в ней знания содержатся и в чем сущность тех моделей, которые они выучили для того, чтобы можно было вообще понимать адекватность и предсказуемость и надежность этих моделей. Вопрос. 

S00 [01:58:39]  : С моей точки зрения, принципиальная возможность есть, но, как правильно было сказано, что если редуцировать те редуцированные программы Стэнфода, которые читали товарищи, и они считают, что это лучшие учителя их учили, и они обладают лучшими знаниями, что, в общем, не совсем, на мой взгляд, соответствует действительности, вот, а все-таки разбираться, то можно, значит, понять, что, собственно, Света выучила, и, собственно, сделать это ценно. Другой вопрос, что те архитектуры, которые сейчас реализуются, они, в принципе, не нацелены на полное решение задач, и, естественно, вот это вот то, что надо там выяснить, выяснится, что да, они там как бы не... в каких-то случаях работают, в каких-то не работают. А так, поскольку нам доступны все элементы этого черного ящика, мы его называем черным ящиком. А если мы залезем в программу или дадим выводы данных, то мы, в принципе, все, как работает наша программа, все же можем узнать. И вопрос только использования тех, как бы, Знание и понимание, к которому вот, собственно, сегодня, к нему даже не апеллировали, к пониманию, как работает нейросети, на этом можно там многое понять и, соответственно, показать, как они что преобразуют. 

S07 [01:59:53]  : Владимир, спасибо. У меня начал появляться мотивизм. Спасибо вам. Александр, пожалуйста. 

S03 [02:00:02]  : Так, добрый день. Ну, прежде всего я хотел поддержать Игоря. Именно вот с этим я тоже хотел выступить, что ну очень невнятная терминология, ну очень невнятно о чем говорится. Получается информация, где данные, где знания. То есть это действительно очень больное место. Это просто, ну как бы язык нужно выравнивать, чтобы было понятно. Потому что, когда Юрий рисовал на картинке, вот поступает сюда информация. Что значит информация поступает? Что это такое? В световом импульсе есть информация или нет информации? Или это только данные? Появляются знания? Откуда знания? Ну и вопрос, конечно, про антропоцентризм – это ниже пояса, конечно, обсуждения. Нужно один раз навсегда, наверное, с Юрой поговорить, разобраться, что это все-таки некорректные такие аргументы по поводу, что нельзя рассказывать по поводу человека. Мы занимаемся именно тем, что дело и человека. И ориентироваться должны на это. И если мы интерпретируем, скажем, если нам нейронка выдала единичку напротив слова «собака», то мы понимаем слово «собака». Нейронка не понимает слово «собака». Для нее все равно, что она не знает, что «собака». Это мы научили на «собак» и видим «собака». Она не знает. 

S02 [02:01:28]  : Вы можете как-то обосновать вот это вот? Или это просто ваши слова, что она не знает? Вы такой ярлык поставили. 

S03 [02:01:37]  : Дело в том, что, ну смотрите, хорошо, вы ребенка спросите, а что такое собака? Она говорит тяф-тяф. А ты любишь собак? Я не люблю собак. Я люблю котов. 

S02 [02:01:51]  : если нейронка тоже самое вам ответит, то она начнет понимать. 

S03 [02:01:58]  : скажем так, там правильно кто-то что-то говорил, что если вы ее не научите этому, Не научите вот правильно так отвечать. Она и не ответит. Она не сообразит ничего. Нет, это неправда. Нет, Юрий, это отдельно можно разговаривать. 

S02 [02:02:16]  : Это очень интересный вопрос. Которых не надо учить, и они отвечают как раз правильно. 

S04 [02:02:22]  : Юрий, давайте все-таки дадим высказаться каждому человеку. 

S08 [02:02:26]  : Да, да, да. Давайте дальше. Это будет правильно. 

S03 [02:02:31]  : И та схема, которая бы на доске нарисована, это схема автомата. Схема какого-то автомата, который как-то должен адекватно ориентироваться в среде. То есть никакого отношения к АГИИ это не имеет. И, ну я не буду оригинально, скажу, там мышления нет, как такового мышления, как автономной деятельности какого-то непонятно кого, но деятельности внутренней, там нет этого. И именно чем отличается ребенок от нейросети, то что он может связать несколько понятий, подумать про кошечку, подумать про собаку, подумать про имя девочки, которых водила к врачу. Он может не знать эту девочку, а потом спросить, как тебя зовут. Меня зовут Анна Бородая. Кто там был, девочка? Ну вот эта девочка, женское имя. А, это ты ходила к врачу? И что тебе лечили, как тебе лечили? То есть вот это все. И либо нужно зашивать нейронки по слову, по слову. именно по слову, что это та же самая проблема, которая с графами. Но с графами, когда мы по слову это зашьем, будем знать, где это лежит и как это поправить, если возникла ошибка, а в нейронке мы не будем знать, где это лежит и как это поправить. И я как бы с Владимиром не согласен, что это все-таки черный ящик, и никогда мы не узнаем, как там. И правильно кто-то замечал, что мы не знаем, как это устроено и в голове, и как это работает у нас в голове. И поэтому какой выход? Может, смириться с этим, что действительно не стоит знать, и не нужно знать это. А может быть, и нужно знать. Вернее, скажем так, если мы обратимся к своему опыту, к своему мышлению, то у нас есть два уровня, скажем, не знаний, а нашей реакции на внешнее поведение, на ситуацию, на текст. Есть знания конкретные. Я вижу Москва, я знаю, что это город Москва, название города. Я вижу формулу Ома, я знаю, что это закон Ома. И есть понимание. Я понимаю, что происходит, но сказать не могу. Я не могу описать. Я понимаю где-то, чувствую квантовую механику, но не могу рассказать. И вот знание и понимание – это наше внутреннее. А в нейронке это не отличить. То есть она всегда будет на уровне знания. Что запихнуло – конкретное, фактическое знание. То и будет. Ну, не знаю. Скажем так, Юрий меня не убедил нисколько. Вообще нисколько не увидел. И самое главное, разочаровал именно в том, что мне показалось, что будет ответ именно про черный ящик, как нам извлечь эти знания. А то, что я скажу собаке своей, Бобик, принеси мне тапки. Он принесет тапки. Я знаю, что он знает, что такое тапки. Но это настолько банально, что если какая-то нейронка распознает лицо человека, который мы обучили, она знает, что это лицо. Ну, знает. Если я что-то положил в базу данных и делаю запросы, получаю из этой базы данных, эта база данных знает то, что я туда положил. Это не вопрос на ответ, что такое знания, потому что это мои все равно знания, я положил их, забрал их. И это не вопрос на ответ, как нам вскрыть этот черный ящик. 

S08 [02:06:03]  : Александр, спасибо. У меня очень короткий вопрос к вам, прежде чем мы двинемся дальше. Все-таки давайте все выскажутся, а потом, Юрий, вы снова сможете откомментировать. Александр, вот вы сказали, что вы разочарованы, что Юрий не показал, как можно извлекать знания из нейросети. И я, честно говоря, тоже этим разочарован. Потому что Prompt Engineering меня совершенно не интересует. По понятным, я думаю, большинству здесь причинам. Но при этом вы сами же сказали, что их извлечь невозможно. Вы ждали, что Юрий сделает какое-то неожиданное? 

S03 [02:06:42]  : Да, я ожидал, что он предложит какие-то варианты, которые позже прозвучали, что можно как-то мониторить состояние сети, можно сказать, что где-то в каком-то месте конкретно в этой области реагируют на такую ситуацию. То есть чисто практически мне это было интересно так, что каким образом связать, скажем, граф знаний, семантическое символное описание с нейронками, чтобы можно было бы реагировать не только на выход нейронки конкретный и связываться с графом, а где-то еще посередине находить какой-то слой, в котором будет еще не полностью формализованная информация, а какая-то обобщенная. Я могу, скажем, как я мечтаю, вот есть нейронка, она воспринимает некую ситуацию, на выходе выдает фиксированный набор, скажем, распознанных объектов, но где-то посередине она уже имеет кластер какой-то. Это драка. или это ситуация в ресторане, и тогда я уже подключаю семантическую сеть, симвельное описание именно этого кластера и помогаю ей распознать конечное состояние, что она выдаст. То есть, скажем, может быть в одной и той же ситуации, но в разных регионах будут выданы разные ответы. Она распознает. 

S08 [02:08:15]  : Хорошо. Александр, спасибо. Я полностью вас поддерживаю. Я тоже на самом деле ожидал, что будет что-то развитие предыдущего доклада, но на более продвинутом уровне. Оказалось, что мы про промпроинженеринг. Давайте дальше двинемся. У нас дальше, по-моему, Николай Робчевский и Сергей Терехов. 

S09 [02:08:39]  : Николай, пожалуйста. Прежде всего, я хотел сказать, что меня оба докладчика не разочаровали. а вполне адекватно, как мне кажется, описали ситуацию, и им спасибо за это. Второй момент по поводу того, можно ли вытащить информацию. Дело в том, что когда мы говорим «можно ли вытащить информацию», мы подразумеваем, то, какую и для чего мы её вытаскиваем. И главная проблема с нейросетями заключается в том, что мы хотим информацию вытаскивать для того, чтобы в тех случаях, когда она работает не так, как мы ожидаем, поправить её. И вот как раз эту информацию вытащить нельзя. Можно вытащить ту, которая что-то говорит о том, почему она так, а не иначе действует. Но это неинтересно, в общем, потому что она действует и действует. А вот если она действует не так, как мы хотим, то нам нужно найти способ корректировать, и вот этого как раз нельзя. Ещё замечание такое. Оно как бы у многих в той степени или иной степени фигурирует. Всем понятно, что нейросети в теперешнем виде, они не соответствуют тем возможностям, которые демонстрирует наш мозг. Ну, например, всем понятно, что нейросеть нельзя научить арифметике. Ну, нельзя и нельзя. Да, человеку можно, потому что это разные вещи, они как бы сделаны по-разному для разного. Но сплошь и рядом говорится так. Нейросеть это может, потому что, смотрите, вот человек же может, значит, мы когда-то там добавим нейронов, там все, и он сможет делать то, что человек делает. Нет, это ложное, то есть апеллировать к возможностям человека для того, чтобы… предсказать возможности нейросетей, которые радикально отличаются от человеческих возможностей, негорректно. Ну и по поводу уже совсем конкретной схемы, которую Юрий Бабуров нарисовал, если речь идёт о схеме потенциальной так сказать, системе искусственного интеллекта, то схему можно считать основой, но нужно назначить в ней тот элемент, который действительно будет делать интеллектуальные действия, а не те, которые там показаны нейросетями. И в этом смысле вот то, о чем говорил Болдачок по поводу этой схемы, оно правильное. То есть там всё правильно, кроме того, что там нет элемента, который будет делать именно интеллектуальную работу. То есть, например, строить описание неизвестных объектов, находить причинно-следственные связи и так далее. Потому что эти действия нейросети делать не могут. У меня все. Спасибо. 

S05 [02:12:43]  : Антон, у вас выключен звук. 

S08 [02:12:45]  : Сергей, пожалуйста. 

S05 [02:12:48]  : Спасибо большое, коллеги. Я прошу прощения, что я сегодня уже так занимал много вашего времени. Я просто хочу немножко вот, во-первых, Николай, как всегда, все сказал. Уже стало теоремой, если раньше было предположением, то теперь уже теоремой. Я просто хотел обратить такое внимание. Во-первых, у нас сегодня во время обсуждения, вернее, во время доклада прозвучало замечательное совершенно утверждение Дмитрия Салихова, которое я считаю ключевым в сегодняшнем нашем обсуждении. Оно состоит в том, что Когда мы говорим нейронные сети, то мы почему-то сразу бросаемся конкретно в эти нейронные вещи. А на самом деле, конечно, имеется в виду некоторый инженерный процесс, который сейчас называют pipeline, раньше называли когнитивную архитектуру, сборки и так далее. Они всегда присутствовали. Начиная со времен розенблата, это были целостные устройства, содержащие много чего. И вот, собственно, сама вот эта штучка вычислительная, которая много входов и одномерная функция пытается делать, она всегда рассматривалась как часть. То есть, если нужно что-то сделать такое существенно полезное, то прежде чем пытаться прямо вот в эту нейронку его засунуть, лучше, конечно, подумать, а нельзя ли это сделать каким-то обычным доступом рядом к состоящей базе данных или каким-то образом. вычислителя математическому, который может что-то сосчитать. Зачем же поручать нейросети, например, числа сортировать? Есть алгоритм сортировки. Поэтому это всегда, конечно, изначально всегда с самого начала это были какие-то гибридные инсертитуры, где вычислитель нейронный, обладающий специфическим свойством, умением работать с очень широколосной информацией путем агрегации ее, так сказать, в одномерную, маломерную функцию. Вот это его свойства. И, соответственно, как следствие устойчивых шумам и так далее. Вот где его используют. Поэтому спасибо, Дмитрий, за то, что вот этот момент нам ответили. Я не знаю, слышите вы нас или нет, но, по крайней мере, вы в зале, но я надеюсь, что вы слышите. А вот теперь в отношении объяснить. Антон, когда мы говорим или вы говорите о том, что можем ли мы объяснить, хотим мы объяснить, то, как всегда, вот я тут, наверное, воспользуюсь Александром, было чего бы, наверное, сказал, но не успел. Давайте сначала договоримся, что такое объяснить. Почему об этом это важно? Потому что представьте себе, что есть куча песка и там есть какая-то песчинка под номером ID. Потенциально я могу залезть в эту песчинку, там найти и утверждать, что пока я не пойму, как конкретно лежит эта песчинка, я никогда не пойму, как лежит куча. Но в действительности мне такой уровень детализации для понимания того, как она куча, если я собираюсь просто эту кучу, например, перейти на другое место, просто не требуется. То есть, казалось бы, аргумент о том, что из-за того, что мы какой-то структурный элемент нижнего уровня не можем его функцию протянуть до функции элемента высокого уровня, как бы из этого следует, что мы не объяснили. Нет, мы потенциально это можем сделать, просто оно часто может оказаться бессмысленным. Так вот, если так вот ответить на вопрос утилитарно, что такое объяснить, то скорее всего речь идет об объяснении вот этого самого учебника природоведения, о котором я говорил вначале. То есть фактически объяснить это, ответить на вопрос вот этой аудитории, терминах, понятных этой аудитории. в случае, когда мы имеем данные, мы имеем данные. любые нейронные сети есть суть функциональное порождение математической статистики. они так или иначе строят вероятностные модели данных или вероятностно-логические или какие-то суррогаты вероятности типа фазе. но это не меняет сути. и в этом смысле они проданы. Поэтому, скорее всего, когда мы говорим, что мы хотим, чтобы эти модели объясняли, то мы должны задать вопрос, объясните нам в терминах данных, объясните нам эти агрегированные в статистическую модель данные в терминах каких-то других данных, которые нам понятны. И тогда фактически мы запрашиваем мэппинг. от того, что у нас находится либо прямо на выходе, либо в скрытых слоях, что, кстати, очень много интересных работ, касающихся того, что же в скрытых слоях, мэппинг, вот это вот нейронная архитектура, деталь, куча песка, в отображение, которое нам состоит из тех вещей, которые нам сейчас понятны, этой аудитории понятны. Другой аудитории это может быть непонятно и неприемлемо. Учебник природоведения не устроил. Так вот, вот такой мэппинг устроить можно. Его можно сделать нейронным. Его можно сделать не нейронным. И, наверное, лучше его сделать не нейронным, как-то логическим и так далее. Его можно сделать адаптивным. К нему можно применить все то же самое, все те же представления о тестировании, об обучении, о, так сказать, его свойствах и так далее, как и к остальным нейронным сетям. И он будет объяснять. Этой аудиторией он будет объяснять. Но, как говорил мудрейший Аристотель, в некоторых аудиториях достаточно логических утверждений для того, чтобы обосновать некоторые положения. А в других аудиториях, это в риторике у него замечательная фраза такая есть, а в других аудиториях нужно обязательно привлекать мнение поэтов. Потому что иначе вы в этой аудитории не объясните. поэтому к вопросу объяснения надо тоже подходить именно с точки зрения вот а что же такое мы хотим объяснить. отмепить на известные ответы или на граф какой-то из цепочек известных ответов это понятный вопрос. и за такую задачу как инженерную решить можно можно ставить. все спасибо еще раз извините пожалуйста. 

S08 [02:18:21]  : Сергей спасибо большое вы меня тоже очень обнадежили. Игорь, пожалуйста. 

S04 [02:18:30]  : Спасибо. Я согласен с Сергеем, что Николай и Александр практически все сказали. У меня, по сути, нет прям чего-то нового, но я хочу попробовать суммировать какую-то вещь и до ее еще сказать. Что вот было правильно Сергеем сказано, вопрос был первый его по поводу того, что а может ли сеть использовать знание для созидания. Мы ходим вокруг этого слова знание, которое было, на мой взгляд, использовано не совсем корректно. И я бы сказал, что знание для человека это информация, которую вот мы знаем нечто и мы это применяем для чего-то. это не просто ну там как-то расклассифицированная информация это нечто что применяется мной как агентом для чего-то как бы в жизни вот можно грубо свести тезис так что пока нет вот этого как бы для чего-то и пока нет этого применения все это внутри знаниями бессмысленно называть потому что это как бы не знание это просто груда расклассифицированной информации и Можете много раз задавать вопросы, получать много раз ответы, но, тем не менее, это знаниями не будет. Это будет многократно расклассифицированная информация. По крайней мере, знаниями в понимании, допустим, меня как человека. И еще одну вещь я вижу в нашем... Но главный мой комментарий-то был не об этом. А вот он был по поводу взаимопонимания, други мои. На мой взгляд, Юрий, если вы раза три пересмотрите первые комментарии Николая Робчевского, то вот вы можете его начать услышать вы просто его не услышали он он как бы вроде как мы на одном языке говорим вроде как термины даже похожие, но вот вы это воспринимаете в каком-то своем инструментальном очень применении, вот как вы привыкли на этой нейросети смотреть, как на... они у вас в руках, они дают результат, вы это знаете, но вы как бы не слышите... и здесь дело не в антропоцентризме, а просто как бы надо попробовать это услышать вот мне кажется что важно в таких дискуссиях пытаться понять вот ту сторону что она что она имеет ввиду не как бы не на критику реагировать а именно ну вот пытаться по сути понять там что хотят говорить мне кажется в шоссе рабчевский все все в первом еще комментарии все в целом сказал то есть там было все понятно если вот внимательно это послушать и последнее по поводу этого взаимопонимания не могу не не упомянуть что я в своей книжке которая там я постил в чат там целых две главы как раз по поводу всех это определение я вот взял и высказался как антон предлагал почему таким развернутым текстом я так понимаю что кроме как раз николай рабческого и сарба дача ее нами никто и не читал ну может быть глядишь там Почитаем, у нас будет больше взаимопонимания. Я за взаимопонимание. 

S08 [02:21:34]  : Игорь, спасибо. Во-первых, я твою книжку собираюсь взять в самолет, когда в Москву полечу. А во-вторых... На два часа, кстати, успеешь прочитать. Да, у нас же есть, кстати, семинар, на котором ты будешь свою книжку представлять. Ты не отказываешься от него? 

S04 [02:21:49]  : Да не, ну могу, конечно, рассказать, но мне кажется, это смешно. Да не, ну можно. 

S08 [02:21:54]  : Ну давай, ладно, хорошо, тогда оставляем. Хорошо, коллеги, все, спасибо. Всем спасибо докладчикам за потращенное время на подготовку и спасибо слушателям за воспринятие информации, за отнесение. 

S02 [02:22:09]  : А я могу все же последний комментарий напомнить? 

S07 [02:22:12]  : Да, Юрий, пожалуйста, хорошо, давайте. 

S02 [02:22:15]  : Значит, смотрите, я извиняюсь, Николай, я первый ваш комментарий просто не прочитал, я бы на него обязательно тоже правильно ответил, просто я его пропустил. Значит, давайте попробую сказать вот так вот кратенько. Известно, что область искусственного интеллекта это те задачи и только те задачи, которые искусственный интеллект, то есть компьютер делать не умеет. Как только какая-то задача делается, она сразу выпадает из этой области, говорится, ну да, компьютеры умеют это делать, но это же не задачи искусственного интеллекта больше. когда-то шахматы были, например, задачи искусственного интеллекта, а сейчас кто считает задачи искусственного интеллекта? никто. В этом плане я прошу вас определиться с тем минимальным каким-то уровнем, который вы зафиксируете и все равно будете считать компьютер, обладающий этим уровнем, искусственным интеллектом или AGI, потому что комментарий в духе, что да, компьютер умеет X, но он же не умеет более сложного Y, поэтому он не интеллектуальный. Но все же делается поступательно, и человек тоже в какой-то момент не умеет Y, а умеет X. А некоторые за всю жизнь не научаются числа складывать, значит, они не интеллекта, что ли. Так что вот здесь очень-очень тонкий вот этот момент, так же, как и со знаниями. Давайте я как-нибудь, наверное, в текстовом виде разверну вот эту архитектуру, которая есть, точнее, один ее кусочек, на который не обратили внимание. На самом деле тут не все нейронные сети, а вот там, где память, у нас запоминание просто на уровне текста, на уровне просто записи текстовых блоков и символьных вычислений получается. Обратите внимание. нейросеть, которая работает симуляцией вычислений. 

S08 [02:24:32]  : Так, Юрий, у вас пропал звук. Юрий, у вас почему-то пропал звук. 

S02 [02:24:38]  : Да, пропал звук на секундочку от наушников. Да, и вот возможно за этим подходом все же будущее. 

S08 [02:24:46]  : Хорошо, Юрий, прежде чем мы дадим заключительное слово Сергею Терехову, у меня к вам просьба. Поскольку у нас с вами планируется доклад на NLP-воркшоп на AGI 2022, кстати, предварительная информация, что наш воркшоп приняли, соответственно, будет анонс, я надеюсь, через неделю, а может быть даже на OpenTalks. Татьяна Шаврина, кстати, любезно согласилась принять участие в программном комитете. И вот мне хотелось бы, Юрий, чтобы вы вот те замечания, предложения, комментарии, которые сегодня прозвучали, чтобы вы их учли когда будете рассказывать про интерпретируемость с точки зрения на лп вот мне кажется это очень интересно попробуйте пытаетесь это учесть спасибо сергей скажите заключительное слово коллеги но я не в правильном заключать и это как никакой не вывод 

S05 [02:25:52]  : Просто я хотел обратить внимание на вот какую вещь. Вот есть замечательная теорема Байеса, на основе которой очень-очень много было чего хорошего и не очень хорошего сделано. Вот эта теорема Байеса содержит прайор, априорное распределение, априорное предположение, вокруг которого дальше строится следующее, уже, так сказать, при помощи протоподобия локалифуда, следующее постерайра. Но мало кто вспоминает о том, что прайор должен отвечать какому-то возможному, истинному какому-то утверждению, которое существует, и он, так сказать, имеет не нулевую, а приорную, значит, возможность быть. Вот, Юрий, я просто хотел обратить ваше внимание. Если вы любые ваши рассуждения строите на основе прайора существования некоторого АГИ, ну, AGI, или некого искусственного интеллекта, дальше из этого прайера ставите вопросы делайте выводы значит и так далее действуйте то вы имейте ввиду что не у всех людей этот прайер такой же то есть возможно расхождение не связаны с выводами какими-то наблюдениями а с тем что просто априори вы очевидным прайерным образом предполагаете некие вещи касательно искусственного телевидения может не так отражаться на иметь и право других людей ничего личного исключительно вот как бы такой вот спасибо большое всем еще раз огромнейшее хорошо коллеги всем спасибо да спасибо до позитив и до новых встреч на open talks и на очередных семинарах спасибо до свидания 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
