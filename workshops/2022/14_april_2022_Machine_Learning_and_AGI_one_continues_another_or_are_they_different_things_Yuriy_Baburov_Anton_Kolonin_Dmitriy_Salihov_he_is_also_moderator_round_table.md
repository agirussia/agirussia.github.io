## 14 апреля - Машинное обучение и AGI - одно продолжает другое или это разные вещи? - Юрий Бабуров, Антон Колонин, Дмитрий Салихов - круглый стол — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/XwjxaD7kUNk/hqdefault.jpg)](https://youtu.be/XwjxaD7kUNk)

Суммаризация семинара:

На семинаре обсуждались вопросы машинного обучения и его связи с созданием искусственного общего интеллекта (AGI). Участники семинара высказывали разные мнения относительно того, каким образом можно достичь AGI.

Ключевыми моментами были дискуссии о том, что такое машинное обучение и как оно связано с AGI. Был поднят вопрос о том, что ML не всегда означает глубокие нейронные сети, а также о том, что экспертные системы также могут быть рассмотрены как формы машинного обучения.

Важным моментом стало обсуждение роли и возможности использования индуктивных предпосылок (inductive bias) в системах машинного обучения и AGI, а также вопрос о том, нужно ли искусственному интеллекту быть универсальным, или достаточно сделать его человекоподобным.

В заключение семинара участники высказали мнение о том, что для развития искусственного интеллекта необходимо более глубокое понимание математических идей, реализуемых в системах, а не только сосредоточение на прикладных задачах или изучении нейронных сетей.








S05 [00:00:00]  : Сегодня у нас очередной четверговый семинар. Семинар изначально планировался как дебаты. У нас нет такого официального формата, но попробуем что-то в виде этого сделать. Дебаты, где две идеи противопоставляются, которые можно, в принципе, обозначить таким образом, путь к AGI, он лежит через ML-подход или он лежит через что-то другое. И что-то другое, Юра будет защищать идею о том, что AGI – это ML в том или ином виде. Я, соответственно, буду защищать противоположную идею о том, что это не ML, а что именно, я как раз не буду рассказывать. Ну и Антон, наверное, в конце нас помирит, скажет, что все не так однозначно, много фейков и так далее. В общем, выступит неким третейским судьем, подведет под этим всем чертой. 

S02 [00:01:05]  : Я с вами огонь. 

S05 [00:01:08]  : Еще веселее. Поэтому, Юра, предлагаю тебе начать свою идею защищать 

S07 [00:01:20]  : Итак, всем привет. На самом деле сейчас давайте начнем с первого пункта, проговорим его подробнее, но потом уже поговорим обо всем остальном. Вопрос у нас первый. Любая деятельность по какому-то получению информации из мира и какому-то построению моделей, по определению это machine learning. то есть если мы говорим с точки зрения определений, то получается то, что любое обучение у нас это machine learning просто по определению. другое дело, что machine learning бывает очень разным. бывает machine learning условно нейросети, а бывают какие-то другие методы, которые могут быть совершенно другими. из классических это какие-нибудь деревья принятия решений, а не из классических это может быть какие-нибудь подходы, похожие на мозг или vocal, условно sensitive hashing. какие-то другие подходы. их много разных. нейросети сейчас вроде как мейнстрим, но только по каким-то одним критериям. а по другим критериям нейросети вообще не подходят. и конечно те люди, которые отождествляют Скажем так, кто говорит, что на нейросетях не сделать искусственный интеллект, они, по сути, говорят о том, что не то, что ML плох, а именно то, что нейросети, как инструмент, это весьма ограниченный специфичный инструмент со своими особенностями, и он не подходит именно для их задач, связанных с искусственным интеллектом. как с универсальным, так и с конкретным искусственным интеллектом. У нас есть куча примеров, как искусственный интеллект плохо работает. Например, планирование в каких-нибудь робоавтомобилях до сих пор делают не с помощью нейросетей, а просто на карте вычисляют какие-то алгоритмы, используют графовые или даже не графовые, а другой алгоритм. вообще не используя нейросеть, потому что неудобно нейросеть. Для каких-то других задач нейросеть не подходит. И будем ли мы сейчас дальше сразу говорить о дальнейших вопросах 1.2.3 или пока что по общему вопросу к этому пройдемся? 

S05 [00:04:19]  : ну я думаю... ну а ты раскрыл же этот пункт? 

S07 [00:04:23]  : основной вопрос я раскрыл, то есть свою позицию, то что любая деятельность по построению моделей это machine learning, поэтому если мы построим как-то искусственный интеллект, то мы это сделаем с помощью методов. 

S05 [00:04:40]  : что сразу вызывает кучу вопросов, типа, а что такое построение модели, что такое модель. ну ладно, давай это в секции вопросов будем делать, чтобы сейчас не размазывать. ну ты продолжай. 

S07 [00:04:52]  : так, хорошо. так, можно мне показать тогда вот этот слайд с пунктами 1.3 у тебя. выключу сейчас мы снова пройдем к тебе теперь конкретно вопрос можешь себя включить это один-два-три а ну или я могу себя ты же можешь у себя расшарить просто и так значит теперь, значит, это общий вопрос. теперь пункт первый. супервайз и антсупервайз. значит, определение, наверное, дошты для супервайз и антсупервайз. но, опять же, надо сказать, что есть огромный диапазон методов, и понятие супервайз и антсупервайз очень условное. и супервайз может быть по отношению к одному вопросу супервайз, а по отношению к другому вопросу будет супервайз. например, если мы читаем книжки, мы одновременно ан супервайз извлекаем из них какие-то знания и одновременно мы при этом учитель может говорить, что мы какие-то неправильно буквы слова читаем. один и тот же процесс, он может в себе иметь элементы supervised и unsupervised. более того, в последнее время в мейнстрим уже попала такая идея. DSL supervised, когда мы используем информацию о строении тех или иных объектов для обучения системы. Например, по одному слову предсказываем соседние с ним слова или наоборот, по контексту предсказываем слово в этом контексте. этот подход вот его с одной стороны он должен быть супервайс по той причине что у нас есть правильное слово которое вставляется в этом тексте в этом месте с другой стороны этот подход от супервайс потому что мы специально не не готовим правильные ответы как отдельные действия Вместо этого, когда мы говорим про человеческий мозг, мы тоже часто говорим о том, что человеческий мозг, он много чего там видит, слышит и так далее, и он обучается предсказывать. Но вот это предсказание, это и есть предсказывание следующих слов, предсказывание каких-то элементов на картинке, по соседним элементам картинки, достраивание этой картинки, поиск каких-то элементов на картинке интересных. Это все деятельность так называемая self-supervised. Основное self-supervised обучение, что мы уже на каких-то других картинках эту информацию научились извлекать, и теперь мы этот опыт обобщаем и можем на новой картинке предсказывать эту информацию. Именно так сейчас достигается большой успех на задачах. При этом, если нам нужно для конкретной задачи находить ответы, мы делаем супервайз от обучения уже вот этой вот обученной сети, которая выбрала в себя опыт знаний о том, какие бывают следующие слова для прошлых слов. И этой же сети мы теперь над ней добавляем настройку, которая уже обучает, позволяет обучиться выполнению конкретных подзадач. Например, определению определению текущее слово, подлежащее или сказуемое в предложении, глагол или существительное, он или она, пропущенное слово и так далее. То есть куча разных задач, но я в основном беру вербальные задачи для примера, но можно брать и на картинках то же самое. и подписи к картинкам, и так далее. То есть успехи, вот, например, Дали-2, она основывается на клипе, который внутри как раз обучилась вот этой штуке. Она обучилась внутреннему представлению единому, которое основано на self-supervised подходе. А потом мы с supervised learning уже доучиваемся до конкретной задачи. То есть этот подход и, по-видимому, тот же самый подход осуществляется в человеческом мозгу. Вначале мы учимся распознавать весь мир в его многообразии, а потом уже в этом мире нам говорят, что вот эта циферка 1, а вот эта циферка 2. А не то, что мы ничего не видели в мире, а нам говорят вот эта циферка 1, а вот эта циферка 2. поэтому вопрос. я не знаю, как-то много у меня получается большой рассказ. я думаю, может как-то по очереди. 

S05 [00:11:00]  : у тебя еще 20 минут, по сути, так что нормально. 

S07 [00:11:03]  : ну ладно. остальные пункты, значит. насколько универсальным должен быть Эйджай по принципам учения? здесь как раз вот самый интересный вопрос. потому что с одной стороны мы имеем такое интересное противоречие то, что если мы хотим сделать более универсальную систему, то такое ощущение, что эта система должна дольше учиться, и таким образом самую универсальную, самую большую систему мы можем вообще не скоро сделать, а можем сделать только маленькую какую-то компьютерную систему. но на самом деле современные методы оценки качества и прогнозов качества приходят к мысли о том, что в принципе в каких-то модальностях, в каких-то доменах типа речи или распознавания картинок, мы дошли достаточно далеко при весьма ограниченной вычислительной мощности, меньше человеческого мозга. по другим задачам мы достаточно далеко, и поэтому скорее тут будет зависеть от того, про какой домен мы говорим. если мы говорим про символьные вычисления и какое-то повторение символьных вычислений, то в общем-то уровень восьмиклассника у нас уже достигнут, судя по качеству ответа. а если мы говорим про решение каких-то там чуть более конкретных, но тем не менее высокоуровневых навыков типа выбор алгоритмов или программирование или выбор алгоритмов для того, как посчитать интеграл, то здесь компьютер может превзойти и 99% обычных людей, и часть программистов или часть математика. я считаю, что в основном у нас проблема пока что просто с вычислительной мощностью, но при этом нужную степень универсальности мы уже достигли по большинству задач, которые которые были связаны с какими-то конкретными доменами, более компактными, может быть. Что касается обучения по видео, что касается действия робота с сенсорами в непосредственной среде, тут мы еще, возможно, далеко, но при этом универсальные принципы, я считаю, что уже воплотились. другое дело, что можно ли воспользоваться нашими существующими технологиями, как-то их переделать так, чтобы вычисления требовалось еще меньше, а результаты были еще больше. и вот здесь такой ответ, что пока что пока что, скорее всего, не получается так сделать. непонятно еще по какой причине. мы знаем набор универсальных принципов, по которым построить AGI, но построить AGI на них за небольшое время, напоминаю, что человек учится лет 10-20-30, IGI мы хотим построить... нейросетки максимум мучатся месяц-два. и мы хотим, чтобы за месяц-два еще и при вычислительной мощности на компьютерных архитектурах мы еще и превзошли человека. Возможно, просто надо еще нарастить в 10-100 раз мощность. Другое дело, что непонятно, есть ли у нас такая возможность на текущий момент железная. И вопрос универсальности будет решен, и всем это будет понятно. Пока что понятно только специалистам, что движение в правильном направлении есть. И теперь, переходя на основе этого, ну, я думаю, более-менее я ответил на вопрос, может, не очень конкретно, но направление изложил. То есть есть отдельные исследователи, но не мейнстрим, которые пытаются именно придумать другие решения, которые были более, может, даже более универсальны, притом более быстрыми. более качественно работали бы и обучались бы на меньшем количестве данных. но как заметил Хинтон пять лет назад, что это наше проклятие, что сверточные сети и трансформеры тоже работают так хорошо. что нам не приходится искать архитектуру, которая была бы чем-то ближе к человеческому мозгу, которая была бы более оптимальна, как-то быстрее бы училась, потому что для большинства более простых практических задач текущий подход работает, и работает весьма неплохо. Поэтому мы в такой локальный минимум сейчас свалились, и из этого локального минимума пока не очень понимаем, как выбраться. поэтому теперь говоря о том, если мы будем отталкиваться от чего мы будем отталкиваться от универсальных принципов оптимизации дипломинга или же повторяя какую-то архитектуру мозга, то понимаете, эти подходы дополняют друг друга. То есть мозг по современным оценкам, по современным инженерным прототипам больше похож на такую систему из слабо связанных между собой областей. которых может быть штук 50-100, другие исследователи говорят цифры ближе к 400. Эти области как-то друг с другом взаимодействуют, но внутри они такие цельные и чем-то похожи как раз на нейросети, тем, что они учатся цельным образом, тем, что они цельным образом реагируют на события. Поэтому в этом плане получается, что мозг чем-то похож на лоскутное одеяло из разных нейросетей. При том, если мы посмотрим на то, насколько нейроны изменчивы, а их насчитывается штук 30 разновидностей, разновидности в том плане, что нейроны – это не все нейроны, но какие-то нейроны, слои идут вот так, элементы коротенькие или длинненькие, реагируют на один нейромедиатор или на другую, на одну комбинацию или на другую. Внутри разных зон есть нейроны разных видов, которые часть из которых реагирует на один нейромедиатор, часть на другую, то есть получается еще и внутри у нас какая-то более сложная архитектура, нежели просто простой конъективистский подход, вот как многие, которые плохо разбираются в нейросетях, считаю, что нейросети это просто какие-то операции, суммирование и много друг с другом всяких разных статистических простых действий. На самом деле нейросети тоже это лоскутное одеяло, но это лоскутное одеяло из трех-пяти типов разных действий. но слои и части нейросети обычно все же одинаковые. но это просто вопрос удобства. то есть если бы мы еще делали разные слои с разными параметрами, с разными настройками, мы бы вообще замучились это все дело оптимизировать. То есть у нас был бы подход такой же, как и в эволюции, что берем миллиард человек, у всех делаем немножко разные мозги и смотрим, какие лучше работают. К сожалению, у нас едва хватает сил один мозг в месяц учить, чтобы показывать крутые результаты, и это тратит затраты составляют при этом 5 миллионов долларов. Поэтому умножить это в миллиард раз, увы, пока что не представляется возможным. Поэтому пока что мы не используем и не пытаемся моделировать разнообразие мозга, но вместо этого отдельные исследователи какие-то кусочки пробуют делать разными, но обычно из этих кусочков составляют целую конструкцию, или там несколько видов кусочков пробуют, но лоскутное одеяло из десятков сотен разных видов кусочек даже не пытаются делать по переборным ограничениям. При этом работает ли подход использовать вот этот вот универсальный какой-то кусочек дипленинга, но есть данные исследований еще почти десятилетней давности, которые говорят, что нейросети, словом, 2014 года зрительную кору повторяли по результатам, которые на выходе, повторяли результаты на 95%. тут скорее следует говорить про уровень корреляции, а не полное совпадение. то есть все равно приходилось какое-то преобразование использовать, но тем не менее этот подход успешно используется, например, для обратного перекодирования мозга. то есть мы подключаем нейросеть, берем, смотрим выходы мозга, между ними ставим еще одну нейросеть, которая перекодирует одно в другое, и таким образом, например, можем получать расшифровку мозга. Говорит ли это о том, что мозг можно сделать из нейросетей? В общем-то, конечно, не говорит. Но, тем не менее, какое-то сродство у этих технологий есть. можно ли при этом делать какие-то кусочки на каких-то других принципах? да, конечно, можно пробовать. но просто вот текущие технологии пока что хорошо скейтятся, то есть в больших масштабах показывают хороший результат. в маленьких масштабах, конечно, зачастую есть какие-то другие технологии, которые показывают более хороший результат. Другие технологии пока что мы не научились масштабировать так же хорошо, как дипленинг. Поэтому дипленинг пока что побеждает на больших масштабах. Есть другая попытка моделировать мозг. Используем какие-то особенности поведения мозга. вытаскивать, строить модели мозга с помощью программистов. То есть делать какие-то правила. Эвристическим подходом это было известно в 60-е, 70-е. годы в 80-е тоже, значит нейросимвольным подходом это называли в 80-е и в 90-е и в нулевые. Сейчас постепенно начинается возрождение на новом уровне нейросимвольных подходов только нейро-часть уже используется на основе дипленина. При этом символная часть никуда не девается или же возрождается, потому что символная часть, ее намного легче отлаживать. И глядя на эти символы, легче понимать, что происходит в этом мозгу, который, конечно же, целиком просто без эволюции на миллиард экземпляров достаточно тяжело конструировать. поэтому мы конструируем по кусочкам и эти кусочки мы как-то должны тестировать. соответственно, для тестирования удобнее использовать как раз символьный подход. теряем ли мы на этом качество? вот тут на самом деле непонятно. где-то теряем, а где-то наоборот приобретаем. потому что у нас есть огромная база накопленных символьных текстов, и мы можем воспользоваться для тренировки методами self-supervised, и за счет этого какие-то модули очень быстро натренировать. При этом для каких-то других задач у нас большие проблемы с нахождением нужных датасетов. Например, для мышления, для рассудочной деятельности, для сознательной деятельности у нас никаких датасетов нет. И есть лишь надежда на то, что постепенно технологии считывания мыслей, считывания сигналов мозга будут улучшаться по качеству, и записывая с 10 тысяч добровольцев этот сигнал в течение полугода, например, мы сможем потом собрать большой датасет для каких-то рассудочных рассуждений. Или же можем в принципе в текстах находить связи, более высокого уровня, то есть в текстах тоже зачастую какие-то рассуждения приведены. Но тем не менее тут есть известная проблема common sense, то есть если буквально переводить то общего знания, то есть это знание общее, при этом поскольку оно общее, оно никому не рассказывается, потому что считается, что все и так его знают. например, все и так знают, что если стакан перевернуть, то вода из него выльется. 

S05 [00:26:48]  : Юр, еще пару минут давай, потом еще на вопросы, потому что нужно время. 

S07 [00:26:56]  : у нас нигде нет датасета для этого common sense, но тем не менее любые, что логическо-символьные рассуждения, что нейросимвольные рассуждения, что даже просто нейрорассуждения должны опираться на этот факт, но откуда нам этот факт узнать – непонятно. А с видео у нас перманентные проблемы из-за того, что видео требует много мощности. Анализ видео. поэтому получается вот такая ситуация, что какие-то области мозга искусственного у нас перекачаны, а какие-то области у нас сильно недокачаны. но что-то каких-то успехов мы уже достигли и в основном все же больше прогресс, пожалуй, за счет гипленинга и меньше именно за счет моделирования вот этой вот сложной какой-то вот обусловленности мозга. Так, ну я думаю на вопросы я, в общем, ответил. 

S05 [00:28:00]  : Готов теперь на остальные вопросы отвечать. Ну вот давай по порядку, поскольку в основном тут писал я вопросы и упомянул, что мы используем такую матрешку сначала, значит, Супервайз режим, на корпусах что-то обучаем, обучаем, потом супервайз обучаем на конкретной задаче. Но в контексте AGI, как ты себе представляешь, что это может быть за задача, которую мы обучаем именно как супервайз, типа МНИСТ? Вообще говоря, 

S07 [00:28:42]  : Я обычно как раз это называю моделирование как раз разумной, рассудочной деятельности, сознательной деятельности. То есть по исследованию психологов у нас есть несколько областей, которые осуществляют какое-то планирование и выполнение действий. Древние подходы к моделированию называли эту задачу General Problem Solver. Также, когда это применялось к объектам реального мира, это называлось Task Planner или Task Planning System. Подразумевается, что у нас есть некоторые механизмы. у которого есть некоторый виртуальный экран, но скорее даже не экран, а набор каких-то слотов, пожалуй, в которых у нас могут храниться какие-то объекты. И мы осуществляем манипулирование этими объектами, при этом они как-то могут преобразовываться. это могут быть виртуальные объекты, а могут быть прообразы реальных объектов. при этом у нас есть доступ к памяти, и мы можем из памяти также извлекать какие-то объекты или же загружать эти объекты в память. Если мы задумаемся, какая структура должна быть у этой памяти, то, скорее всего, мы придем к чему-то, что напоминает онтологии графовые, но, тем не менее, деятельность сама по себе, рассудочная деятельность к этим онтологиям не сводится. Она сводится к некоторым другим манипуляциям, а именно манипуляциям над активной частью памяти. объем активной части памяти небольшой, считается, что штук 5 примерно объектов у нас умещается в любой текущий момент, и при этом объекты могут быть не обязательно это может быть какой-то там объект, это может быть и фраза, это может быть кусок мысли, это может быть в случае юристов, которые профессионально учатся запоминать длинные фразы, это может быть очень длинная мысль этим объектом, но в общем все сводится к тому, что рассудочная деятельность это какая-то манипуляция вот этими вот вот этими вот объектами. 

S05 [00:31:29]  : Извини, Юр, перебью и обобщу. Правильно я понимаю, что ты говоришь о системе, которая в качестве выхода имеет алгоритмически связанные действия, то есть построение алгоритма? Нет, это не так. Хорошо. Что на выходе твоей системы? 

S07 [00:31:48]  : Если человек решает задачу сортировки, Вот ему надо объекты как-то рассортировать, поделить. Вот карты игральные по порядку расставить. Это не значит, что человек при этом вообще знает алгоритм сортировки. Он может изобретать по ходу, может его забывать, потом изобретать в следующий раз заново или делать в следующий раз по-другому. То есть получается то, что вот сама вот эта деятельность, это не есть построение алгоритма. Это есть выполнение каких-то действий в рамках какой-то текущей поставленной самим. 

S05 [00:32:26]  : Ну понятно, действия, которые же не просто идут один, два, три, четыре, а это именно алгоритмически построенные, ну типа дерево, да, действия, правильно? Возьмем твою сортировку, смотри, сортировка это же все такое. Возьмем элемент номер один, поменяем его с элементом номер два, если там условия, если потом циклы. Это же все дерево. Действия объединены в дерево определенным образом. 

S07 [00:32:52]  : Или нет? Не совсем. То есть эти действия у нас вроде бы есть. В то же время у нас есть память действий. В то же время у нас есть перед собой какая-то цель, какая-то подцель. Но это максимум от дерева, который у нас есть и хранится в текущей памяти. Все остальное у нас где-то там на задворках мозга. 

S05 [00:33:23]  : Я понял. Просто я тебя подводил к одной простому вопросу. Где мы возьмем датасет для таких действий? Где мы наберем данные для обучения? 

S07 [00:33:35]  : Вот как раз с этим и есть проблема. Есть в принципе датасет и задач, и решение этих задач. датасеты для математических задач. также для задач программирования есть датасеты, которые сводятся к тому, что есть вход и есть выход. в таком виде у нас много задач есть. 

S05 [00:34:03]  : но они все узкодоменные и не позволяют нам перейти на общие задачи. давай следующий вопрос, у нас уже по времени. Вот ты говорил про восьмиклассников, которые сдают экзамены, точнее системы, которые сдают экзамены для восьмого класса. Но это скорее не вопрос, а просто возражение. Ты же понимаешь, как они внутри устроены. Там очень инженерно все адаптировано под именно эту задачу. Набор нейросетей, которые просто Заранее в определенном формате принимают данные вопросов, заранее в определенном формате, соответственно, выводят. Но если попробовать в такой системе дать какой-то открытый вопрос в заранее не согласованном формате, то ты же понимаешь, что все поломается. Поэтому сказать, что у нас есть интеллект на уровне восьмиклассника, это слишком самодеянно. 

S07 [00:35:03]  : этим я согласен. если у нас лингвистический интеллект, который в чем-то, вербальный интеллект, который в чем-то похож на мозг восьмиклассников, здесь ответ скорее да, чем нет. потому что, ну опять же, то есть проблема, то есть проблема AI с AGI, вот здесь буду рисовать, хотя могу и на доске перехода. это перехода, скорее, проблема обобщения доменов. если мы это признаем, то что мы умеем делать AI, если бы мы научились делать 100 тысяч разных AI для разных доменов и их объединить в единую систему, то по большей части проблема AI была бы решена. если мы этот тезис принимаем как основу для действий, ну понятно с оговорками, потому что это упрощение огромное, то у нас возникает вопрос, а как мы можем обобщать вот эти, то есть мы не хотим 100 тысяч создавать разных зон, как мы можем обобщать домен, в котором действует система. я проделывал такое обобщение на звуковой, на звуках, на распознавании речи. Также с результатами экспериментов в других предметных областях общался, общался знакомый в смысле. И вывод везде примерно один. То, что система, если система размера X решает задачу для какой-то модальности, для какого-то узкого домена, для какой-то подмодальности. то есть система размеров примерно x на 100, x на 1000 решает задачу для more general domain. для звука на самом деле здесь коэффициент был ближе даже к десятке. то есть если у нас есть 10 разных доменов и они более-менее очерчивают всю область, все пространство типичных задач, то мы строим сетку, которая общая, и она начинает работать на новых поддоменах. начинает работать достаточно хорошо то же самое наблюдается в области зрения и это показала работа работа клип работа клипа то что с ней связано там еще была сеть далее первая но в основном основном клип это показал что то, что клип... нет, там была еще одна другая сеть, я забыл название. вот до этого мы учимся, например, на имачнете или на сифаре или вообще на амнисте. я возьму вот три дата сета. вот если мы посмотрим качество разных сетей этих трех доменах давайте создадим табличку подскажет вам покажу очень интересную интересную штуку так insert table вот примерно такой 

S05 [00:39:10]  : Юр, ты точно будешь табличку заполнять? Мне кажется, мы вышли за формат. 

S07 [00:39:19]  : Одну минуту я покажу. Если мы возьмем сетку простенькую, то сетка простенькая, учится на МНИСТе, она показывает условные 99% на МНИСТе, но показывает 0% на ImageNet и на открытом домене она показывает 0%. берем сетку побольше, учим ее на ImageNet, доучивая на МНИСТе. она показывает нам результаты на иммачнете 70-80 процентов, а на мнисте показывает результат при этом 10 процентов. на опендомене показывает результат 20 процентов. понятно, что если мы ее немножко доучим, мы в режиме future touch. дальше мы процесс этот продолжаем, учим уже на опендомене. каком-то сетку, причем учим одновременно текстовое представление, вот как у клипа, и общее представление. И вот даже мы не учили ее конкретно классовым интернетом, не учили классовым листом, учили на OpenDomain, научили ее там где-то там до 70% условных. так вот, она начинает у нас показывать на имачнете результаты под те же 70% и на месте начинает показывать результаты под те же 80-90%. то есть если мы экстраполируем, то мы получаем то, что достаточно большого размера сетка, она берет все предметная область со временем и научается решать произвольные задачи. 

S05 [00:41:15]  : мысль понятна, Юр. я понял. спасибо. у меня был еще вопрос по железу, но я думаю мы его перенесем на уже общую вопросную часть, потому что немножко мы уже задержались. так, давай я попробую сейчас расшарить экран не знаю что нужно сделать для этого антон ты может быть должен переключить там что-то я не знаю что должен сделать берешь и шаришь беру берешь и шаришь до действительно нужно было чтобы юра освободил так вот то есть как я обещал у меня Доклад будет немножко более общий, без захождения даже. Изначально я думал про supervised vs unsupervised подходы и как-то более раскрыть эту тему, но потом подумал, что там мы слишком сильно утонем в определениях, потому что нет прям четкого такого разделения между одним и другим. Решил еще более обобщенно рассмотреть всю эту тему и предложил вынести ML как полностью отдельный подход, который некоторыми признаками можно обобщить. Юра в самом начале сказал, ML – это все, на базе чего можно построить модели, и наоборот. Нам нужно строить модели, а ML – это полностью исчерпывающий набор технологий, который нам эти модели может построить. Как раз в противовес этому я хочу сказать, что есть Вещи, которые к ML точно не относятся, и тем не менее на базе этого можно строить и модели, и интеллект. Что это такое, сейчас мы посмотрим. Давайте сначала какую-то черту проведем между AGI и не AGI. Иначе у нас не будет базы для аргументации. Лично для меня маркером AGI – это возможность автоматизировать интеллектуальные профессии. Именно профессии. Например, оператор колл-центра, дизайнер, бухгалтер, менеджер, программист. Разница с ML именно в слове «профессия». Отдельные задачи внутри профессии уже автоматизировано или скоро будут автоматизированы. В том же самом колл-центре действительно очень большая нагрузка, уже процентов 70, наверное, у нас в мире делается автоматизировано с помощью большого количества ML-техник. Но для полноценной замены работника, чтобы взять и убрать из колл-центра людей, нужен все-таки полноценный AGI. Почему так? Что не позволяет автоматизировать целую профессию? Прежде всего, круг задач в рамках профессии не определен заранее. Задач много, они маленькие, но все разные и, скажем так, связаны между собой цепочками и причинно-следственными связями. Поэтому, в целом, такому интеллекту нужна некая автономность. На каждую задачу нельзя привлечь дата-сиентиста, который быстренько найдет ассет, настроит модельку и добавит эту фичу в общий пайплайн. В то время как ML-подход, он справляется с заранее определенными задачами, а не с теми задачами, которые у нас на этапе постановки неизвестны. Второй момент – это человеческий язык. Невозможно представить работника сколько-нибудь интеллектуальной профессии, который не владеет языком. Здесь язык – это не только коммуникация, но и основа для мышления. Чем вообще можно заменить имейн? органический подход. Давайте разберемся, чем отличается органика от машинного обучения. Прежде всего поговорим об обучающем сигнале. Обучающий сигнал – это то, что заставляет нашу систему обучаться, то есть менять параметры и адаптироваться под ситуацию. В случае с email – это всегда ошибка. У нас обязательно должна быть ошибка, которая в случае с датасетом – это разница между эталоном и некой предсказанной сущностью. В случае с RL – это какая-то награда, которая задается человеком. У живых систем, Обучающим сигнал поступает, как правило, дофамин и кортизол. Про это мы немножко позже поговорим. Таким образом, здесь условно можно провести черту, что здесь с учителем, что без учителя обучается, но, как я говорил вначале, тут не имеет смысла именно таким образом определять, что с учителем и что без. Почему это плохо? Я имею в виду, почему плохо, что нам нужна обязательно ошибка или награда. Это плохо потому, что мы оказываемся в ловушке датасетов. Это как раз то, что сейчас Юра говорил. У нас нет датасета от этого, нет датасета от этого. Действительно, от более-менее серьезных вещей датасетов нет и быть не может. И все задачи, которые решаются ML, так или иначе требуют датасета или корпуса. Корпус мы тоже будем считать датасетом. Просто там метки проставляет не разметчик, а они, скажем так, естественным путем там образуются. А в случае SRL мы тоже в ловушке, только это ловушка награды. Нам нужна обязательно награда. Но для многих вещей датасетов просто нет и быть не может. Например, нельзя обучиться языку. Именно в общем смысле этого слова, то, как люди пользуются языком, такого датасета нет и быть не может, потому что для обучения языку нужен датасет. Датасетом может выступать только сама жизнь. Жизнь вместе с окружающим миром, и живыми людьми в нем. Это просто обязательно, потому что иначе, опять же, не будет этого настоящего владения языком. Можно также пройтись по профессиям конкретно, где датасетов тоже быть не может, но в целом любую профессию берем, бухгалтер, дизайнер и так далее. Ну, в общем, как я говорил, язык – это такой универсальный прокси для любой интеллектуальной профессии, поэтому, не овладев языком, мы, в принципе, дальше двигаться не можем. Что предлагает вместо этого органический подход? Он предлагает такую штуку, я ее называю inductive bias. Перевод на русский язык ничего не добавляет к этим словам, поэтому просто так и буду говорить. Вкратце, это некое предустановленное ПО у нас в голове для того, чтобы организм адаптировался в этом нашем мире. Именно в нашем мире, не просто там где-то, не для универсального какого-то мира, для игры в Супер Марио, скажем, а именно мира, в котором мы живем. То есть никакого универсального интеллекта пока не существует, не создано. Именно живых интеллектов, про искусственную я вообще молчу. Все интеллекты очень адаптированы под конкретные условия обитания. Почему имеет смысл идти именно этим путем? Ведь, казалось бы, мы теряем универсальность. Если мы адаптируемся с конкретными предустановленными Inductive Bias, мы заведомо жертвуем универсальности. Но что мы получаем? Мы получаем выход из ловушки датасетов. То есть нам датасеты уже, получается, будут не нужны. И мы сможем взамен этого обучать наши искусственные интеллекты просто в обычных средах. В обычных средах довольно тяжело, а вот в искусственных, виртуальных – очень даже пожалуйста. Давайте тогда более конкретно, что такое вообще inductive biases, которыми мы обладаем для обучения. Это очень короткий список. Я думаю, что у человека их реально сотни. Давайте вкратце пройдемся для ликбеза. Во-первых, у нас очень интересно устроено зрение. Что позволяет нам учиться распознавать объекты без датасетов? У нас заранее встроена гипотеза о том, что мир состоит из объектов. Эти объекты имеют довольно постоянные границы. Это очень важно. И система зрения определяет сначала контуры объектов, и делает она это исходя из предпосылки того, что объект движется. Даже если на самом деле объект стационарный, наша саккадическая система устроена таким образом, что она делает этот объект, на который мы фокусируемся, как бы немножко колеблющимся. За счёт этого мы можем выявлять контуры и таким образом очерчивать угловое пространство нашего зрения для того, чтобы этот объект дальше сканировать более детально. Также у нас, например, встроена арифметика. Благодаря саккадическому зрению взгляд перемещается между объектами и есть специальный датчик, который считает количество перемещений. не просто считает, но и может сравнивать количество разных объектов, допустим, есть пучка 1, пучка 2, или какие-то протяженные величины он также может сравнивать. Соответственно, есть система датчиков, которая позволяет непосредственно без всякого сознательного подсчета сразу сказать, загорается лампочка, В левой кучке больше объектов, чем вправо. Это работает, конечно, не для любого количества. По-моему, до пяти мы можем надежно определить, что больше, что меньше. И самое интересное – это механизмы всяческого подкрепления. То есть тот самый BIAS, который позволяет нам учиться. Позволяет учиться в условиях, когда нет внешней награды. Например, один из самых распространенных источников положительного укрепления – это всякая новая информация, то есть новизна. И человек, по сути дела, обучается получать больше новизны. И это позволяет ему, в принципе, обучаться двигать самого себя и совершенствовать свои навыки так, чтобы получать больше новизны и познавать мир таким образом. Отрицательное подкрепление идёт от страхов в основном и позволяет регулировать поведенческие программы так, чтобы один положительный сигнал никогда не приведёт к настоящему обучению и подстройке. Прочие базовые потребности являются системой сдержек и противовесов для того, наши программы подстраивались под нужное нам поведение, под нужный рефлекс. Но вопрос, собственно, в чем? В том, насколько искусственному интеллекту нужны именно человеческие наши байесы. Мне кажется, нужны, но в какой степени – это, конечно, вопрос. Возьмем, например, страх. У человека очень много страхов. который на самом деле, там есть такая система звездообразная, в центре страх смерти, от него уже расходится много разных страхов, страх одиночества, страх пауков, грызунов или еще чего-то. Настолько детально делать это, скорее всего, не имеет смысла, то есть искусственному интеллекту точно не стоит бояться пауков, В принципе, иметь понятие страха и механизм реагирования на него, именно как обучающий сигнал, я думаю, нужно просто обязательно иметь, потому что это позволяет, скажем так, бояться потери собственных механизмов. Ты можешь сделать чего-то, после чего ты перестанешь работать. Вот этого нужно бояться и всячески избегать. Это как раз вопрос о том, Искусственный интеллект должен быть обномен в целом. В общем, заключение моего доклада. Такой простой вывод. Нам не нужен универсальный интеллект. Давайте сделаем просто человекоподобный интеллект. А потом, когда мы его сделаем, он будет равен человеческому, мы уже будем его потихоньку апгрейдить, чтобы он мог решать всякие сверхчеловеческие вещи. Ну, за счет того, что там памяти, будем неограниченно делать, еще какие-то будем хаки использовать и так далее. В общем, у меня все. Собственный доклад я закончил. Так, устанавливаем демонстрацию, смотрим вопросы. Вопросов, кажется, не появилось. Или появились? Участники, можете спросить вслух, что-то интересно спросить, или если нет, то переходим к Антону. 

S04 [00:56:11]  : Вопросов-то в чате очень много. 

S02 [00:56:12]  : Там есть вопросы. Прямо смотри, Сергей, вопрос вот есть, я вижу в конце. 

S04 [00:56:19]  : не только концертам походу много вопросов там ну либо мы совсем уж в конце их Сергей давай давайте попробую так индуктив баяс должен ли быть настолько обширного чтобы агент не подогреть меня сначала вопрос там был логически к этому самому предыдущему докладу да в самом начале самый первый давай давайте тогда к юре вопросы вынесем на общее обсуждение а давай тогда идем тогда давай тогда действительно все на общее обсуждение потому что ну так чтобы не разрывать давай давай все тогда тогда антон тебе слово 

S02 [00:56:47]  : хорошо спасибо у меня слайдов нету я вот сейчас вот просто по вопросам пойду начну действительно как обычно для того чтобы говорить как соотносится машинное обучение и GI надо определиться да что такое машинное обучение что такое GI И то определение, которое прозвучало у Юры сегодня, что любая деятельность – это машинное обучение. В этом смысле можно расходиться, потому что если любая деятельность – это машинное обучение, а любой интеллигенс – это general, то тогда они вообще тождественны. И чего обсуждать? Это с одной стороны. С другой стороны, если попытаться разобрать разные гипотезы того, что такое машинное обучение и что такое AGI, то в моем понимании машинное обучение – это инструмент, а AGI – это цель. То есть мы с помощью машинного обучения в том или ином виде достигаем AGI. Вопрос заключается только в том, нужно ли что-то еще кроме машинного обучения для достижения AGI или одного машинного обучения достаточно. Но для того, чтобы про это говорить, нужно все-таки определиться, что мы подразумеваем под машинным обучением. Значит, если под машинным обучением подразумевать любую деятельность, то вопрос снят. С другой стороны, если под машинным обучением подразумевать некоторый набор технологий вычислительных, включая линейную регрессию, линейную алгебру и функцию взаимной корреляции Пирсона, то, наверное, без этих методов AGI не построишь. Вопрос в том, что где-то нужна функция корреляции, где-то нужна линейная регрессия, а где-то нужны трансформеры. Более интересен вопрос, что такое AGI. За последние годы, которые идет уже этот семинар, можно выделить несколько определений того, что такое AGI. Первое определение AGI – это возможности человека. Либо это возможности сверхчеловека. На самом деле разница между ними не очень большая, потому что если мы создадим некоторую архитектуру, когнитивную архитектуру, так называемую, или конструкцию, или комбинацию нейросетей, как бы это ни называть, которые достигают человеческих, которые способны выполнять функции на уровне человека, то добавлением либо модальностей каких-нибудь дополнительных, либо добавлением памяти, либо добавлением быстродействия мы автоматически получаем сверхчеловеческий AGI. То есть человек, который делает все то же самое, как человек, но быстрее хотя бы в 2 или в 10 или 100 раз, это уже сверхчеловеческие возможности или память имеет больше. Поэтому, если мы просто говорим о создании некоторого устройства, которое имеет возможности сопоставимые с человеком или превышающие его, то в зависимости от того, какую архитектуру мы будем строить, очевидно, что какие-то вычислительные методы нам понадобятся. Это с одной стороны. С другой стороны, теперь рассмотрим, а надо это или нет. Если мы хотим, чтобы AGI позволял как человеку самому всему научаться и самому себе ставить цели, и самому чего-то хотеть или не хотеть, или как-то еще взаимодействовать с другими людьми, и при этом еще иметь возможность просто добавлением памяти или быстродействия получать сверхчеловеческие возможности, то при существующем уровне развитие человеческой цивилизации, очевидно, это просто вредно. То есть, мы тут с людьми, как выясняется, не можем обеспечить безопасное существование. А если еще тут EGI и сверх EGI начнут свои амбиции удовлетворять, ну, будет вообще кисло. Поэтому с практической точки зрения мне ближе другой подход к AGI. Опять-таки, что такое AGI, каждый понимает как хочет, но вот разные гипотезы. Еще одна гипотеза AGI, это гипотеза, которая тоже озвучивается по-разному. У Евгения Витяева и Дмитрия Ивановича Свериденко это формулируется как задачный подход. Немножко другими словами, с моей точки зрения, это формулировал недавно Борис Новиков. То есть, идея заключается в том, что по DGI мы можем подразумевать не нечто, что может как человек учиться, расти и функционировать на человеческом уровне. Нет. Мы хотим просто сделать некоторые устройства, которая будет настолько универсальна, что способна быть предзагружена любой преднастроенной средой. То, что Дима называет как раз Inductive Biases. То есть, если мы можем в некоторую железяку, которую мы сконструируем, загрузить некоторый набор Inductive Biases, то, что Дима называет Inductive Biases. Я перед семинаром посмотрел, что такое Inductive Biases и увидел, что это немножко не то, про что Дима говорил. Я сейчас в терминах Димы говорю. То есть некоторые преднастройки, которые позволяют на уровне железа, скажем так, или на уровне биоса эффективно выполнять какие-то функции и обучаться дальше более высоким функциям, более высокого уровня. Так вот, если мы сможем преднастраивать одну и ту же железяку работе, допустим, там либо под водой, либо там в бухгалтерии, либо там при управлении самолета, и, так сказать, железо это будет достаточно дешевым, чтобы его штамповать над производской линией, и преднастройки будут недостаточно дорогие, и обучение будет недостаточно долгое, то, наверное, мы решим большое число экономических вопросов. Вот, повысим эффективность экономики, производительность труда и безопасность граждан. И это, наверное, полезная история, потому что в конце концов мы изобрели персональный компьютер, куда можно загрузить любую программу, и написав эту любую программу любым программистам, можно автоматизировать любой вид деятельности. Проблема в том, что эти программы недостаточно интеллектуальные. То, что мы хотим с точки зрения второго определения AGI получить от AGI, это некоторую вычислительную архитектуру, которая позволит программировать или конфигурировать возможность обучения самопрограммированию каких-то узких специфических задач. И опять-таки, с точки зрения Социальной функции нам вообще не нужен искусственный человек, он нам просто не нужен в ближайшей перспективе, потому что у обычных людей есть проблемы безработицы. Хотя, опять-таки, как я где-то в какой-то момент говорил, и как говорят тоже многие люди, включая Шмидт Хубера, что, конечно, в долгосрочной перспективе, наверное, настоящий сверхчеловеческий AGI – это вещь полезная, потому что солнце погаснет. И кто-то должен будет интеллектуальный код человеческой цивилизации внести в другие галактики. И в условиях открытого космоса только искусственный интеллект и искусственная жизнь или искусственный разум, искусственная разумная форма материи, нечеловеческие, способны это будут сделать, в моем понимании. И, естественно, для создания таких технологий очевидны математические методы. включая то, что можно называть методами машинного обучения, будут полезны. Наконец, еще одно интересное определение AGI, чтобы картинка была полная, это вот та история, про которую я недавно упоминал. Как раз вчера в Singularity.net был закрытый семинар. В данном случае этот человек был геолог Майкл Расселс. Он рассказывал историю про то, что вообще нет разницы между живым и неживым, потому что из физики плавно возникает химия. Из химии плавно возникает неорганическая химия, из неорганической химии плавно возникает жизнь, из жизни плавно возникает интеллект, и все это находится под соусом. В рамках того, что товарищ Фристон называет свободной энергией, просто имеет некоторая форма развития сложности материи, которая с какого-то момента может начинаться называться в каком-то смысле разумной и постепенно она становится все более и более разумной. Если мы хотим делать вот такой GI, хотя на самом деле зачем бы это было нужно не очень понятно, то есть зачем нам создавать искусственную эволюцию, для того, чтобы смоделировать AGI в такой вот AGI, когда он у нас уже есть. Если мы хотим денег заработать или практическую проблему решить, лучше отталкиваться от того, что уже есть, и строить конструкцию на этом уровне. Но, однако, если мы хотим чисто теоретически решить проблему такого саморазвивающегося AGI из почти ничего человеческого или сверхчеловеческого или там почти человеческого уровня, то наверное здесь самой полезной технологией будет как раз технология вот близкая к тому, ближе всего к которой как раз доклад, который у нас недавно делал Андрей Климов, Это история про вероятностное программирование. Это история про то, что мы пытаемся строить систему на основе некоторой системы программирования, которая в том числе может программировать сама себя и оптимизировать сама себя. И все эти программы являются вероятностными. некоторыми операторами этих вероятностных программ, в том числе могут быть некоторые векторные и то тензивные операции, вычисления корреляций, регрессий. Соответственно, без математических методов, статистики и машинного обучения здесь тоже никуда не денешься. Это как бы по поводу главного вопроса. Теперь пройдусь по деталям, по вопросам, которые Дима задавал. Первый – супервайзер vs супервайзер. Определение, применимость к AGI. Очевидно, что если мы говорим AGI, то все формы обучения ему должны быть доступны. Даже если мы строим некоторую систему на основе Hardware Advice, применимую для какого-то конкретного круга задач, все равно в рамках этого конкретного круга задач в рамках этой узкой предметной онтологии, она все равно должна иметь возможность чему-то дообучаться. Как она может этому дообучаться? Тут можно выделить четыре основных способа обучения, хотя они на самом деле между собой в реальности пересекаются. Первый способ обучения – это привыкание. Что такое по обучению привыкание? Иногда, когда езжу на машине, мне лень пристегиваться, и я просто еду не пристегнувшись. Машина орёт. Причём через минуту я перестаю обращать на то, что она орёт, и она орёт, а я еду просто не обращая внимания. А если человек непривычный со мной в этой ситуации садится, он очень удивляется. Но я просто привык, я знаю, я уже привык к тому, что через минуту после этого пикания я привыкаю. Человек имеет возможность адаптироваться к стимулам, которые не подкрепляются необходимостью что-то с этими стимулами делать, и он перестает на них обращать внимание. Другая форма обучения – это обучение подорожания, то есть если мы видим, что особь в нашем сообществе что-то делает как-то и получает от этого какую-то выгоду, или даже не получает выгоду, а у нас просто как раз есть hardwired bias, что мы должны подорожать поведением своих подобных, то есть это получается некоторый мета-байас, который предполагает некоторые методы обучения и некоторые обученческие дефлексы, встроенные, как, например, обучение подражания. Третья форма обучения – это обучение на основе подкрепления из окружающей среды. Причем обучение на основе подкрепления из окружающей среды – это то, что называется в искусственном интеллекте, это определение широко использовалось в тусовке Герцеля двадцать лишних лет назад. Это называлось по-английски experiential learning или обучение на основе опыта. Сейчас оно в компьютер-сайенс не используется, хотя оно по-прежнему используется в педагогике и психологии. А вот тот термин, который используется в машинном обучении, классическом reinforcement learning, это, на самом деле, в моем понимании, немножко уже, потому что reinforcement learning предполагает reinforcement, а reinforcement может не быть. На самом деле реинфорсмент может генериться разными способами в жизни. Я могу реинфорсироваться новизной в каких-то случаях, в каких-то случаях я могу реинформироваться тем, что я достиг такого состояния, которого я ожидал достичь. Наоборот, отсутствие новизны подкрепляется, потому что Я хотел получить что-то ожидаемое, я его получил, и я получаю подкрепление за свою поведенческую схему, что она правильная, потому что я получил достигаемого результата, а в явном виде подкрепления не было. Это как раз история про то, как работает теория функциональных систем. Дофамин получается при удовлетворении результата действия ожиданием акцептора результата действия. И последняя, четвертая форма обучения – это обучение методом transfer learning, когда мы воспринимаем информацию не на основе собственного опыта, не на основе методов проб и обшивок в процессе experiential learning, А когда нам просто дают эту информацию, не методом телепатии, а методом дидактическим. Нам дают прочитать книжку, нам дают прочитать инструкцию, нам показывают блок-диаграмму того, как себя вести. И что интересно, что как раз в случае систем искусственного AGI или GI или AI. Есть очень интересная возможность, что как раз вот та телепатия, которая у людей то ли есть, то ли нет. Большинство считают, что ее нет. Вот искусственную телепатию мы создать как раз можем легко. То есть, мы легко можем от одной системы искусственного интеллекта передавать мысли по воздуху, по проводам или по Wi-Fi. Таким образом, обучение новым паттернам поведения в сообществе искусственных интеллектов может быть очень эффективным. Это к вопросу о том, какие есть формы обучения. Естественно, они все должны коррелировать, взаимодействовать между собой, потому что на самом деле для того, если мы получили какую-то новую схему либо подражанием, либо методом трансфер-ленинга, мы все равно ее адаптируем к своим условиям, конкретной среде, в которой мы работаем через experiential learning и наоборот. Получив некоторый притренинг на основе experiential learning, мы получаем некоторые байсы, не hardwired байсы, но выученные байсы, которые позволяют нам воспринимать какую-то дидактическую информацию. Именно поэтому в педагогике нет такого, что у нас только теория или только практика. взаимодействуя с практикой и где некоторая теория она хорошо ложится на практику, а некоторая практика хорошо ложится на теорию. Насколько универсален должен быть AGI по принципам обучения? В общем случае он должен быть универсален, хотя для различных прикладных задач, то есть если мы следуем концепции AGI, когда AGI это просто вот некоторая вышлительная архитектура, которая не программируется, а преконфигуируется для последующего постобучения, То в этом смысле, может быть, как раз каких-то способов обучения не нужно, допустим, обучение новизне, обучение новизне, к примеру, и обучение привыканию, их можно захардкодить. К примеру, обучение подражанию. Подражание может быть вообще не нужно. Если мы делаем робота для того, чтобы он там копал или сверлил или добывал что-нибудь на астероидах, у кого ему там учиться? Ему там самообучение нужно и электронная телепатия. Последний вопрос. ML-сетап, датасет и численная метрика. Насколько это отходит для AGI? Ну, оптимизация нужна, численные метрики нужны. Естественно, все это нужно. Вот. Ну, а на остальные вопросы я, наверное, ответил. Все. 

S05 [01:14:48]  : Спасибо. Спасибо, Антон. Так, ну, конкретно сейчас по тебе вопросов вроде. не образовалось, тогда давай уже в общую секцию переходить. И у нас первый Сергей Александрович хотел сказать или прокомментировать или спросить, пожалуйста. 

S04 [01:15:12]  : Спасибо большое. Во-первых, спасибо огромное докладчикам всем, что вы, так сказать, очень комплексно со всех сторон к этому подошли. Всех трём я, на самом деле, в этом случае не веду. Вот вопрос, который я задал сначала Юрию, но написал его, так сказать, о его факте существования этого вопроса. Потом выяснилось, что этот вопрос уже преломляется в свете доклада Дмитрия, и на самом деле он же ещё и возникает потом в комментариях и в общении Антона. поэтому я вот его немножко вот так вот в общем виде и задам. Насчет фактически что получается. Если послушать Дмитрия, то он фактически говорит следующее, что коллеги, давайте прежде всего сосредоточимся на вот этом самом правильно априорном неком таком задании каких-то свойств. но вот в узком смысле inductive bias, если то, что говорит Антон о машинном обучении, это конкретно какие-то архитектурные вещи, а в более широком смысле, в том, о котором говорит Дмитрий, это то, что мы должны фактически привнести априорно некоторые определенные свойства в этой системе. Ну а вот там любители, например, байсового подхода, они мыслят это как некое создание прайера и так далее. он всегда есть. и несмотря на то, что, например, когда Юрий говорит о том, что мы приступаем к обучению, но все равно у нас inductive bias всегда есть. например, у нас есть понятие, вот он пример для обучения. вот мы начали его читать, потом мы закончили его читать, после этого поступает сигнал, что вот то ты должна по определению сеть знать, что такое пример. Вот я тебе сейчас дал этот пример, и вот ты теперь его обрабатываешь. Это классический inductive bias, ты его встроил, обязательно встраиваешься. И таких вещей очень много, можно много чего предполагать. Так вот, тут всегда возникает вопрос, соотношение между вот этим априорным, inductive, так сказать, биасом, или prior, или исходным каким-то innate knowledge, предсуществующим знанием, и адаптацией того, что после того, как мы это создали, уже, так сказать, путем, условно говоря, обучения. Если ответ лежит так, что вот 99 процентов, как вот Дмитрий говорит, вообще там вообще 100 процентов, можно адаптация там даже и не возиться, если грамотно задать все interactive biases, то мы уже получаем систему, которая там жизнеспособна. Тогда получается, что вот это обучение, оно как бы вторично немножко подтюнит, немножко подстроит, но вообще-то основную задачу мы уже решили. Мы создали систему, которая способна работать, способна ее воспринимать, способна выдавать ответы и так далее. И тогда получается, что все сводится к синтезу этой исходной архитектуры. И тогда сразу я задам второй вопрос. Теперь уже преломлю его. В конце у меня он был задан, но я теперь Дмитриева преломлю. Дмитрий, а тогда вопрос к вам соответствующий. А как программировать эти IntactDevice? Нам же нужно какой-то инструмент, какой-то язык или какой-то способ, какие-то средства, какие-то отвертки. которыми мы будем эти байосы, условно говоря, вносить в систему, то есть мы будем их туда вкладывать. Если это классический искусственный интеллект на уровне правил алиграфов или на уровне известных математических конструкций, нечётких, аксиоматических построений, то тогда понятно, то есть мы должны запрограммировать фактически огромный объем этого interactive bias, и после этого мы получим систему, которая уже способна выжить, чтобы начать адаптацию по Юрию. Вот это вопрос, как тогда начать программировать. Отчасти Юрий, я вот забегаю вперед, немножко так вот скажу, отчасти Юрий немножко о нем как бы сказал, но он не ответил на этот вопрос, потому что вопроса еще не было, но он уже об этом сказал, что если у нас есть тысяча разных скиллов, условно говоря, тысяча отдельных решенных задач, хорошо, да? то тогда inductive bias может состоять в том, что какой набор из этих скиллов мне сейчас собрать себе в корзинку, чтобы вот полученный объект из этих 36 уже отобранных мы руками человеком или кем-то, кто задает этот inductive bias, вот этими скиллами, он тогда способен решать какую-то вот эту задачу. А для другой задачи я из этих же тысячи, но наберу уже новый набор из 12 или из 14, он будет тогда решать другую задачу. То есть это как бы способ программирования. Коллеги, если это не трудно, прокомментируйте, пожалуйста, потому что этот вопрос очень принципиальный. Если все дело в innate knowledge, в признании, вот в этом inductive bias, то есть в изначальном том, что мы должны внести систему, чтобы она просто начала жить, то тогда это вот одна сторона. ежели максимально профьюри, он говорит так, что inductive bias минимальный, но фактически мы там берем практически 5-7-10 разных сетей, а все остальное получается обучением, то тогда это вот другой взгляд. спасибо большое. 

S02 [01:20:08]  : я отвечу сразу. 

S05 [01:20:10]  : ну ё-моё, я хотел ответить. 

S04 [01:20:14]  : Юрий грамотно даже микрофон не включил, это правильно. 

S05 [01:20:17]  : вопрос больше ко мне, потому что действительно я с этими индуктив байосами больше всего про них рассказывал. тут, что называется, размер имеет значение. как раз 99 к 1, золотое сечение, про которое вы говорили. Это как раз вопрос универсальности, легкость старта vs адаптируемость к новым условиям. Понятно, что мы не можем полностью его обвешать байосами так, чтобы он как теленок, которого только что родили, встал, сразу пошел щипать травку. У нас тогда получается система слишком будет жесткая. и будет не способна адаптироваться к новым условиям. Теленок не сможет плавать, научиться и так далее, хотя какие-то базовые вещи он имеет. Но все-таки без биосов изначально не обойтись от слова «никак», потому что оно нам не позволит выйти из этой привязанности к датасетам и позволит при этом начать получать первую адаптацию к среде, начать учиться миру, физике, начать учиться словам и так далее. Это всё невозможно без байесов. Но вот сам процесс, то, что мы уже, имея эти байесы, начинаем на себя нанизывать, это уже, собственно, гибкая модель мира, с помощью которой мы становимся универсальными. Поэтому здесь сказать 99 к 1 или 80 к 20 нереально, это не поддаётся количественному числению. но я думаю, что мало должно быть байсов и больше пространства. 

S04 [01:22:10]  : Дмитрий, если в одном предложении, грубо говоря, вот если вы на примере вот этого бухгалтера, который упоминали, Он должен уже быть бухгалтером, и это уже задано должно быть, а потом только станет хорошим бухгалтером, опытным бухгалтером. 

S05 [01:22:27]  : Бухгалтер – это 5% наших знаний. Берем средневзвешенного бухгалтера – это 5% его специфических знаний. Остальные 95% – это язык, здравый смысл, понимание социальных взаимодействий, понимание математики и так далее. Common Ground наш, с помощью которых бухгалтер может стать кем-то другим. 

S04 [01:22:48]  : Вот этот Common Ground нужно задать в Inductive Bias? Нет, в нем 5% Inductive Bias, все остальное, слова, языки – это все то, что мы можем без Inductive Bias, точнее на базе Inductive Bias мы уже получаем обучение. У вас оценка 5 против 95. 

S05 [01:23:13]  : Я услышал. Пусть так. 

S02 [01:23:16]  : Давай, Антон, ты. Два момента. Сергей, во-первых, то, сколько должно быть байса, а сколько не байса, это зависит от задачи. Например, мне не нужен бухгалтер, который будет во время работы сидеть в Инстаграме. Поэтому мне вот эти 95 совершенно не нужны. Мне здесь близок подход Бориса Новикова, что давайте, если нам нужно делать искусственного бухгалтера, давайте мы сделаем искусственного бухгалтера, у которого не будет мотивации ходить в Инстаграм. Ничего человеческого в нем не нужно. А если ему потребуется что-то человеческое, он поднимет руку и скажет, вот надо эту транзакцию делать или нет, и я ему скажу. Это вот один вопрос. Но, может быть, есть какие-то задачи, где если нам нужен не бухгалтер, а художник, то тогда, конечно, байосов поменьше, но лучше я художником сам поработаю. Или, так сказать, жена моя, если у нее способности больше. А по поводу того, на каком языке писать, опять-таки, 

S04 [01:24:22]  : Это абстрактно имеется ввиду. Не в смысле кодировать, а в смысле на чем формулировать его. 

S02 [01:24:27]  : Смотрите, в том мире, в котором я живу, их даже не обязательно формулировать. Нам не обязательно разрабатывать язык для программирования биосов, если мы можем какие-то предопределенные поведения, предопределенные чувства, предопределенные наклонности или предопределенные, скажем так, реинфорцменты написать на ассемблере, на C++, на Java, на Python. Есть понятие, которое в OpenCog называется Grounded Schemanode. Что такое? Как устроен OpenCog? Это некоторое, что состоит из разных концептов, которые соответствуют когам, грубо говоря. анохинским или нейронным кластером или колонком в концепции Пивоварова-Шумского, которые могут получить активацию в результате каких-то связей между ними. Но они могут получить активацию, активироваться в результате каких-то собственных вычислений. Они что-то распознали, вот они активировались. Какая-то Grounded Schema Note распознала повышение цены и она реагирует, что нужно покупать или наоборот продавать. Или она распознала, что у меня акцептор действия не сработал и соответственно я должен получить отрицательную связь. А если она распознала, что акцептор действия сработал, то я должен получить положительную связь. связи, тогда в зависимости от отрицательной положительной связи я перестраиваю либо свои байосовские пробабилити, либо распространяю ошибку в зависимости от того, какая у меня вероятно символьная архитектура или нейросетевая. Но само вычисление этой фитнес-функции или какого-то сигнала или активации какого-то нейрона в каком-то слое Это может программироваться. То есть, мы можем создавать по сути искусственные, не только искусственные акторы, но и искусственные сенсоры, которые будут для верхних уровней вычислительные какие-то функции, осязательные какие-то функции выполнять. И они могут быть на любом языке программирования. Естественно, можно придумать новый язык программирования. 

S04 [01:26:46]  : Нет, Антон, я не про язык. Я не про форму представления. Я про принцип. Вот ты уже, например, в рассказе упомянул очень много сущностей, что есть сигнал, этот сигнал может меняться, некоторые изменения важны, некоторые не важны. Вот это все, это вот тот самый проект. Я хочу на самом деле вернуться, уточнить вопрос по поводу бухгалтера. Вот ты очень грамотно сказал, я хочу бухгалтера, который будет только бухгалтером, но он должен уметь поднимать руку, если ему что-то надо сделать. Вот это его умение или возможность поднимать руку, это ты должен ему запрограммировать или он должен это сам понять в процессе обучения с твоей точки зрения? 

S02 [01:27:33]  : критерии могут быть разными то есть в зависимости во первых я могу запрограммировать bias поднимать руку если порог уверенности ниже там 0 целых там 2 десятых да то есть если мы больше цены целых 2 десятых он сам проводки делает а если меньше то он задает мне вопрос а могу сказать задать другой проект что ты этот порог сам будешь определять по итогам твоего performance review, которое я буду сделать раз в квартал. То есть, если у меня, к примеру, в конце квартала убытки, опять-таки выше какого-то порога, то есть, если у меня убытки больше, чем 20 процентов, И это то я говорю, что вот тогда, значит, на следующий квартал порог, значит, давай поднимем с 0,2. 

S04 [01:28:21]  : Антон, я все равно немножко об этом другого спрашиваю. Сам факт того, что бухгалтер в принципе может способен быть поднять руку, вот этот факт, вот если в программу... 

S02 [01:28:31]  : Отвечаю. Смотри, у меня есть две руки. Наличие у меня двух рук – это тот баяс, который мне как человеку дан природой. 

S04 [01:28:42]  : Подожди, ты сюда дополняешь следующую вещь. Наша с тобой культурная общая позиция такова, что поднятая рука в нашем сообществе что-то означает. В другом сообществе она может означать что-то совсем другое. И вот тот факт, что поднятие руки в нашем культурном сообществе означает нечто, это можно либо этому обучиться методом подражания или наблюдения, либо должно быть это задано как факт. Поднимаешь руку, значит Другие тебя будут слушать, ты имеешь возможность высказаться, можно задавать вопросы и так далее. Вот я хочу как раз это именно понять, что вот эта вот возможность поднять руку вот этому искусственному богатому, ее надо по Дмитрию запихнуть в Interactive BIOS или по Юрию надо отдать на обучение на основе каких-то данных или примеров. или ситуации во внешнем мире. Вот как ты считаешь, где вот этот… Потому что я все жду, когда ты скажешь… Давайте я попробую обобщить. 

S02 [01:29:36]  : Сейчас я коротко отвечу Сергею, а потом… Сергей, короткий ответ в зависимости от поставленной задачи. 

S04 [01:29:42]  : Понятно. 

S07 [01:29:45]  : Давайте я попробую обобщить. То есть Hardware, вот эти вот наши Inductive Bias, это, как сказать, это… также как и обучение. это не привилегии, это необходимость некая. то есть нельзя к этому подходить с точки зрения «а как нам лучше сделать? вот так вот будет красивее работать или так?» мы подходим так, чтобы оно в принципе работало. мы можем это сделать любым образом. может это какие-нибудь Должна ли система при этом понимать, что внутри нее происходит какое-то действие или нет? Вообще говоря, нет. Вообще говоря, человек тоже много делает невербальных действий, не понимая то, что он их делает, и эту информацию считывают другие и пользуются. Это значит ли это, что должен человек полностью свое поведение понимать, чтобы лучше коммуницировать с другими людьми? Нет, не значит. Да он, в общем-то, и не может действовать. Он сознательно может контролировать. Опять же, вот эти пять своих проявлений каких-то, все остальные будут неконтролируемыми в данный момент. Даже и не получится. 

S04 [01:31:07]  : сколько его должно быть этого байса? мало или много? это очень важный момент. 

S07 [01:31:15]  : мы были бы счастливы этим байсом задать все, потому что получилась бы тогда очень легко перепрограммируемая, настраиваемая система, легко контролируемая. но, увы, эту привилегию нужно заслужить Должен быть программистский мозг размером с планету Земля, чтобы на языке программирования сделать таким образом существо размером с человека. 

S04 [01:31:46]  : смотри, вот я почему вопрос задаю, он мне очень важен, вот почему. потому что многие люди, которые сейчас говорят про гибридное обучение, тот же Джуди Пирл, который стартует с графа, без графа он вообще не начинает обсуждать ничего. а это огромное воздействие, это настолько сильное воздействие на систему, которая потом дальше будет работать. целый граф возможных направлений. то есть это вот мои 99 процентов. а вот если послушать тебя, то получается, что нужно минимум-минимум, а дальше вот только надо где-то нам набрать вот этого опыта. Не так. 

S07 [01:32:23]  : Все же не так. Все же мы были бы счастливы, и мы счастливы писать простенькие программы, которые работают, писать, как Антон говорит, условия 0.2, порог ставить, а в следующем портале 0.4. Мы бы счастливы, если бы это работало для достаточно сложных задач. Мы были бы счастливы сделать искусственную муравья, если бы он мог при этом. нам готовить еду и при этом, значит, это плесневые помидоры не добавлять в салат. Те же там помидоры, там куча с ними проблем может быть. То они плесневые, то они неровной формы, то они не того цвета даже бывают. то еще с ними что-нибудь не так, то они растекаются в руках, что их не разрежешь, то нож тупой. То есть как мы начинаем, вот даже робота пылесоса мы делаем, мы не можем программировать робота пылесоса просто на правилах, потому что иначе то он начинает, простите за мысль, собачьи какашки по полу размазывать, а то он наоборот не может. ему кажется, что там перепад высоты, хотя пол таким образом просто сделан такого цвета. 

S04 [01:33:48]  : это понятно, да. это классическая задача. она в древние времена называлась проблема ножа и масла. робот может отрезать очень точно от масла кусок, но когда он поднимает нож, кусок прилипает к этому ножу и после этого падает на пол. Вот это уже робот, нарезающий масло, с этим не справляется. 

S07 [01:34:09]  : Действительно у нас есть какие-то задачи, где коэффициент этой hardware biases может быть 99%. И многие из этих задач мы повторили методами. таким образом, что мы их научились решать, не задавая или почти не задавая hardwired bias. то есть процент этот свели от 99 процентов к 1 проценту и наоборот. Мы можем эту задачу, которая решается без hardwired biases, начать эвристическим методом, начать изучать, как же этот робот-муравей выполняет эту работу. Он делает вот это, значит, напишем для этого программный код для этого действия, для вот этого действия, для вот этих всех действий. Получим программу. Другое дело, что для более сложных случаев у нас нет возможности писать hardware и прочие программистские методы, и у нас остаются только методы машинного обучения. поэтому в более сложных задачах у нас соотношение hardwired biases к обучению, увы, в сторону машинного обучения, то есть 99% к машинному обучению, а у biases едва ли там один процент. но это вынужденная ситуация, хотя могло бы быть и в другом мире. 

S05 [01:35:39]  : так, дальше у нас хотел Игорь высказаться. Игорь, давай. 

S01 [01:35:48]  : коллеги всем добрый вечер вообще ужасно затянуты сегодня семинара прям безумно и все-таки надо как-то стараться аккуратнее быстрее свои мысли формулировать это пожелание всем в целом а у меня комментарий знаете какой я сперва дом что-то комментарий к вопросу дмитрия но вообще таковы комментарии такой им дмитрий к и к юре вообще ко всему нашему чату знаете такой у нас последнее время в чате регулярно разгораются битвы между людьми которые ну просто на разных уровнях как бы рассуждают есть такие генералы общие есть такие как бы солдаты с тыками И очень сложно друг друга понять, когда генерал говорит, ну как бы надо в принципе выбрать стратегию, как бы обходить с флангов, а солдат ему говорит, да ну я штыком, вот куда штыком-то тыкать, ты не понимаешь, мне вот как бы надо удобнее тыкать справа, а ты тыкаешь слева. И вот в этом плане иногда такие, знаете, дискуссии вот они напоминают вот это, и в чате это часто видно. А сегодня это вот в докладах вот как проявилось, я хотел этот момент просто особо отметить. И главный вопрос к Юре. Вот смотрите, Юра, когда вы говорите, что типа вот нейросети, грубо говоря, вы используете термин нейросети, мой снотезис вот к этому термину, что вы его используете, его неправильно вообще использовать. Я бы предложил вообще его запретить в нашем чате. Почему? Потому что вы говорите мозг там это комбинация разных нейросетей. Или что нейросетями, в принципе, можно решить все, но нам нужны данные, например. Или нужно понять, как там… И вот у меня, знаете, стало такое впечатление, что… Смотрите, я приведу три… Нейросеть, с одной стороны, мы понимаем, что мозг устроен как набор… То, что нам сегодня известно про мозг, это набор нейронов, соединенных с собой связями. И мы предполагаем, как они работают. Условно, это можно назвать нейросеть. Это не та нейросеть, которую, Юр, вы имеете в виду, но, как бы, в принципе, как бы это можно назвать нейронной сетью. Естественная нейронная сеть. Нейроны, соединенные друг с другом, там, на самом деле, все сильно сложнее, но наше базовое понимание такое, что нейроны друг с другом общаются. И поэтому есть, как бы, некоторый следующий уровень того, что принято называть нейросетью, а именно математические модели этих нейронов, как они друг с другом соединены, передают сигналы и на backpropagation работают. И это как бы другое понимание нейросети, в которое вкладывается уже математическое описание, способ их обучения и так далее. И, наконец, третий, у нас их больше, но я просто сейчас для… самый нижний уровень нейросети – это как бы некоторая конкретная модель, например, резнет или там какой-нибудь трансформер, конкретно заточенная на определенную задачу. И вот мой поинт к вам вот какой, Юр, я так вам хочу сказать, что мы как сообщество машинного обучения прекрасно мы понимаем, что такое нейросети, вот эти третьи, самые маленькие, узкие, конкретные, которые решают определенную задачу. Я с вами могу согласиться в использовании такого термина нейросетей. Вот нейросети решают определенную конкретную задачу, эти распознают картинки, те тексты распознают и так далее. Эти нейросети совершенно четко определены. У них есть LOS-функция, у них есть датасет, они определяются и они решают маленькую инструментальную задачу. И здесь у меня нет вопросов. Из таких сетей вы EJ не соберете никогда. Потому что они решают отдельные маленькие задачи. Надо иметь нечто, что их соединяет. Но теперь дальше, если мы посмотрим на мозг, то в мозгу есть структуры, которые вроде как тоже нейросети. но это совсем другие нейросети. Извините как бы вот здесь за тавтологию, потому что слово мы используем одно и то же. Какая-нибудь базальные ганглии, амигдала, гипоталамус, таламус – это тоже нейроны, соединенные связями. Но у нашего сегодняшнего сообщества глубоких нейронных сетей нет никакого понимания архитектуры этих сетей. Никакого понимания Loss функции. Вообще, мы вообще не понимаем ничего про это. Я уж молчу про датасеты, какие до меня должны быть, вообще никакие датасеты. Но вы когда в своем докладе вы говорите, мы все решаем, вот главное нейросети, вышей непосредственности не хватает. вы в каком-то смысле некорректно оперируя вот этим термином сами для себя эту картинку разрушаете и для всех остальных и разрушаете вот я и вот в этом смысле был правильный комментарий владимира смоль на который там Собственно, я написал, что сегодняшнее сообщество очень зациклено на этих сетях с backpropagation. Мой тезис в чем? Есть куски в мозгу, которые вроде как устроены как нейросети, но мы вообще не понимаем, как они работают. ни на каких данных я оперирую, ни какие у них задачи, ни какие у них лос-функции, ни какие у них цели, мы ничего про них не знаем. И обобщая их термином нейросети, это такая, знаете, мы подменяем неизвестно известным, и нам сразу вроде начинает казаться, что мы что-то понимаем. Мой пойнт в том, что мы ничего здесь не понимаем. И вы, пожалуйста, не заблуждайтесь. мы ничего не знаем пока про эту структуру у нас есть отдельные представления у отдельных людей отдельное представление как они устроены но мы как сообщество в целом ничего про них не знаем и поэтому говорить про то что можно из нейросетей а вы под этим поднимаю понимаете конкретно инструментальные штуки которые решаются backpropagation с loss-функциями на определенных датасетах, что мы из нейросетей соберем некий AGI, никогда не соберем, потому что там другие структуры должны работать, а не вот эти вот простые примитивные сети. Трансформер тоже в этом смысле примитивная сеть, потому что у него есть датасет на входе, понятным образом обучается и так далее. Это как бы часть моего комментария. Я еще хотел сказать все-таки для Дмитрия маленький коммент. что ты когда в своем докладе говоришь про ML ты на самом деле не имеешь ввиду ML ты имеешь ввиду конкретно глубокие нейросети некорректно, некорректно обобщать как бы нейросети до ML. RL это тоже в частности ML, так к слову, но как бы каждая глубокая сеть это ML, но не каждая ML это глубокая сеть. Каждая рыба селедка, не каждая селедка рыба. И в этом смысле некоторые тезисы, которые ты говорил по отношению к машинным обучению, были, на мой взгляд, некорректны. Они были корректны по отношению к глубоким нейросетям, да. но не к машину машина обучение сильно шире шире намного шире и как бы там есть есть чем поспорить я дальше задача прямо можешь маленький пример что что именно из экспертной системы экспертной системы старой доброй на прологе который я писал еще там назад это машинное обучение это что называется пример 

S05 [01:43:24]  : В приличном обществе джентльменов мы же вообще не упоминаем эти экспертные системы. Почему нет? Потому что это не обучающее. В контексте AGI. 

S01 [01:43:40]  : нет нет нет нет они прекрасно обучаются дима это ты вот тут это самое потом нужно использовать коллеги нужно стремиться использовать корректный термин раз уж у нас научные семена давайте мы понимать что машинное обучение вообще есть искусственный интеллект вообще некоторые широкая очень размытая область внутри него есть машинное обучение Внутри машинного обучения есть глубокие нейронные сети, но они точно не равны. И недостатки глубоких нейронных сетей с backpropagation, которые ты упоминал, и я с ними согласен, они не относятся ко всему ML. Просто это надо точно понимать. А иначе мы начинаем решать задачи, которые не существуют или проблемы ставим, которые отсутствуют. 

S05 [01:44:31]  : Я бы его спросил, потому что e-mail – это лернинг, а в экспертных системах лернинга вроде бы не подразумевается. 

S04 [01:44:38]  : Дима, зачем же ты так? Прекрасно были обучающиеся системе и фазе настраиваемой функции, и правила веса выбирались, адаптации. Согласен. 

S05 [01:44:47]  : Там адаптации было огромное количество. Пробелы в знаниях, согласен. 

S04 [01:44:51]  : Да не пробелы, там все ты это знаешь, это ты просто это самое. Стесняюсь. 

S07 [01:44:55]  : Давайте я реагирую все же на другую часть вопроса, на комментарии. И все же скажу, что на самом деле тут есть такой нюанс. Игорь, когда мы говорим про точность термина, и когда ты говоришь про то, что у мозга есть другие области, у которых есть какой-то lost function, Вообще говоря, это тоже большое заблуждение, потому что loss function… Я этого не говорил. 

S01 [01:45:29]  : Нет-нет-нет, я этого не говорил, Юр. Мне не надо. Я говорил, что есть области мозга, где тоже нейроны, они тоже соединены связями, но они работают, судя по всему, по другим принципам, не так, как вот эти нейронные сети, которые сейчас мы обучаем с loss-функциями и дата-сетами. А ты в своем докладе, как бы говоря про то, что мозг – это конструкция из нейросетей, неявно апеллируешь к тем нейросетям, которые… Вот, давайте я поделю процесс на две части. 

S07 [01:46:03]  : То есть, когда мы работаем с нейросетями, у нас, вообще говоря, есть два разных процесса. Два совершенно разных процесса. Первый процесс – это обучение, а второй процесс называется inference, будем говорить его вывод по-русски, хотя это немножко чуть-чуть другое. так вот, что я хочу сказать, что когда мы говорим про то, что в мозгу есть какие-то области, которые по-другому обучаются, обучение скорее всего мы тут вообще не говорим мы говорим про то что которые как-то по-другому делают какой-то вывод потому что обучение мозгу занимает но часы большинстве случаев до памяти Обучение по строению памяти тоже занимает долговременные от десятков минут до десятка часов, грубо говоря, но в идеале 3-4 часа. если мы говорим про то, что быстро происходит, быстро происходит какая-то маленькая только настройка на магниевых каналах. 

S01 [01:47:23]  : подожди, подожди, подожди, да ты не путай все в одну кучу. Юр, а кто тебе сказал, что базальные ганглии вообще обучаются? вот откуда ты это знаешь? 

S07 [01:47:33]  : вот, вот, если они не обучаются, то что это? это получается пункт два вывода, почему вообще говорю 

S01 [01:47:38]  : Причем здесь вывод? Да нет такого вывода. Ты оперируешь своими очень инструментальными терминами. Хорошо. 

S07 [01:47:50]  : Как мы мозгу назовем то действие, которое делают базальные гангстеры? 

S01 [01:47:54]  : Сначала надо понять, что это за действие и как его смоделировать. И можно ли его смоделировать в терминах обучения инференса. 

S07 [01:48:06]  : я в курсе не только мейнстрима, но и в курсе тех работ, которые занимались именно построением моделей мозга. 

S01 [01:48:18]  : мой пункт в том, что те нейросети, которые мы сейчас используем, мы в основном всегда говорим, подразумевая в скобочках, что это градиент нейронной сети, функция активации и так далее. Совершенно не факт, что эта модель описывает хоть как-то, например, базальные ганглии. Абсолютно не факт. Когда ты говоришь про то, мозг это набор нейросетей я думаю что ну бы вот я не согласен с этим терп тезисом а дальше у тебя из него все выходит из этого тезиса что потому что происходит подмена понятия но в другом месте происходит подмена понятия нейросети 

S07 [01:49:21]  : на понятие backpropagation и обучения. Если мы возьмем тот же GPT-3, которому дают данные, он вообще не учится, но при этом работает. 

S05 [01:49:38]  : Коллеги, предлагаю не углубляться в термины обучения. 

S07 [01:49:41]  : То есть получается GPT-3 не нейросеть тогда? 

S01 [01:49:47]  : Сначала хорошо обучен. 

S07 [01:49:51]  : Как-то обучен, но не факт, что хорошо. 

S01 [01:49:54]  : Сначала сильно обучен дат пропагейшн. На гигантских датасетах. А потом говорит, что он не обучается, но это смешно. Смешно просто. 

S07 [01:50:06]  : Базари Гандри тоже. Они таким образом пришли на свое место. эти нейрончики, да? как-то они встали на свое место, как-то с кем-то они соединились. 

S04 [01:50:20]  : это индуктив байос. это индуктив байос, он нам дан. 

S02 [01:50:27]  : Дима, дай слово Владимиру Смолину. 

S05 [01:50:29]  : да, коллеги, давайте эту тему переключимся и продолжим ее в чатиках. а сейчас давайте Владимир, пожалуйста. 

S00 [01:50:39]  : ну, значит, меня слышно, во-первых. Да. Отлично. Хорошо. Вот, значит, ну, я вам, на самом деле, могу, как вы знаете, очень долго говорить, а мне, значит, ограничиться, поэтому постараюсь только самые основные идеи, так сказать. То есть, не то чтобы я совсем не согласен с тем, что вы говорили, но в целом, значит, эта проблема, как бы она присутствует и в нашем сообществе, что мы не очень, вот как говорит Игорь, что мы ничего не знаем. Вот, на самом деле, значит, большинство считает, что они-то знают, значит, как нужно построить социальный интеллект, хотя говорят другое, вот, а, соответственно, другие-то, естественно, не знают, вот. Ну, я про себя там тоже, конечно, говорю, что я-то знаю, вот, и вы мне, конечно, не верите, вот, но, тем не менее, значит, хотелось бы просто пройти, значит, по тем расхождением, которое есть. Давайте начнем не с расхождения, а с того, что, на мой взгляд, было, собственно, правильно сказано. Значит, вот Дмитрий очень хорошо сказал о том, что вот эта вот гипотеза о том, что мир состоит из объектов, она у нас как-то в мозгу должна быть заложена. Я, в общем, с этим согласен, что действительно это очень полезная гипотеза о том, что мир как бы надо представлять разные, значит, системы. Я много чего записывал, да, но не очень старательно писал. Мне сейчас, значит, тяжело даже прочитать, что я написал. Вот. Но, значит, и, собственно, вот второе, значит, что положительное, опять же, что, значит, вот Антон, значит, говорил, что вот есть три основных определения, что такое AJI, значит, что меня порадовало, что, значит, то определение, которое, значит, раньше у нас обсуждалось, что AJI — это то, что решает все задачи, оно все-таки не прозвучало. Вот. То есть AJI — это, значит, что-то другое, что решает не все задачи, ну, там, либо, вот, как он сказал, похож на человека, там, либо, соответственно, решает какой-то задачный подход, либо может, значит, за счет эволюции, значит, сформироваться. Вот. Ну, значит, Я, конечно, говорил еще четвертый подход, то, что он не вошел, меня не удивляет, поскольку все, каждый знает, что его знания самые лучшие. Но раз мне дали сказать, я тоже скажу про свои знания, которые тоже самые, естественно, лучшие. Главное – это не решать все задачи и, собственно, не пытаться решить побольше задач, поскольку, если мы не знаем, как, собственно, решать новые задачи и получать новые знания, то это, в общем-то, автоматы, которые мы будем программировать, а ничего нового, о чем мы хотим от искусственной интеллекту, говоря о том, что он работает как человек, что он мог создавать что-то новое, чем, собственно, человечество отличается от животного, что мы строим цивилизацию, которой раньше не было, много алгоритмов придумываем, каких-то методов, логики, интегрирования, еще чего. И хотелось бы, чтобы этот искусственный интеллект тоже мог что-то новое придумать. Не только воспринять наше издание, что мы можем в той или иной степени заложить программы, базы данных, научить нейронные сети на основе статистики, но чтобы эти какие-то новые знания, этот сильный искусственный интеллект, получать самостоятельно. То есть, на самом деле, за историю развития цивилизации мы получили очень много знаний. То есть, эти знания у нас как грязь. И мы учимся по-разному их объединять. Но, на мой взгляд, отрисовывая мнение, что мышление – это логика, это ошибочно. Конечно, это форма работы за знаниями, которые у нас есть. Такое же изобретение цивилизации, как колесо, использование огня и много чего-то другого. Логика тоже полезное изобретение, но это не основа мышления. Это способ решения отдельных задач, который, как и много других изобретений, полезен. на мой взгляд, собственно, определение сильного искусственного интеллекта как раз состоит в том, что, во-первых, он должен выявлять новые знания, которые пока что не имеет цивилизация, не было для него заложено, но это не должен быть логический вывод, не Баевский вывод, не какие-то другие, а получение каких-то новых, не знаю, какие-нибудь новые пространства преизобретать, новые физические явления открывать, новую математику. То есть это не просто использование тех, скажем так, формул или методов вывода новых знаний на основе старых, которых мы можем уже отделять от наших машин, и это положительно, это хорошо работает. Но это, собственно, не то новое, что мы хотим получать. Чтобы это было понятно, о чем я говорю, что все мы считаемся полубогами, то есть мы в той или иной степени создаем сильные искусственные интеллекты. По этому поводу есть такой простой анекдот о том, что такие, как мы, человек, пришел к Богу и говорит о том, что теперь я могу, как ты, равен тебе, я могу создать человека. То есть дай мне глину, и я в него вдохну душу, и он, соответственно, будет так же, как ты. Но он говорит, нет, ты, говорит, сперва создай глину, а потом уже вот. То есть вот чем мы сейчас занимаемся, это вот на той глине, которая, значит, наработана человечеством, а мы пытаемся, значит, научить наш сильный искусственный интеллект, чтобы он, значит, что-то создавал. И это получается. А нужно, собственно, получать новые знания. То есть вот и, собственно, проблема вот большинства всех, значит, алгоритмов, которые есть и нейросети, в том, что они используют старые знания, которые в них заложили, и по-разному с ними оперируют. тот же АГИ, который там, в смысле, не АГИ, а ЖПТ-3, который там обучился на большом массиве данных, он там на какой-то новый вопрос использует все данные и все-таки на него как-то отвечает. Это замечательно. Но он никаких новых явлений не открывает. И, собственно, проблема в том, чтобы получать какие-то новые знания. Вот о чём, значит, неоднократно говорил Сергей Александрович Кирихов, о том, значит, что, и тут я его поддерживаю, что вот с другой стороны, значит, задача один можно сравнивать в том смысле, что надо его научить решать задачи, которые не решаются статистическими методами. То есть понятно, что мы уже упираемся по объему данных, по энергии, по времени вычислений, что мы уже можем, конечно, растить наши системы, но пределы уже где-то недалеко. То есть надо заниматься не тем, чтобы увеличивать объем статистики, а решать задачи, которые не поддаются статистическому решению какими-то методами. Но других методов, кроме статистики, изучения этого мира у нас нет. вот и значит собственно я уже неоднократно говорил что собственно вот как бы кроме вот этого подхода оптимизации который хорош то есть на самом деле вот backpropagation который реализует градиентный спуск он в принципе может поддержать любую оптимизацию то есть если вот о чем я как-то пытался донести, но как-то это у всех пролетело мимо, что основные математические методы, которые, ну, по крайней мере, в первую очередь надо как бы пытаться найти, это, собственно, локализация вот этой памяти, соответственно, декомпозиция и линеризация представлений. В принципе, если в вашей, не знаю, в GPT-3 или в какой-то другой системе какая-то там декомпозиция случайно начинает формироваться, я считаю, что backpropagation я должен поддержать, поскольку это эффективный способ представления данных, если мы более эффективно представляем данные, то, соответственно, система будет лучше работать, и градиентный слуз в этом смысле тоже должен есть. Другой вопрос, что поскольку никаких специальных механизмов, чтобы инициировать вот эту декомпозицию, мы туда не закладываем, то случайность возникновения вот этой декомпозиции, она пропорциональна числу слоев. Если у нас слоев 5, то вероятность очень маленькая. Если их 1000, то уже там, соответственно, в 200 раз побольше эта вероятность, и она там может возникнуть. и другие какие-то методы, идеи, скажем, математические тоже могут возникнуть, но вероятность, понимаете, маленькая, потому что мы ничего специально не делаем, чтобы эту вероятность повысить, кроме того, что увеличим число слоев, то есть чисто вот таким экстенсивным методом увеличим число слоев, вероятность каких-то интересных оптимизаций, которые там могут реализоваться, она возрастает, но моя идея состоит в том, что надо пытаться вот эти перечисленные хотя бы мной три оптимизации, значит, закладывать изначально структуру сети, вот то, что Дмитрий говорил о том, что, собственно, должно быть заложено представление о том, что мир состоит из относительно простых объектов, в принципе, структуру сети надо закладывать, чтобы, значит, разные объекты, там кошки запоминались в одном области, там собаки в другом, в общем, не надо замечать, в какую мы, может, мы никогда в жизни кошек не встретим. Но важно, что есть разные объекты, и чтобы вот эти разные объекты могли распределиться по разным системам, и когда мы там учимся как общаться с кошкой, наши навыки общения с собакой, чтобы не портились. Вот, то есть вот это, значит, та область, где было заполнено про собаку, когда мы учимся что-то про кошку, чтобы про собаку вообще не активировалось и там ничего не портилось. ну и декомпозиция, понятно, что это способ, собственно, использовать статистику для решения различных задач. почему? потому что если у нас там какой-то параметр зависит от одной-двух переменных, то мы там легко... Владимир, прошу прощения, еще пару минут, ладно? я понимаю, да, что я никак не говорю. мне 10 минут за глаза, да, конечно. но, соответственно, если мы сляем а какой-то параметр зависит от 1-2-3 переменных, то регрессия, линейная или нелинейная, какая-нибудь, и все решается если переменных много, то ничего не работает ну или работает на нейросетях, и вот и наши успехи в нейросетях за счет того, что мы сейчас умеем делать регрессию фактически для достаточно высокоразмерных задач опять-таки, какие-то существенные переменные выявляются, есть методы различные, автоэнкодеров, которые это делают, это все работает, но опять-таки это делается посленным путем, а надо пытаться делать напрямую третья лионеризация связана с тем, что нужно выявлять существенные переменные, которые нужны. Если мы лионизируем задачи, то какие переменные, в какой комбинации они существенны, это легко решается. И, соответственно, это путь к решению задачи выделения существенных переменных при решении задач построения действий. Конечно, поскольку у меня уже осталось меньше минут, насколько я понимаю, естественно, там должна быть аксиметрия выявляться, инвариантность появляться, много еще чего, о которых я, конечно, сейчас не буду говорить. Ну и, собственно, надо... Ну и проблема, которую Игорь Павловаров очень хорошо понимает, что то, о чем я рассказал, все хорошо, но финансировать это не буду, поскольку коробку с работающим устройством я не положу. И, соответственно, я вам, конечно, рассказываю какие-то идеи, но не только мне, но и никому из вас на развитие этих идей денег не дадут, и, соответственно, это вот мы просто поговорили. 

S05 [02:01:41]  : Вот, собственно, все. Очень печальное завершение вашей речи насчет того, что денег никому не дадут. но вдруг дадут, несу я критику. 

S00 [02:01:52]  : Ну, хорошо. Я, правда, не надеюсь, что если вам дадут, вы меня пригласите. Но, тем не менее, если даже хотя бы... Я уже буду рад. 

S05 [02:02:01]  : Если денег много, то и вас тоже позову. 

S00 [02:02:03]  : Не переживай. Не бывает денег много, а бывает денег мало. 

S05 [02:02:07]  : Ладно, ребят, кто еще хочет сказать что-нибудь? У нас, я не знаю, Антон, как у нас обычно по времени бывает? По-моему, мы уже, в принципе, все. 

S04 [02:02:15]  : по-моему да по-моему уже давайте у меня есть есть еще комментарии на пару минут но если завершаем я думаю что уже пора 

S03 [02:02:27]  : у меня одна секунда. всем спасибо. мне добавить больше нечего. было очень интересно. именно перемалывание одного и того же столько раз с разных сторон без действительно определенного фундаментального ответа. а что делаем-то? что делаем? То есть нужен ли нам бухгалтер, нужен ли нам второй мозг или второй бухгалтер, или решить конкретную задачу. Все, спасибо. 

S05 [02:03:00]  : Я могу уточнить. Мне нужен бухгалтер. Вот прям конкретно. Сделайте бухгалтера. 

S03 [02:03:05]  : Именно бухгалтер. Не система управления предприятием, а бухгалтер. Да. Вот именно такой индивид такой. 

S05 [02:03:20]  : Если вы сможете собрать его на антологиях, я его у вас куплю за миллион долларов. 

S03 [02:03:24]  : Ни за что, никогда не соберу. 

S01 [02:03:26]  : Так, мы все свидетели, побежали собирать роботы на антологиях. 

S03 [02:03:31]  : Вот, не соберу. Вот система управления в целом, да, а одного бухгалтера нет, он никому не нужен один. Мне нужен. сейчас нужен, да, действительно. сейчас и водитель нужен для машины, но в скором будущем ему нужен будет водитель для машины. 

S01 [02:03:44]  : видимо, Дмитрий просто знает, кому его в Сбербанке за 5 продать. поэтому он готов купить за миллион, чтобы потом за 5 продать. 

S05 [02:03:54]  : так, коллеги, ну что, кто еще? Сергей хотел? Сергей Александрович. 

S04 [02:03:59]  : но я позвольте я просто хотел немножко вот какую вещь еще в контексте вот обсуждения которые сегодня были значит такой вот осветил как бы озвучить мне кажется что сейчас настало время немножко изменить терминологию понятия того что называется обучение там с учителем без учителя так далее вообще вернуться к роли учителя вот собственно подход, о котором говорил Антон, который перечитал четыре способа обучения, он действительно вот такой глубокий, а вот в контексте наших действий насчет данными там и вообще с которыми мы там вот те системы третьего уровня, о которых говорил Игорь, предложение такое. на самом деле по большому счету что делает учитель? считается, что учитель это тот, кто дает y к этим x. на самом деле даже дача x, то есть вот когда учитель говорит на тебе x вот это, до y дело вообще не дойдет, до правильного ответа не доходит, до рефорса нет. просто вот этот x попробуй с ним поработать. это уже сигнал учителя. То есть я хочу сказать, что роль обучения с учителем, суть его состоит в том, что есть некто, внешне по отношению к агенту, который ему как-то с ним взаимодействуют методом любым вообще говоря вот выдачи ему ситуации выдачи ему примера выдачи ему и ответа может быть и подкрепление сюда входит это все дело вот если такой есть то это обучение с учителем ну то есть это вот некая дача чего-то Вы прекрасно лучше меня знаете. Там куча способов восточного обучения, когда учитель вообще молчит. Он просто говорит, какую задачу решать. Он даже не оценивает ученика. Мне кажется, что нужно сейчас, особенно с учетом субсупервеста, перейти к термину такому, что Любое поступление внешнее к агенту информации, данное кем-то, это уже учитель. вот это вот комментарий Сергей вопрос кем-то или чем-то чем-то можно считать учителем это вот это уже тонкий вопрос если кто-кто может учить среда может ли механическая быть таким учителем или нет это вот отдельный вопрос но но я хочу просто хочется хочу сказать что взгляд на то что учитель это тот кто создает дает ответ или дает reinforcement это сегодня это уже очень узко информация о том, какие бывают иксы, это уже огромное количество информации. это потрясающее количество информации, потому что дав мне огромную базу данных из миллиарда иксов, я сразу могу понять, начать какие там структуры есть, что там повторяется, что там не повторяется, увидеть там топологии какие-то и так далее. это огромный, огромный сигнал учителя на самом деле, хотя ни одного икса, ни одного подключения я не получил. но я получил информацию. Рассказыватель о задаче – это учитель. 

S05 [02:07:06]  : Выскажу сегодня немного. Иксов много, их целый мир, но они не структурированы в этом проблеме. 

S04 [02:07:13]  : Ладно, это отдельная тема. Задача выбора кем-то должна быть решена. Не вообще все иксы, какие на свете существуют, потому что все на свете существующие иксы – это просто все на свете, это весь свет, просто тождественный этому свету. а вот если кто-то решил значу выбора под множество из того что существует вот это уже сигнал очень хорошо денис 

S05 [02:07:37]  : давай, ты будешь завершающим. 

S06 [02:07:40]  : спасибо, что дали слово. всем добрый вечер, я в вашем сообществе. я давно слежу в Redon Limode, то есть тоже читаю, вот решил и сам немножко высказаться. у меня вопрос в догонку к вопросам игры, то есть мы в данный момент не понимаем, как устроено взаимодействие участков мозга. И очень важно при моделировании и создании каких-то искусственных моделей, искусственных сетей и других участков мозга, которые будут выполнять конкретную задачу, решить вопрос с нейропластичностью. Когда наши искусственные сети будут решать задачу вышедших из строя искусственных сетей, которые отвечали за другие задачи. вот по поводу этого я хотел бы немножко подиспутировать и узнать ваше мнение. как создавать такие искусственные сети, которые будут 

S05 [02:08:52]  : Мне кажется, мы сейчас конкретно к этому вопросу не готовились, поэтому подискутировать времени уже не осталось. Я могу ответить. Спроси хотя бы у Юрия. Спасибо. 

S07 [02:09:04]  : Вообще говоря, в больших сетях нейропластичность опять же есть. Если мы какой-то кусок сети отрезаем, то остальная сеть задачу как-то решает и тем более уж сеть может доучиться решению этой задачи. Поэтому в этом плане вопрос повторения нейропластичности перед нами не стоит. Более того, мозг достаточно плохо решает задачу нейропластичности, особенно для большинства двигательных навыков. Как вы знаете, восстановление после травмы в аварии занимает полгода-год, и то зачастую точная моторика, мелкая моторика потом не восстанавливается вообще. Поэтому 

S01 [02:09:52]  : Но вот я не совсем согласен с ответом. Все-таки нейропластичность определяется достаточно узко. То есть, с одной стороны, действительно сети учатся. Если мы говорим про то, что сеть на распознавании, мы из нее убираем кусок и потом по новой ее обучаем, то да, там будет веса перераспределяться, она по новой, она будет чуть хуже, но она продолжит распознавать. Но у мозга все-таки есть нейропластичность. Ну, допустим, условно. там вот один проект любопытный этот недавно видел они активно развиваются слепые люди им делают очки И оказывается, что там, допустим, кожа в районе висков достаточно... там много рецепторов. И, короче, там такие пупырышки типа шрифта Брайля. Прямо вот здесь, в очках. 

S07 [02:10:41]  : Большая точность развлечения, да. 

S01 [02:10:44]  : Да-да-да. 

S05 [02:10:45]  : И в результате... Еще языка можно видеть еще. 

S01 [02:10:48]  : Эти нейроны... Короче, к этим очкам там камера, и она там, условно говоря, выдает сигналы. в височную область, и у человека появляется некоторое ощущение зрительное в результате. Но я к тому, что это совершенно другая область, соответственно, совершенно другие задачи, и нейропластичность, которая в этом смысле произошла, я уж молчу про истории, когда у человека там часть мозга снесло, и у него другие функции мозга, другие области мозга начинают выполнять там задачи удаленных кусков. То есть там нейропластичность на порядке выше, чем в тех нейросетях, которые мы сегодня используем. 

S07 [02:11:25]  : Но если мы сегодня используем многомодальные нейросети, то кроме клипа почти таких нейросетей и нет сейчас. В них нейропластичность как раз есть, и более того, примеры как раз все показывают, что многоподальный перенос делает. А вот то, что мы видим картинку, вот говорим, что феномен нейропластичности заключается в том, что мы что-то почувствовали и увидели после этого картинку, так здесь объяснение немножко другое. Мозг эту картинку, он ее все равно строит сам. Вот то, что мы видим, это тоже наш какой-то внутренний экран. То, что мы думаем, что мы видим, мы же этого не видим. Вот у нас вот есть слепое пятно, где-то вот здесь вот, например, оно есть. Но мы же в той картинке, которую мы строим, у нас же нет этого пятна. Так получается, что картинка, которую мы видим, это не та картинка, 

S04 [02:12:25]  : Я только добавлю к твоему комментарию очень важный момент. Ты не вводи в заблуждение людей. Были прекрасные работы Тоби Кахонена в середине 80-х годов, когда были многослойные СОМ-карты, которые прекрасно синтезировали разные модальности. Они, собственно, это и делали. то есть создавалась целая структура тогда, и можно было действительно и одну модель на другую переносить, одну-другую корректировать, взаимо их обучать. Такого количества, так сказать, работ в 80-е, в 80-е, обращаю твое внимание, годы, было очень-очень много. Поэтому, когда ты говоришь, что там какой-то клипс, который там где-то появился, я даже не знаю, что это такое. А вот что такое многослойная сети Кахона, оно, правда, это другое поколение. Да, хорошо, ладно. Так что это тоже не... Ну, то есть, конечно, изучалось это давно. И работало, работало. Вот прекрасно работали, например, обработки космических снимков, на этом даже делались. Потому что там были очень много разных спектральных модальностей, потом к ним подтягивалась информация ГЕО в разных диапазонах, потом еще снизу, с Земли радарная, и все это вместе синтезировалось в общую картину. Несколько слоев там было, так сказать, и так далее. такие работы были они как бы то самое ничто не новоподобное вот сейчас 

S06 [02:13:41]  : Вдогонку хотел спросить у Юрия и у остальных по поводу информации, чем занимается нейролинк и Илон Маск. Они сейчас объявляют чипы в мозг макакам. Знаете, да, Юрий? И у них собраны данные именно по той, ну то, что вы говорили, то, что мышление, нам не хватает данных по мышлению и так далее. Вот у них датасеты собраны. но они публично ничего, ну как полупублично можно какую-то информацию узнать, а вот публично информации нигде нет. что вы знаете по этому поводу их датасетов? 

S07 [02:14:19]  : спасибо. спросите в твиттере. 

S06 [02:14:24]  : Не ответят. Засекречено все. Это США, там все засекречено. 

S04 [02:14:31]  : Маск просто покупает твиттер. Вот это вот сейчас. 

S01 [02:14:33]  : И цена уже известна. Я могу ответить, но предлагаю записи выключить. Я человек политкорректный. 

S06 [02:14:40]  : Давайте, давайте. 

S07 [02:14:41]  : Пока есть запись, поговорим. Да, потом тогда, надеюсь, сможем на этот вопрос ответить. Дело в том, что сейчас нейролинк все еще на этапе прототипов, то есть они еще не получили оптимальную конфигурацию, которая будет потом пригодна для массового применения. Они сейчас занимаются как раз подбором этой конфигурации и выбором именно того... Извините, я перебиваю, добровольцев они сейчас. но главная у них задача с точки зрения инженерии – это построение программно-аппаратного комплекса для его массового использования. Учитывая то, что нейропластичность есть, у них есть надежда, что если они в одну область маленькую живят, тысячи электродов, то они потом смогут ну что-то типа канала связи устроить со всем мозгом и всю информацию передавать. идея такая. ну и, соответственно, пробуют. 

S06 [02:15:54]  : но это публичная информация, это все знают. а именно то, каким успехом они сейчас пришли, как Игорь предлагает выключить запись и поговорить на это. потом поговорим. 

S00 [02:16:06]  : я не выключаю запись, пару слов скажу. Не выключая запись, можно пару слов сказать? Вот, то есть вот сегодня озвучилось как бы два подхода, что давайте мы будем решать прикладные задачи и на нем пойдем решать сложности. И, собственно, второй подход – это давайте поймем, как работают нейронные сети, тогда тоже все поймем. Есть третий подход, о котором я пытаюсь неоднократно говорить, что давайте поймем, что нам, какие математические идеи нужно реализовать в наших системах, чтобы решать сложные задачи. Вот как бы этот подход, на мой взгляд, более продуктивен. Значит, с Маском там, да, они на свиньях, на макаках, значит, экспертируют. Разговоры о том, что они ищут добровольцев, это, видимо, где-то в Конго и на Украине, потому что в цивилизованных странах опыты выживления, как бы сказать, типов небольных людей, значит, ну, как бы запрещены. То есть там, конечно, выживляют чипы, но когда там позвоночник сломан, еще что-то, и есть успехи. И с выживлением чипов больше проблем чисто медицинских, чтобы обживили, там, чтобы конгрен не началась, там, еще что-то. Мозговая ткань более устойчива к различным инфекциям, поскольку там спинальная жидкость, но все равно там проблемы есть. Вот, и вот, значит, поддержу, хочу Сергея Кирехова о том, что, конечно, значит, внешние данные есть уже большое обучение, и, в принципе, как бы, как сказал еще Высоцкий, нас жизнь заставит, нас жизнь научит, то есть, в принципе, получая внешние данные и прогнозируя, как все будет развиваться, мы каждый раз, как бы, можем сравнивать то, что мы прогнозировали, то, что на самом деле получилось, вот, получать эту разницу, и дальше, как вот считает Перебоборов, основной метод — это, собственно, по разности между тем, что получилось, считать градиенты и, собственно, улучшать наши предсказания. Вариантов обучения тут тоже говорили несколько. На самом деле речь идет не только об обучении и воспроизведении. Есть там, собственно, какое-то поисковое поведение, то есть вместо того, чтобы выполнять какие-то действия, можно перейти в режим поискового поведения, постараться дообучить свои знания или где-то еще какие-то знания получить. ну и на самом деле режимов работы нейросети значительно больше, чем 4, и, соответственно, отличие не только в том, о чем справедливо говорил Пивоваров, что много очень разных сетей есть в мозге, они по-разному работают, но еще и это много разных сетей, они работают в очень разных режимах, то есть, не знаю, кто-то находит десяток, кто-то два десятка разных режимов, но их как бы разные. То есть, действительно, система сложная, и вот, собственно, эта работа стоит не только в том, чтобы найти, какие структуры, но и в каких режимах, как они взаимодействуют. Ну и мой-то подход, чтобы это понять, нужно, собственно, понять, а что нам нужно, чтобы решать вот те задачи, о которых говорит, собственно, неоднократно Терехов, о том, что которые не решаются статистическими методами, как с помощью нейросетей научиться решать те задачи, которые статистически медленно решаются. Поскольку в одну реку нельзя войти дважды, и каждый день мы встречаем ситуации, которые мы решаем не на основе статистических методов, а другими путями. И вот, собственно, эту задачу нужно пытаться теоретически решать. что там Маск накопил, он, конечно, пиарщик большой, но, в принципе, много источников методов получения данных, да, я заканчиваю, но их понять без каких-то предварительных теоретических идей совершенно невозможно. Рассчитывать то, что мы получим миллиард или много миллиардов очень данных, и мы сразу все поймем, это, как сказать, мы просто утонем в этом море. Без каких-то идей и предварительного понимания этих данных. 

S05 [02:19:40]  : Коллеги, я прошу прощения, модерирование заканчиваю, потому что у меня там свои дела. Я просто иду в фоне слушать. 

S02 [02:19:45]  : Скажи, пожалуйста, с твоей точки зрения, что мы узнали, есть разница между AGI и машинным обучением или нет? 

S05 [02:19:54]  : Я считаю, что все, как всегда, остались при своих. Просто мы немножко друг друга информировали. То, что мы можем как-то сдвинуть наши картины миру, это наивно было предполагать с самого начала. Но я, допустим, сегодня узнал о том, что экспертные системы бывают обучаемы. Для меня это главный кусок знаний сегодня. 

S02 [02:20:15]  : Как разница-то есть между машинным обучением и GI? 

S05 [02:20:18]  : Для меня, конечно, есть. Это был главный мой пойнт. 

S02 [02:20:25]  : Ладно, коллеги, на этом мы завершаем запись. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
