## 28 июля - Когнитивная архитектура на основе принципов обработки информации мозгом и задачного подхода - Антон Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/Hlld3ZJO6iw/hqdefault.jpg)](https://youtu.be/Hlld3ZJO6iw)

Суммаризация семинара:

ТЕМА
- Семинар посвящен когнитивной архитектуре и ее потенциальной применяемости в реальных задачах.

СУТЬ
- По словам представителя, семинар является заключительным перед каникулями и заключает итоги деятельности авторского коллектива, включая сотрудников НГУ и Сбербанка.
- Важной задачей семинара является соединение пониманий работы мозга из лаборатории нейронаук Сбербанка и формальных математических методов, разработанных в Новосибирском государственном университете и институте математики.
- Обсуждается возможность построения прикладных приложений на основе этого объединения, с последующим их тестированием.
- Участники обсудили принципы обработки информации и их применение для построения когнитивных архитектур.

ДЕТАЛИ
- Участники семинара обсуждали принципы генерации сложности, упоминая работу Андрея Владимировича Курпатова и его книгу "Мышление".
- В дискуссии затрагивалась тема парсинга деятельности и его важности для модернизации экспертных систем.
- Поднимался вопрос о разных подходах к анализу и обработке данных, в том числе сравнение событийной антологии и РДФ.

РЕЗУЛЬТАТЫ
- Обсуждалась возможность построения когнитивных архитектур на основе базисных принципов и формальных математических методов для решения конкретных задач.
- Участники семинара подводили итоги работы коллектива и отмечали важность дальнейших исследований и экспериментов.
- Обсуждалась возможность использования результатов семинара в практических приложениях.






S03 [00:00:08]  : так да коллеги мой экран видно а наверное надо сделать так они видно отлично тогда и тогда это тогда сейчас я делаю да я делаю share screen и теперь я делаю slide slide slide slide slide slide show Теперь видно, да? Отлично, да. Хорошо, значит сегодня у нас семинар, который последний. перед отправкой на небольшие каникулы, то есть мы в каком-то смысле подводим итоги года, прошедшего с момента прошлых каникул, а заодно мы сегодня попытаемся подвести итоги относительно большой работы, которую выполнял указанный здесь авторский коллектив, включая представителей Новосибирского государственного университета и Сбербанка. И задачей этого подхода было, с одной стороны, соединить те, скажем так, понимания того, как работает человеческий мозг, которые есть у лаборатории нейронаук Сбербанка во главе с Андреем Владимировичем Курпатовым, А с другой стороны, с теми формальными математическими методами, которые разрабатываются в Новосибирском государственном университете и институте математики сибирского отделения коллективом с участием Евгения Чевитяева, ну и не просто это объединить, но и попытаться вообще понять, можем ли мы на основе вот этого объединения строить какие-то прикладные приложения. При этом, конечно, по-настоящему, чтобы это понять, нужно эти прикладные приложения построить и успешно их опробировать на практике. И на самом деле эта работа тоже является частью некоторого большого проекта. Но сегодня про практические эксперименты будет совсем мало. И апробация будет больше с точки зрения того, как мы можем в рамках пресловутого задачного подхода, про который я буду тоже говорить дальше, как в рамках этого подхода можно действительно построить то, что называются когнитивные архитектуры на основе вот этих базисных принципов и формальных математических методов. где было бы видно, как эти когнитивные архитектуры будут решать совершенно конкретные задачи, описанные в соответствии с задачным подходом в терминах соответствующих предметных областей. Ну и, наконец, поскольку мы все живем в современном мире нейросетей, где есть понимание уже практически у всех, включая самых заядлых любителей искусственных нейронных сетей, у всех есть понимание того, что нейросимвольная интеграция – изол-юнит. В этой перспективе, конечно, мы не обойдемся Мы говорим о разработке системы, которая будет использовать пресловутую нейросиммульную интеграцию, где у нас с одной стороны есть глубокие нейросети различных архитектур, а с другой стороны формальные математические методы, которые отвечают за логическое мышление. а не ассоциативное мышление. То есть мы говорим о том, что у нас мы работаем в парадигме двух систем Канемана – система 1, система 2. Ну и в сегодняшнем докладе мы будем как бы фокусироваться именно на интерпретируемой или логической части вот этого нейросимвольного дуализма, то есть у системе 2 Канемана. Значит, чтобы попытаться понять рецепт вот того супа, который мы сегодня будем расхлебывать, можно представить себе ситуацию следующим образом. Допустим, мы пытаемся подойти к проблеме создания прикладных систем на основе искусственного интеллекта с точки зрения междисциплинарного подхода. ну, он не совсем междисциплинарный, там, литературы и живописи у нас не будет, но у нас вот есть психиатрия и психотерапия, у нас есть нейрофизиология, есть машинное обучение, есть математика – это вот как бы различные предметные области, из которых мы, которые где-то между собой, естественно, пересекаются, и вот мы попытаемся взять из них аспекты, которые в них прорабатываются во всех. Со стороны психотерапии, психотерапии и отчасти нейрофизиологии, прежде всего в левой верхней стороне мы берем те принципы, которые руководитель лаборатории Нейронауксбербанка Андрей Курпатов сформулировал в вышедшей пару лет назад книжке, зеленой книжке, которую Греф вручал Путину про сильный искусственный интеллект, который многие здесь считали и в которой Мы с Евгением Евгеньевичем и Дмитрием Ивановичем, который только что присоединился к нашему разговору, тоже участвовали в качестве соавторов. Так называемые пять принципов программирования мозга, как это называют лаборатории нейронаук. Я про них остановлюсь несколько подробнее. Вот мы тут их выделяем, что это такое, расскажу. И мы их, кстати, на нашем семинаре уже раньше обсуждали. Там у нас была довольно бурная дискуссия. Сегодня у нас будет возможность эту дискуссию продолжить. помимо этих принципов конечно же у нас да ну и значит опять-таки глубоко мы в это погружаться не будем для того чтобы погрузиться во все эти пять принципов больше можно почитать вот эту книжку можно почитать соответствующие книги курпатова вот но кроме этого значит у нас естественно участвуют в качестве одного из ингредиентов – это теории функциональных систем Анохина. Те аспекты нейрофизиологии, которые связаны с сознанием, про которые пишет Танони и про которые, в частности, рассказывает как минимум на одном докладе, которые я видел, о проблеме сознания Сергей Шумский. Очень хороший доклад про то, как устроено сознание есть у Анила Сетха. Ну и вот многие вещи, которые в этих докладах и работах есть, они тут вот будут, я, может быть, даже на них не буду явно как-то ссылаться, но они будут незримо присутствовать, поэтому для того, чтобы понимать некоторые вещи, хорошо бы эти вещи иметь в бэкграунде. Собственно, когнитом Анохина эта концепция гетерархии нейронных сетей, она тоже будет присутствовать неявно, поскольку мы будем говорить о том, что внутри реализации тех предкладных систем, которые дальше будут обсуждаться, лежит так называемая Когнитивная база данных. И, собственно, в основе когнитивной базы данных лежит гиперграфовое представление информации. А гиперграфовое представление информации – это, по сути, может быть использовано для описания как раз гетерархии сетей, сетей, сетей, которая, собственно, в качестве когнитума рассматривает Константин Анохин. Ну и наконец, с другой стороны, у нас есть глубокие нейросети, которые неявно будут присутствовать у нас за кадром, как некоторый глубинный ассоциативный слой для решения ряда подзадач в рамках общей инфраструктуры на нижнем уровне. У нас, конечно же, будет нейросимвольная интеграция присутствовать незримо, которая будет сшивать, собственно, какие-то компоненты системы, работающие на основе глубоких нейросетей, и, собственно, саму логику системы, которая будет работать на основе системы 2 Канемана, то есть на основе вероятностной или нечеткой логики. Ну и, наконец, у нас в более явном виде будет присутствовать нечеткая логика, а точнее вероятностная логика, причем вероятностная логика на основе разработок товарищей Байеса Фитишера и Редхера. Конечно же, будет использовано, опять-таки, может быть не очень явно, понимание того, что такое системы, категории и естественные классификации. Это метод вероятностных формальных понятий, развиваемый Евгением Витяевым на основе обычного метода форма форма анализа формальных понятий ну и конечно же поскольку мы будем говорить о прикладных системах в рамках которых мы хотим решать задачи описывая эти задачи в терминах антологии предметных областей и оценивая решабельность или решаемость и успешность решения этих задач в терминах данной предметной области, для этого, конечно, нам понадобится задачный подход и семантическое моделирование, вот в тех позициях, с которых его нам рассказывал Дмитрий Иванович Севереденко, думаю, семинара. Значит, начнем с нейросимвельной интеграции, чтобы потом к этому не возвращаться. Вот слайд как раз с недавнего обзорного доклада Михаила Бурцева, где он рассказывал, где буквально месяц прошел с этого доклада. Как раз Михаил подробно с большим количеством примеров рассказывал, в каком месте мы сейчас находимся с точки зрения развития глубоких нейронных сетей, глубокого обучения, что хорошо, что плохо, чего не хватает. И как раз один из последних слайдов – это о том, что нам нужно взять лучшие из двух миров и интегрировать систему 1 – канемана слева и систему 2 – канемана справа, каким-то образом интегрировать возможности этих двух систем. Ну и вот мое видение этой картинки, которая заключается в том, что с точки зрения теории информации мы одни и те же знания, или одни и те же правила, или одни и те же поведенческие схемы, или одно и то же нечто, что определяет наше поведение, или одни и те же модели, мы можем закодировать некоторым количеством битов. И это некоторое количество битов может быть сохранено в памяти какой-то нейронной сети или какого-то сочетания нейронных сетей, какой-то конфигурации из N нейронных сетей, где каждая из этих N нейронных сетей имеет M слоев и K нейронов в каждом слое. Но эти же биты могут быть представлены в виде взвешенного графа, который будет описывать некоторую уже семантическую модель. То есть, одно и то же количество битов может сохранить одно и то же информацию. И вопрос в том, является это нейросетью или является это каким-то графом, или семантическим представлениям, это вопрос именно того, какие математические методы мы применяем для работы с тем или иным, с этими битами, как мы это интерпретируем, ну и в конечном итоге, какова структура этих битов и каковы средства хранения этих битов, на каком носителе и в какой форме мы храним. Но и если, с левой стороны, в парадигме системы 1 у нас информация хранится распределенная, и решения могут приниматься быстро, но обучать приходится очень долго, а с правой стороны, и это неинтерпретируемо, с правой стороны, в парадигме, в рамках системы 2 Канемана у нас информация хранится в структурированном интерпретированном виде, обучается очень быстро, но для того, чтобы принять решение, нужно потратить достаточно большое количество времени. Если мы понимаем, что одна и та же информация может быть в том и в другом представлении, то у нас возникает возможность с одной стороны переводить информацию и с левой стороны в правую, объясняя структуру имеющегося у нас знания для того, чтобы его верифицировать. А с другой стороны, получив быстро некоторое структурированное знание, мы можем его закачать в ассоциативную структуру налево и таким образом осуществлять быстрый инференс на параллельном вычислительном оборудовании. А может быть мы можем строить какие-то гибридные архитектуры. Но это вот все было к тому, что мы сегодня будем говорить о том, что происходит больше в правой части. И в правой части мы будем опираться на такие формальные математические методы и подходы, которые разрабатывались нашими коллегами в НГУ и Институте математики Саран. Это, прежде всего, логиковероятностный вывод. про который и я рассказывал, и Евгений Евгеньевич много раз рассказывал, я здесь про него повторяться не буду. Можно посмотреть наши семинары. Вероятностные формальные понятия, про которые также многократно рассказывалось, если очень коротко, для тех, кто здесь Оказалось в первый раз, что логиковероятностный вывод помогает описывать знания на основе предикатов с вероятностными оценками истинности каждого из предикатов. То есть, если в прологе у нас предикаты только «да» или «нет» могут быть, то логиковероятностные выводы и предикаты имеют вероятностные оценки. На сегодняшний день в мире существует несколько систем такого рода. Одна система – это НАРС Пиэванго, другая система – это Опенкок, Пиэлэн, Бена Гёрдзель и третья система как раз Это система Евгения Дмитриевича Витяева, который вот один из участников нашего проекта. Соответственно, вероятностное формальное понятие, это по сути, грубо говоря, с точки зрения машинного обучения, это некоторый подход к ластеризации. основанные, во-первых, на формальной математической логике, а с другой стороны, допускающие вероятностные оценки. То есть, если классический метод формального Формал-концепт к анализу формальных концепций или концептов позволяет работать в сильном представлении в таблицах свойств и объектов, то вероятностные формальные понятия позволяют делать вероятностные оценки того, насколько данная совокупность свойств соответствует тому или иному классу объектов. Где класс объектов является некоторой инвариантной комбинацией свойств, которая имеет, где каждая из этих свойств имеет некоторую логическую взаимосвязь с другими свойствами. Вот как раз совокупность логических взаимосвязей, свойств друг с другом, того, что вот если там У меня есть крылья, и я летаю. То есть, если я летаю, у меня, по-видимому, есть крылья. А если у меня есть крылья, то, по-видимому, они используются для полета. И, за исключением Страуса, это два таких обстоятельства, которые обуславливают некоторое функциональное поведение. И вот на как раз сочетание вот этих вот атрибутов, множества носителей этих атрибутов, там орлы, ласточки, журавли, значит, это являются объектами, но совокупность этих объектов, этих свойств и этих логических правил как раз определяют там формальное понятие птица, которое вот в терминах нашей дальнейшей работы называется инвариантом. Вариантная комбинация свойств, соответствующая некоторому множеству экземпляров или прецедентов. Дальше. Теория функциональных систем, которая является, скажем так, математическим и физиологическим обоснованием всего, что в современном мире дата-сайенса описывается задачами reinforcement learning. То есть, когда мы имеем возможность, теория функциональных систем дает возможность математически и физиологически обосновать построение систем, работающих на основе подкрепления. Ну и, наконец, задачный подход позволяет решать прикладные задачи таким образом, что если у нас есть некоторая операционная среда, в которой мы описали некоторую задачу, некоторую предметную область, будь то управление атомной электростанцией или оформление накладных в интернет-магазине. Если в терминах этой операционной среды мы можем определить не только правила выполнения тех или иных операций, но и конкретные цели, собственно вот этих бизнес-операций, то мы на самом деле можем не только эффективно выполнять эти операции, мы можем генерировать и правила. То есть, если у нас есть некоторая цель формализованная, если у нас есть некоторый поток формализованных данных, если у нас есть некоторая возможность оценки того, как некоторая последовательность наших действий соответствовала некоторой последовательности этих данных, и далее оценивать, насколько эти две последовательности достигали или не достигали формализованной цели, мы чисто математически можем посчитать эффективность или неэффективность тех или иных поведенческих схем для того, чтобы их откорректировать. Это для чего нужен задачный подход. Теперь давайте перейдем к тем пресловутым принципам обработки информации мозгом для принятия решений, которое у наших коллег в лаборатории нейронаук Сбербанка называется как Brain Principles Programming. Соответственно, вот аббревиатура BPP, она это обозначает. Почему принципов пять? На самом деле, как мы знаем, любую систему можно разложить на бесчисленное множество функций. То есть, там вот психологи в соционике людей классифицируют на 16 психотипов. В других есть классификации, которые людей классифицируют, точнее, социотипы. Про соционик это социотипы, значит, 16 типов личностей. В других системах есть четыре – холерики, сангвиники, флегматики, меланхолики. Есть там шизоиды и стероиды. Можно раскладывать любую систему. любую совокупность объектов на разное число групп. Кстати, на возможность альтернативных классификаций как раз у нас будет семинар 18 августа, но там с точки зрения более чисто Data Science. Здесь, в принципе, то же самое. То есть, я могу на самом деле показать, что, например, принцип локальности-распределенности можно расщепить на два. То есть, я могу сказать, что принцип локальности… Я сейчас чуть позже буду эти принципы разжевывать, чтобы потом было что обсуждать. В общем, локальность-распределенность здесь подразумевается как один принцип, хотя его можно разнести на два. С другой стороны, принцип тяжести и принцип аппроксимации досущности на самом деле как бы являются двумя частными случаями одного и того же. Только если принцип тяжести – это про ассоциативные связи, или сущностные связи, или про атрибутивные связи, связи типа HES. если мы говорим в терминах онтологии, то апоксимация дослушности – это скорее про связи между классами и объектами, это скорее про связи отношения наследования. То есть, грубо говоря, если мы будем говорить в терминах у некоторой универсальной системы логического вывода, то можно сказать, что принцип тяжести и принцип апоксимации дослушности, они описываются где-то одними и теми же одними и теми же математическими операциями. Ну а когда мы говорим о том, что все это реализуется с точки зрения нейронов, то тут как бы тоже, так сказать, в принципе одни и те же нейронные механизмы, они описывают, реализуют в принципе работу функциональных систем головного мозга, где работают все эти пять принципов. Итак, как эти принципы работают? Предположим, мы сталкиваемся с некоторой проблемой. Допустим, мы заходим в темную комнату, и нам положили что-то в руку. И мы не знаем, что это такое. Мы не знаем, что это такое, но у нас рука сгибается, напрягается под тяжестью этого. И мы понимаем, что тяжесть вроде как и не очень большая, но и не очень маленькая. То есть, мы сразу понимаем, что это не ядро от пушки, с одной стороны, и не маленький воздушный шарик. То есть, вес средний. С другой стороны, мы ощущаем поверхность. Мы сразу чувствуем, поверхность там ворсистая или гладкая. Мы чувствуем мягкая поверхность или твердая. То есть у нас сразу возникает некоторый поток ассоциаций. Точнее, сначала у нас возникает поток чувств, а вот дальше за этим потоком чувств возникает поток ассоциаций. И возникает та самая генерация сложности, Вот про которую я помню, против которой была очень серьезная аргументация пару лет назад, когда мы обсуждали, по-моему, позапрошлогоднюю конференцию AI Journey, где этот принцип как раз был представлен. Для того, чтобы отвлечься от того, что у нас в руке, я приведу простой пример, чтобы пояснить, что такое генерация сложности. Представьте себе, что вы назначили свидание, или вам назначила свидание прекрасная незнакомка, или там знакомка, вот, и вы ее пришли там в условленное место, и вы ее ждете, а она все не приходит, и не приходит, и не приходит, вот, и, значит, у вас в голове вообще начинает роиться клуб мыслей. Сначала вы себе представляете, что ее там, значит, самый у вас увел какой-то ваш друг, да? И вот вы представляете, как она с этим другом там сидит где-то в ресторане и ржет над тем, что вы как дурак там самымечитесь в беспокойстве. Потом вы начинаете думать, нет, она этого сделать не могла. Она, так сказать, торопилась ко мне навстречу, но она так торопилась, что я сбила машину. И вот вы представляете, как она лежит со сломанной ногой. И к ней не может доехать скорая помощь. И вот вы, так сказать, генерируете вот эти вот бесконечные образы того, как все плохо. И в какой-то момент она к вам приходит и выясняется, что у нее такси застряло в пробке, а батарейка на телефоне села. Она не смогла вам позвонить. Вы начинаете рассказывать, как вы тут распоряжевались. целует щечку и говорит, что ты все усложняешь. Все просто. Такси в пробке, батарейка села. Но помимо вот этой генерации сложности и возникновения всех ассоциаций, которые у нас возникают в связи с тем, что у нас оказалось в руке какое-то на ощупь, на вес и на поверхность. Может быть, даже мы чувствуем запах или не чувствуем его. У нас эти все гипотезы они начинают между собой взаимодействовать. То есть мы начинаем, так сказать, рассуждать. Ага, вот раз, значит, если это не такое тяжелое, как пушечное ядро, то какие ассоциации могут быть со средним весом? Или наоборот, если оно тяжелое, то какие ассоциации могут быть с чем-то тяжелым? То есть представьте себе, что вот у нас, значит, мозг – это вот такая вот полая сфера. Вот здесь вот мы видим полую сферу, да, вот в середине. И в этой полой сфере, значит, у нас есть участки этой сферы, которые отвечают за разные... так сказать, восприятие. Есть зона коры, которая отвечает за вес. Есть зона коры, которая отвечает за поверхность, за твердость поверхности. Есть зона коры, которая отвечает за ощущение размера, которое мы пальцами можем ощутить. Есть зона коры, которая отвечает за гладкость поверхности, насколько она ворсистая или не ворсистая. Есть форма, которая отвечает за округлость этой формы. И вот в дырочку маленькую или в несколько дырочек к нам залетают сигналы о том, что мы ощутили. И вот эти сигналы начинают метаться по этому полному пространству, отражаясь друг от друга и либо усиливая, либо ослабляя друг друга. То есть, если мы понимаем, что оно не тяжелое, то, скорее всего, оно не черное, потому что пушечные ядра обычно черные. И раз это не тяжелое, то, скорее всего, это не пушечное ядро, значит, черный вес отметается. Ну и так далее. А если оно мягкое, если оно очень легкое, то цвет может быть любой, потому что воздушный шарик может быть любой. Но при этом поверхность должна быть гладкая. А раз поверхность не гладкая, то значит это не воздушный шарик. Ну и так далее. Соответственно принцип отношения как раз позволяет соотносить различные гипотезы, различные сложные построения или ассоциации, которые мы сами себе придумывали при ограниченном числе стимулов. И в итоге Дальше подключается пресловутый принцип тяжести, который, собственно, обеспечивается локальной ингибицией или локальным торможением, когда те сигналы, которые оказываются в итоге более активны, начинают тормозить сигналы, которые менее активны. и в результате локального торможения у нас в конечном итоге побеждает самый сильный символ. Далее надо сказать, что все это происходит одновременно, то есть у нас все зоны коры работают в мультизадачном подходе, то есть когда одна зона обсчитывает и пытается вычислить все гипотезы, связанные с округлостью, другая обсчитывает все гипотезы, которые, значит, вычисляют, могут быть связаны с поверхностью, потом, когда эти гипотезы насчитаны, значит, они посылаются навстречу друг другу, где происходит их сопоставление и уже возникает, значит, начинает работать фактор распределенности, который позволяет как раз, собственно, соотносить эти гипотезы между собой. Ну и в конечном итоге у нас в какой-то момент происходит попытка разные варианты, допустим, мы себе воображаем, что может быть это яблоко, и сразу же воображаем, значит, что у нас яблоки бывают желтые, у нас яблоки бывают зеленые, у нас яблоки бывают красные, но в конечном итоге У нас все это является яблоками. И мы берем в конечном итоге и говорим, да, это яблоко. Это яблоко. Решение принято. После того, как мы поняли, что это по поводу пяти принципов. Дальше мы увидим на более прикладном примере, как эти пять принципов могут быть задействованы при решении прикладных задач. Можно сказать, что все эти принципы применимы в рамках реализации тех математических методов, на основе которых мы строим прикладные приложения, про которые я буду рассказывать дальше. Материалы, которые я сегодня буду рассказывать очень поверхностно. Задача моя сегодняшняя – это походить вокруг верхушки айсберга некоторого, у которого есть с одной стороны математический фундамент, который будет представлен на конференции IGI через пару недель. А с другой стороны некоторые прикладные аспекты реализации, которые будут представлены на конференции Байка осенью. Есть соответствующие статьи в архиве. Эти статьи можно почитать. Они сейчас публичные. Но мы не будем глубоко зарываться. У меня задача попытаться все-таки проговорить какие-то принципиальные вещи. Для того, чтобы попытаться понять, как мы можем на основе этих принципов и этих методов реализовать какую-то прикладную систему, мы провели некоторую работу, связанную с выявлением некоторых типовых и наиболее важных с точки зрения Сбербанка, Сбера в данном случае, поскольку работа выполнялась совместно со Сбером, какие основные имеются случаи и были выявлены или выделены наиболее интересные приложения из разных спектров. То есть, есть три задачи, которые имеет смысл решать. Во-первых, задача психотерапии, собственно, которой профессионально занимается Андрей Курпатов, руководитель лаборатории. Другая задача – это классическая задача современного маркетинга – это построение цифровых двойников клиентов. Ну и понятно, что поскольку Сбербанк это у нас один из основных интеграторов отечественных, то задача построения цифрового аватара клиента или цифрового профиля клиента у него стоит в полном профиле. Ну и последняя задача – это то, что называется система поддержки принятия решений. Система поддержки принятия решений, я думаю, многие здесь знают, что это широко распространенная область, которая имеет которая имеет варианты реализации в различных предметных областях. Но в данном случае, поскольку это у нас не Росатом и не Газпром, то у нас не когнитивный ассистент бурового мастера или оператора атомной электростанции или энергосети, у нас когнитивный ассистент менеджера, которому нужно управляться со своими задачами и с коммуникациями. Соответственно, разбирая те бизнес-кейсы и сценарии, которые есть у каждого из них, мы обнаружили, что для каждого из них есть три группы функций. Первая группа функций, которая есть у каждого из этих рабочих мест – это функция ассистента или консультанта. когда он мне просто подсказывает, что делать. Грубо говоря, если у меня ассистент психотерапевта, он мне подсказывает, о какой диагноз нужно этому человеку поставить или какое лечение ему нужно прописать. Если это цифровой аватар клиента, то ассистент мне подсказывает, что этому клиенту сказать, если он хочет закрыть счет. Или, если он не хочет закрыть счет, что ему можно еще предложить в качестве кроссела или апсела? Если это ассистент менеджера, то этот ассистент менеджера он рекомендует, а вот какой приоритет назначить этой задачи, а какой бюджет выделить такому-то проекту, а кому вообще назначить вот эту задачку, чтобы она с гарантированным качеством и гарантированные сроки решились, а кого назначить тем лидом на вот такой-то новый проект. То есть чисто ассистировать. значит 2 за 2 группа функции это вот которая условно называется вот это третья стрелочка сверху в каждом блоке например психореконструктор там расширение профиля реконструктор менеджера это получение новых знаний То есть, мы проговаривали в свое время на семинаре такой кейс, как извлекатель не структурированной информации. Так вот, как раз это то, что тут называется реконструктор, или расширение профиля, или реконструктор менеджера. Это как раз кейсы. Почему это называется реконструктор, я не буду сейчас обсуждать, это некоторая внутренняя культура. и внутренний язык лаборатории нейронаук, но суть примерно такая, что то, что называют вот этот функционал, он обеспечивает выявление некоторых закономерностей, нахождение некоторых инвариантов. Например, мы можем выявить, что все, допустим, люди, которых увольняют с работы, у нас просто дальше будет соответствующий пример, все люди, которые увольняют с работы, они страдают к примеру, катастрофизацией. Катастрофизация – это некоторый признак когнитивных искажений, который имеет определенную симптоматику и, соответственно, определенные методики психотерапевтического воздействия. Вот, соответственно, если к нам приходит человек, и первое, что он говорит, вот вы знаете, меня уволили с работы, мы уже сразу понимаем, что он скорее всего страдает катастрофизацией, и уже мы знаем, как с ним дальше себя вести, какие вопросы ему задавать, как с ним разговаривать. То же самое с цифровым аватаром клиента. Если мы, анализируя кучу профилей клиента, выявили некоторую закономерность, что все молодые люди любят котиков, То, соответственно, если нам нужно рекомендовать какие-то продукты этим людям, вот мы будем всем молодым людям рекомендовать котиков. А пожилым людям котиков рекомендовать не будем. Ну и, соответственно, с когнитивным ассистент менеджера. Если мы там знаем, что, к примеру, Петя все задачи решает очень качественно, но долго над ними возится. А Маша решает задачу очень быстро, но с плохим качеством. Соответственно, если нам нужно по-быстрому закрыть не очень важные задачи, мы их назначим Маше. А если нам нужно в любой срок, но гарантированно решить какую-то очень важную задачу, мы ее дадим другому человеку, как его, Пете зовут или как. Ну и, наконец, актуализатор менеджера – это вот некоторый такой, значит, или предсказание, то, что здесь называется психоактуализатор, тут это называется предсказание активности, тут это называется актуализатор менеджера – это некоторый функционал, который позволяет, ну, грубо говоря, создает возможность некоторого аналитического дэшборда к тем знаниям, которые выявлены в ходе реконструкции. То есть мы, грубо говоря, можем сказать, а вот, значит, Меня интересует проект, связанный с разработкой системы предсказания продаж в конкретном сегменте рынка. И мне сразу вываливаются все проекты, которые похожи были в организации на эту тему, каким-то зеленым цветом вываливаются, какие проекты провалились, красным, которые, наоборот, прошли успешно, и, соответственно, под себя подтаскиваются те люди, которые влияли на исходы этих проектов. И я могу эту информацию каким-то образом визуализировать, анализировать и принимать уже сам решение без всяких ассистентов, но на основе вот такой структурированной информации. как это делают системы типа The Brain, Мира, то есть, грубо говоря, это актуализаторы, это и предсказатели, это система предсказательной аналитики с некоторой интерактивной визуализацией. И, соответственно, имея вот такие группы кейсов, имея три прикладных приложения, мы понимаем, что для того, чтобы нам построить некоторую универсальную систему а-ля AGI, то есть под AGI мы здесь подразумеваем не систему, которая может научиться чему угодно, а мы под системой искусственного интеллекта подразумеваем систему, которую с помощью соответствующей операционной среды, описанной с помощью в терминах предметной онтологии, мы можем эту систему заставить работать в любой предметной области. Соответственно, вот у нас есть когнитивное ядро где есть логика и вероятностные выводы теории функциональных систем и вероятностное формальное понятие. И мы понимаем, что если загрузим в нее онтологию психотерапевтическую, мы будем решать психотерапевтические задачи. А если загрузим онтологию связанную с ERM или таск-менеджментом, мы будем решать, соответственно, задачи управления клиентами или поддержки применения решений для менеджмента. А кейсы, они остаются те же самые. То есть, вот у нас есть бизнес-кейс «Когнитивный водород-консультант», где работают в основном логика, вероятностные выводы, теория функциональных систем. как они работают, будет на следующих слайдах. Есть актуализатор, где в основном задействована логика и вероятностный вывод. И есть реконструктор, где в основном задействованы вероятностные формальные понятия. И все это сидит на так называемой когнитивной базе данных, в которой есть графовое представление инвариантное ко времени. Это... Так, я уже сейчас... Даже уже, так сказать, вылетело из головы, что обозначает этого аббревиатура. А, семантическая вероятность базы данных. Семантическая вероятность базы данных, где хранятся инварианты. И семантическая вероятность темпоральной базы данных, которая хранит то, про что нам регулярно рассказывает Александр Балдачев. в своих докладах про темпоральную логику. Соответственно, сущности темпоральной логики, они вот как раз находятся в СВТ-БД, а сущности инвариантной ко времени выращенной, выявленные на основе темпоральных сущностей, они находятся в базе ФБД инвариантной ко времени. Как это работает? Вот теперь, собственно, когнитивная архитектура когнитивного ядра, куда еще добавлен задачный подход для того, чтобы можно было бы оценивать, собственно, успешность, неуспешность тех или иных событий, явлений. Вот у нас есть когнитивная база данных, где с одной стороны у нас наверху есть метаданные, то есть метаданные это как раз типы данных, атрибуты и классификаторы, которые описывают данную предметную область, какие у нас есть сущности, какие у них есть атрибуты и какие классификаторы используются для наполнения тех или иных атрибутов. Дальше у нас есть, собственно, база данных, которая состоит из двух слоев. Есть так называемые композиционные классификаторы и инварианты. Что-то такое я, надеюсь, обсужу, расскажу. Сейчас огляну, сколько там у нас по времени. Значит, это вот композиционные классификаторы и инварианты. Это, собственно, то, что является инвариантной информацией, описывающей, собственно, исходные данные. И, наконец, у нас есть сущности, которые мы фиксируем в процессе функционирования нашей системы и отношения между этими сущностями. Ну и, наконец, отдельно сбоку у нас находятся правила логики вероятностного вывода, которые объединяют между собой как вот эти сущности, так и инварианты и композиционные классификаторы между собой. То есть, эти правила просто описывают то, как все находящееся в базе данных может соотноситься между собой с точки зрения логических закономерностей, которые были выявлены. Система работает следующим образом. Во-первых, мы фиксируем все данные, которые у нас есть в жизненном цикле нашей системы, и они откладываются в сущности отношения между ними. Дальше вероятностные формальные понятия. Они берут то, что мы накопили, обобщают и формируют инварианты, которые на самом деле по сути очень близки с композиционными классификаторами. То есть композиционные классификаторы, инварианты – это примерно понятия одного и того же вида. Я чуть позже про это скажу. Дальше, после того, как у нас появились некоторые вероятности, причем вероятностные формальные понятия, когда выявляются, они выявляются опять-таки в совокупности, используя методы логики вероятностного вывода. И когда у нас сохраняется каждый инвариант, полученный на основе некоторых сущностей, вместе с этим инвариантом сохраняются те правила, которые описывают вообще правомощность существования этого варианта. Насколько, допустим, сочетание молодого возраста и пристрастия к котикам, насколько оно статистически является выраженным или нет. Может быть, есть еще более ярко выраженные статистические закономерности, соответствующие варианты. Вот, соответственно, правила, они хранятся в отдельной базе данных, и их логиковый вероятностный вывод можно сохранять и обновлять. Наконец, когда у нас что-то начинает происходить в системе, у нас в систему поступают запросы и контексты. То есть, запрос – это что делать или потребность выполнить какое-то действие, а контекст – в каком контексте мы это хотим произвести. В результате того, что мы получаем этот контекст, этот запрос, система логики вероятностного вывода делает некоторый прогноз. Причем прогноз делается таким образом, что мы из базы данных берем правила, которые относятся к тем данным, которые передаются через контекст. И либо на основе правил строится некоторый прогноз, либо этот прогноз делается на основе инвариантов. То есть, на самом деле, если мы выясняем, что к той совокупности исходных данных, которые передаются в качестве контекста и запроса, есть подходящие инварианты. То есть, если мы сразу узнаем, что вот была такая ситуация, то мы на самом деле можем, исходя из знакомой ситуации, сразу рекомендовать некоторые решения. А если такого инварианта нет, такой ситуации нет, то мы начинаем делать логику вероятностного вывода, долгую, мучительную, и рекомендовать какое-то решение или какой-то исход с какой-то вероятностью. И, соответственно, тогда мы даем прогноз, который выдается на выход спросителю этого прогноза и давателю этого запроса. И одновременно этот прогноз выдается на модуль, отвечающий за теорию функциональных систем, который включает акцепторы результата действия и говорит, что вот я тебе дал такой прогноз, вот, пожалуйста, скажи мне, помогло или нет. после чего возникает обратная связь вот и если значит это помогло то, соответственно, у нас на основе тех данных, которые фиксируют вот эту вот эффективность или неэффективность следования данным рекомендациям, у нас происходит оценка успешности соответствующей ситуации. Ну и в результате обработки… То есть, успешность – это на самом деле соответствие, акцептура результата действия в терминах теории функциональных систем. После чего может идти корректировка правил логико-вероятностного вывода блоком функциональных систем. Ну и задачный подход, как я, по-моему, уже сказал, он, собственно, отвечает за оценку как раз этой успешности, которую можно подать на вход акцептеру результата действия. Ну и, что важно, для того, чтобы оценить успешность модулем задачного подхода, нужно формулировать цели. Разберем конкретный пример. Допустим, у нас есть менеджер, который отвечает за продажи. Если мы запускаем его с чистого листа, то начинается все с того, что мы просто идем и начинаем фиксировать данные. Мы здесь находимся в режиме unsupervised learning. В одном из докладов я приводил историю про то, как меня учили серфингу. Настоящий серфер, когда приходит на пляж, он должен на новый спот Он должен на этом споте как минимум полдня просто просидеть на берегу, глядя на волны, да, и накопить у себя в подсознании инварианты, закономерности того, значит, с какой частотой приходят сеты для того, чтобы потом, когда, значит, он будет уже в воде, чтобы не думать тогда, значит, не думать когда придет очередной сет, соответственно, когда нужно начинать грести или лучше подождать, пропустить эту кажущуюся волну и дождаться начала другого сета. Соответственно, мы кодируем, получаем эти данные накапливаемые, И по мере того, как мы их накапливаем, мы работаем в режиме unsupervised learning, где у нас экземпляры поступают на вход логики вероятностного вывода и системы вероятностных формальных понятий. Значит, вероятность системы вероятностных формальных понятий с помощью логики вероятностного вывода выявляет правила, которые описывают некоторые закономерности, и соответствующие закономерности они записываются как инварианты. В примере с серфингом у нас мы знаем, что в среднем на каждые шесть волн приходит одна большая. Соответственно, если мы на одной волне проехали, то пять волн нужно пропустить, а шестую можно седлать. Ну а если мы возьмем, кстати, пример Мы будем в рамках моего примера обсуждать. Допустим, у нас задача менеджера. Мы фиксируем истории продаж. Кстати, когда у нас происходит вот эта фиксация вариантов, у нас по сути как раз срабатывает тот самый метод аппроксимации досущности. то есть у нас вот как раз инвариант – это как раз такая сущность. Мы, например, формируем сущность С. Все исследовательности из шести волн или все циклы продаж или все известные истории о том, когда продажи росли и когда продажи падали, они записываются как сценарии или как инварианты. И здесь работает метод аппроксимации до сущности. Наконец, мы обнаруживаем, что в какой-то момент в этих данных мы фиксируем падение продаж. И тут же возникает запрос, что делать, и некоторое уточнение того, что целью является повышение рентабельности. То есть у нас есть данные, есть задача, есть запрос, что делать. И вот здесь мы, например, начинаем выявлять инварианты. И, например, мы находим такой инвариант, который мы, например, не выучили сами, а ведь у нас инварианты, они же могут браться из внешнего мира, у нас же система онтологическая. То есть мы можем инварианты как закладывать в систему в виде правил, так и выучивать. А я это к чему говорю? К тому, что вот для данного случая падения продаж есть харизматичный пример у Филиппа Котлера в основах маркетинга. где он описывает, как, не помню, то ли у Смирнова, то ли у его конкурента стали падать продажи водки, потому что, значит, появился какой-то конкурент, который стал, значит, продавать водку, значит, такого же литража, но там, так сказать, на несколько центов дешевле, и все убежали. И вот товарищи маркетологи долго думали в этой компании и нашли гениальное решение. Они расширили линейку и стали продавать одну и ту же водку в трех разных упаковках. Только одну они сделали чуть-чуть дороже, чем было. Вторую сделали существенно дороже, чем было. А третью сделали существенно дешевле, чем было. То есть, водка была разная, но, соответственно… Кстати, вот как раз это тот самый кейс, с которого началось разделение на Silver, Gold и Platinum Client, Light и Professional. Это вот оттуда все пошло, если что. Ну вот, вот как бы стандартное решение. Соответственно, мы находим такой вариант, когда кто-то или мы сами делали. Кстати, для того, чтобы найти этот вариант, мы же как бы генерируем еще разные сценарии. То есть мы, когда у нас падают продажи, мы вспоминаем сразу же все, что у нас происходило, как мы разорялись в одной жизни, в другой жизни. увеличивали цену и это не помогало. Как мы в другой ситуации уменьшали цену, это тоже не помогало, потому что если мы увеличивали цену, то никто не покупал. А если мы уменьшали цены, то у нас падала выручка за счет. Все покупали, но мы в итоге разорялись. И тут мы генерируем все возможные варианты, соотносим их между собой, делаем все это одновременно. Соответственно у нас работают принципы локальности, распределенности, отношения, генерации сложности. Ну и, наконец, побеждает тот вариант. с расширением линейки, у которого не оказалось никаких сайд-эффектов, но вот он оказался известным из литературы. Соответственно, мы в результате даем рекомендацию расширить линейку и ожидаем роста продаж. А дальше мы фиксируем, что у нас продажи действительно выросли. Соответственно, модуль задачного подхода фиксирует успешность, поскольку в терминах предметной онтологии рост рентабельности соответствует повышению значения функции успешности. И, соответственно, мы закрепляем это правило, и у данных правил, на основе которых этот прогноз был выдан, у них увеличивается вероятность. Каким образом мы это все думаем можно реализовывать? Поскольку мы говорим о задачном подходе и поскольку было обозначено, что нам для описания предметных антологий различных задач для использования одним и тем же когнитивным ядром универсальным, нам нужно на каком-то языке унифицированным описывать разные предметные онтологии, то мы описываем унифицированную верхнюю онтологию. Это возвращение к моим вопросам к Александру Балдачеву, почему вы не называете, не нравится слово «онтология». В моем понимании антология – все есть антология. То есть, если у нас есть антология, которая описывает другую антологию, то просто у нас есть два уровня антологии. То есть, у нас есть предметная антология, а на дне есть некоторая метаантология, которая описывает предметную антологию. Еще это называется антология верхнего уровня. И вот в этой верхней онтологии, про которую я, кстати, рассказывал на одном из семинаров, я просто быстро обозначу некоторые принципиальные вещи. Естественно, вверху этой онтологии, как у большинства онтологий, существующих на свете, стоит понятие «вещи». А дальше эта вещь распадается на два типа вещей. Одна вещь – это экземпляр. То есть, это результат каких-то физических наблюдений того, что есть в реальном мире. А другое – это инвариант. При этом экземпляры, они бывают либо временные, прецедент, где экземпляр временной типа прецедент, у него есть время, временные марки, начало и конца в общем случае. вот может быть там с какой-то погрешностью то есть как измерять время там какого-то президента это отдельная история там на несколько семинаров но вот в простейшем приближении вот в рамках того проекта который мы рассказываю есть на и время начала и конца вот а есть временно вне временные экземпляры да то есть это к примеру там клиент это предприятие это значение какого-то справочника тут можно тоже спекулировать что на самом деле человек тоже может рассматривать как прецедент потому что у него есть там время начала и конца жизни вот но В рамках жизненного цикла системы мы от этого абстрагируемся, в тех предметных антологиях, которые мы обсуждаем. Прецеденты у нас могут распадаться на единичные события, на совпадения событий, когда несколько событий происходят одновременно, и процессы, когда имеют место некоторые последовательности либо событий, либо совпадения этих событий. Ну и дальше уже начинается более тонкое ответвление. Например, эти экземпляры у нас там могут быть категории, могут быть сущностями, могут быть отношениями, могут быть субъектами, физически или из-за группы лиц. То здесь уже мы начинаем перебираться, зарываться в предметную онтологию, связанную там с поведением системы в мире людей и физических лиц. Ну и опять-таки, если мы пойдем в область инвариантов, то у нас есть такие инварианты, как явление, которое описывает одномоментное событие, ситуация, которая описывает либо комбинацию каких-то единичных событий или совпадение событий, либо это какая-то развилка. То есть, вот есть понятие сцена и развилка, которые на самом деле являются либо канюнцией, либо дизюнцией. конъюнктивная ситуация, когда мы точно знаем с большой вероятностью, что что-то происходит одновременно, а развилка – это ситуация, когда происходит либо то, либо другое, либо третье. Ну и, наконец, сценарий – это некоторая, опять-таки, инвариантная последовательность каких-то явлений, либо ситуаций, объединенных в некоторую последовательность, которую мы знаем, где элементы этой последовательности выполняются один за другим. Ну и, собственно, на основе этой… Да, и, естественно, если мы возьмем некоторые инвариантные, вещи, иные сущности, то мы обнаружим, что есть такое понятие, как классификатор, который используется для атрибутирования значений всего, что здесь есть. И эти классификаторы могут быть либо уникальными, либо множественными, либо композиционными. Разницу между ними, я надеюсь, успеем разобрать. Значит, когнитивная база данных, но здесь просто большим планом та же самая картинка, где у нас есть метод данные, есть, собственно, данные и есть правила, которые описывают эти данные, где данные имеют два слоя, значит, инварианты и прецеденты или экземпляры. Ну вот, собственно, к вопросу о том, как мы эту информацию храним и как мы ее представляем для того, чтобы, собственно, с ней работать значит здесь к вопросу о графовую базу данных значит здесь получается примерно так сколько графовую базу данных не строй все равно получается революционная вот и через это в общем Многие проходили, многие еще пройдут. И в конечном итоге, хотя система OpenCock 23 года назад была задумана в своей нынешней регистратуре, непосредственным участием. По сути, когда мы переходим на уровень энарных связей, то есть когда мы говорим, что нет, блин, бинарных связей не хватает, и типизированных, то бишь триплетов нам тоже не хватает, потому что нам нужен еще четвертый или пятый атрибут, который точно описывает это отношение, а это у нас уже возникает классическое революционное отношение товарища Кодда, которое мы вынуждены хранить в революционной базе данных и выполнять к нему правила революционной алгебры. пусть даже, а в терминах математической логики мы вынуждены иметь дело с предикатами, где, соответственно, N местный предикат соответствует N арному революционному отношению революционный алгоритм. Если мы возьмем конкретный пример из бизнес-задачи про цифрового аватара, Так, сейчас я вижу, что у нас со временем. Мы, например, видим, что... Мы можем описать, к примеру, конкретного клиента, у которого могут быть какие-то атрибуты. Вот там есть имя, пол, хэштеги, тематики, которые его интересуют, и продукты. И вот, например, мы понимаем, что один из его атрибутов может быть, что называется, уникальным. То есть пол может быть только один. И для этого вообще графовая база данных не нужна. Мы просто храним такой атрибут, как пол, у данного клиента. Дальше, если у нас атрибут множественный, то, например, атрибут хэштеги, какие хэштеги человек использует или какие хэштеги, какие посты с какими хэштегами он читает, то это уже так называемый множественный классификатор, где у одного и того же человека может быть множество значений, отношения многие ко многим. И вот здесь вот уже как раз нам нужен пресловутый граф, да? То есть у нас уже есть связь типа хэштег, у нас есть источник связи, у нас есть конец связи, и вот как раз вот такое отношение, оно прекрасно описывается триплетом, да? Оно прекрасно ложится на какой-нибудь RDF, на GraphStore, и вот мы можем, вот если бы у нас не было всех остальных, атрибутов, про которые я сейчас поговорю, мы бы прекрасно любую информацию в базе данных могли бы описывать графами в базе данных. Но вот у нас, например, возникает такое понятие, как интернет тематики клиентов, где там вот какой-нибудь Антон, к примеру, на ленте.ру читает политику, а бизнес его интересует на сайте xe.com. к примеру. То есть, у нас возникает уже… То есть, во-первых, есть тип связи, а связь-то уже, так сказать, получается гиперграфовая. Ну и, так сказать, дальше хуже. И, соответственно, у нас возникает ситуация, когда мы не можем использовать не тернарные, а тем более бинарные связи, а мы вынуждены использовать пресловутые революционные отношения. И возможным решением этой проблемы является введение понятия связующего объекта данных или композиционного классификатора. У нас есть понятие композиционный классификатор, который выносит на свой уровень некоторые устойчивые ассоциации. читает на Ленте.ру про политику, а на Ксе ком-бизнес. И если вот эта вот комбинация она повторяется устойчиво, то мы выделяем отдельные сущности, как вот такая вот группировка определенного сайта и определенной тематики. И имея вот эти вот композиционные классификаторы, мы уже имеем возможность давать конкретным атрибутам ссылки на эти классификаторы. Но мы ведь такие классификаторы заранее все можем не знать. Мы ведь можем вот эти вот закономерности выявлять в процессе работы системы. Таким образом, как раз вот эти композиционные классификаторы, которые мы знаем заранее и задаем на стадии конфигурации СИО, конфигурации системы или ручного программирования бизнес-логики, они являются как бы некоторыми прототипами новых возможных композиционных классификаторов, которые могут быть построены совсем на других исходных атрибутах и совсем других исходных базовых классификаторах, которые мы даже не можем возразить, не можем вообразить. Вот там дальше у нас, если успеем, будет пример того, что, к примеру, предпочтения жизненные, они связаны, к примеру, со стилем общения. Люди, у которых один стиль общения, у них такие коммуникационные предпочтения. И у нас возникает связь двух каких-то атрибутов, которые приводят к появлению некоторого классификатора, где есть возможные устойчивые суперпозиции и, собственно, отношение человека кто или другой суперпозиции, с одной стороны является информационным признаком, который может оказаться решающим в каких-то прикладных задачах, а с другой стороны мы тогда имеем возможность к этим компенсационным классификаторам строить простые графовые связи, упрощая, собственно, работу над структурой данных, поскольку у нас простые связи просто опираются на большом числе объектов. И вот таким образом, так пресловутая задача нормализации или ренормализации базы данных, она может происходить просто в процессе жизненного цикла системы, как система реструктуризации, выявления новых и обновления новых инвариантов и построения на основе их композиционных классификаторов. Ну вот теперь пришло время обсудить, не разобрать несколько практических примеров, сколько успеем. Значит, пример первый, который мы разбирали, это и психотерапевт. Для тех, кто не знаком с областью психотерапии, я скажу, что существует очень много школ, То есть, по сути, каждый известный психотерапевт является носителем своей собственной школы психотерапии. Но есть большие группы психотерапевтов, школы которых достаточно близки друг к другу. И самое большое сообщество близких по своим школам психотерапевтов объединяется под флагом когнитивно-поведенческой терапии. где за основу лежит… Одним из основных понятий является когнитивная ошибка. Есть, опять-таки, в разных школах разное число когнитивных ошибок. Есть 12, есть 13, есть 16. Они характеризуются… Давайте разберем конкретный пример. К примеру, у нас есть ситуация, когда человеку уволили с работы. Известно из психотерапевтической практики, что если человеку уволили с работы, то он может испытывать такую эмоцию, как страх. И он может испытывать такую ошибку катастрофизации. Что такое катастрофизация? Это вот такое поведение человека, когда вот что бы ни произошло в его жизни, он считает, что это все. То есть, там разбилась чашка, все, жизнь моя кончена. Горячая вода пошла из крана вместо холодной. Наоборот, все, моя жизнь кончена. Я лузер, все пропало, все погибло. состояние, в котором, я думаю, эмоционально многие из нас бывали, может быть, там временно, но вот когда такое состояние является перманентным, это, в общем, существенное ухудшение качества жизни, вот с которым, собственно, призвано бороться психотерапевты. Ну и таких вот состояний много. Но и для того, чтобы поставить диагноз, для того, чтобы выявить, собственно, вот эту когнитивную ошибку, и для того, чтобы понять, что с человеком делать, осуществляется, собственно, психотерапевтическая диагностика, которая в той парадигме, которую мы прорабатывали с коллегами, описывается пятимерным пространством. То есть, вот здесь на картинке показано трехмерное пространство, просто потому что я не умею в презентациях рисовать пятимерное пространство, это трудно. Но, в общем, пространство пятимерное. То есть, справа показано, что диагноз у нас пятимерен. И вот эти вот пять измерений, значит, одно из них – это вот то, которое нам предстоит найти, это как бы основное измерение – это когнитивные ошибки. Вот. Второе – это, значит, так называемое состояние, да, то есть там, значит, какое состояние у человека, там есть своя шкала состояния, я их сейчас вот сходу себе не помню. Дальше, значит, эмоции и чувства, вот, например, тревога или страх – это одно из чувств, там тоже есть своя шкала. Социальные ситуации, да, но социальные ситуации – это вот там, так сказать, новая работа, там, увольнение, там, движение по службе, там, так сказать, выговор, там, свадьба, Рождение ребенка – это все социальные ситуации. Очевидно, что негативные социальные ситуации являются триггерами каких-то когнитивно-поведенческих нарушений. Ну и, наконец, психотип клиента. То есть, на самом деле, профиль клиента или его психотип может быть дальше разбит Чуть ли не 10 различных подсоставляющих, но мы тут это все объединяем как бы вот одно такое измерение обобщенное, которое дальше может доробиться. То есть, на одном этом измерении на самом деле есть много инвариантов, которые представлены пресловутыми композиционными классификаторами, на которые я говорил раньше, где сочетаются много всяких разных вещей, которыми как раз владеют психотерапевты. Собственно, диагноз как раз описывает комбинацию этих состояний. Например, у нас при увольнении может быть как катастрофизация, так и персонализация. Катастрофизация – это когда человек считает, что все плохо. А персонализация – это когда он все принимает на свой счет. То есть не обязательно все плохо у него, не обязательно все будет плохо, но вот грубо говоря, если там что-то происходит негативное, то это все из-за него. То есть он считает, что вот он всему виной и считает себя все время виноватым. И это немножко другая симптоматика и другие меры психотерапевтического воздействия, чем катастрофизация, когда человек считает, что все погибло, но не обязательно по его вине. Таким образом, вот, например, на этой картинке, если мы отбросим психотип и профиль клиента, И состояние, то в пространстве социальной ситуации, когнитивной ошибки эмоции, у нас диагноз будет выглядеть так. Катастрофизация при увольнении, связанная с тревогом или страхом. Или тревога и страх, связанная с катастрофизацией при увольнении. Это вот, грубо говоря, тот диагноз, который вы получаете, значит, если не в явном виде, привезите к психотерапевту в такой ситуации, но вот психотерапевт ставит его у себя в голове и дальше с вами взаимодействуют соответственно. Как это работает? Как мы осуществляем диагностику и дальше последующее лечение в указанном пространстве категории когнитивно-поведенческой терапии? Соответственно, к нам приходит человек, и мы в результате бизнес-функции постановка диагноза, которая выполняется сейчас вручную, а мы можем рассуждать о том, как автоматизировать эту постановку диагноза. В результате определяется положение данного пациента в пятимерном пространстве, в данном случае в трехмерном пространстве. Соответственно, вот мы ставим диагноз. После чего нам нужно определить некоторый набор терапевтических воздействий. В случае психотерапии это не медикаментозные, а коммуникационные взаимодействия, хотя на самом деле в случае психиатрии они могут быть и медикаментозными. И в результате этих воздействий мы должны изменить человека вот в этом трехмерном пространстве или пятимерном пространстве. Обратите внимание, что мы изменяем положение человека, но только по двум осям. То есть, увольнение, факт увольнения человека мы не можем убрать. То есть, его уже уволили. А вот Ликвидировать когнитивную ошибку или ликвидировать негативные эмоции мы можем. Обычно это происходит либо в процессе диалога, когда есть такая практика, когда в процессе взаимодействия человек понимает, где он находится, понимает логику всего происходящего с ним и как-то у него все встает на свои места. Либо мы можем в этом помочь какими-то словами, какими-то вопросами, можем убедить его, что все не так страшно. Дальше чуть будет пример. Соответственно, после того, как мы диагностировали, что после лечения он оказался в этой точке, мы, собственно, ставим диагноз. И, например, если говорить про оценку функций успешности, то у нас и теорию функциональных систем, к примеру, то у нас здесь возникает возможность применить теорию функциональных систем, во-первых, для разработки автоматизации процедуры максимально быстрого и максимально исчерпывающего диагноза, То есть, функция успешности в данном случае будет фиксировать то, что у нас поставлен диагноз один и исключены все диагнозы другие. То есть, как только у нас поставлен один диагноз и все остальные диагнозы исключены, у нас срабатывает акцептор результата действия. Соответственно, все, что мы делали в ходе соответствующей терапевтической сессии, ведущей к такому состоянию получает положительное подкрепление в терминах reinforcement learning. А если мы возьмем шире, если мы еще и возьмем те лечения терапевтического воздействия, то, соответственно, те терапевтические воздействия, которые в процессе последующей диагностики привели к снятию диагноза, то опять-таки те терапевтические воздействия, они получают свою долю, если угодно, положительного подкрепления. Мы сразу же видим, что у нас даже теория функциональных систем может работать на нескольких уровнях. Первое – это то, что называется на сессионном уровне, то есть в рамках одной сессии за решение задачи диагностики. И на межсессионном уровне, когда от сессии до сессии мы прослеживаем траекторию пациента вот в этом вот пространстве. То есть, может быть, на втором визите к нам пациента мы увидели, что он не ушел в ноль по когнитивным ошибкам и негативным эмоциям, но увидели, что он ушел из этой точки. Скажем так, он приблизился к спокойному состоянию. И, соответственно, на второй сессии мы продолжаем его двигать. в правильное положение, чтобы, значит, снизить ошибки и эмоции. Так, значит, соответственно, ну вот, если углубляться в практику, практически, да, ну вот, да, вот как раз, собственно, значит, как это выглядит на практике. что мы на входе здесь у нас уже соответственно не рука с яблоком на входе у нас какие-то речевые паттерны которые психотерапевты как бы держат в своей голове вот некоторые держат своих книжках А искусственный интеллект может держать в своей базе данных или в распределенных векторных представлениях. В данном случае человек приходит и со вздохом говорит психотерапевту «Выпнули лузера». После чего Благодаря генерации сложности мы генерим всевозможные гипотезы, соотносим их друг с другом, делаем все это одновременно во всех аспектах, выявляем ту гипотезу, которая победила, формулируем эту гипотезу как некоторый предположительный диагноз, делаем предположение о том, что имеет место катастрофизация при увольнении после первых же слов, и дальше начинаю задавать наводящие вопросы, которые позволяют либо верифицировать данный диагноз, либо двинуться по вот этому многомерному пространству в поисках более диагноза, более подходящего данному соответствию человека, чтобы исключить все гипотетические диагнозы, которые не имеют места быть, а выявить, значит, те, которые имеют место быть. Ну и вот все вот эти вот стрелочки, они описываются некоторыми вероятностями в терминах логики вероятностного вывода. Если мы возьмем это в виде некоторой временной диаграммы, что у нас есть сессии, на каждой сессии у нас происходит схема взаимодействия, то есть у нас в каждой сессии есть различные воздействия этого события. То есть, если переходим к событийной логике Александра Балдачева, например, или похожей моей системе, про которую я тоже рассказывал на одном из первых наших семинаров два года назад, то вот у нас на временной оси есть разные события. В данном случае событиями являются воздействия, где воздействия могут быть либо воздействием психотерапевта, либо реакциями клиента. И эти реакции и воздействия связаны друг с другом как временными, так и причинно-следственными связями. Временные связи фиксируем, а причинно-следственные связи мы выявляем. с помощью логики вероятностного вывода. В свою очередь, воздействия могут быть как диагностические, направленные на постановку диагноза, так и лечебные, направленные на снятие этого диагноза в конечном итоге. И воздействия, и реакции у нас все связано с речевыми паттернами, потому что какова реакция человека и какие измерения в многомерном пространстве мы выявляем и обнаруживаем, зависит от того, что он говорит. То, что мы говорим человеку, то, что мы ему спрашиваем или рекомендуем, оно опять-таки опирается, берется из речевых паттернов, которые мы либо программируем, либо задаем с помощью некоторой сетки каких-то лексем, а дальше осуществляем аугментацию всего этого дела с помощью тех же самых глубоких нейронных литей того же самого Берта. Допустим, если мы хотим спросить человека, если у нас есть, допустим, рисковой паттерн узнать, не выгнали ли тебя с работы, Вот, значит, мы можем иметь паттерн, скажем так, в некоторой базе правил, условно говоря, базе воздействий мы можем иметь выражение, там, увольнение с работы вопросительный знак, а дальше с помощью, там, GPT-3 мы можем этот вопрос генерировать практически бесконечным числом различных способов, чтобы человеку не надоедали повторяющиеся вопросы. если он уже нужден с ними сталкиваться. Но, так или иначе, принципиальным здесь является то, что вот в этой схеме, которая может быть реализована на множестве различных эпизодов различных пациентов, у нас Задействованы все как раз три метода математических. Во-первых, это логика вероятностный вывод, который позволяет как ставить диагноз, так и рекомендовать воздействие в зависимости от соответствующих диагнозов в контексте сействий. сессии, так и корректировка протоколов и воздействий в контекстах сессии эпизода, ну и, наконец, выявление диагностических отношений и эффективных или неэффективных протоколов на множестве эпизодов в процессе на уровне межсессионных взаимодействий. Вот здесь у нас могут быть задействованы вероятностные формальные понятия. Разберем конкретный пример. Как это работает. Это пример, скажем так, эмпирический. Это не пример живого диалога. Это пример просто на пальцах просчета работы той схемы, которую я сейчас описал. Вот у нас приходит человек. Здравствуйте, как у вас дела? Человек говорит, что выкнули лузера по ключевым словам. которые могут быть не обязательно ключевыми словами. Это могут быть некоторые точки в семантическом векторном пространстве, которые привязаны к определенным категориям в пятимерном пространстве. Но, так или иначе, цепляясь за эти слова, мы выявляем такие понятия, как социальная ситуация увольнения и когнитивная ошибка персонализации. Дальше, соответственно, есть, поскольку речь идет о социальной ситуации, то вопрос, кто генерируемой системой. Он направлен на уточнение социальной ситуации. Человек начинает разговаривать, говорить, что дело было на работе, что его там уволили. То есть мы понимаем, что выпнули действительно имеет место к увольнению. То есть мы уже фиксируем увольнение. Окей, по этой оси мы уже поставили точную жирную точку, что у нас увольнение в этом измерении есть. Дальше мы пытаемся понять, какая у нас эмоция. Есть эмоция типа тревога, есть эмоция типа раздражения, которые связаны со спугом или обидой. Пугают или обижены на них, которые уволили. Уточняем эмоцию. Человек подтверждает, что надо платить. Мы знаем, что то, что надо и платить, это связано с тревогой, исходя из экспертных правил или обучения на какой-то выборке, на основе которой мы обучались. Соответственно, дальше мы пытаемся задавать вопросы, значит, про увольнение с работы и подтверждение, соответственно, вот этой вот тревоги. Вот, да, человек говорит «да», тем самым подтверждая, что действительно мы верно угадали социальную ситуацию, эмоции. Дальше задается вопрос, значит, что явилось причиной. Это, так сказать, штатный вопрос. который задается, когда ситуация известна. Соответственно, человек говорит, что ему просто не повезло, ну и мы сразу же хватаемся за это не повезло, потому что оно у нас где-то в правилах либо в векторном пространстве привязано к персонализации. Соответственно, Мы уточняем, мы строим гипотезу, что у нас персонализация, спрашиваем вывод, им виноваты, человек говорит нет, то есть мы не угадали, говорит, что все пропало, а это уже методом логики вероятностного вывода фиксируется, выявляется как катастрофизация. Дальше мы это дело подтверждаем, что вы боитесь, после увольнения не будет. Новые работы в данном случае. Да, пытаем и верифицируем тревогу увольнения и катастрофизации. Полноценный диагноз в трехмерном пространстве. Соответственно, человек подтверждает наш диагноз, дальше мы уже сможем переходить к терапевтическим воздействиям. Ну и, соответственно, это предметная онтология данной задачи, про которую я сейчас рассказывать не буду. Соответственно, реализована данная простейшая задача, чисто которая решает задачу диагностики. Может быть интеграция с тем или иным веб-сервисом, который обеспечивает сервис диалога. где с одной стороны у нас есть контекст, когнитивная база данных, собственно, смычка с векторными моделями для вычисления асимматической близости, если мы работаем не только по ключевым словам. Ну и, наконец, если нам нужно варьировать генерацию фраз, которые мы говорим клиентам, мы можем подключать генеративные модели, ну а собственно вот вся логика, которая вот здесь описана, она вот как раз находится вот в этом сервисе диалога, который задействует контексты базы данных, модели выявления контекстов и генерацию слов, используя какие-то сторонние методы. Ну, наверное, все. То есть, мне кажется… Ну, я давайте быстренько еще немножечко пробегу, чтобы была полная картинка. 

S02 [01:22:22]  : Значит, примерно… Антон, только имей в виду, что у тебя нет модератора, а времени уже… Да-да-да, все, я по этому сейчас… 

S03 [01:22:30]  : я принял я смотрю у меня модератор есть вот на часы у меня там стоят поэтому я сейчас пять минут еще быстренько пробегу и мы перейдем к обсуждению значит вот для задачи цифрового аватара клиента соответственно вот мы тоже описываем некоторую предметную антологию тоже у нас есть проекция этой антологии на некоторую событий но если угодно логику где у нас тоже есть эпизоды есть некоторые события только там у нас уже другая такая частная антология Также мы применяем в логике вероятностную теорию функциональных систем вероятностное формальное понятие для взаимодействия с этими событиями в этих эпизодах. Также мы строим некоторую, можем для конкретной задачи, рекомендации, предложений клиентам строить некоторую архитектуру, более частную, где у нас есть когнитивная база данных и конкретные классификаторы профилей клиентов и предсказатели принятия предложений. В данном частном примере у нас нет ТФС, у нас есть только логиковероятностный вывод и вероятностные формальные понятия. Ну и вот как раз пример численных экспериментов Евгения Евгеньевича по выявлению как раз инвариантов, когда мы выявляем, что у нас там есть такой клакс, как замужняя женщина, проживающая в своем городе, для которой главное в жизни семья – дети. и которые ценят в людях доброту и честность. И есть неженатый мужчина, возможно подросток, который ценит в людях доброту и честность. То есть вот мы получаем не просто кластера каких-то людей в каком-то разреженном векторном пространстве, а мы получаем вполне понятные интерпретации тех сущностей, которые мы выявляем. Ну и второй пример, опять-таки, это ассистент менеджера, где мы строим, решаем немножечко другую прикладную задачу. Мы строим задачу как раз реконструктора, актуализатора клиентских коммуникаций, очень близкую к той задаче, которую мы на одном из семинаров обсуждали, как задача структурирования коммуникаций в группе. То есть, есть здесь как раз, по сути, те кейсы, которые Мы там обсуждали, они вот здесь проявлены, то есть у нас есть сборщик коммуникаций, который выявляет упоминания, эмоции, когнитивные искажения, которые мы выявляем в тексте. И есть когнитивное ядро. в виде вероятностных формальных понятий, которые выявляют темы, на которые участники говорят, и упоминания конкретных людей в конкретных темах, в контексте конкретных тем, и, наконец, типовые реакции типа лайк, дислайк, позитив, негатив в отношении конкретных тем и конкретных участников. Соответственно, мы можем выявлять какие проекты, какие темы, какие начинания, какие задачи позитивно или негативно рассматриваются теми или иными участниками в тех или иных контекстах, ну и для того, чтобы использовать это для каких-то решений как с точки зрения проекта управления, так и с точки зрения персональных коммуникаций. Ну, собственно, все. То есть, на этом я предлагаю перейти к премиям. Поскольку я модератор типа, я тогда давайте перейду к вопросам. Поскольку… Так, значит, пойдем, так. Альтернатив представления и изменения не две, их заметно больше. Так, ну, окей. На слайде нейросимвельная интеграция, соответствие между узлами нейросети и онтологией устанавливается как? Ну, что называется, как устанавливается соответствие между узлами нейросети и онтологией. Что называется, знал бы Прику, был бы в Сочи, Вот, но есть... Сейчас, Игорь, я попытаюсь ответить на твой вопрос. Я это рассказывал. То есть, у меня было на семинаре и есть соответствующие публикации. Есть соответствующие публикации. Идея простая. Можно рассуждать о том, как извлекать знания из нейронных сетей. Я ожидал, что Юрий Бабуров нам про это расскажет, но он не рассказал. Но одно из направлений, которое я видел, это попытка разобраться в том, что происходит на нейронах. Попытка предположить о том, что каждый нейрон со всеми его связями – это, предположительно, некоторый узел в некоторой логической сети, и попытаться вычислить, какую роль в этой гипотетической сети данный искусственный нейрон играет. Например, если мы, допустим, будем считать, что ядерная функция нейрона – это простой сумматор, И если мы предположим, что нейрон передает возбуждение дальше только когда сумма входов больше или равна единице, то тогда, если у нас все входы данного нейрона равняются единице, то тогда этот нейрон работает как дезюнкция. Потому что по любому входу придет сигнал, он все равно выстрелит, потому что всегда будет единица. А вот это получается чисто дезюнктивный нейрон. Если же мы Имеем на входе некоторого нейрона множество связей, где веса всех связей, к примеру, 10 связей, где веса всех связей 0,1, то тогда этот нейрон выстрелит, только если все 10 связей на его входе будут активны. И этот нейрон получается чистой конъюнкцией. И есть соответствующие публикации, там ключевые слова, которые можно гуглить, это soft disjunctive form и soft conjunctive form. То есть есть нормальная конъюнктивная форма, есть нормальная дезюнктивная форма, к которой можно записать любые логические выражения. Вопрос в том, насколько эффективно. Так вот, с этой точки зрения любую любую вероятностную логику можно с той или иной степенью эффективности записать трёхслойной нейронной сетью, где у нас либо на первом уровне будут конъюнктивные нейроны, на втором – дезинъюнктивные, на двух внутренних скрытых клоях, либо наоборот. Ну а софт в данном случае подразумевает, что не обязательно все веса должны быть равны единице. То есть там могут быть промежуточные формы. То есть могут быть нейроны, которые отчасти дезинфективные, отчасти конъюнктивные. 

S02 [01:29:13]  : Антон, можно я уточню этот вопрос, так как это мой вопрос? Вот весь доклад, он в целом достаточно конкретный, про конкретную когнитивную архитектуру. Выглядит так, что вы ее делаете, ну там, в части кода и какие-то как бы вещи, ну как будто реализованы. А вот этот слайд выглядит чисто теоретическим. У меня вопрос. Вот это конкретно то, что ты сейчас говоришь, оно в этой модели тоже как-то реализовано? Или это действительно слайд теоретический, который показывает, что в принципе можно было бы сделать, но вы вообще-то этим пока еще не занимались? 

S03 [01:29:51]  : Значит, этот слайд, он про нейросимульную интеграцию. я догадался. И он не теоретический, он основан на работах, которые делали другие люди. 

S02 [01:30:04]  : В этой модели, которую ты сегодня рассказываешь, это приняется? Значит этот слой можно выбросить без потери смысла. 

S03 [01:30:14]  : Хорошо, принял к сведению. Тезис принят. Так, дальше, дальше идем. Так, вопрос о соответствии с истинной логике. Окей, дискуссион. Итак, про пять принципов. Антон, ты согласен с принципом генерации сложности? Ну, Игорь, я его даже несколькими способами показал, как я… Верно. 

S02 [01:30:37]  : Я ниже дальше по тексту я написал. Хорошо, идем дальше. Конкретно. Да, ну хорошо. 

S03 [01:30:42]  : Давай-то пойдем дальше. Как-то эти описания метания вызывают ассоциации с древним объяснением иммунации. Да, вот как раз про описание метаний. Значит, смотрите, про описание метаний я не буду тратить время, просто возьмите у нас в группе, посмотрите доклад Шумского про сознание и доклад Анила Сетха про то же самое сознание, и вы поймете, что я имею в виду подметаниями. Значит, я просто не буду отнимать время. Я, на самом деле, давайте все-таки отниму, потому что это важно. Идея заключается в том, что вот как раз и Шумский, и Сетх, и Танони, да, они как раз вот рассматривают сознание как как раз некоторый осмысленный, некоторый структурированный обмен информацией между всеми зонами коры. То есть вот то, что феноменологически называется сознательным поведением, или когда мы феноменологически говорим, что у человека есть сознание, И при этом мы в данный момент, при его конкретном поведении, которое регистрируется снаружи человека, и одновременно снимаем его энцефалограмму, мы обнаружим, что в этот момент у него в коре происходит следующее, что сигналы ходят между зонами коры примерно так же, как они нарисованы на этой стрелочке. Причем они ходят туда-сюда, обратно. И как раз именно вот эта вот степень взаимного взаимодействия, она как раз математически описывается знаменитой формулой интегрированной информации, TANONI, которая как раз определяет именно обладание субъектом в данный момент сознания. Так, поэтому я рекомендую настоятельно это посмотреть. Хотя с этим можно спорить. Так, выявление проявляции между известными понятиями – это тоже новое знание. Ну, действительно, новое знание – это выявление новых понятий. Совершенно верно, да, я согласен. То есть, понятие, которого мы не знали, но выявили, Да, это новое понятие, новое знание, новое понятие ОК. Примеры с продажами дешевого водки, о чем, собственно, и найденный вариант, и как система его может найти. Ну, Игорь, смотри, значит, в данном примере В данном примере, для того, чтобы этот инвариант выявился, система должна либо прочитать книжку этого самого Котлера и записать это как инвариант, либо у нее должен быть жизненный опыт, когда она или кто-то несколько раз при уменьшениях продаж увеличивало линейку и в итоге росли продажи. И тогда после двух-трех раз таких действий возникнет инвариант. Вот. То есть, естественно, сам он не возьмётся. Дальше. Владимир Смолин. «Я ничего не слышал про то, что система сама ищет инварианты, но если такие методы есть, то интересно было бы узнать». Значит, Владимиру Смолину рекомендую послушать доклад Евгения Витяева про вероятностные формальные понятия, либо в Гугле набрать «вероятностные формальные понятия Витяев». Так, внедрения системы были или пока только разработка? Пока только теоретическая разработка. Владимир, по сути, если такая система сама находит... Игорь Пивоваров пишет, Владимир, по сути, если такая система сама находит новый инвариант, то это и есть выявление новых понятий, про которые вы написали выше. Полностью согласен. Так, Владимир Смолин, Игорь, это не совсем обязательно, но про это было бы интереснее всего узнать. В общем, Владимир, давайте так, дойдем до конца, вы зададите вопрос, на который хотите узнать ответ. Но слова про выявление инвариантов все-таки произносятся. Да, этим занимается, вероятно, формальное понятие. Так, Игорь Ивоваров очень любопытно про персихотерапевтический диагноз. Слышь, Лечение, но мне кажется, что этот раздел сильно перегружает доклад и мешает понимание основной линии когнитивной архитектуры. Ну, может быть, может быть. Значит, про когнитивную архитектуру я рассказывал на примере продаж. как работают разные модули между собой. Дальше у меня в планах было как раз рассказать три прикладных примера. Может быть я увлекся в этом самом. Да, Игорь, твоя рука, вижу. 

S02 [01:35:24]  : Ты дойди до конца, до вопросов. 

S03 [01:35:26]  : Хорошо, хорошо, хорошо. Тогда напиши, что твоя рука, потому что я не вижу рук в режиме скриншеринга. Согласен с комментарием, что я увлекся разжевыванием психотерапевта. А как же выдача кредита как коррекция когнитивной ошибки? Это шутка, это шутка. Ладно. Очень странный кейс. Место предоставления новой работы уволенному Ну Виктор, я как бы с одной стороны согласен с вами, но с другой стороны, я вам просто свой пример привяжу. Вот у меня была в жизни ситуация, причем достаточно недавно, когда мне было плохо. Вот. Ну и по ряду причин. Я пришел к психотерапевту, он мне дал совершенно конкретное... Он не мог бы... То есть, если бы эта ситуация была связана с увольнением, то он не смог бы мне найти работу, да? То есть, за новой работой ходят в кадровое бюро, а не к психотерапевтам. Но психотерапевт в моей ситуации, он мне помог, так сказать, Скажем так, увеличить комфортность своего самочувствия, чтобы я начал думать о решении каких-то прикладных задач, а не переживать по поводу того, что я не могу изменить. да вот поэтому вот ну и кстати я тоже вот значит раз уж зашла эта тема то есть некоторое понимание меня самого и некоторых моих близких людей что психотерапевты они не только деньги выкачивают они помогают решать реальные проблемы и спасать жизни Это вот реальность. Просто, может быть, не все с этим сталкивались. И есть, кстати, у нас в сообществе люди, я не буду тыкать в них пальцами, но вот некоторым из них визиты к психотерапевту регулярные очень помогут. личных проблем и проблем, которые они иногда создают в нашем сообществе. Надеюсь, никого не обидел, если себя узнали. Так, все рассказы про серфинг, теннисную ракетку руки и прочее уводят от темы. Ну, собственно, у меня задача была вот как бы разжевать на популярном уровне. Может быть, уводят. И да, если это Владимир Смолин, то тут я согласен, потому что Владимир, конечно, человек более глубокий, и такая популярщина не очень интересна, тут согласен. Так, Игорь Пивоваров, вот конкретно для психотерапевтического примера. Генерация сложности понятна, так как нужно, по нескольким словам, восстановить картину. То есть, Андрей Курпатов просто переносит свою профессиональную область на рассуждения о работе мозга. Ну, не знаю. Не знаю, не могу прокомментировать. Так, для слайда про кситерапию, связь речевых конструкций где? Опять. Значит, смотри. Опять-таки, каким образом соответствие, устанавливается соответствие руками? Значит, Игорь, я тебе просто скажу как факт. Значит, на сегодняшний день во всей психотерапевтической практике это устанавливается не то, что руками, это устанавливается головой психотерапевта в большинстве случаев. В ряде случаев это устанавливается руками. Вот, например, в Англии есть статья на эту тему, я могу дать на нее ссылку, я на нее ссылаюсь, можно опять-таки погуглить. значит, архив колонен Cognitive Distortions, там я на эту статью ссылаюсь и рассказываю, что мы с этим делаем, значит, есть просто словари. Есть словари, которые используют англоязычные специалисты в области когнитивно-поведенческой терапии для того, чтобы выявлять когнитивные искажения. Вот. В этой статье, которую я могу дать ссылку, там эти словари приложены в приложениях. 

S02 [01:39:21]  : Это понятнее. На самом деле речь шла не про психотерапевта, а конкретно про систему, про которую ты рассказываешь. Вот у тебя там есть слайд. Промотай, пожалуйста, слайд. У тебя там вопросы, ответы и пример с этим психотерапевтом конкретный. 

S03 [01:39:42]  : Значит, смотри, Игорь, я понял твой вопрос. Значит, смотри. Сейчас я выйду на этот пример. Значит, там у меня есть к этому слайду еще ряд других картинок, которые я уже не могу показать, потому что это уведет нас слишком глубоко. от вершины айсберга но если коротко то в первом приближении это задается безусловно руками потому что как ведут себя системы основанные на машинном обучении любой может узнать не в обиду Виктора Носко будет сказано но просто попользовавшись его психотерапевтическим ботом или поговорив с этой самой как и называется реплика Вот. И чтобы понять, что человек после такого общения, он, если не покорит жизнь с собой, что просто у него произойдет существенное ухудшение его психического самочувствия. Вот. Поэтому в первом делать это только методами машинного обучения просто категорически нельзя но есть понимание что это можно комбинировать то есть есть понимание что можно какие-то каркасы диалогов как бы взаимосвязи между различными вот этими измерениями, типа социальная ситуация, эмоция, чувство, когнитивное искажение описывать руками, но связывать их с конкретными текстами уже методами машинного обучения. Но как бы сетка понятийная должна задаваться вручную, в этом я убежден. окей если ответил на вопрос так дальше так что такое да что такое система и психотерапевт делать принципиально лучше не просто чат бот на правилах ну смотри значит Ну, значит, сейчас в моем понимании не существует ни ИИ-системы психотерапевт, ни ИИ-чатбот на правилах. Вот. То есть, как бы говорить не о чем. Если гипотетически, то я не знаю, как закодировать такое число правил, которые можно описать вот с помощью той системы, которую я рассказал. Может быть, я ее не очень хорошо рассказал. но с помощью чат-бота на правилах это все не опишешь ну и к тому же чат-бот на правилах не будет учиться вот а здесь как раз связи они выявляются на основе на основе логики вероятностного вывода и формирование вариантов на основе терапевтических сессий то есть мы же в конечном итоге значит ну опять-таки вот то что я рассказал вот сейчас да вот то есть я рассказывал вот этот конкретный кейс, который кончается этой стучкой, здесь только диагностика. Если у нас только диагностика, то, естественно, мы все должны прописать вручную. Но если мы, кроме диагностики, осуществляем еще и лечение, и если мы имеем возможность верифицировать эффективность диагностики по ходу этой диагностики, подключая, я про это говорил, если мы быстрее достигаем верификации диагноза, значит, и исключение всех остальных диагнозов, то у нас срабатывает акцептор результата действия, и, соответственно, те схемы ведения диалога, которые были успешны в прошлом, они становятся успешными инвариантами. то тогда у нас возникает еще и обучение. То есть у нас, грубо говоря, после того, как такой психотерапевт, самообучающийся, там три раза разговор, начинающийся с выпнуния лузера, будет кончать, значит, точно поставленным диагнозом катастрофизация при увольнении, вот, если он после трех раз начнет делать это все быстрее, быстрее, быстрее, то как бы вот мы уже получили, как называется, увеличение пропускной способности врача-психотерапевта, если это важно, или повышение точности его диагноза. Так, значит, дальше Сергей Терехов. Как из разряженных кластеров, которые понятно, как строить, вам понятно? Давайте 18-го числа с вами поговорим, как вам понятно. 

S04 [01:43:52]  : Да, конечно, понятно. Это закрытый вопрос, его известно, как решать. 

S03 [01:43:56]  : Хорошо, значит, восемнадцатого числа вы расскажете. 

S04 [01:43:59]  : А это как раз простое место, а вот дальше там сложно. Нет, ну смотрите, замужняя женщина, как, так сказать, семейное положение, атрибут, проживание... Нет, смопировать словесные атрибуты в какую-то абракадабранную фразу, просто заменив нолики, единички, значением женщина или мужчина там женщина женщина замужняя незамужняя замужняя и так далее собрать текстовое название для единичек это конечно несложно вот если я правильно понимаю покажите вот слайд который там да вот смотрите что здесь это самое Вот смотрите, для которой главное в жизни. Вот как сделан вывод, что из той атрибутики, которая есть, следует, что для этой женщины вот это именно главное в жизни. Она там указана, значит, и так далее. То есть, смотрите, правильно ли я понимаю, что для сделать... Ценности. 

S03 [01:45:04]  : Ну, смотрите, здесь ответ простой. Евгений Евгеньевич меня может поправить, потому что это его материалы, но сколько бы не понимаю, там был множественный классификатор, где ценности, где одна из позиций, что для вас... Там был вопросник, что для вас главное в жизни, и там была опция семья и дети. Вот и все. 

S04 [01:45:21]  : если это один в один соответствие, просто приведенное к правильной грамматической форме, тогда да, вопросов нет никаких. а если это вещь, которая следствие выводит, нетривиальное, из атрибутов, которые просто информативные, то есть когда знание получается за информацией, то тогда это вопрос. а действительно построить кластер разреженное, это он и не знает сейчас, не хочу отвлекаться, книжки стоят там по кластерам. 

S03 [01:45:51]  : Главное это определить число кластеров. 

S04 [01:45:57]  : Это все тоже, Антон, это вопрос математический, как только вопрос сформулирован как математический, в нашем контексте можно считать, что он решен, за исключением, конечно, каких-нибудь там НП-полных задач. А вот если задача уже сформулирована, формализована и она уже, так сказать, поставлена, то дальше это вопрос уже, так сказать, там инкрементальной какой-то работы. Дальше это техническая наша с вами работа. Это простая вещь. А вот сделать вывод, что это для нее главное только из-за того, что вот мы видим три там атрибута, где нет явного указания, что для нее главное в жизни. Может она думает, что это главное в жизни, может она врет. Может, главное в жизни у нее туфли какие-то красные? 

S03 [01:46:38]  : Ну, смотрите, здесь опять-таки все зависит от той онтологии, которую мы напишем. 

S04 [01:46:44]  : Окей, то есть это все-таки такое продуцирование, прямое мэппинг разреженных наборов атрибутов на их напоминающий естественный язык, текстовое описание. 

S03 [01:46:56]  : Нет, нет, нет. Смотрите, здесь, смотрите, текстовое описание, оно здесь вообще просто ни о чем. То есть, ну, так сказать, это просто для... Текстовое описание здесь дано именно для задач презентации. То есть, в данном случае здесь восьмой класс — это одна комбинация атрибутов, одиннадцатый класс — это другая комбинация атрибутов. 

S04 [01:47:14]  : Понятно, понятно, понятно. Нет, я там... Меня интересовал именно вопрос следующий. Вербализация на фразах естественного языка ответов формальной системы. Это задача, которая очень важна. 

S03 [01:47:24]  : Я понял, значит, скажем так, вербализация это вообще не тема данной работы, данного доклада про вербализацию. Хорошо, все услышал. Про вербализацию есть другая работа, которую мы делали в прошлом году, про нее можно отдельно разговаривать. 

S04 [01:47:44]  : Окей, все, я услышал. Спасибо, Антон. Вот. Но рука у меня поднята по другому вопросу. Хорошо. Оставляю ее поднятой. 

S03 [01:47:50]  : Да. Значит, кстати, про вербализацию, Игорь, значит, я буду, по-моему, в сентябре рассказывать про interpretable natural language processing, делать обзор. Вот там вот можем вернуться к теме вербализации. Если на английском хотите, я вам пошлю доклад. Он был раньше. Так вот, мы дошли до Александра Балдачева. В чем отличие от старых добренных экспортных систем, дополненных Но смотрите, значит, если мы возьмем логикой вероятностный вывод, то действительно мы дополнили семантической БД вероятностной логикой. Окей, это раз. Но в добрых старых экспертных системах нет вероятностных формальных понятий. Это первое. Потому что там знания задаются экспертами. И второе, там нет теории функциональных систем. потому что вероятности не меняются в зависимости от успеха или не успеха тех или иных предсказаний. Вот, собственно, отличие. А в чистом виде логика вероятностный вывод – это вероятностная логика и семантика, расширяющая возможности вероятных систем. Игорь, я вижу твою руку, но хочу прочитать коммент Алекса Бура. После каждого общения с чат-ботом большой компании можно смело идти к психологу. Я бы добавил, если успеешь. Если успеешь дойти к психологу, то да. Игорь, пожалуйста, твой вопрос. 

S02 [01:49:28]  : Да, спасибо. У меня тут засверлили сейчас в моменте. Я хочу сказать двойное спасибо за доклад. Это был, на мой взгляд, один из самых интересных докладов, который я в этом семинаре видел. И отдельное большое спасибо за объяснение этого принципа генерации сложности. потому что я наконец понял, что туда вкладывает доктор Курпатов, и что это как бы не очень имеет отношение вообще к обычной нормальной работе мозга, но к некоторым кейсам работы мозга действительно имеет непосредственное отношение. В данном случае я это прям понял. Огромное спасибо. Но чего я не понял, так это про... как бы в каком-то смысле я не очень понял про всю когнитивную архитектуру потому что мне кажется что внимание было уделено не тем не тем вещам на которые которые нужны сейчас секунду я попробую наушники ставлю 

S03 [01:50:44]  : Я, по-моему, уже знаю ответ, но я дослушаю до конца. 

S02 [01:50:48]  : Да, голос лучше в наушнике, а то меня тут сверлят. Блин, вечером сверлят, 8 вечера. Смотри, как бы мысль такая, ты очень много внимания уделил там понятие это антологии как она устроена нормализации баз данных какая она революционно устроена и это как бы все понятные вещи про них можно сильно много не рассказывать и в этом смысле я тоже понимаю вопрос был до чего в чем отличие от старых добрых экспертных систем вот как бы семантическая бд и вероятностный вывод но вот было два момента которые мне кажется были принципиально важными про которые я честно не очень понял в результате и первая вещь это про некое выявление вариантов вот когда ты приводил пример с продажами то центральная идея была такая что это когнитивная архитектура смотрит на историю продаж видит падение продаж и каким-то образом выявляет там некий новый инвариант и предлагает на его базе решение одно дело если у него список рецептов этих инвариантов записан в базе данных тогда я понимаю что она просто перебирает эти решения которые есть из них выбирает какой-то и предлагает это одна история но если она каким и тогда это все равно та же самая экспортная система ну просто в которую руками внесли данные и но если каким-то образом система вот этот инвариант сама выявляет то вот про это нужно было бы рассказать как-то подробнее каким это каким образом происходит 

S03 [01:52:21]  : Ну смотри, Игорь, я понял вопрос. Спасибо. Видимо, я допускаю, что я где-то сделал перекос в изложении. Спасибо при этом за высокую оценку. Я реально польщен. Дорогого стоит. Ответ на твой вопрос. Я издалека начну. У нас есть еще время. Как человек учится и как человек живет в жизни? Что-то он в школе узнал? Что-то ему друзья в подъезде рассказали, а до чего-то он сам допер. А что-то родители. Человек часть информации воспринимает в виде знаний структурированных. А часть информации он воспринимает в результате самообучения. При этом, после того, как он часть информации получил в результате самообучения, он эту информацию дальше уже в виде знаний может давать другим. То есть это, в моем понимании, если мы говорим как о людях, так и о системе AGI, это две обязательных составляющих. И если я не говорил явно о том, что в общем, в системе эти две части, они являются равнозначны, то это вот мой косяк, потому что в моем понимании они не равнозначны. Это пункт 1. Пункт 2. Если мы говорим о практической стороне, то какие-то из этих составляющих в каких-то случаях могут быть более практические, а какие-то менее практические. Я приведу пример. Например, если мы пишем чат-бота, для психотерапевтического, то я убежден, что, так сказать, лучше его запрограммировать вручную, да, по крайней мере, там он, если он что-то, либо он ничего не скажет, Либо он скажет по делу, а фантазировать ему нести колесицу он не будет. И в этом смысле, если мы программируем чат-бота, то лучше его для начала сделать на правилах, и уже будет какая-то польза, а потом уже это можно совершенствовать. Вот, с одной стороны. С другой стороны, если мы строим систему, там, к примеру, допустим, для того, чтобы она автоматически там училась пинг-понг играть, да, или для того, чтобы она автоматически, ну, пинг-понг играть в развлечения, ну, скажем так, и систему, которая должна работать в незнакомых условиях, да, то есть мы пытаемся построить там нано-бота, который должен уметь доставить лекарства в какой-то орган тела, но мы не знаем, какие ощущения может испытывать конкретный нанобот. Он должен обучаться. В каких-то ситуациях, когда мы не знаем правила, мы эти правила мы должны сделать так чтобы система обучалась да ну вот не очень удачных пример я могу привести что если мы хотим построить торгового бота да то нам не обязательно закладывать все правила, мы можем написать такого торгового бота, который сам все правила выявит. На самом деле это тоже ошибка, потому что если мы не хотим сразу попасть в минус, то нам лучше все-таки эти правила запрограммировать, хотя бы основные. Ну вот, то есть и то, и другое. Просто в каких-то конкретных случаях правила есть, и их лучше заложить, если о них есть. А в тех случаях, когда правил нету или существующих правил недостаточно, естественно система должна иметь возможность их выучить. 

S02 [01:56:17]  : Я ответил? Да, но эта система, она выявляет какие-то новые варианты или нет? 

S03 [01:56:23]  : Конечно. Так, собственно, вероятно, Игорь, смотри, вероятно, я вот, видимо, зря. Плохо. Я, как Владимир Смолин, тоже буду сейчас жаловаться, что никто меня не понимает сейчас. Вот, смотри. выявление диагностических отношений и выявление эффективных или неэффективных протоколов на множестве эпизодов. То есть вот мы работаем каким-то образом с пациентами, допустим, и фиксируем то, как мы с ними работаем, а потом мы смотрим, в каких случаях после наших воздействий у человека диагнозы снимаются, а в каких случаях нет. И мы выявляем, что вот эта вот совокупность манипуляций при конкретных диагнозах, она привела к исчезновению этого диагноза при последующем приходе, а в каких-то нет. И вот, пожалуйста, вот теперь два формальных понятия при одном и том же диагнозе – эффективное воздействие и неэффективное воздействие. Ну просто вот пример. Ну и любые другие ситуации тоже можно взять. То есть да, конечно, мы находимся... Или вот, пожалуйста, пример. То есть мы, например, выявили, что... Сейчас где-то у меня картинка... Вот как раз с этими. То есть мы, например, мы сегментируем аудиторию не для того, чтобы там просто, значит, текстом выражать, описывать наш социум, а для того, чтобы просто понимать, можем ли мы там им рекомендовать кредитные продукты или нет. Например, мы понимаем, что представители восьмого класса принимают предложение на кредит, А одиннадцатого наоборот, одиннадцатого принимают предложение на кредит, а восьмого класса на страховку. И соответственно, как только мы видим, что у нас там замужняя женщина, проживающая в родном городе, мы знаем, что ей можно страховку рекомендовать. А если не женатый подросток, то тогда очевидно кредит. Ну, к примеру. То есть на самом деле здесь возможность выявления инвариантов и наличие в базе данных инвариантов позволяет существенно снизить косты, извините за выражение, при принятии решений. То есть принятие решений на основе уже имеющихся инвариантов, оно просто дешевле вычислительно. И основная фишка и смысл, с моей точки зрения, бизнес-смысл под системой выявления инвариантов, что нам не нужен инференс. То есть, чтобы принять решение по логико-вероятностному выводу, нам нужен инференс, который дорогой, а для того, чтобы по всем возможным правилам и значениям атрибутов. А если мы выявили инвариант, то мы просто вот знаем, что с этим инвариантом делать. Поэтому выявление их, конечно, важно. Считаю это как индексирование. То есть выявление инвариантов – это, по сути, семантическое индексирование. То есть ты можешь искать по тексту, по базе данных без индекса, а можешь с индексом. Затраты на индексирование, они тоже стоят, то есть нужно эти индексы где-то хранить и обновлять каждый раз при инсерте или апдейте или делите, но зато если индекс на колоночку есть, по ней ищется все быстрее. Вот CINVARIAN вариант и это то же самое. Тегнитивная оптимизация. Шаблонное мышление. Люди любят... Что такое шаблоны программирования? Это инварианты. Вот поэтому сейчас у нас учат люди... Ладно, это я уже сейчас уйду. Так, рука Сергея Терехова. 

S04 [02:00:16]  : Ну, во-первых, Антон, позволь мне присоединиться к благодарности со стороны Игоря. Причем я хочу, знаете, какую вещь сказать, такую важную. У меня есть такая тетрадочка, вот такая вот замечательная. Она была начата мною в каком-то 2001 году. Это тетрадочка с семинарами. И вот последняя страница этой тетрадочки это конспект твоего доклада. То есть эта тетрадочка у меня ей там 15 лет. Она закончилась на твоем последнем докладе и поэтому вот он у меня остался. Я еще закрываю. Она полна завершена полностью. Спасибо тебе огромное. Комментарий у меня вот какой вот какой был. у тебя прозвучало, ну не у тебя, но ты это озвучил, вот такое как бы отождествление системы 1 и системы 2 между собой, как вот условно говоря там нейронные сети и там логические какие-то системы. в действительности ситуация, вот она не в этой плоскости происходит разделение. Но я приведу простой пример. Всегда, когда я делаю какую-то нейронную систему, у меня всегда на входе стоят какие-то кластеры. Те или иные разреженные, арт-кластеры или нейронный газ, в зависимости от того, что мне нужно, или карта Кахонена, или просто какие-то кластеры, какие-то структуры. И я первым делом отвечаю на простой вопрос. Новый пример. Он близок к центроиду. Центроид найдется, естественно. Он близок к центроиду. Если близок, я могу реактивно ответить очень быстро. Я могу сразу же либо прямо приписанно к этому кластеру что делать, либо какая-то маленькая нейросетёжка, которая быстро реактивно отвечает. Это как бы быстрый ответ. А если, условно говоря, я далеко от кластеров или я близок одновременно к нескольким кластерам и не могу между ними выбрать, то я могу пойти на следующий уровень поиска. Могу обратиться к ассоциативной памяти, посмотреть, что оттуда, какой мне образ придет его, сравниться входным образом и так далее. Если я увижу, что это у меня там не работает, я могу пойти по еще более высокому кругу. Например, взять ассоциативную память следующего уровня и сравнить ассоциативные образы второго уровня с первым. Если они матчатся между собой, тогда я подтверждаю гипотезу. То есть все инженеры, все люди, которые работают с нейронными сетями много лет, но я к таким отношусь, У них, конечно, любые такие нейронные системы, они вот такие многоблочные, многоуровневые, у каждого там свои под разные задачи и так далее. И они могут работать как быстро, так и медленно. Это вопрос... Ну, во-первых, я уволен, так сказать, им задавать такую архитектурную ситуацию, а вообще, так говоря, они каждый раз отвечают, на какую ситуацию они могут отреагировать быстро. Я могу и запретить им медленно думать и в восстательной памяти копаться, могу разрешить. Это вот что касается этих систем. Теперь логические системы, они устроены точно так же. Можно построить первый слой правил, которые быстро работают в условиях жестко наложенных ограничений. Например, точно совершенно не больше, чем 3 прохода по цепочке правил. Все, что лучшее, прошлись по всем слоям этих самых трех уровней. Лучшее, что нашли, Сравнили между собой, отличается или нет, приняли это решение, отреагировали быстро. Могу запустить это на более длительный цикл. Например, я могу перейти на подгрузить более большую логическую систему. Эта большая, более логическая система может обратиться к какому-то архиву с запросом, чтобы получить дополнительные атрибуты, которые обогащают мою задачу. Она даже может пойти в интернет, задать вопрос. Например, если это текстовая информация, я могу обратиться к словарям Синонима, могу и не обратиться. То есть, вся обработка логическая, полностью абсолютно аналогическая остается. То есть, это вот запрос, там ответ, сравнение и так далее. Но она тоже может работать и медленно, и быстро. То есть резюме с моего собственного комментария такое, что система 1 и система 2 – это не есть там нейросеть логика. Это способ того, насколько система сама внутренне рефлексивна, в каждой системе есть своя рефлексия, как она рефлексивно готова работать. может ли она подняет решение, что она может дать быстрый ответ, тогда она его дает, или она такое решение принять не может, или ей запретили по условиям, использовали по контексту, например, тогда она идет на длинные круги. то есть нет здесь противопоставления, что матчинг один в один нейросеть логика и система 1 и система 2. вот я просто хочу на это обратить внимание. 

S03 [02:04:59]  : Ну да, я соглашусь, потому что на самом деле мой собственный пример про то, что работа по инвариантам и работа по логиковероятностному выводу – это как раз другой пример. По инвариантам быстро, это тот случай, когда попали рядом с центроидом, с центром тяжести, с центроид кластера. А если рядом не попали, то тогда запускаем ЛВВ и тогда все долго. Ок. Хорошо. Согласен. Спасибо еще раз тебе. Спасибо. Спасибо. Значит, Александр, пожалуйста. 

S00 [02:05:43]  : Добрый день всем. Антон, тоже добрый вечер. Большое спасибо за доклад. Значит, первый мой комментарий, ну не первый, а один из первых, который я записал. Это у меня Сергей сорвал, как бы уже все ликвидировал. Я тоже самое хотел сказать, что обращение графу знаний может быть совершенно быстрым логическим выводом, гораздо быстрее, чем что-то, поиск какой-то по нейронной сети. И вообще противопоставления здесь вот двух систем конемана я вообще не вижу, как сюда вообще ложиться, каким образом. Тем более, что в вашем рассказе есть некоторое неразделение. Особенно, когда рассказывал про яблоко, непосредственная данность, непосредственное восприятие чего-то. Вот то, что я воспринимаю без мышления. Вот я вижу, что яблоко и дано яблоко. Или я чувствую в руке яблоко. Я не думаю. Сразу мне дано, именно как восприятие. Есть мышление. Когда я начинаю мыслить, когда я устрою гипотезы, когда я ищу различные ответы. И вот нужно четко различать вот эти вещи, которые даны даже у врача, у психотерапевта есть. Вот он смотрит на человека, и у него сразу возникает полное решение. И другое дело, он смотрит, задает вопросы, ставит галочки, пробегает по разным тестам и выводит что-то. Различие между двумя этими вещами непосредственной данностью, и трейдером может непосредственно данность быть какая-то, и междумыслительной деятельностью – это не было проведено. Основной мой, конечно, пассаж будет касаться моего комментария по поводу экспертных систем. И немножко с дополнением таким. Допустим, если бы я к вам подошел и сказал, Антон, давайте мы сделаем экспертную систему, улучшим с учетом всех ваших знаний. Да, хорошо, давайте. Что мы сделаем? Давайте в экспертной системе старых там не было семантической базы данных. Давайте заменим семантическую базу данных. Там ручной ввод был всех правил и не было автоматического выделения вариантов, объектов. Давайте добавим сюда. А их не всегда можно выделить точно. Давайте добавим туда еще вероятностный вывод. И мы получим то, что вы сейчас получили. Вот абсолютно. То есть я мог бы слушать только вас и только Евгения Витяева, еще каких-то задач на подход, и мы получили бы то, что вы сейчас. Знаете, к чему я веду? Что ваши первые три слайда можно выкидывать. То есть то, что вы предъявляли как какую-то концептуальную основу для вашей разработки, ее нет. То есть, своими словами, то, что там была фамилия Курпатов, это никак не повлияло на то, что вы сделали. И история с этой сложностью я, Игорь, поддержу тоже. По сути, это не генерация сложности, а генерация данных по имеющейся сложности. В вашем примере про молодого человека, который ждал, он не генерировал никакой сложности. Он просто генерировал данные. И в этом плане наиболее лучшим примером был бы Акрын, который сидел бы целый день и пел про все, что видит. Он не генерировал никакой сложности, он только повторял все, что видит. И ваш молодой человек тоже не генерировал никакой сложности, он просто генерировал гипотезы на основе той сложности, которая у него есть в голове. Это тоже лишний какой-то элемент. И в первых слайдах было по кругу различные какие-то элементы, и вы упомянули в вашем рассказе только те элементы, которые я слышал от вас – это задачный подход, ваша антология, еще чего-то. То есть от Сбера там как бы не было никакой. Но в итоге получилось модифицированное. Экспертная система, в которую данные вводятся не только на начальном этапе, а еще в результате анализа деятельности. То, что я где-то в году 2012, когда делал симметрическую систему первую, назвал парсель деятельности. То есть ценно не сами данные, которые лежат, а что с ними совершают. И вот если пар сидит в деятельность, то тогда мы получим наиболее точное представление предметной области. Скажем даже вот так, что ценно не сама статья, которую получил человек, в результате своей деятельности, по составлению, а вот сам процесс, который он делал, что он искал, где он искал, какие были ошибки, какие он исправления делал, вот этот парс в деятельности гораздо ценнее, чем тот результат текста, который он получил, нам ценнее даже с точки зрения анализа. и анализа симбольного, анализа семантического, и тем более анализа с помощью ML-технологии. То есть когда мы будем парсить не текст конечный, а парсить деятельность. То есть по сути вы рассказали, что как можно с помощью экспертных систем реализовать деятельность и при помощи парсинга этой деятельности модернизировать и дополнять эти экспертные системы. спасибо большое, да, ну и маленькое замечание, ну как бы не замечание, так просто, что все-таки событийная антология и тех проблем, которые вы там разделение на объекты неизменные, на объекты меняющиеся, то есть там все гораздо проще получается, и все проблемы с размерными Свойствами, отношениями решаются элементарно, не так, как в РДФ. Можно было просто взять мою базу данных и подложить вам, и она бы работала великолепно. 

S03 [02:11:19]  : Смотрите, во-первых, я не знаю, что вы подразумеваете под вашей базой данных. Исходя из того, что я рассказывал, то, что вы делаете, ничем отличается от того, что я рассказывал два года назад на семинаре. То есть, если вы до меня не смогли донести разницу, чем ваш субъективный подход отличается от моей событийной модели, которая была из сценариев. Времени было мало. Если я до сих пор не понял, в чем разница, кроме названий и языка, то, значит, вам, видимо, как и мне, нужно совершенствовать свои представления. Я никакой разницы не вижу. То есть, как структуру исходных данных, семантических, я использую ту же модель, примерно, что и вы. 

S00 [02:12:10]  : Нет, принципиально разная модель. Александр, тогда значит… Значит, я не сумел. Да, это совершенно моя… Сейчас я заканчиваю статью. Хорошо. 

S03 [02:12:22]  : Да. Это один момент. Насчет генерации сложно, насчет того, что не сделали ничего нового. Но смотрите, я тоже могу сказать, что... Опять-таки, может быть, я субъективно, но можно взять из трех кирпичей и сложить пирамидку. Поставить два кирпича и сверху еще один. Получится буква П из кирпичей. А можно из кирпичей построить Кремль. Да, ну, казалось бы, ну, так сказать, ну, подумаешь, Кремль, ну, взяли просто, взяли много кирпичей, поставили один на другой, вот получился Кремль. Ну, что за ерунда? Что вы предлагаете? Вот, поэтому, когда мы говорим, что вы ничего не сделали, кроме как добавили к экспертным системам вероятностное формальное понятие Петра Кузьмича... Нет, ну, Александр, я говорю... А что? 

S00 [02:13:10]  : Нет, нет, нет, вы неправильно поняли меня. Основной мой посыл не то, что вы ничего нового не сделали, вы очень много нового сделали. Мой посыл тот, что к этому новому ничего не имеет никакого отношения ваши первые три слайда. Прониеросимованную интеграцию, да. Скажи так, что в этой системе был вход от Сбера, что вы сделали? 

S03 [02:13:33]  : Какое предложение, какая реализация была от Сбера? 

S00 [02:13:36]  : Я видел только ваше и Витяева. 

S03 [02:13:52]  : Нет, ну подождите, Александр, я сейчас рассказываю работу, которая была сделана совместно. То есть, вся математика, все математика, она даже не моя, вся математика Витяева. 

S00 [02:14:06]  : Да, да, я говорю, математика и онтология ваша. Да. А что от Збера? 

S03 [02:14:15]  : Заказ. Заказ. Хорошо. Отлично. Причем здесь заказ? Смотрите, Алексей, коллеги, нам уже нужно закругляться, но давайте я коротко отвечу на ваш вопрос, чтобы нам в дискуссию не ходить. Значит, здесь задача была как раз именно по увязке. вот тех принципов, про которые я рассказывал в начале. Увязка их с одной стороны с формальными материческими методами Евгения Генича Витяева и системой категории Егорычева. А с другой стороны, увязка их с теми конкретными бизнес-кейсами, которые были в наличии. Проработка бизнес-кейсов и соединение этого в непротиворечивую конструкцию – это была задача. Ну и последнее, значит, про генерацию сложности. Ну про генерацию сложности я просто с вами не согласен. То есть вы называете это данными, то есть тогда нам нужно сейчас уходить в дискуссию, что такое сложность, то есть когда человек, если человек представляет, что его любимую девушку разрезал трамвай. Это не генерация данных, это генерация... Никакой новой сложности там нет. Окей. Это ваша позиция, с которой я не согласен, но давайте сейчас не будем устраивать дискуссию по поводу того, что такое сложность. Коллеги? раз договорились не устраивать дискуссию давайте не будем да нет нет по поводу того что такое сложность давайте отдельно значит на эту тему поговорим всем спасибо сергей вам значит по поводу значит кластеризации я с вами с одной стороны согласен с другой стороны приглашаю вас на внеплановый семинар восемнадцатого числа ну антон антон понимаешь но 

S04 [02:16:27]  : вот эта задача здесь такая книжка вот книжка такая вот называется дата кластер и так далее в этой книжке но довольно-довольно старая там или там уже 15 или 20 так далее вот ты видишь сколько там закладок моих доска там лежит да и так далее Изложено столько всего про кластеры и как чего можно сделать, как чего нельзя, где ходить, где куда не ходить, где какие метрики, где какие там можно ИИДИ использовать или не надо, или групповые там пульпиляционные изучения. Столько всего, но там вот эти вот тут китайцы, китайцы же они там все аккуратно описывают, что вопрос не в том, как методику построить в данном случае, А вопрос в том, как, условно говоря, если, например, тебе нужно что-то побыстрее сделать. Или тебе нужно как-нибудь контрастировать специально, или тебе нужно какую-то там... У тебя признаки очень сильно связаны между собой, и ты не можешь по каждому из признаков вычислять отдельное, так сказать, его наличие, потому что они замещают друг друга. Там вот эта женщина мог быть признаком, а мог быть еще там существо, которое там родила ребенка. Так вот, признак родила ребенка – это тоже женщина, но он замещает признак женщины, у которой есть явность. И вот когда вот такого типа какие-то вещи неортогональные есть, там могут возникать какие-то вопросы, но они не математического плана. Это вопросы именно проекции математических достижений, которые есть. Там и топологические методы. Все, что на свете бывает, все рассмотрено уже давно. Но, Евгений Евгеньевич, можем поговорить. Можем даже спортивное состязание устроить. 

S03 [02:18:13]  : Коллеги, очень важное. Евгений Евгеньевич, давайте так. Вот сейчас обменяемся репликами. Сергей, ваша реплика пленника. Евгений Евгеньевич, можно расшифровать немножко? 

S04 [02:18:25]  : Евгений Евгеньевич, может быть вы просто выскажите. 

S03 [02:18:32]  : у меня просьба вы выскажитесь сейчас вот по первых потому что сергей сказал и может быть вы еще как бы подведете итог вот какие-то вопросы которые я не ответил может быть вы ответите И на этом закруглимся. А, Сергей, по поводу кластеризации мы потом еще 18 числа отдельно с вами поговорим. Евгений Евгеньевич, пожалуйста, подведите итог. 

S01 [02:18:57]  : Нет, я отвечу Сергею. Дело в том, что та кластеризация, которая получена, у нее, во-первых, принцип совершенно другой. Те методы кластеризации, которые есть, они делаются на основании некоторого, так сказать, сверхкритерия. 

S04 [02:19:12]  : А во-вторых... Нет, нет, есть популяционные, есть контрастирующие, есть непредполагающие. И есть очень-очень много чего. 

S01 [02:19:22]  : Следующее. Дело в том, что кластеризация, которая делана, основана на правилах. Кластеризация на правилах, чтобы получить неподвижную точку непротиворечивую, для этого надо доказать тот результат, который нами получили. Без этого результата это невозможно в принципе. Поэтому в принципе не могло быть такого метода кластеризации. 

S04 [02:19:41]  : Евгений Евгеньевич, мы с вами уже на эту тему говорили. Вы закладываете в вашей логической системе наличие остановки. Вот если вы гипотезу о том, что ваши логические утверждения, которые потом однозначно производят кластеризацию, останавливаются обязательно, то в этом случае работает то, что вы говорите. Но, к сожалению, доказать тот факт, что любые ваши логические построения остановятся, вы не сможете, потому что задача не разрешена. 

S01 [02:20:05]  : Поэтому, когда вы говорите… Нам она разрешена. Дело в том, что те логические замыкания по правилам, которые у нас получаются, мы доказываем, что они логически непротиворечивы и замыкаются сами на себя, если все правила обнаружены за один такт. 

S04 [02:20:24]  : Из этого не следует, что не существует какой-то комбинации логических утверждений, которые не остановятся при выводе? Вы показываете, что то, что вы обнаруживаете таким способом, оно устойчиво, но вы не исчерпываете всех элементов множества. Но это математический разговор. 

S03 [02:20:39]  : Да, Евгений Евгеньевич, спасибо. У вас, значит, вот по поводу кластеризации у нас будет отдельный семинар 18-го числа. Вот, если Сергей Терехов... А что за семинар? 

S04 [02:20:52]  : Откуда, кто, модератор откуда взялся? 

S03 [02:20:55]  : Давайте так, мы сейчас подведем итог. Евгений Евгеньевич, у вас по содержанию доклада какие-то еще комментарии есть? Или ответы на вопросы, которые я недостаточно четко ответил? 

S01 [02:21:10]  : Ну, был один обзор по поводу инвариантов, но это опять же те самые вероятностные формальные понятия. А в целом, по работе, дело в том, что там, конечно, с принципами, которые формулировал Курпатов, можно было бы разбираться отдельно, причем отдельно в докладах. Насколько они действительно точны, насколько они хорошо изложены в его книжке «Мышление», насколько хорошо они могут быть мотивированы. математизированы и сведены к тем принципам, которые у нас есть, это отдельные, самостоятельные, может быть, обсуждения. 

S03 [02:21:45]  : Хорошо. Евгений Евгеньевич, спасибо. Я, кстати, вот по этому поводу есть статья на русском и на английском языке на архиве. Соответственно, вот я предлагаю всем заинтересованным с этой статьей ознакомиться на русском или на английском. И если будет желание, тогда, может быть, можно будет попросить Евгеньевича вот как раз именно эту сторону математическую, так сказать, отдельно обсудить. Вот. Но на этом давайте я всем скажу спасибо. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
