## 30 июня - Вероятностная (нечеткая) семантическая логика - новая надежда или отжившее старое? - Круглый стол (Александр Болдачев, Юрий Бабуров, Евгений Витяев, Захар Понимаш, Антон Колонин) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/tbzCrmwZ60k/hqdefault.jpg)](https://youtu.be/tbzCrmwZ60k)

Суммаризация семинара:

ТЕМА: Вероятностная и нечеткая семантическая логика в контексте новой надежды или отжившей старой. Обсуждение роли и применения логики на основе небинарных и небулевских операций в оценке истинности и достоверности фактов и понятий.

СУТЬ:
- Семинар посвящен дебатам между символистами и коннекционистами, а также возможному диалогу между ними.
- Основной темой является обсуждение вероятностной и нечеткой семантической логики как инструментов для построения моделей и анализа данных.
- Фокус на некоторых когнитивных функциях, выполняемых путем работы с графами и отношениями, которые основываются на небинарной логике.

ДЕТАЛИ:
- Приведен пример работы человека, обучающегося на основе определенных правил, где после начального обучения и 81% точности в задачах умножения и сложения, система демонстрирует отсутствие обучаемости.
- Рассмотрена теорема, согласно которой система анализирует данные без ошибок, находит максимально специфические правила и анализирует их полностью.
- Обсуждается дифференциация стимулов как процесс обучения, который включает все более тонкие стимулы и их автоматическое включение в правила системы.

РЕЗУЛЬТАТЫ:
- Демонстрация потенциала вероятностной семантической логики как инструмента для построения моделей и анализа данных.
- Приведение примеров экспериментов, которые показывают возможности системы Евгения Евгеньевича Витяева.
- Обсуждение практического применения системы, включая обнаружение причинных связей и сравнение с глубоким обучением, где система показывает высокую точность, но сниженную производительность из-за отсутствия проблемы забывания.

ЗАКЛЮЧЕНИЕ:
- Вероятностная и нечеткая семантическая логика представлена как инструмент, способный решать сложные задачи анализа данных и моделирования, хотя и имеет свои ограничения и недостатки, такие как необходимость формирования определенных состояний или слов, и необходимость механизма формирования этих фраз.
- Обсуждение того, как эта логика может быть использована для интерпретационного логического вывода и 









S05 [00:00:03]  : Да, коллеги, всем добрый вечер. Сегодня у нас новые песни о главном. Очередная битва символистов с когнитивистами, или, точнее, коннекционистами. А также, может быть, попытка организовать мир и дружбу между ними. Значит, у нас шесть докладчиков. Я один из них, поэтому я, наверное, возьму наглость на себя выступить первым. Обозначу тему, а потом предлагаю докладчикам на общих основаниях в чате писать, кто хочет выступить следом. Ну и, соответственно, в таком порядке и будем выступать, если не будет никаких других предложений, которые можно, опять-таки, участникам семинара, докладчикам. предлагать. Ну и предполагается, что каждому докладчику дается 15, максимум 20 минут. Ну и порядка 5 минут на короткие вопросы-ответы, на понимание. А в оставшееся время общая дискуссия. Итак, я расшарю экран с вопросами. Вот, собственно, наша тема. Такое название немножечко амбициозное. Оно вначале было еще более амбициозное, но причесали. Вероятностная или нечеткая семантическая логика, новая надежда или отжившая старая. И вопрос, который прежде всего хотелось обсудить, это что вообще за этим стоит. Потому что терминология – дело тонкое. Поясняя того, что для меня стоит за этими словами, я лишний раз приведу пример того, что терминология – дело тонкое. Я под этим понимаю некоторые когнитивные функции. Что такое когнитивные, мы оставим за рамками. Некоторые когнитивные функции, которые выполняются на основе некоторых структур, где структуры могут быть либо графами, либо отношениями. Я раскрою чуть-чуть позже эту разницу. И эти операции выполняются с использованием небинарной логики, небулевской логики. То есть, мы оцениваем Истинность, достоверность, вероятность, экспрессию, как угодно назовем, самого некоторого факта, некоторого понятия, некоторого выявления, некоторого сигнала по какой-то шкале от нуля до единицы. То есть, у нас нет того, что нет или да, или ноль, или единица. А у нас некоторое число с плавающей точкой, которое определяет некоторую характеристику сигнала, истинность, достоверность и чего угодно. Это вот такое определение. Теперь, что стоит за этим определением? Во-первых, про структуры. Те системы, которые мне известны, я по ходу отвечу на некоторые вопросы дальше. Мне известны три системы подобного рода. Одна система – это система Евгения Евгеньевича Витяева «Дискавери». Он про нее скажет по ходу дела. Я думаю, вторая система – это система НАРС Пи-Ванга. Третья система – это опенкок Бена Герцеля. И в качестве структур, например, у Пи-Ванга используются графы в НАРСе. А у Герцеля Бена в Опенкоге используется система гиперграфов. По сути, система гиперграфов, на самом деле, это некоторый гибрид графовой БД и революционной БД, которая, на самом деле, в конечном итоге хранится на основе революционного представления под капотом. Эти элементы, кстати, можно называть их атомами. В аппенкоге это называется не связями, не концептами, это называется графами. То есть, если в обычном графе у нас есть вершины и ребра, или концепты и отношения между этими концептами, или связи, то в атомспейсе все является связью и отношением, все является атомом, и эти атомы могут как угодно между собой быть связаны. У Евгения Генича Витяева это называется предикатами, поскольку у него в чистом виде логическая система использования вероятности логики, он работает с предикатами. Значит, теперь по поводу нечеткости вероятности и логики. Существуют разные вообще понятия на эту тему. Например, нечеткая логика и вероятностная логика. Если посмотреть в Википедии, то можно обнаружить, что когда мы говорим про нечеткую логику, мы говорим о... Достоверность чего-либо может измеряться по шкале от нуля до единицы. А когда мы говорим о вероятностной логике, то у нас имеет место вероятность. И она тоже может быть от нуля до единицы по той же самой шкале. А теперь представим себе, что мы хотим решить задачу, что вот у нас есть 100 мужчин, и из них 50 блондин и 50 брюнеты. Соответственно, у нас как достоверность того, что все мужчины – брюнеты, будет 0,5. потому что остальные 50% это блондины. Так и вероятность встретить мужчину блондина или брюнета, она будет те же самые 0,5%. То есть в каком-то смысле разница между вероятностью и нечеткой логикой, а это вопрос интерпретации вот этой метрики, которой мы оцениваем некоторый элемент вот этой вот структуры, с которой мы работаем. С одной стороны. С другой стороны, есть еще формулы, по которым это все считается. И вот здесь вот тоже есть путаница. Потому что, например, в НАРС, в НАРСе, у Пи-Ванга, система осознанно не называется вероятностью. То есть, Пи-Ванг не использует понятие нечеткая логика. Он не использует понятие вероятностная логика. Он говорит, что у меня не аксиоматическая логика, но он аксиоматик логик. Логик. И у него есть свои формулы совершенно определенные, которые, так сказать, не баясовские. То есть, у него не баясовская вероятность опиеванга. И вот, значит, он и эти формулы, с его точки зрения, описывают так называемую не аксиоматическую логику. А Евгения Евгеньевича Витяева, в свою очередь, логика Баясовская, насколько я понимаю, если я не прав, он меня поправит. А вот у Пиванга, да, а система Евгения Евгеньевича называется, так сказать, система логики вероятностного вывода. А у Пи-Ван, у Бена Герцеля в ОпенКоге есть пробаболистик логик нетворк, то есть есть пробаболистик логик, то есть тоже сети вероятностной логики, хотя формулы, которые используются у Бена Герцеля, они по сути те же самые, что у Пи-Ванга, то есть он заимствовал формулы неоксиматической логики из Пи-Ванга. Поэтому в терминологии есть некоторая путаница. Она зависит от некоторого субъективного восприятия, и копия здесь можно ломать очень долго. Но мы не будем ломать копию, мы двинемся дальше. Как вы соотносите в вероятности асимматической логики с символьным искусственным интеллектом. Очень просто. Вероятностная асимматическая логика основана на символьном искусственном интеллекте. То есть, она является его расширением. Если классический символьный искусственный интеллект работает с символами, которые либо есть, либо нет, то здесь мы работаем с вероятностями этих символов. Все очень просто. Мы расширяем или дополняем символные подходы к искусственному интеллекту до вероятностной или нечеткой интерпретации. Каковы сильные стороны? Сильные стороны – интерпретируемость, потому что мы можем любое отношение каким-то образом проинтерпретировать. Мы сможем сказать, что вот эта связь между этими точками, где одна точка – это мужчина, а другая точка – это женщина, вот между ними связь означает муж-жена. У нее есть смысл. И мы можем оценить вероятность того, что эти два человека являются мужем и женой по какому-то набору признаков. То есть, мы можем интерпретировать те знания, которые формируем в системе. С другой стороны, как это не удивительно, масштабируемость. Потому что когда мы создаем некоторую нейронную сеть с некоторым количеством искусственных нейронов и некоторым количеством слоев, мы фиксируем набор параметров, который мы можем заучить. И если масштаб задачи, которую мы пытаемся затолкать в эту сетку, не вписывается в это количество параметров, то мы эту задачу не решим. А если набор параметров у нас слишком большой, то мы просто зря жжем энергию, потому что нам не нужно столько параметров на логическую структуру, которая имеет гораздо меньше параметров. А вот достоинство как раз вероятностного семантического похода заключается во том, что мы можем сгенерировать столько вероятностных связей, сколько нужно. Мы не генерируем лишние связи. По ходу обучения мы можем строить некоторые гипотезы, но потом они все отсекаются как статистически недостоверные. И, казалось бы, и дальше сколько у нас памяти, если не хватает памяти, мы ее просто прикупаем, и система растет. Кстати, вот по такому принципу устроена нейроморфная система у Вадима Филиппова из Тюмени. У него тоже вроде как нейронные сети, но эти нейронные сети могут расти. Каковы слабые стороны? Слабые стороны, насколько я понимаю, пока что эти системы себя не показали. То есть, вроде теоретически все хорошо, и масштабируемо, и интерпретируемо. Практических примеров очень мало. Дубе на Герцеле система до сих пор для промышленной эксплуатации непригодна, чисто технически. Нарс пи и ванга хорошо оформлен как опенсорсный пакет, можно скачать, есть примеры, но задачки там стандартные, не самые сложные задачки из OpenAI Gym. Плюс в последнее время они экспериментируют с мобильными телефонами на тележках, с манипуляторами, решают какие-то простые задачи из области ранней робототехники. Евгений Евгеньевич Витяев, те примеры, которые он показывал. Да, то есть, там мыши бегают, там нематода ползет. Может быть, Евгений Евгеньевич прокомментирует его разработки, которые используются компанией EyeLineMobie. Может быть, там есть какие-то большие масштабные промышленные решения. Это тогда, конечно, было бы хорошим примером. Дальше. Как вы относитесь к идее Канемана про две системы? Если хорошо, является ли WSL аналогом системы 2? Я отношусь хорошо. И, конечно, вероятностная семантическая логика как раз и является аналогом такой системы. То есть, у нас она работает медленнее. чем ассоциативная или система, построенная на нейросети. Но она, во-первых, является интерпретируемой, а во-вторых, она обучается быстрее. У нас может быть реализован one-shot learning. Мы получили какую-то информацию в виде подграфа, мы его фиксировали в семантической базе данных. После чего он у нас уже в базе данных есть, нам не нужно много выборок учиться. Можно ли решить любую задачу примерно с одинаковой точностью, но с разными затратами с помощью нейросети и WSL, теоретически и практически? В моем понимании теоретически можно, потому что и там, и там в конечном итоге мы имеем дело с графом. И весь вопрос в том, какая математика у нас обслуживает расчет этих связей между вершинами этого графа и какой смысл мы в эти связи вкладываем. Мы можем обеспечить в конечном итоге одну и ту же топологию некоторой семантической сети и одной и той же нейросети, если это вдруг зачем-то надо. Те эксперименты, которые я показывал на примере пинг-понга, показывают, что разные подходы могут одну и ту же решить задачу с примерно той же точностью. если мы ее параметризуем в одном и том же операционном пространстве. Соответственно, видите ли вы будущее нейросимвольной интеграции? Ну, да. Поскольку система 1 – это про медленное обучение, но быстрое принятие решений. Система 1 – это про медленное обучение и быстрое принятие решений. неосознанная, неинтерпретируемая. А система 2 – это про быстрое обучение, медленное принятие решений, но возможность интерпретации. Как можно соединить? Этим сейчас как раз занимаются люди, которые работают в области нейросимвольной интеграции. Тут нужно это для того, чтобы, с одной стороны, интерпретировать решения и модели нейронных сетей, чтобы их можно было понимать, как они устроены, насколько они достоверны и что от них можно ожидать. в случае каких-то критических задач. А с другой стороны, если у нас в результате быстрого обучения семантической вероятностной модели появилась какая-то работоспособная модель, на основании которой нам нужно быстро принимать решения, мы можем просто загрузить эту семантическую сеть в нейросеть. И эксперименты подобные я даже видел, и докладывали Пару лет назад на конференции ICHI. Шанхае. Ну и какие, вы знаете, достоинственные недостатки у существующих систем ВСЛ. Ну, я сказал. То есть, одна не работает. Вот. Вторая решает очень простенькие задачки. Третья – система Евгения Евгеньевича Витяева. Ее, к сожалению, нет в открытом доступе. Ну, а насколько она пригодна для масштабной промышленной эксплуатации, я думаю, Евгений Евгеньевич, когда будет выступать, он скажет. Все. Спасибо. Я уложился даже в 15 минут. Коллеги, кто хочет следующий выступить? Так, желающих нету? Ну тогда мне, наверное, придется попросить Юрия Бабурова. 

S06 [00:15:22]  : Поскольку последний... Но для критики немножко рановато еще, мне кажется. То есть я бы, наверное, предпочел схему... Ну, я думаю... Нет, давайте мы поочередно. 

S05 [00:15:31]  : Давайте мы все-таки как-то будем передавать. Ну, давайте Александр Бал... Если вы не готовы, давайте Александра Балдачева попросим. Александр, вы готовы? 

S02 [00:15:39]  : Добрый день. Я все тоже как бы подумал над тем, что хотелось бы услышать все «за», и тем более у меня такое более-менее короткое сообщение. 

S05 [00:15:48]  : Ну, смотрите, если сначала все «за», а потом все «против», то будет нечестно. 

S06 [00:15:54]  : Ну, не обязательно все «за», но можно еще одно «за» хотя бы выслушать. 

S05 [00:15:58]  : Ну, давайте Захара. Захар, вы можете высказаться? 

S07 [00:16:07]  : Да, меня слышно? 

S05 [00:16:09]  : Да, у нас слышно. Да, Захар, пожалуйста, я попытаюсь Владимира Смолина подключить, если он не с нами еще. Пожалуйста, Захар. 

S07 [00:16:17]  : Да-да, сейчас. Ну, во-первых, вопрос, что у тебя стоит за словами «вероятностная нечеткая тематическая логика». Вот, для меня это… Во-первых, я занимаюсь в основном вероятностной логикой. То есть у нас есть некоторые события, которые являются одной причиной другого. И не всегда данное событие переходит в следующее, то есть с некоторой вероятностью. И мы можем определить тогда такой операции как импликация с двумя событиями, то есть что из A следует B с вероятностью некоторой. И далее построить некий граф, по которому рассчитывается вероятность из события A перейти в событие B. Но также мы можем перейти не в следующих событиях, а через одно или через два события. И здесь почему именно вероятность аналогичная? Потому что она позволяет учесть вероятность перехода по этому графу, причем если мы переходим из события A в событие B, а из него в событие C, мы можем рассматривать это как операцию E. И тогда мы получаем вероятность перехода, путем перемножения вероятности из A в B и умножения из B в C. Также, если мы можем попасть из одной вершины в другую двумя разными способами, мы можем складывать вероятности на ребрах этого графа и вычитать их произведение. Вообще, на мой взгляд, вероятностная и нечеткая логика – это две разные по своему смыслу логики, поскольку нечетко она оперирует тем, что для нас какое-то событие может быть не только истинным или ложным, но может быть какой-то долей истинной и ложной. А вероятностное, что оно может быть с какой-то вероятностью, если не ложное. Но многие операции из вероятностной и нечеткой логики, они по сути... Ну, во-первых, сразу можно сказать, что вариантов репликации может быть очень много, как вероятности, так и нечеткой логики. В нечеткой логике задается просто, что у нас все операции, которые мы применяем, они должны в случае, если мы используем единицы нули, то есть истинная ложь, давать точно такие же результаты, как, скажем, дает те же самые операции в случае применения бинарной логики. В вероятностной логике, по сути, то же самое, но только мы оперируем понятием вероятности. А как это связать еще и с семантикой? На мой взгляд, вершина графа должна представлять некую семантическую структуру, и тогда отраться на нем является вероятностной семантической логикой. Насчет второго пункта, как я отношусь к вероятностематической логике с символьным искусственным интеллектом, я здесь полностью согласен с предыдущим спикером. С сильными сторонами вероятностематической логики я считаю также, возможен так называемый one-shot learning, когда мы добавляем одно правило и решаем новую задачу. Также то, что мы можем интерпретировать систему и то, что мы можем изменять ее. То есть, если у нас, скажем, имеется какая-то нервная сеть, мы не можем подкорректировать какой-то параметр вручную, чтобы получить Ну, чтобы корректировать выход, нам нужно именно обучать всю сеть целиком, и тогда мы можем, получается, получить более точное предсказание. Вот графами мы можем изменить, убрать или добавить некий путь, либо изменить и получить более качественный результат с меньшими затратами. Слабыми сторонами вероятностной логики можно к ним отнести то, что необходимо либо изначально составлять правила, Либо, чтобы система сама не составляла, нужно выделять некие состояния. Ну, например, чтобы у нас были, как раз таки, формировались вершины этого графа, то есть у нас была некая причина, некоторая следствия. Если делать вывод на базе аппликаций, они должны быть изначально выделены. но данный недостаток в принципе можно устранить, если использовать аппарат вероятностной логики вместе с нейронными сетями, об этом я чуть позже скажу. По поводу Идея про две системы, является ли WSL аналога системы 2, ну, мое мнение, что да, является. Так как она наиболее близка к логическому мышлению, поэтому я считаю, что является. Можно ли решить любую задачу, приносить одинаковую осужденность, но с разными затратами на обучение? и вывод с помощью нейросетей и вероятности матерической логики, теоретически и практически. Здесь я все же думаю, что нет, потому что, на мой взгляд, нейросети решают лучше одни задачи, например, где нужно моделировать какое-то распределение на выходе, имея некий вход, например. 

S03 [00:23:15]  : Вы о чем? Коллеги, микрофон отключите, пожалуйста. 

S07 [00:23:40]  : В общем, на мой взгляд, нейросети, они решают задачи, когда нужно аппроксимировать некоторую функцию, либо смоделировать распределение, а вероятность вывода, она больше относится к задаче логического вывода. У нейросимбольной интеграции я вижу огромное будущее, поскольку с помощью нейронных сетей можно создавать те самые, например, состояния, между которыми потом строить импликации, переходы. То есть немного поясню этот момент. У нас может быть, например, нейросеть, например, ResNet, который на выходе выдает некий embedding. Данный embedding мы можем преобразовать в последовательность нулей или единиц, используя, например, механизм LSH. То есть это такой механизм, когда мы берем какую-то другую нейронку, ну либо мы берем просто случайные несколько векторов, составляем из них матрицу, потом эту матрицу умножаем на embedding, получаем значение выхода, после чего мы можем взять знак этого значения, если знак отрицательный, то есть если значение меньше нуля, то мы записываем 0, если больше, то 1, и вот формировать такие образы, а далее строить матрицу переходов между этими образами и применять, например, ту же вероятностную логику для прогнозирования следующего образа. Ну, кстати, это, наверное, и на восьмой вопрос ответ. Ну и про достоинства и недостатки существующей системы вероятностной схематической логики. На мой взгляд, есть из недостатков, что можно назвать, то, что необходимо формировать определенные вот эти вот состояния, либо слова, либо нас, ну, что я называю состояниями, это, скажем, условия, что, например, стало облачно. и следствие из него, что пойдет дождь с какой-то вероятностью. Вот эти фразы нужно откуда-то брать, нельзя их получить напрямую из какого-то наблюдения, то есть это нужен еще механизм какой-то, который их формирует. А из преимуществ то, что нужно строить интерпретируемый логический вывод. Ну, это моё видение данного вопроса. 

S05 [00:27:28]  : Антон, звук. Да, извиняюсь. Захар, спасибо. У меня два вопроса к вам. Во-первых, вы сказали, что нужно выявлять состояние. Вводить руками понятно, но хотелось бы хотя бы часть работы делать автоматически. Вы назвали это выявлением состояния. А есть идеи, как их можно выявлять? 

S07 [00:27:52]  : Я просто не знал, что на круглый стол нужно готовить презентацию, поэтому я только начал готовить во время уже того, как начался этот круглый стол, но вот слайд с этим я подготовил в свое время и состоянии, так что я сейчас его просто покажу. Давайте, да. Так. Вот. Я надеюсь, видно, да? да-да, но здесь идея в том, что вот как раз мой проект, что есть некоторое изображение, по нему может выйти мышка и координаты отображаются где находится мышка вот как раз таки здесь, но здесь он после уже получается после система автоматической регулировки усиления, чтобы сделать то, что в машинном обучении называется нормализация данных, так у нас во времени приходит, поэтому здесь автоматическая регулировка усиления, вот такой образ появляется, а потом из него формируется, получается вот здесь вот это состояние, то есть ряд векторов. мы берем несколько векторов, приставляем их к матрице, а потом мы вот этот вектор, который получается здесь, его визуализация, умножаем на... точнее, матрицу умножаем на этот вектор. получаем вот такой вот семантический образ, а после этого мы можем просто взять и сказать, что если у нас значение больше нуля, значит это единица, а если меньше нуля, то это ноль. Ну, меньше либо равно. И тогда у нас получится здесь состояние, которое будет характеризоваться, здесь будет ноль, здесь единица, потом ноль, ноль, ноль, ноль, один, ноль. Вот. И потом мы можем добавить его в граф. Это, по сути, визуализация матрицы смертности графа. Мы можем его добавить в граф, и у нас будет некоторое состояние, либо условие, либо следствие. И если мы из этого состояния переходим в другое, то можно сказать, что из этого мы можем перейти в следующее. И далее, если мы отметим этот граф, он без петель, то мы можем посчитать частоту переходов, из них получить вероятность переходов. И далее их использовать в импликации, как значение вероятности того, что из А следует Б. 

S05 [00:30:47]  : Спасибо. А можно вернуться к исходному слайду? У вас там нарисована собака. Что у вас является состоянием и что является переходами? 

S07 [00:30:59]  : Смотрите, вот здесь выделяется состояние. Если вы немного подождете, я просто не знаю, насколько здесь по таймингу все жестко, но если вы немного подождете, я могу запустить этот код и показать. 

S05 [00:31:13]  : Давайте, если это быстро. У нас, тем более, что один спикер, похоже, не появляется, поэтому у нас есть еще чуть-чуть времени. 

S07 [00:31:21]  : Хорошо, я сейчас тогда это сделаю. так я уже выпускаю переключу 

S05 [00:31:39]  : Пока вы запускаете, я расскажу анекдот. Я тут написал голосовое сообщение Владимиру Смолину. Я позвонил Владимиру Смолину. И там от меня ответил ассистент Олег. Как вы знаете, тот самый ассистент Олег, благодаря которому заблокировали вчера или сегодня карточку какого-то человека, которому один Олег позвонил из банка, а второй Олег ответил с телефона клиента. В итоге два Олега не договорились. И тот Олег, который был в банке, решил, что тот Олег, который на телефоне, пытается совершить мошенническую операцию, и человеку заблокировали счет. Мне сейчас пришла смс от ассистента Олега Владимира Смолина. У меня это шок. Это такая голематья. Он такого распознавал в том, что я говорил, что я не знаю, что Владимир будет думать теперь про меня по такому ассистированию. Жесть. так, давайте. я вот думаю, что экран виден? 

S07 [00:32:46]  : да, да, экран виден. а, ну вот здесь как раз-таки образ, который приходит на вход, он... вот здесь вот замечен этот вектор. если я вот начинаю двигать, то видно, что здесь появляется он изменяется очень. А вот здесь у нас кодируется этот образ, который на слайде был. Выглядит он вот так. Его можно представить в двоичном виде и можно представить в действительной системе счисления. А в действительной системе счисления его можно образовать напрямую на номере вершины графа. И тогда можно сказать, что если у нас, например, сейчас было 1,7, значит мы из первой вершины переходим в седьмую и вот сейчас второй раз был 1,7 И вот он считает, сколько раз перешли, а потом делит на все переходы и получается вероятность переходов. То есть логика очень похожа, например, на работу марковской модели, когда там тоже строится матрица переходов, но сам вывод делается иначе, не так как, например, генерация того же текста с помощью марковской модели. Вот эти значения есть. 

S05 [00:33:58]  : А задача-то какая решается? А задача-то какая решается? 

S07 [00:34:02]  : В данном случае задачей решается прогнозирование, то есть, если этот образ, то какой образ будет следующим. Ну и вот сейчас 61%, но если надолго поставить обучаться, то у меня получалось добиться 98%, что я, в принципе, и показывал на слайде. 

S05 [00:34:21]  : Хорошо, коллеги, ещё есть какие-то вопросы к Захару? Захар, спасибо. Захар, у меня к вам последний вопрос. Скажите, насколько я знаю, вы с Виктором Носко взаимодействуете как-то, который занимается коннекционистским подходом. То есть, он на основе нейросетей строит решения. А вот то, что вы делаете, рассказываете, это как-то связано с вашим взаимодействием с Виктором? Или это просто разные проекты? 

S07 [00:34:50]  : Ну, конкретно этот проект я ему уже довольно давно занимаюсь. То есть, можно сказать, с первого курса. То есть, это как, ну, хобби, можно сказать. 

S05 [00:35:04]  : Ну, то есть, вы не занимаетесь, то есть, у вас нет задачи внедрения нейросимвельной интеграции в NewtonBot пока? Ну, на данный момент 

S07 [00:35:17]  : Нет. 

S05 [00:35:18]  : Понятно. Хорошо, коллеги, еще к Захару есть какие-то вопросы? Хорошо. Тогда, Захар, спасибо. А, давайте спасибо. И я думаю, что у нас достаточно спикеров, которые топили за. Вот, теперь есть предложение выступить двум спикерам, которые будут топить против. Александр, Юрий, кто готов первый выступить? 

S06 [00:35:46]  : Давайте я попробую. Сейчас развернем презентацию. Извиняюсь, сегодня я без камеры. Мы поговорим все же о классических вероятностных асимметических и логических моделях вначале, а потом подумаем, можно ли с этим что-то сделать. Во-первых, когда мы говорим о вероятностных моделях, сразу возникает вопрос, а как считать эту самую вероятность. И здесь практически все сразу отвечают, что надо считать вероятность через произведение вероятности, какие-то похожие формулы, и таким образом выяснять, делать какие-то логические выводы, то есть пытаются расширить обычную логику, в которой бывает только да-нет, причем всегда да и всегда нет. на какие-то модальности, на какие-то более конкретные кейсы. И получается самым простейшим кейсом уже выходит нестыковка. Значит, я хожу в спортзал по четным дням, то есть 50% всех дней. Вы ходите в спортзал по нечетным дням, тоже 50% всех дней. Получается, умножаем 50 на 50%, значит, вероятность нашего события, что мы одновременно будем в спортзале, 25%. Но на деле это не так. Получается, вероятность – это такая сложная штука, которой, в общем-то, нельзя доверять. Возникает вопрос. Хорошо, допустим, мы делаем невероятность, но тогда что мы делаем? И вот если мы попытаемся чуть поглубже попытаться понять, какие вообще бывают вероятности, Вероятность чего? Вот, например, возьмем «иногда», которое упомянуто во фразе. «Иногда» — это когда? Это два раза в неделю, три раза за два года. Причем эти все три раза могут быть в соседние дни. Кто-нибудь поехал кататься зимой, значит, он три дня покатался, значит, он говорит три раза катался за два года. Вот там с Васей, но не с Петей пошел на рыбалку, значит иногда хожу на рыбалку, значит и даже может где, в лесу, но не в горах. На самом деле классов больше, их там не 5, больше и фактически мы, получается, пытаемся моделировать в языке на речи. То есть в основном то, что относится к вероятности, это или модальная логика, и там отдельный момент. Вот эти хочу, могу, надо и прочее. Мог бы – это какая вероятность? Но даже если мы не берем модальности глагольные и оставляем только наречные модальности, то посмотрим, какие вообще наречия есть. Вопросительный откидываем. Вопросительный, по сути, это классификация групп. В общем, по группам нам деление неинтересно, наверное. Пространственное деление и какие-то признаки действия нам тоже пока что неинтересны. Хотя бы попытаемся определиться с этими. Мало-много, трижды, надвое, очень, весьма. на речь о степени. Мы понимаем, что даже с ними в языке существует огромное число правил словоупотребления, правил вычисления вероятностей. И так их свести к одной вероятности какой-то не получается. Получается, нам надо для каждой фразы придумывать много разных вероятностей. У одной будет вероятность маломного количественного числа предметов, у другой будет вероятность, что было рассмотрено выше 2 раза в неделю или 3 раза в год. У третьей части будет еще вероятность, еще одна модель. А как сгоряча и поневоле оценивать вероятность, вообще непонятно. У нас в уголовном кодексе есть, например, Преступления, совершенные, ну то есть там не мотивировано, там по-разному называется, без предварительного сговора, значит без плана совершения преступления и так далее. Это тоже модальность. То есть человек думал об этом, не думал. И там как раз по сути вот в законодательстве есть какой-то аналог тоже вычисления этих вероятностей. Там невероятность количества лет, сколько человек потом проведет в тюрьме. В одном случае при одних условиях одно количество лет, при других условиях другое количество лет. Система, как понимаем, достаточно сложная, и все попытки эту систему сильно упростить, они не получаются, не работают. В NARS, как я понимаю, вероятность пытались свести к двум подвероятностям, к двум модальностям. В других системах чаще всего вероятность одна. Особенность нейронных сетей в том, что они внутри, в своих распределенных представлениях, они могут эти все вероятности как-то учитывать, они действительно могут разные слоты занимать. Мы даже не будем задумываться. задумываться о том, как это работает. Ну, безусловно, проблематику я понимаю, потому что нам хотелось бы это как-то, как-то все же то, как человек этими вероятностями, этими модальностями. мыслит, как он с ними обращается, нам бы хотелось перевести в цифровую форму, сделать наглядную. Но, увы, задача очень сложная. Единственная имеющаяся детальная разработка на русском языке, это модель Тузова, у которого как раз вот эти наречия были цифровизованы до, то есть наречие накладывалось на фразу семантически, значит там мало-много, значит какая-то была количественная оценка и была наложена на фразу Но дальше он не пошел, то есть у него была такая неглубокая семантика, правил преобразования у него еще почти не было. Увы, он там не успел многое сделать, но много лет, даже больше 10 лет составлял свою семантическую базу. Поэтому работа сложная. То есть, с одной стороны, двигаться надо, с другой стороны, количество правил, боюсь, будет составлять миллионы. И поэтому никакая вероятностная логика. Это вам не Аристотельевская логика, где там, по сути, 10 правил и все. А когда число правил до миллиона, то сразу все люди чему-то сдаются. Так что с вероятностной семантической логикой, на мой взгляд, происходит именно это. Она слишком получается сложной и не работает. 

S05 [00:44:30]  : Спасибо. Юрий, я не расслышал, все люди что вы сказали? 

S06 [00:44:37]  : Не справляются. не справляются с тем, чтобы строить сложные модели. Аристотелевую логику с 10 правилами построили и этому формальному аппарату можно обучить других людей. А вот когда мы говорим про более сложные отношения, которые передаются в языке в основном на речи, то внятная система правил, мне кажется, будет занимать миллионы правил, поэтому люди с ней не справятся. 

S05 [00:45:11]  : А почему люди должны с этим справляться? 

S06 [00:45:15]  : Ну, мы же хотим, чтобы люди для компьютеров заложили эту какую-то систему и как-то могли ее проверять, как-то что-то с этим делать. 

S05 [00:45:25]  : А люди должны проверять всю систему или люди должны задавать какие-то вопросы и получать конкретные ответы? 

S06 [00:45:34]  : Сейчас задают для нейронных сетей вопросы, получают очень странные ответы. И что с этим делать непонятно. 

S05 [00:45:42]  : Хорошо. Еще несколько вопросов на понимание. Есть рука у Николая Шилова. Сейчас давайте я свои вопросы задам. Вы сказали, что в НАРСе две модальности? 

S06 [00:45:55]  : Да, по сути. Каких это две модальности? Там одна вероятность обычная, вторая вероятность достоверности. 

S05 [00:46:09]  : Я понял. На самом деле у него это называется не две вероятности, у него это называется сила и уверенность. Он всегда очень ругается, когда используется слово вероятность при разговоре про его систему. Хорошо. Дальше еще у меня, знаете, какой к вам вопрос принципиальный? А вы как-то очень внезапно, значит, начали с вероятности, а потом все время говорили про язык. Вот. Для вас вообще вероятностная семантическая логика – тождественный язык? У меня создалось такое впечатление. Может быть, вы к первому пункту вернетесь и все-таки сформулируете то, что для вас 

S06 [00:46:49]  : давайте попробуем по-другому сказать. почему происходит проблема здесь? почему здесь происходит ошибка? вот это вот простой нашей логики, что вероятность производного события, ну не производного, неправильно говорить, а комбинации событий, произведения вероятности. Причем тут события друг с другом не связаны. Говорят, что события, наверное, связаны у вас, раз у вас произведение вероятности не работает. Нет, события не связаны. Они частично связаны, конечно, тем, что выбраны нечетные и нечетные, которые друг с другом связаны. В этом плане не связано. Получается, у нас над нашей простой логикой, которая должна как-то с вероятностями работать или вычислять что-то, у нас над ней существует какой-то языковой пласт. вот этот языковой пласт, который определяет вот эти дополнительные условия, как оно на самом деле, то есть из-за чего в данном случае получается не 25 процентов по норме, а в другом случае, если бы тут были бы четные дни, было бы вообще 100 процентов, если бы у обоих людей были бы четные дни. есть вот эти дополнительные условия. если мы их не проговариваем и не учитываем, мы редуцируем модель до такой модели, что она становится применима лишь в очень-очень узком диапазоне случаев для очень узкого класса задач. которые ненамного больше, чем в классической моде. 

S05 [00:48:53]  : Хорошо, спасибо. Есть комментарий от Алекса Бура, что произведение вероятности была ошибка, возможно, я не дослышал условия задачи или условия все не были озвучены. Но это комментарии, а есть вопросы еще от Николая Шилова. Николай, пожалуйста, а потом Захар. 

S03 [00:49:12]  : Спасибо. Юрий, спасибо. Очень интересное выступление, реплика. Скажите, а не получается ли у нас просто лингвистическая переменная за D? Вот то, что вы называли. Модальности – это лингвистические переменные за D. И тогда соответственно нам надо рассматривать не вероятностную логику, а соответственно нечеткую логику за Д в контексте лингвистических переменных. Спасибо. 

S06 [00:49:40]  : С одной стороны да, с другой стороны у нас вот этих вот дополнительных правил вагонов, у нас их сотни тысяч. какое-то там одно общее правило. И, соответственно, если мы начинаем учитывать то, что здесь там может быть упомянуто, учитываться одно правило, здесь другое правило. Как минимум, нам надо все комбинации этих правил описать, тогда мы будем представлять весь диапазон возможных получаемых значений. И мы получаем своего рода комбинаторный взрыв. 

S05 [00:50:22]  : Спасибо. У меня небольшой комментарий есть. Во-первых, это комментарий к выступлению Захара. Захар, если вы не видели презентацию Лайна Савьепстаса на конференции AGI в прошлом году, то вам, наверное, будет любопытно посмотреть, потому что многие вещи, то, что вы говорили, показывали, у меня перекликаются с тем, что он показывал. То есть, он топит за то, что вообще-то нужно все делать на графах, и что любую задачу, которую решают нейросети, можно свести к задачам на графах, и просто приводить некоторые примеры комплементарные тому, что вы показывали. Если не знаете, про что я говорю, напомните мне, я вам потом кину ссылку. Это один момент. А второй – почему я про это вспомнил? Потому что никто же не себя заставляет несчастных людей сидеть и вводить эти правила. Когда мы говорим про вероятность и логику, мы говорим про то, что правила могут выводиться автоматически. Весь вопрос в том, чтобы эти правила были привязаны к какой-то предметной онтологии и имели какой-то смысл. То есть, человек может определить базовую онтологию, А в рамках этой базовой онтологии уже могут выводиться какие-то производные правила. И у того же Лайнесса Вепсеса устроена вся его лингвистическая система, основанная на грамматике правил, где есть какие-то базовые вещи, понятия, а сами правила выводятся автоматически на основе статистической обработки текстов. Как это хорошо или плохо работает – это отдельный интересный вопрос. Я бы про него рассказывал. Никто не говорит про то, что нужно все правила кодировать вручную. А то, что их получается комбинаторный взрыв, почему? Я не вижу, почему правил должно быть больше, чем правил появляется в любой нейронной сети, в любом Берте, который тренируется на одном и том же корпусе. То есть, точно так же можно сказать, что любая нейросеть тоже будет уходить в комбинаторный взрыв. Но это просто ремарка. Давайте послушаем, что Захар еще хочет спросить или сказать. 

S07 [00:52:33]  : Первое, что я хотел сказать, это то, что вы сейчас сказали про то, что правила могут формироваться сами, так как мы можем. устанавливать взаимосвязи между двумя событиями и просто считать по количеству активации вероятности между ними. И второй вопрос, это был уже вопрос к Юрию, насчет резкого перехода от вероятности к текстам. Нет ли смысла, вот как вы говорите, что люди не набьют столько правил и не сделают их? Здесь как бы я согласен, но во-первых, машина может сама их изучать. Второй момент, почему правила нужно формировать именно на уровне конкретных слов? Почему нельзя пойти на более высокий уровень абстракции и формировать правила уже на уровне предложения перед своих текстов. 

S06 [00:53:36]  : Отвечу с конца. Я не говорю нигде про уровень конкретных слов, я просто говорю про то, что достаточно часто как раз вероятностные отношения в языке кодируются наречными и наречными отношениями. При этом, конечно, есть другие способы. Почетным дням в общем-то, не на речи языке. Это фраза, которая тоже задает определенные отношения, накладывающие ограничения на вот это событие. Просто я говорю, что если мы вот это вот отношение будем редукцировать до вероятности, тогда мы получим ошибку. Да, нейросеть, безусловно, может порождать правила, но, опять же, Я прошу вас всех всегда пытаться избежать плавной ловушки, считающей, что раз нейросеть или статистическая обработка что-то может делать, значит, эта статистическая обработка делает какую-то правильную вещь. Потому что это не доказывает. Это вы утверждаете, что если я прочитаю книжку, я ее правильно пойму. Почему вы считаете, что я ее правильно пойму? 

S05 [00:55:04]  : Юрий, спасибо. 

S06 [00:55:06]  : Ну, детально углубляться, наверное, не буду. 

S05 [00:55:10]  : Давайте пока достаточно. И на самом деле, все-таки, Юрий, для меня вот ваше перепригывание с вероятностной семантической логики на лингвистику и речь не очевидно. То есть, я как бы понимаю, но вот мне это не очевидно. 

S06 [00:55:27]  : Ну, в языке правила. Вот это вероятностные все правила кодируются. 

S05 [00:55:33]  : Но это в языке. Но мы же не говорим про язык. У нас нет НЛП вообще в повестке сегодняшней. 

S06 [00:55:37]  : Смотрите, вы говорите про онтологию, но онтология не на основе языка строится. 

S05 [00:55:44]  : Но это отдельно интересный вопрос, что да, онтологии на самом деле не обязательно, в моем понимании, они не обязательно строятся на основе… Ну, давайте сейчас не будем делать дискуссию пока, потому что у нас еще есть два докладчика. Александр Балдачев, можете высказать свое мнение? Юрий, спасибо. 

S02 [00:56:05]  : Добрый день, добрый вечер. Я немножко, как обычно, в сторону отойду, более теоретическую и более глобальную. Прежде всего начнем, как всегда, с терминологии. Если так подумать, прикинуть, никакой семантической логики быть не может. Семантическая логика – это, по сути, оксимарод. То есть логика – это то, что не касается семантики. Логика – это то, что занимается какими-то символными расчетами, символным преобразованием по каким-то правилам и каким-то определениям, не вникая в содержание, то есть в семантику. И, скорее всего, наверное, здесь имелось в виду, что это семантические системы на базе нечетких вероятностных логик. Вот так, наверное, Антон… Можно еще раз? Семантические системы… на базе нечетких вероятностных логик. у нас есть, скажем, семантическая система SemanticWeb, которая есть там RDF, OLE, это семантическая система на базе дескриптивных логик. поэтому сегодня мы обсуждаем семантические системы на базе нечетких вероятностных логик. То есть, по сути, семантика здесь как бы так боком. Если мы сейчас семантику выкинем, мы просто будем обсуждать сравнение двух логик. Поскольку мы графы сюда приплели, вы, Антон, тоже начали именно с графов, то мы имеем в виду здесь то, что у нас есть некая семантическая система, есть некий граф, построенный по каким-то непонятным правилам, он может быть и совместим с РДФ и ЛМРТ несовместимы, это может быть граф свойств какой-то, но помимо логики дескриптивной, которая вводится обычно для расчетов недостающих узлов, у нас есть еще и какая-то вероятность на нечеткая логика. И если говорить именно о проблемах семантического моделирования вкупе плюс с логикой, одной или другой, или третьей какой-нибудь логикой, то основная проблема, на мой взгляд, все-таки в так называемом символном подходе к искусственному интеллекту не в логике, Не в логику все упирается, а упирается в то, что до сих пор наши симметрические системы, они являются статичными, не динамическими, не моделируют действия, деятельность. Есть какие-то попытки это сделать, вести время, значит, в РДФ, множество вариантов есть, попытки присовокупить к семантике темпоральные логики различные. Но это тоже не решает проблему в той степени, в которой нам бы хотелось решать. Поэтому здесь нужно все-таки понимать, что мы хотим добиться и для чего подключаем различные логики. То есть различные блоки, скажем, если мы дескриптивные блоки подключаем к семантике, то мы решаем проблемы пересечения классов, включения в классы, то есть расчет недостающих каких-то элементов по правилам. И то же самое мы решаем нечеткую вероятность на логике, но только у нас либо классы размыты, либо выводится вероятность перехода связи между отдельными узлами. И теперь это просто изначально, как нужно было поставить задачу, и насколько наше обсуждение будет решать эту задачу с применением семантических технологий, символьного подхода для искусственного интеллекта. И мой ответ, что присвокупление к той или иной логике не решает проблему, а решает какие-то частные задачи. То есть вполне возможно, для каких-то задач нужна нечеткая логика, для каких-то задач вероятность логика, где-то достаточно инскриптивная, где-то нужно добавлять различные темпоральные логики, интервальные и прочее. Теперь возьмем более еще общий такой вопрос. Ребята, а вы действительно часто применяете логику в жизни? Ну ладно, вот вы конкретный инженер, мы конкретно занимаемся какими-то инженерными расчетами, научными, мы действительно применяем логику и знаем более-менее логику. Но в жизни логика обычно человеку не нужна. Он мало того, что не знает законов логики, вообще в принципе, так он и не применяет. Ни классическую, ни модальную, ни темпоральную, ни четкую невероятность, никакую логику не применяет. И более того, что человек обычно не занимается решением каких-то задач. То есть я могу себе представить, что процентов 80-90 населения планеты после того, как они закончили школу, никаких задач вообще не решали. В принципе, ни логических, ни математических, а действуют на основе здравого смысла. здравого смысла, моделей здравого смысла, и инструкции, которые им спускаются при их деятельности, профессиональной деятельности. То есть вот именно такой острой задачи воспроизведения какой-то логики, для моделирования деятельности человека, среднего человека. Мы не рассматриваем сейчас деятельность профессора, Нобелевского лауреата. Там другие проблемы возникают. Проблемы возникают уже не с логикой, а с сверхлогикой, с творчеством, которое тоже логику не описывает. То есть у нас получается, что мы можем поставить задачу моделированной деятельности человека, вообще не обращаясь к логикам. Тут еще интересное наблюдение. В этом году, несколько лет назад провели тестирование профессоров в университетах, не у нас, в Штатах, кажется, и задавали им логические задачки, и большинство из них эти задачки не смогли решить. И какой делаем вывод? Один вывод можно сделать, что эти профессора проф. непригодны, а второй вывод, что знание формальной и прочих логик не является необходимым элементом интеллектуальной деятельности. Они занимаются интеллектуальной деятельностью, они пишут статьи, они преподают, они являются высокоинтеллектуальными устройствами. Потом есть еще интересные соображения по поводу нечетких логик. Вот давайте подумаем, зачем они нам нужны. То есть чаще всего нечеткие логики применяются, и все примеры, которые мы можем в книжках почитать, в учебниках, связаны с… описанием от третьего лица каких-то ситуаций, отношений, взаимодействия каких-то агентов, и все это описывается от третьего лица. То есть когда мы не знаем, как себя поведет человек, ну типа вот Юрий приводил пример, там 50% известно, что 50% в них один человек туда, другой сюда, и вот мы можем как-то, не зная этих людей, рассчитать какие-то вероятности. Но это ли задача стоит? То есть обычно для того, чтобы не описать извне какое-то действие, а реализовать это действие, у нас не стоит задача описать это вероятностно. Вот возьмем типичный пример из различных статей или учебников касательно нечеткой логики. Вот, допустим, у нас есть чай, и температура чая не говорится какая. Чай горячий. И начинается рассуждение. Горячий – это 60 или 80, нечеткие границы. Мы должны рассмотреть, вот этот конкретный чай войдет в эти границы, не войдет. Мы когда-нибудь задумываемся над этим, над вероятностью, над нечеткостью. Для каждого из нас конкретный момент, здесь и сейчас, чай либо горячий, либо не горячий, мы все четко знаем. И даже если мы рассмотрим ситуацию, когда не мы знаем, а, скажем, домработница, она готовит чай, и хозяин говорит, сделай мне горячий чай. Если опять нет проблемы и четких границ этой горячести, потому что она прекрасно знает, она бы ее выбурили, если бы она не знала четкую температуру, какую нужно подать хозяину, что он поджимает горячий чай, что он поджимает холодный чай. То есть обычно в деятельности мы не разбираемся с нечеткими множествами. А нечеткие множества и вероятность описания – это инженерное описание, когда недостаточно знаний. То есть это не жизненные ситуации, а сугубо инженерные. Инженерные расчеты. Это статистические предсказания в социуме, то есть социологов. Психологические тесты. Поэтому нужно четко все-таки понимать, какую задачу мы ставим перед собой. Описать систему от третьего лица, которой мы ничего не знаем, либо создать действующую систему, которая будет действовать от первого лица и должна четко понимать, по каким схемам, какие задачи она будет решать, а не приблизительно, а четко. Ну и, наверное, я хотел бы еще сказать несколько слов про Каннемана. Я думаю, что не соглашусь с Антоном, что вторая система имеет какое-то отношение к нечеткости или к вероятности. То есть у него разделение идет четко на исходное разделение. То, что мы затрагиваем усилия на что или не затрагиваем. То есть вполне возможно, наш мозг, вероятно, не затрагивая усилий, моментально решает какие-то незадачи, какие-то ситуации описывает, определяет. Вот эта ситуация подходит под такую-то схему, эта ситуация подходит под такую-то модель. Я вижу это. И вполне вероятно, где-то как-то наш мозг, вероятно, или нечётко это всё компенсирует и выдаёт один ответ. Когда же мы говорим о втором уровне, когда сознательные мы делаем искусственные затраты, то там действительно, если мы специально не занимаемся задачами, связанными с нечёткими множествами, там обычно всё чётко. То есть мы никогда не ставим перед собой задачу, когда мы мыслим о чём-то, что вот о какой вероятности, а достаточно ли чётко я понимаю определённое понятие передо мной, чётко определённые понятия, и с этим понятием действуем. И вообще говоря, понимание здесь, наверное, Следовало разделить не на два уровня, а на три. То есть есть непосредственное восприятие, до и вне мышления. И это примеры все, которые связаны с визуальными иллюзиями, с лепотой по невниманию. Это все вообще не касается мышления. Это просто непосредственное восприятие. Потом есть понимание на уровне здравого смысла, базовые схемы, традиции, социальные установки. Это уже мышление, но оно не затрагивает ни логику, никакую вообще логику, а просто действия в конкретных ситуациях, которые уже для нас ясны, впитаны в молоко матери, обучены в школе, в институтах. И уже третий уровень – это автономная деятельность мышления, которая может быть и вероятностью, и невероятностью, и логическим, и вообще не логическим. Можем мыслить образами, там логики вообще никакой не будет. То есть привязывать здесь логику как бы бессмысленно. Может быть, скорее всего, на втором уровне, на уровне взрывов смысла, горпологии гораздо больше, чем в автономной нагруженной деятельности мышления того же ученого. ну и все, наверное, потому что высказывать свои мнения по поводу нейросильной интеграции, да, я считаю, что именно гибридные системы возможны двигаться, но с какого боку там будет привязан бантик нечетких логик или вероятность логик, будут Но построить на них, скорее всего, нельзя будет, только на них, потому что нужен какой-то совершенно другой подход, другая концепция. Все, спасибо. 

S05 [01:08:17]  : Александр, спасибо. Коллеги, к Александру какие-то есть вопросы или комментарии? Ну вот есть комментарии Ольги Заречной, к которой я присоединяюсь, что на самом деле люди все-таки, если не большинство, то гораздо больше, чем только академики, применяют логику или одну из логик, они просто не знают, что она определенным образом называется. 

S02 [01:08:46]  : Не применяют все-таки. Давайте понимать, что одно дело мы поступаем логично, Скажем, если я по инструкции буду выполнять какие-то действия, внешне они будут выглядеть логично, но при этом логику я применять не буду. Переход от одного пункта к другому – это не логика. И точно так же, когда мы, скажем, говорим о OL, когда рассчитывается какого-то объектов класса, этот класс входит в другой, надкласс, еще надкласс, и мы применяем какие-то логические вычисления, дескриптивные логики для расчета вот этих вхождений, то для ребенка вообще очевидно, что если вещь положили в предмет, сумку перенесли, то вещь осталась там. Это не логический вывод. Это банальные схемы, простейшие схемы здравого смысла. Мы не делаем логических выводов. 

S05 [01:09:40]  : И очень редко, иногда бывает… Александр, тогда вопрос, чем отличается схема здравого смысла от логики? Может быть, схема здравого смысла, она и описывается логикой? 

S02 [01:09:54]  : Нет. То есть она описывается логикой, но применяем мы ее не как логику. А как что? А как готовой схемы. 

S05 [01:10:00]  : Ну, а что из схемы? Ну, схема же где-то хранится, может быть, применение этой схемы… Нет, она хранится. 

S02 [01:10:04]  : Понимаете, логика – это когда я беру а из а следует b, из b следует c. Если c и b – это а, вот это логического перехода мы никогда не делаем. Логика здравого смысла – не логика, просто применение здравого смысла. Я вижу и сразу вижу результат. То есть, когда я смотрю на мокрый асфальт, я никогда не делаю логических выводов. Асфальт может быть мокрый, если прошел дождь. Я просто сразу вижу одним взглядом. тучи, мокрый асфальт, значит, был дождь. И это не логический вывод. Это применение схем, которые в нас вложили родители и в школе. И даже, скажем, когда мы решаем задачки в школе, то мы тоже не применяем логику. То есть, когда мы делаем умножение столбиком, это не логические операции. Это просто последовательность выполнения инструкций. Там нет логики никакой. 

S05 [01:11:08]  : Ольга, можете прокомментировать или уточнить вопрос? А потом Захар. Ольга, пожалуйста. 

S00 [01:11:15]  : Могу и прокомментировать, и уточнить. Давайте. Поскольку я, судя по всему, здесь единственный специалист в области психологии и психиатрии, у меня поэтому и вызывает сопротивление подобного рода. Сентенции. Почему? Потому что одно дело, когда мы с вами говорим о четкой обусловленной последовательности действий, и на самом деле с точки зрения психологии и принятия решения не имеет значения, осознанно они совершаются или нет. Важно, что последовательность действий есть, и она может быть выявлена при внешнем наблюдении, что мы, собственно говоря, с вами и видим. При этом я точно могу сказать, что как таковой здравый смысл, ввиду того, что, как говорит у нас докладчик и выступающий, он как бы не осознается, то есть сам процесс принятия решения в узловых точках не осознается, поэтому это может не считаться и не является логикой, Вот с этим не согласна. То есть здравый смысл – это та же самая четкая обоснованная логика, просто мы в силу особенностей восприятия этой логики, как она была заложена и как она попала, не всегда осознаем, почему происходит то или иное действие. Но при этом это не означает, что нет логики как таковой причинно-следственной. Вот в чем здесь вопрос. То есть когда мы говорим о логике, это прежде всего установление причинно-следственных связей. Каким образом это происходит? Интуитивно, с помощью съеденных от родителей установок в правильном младенчестве, с помощью образов, или через осознание своего практического, профессионального или личностного опыта, значения не имеет. Причинно-следственные связи есть всегда. И точно так же в машине это, собственно говоря, тоже должно быть. 

S02 [01:13:06]  : Ну, это технологический спор. Логика есть, но она не видна. 

S00 [01:13:14]  : Если она не видна наблюдателю, значит, у него просто может не быть средств наблюдения, но это не значит, что ее нет. 

S02 [01:13:21]  : Нет, дело в том, что логика – это вполне конкретная деятельность, вполне конкретные операции логические. Придумайте другое слово. 

S00 [01:13:31]  : Это конкретные операции логические, просто если они не видны наблюдателю по каким-то причинам, это не значит, что они отсутствуют. 

S02 [01:13:39]  : Понимаете, в данном случае я оперирую к некоему явленности, говорю, что этого нет, а вы говорите, что это есть, но нам не видно. 

S05 [01:13:49]  : Хорошо. Коллеги, Ольга, Александр, я думаю, есть понимание того, что есть непонимание или различные термины. Давайте мы здесь пока остановимся, потому что есть еще вопрос от Захара, и потом у нас еще есть один докладчик. Ольга Александровна, спасибо. Захар, пожалуйста. 

S07 [01:14:07]  : Вот у меня вопрос примерно такой же, как и у Ольги Александровны, то есть это насчет того, что в пиховаризме есть такое понятие, как стимул реакции, то есть у нас есть какой-то стимул, на него следует какая-то реакция. Если у нас из чего-то следует что-то, мы можем это записать как импликацию. и импликация – это вполне логическая операция. А если у нас часто такое происходит, мы можем сказать, что с большей вероятностью это произойдет. Понятно, что в нашем мозгу не хранятся конкретные значения по частотности, не хранятся какие-то значения вероятности, но сама логика мы можем представить как некоторую функцию от вероятности то, что у нас хранится мозг. Понятно, эта функция будет нелинейная, но все же, если у нас есть какое-то событие А, из него следует какое-то действие или реакция из стимула А следует реакция Б, то это вполне логическая операция, импликация. Если у нас есть два стимула, свойства одной реакции, то понятно, что это можно промоделировать путем сложения вероятности и так далее. 

S02 [01:15:24]  : у вас микрофон выключил. вы очень точно ответили, что это можно промоделировать, смоделировать при помощи логики. все понятно, логика у нас моделирует то, что мы наблюдаем, но нельзя сказать, что камень падает, потому что это логично. То есть все-таки не нужно путать символьные операции по каким-то законам, которые мы называем логикой, с помощью которой мы описываем то, что видим и то, что думаем, и саму логику, то есть и то, что происходит, то, что мы описываем. То есть не нужно это путать. Да, кстати, вот один интересный момент. Если вы, наверное, знаете, что читали, как люди описывают свою творческую деятельность, ученые, то тот результат, к которому они приходят, они никогда не приходят логически. Логическая работа начинается потом, когда ты уже записываешь это. То есть ты уже знаешь результат, ты уже знаешь, что твой итог, как ты его получил, ты не знаешь, а потом в тексте ты должен представить это в логической форме. И вот представление в тексте логической формы – это неравноценно тому пути, который ты пришел к этому результату, что подтверждает то, что тот путь был не логичным, а каким-то вообще непонятным, а логика появляется только в тексте. То есть я могу думать совершенно логично, логику я подключаю тогда, когда начинаю строить свою фразу. Это абсолютно неправильно. 

S07 [01:16:51]  : То, что вы говорите, абсолютно неправильно. Рассуждение от противного – это логика или нет? 

S02 [01:16:55]  : Если вы рассуждаете, если вы рассуждаете от противного – это логика. Но если вы не рассуждаете, а просто видите это, то это не логика. Вот ответ конкретный. Рассуждение – это логика. Но мы очень редко рассуждаем. Очень редко. Из всего мыслительного процесса рассуждение у нас занимает, наверное, там несколько процентов. А у большинства людей еще, может, меньше. Они не рассуждают. Просто действуют по схемам и все. 

S05 [01:17:25]  : Хорошо. Спасибо за вопросы и ответы. Давайте мы дадим слово Евгению Евгеньевичу. 

S04 [01:17:36]  : Евгений Евгеньевич. Добрый день. Да, мне надо расширить экран. Да, пожалуйста. 

S05 [01:17:47]  : Видно? Да, да, пожалуйста. 

S04 [01:17:55]  : Ну, я начну немножко издалека. Зачем, собственно, нужна логика, и как она вообще возникает? На самом деле, это вопрос более общий. Например, Тегмарк рассматривает, что когнитивные процессы отражают реальность в виде некоторой такой информационной системы. То есть вот между настоящей реальностью физической, которая описывается уравнением, и когнитивными процессами, которые есть во внутренней реальности, есть на самом деле такая промежуточная реальность. Что это за промежуточная реальность? Это есть как раз информационные процессы прогнозирования внешней среды. Причем это именно информационный процессор, потому что основные свойства мозга – это не логика, это предсказание. С точки зрения Петра Кузьмича Анокина, основной принцип всего живого – это опережающие отражения действительности. Опережающие отражения действительности основаны на прогнозе, на информации, на тех причинно-следственных связях, которые здесь есть у машины. Вот реальность описывается физически, она описывается в уравнении. Но дело в том, что реальность мы-то, как люди, воспринимаем внешне, нам уравнение неизвестное, нам видны внешние формы, так сказать, объектов. Но дело в том, что эти внешние формы, они подчиняются принципам физического деграминизма, который гласит так, что есть у нас некоторые начальные условия известны, есть известны законы изменения, этих переменах, то мы можем вычтись результирующие перемены. Так вот, принцип физического детерминизма он внешне наблюдает. И вот внешне он наблюдаем именно в таком смысле, что это некоторая такая информационная система, которая постоянно отслеживает всю совокупность причинных связей. Я уже делал отдельный доклад, в котором я, так сказать, показывал, что на основании обнаружения всех возможных причинных связей, если делать все возможные выводы по ним, то в этом случае можно объяснить множество когнитивных процессов, в том числе понятие когнитомы, теории функциональности и другие физиологические теории. То есть мы можем объяснить тем самым внутренние когнитивные процессы, которые основаны на том, что мы отслеживаем причины следственной связи. Отслеживаем причины следственной связи вполне записывается логически. Хотя, по существу, это вероятностная логика, причем вероятностная логика, в которой вероятность интерпретируется в смысле поппера, как предрасположенность некоторой физической системы к некоторым исходам. То есть, есть вполне определенная, чисто, так сказать, такая интерпретация. Так вот, На основании такого рассмотрения можно как раз и рассмотреть, что это за такая промежуточная информационная реальность. Вот я уже сказал, что, так сказать, основной принцип работы всего уже обуда – это опережающее отражение действительности, основанное как раз на возможности прогнозирования. А прогнозирование – это уже есть информационная теория, предвосхищающая течение событий внешнего мира. А нейрофизиологические, физиологические и психологические теории, они уже как раз должны описывать и обеспечивать, как этот информационный процесс реализуется как раз физиологически, нейрофизиологически и психологически. И более того, вот это отслеживание, оно еще должно соотноситься со внешним миром, потому что если бы внешний мир был случайным, то никакого прогнозирования в нем было бы невозможно. Внешний мир как раз хорошо детерминирован, детерминирован, прежде всего, принципом физического детерминизма, с различием причин и связей. То есть именно за счет того, что, так сказать, внешний мир имеет довольно четкую структуру, мы имеем возможность его прогрессировать и создавать вот эту самую информационную теорию. Так вот, на самом деле, не только эта информационная теория обложения причины к связи, но еще есть некоторые другие законы внешнего мира, о которых я скажу, которые позволяют как раз более точно отражать всю структуру предсказаний внешнего мира. То есть я утверждаю, что совокупность причинных связей одновременно отражается вся структура предсказаний внешнего мира и одновременно описывается все внутренние психологические процедуры, которые находятся в точном соответствии с отражением этих причинных связей. Пойдем дальше. Опять же, эти причины связаны с точки зрения логики и методологии науки. Причинные отношения есть предсказуемые, в том смысле, что если полная предыдущая ситуация известна, события могут быть предсказаны, если будут даны все относящиеся к событию факты и законы природы, то есть как раз это принцип физического детерминизма. Таким образом, причинные отношения свойствуются к выводу предсказаний из имеющихся фактов и законов. А это вот уже довольно четкая логическая схема. которое сводится к дедуктивно-номологической и индуктивно-статистической схеме вывода, предсказаний. И здесь работает чистая логика, но основанная на в том числе причинных связей. Особенно это касается индуктивно-статистического вывода, который основан как раз на причинных связях. Но здесь уже с чисто логической точки зрения возникают некоторые противоречия для системы работочного сознания. Во-первых, возникает статистическая неопределенность. Ну, я об этом уже как-то рассказал, вы будете этого даже пропущу. И фактически для того, чтобы избегать такой неопределенности, нужны вполне специальные причинные связи, так называемые максимально специфические причинные связи. У нас есть точное определение максимально специфических причинных связей, которое удовлетворяет, во-первых, определение Cartwright, вероятностных причинных связей, основанных на бэкграунде. Во-вторых, они еще более и удовлетворяют еще некоторые более сильные связи, которые, так сказать, содержат смысл в том, что причинных связей необходимо использовать максимум наличной информации. Иначе будут возникать те самые противоречия, о которых говорил Юрий Бабуров. Но если как раз учитывать всю максимальную информацию, то можно строго доказать, и это теорема. Юра, это теорема. Возьмите и изучите. Вот что, если мы будем находить причинные связи, которые используют максимальную информацию, то никаких противоречий уже не будет. И на самом деле вот эти причинные связи не могут обнаружиться, например, даже в специально формальном модели нейрон, который обнаруживает эти причинные связи таким образом, что если находятся какие-то стимулы, которые позволяют с большей вероятностью предсказывать некоторые, так сказать, безусловные стимулы же, а потом находятся еще дополнительно какие-то стимулы, которые позволяют увеличить это условные вероятности, они включаются в эту причинную связь. И если они включаются все возможные, то в этом случае мы будем получать прогноз это уже без противоречия. Это опять же формально здесь описано в работе ниже. Кроме того, то самое отражение внешнего мира может быть осуществлено совокупностью специальных нейронов вот такого вида, которые будут отражаться на мире биологическом уровне, то самая информационная модель мира, которая находится в промежутке между реальностью и когнитивным процессом. Это подтверждается также в когнитивных науках. Там есть исследование, например, о прототипической теории восприятия, где говорится, что внешний мир, он имеет высококоррелированную структуру. И категории могут быть рассматриваны в терминах и в чистых случаях, если воспринимающий обращает внимание на корреляционную структуру воспринимаемых атрибутов. С чем это связано? Это связано как раз с тем, как мы отражаем реальность. Дело в том, что вот у нас есть некоторый объект. В нем физика работает с помощью своих законов, но с помощью своих законов она создает его внешние свойства. Но эти внешние свойства, поскольку они получены по вполне определенным законам, с определенными начальными условиями, они между собой связаны высококорреляционной структурой, которая как раз и обнаруживается в рамках когнитивного канауда с помощью, я описываю это как прототипической теории, теории восприятия. Кроме того, есть еще такая теория, которую сформировал Боб Рехтер, это тоже конъюнктивная наука, которая говорит, что такие категории и такие объекты описываются причинными моделями, то есть на самом деле информационные модели внешнего мира, которые находятся в этой проложительной реальности. причинные модели отражения внешнего мира. Так вот, в совокупности причинных моделей, в совокупности всех причинных связей, на самом деле, это у меня был отдельный заговор, можно объяснить все когнитивные процессы, например, когнитома. В том числе, так сказать, теорию концептов более который как раз описывает вот такие нейробиологические комплексы с так называемой интегрированной информацией, которые как раз и содержат в себе зацикленные причинные связи, то есть вот такую причинную модель, которая отражает причинные связи, описывающие некоторые объекты внешнего мира. Поэтому у нас, так сказать, на самом деле надо говорить не о вероятностной логике, А вероятность леологии как логики, описывающие процесс предсказаний, то есть той самой индуктивной статистической логики, которая использует причинные связи. Поэтому для описания когнитивных процессов надо использовать именно вот эту логику. И мозг, на самом деле, он не работает по чистой логике, математической логике, описанной в правилах. Он работает по совокупности причинных связей, по комплексам причинных связей, которые схватывают контекст ситуации в целом. Но это все можно формализовать и причинные связи, у нас есть и математические модели, есть и алгоритмы, которые Это все точно описывают и работающие системы, и есть математические описания вероятностных формальных понятий, которые описывают клеточные ансамбли, то есть на самом деле вот эти вот клеточные ансамбли. И это делают более точно, чем интегрированные информации. Это есть, опять же, отдельное исследование на эту тему. Кроме того, для того, чтобы закруглить возможности использования партийных связей, можно объяснить и теорию функциональных систем, если включить в рассмотрение не только стимул, но и действия. Если мы включаем рассмотрение действия, то обнаружение причинных связей между стимулами и действиями и их результатами можно обнаружить и в том, что описать целенаправленное поведение. Более того, объяснить, почему целенаправленное поведение описывается в совокупности причинных связей. Это объясняется вот на этой картинке. Если у нас возникла некоторая мотивация, некоторая потребность, И мы хотим удовлетворить эту потребность некоторой совокупности действий. Как обнаружил еще Анохин в своих исследованиях, Пётр Кузьмич, о том, что если есть некоторое действие, которое идет от моторных нейронов во внешний мир, то обязательно есть ответвление этих же возбуждений уже внутри мозга, которые идут в проекционные зоны. Поэтому если мы, пытаясь удовлетворить нашу потребность, выполняем некоторые действия во внешнем мире, то обязательно параллельно идёт некоторый сигнал в проекционной зоне, и обязательно найдётся нейрон, который воспримет как результат действий, так как перед этим получили стимул о том, что будет такое-то действие, и на нём образуется причинная связь. После такого действия получается какой-то результат действий из внешнего мира. Если мы потом сделаем еще одно действие и получим, и зафиксируем его результат во внешнем мире еще одним нейроном, то мы и удовлетворим нашу потребность. То мы получим некоторый внутренний контур проанализирования внешнего мира. Тот самый принцип опережающего отражения действительности, о котором говорил Петр Кузьмич Анохин. И в этом случае, когда в следующий раз у нашего потребности возникнет мотивация, Мы по внутреннему контуру еще на диване сможем спрогнозировать, что после такого действия мы получим такой-то результат, а после такого-то действия такой-то результат и удовлетворить свои потребности, мы можем прогнозировать достижение целей на основании совокупности причинных связей. Но более того, на самом деле вероятность и вероятностный прогноз, он играет еще большую роль. но опять же это с использованием вероятностной логики. Это было открыто информационной теорией Моцисимова. что эмоциональная оценка текущей ситуации, которая используется для того, какое решение нам принять. Нам нужно, так сказать, синица в руках или журавль в небе. Синицу в руках мы с большой вероятностью можем получить, но это маленькая добыча либо журавля в небе, большого у нас малой вероятности. Перемножаем невероятность на тот эффект от достижения результата, который мы получим, мы получаем эмоциональную оценку, которые позволяют нам принять решение о чем же мы хотим. Это все тоже достаточно точно описано, и здесь используется фактически определение вероятности, которая используется в искусственном интеллекте, называется теория полезности. Эта вероятность умноженная на полезность. И в этом случае, если мы присовокупим еще причинные связи, имеющие определенные вероятности, вот вероятность основ, которая оценивается эмоционально, мы можем описать достаточно широкий круг когнитивных процессов, опираясь, опять же, на ту информационную теорию, отражение реальности, которое находится между креативными процессами и физической реальностью. Эта теория описывается в совокупности причин и связи, которые в случае нормальных понятий либо прямо прогнозируют достижение результата, либо они циклически зацикливаются на некоторых концептах, тем самым формируя некоторое строение внешнего мира в виде такой его естественной классификации. И мы тем самым получаем еще некоторую промежуточную прогнозируемую теорию, которая находится между когнитивными процессами и реальностью. Именно информационную теорию отражения действительности, как эта философия еще иногда называется. И в результате мы имеем такое тройное рассмотрение. У нас есть внешний мир, принцип физического детерминизма и причинность, которая в результате формализуется в совокупности причинных связей, которые могут образовываться в виде максимально специфических причинных связей. формальной понятии, которая создаёт информационную теорию, которая фактически описывает прогнозирование, прогнозирование внешнего мира, то есть то самое опережающее отражение действительности. нейробиологические результаты, клетчатый ансамбль, эмоции, сознание патанолий в точности к этому же относится, и образ мира Леонтьева. То есть это совокупность психологических, физиологических и нейробиологических реализаций, этого самого процесса, определяющего отношение к действительности. Поэтому вероятностная логика вместе со всеми ее свойствами здесь работает в достаточно полном объеме и в достаточно полном объеме объясняет когнитивные процессы. Причем для этого не нужно использовать какие-то еще дополнительные нейроны. Нейроны с нашей точки зрения – это логиковероятностные нейроны, имеющие совершенно четкий смысл, который представляет собой совокупность логиковероятностных правил. Эта модель интерпретируема и в том числе обладает всеми свойствами реальных нейронов. Сейчас мы даже проводим работу такое, что мы можем взять любую напереразадную нейронную сеть, ее обучить, как это она обучается, а потом каждый конкретный нейрон, входящий в нее, заменяем на логиковероятностный нейрон, и хотим при этом получить, во-первых, интерпретируемую, во-вторых, принципиально более точную логиковероятностную нейронную сеть. Поэтому про старое, после того, как мы все это провернем, про… можно будет заменять старые геоносити на новые. Так, у меня все. 

S05 [01:36:36]  : Евгений Евгеньевич, спасибо большое. Есть вопросы у Сергея Терехова, у меня и у Александра Балдачева. Сергей, пожалуйста. 

S01 [01:36:49]  : Сергей Евгеньевич, добрый вечер. Спасибо не только вам и всем, кто выступал. Я всегда очень внимательно слушаю ваши выступления. И каждый раз у меня возникают дополнительные вопросы. Это наслаждение, если хотите. Спасибо большое. Вот группа вопросов, которая у меня сегодня возникла, она из трех частей состоит. Первая часть касается вот этой всей понятия, вся необходимая информация, которая приводит к физическому принципу физического детерминизма. Тут есть действительно такой комментарий, связанный с тем, что если эта информация конечна, то тогда мы находимся в состоянии, так сказать, вот работы с конечными какими-то объемами и так далее. Но утверждать о том, что вся необходимая информация, которая детерминирует природу, является конечной, то бишь она доступна наблюдателю, который конечен, это аксиматическое утверждение. Если даже она счетная, то уже есть там вопросы, потому что в зависимости от того, как вы будете суммировать эту информацию, подпоследности могут сходиться к разным вещам. Если она превышает счетную, то там уже возникают вообще более сложные вещи. Поэтому на самом деле вы не явно предполагаете, что вот эта самая информация, которая полностью специфицирует природу, она является конечной. Правильно я понимаю вас? 

S04 [01:38:19]  : Правильно, сейчас я отвечу на ваш вопрос. Это первая из трех. Я понимаю, да. Нейрон, конечно же, улавливает конечную информацию. И количество стимулов, которые он воспринимает, десятки тысяч, оно все равно конечное. И более того, он в каком-то определенном смысле определяется на частотную интерпретацию вероятности. Но фокус в том, что вот эту теорему мы можем доказать для любого формального определения вероятности, в том числе для частотной. Поэтому даже эта теорема, она не противоречива, верна даже для частотной вероятности, которую использует Мирон. Но понятное дело, что эта частотная вероятность, она, так сказать, приближается к той самой реальной вероятности, которая нам неизвестна и в пределе к ней стремится. И это, так сказать, у нас в статье как раз И есть две вероятности. Одна физическая вероятность, вероятность в реальном мире, то есть вероятность тех действий, тех последствий, которые мы делаем, которые будут происходить в реальном мире. И та вероятность, которая используется при нашем... Евгений Геннадьевич, уточните, пожалуйста, терминологию. 

S01 [01:39:27]  : Все-таки вы говорите о принципе детерминизма мира. Или вы все-таки относите некоторые явления мира к чисто вероятностным? Вы говорите о том, что есть правильная вероятность, реальная, а есть какая-то внутренняя субъективная. 

S04 [01:39:42]  : Правильная вероятность – это вероятность по Попперу. Попперская интерпретация вероятности – это предрасположенность физической системы к определенным исходам. Это внешняя вероятность. А вероятность, которую использует нейрон, это конечная вероятность, которую он получает. Но теорема доказана для любой такой вероятности. Она верна и для нейронов, и для физических. 

S01 [01:40:06]  : Но подождите, чтобы сделать утверждение, нужно сделать утверждение и в отношении системы, в которой есть вероятность. И в отношении того, что мы моделируем, то есть реального мира, в котором тоже есть вероятность. Вот это второе утверждение, оно аксимонатическое, оно введено уважаемым господином Карлом Поппером, потому что у него такие воззрения на реальный мир. есть и другие там воззрения и так далее. то есть это вещь, которая на самом деле это же не непроверяемая вещь. вот если мир устроен так, как считает Карл Поппер, то тогда между этими двумя вероятностными структурами... ну понятно, вот это вот момент, который... потому что мы теряемся в какой-то момент говорить о структурных доказательствах, а в каких-то моментах мы говорим об аксиматических утверждениях. А поскольку вы своей харизмой нам даете такую точную информацию, то может создаваться впечатление, что вообще все доказано. А в действительности там есть вот эти самые... Хорошо, значит с конечностями разобрались. Теперь в отношении причинно-следственности. Здесь есть вот такая сложность. Вообще говоря, причина-следственность – это чисто свойство той самой промежуточной системы, то есть это чисто человеческая конструкция. И она релятивистская, то есть она относительная. Ну, это понятно почему. Ребенок может иметь свою собственную причину-следственную объяснение наблюдаемых явлений, исходя из той картины мира, которую он сейчас воплотляет. По мере расширения этой картины мира он узнает о новых явлениях, о новых свойствах, Он по-прежнему теперь старое явление тоже может объяснить причинно-следственным образом, но это уже будут другие причинно-следственные структуры и длинную цепочку могут вырасти, может нет. И там по мере роста знаний, Вот эта вот причинно-следственная объяснимость, свойство объяснимости, оно меняется. То есть, оно релятивистское. Это значит, что от человека к человеку оно меняется и так далее. То есть, это конструкция, которая свойственна вот нашему свойству, нашему информационному процессу. 

S04 [01:42:11]  : Это дифференциальная стимула называется. 

S01 [01:42:13]  : Я понимаю, но это все про наши информационные процессы, не про природу. Вопрос о том, существует или нет причинно-наследственной связи в природе, он сложный. Почему? Потому что если есть причинно-наследственная связь, то должен быть носитель этой связи. Если мы материалисты, если мы исходим из материалистического понимания мира, то для того, чтобы причина воздействовала на наследствие, должен быть носитель, который, вообще говоря, порождается причиной и дальше влияет на наследство. Если этого носителя нет, И тем более, если это носитель вероятностный, неустранимо, то тогда можно говорить о причиноследственности. Там Алексей Бур спрашивает, ну хорошо, это наверное отметим. То есть причинно-следственность, я что хочу сказать, что причинно-следственное понятие это исключительно свойства нашего мышления. То есть это наши субъективные, релятивистские, зависящие от человека, от его состояния и так далее свойства. Они могут быть сложными, могут быть простыми, но это вот такие всякие вещи. И теперь, соответственно, вы с этим согласны, да? 

S04 [01:43:26]  : Нет, я согласен, да, я могу ответить. Второй вопрос закончен? 

S01 [01:43:31]  : Ну, вопрос именно в отношении того, что нет такого понятия, как абсолютные причинно-следственные связи, какие-то абсолютно более правильные или менее правильные. Это вещи субъективные. 

S04 [01:43:41]  : Причинно-следственные связи, разумеется, различаются. Есть физические причинно-следственные связи, есть носитель. И там можно проследить, что на что воздействует круг последовательности. 

S01 [01:43:51]  : Вот с этим утверждением, простите, я как с доказанным, как с аксимостическим утверждением, я готов согласиться. Но как с доказанным, а на самом деле нет. Почему? Ровно потому, что я задавал первый вопрос. Первый вопрос касался того, что все это можно сделать, обосновать, если конечная информация. Если информация не конечная, счетная или там дальше, то установить факт причиноследственности структуры мира, вне нашего сознания. Объективная причина, естественно, не представляется возможной. 

S04 [01:44:28]  : Я рассматриваю так называемые логики вероятности причинной связи. Они определяются немножко отдельно. Понятное дело, что они есть, во-первых, отражение реальности, во-вторых, они, разумеется, ухватывают, так сказать, конечным образом события внешнего мира в виде определенных стимулов. и это логика вероятности причинных связей. то есть то опрыгнение, которое есть, теорема доказана в том числе, относительно логики вероятности причинных связей. 

S01 [01:44:58]  : понятно, то есть если есть две системы логики вероятности причинных связей, то между ними ваша теорема утверждает, что Анни с Вадимом и понятно. а при этом их существование постулируется, потому что оно постулируется, не является следствием теоремы. Это не доказано. В этом нет никакой слабости. Я просто для того, чтобы было точно. И теперь вопрос в отношении принципа физического детерминизма. Здесь тоже возникает такая вещь. Представьте себе, что есть два наблюдателя, и они начинают употреблять информацию, собирать туда достаточно необходимую информацию, максимально достаточную информацию о каком-то событии. Но один действует быстрее, другой действует медленнее, но оба действуют с конечной скоростью. Из этого следует, что если опять-таки с первого вопроса, что если мы не имеем дело с конечным объемом информации, то у этих наблюдателей нет шансов собрать максимально детренирующую информацию. То есть ни у одного, ни у другого. Один остановится вообще на полпути, второй продвинется дальше, но все равно не соберет эту информацию. Из этого следует, что фактически у нас нет шансов увидеть детерминированность этого мира. Он все время будет представляться нами, то есть как только вы добавите время, именно время сбора информации, не просто вот если собрать информацию, это же утверждение предполагает процесс сбора, процесс с конечной скоростью происходит в любой системе, в живой системе, физической системе или какой-то еще. Этот процесс, он лимитирует объем информации, которую мы в состоянии собрать. Это не относится к ментальным процессам, потому что ментальные процессы могут происходить очень крупными объемами, какими-то перепрыгиваниями. Они могут сразу на бесконечность уводить запросто, даже не определяя, что это такое. То есть ментальные процессы, сколько угодно, пожалуйста, здесь нет вопросов. Но если мы говорим о сборе информации о реальном мире для того, чтобы получить принцип терминизма, то получается, что ни живому наблюдателю, ни роботу, которая будет намного быстрее, чем живую, но все равно конечной по скорости, установить факт максимальности собранной информации для получения детерминированного описания не представляется возможным. Правильно? Правильно. 

S04 [01:47:21]  : Дело в том, что, конечно, например, Карна приводит такой пример, что произошла автомобильная авария. Как определить причину это автомобильной аварии? То ли водитель, на него солнечный гулик попал, то ли стекло, то ли он был немножко не в себе, то ли у него психологические причины, то ли в машине что-то было не так, то ли асфальт был не совсем твердый, то ли резина не совсем мягкая, то ли что-то проскользнуло и так далее, и так далее, и так далее. Понятное дело, что для того, чтобы физический детерминизм работал, нам нужно ограничить эту ситуацию. То есть как в принципе физический детерминизм. Есть некоторые начальные условия. которые фиксируют не все. Есть совокупность некоторых начальных условий, которые мы взяли и зафиксировали. После этих начальных условий есть система уравнений, которая… Опять, Евгений Евгеньевич, опять, конечно. 

S01 [01:48:17]  : Если конечно, можем зафиксировать. 

S04 [01:48:19]  : Если бесконечно, не можем зафиксировать. есть, конечно, система уравнений, которая все это описывает, то мы можем просчитать. 

S01 [01:48:29]  : Дальше понятно. Да, конечно, но после этого эта система становится аксиматической, потому что мы ее волонтаристским способом сделали конечной. Мы же остановились в каком-то месте, это было наше решение. Это наше чуть ли не субъективное решение, вот в этом месте систему ограничить. И после того, как мы вот это решение приняли, в дальнейшем мы изучаем, вот это на самом деле наше решение, мы изучаем наши следствия, наше восприятие действительности, уже теперь не реальность, а только вот эту нашу самую ограниченную нами же систему уравнений. В отношении вот тут Алекс Бур просто к нашей дискуссии, он говорит о том, что причина следственной связи, значит, объективное свойство системы и упоминает инварианты. действительно инварианты, они просто приводят к тому, что некоторые классы событий становятся неразличимыми, но не более того. то есть они не детерминируют систему до детального причинно-следственного баланса, существование которого непроверяемо просто из-за того, что у нас нет способа это делать. но ментально нам никто не мешает. мы можем построить модельскую любовь. Евгений Евгеньевич, спасибо огромное еще раз. очень было интересно и приятно. 

S05 [01:49:41]  : Сергей, спасибо. Вот я здесь подхвачу тему про причинно-следственные связи, поскольку тут у меня был на эту тему вопрос, и у Алекса Ксабура тоже есть комментарий. Значит, вопрос следующий, значит, как бы подводящий. Евгений Евгеньевич, я правильно понимаю, что Вот то, что вы пишете, точнее говорите, про причинно-следственные связи, на самом деле и то, что мы подразумеваем под вероятностной семантической логикой или системой семантического моделирования с использованием логики вероятностного вывода, это все просто инструменты для построения моделей. Правильно? Можем мы так сказать. 

S04 [01:50:20]  : Модели чего? Модели определенных моделей мира, определенных моделей ситуации, определенных моделей контекста, в котором мы принимаем ситуацию. Да. Вот. 

S05 [01:50:35]  : То есть, здесь как раз вот есть большая синергия того, что вы говорите с тем, как я это себе вижу, и то, что вот Алекс Бур у нас в группе пропагандирует, в частности, отсылаясь на ваши работы. Вот. Значит, тогда вот я, собственно, задаю свой вопрос, который здесь есть. Правильно ли я понимаю, что вот этот вот формализм для используемой для описания моделей, он может применяться на разных уровнях, на разных уровнях, начиная от отдельного нейрона и кончая формальных умозаключений, которые вы или другие математики используют в своей работе. 

S04 [01:51:14]  : Да, совершенно верно. Как Константин Владимирович Анофильевич еще говорит, он приводит при этом картинку из Танони, что, во-первых, отдельный нейрон, он уже интегрирует информацию входящую и выдает, так сказать, вполне определенную информацию о... нейрон либо возбуждается, либо нет. Это уже есть некоторый класс. Принадлежит некоторому классу или не принадлежит. Следующий уровень, это так называемая вторичные признаки. То есть вот у нас, как пишет Гибсон в своей книжке «Экологические теории восприятия», мир устроен иерархически. В нем есть некоторые деловые элементы, пищинки, листья, деревья, почки. То есть все элементы, все Объекты внешнего мира состоят из кирпичиков, есть еще более элементарных либо элементов, либо частиц, либо вполне определенных свойств, так называемых вторичных признаков. Так вот, как только мы получаем, что это вторичный признак, это встречается в разных местах, окружающего мира, можно доказать, что он в этом случае автоматически будет формировать и обнаруживаться в некотором вероятностном формальном понятии. Поэтому вторичные признаки тоже формализуются в вероятностном формальном понятии. Понятия классы и некоторые естественные объекты внешнего мира тоже формализуются в вероятностном формальном понятии. Контексты в смысле каноний. И прототипы, в смысле Элеонор Рош, тоже описываются вариантно-формально понятиями. 

S00 [01:52:55]  : Идем выше. 

S04 [01:52:56]  : Контексты. Контексты, в рамках которых мы воспринимаем ту или иную ситуацию. И в частном случае контекст является функциональной системой, когда мы достигаем какой-то определенной цели и решаем какую-то определенную задачу. Вот эти контексты, это тоже есть вероятность для формальной понятия, потому что мы вытаскиваем из памяти всю информацию связала с данной ситуацией, причем именно с данной ситуацией, чтобы не включать сюда другие правила, которые не имеют к ней отношения, потому что именно формируя определенный контекст, мы выделяем и вырезаем те правила, которые наиболее точно работают, подобных ситуациях, и поэтому у нас прогноз будет наиболее точный. Опять же, с точки зрения наиболее точного прогноза, нам нужно выделять вот эти контексты. А эти контексты – это, опять же, замкнутые на себя причинные связи, которые описываются вероятностными формальным понятием. И, наконец, самый высокий уровень – это так называемый образ мира, который описывал Леонтик. И самая последняя его статья, которая у него была на рабочем столе – это как раз описание образа мира. То есть всего того образа мира, который создается у человека, или Константина Владимировича Анотина, так называть, разу. Это то всего, чему мы обучились, все, что у нас сформировалось в результате системы обучения, и что мы используем для ориентировки и работы, и принятия решений во внешнем мире. Поэтому это иерархия от начала до конца. 

S05 [01:54:32]  : Спасибо, Евгений Евгеньевич. Тогда следующий вопрос по цепочке, которая идет. Правильно ли я тогда понимаю, что язык и языковые феномены и неоднозначность, про которую говорил Юрий Бабуров в своем докладе, И вообще само понятие осознанности для принятия решений вообще как бы имеют опосредованное отношение к тому, что вы рассказываете, потому что язык – это просто некоторая вершина айсберга, построенного на основе тех принципов, про которые вы говорите. Или, может быть, даже не вершина айсберга, а какая-то некоторая пристройка сбоку. Ну и осознанность тоже, то есть то, что вот те, так сказать, причинно-следственные связи, которые мы руководствуемся при принятии решений, они не всегда могут быть осознаны, могут быть нет, и большинство из них на самом деле не осознаны, а в осознанное попадает очень маленькая часть, еще меньшая часть оказывается выражена через язык. Это правильно? 

S04 [01:55:37]  : Но здесь два вопроса на самом деле. Во-первых, первое, что у нас особо, а что нет. Это очень легко демонстрируется тем, что у нас есть так называемая интериоризация деятельности. Вот мы, когда в первом классе буквы выводим последовательно, выписываем А, В, а во втором классе мы это уже делаем быстро. То есть мы совершенно бессознательно вот эти действия, которые мы первоначально не мучили, они потом происходят бессознательно. И все эти, они переходят в автоматизм. И выстраивается иерархия автоматизма. Так вот, дело в том, что когда опытный пилот ведет самолет, или, так сказать, водитель ведет машину, он не чувствует рычаги вот эти, чего он куда нажимает. У него же настолько богатый опыт, что это делается автоматически и бессознательно, на основании уже подсознательных правил. Но главное, что он отслеживает, он отслеживает вероятность. Вероятность достижения цели, он отслеживает движение цели, где цель, куда повернуть и что делать. То есть там, где у нас нет автоматизма, нет стопроцентной, так сказать, по планированию действий, а там, где есть небольшие расхождения или возможность выбора, у нас там сосредоточено внимание и сознание. А остальное находится действительно под сознанием. Это ответ на первый вопрос, что у нас осознано, а что нет. Теперь по поводу языка. Дело в том, что сейчас в языке как раз разрабатываются такие методы, в том числе нейронными сетями, так сказать, Attention, Transformer и всякие прочие, которые как раз и пытаются замоделировать те самые контексты. И поэтому такие методы разорваться. Более того, их эффективность напрямую зависит от того, насколько точно они эти контексты вылавливают. 

S05 [01:57:28]  : Спасибо. Следующий вопрос. Вы согласны с тем утверждением, которое Ольга высказывала, апеллируя к Александру Балдачеву, что на самом деле, даже если люди не понимают, что они используют какую-то логику, нечеткую, расплывчатую, неаксиматическую, то это не значит, что они ее не используют. Они все равно принимают решения на основе каких-то причинно-следственных моделей. 

S04 [01:57:58]  : Так вот, психология как раз это знает наиболее точно. Она рассуждала в точности в соответствии с тем, что я рассказывал. Абсолютно точно. С психологами в этом случае гораздо удобнее говорить, чем... так сказать, с другими людьми. 

S05 [01:58:12]  : Хорошо, спасибо. Тогда следующий вопрос по поводу как раз вот комментария, значит, Алексбура, на который ссылался Сергей. Значит, вот что пишет Алексбур по поводу того, что в физическом мире нет причинно-следственных связей. Так, сейчас я найду этот комментарий. Причинно-следственная связь – это просто следствие наличия системы. Какая бы система ни была, в ней будут какие-то инварианты, по сути, законы. И эти законы будут обеспечивать причинно-следственные связи. Представить мир без причинно-следственных связей я не могу. В литературе мне такое тоже не встречалось. Вы согласны, Евгений Евгеньевич, с таким утверждением? 

S04 [01:58:57]  : Не, ну согласен, но в этом случае он сам ответил на вопрос. Да, да, это не вопрос, это просто я вот фиксирую. Это как бы апелляция. Да, должна быть система рассмотрения. 

S05 [01:59:09]  : Это апелляция к тому, что Сергей Терехов говорит. 

S01 [01:59:11]  : Евгений Аркадьевич, тогда вы со мной должны быть не согласны, потому что вы либо согласны с тем, что мы говорим о причинно-следственной структуре внешнего мира и знаем это, либо мы так не говорим. 

S04 [01:59:23]  : Нет, так Александр Буржуев сказал, что должна быть некоторая система. Система, что есть система. Я как раз так и понимаю, что нами выбранная система рассмотрения, что мы фиксируем. 

S01 [01:59:34]  : О, ключевое место – нами выбранная. Значит, это ментальный образ тогда. Если совершенно верно, так я вопрос… Ну все, тогда вы согласны со мной, но не с Алексом. 

S04 [01:59:45]  : Нет. А у него в самом начале утверждения она сказала, что система. Система чья система? Нами поставлена система, нами сформулирована система. Ну, разумеется, я так понял, по крайней мере. 

S01 [01:59:57]  : Нет, а посмотрите, Антон, пожалуйста, там указано, что... Нет, там не сказано, какая система. 

S05 [02:00:04]  : Нет, Сергей, по-моему, как раз Алекс Бур был с вами не согласен, потому что вы сказали, что в физическом мире нет причинно-следственных связей. 

S01 [02:00:11]  : Я сказал, что мы не можем это установить. У нас нет возможности это установить. Но они же есть. У нас с вами в голове они есть без сомнения. 

S05 [02:00:26]  : Хорошо, коллеги, давайте продвинемся. У меня как раз следующий вопрос именно на эту тему про нас с вами. Вот смотрите, Евгений Евгеньевич, допустим есть причинно-следственная система, некоторая система внешняя с причинно-следственными связями, которые обусловлены действующими в мире физическими законами. которые есть безотносительно от нашего желания и восприятия. И при этом у нас есть некоторые субъекты, которые наблюдают эти физические системы. То есть, переходим на субъективный уровень. И у этих двух субъектов, или их может быть больше, Сергеев, Александр Болдачев, Алекс Бур, У них различный жизненный опыт, различная скорость восприятия, различная острота зрения, слуха. И они воспринимают какую-то часть тех природных феноменов, которые им даны в объективную реальность. Я правильно понимаю, что у каждого из этих наблюдателей будет своя собственная причинно-следственная модель вот этого объективно существующего мира? 

S04 [02:01:31]  : Конечно же. Он будет достаточно субъективен, причем будет зависеть от того, во-первых, той массы стимулов, которые люди воспринимают, они вообще воспринимают в разности стимулы. А во-вторых, от того обучения или того опыта, который у них есть. Например, было такая информация, что если человек видел какой-то Какой-то там… Я про это рассказывал. 

S05 [02:02:10]  : Я видел летающую тарелку, поэтому существование летающих тарелок для меня не является вопросом вообще. 

S04 [02:02:16]  : Да-да-да. Или вот они после этого начинают это видеть. Такие бестелесные вот эти существа. Если у него такой опыт был, он сможет видеть. Если у него не было, он это не видит. То есть от опыта это, понятное дело, тоже сильно зависит. Кроме того, у людей есть масса так называемых вырожденных стимул, которые еще не исследованы до конца. Понятие милоты, как реагировать на детей. Есть масса дополнительных стимул, которые мы воспринимаем даже неосознанно. Они различны у разных людей. 

S05 [02:02:58]  : Хорошо. Спасибо. Еще у меня два вопроса есть осталось. Один вопрос, по-моему, у нас вместе возникло. Некоторая Эврика с Юрием Бабуровым. У меня такой вопрос возник. Вы сказали, что мы умножаем вероятность на эмоцию. А у меня возникает такой вопрос. А мы вообще эмоцию не можем выразить тоже через вероятность? То есть, что такое эмоция? Эмоция – это вероятность удовлетворения достижения некоторой суперцели. То есть, если вероятность какого-то шага в направлении каких-то двух целей разная, то мы считаем не только вероятность того, какой шаг с большей вероятностью будет успешно выполнен, но и того, насколько велика вероятность того, что цель, которая в итоге будет достигнута, будет на самом деле достигнута. И тем самым важность этой цели, она на самом деле, и эмоциональное подкрепление конкретного шага тоже может быть исчислено через вероятности. И вот то, что Юрий пишет. Вот восклицательный знак. Теория полезности – это есть вся область применения вероятности в семантических логиках. 

S04 [02:04:18]  : Ну да, но это и есть как раз произведение вероятности на то качество удовлетворения или то качество потребности, которое мы в конце концов получим. 

S05 [02:04:28]  : Хорошо. И последний вопрос. У меня он был более мягко, а у Александра Балдачева звучит гораздо более категорически. Если все строго описано, есть куча теорий и принципов, имеется однозначное понимание процесса, включая когнитивные, то чего не хватает для мало-мальски убедительного результата? Не прячется ли за таким большим списком теорий, которые все объясняют, отсутствие хоть какой-то теории? 

S04 [02:04:55]  : А какой именно? Пожалуйста, любой вопрос. Что надо объяснить с помощью причинных связей? 

S02 [02:05:02]  : Наугад. Нужно не объяснить, а хочешь делать какой-нибудь продукт. Что? То есть объяснять мы можем всегда. Всю жизнь всегда все объясняли. Если теория описывает, есть четкое представление, значит, должно быть какое-то воплощение. 

S04 [02:05:16]  : Программное воплощение? 

S02 [02:05:18]  : Ну, хоть какое-нибудь. Нет, у нас есть программы-эксперименты, есть программы… Это на уровне когнитивных экспериментов? Или имеется в виду нематода шевелиться? Да, нематода и… Ну, понятно. Тогда нужно исключить слово «когнитивных» из вашего доклада и рассуждать только о примитивных движениях, примитивных животных, которые подчиняются причинно-следственным связям. Но вы же рассказываете про теорию. То есть у вас огромное количество теорий. Десятка-полтора теорий, которые между собой не согласованы, которые из разных областей. Одни из Диамата, другие там ближе к кокодилистическим каким-то, какие-то технологические. Вы всех в одну кучу собрали, все на них ссылаетесь и говорите, что вот они все подтверждают что-то одно. А что? 

S04 [02:06:09]  : Но вот на самом деле в теории этанонии там есть формулы, я могу сравнивать формулы. 

S02 [02:06:15]  : В теории этанонии ничего не следует, это просто несколько формул, которые просто взяты с потолка. Ну нет, не с потолка, не скажите. С потолка, никаких подтверждений в теории этанонии еще нет, это просто формулы. Ссылаться на это как на что-то достоверное, ну согласитесь, совершенно несерьезно. 

S04 [02:06:36]  : Есть еще описание, так называемое у Соколова, так называемый моделирование стимулов. 

S02 [02:06:45]  : Вот у него тоже есть довольно… Вот вы подтверждаете, что есть куча-куча теорий, которые вы для одного применяете одно, для другого третье, для четвертого четвертое. Со всех сторон вы как бы находитесь, а есть теория еще такая, а есть еще теория такая. Но если мы говорим о описании некого явления моделирования, должна быть одна теория. 

S04 [02:07:03]  : Так вот у меня одна теория… Стоит из десятков и других. Понятно. Я могу более-менее точно сопоставить. 

S05 [02:07:12]  : Хорошо. Спасибо. Евгений Александрович, спасибо. Я все-таки уточню вопрос, как он у меня стоял. Меня не столько теория интересует, сколько практический выход. Вот что хорошо про нейронные сети, которые ничего не знают про логики вероятностных выводов и только сейчас начинают туда двигаться с помощью трансформеров, тем не менее нейронные сети решают массу задач, включая разговорных ботов, распознавание чего угодно и даже предсказание чего-то. чего только не захочешь. У вас есть какие-то примеры, помимо экспериментов, которые про мышей вы показывали, про нематоду, про агента. Какие-то примеры есть? Вот внедрение вот этих разработок в производстве, что называется. Я так понимаю, вы же с компанией Бумирова работаете? То есть, что-то оно на практике работает? 

S04 [02:08:19]  : Да, у нас есть реализация обнаружения причинных связей на таком уже довольно хорошем уровне. на параллельных процессах, на кластере, то есть там есть достаточно эффективные, то есть, скажем так, более-менее не слишком большие, но достаточно промышленные задачи мы можем решать. А по поводу глубокого обучения у нас была одна статья, самостоятельная статья, мы вместе с моим аспирантом поставили задачу сравниться с какой-нибудь статьей по глубокому обучению. Мы такую статью нашли как раз по анализу языка. И промоделировали ту задачу, которую они решали с помощью глубокого обучения. Мы получили по точности сравнимый результат, но объяснимый, так сказать, по прогнозам, по двум словам, по тем данным, которые были взяты из некоторых репозиторий. То есть, эта статья есть, она есть на сайте. 

S05 [02:09:28]  : А можете на нее ссылку прислать? А, прямо в чат? Ну, если можно, прямо в чат, или потом, в крайнем случае. Евгений Евгеньевич, а еще сразу вопрос, а по производительности, то есть по точности, по точности объяснимости вы сказали, а по производительности? 

S04 [02:09:44]  : Ну, точность, понятное дело, выше, производительность, понятное дело, хуже, потому что точность без... точность, значит, даром не получается. 

S05 [02:09:57]  : А хуже что значит? Просто нейроны нейросети же вычисляются обычно на кластерах с ГПУ? 

S04 [02:10:08]  : Нет, а у нас тоже с ГПУ. У нейросети, например, есть проблема забываний. Если они решают одну задачу, она переобучается. переобучается на следующее, то она предыдущие забывает. А у нас, поскольку в причине связи они все довольно точно настраиваются на ту информацию, которая поступает, они этим дефектом не обладают. Вот она что выучила, она это будет помнить. Это в частности моделирует так называемый эффект компенсаторной функции эмоций, который Симонов наблюдал, что если мы попадаем в новую ситуацию, мы тем не менее в ней можем применять некоторые свои старые правила, не специализированные, а старые, потому что мозг их все помнит. Вот, и он в новой ситуации способен... Евгений Евгеньевич, комментарии очень важные есть. 

S01 [02:11:03]  : Дело в том, что ваша система, она действительно помнит те связи, которые вы называете причинно-следственными, я их называю корреляционными, потому что это соотношение между элементами, а вы их называете причинными, но это неважно. Важно то, что она вместе с ними помнит свои ошибки. Поскольку она обучилась на конкретном конечном наборе информации, то она вытащила корреляционные связи или причинно-следственные связи в вашей терминологии. Те, которые достаточны для того, чтобы ту информацию, на которую она училась, объяснить. Все то, что не присутствовало в этой обучающей информации и тем самым было неправильно объяснено, закрепилось. И вы будете продолжать эти ошибки тянуть с собой и наставить на них. То есть надо этот момент понимать. Потому что когда Антон Гермич говорит, что нейронные сети пытаются идти в сторону какой-то логики, надо понимать, что они запросто могут обучиться базе данных, которая алогична сама. Вы просто берете примеры, которые в своей совокупности содержат внутри себя логические противоречия. Но из-за того, что это оверкомплитная штука, она запросто запомнит все метки. То есть она концептуально генетически не способна к логическому выводу, потому что для того, чтобы она была способна к этому, она должна сначала все эти ошибки обнаружить, восстановить их на правильные и запомнить правильные. Этот вопрос мы с Михаилом Бурцевым обсуждали на его выступлении недавно на семинаре по Байке, когда я ему приводил пример о том, как быть с человеком, который научился утверждать, что он знает таблицу умножения, но делает ошибки при умножении на число 7. Вот он все остальное прекрасно умножает, а на семерку умножает с ошибкой. Тогда в таблице умножения он делает 81% правильных утверждений. Вопрос, этот человек чему-нибудь научился или нет? ответ он не научился ничему хотя точность у него 81 процент даже если он понял суть операции умножения ее аксиматическое содержание там через сложение так далее так далее то то что мы наблюдаем невозможно то есть 81 процент точности ничего не говорит об обучаемости этой системы вот просто это мы с Михаилом это обсуждали но вот его здесь нет к сожалению нашему обсуждению еще присоединился Поэтому, когда вы говорите, что нейронные сети, обученные на каких-то базах, стремятся к какой-то логике, это, по крайней мере, это дискуссионное утверждение. 

S04 [02:13:31]  : Между прочим, вот это теорема, которая здесь у меня на слайде. Какие бы данные ни были, какие бы зарковерки, смешины и все прочее, они не были. Системе дается эти данные, она их анализирует. анализируют полностью, то есть она находит все максимально специфические правила и поискала после этого без противоречий. у нее и нет 80 процентов ошибок. 

S01 [02:13:54]  : Евгений Никитич, она анализирует, вы только что правильно сами сказали, она анализирует те данные, которые ей дали. если дать ей новую порцию данных, которые 

S04 [02:14:03]  : отвергает утверждения, которые там были, то, короче, вы утверждаете… Понятно, что если у нас правила другие, она будет делать ошибку. Но у этих систем есть дифференциация стимулов. То есть, вот как человек обучается? Он сначала обучается главу, а потом все тоньше, тоньше, тоньше. Это, так сказать, в процессе Обучение человека – это психология, это эффект. Мы начинаем использовать и включать в свои действия все более тонкие и тонкие стимулы, и они автоматически будут включаться вот в эти правила, которые обнаруживаются, максимально специфические. И она автоматически потом исправит ошибку, автоматически доучится. 

S01 [02:14:45]  : Евгений Евгеньевич, это отсылка тоже. Дело в том, что этот самый человек может запросто, по мере улучшения своей юстировки, перейти в систему ошибочных представлений и продолжать в этой системе ошибочных представлений юстировать, уточнять свое представление, но на самом деле он будет удаляться от истины. Понимаете, это же как бы... Коллеги, извините, у нас еще есть... А нет, подождите, подождите, не уходите, я вам отвечу. 

S04 [02:15:14]  : Вот, а то, это самое, дайте ответить. Вы сформулируете очень правильный ответ. Вопрос. Вот он уходит в другую немножко область. А понятие контекста зачем? Контекст нужен для того, чтобы если мы решаем какую-то задачу, мы берем правила именно в этом контексте, именно верные для этих ситуаций. а не для каких-то других. Понятное дело, что если мы перейдем куда-то в другое место, но если мы с этим тоже работали, у нас автоматически выберется этот новый контекст. Если мы перешли в ситуацию, с которой мы вообще не встречались, понятное дело, что мы первое время будем ошибаться, но мы доучимся. Понятие концепции затем и нужно, чтобы автоматически адаптироваться к тому множеству правил, которые там работают. 

S01 [02:16:08]  : Да-да, я здесь с вами абсолютно согласен. Именно поэтому те тензорные системы, с которыми я занимаюсь, они прежде всего про контекст. Но это уже совсем другой разговор. Спасибо большое еще раз. 

S05 [02:16:17]  : Да, спасибо, коллеги. Есть еще запрос. У нас мало времени. Есть еще вопрос или комментарий у Захара. Захар, пожалуйста. 

S07 [02:16:26]  : Я вкратце. У меня есть вопрос, который из трех подвопросов состоит. Первый – это то, что То, что вы рассказывали, очень сильно перекликается с тем проектом, который я сейчас веду и о котором рассказывал. В связи с этим хотел бы попросить какие-то ссылки на литературу. 

S05 [02:16:45]  : Я скинул только что в чат. 

S07 [02:16:47]  : Спасибо. Второй момент, он связан с нейроном, который вы изобразили на слайде и говорите, что у вас был эксперимент или сейчас проводится, когда вы берете уже обученную сеть, заменяете один нейрон к изображенному слайду и обучаете вот здесь вот несколько непонятно как происходит обучение потому что я вот вижу что здесь операции и между различными входами и вот Идет ли обучение градиентным методам, либо как-то иначе? Ну и если есть какая-то тоже статья, где вы об этом пишете, тоже был бы интерес почитать. 

S04 [02:17:32]  : Да, лучше статью, конечно, да. Но я Антона могу отправить. 

S05 [02:17:40]  : Дарья Евгеньевич, вы можете либо мне переслать, я в группу перешлю, либо сами в группу можете переслать, как удобнее. 

S07 [02:17:46]  : Ну и третий, это скорее как бы насчет аттеншенов, то есть я не совсем согласен с тем, что аттеншены, они выполняют как раз таки, ну можно сказать, что они делают вероятностный вывод. 

S04 [02:18:05]  : Нет, там нету вероятностного вывода, конечно. 

S05 [02:18:14]  : Спасибо. Хорошо. Коллеги, еще есть какие-то вопросы или комментарии, если очень короткие, оставшиеся две минуты? Ну тогда всем спасибо. У меня позитивные впечатления. Были ценные замечания по поводу необходимости четко формулировать утверждение. И Александр Балдачев тоже по формулировкам сделал важное уточнение в самом начале. Но вот расхождение мне показалось появились по поводу того, что мы подразумеваем под строгим доказательством, и что мы понимаем под, собственно, логикой. Является ли это логика, которую мы не осознаем логикой. Но в целом, как я понимаю, нет возражений, что системы, основанные на причинно-следственных связях, системы, позволяющие моделировать окружающую реальность более точно и более объяснимо, чем это делают нейронные сети, они представляются полезными. Хотя тоже, наверное, никто не спорил с тем, что только на одних таких системах можно решить все проблемы и что, наверное, где-то Нужно использовать и существующие нейронные сети, и какие-то способы интеграции одних систем с другими. Другими должны существовать. Насколько я понимаю, в системе, которую Евгений Евгеньевич Витяев с Дмитрием Ивановичем Свириденко разрабатывают, есть понятие оракла. Под ораклом может подразумеваться Любая система, будь то там какое-то механическое устройство, либо это может быть нейросеть, которая решает одну какую-то задачу. А в системе OpenCock, например, есть понятие, при том, что там система предполагает семантическую архитектуру, то есть там есть типизированные связи, типизированные отношения, но там есть такое понятие, как Grounded Schema Node. Игровая схема нод – это некоторые вершины в вычислительном графе, которая на самом деле за собой может скрывать все, что угодно, начиная от альфа-го, или какое-то ядро Берта, или какое-то ядро GPT-3, которые решают совершенно конкретную задачу. Какая-то другая грауниц, схема нод, у них может иметь другую модель того же Берта или GPT-3, решающую другую задачу. То есть, наверное, все-таки нейросимульная интеграция, про которую, кстати, и Михаил Бурцев говорил в своем докладе, на который Сергей ссылается, и который, кстати, в группе был. Я давал ссылку на прошлой неделе. Видимо, это такое будущее, которое будет активно развиваться. Всем спасибо за участие, спасибо докладчикам, спасибо за вопросы, спасибо за ответы. 

S02 [02:21:31]  : До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
