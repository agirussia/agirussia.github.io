## 25 августа - AGI/AI для финтеха и квантов? — Обзор воркшопа AGI-in-FinTech - Антон Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/3aDGldX_DA0/hqdefault.jpg)](https://youtu.be/3aDGldX_DA0)

Суммаризация семинара:

## Формат суммаризации семинара

Тематика семинара

- Семинар посвящен теме финтех в контексте последних достижений в области искусственного интеллекта (AGI) и квантовых технологий.

Суть семинара

- Обсуждались перспективы и нынешние границы применения искусственного интеллекта в финансовых технологиях..
- Подчеркивалось значение стратегического планирования и управления финансовыми средствами, включая выбор источников данных и генерацию фичей для анализа.
- Исследовались методы анализа рисков и построения предсказательных моделей, а также метрики для оценки производительности предсказаний.
- Обсуждались аспекты управления портфелями, осуществления торгов и управления операционными рисками.

Детали семинара

- Приводился список докладов, в том числе работы собственной команды и других участников конференции AGI 2022.
- Упоминалась работа молодого исследователя из Нью-Йоркского политехнического института, который использовал NARS и попробовал мультимодальное обучение для построения универсальных предсказательных моделей.
- Обсуждался анализ социальных сетей, новостей и других данных для генерации метрик сентимента и когнитивных искажений.
- Рассматривалось использование более чем сотни метрик, полученных из рыночных данных, включая производные цен и других финансовых показателей.

Результаты семинара

- Был представлен пайплайн, позволяющий предсказывать рыночные тренды с высокой точностью, используя совокупность данных из социальных сетей и рыночного анализа.
- Обсуждались стратегии трейдинга, включая использование двух стратегий: одна от компании Neox и другая от проекта Humminbot.
- Были представлены результаты торгов на трех видах рынков за разные месяцы, демонстрируя стабильность дохода и влиятельность стратегий на изменения рыночных цен.

Значения и выводы

- Семинар подчеркивал важность интеграции искусственного интеллекта с финансовыми рынками для создания эффективных предсказательных моделей.
- Исследования показали возможности улучшения точности предсказаний и адаптации стратегий трейдинга в соответствии с изменениями на рынках.
- Важностью признан анализ социальных сетей и новостных ресурсов как источника информации для формирования сентиментальных и когнитивных метрик, которые могут дополнить аналитические инструменты финансового анализа.

Применение знаний

- Участникам семинара были предложены методы и стратегии для улучшения управленческих решений в финансовой сфере.
- Рассмотрены практические примеры использования предсказательных моделей и стратегий трейдинга, позволяющих формировать эффективные финансовые портфолио.

Вывод о семинаре

- Семинар представил актуальные исследования и практические подходы, которые могут способствовать развитию и оптимизации финансовых стратегий и дисциплин.
- Приведенные примеры и методы могут быть использованы для повышения точности оценок рыночной динамики и для принятия обоснованных решений в финансовом секторе.
- Семинар подчеркивал необходимость интеграции искусственного интеллекта с финансовыми рынками для создания эффективных адаптивных стратегий торговли и управления финансовыми рисками.






S01 [00:00:05]  : Сегодня у нас не совсем обычный семинар, и ожидаемо немного народу. Видимо, не всем тема, которую мы будем сегодня обсуждать, близка. Но поскольку голосование в группе показало, что кому-то эта тема интересна, и еще больше народу высказали, что они готовы потом посмотреть в YouTube в удобное для себя время, то вот я решил рассказать о том, что происходило в прошлую пятницу. А в прошлую пятницу проходил семинар, который проходил в рамках конференции AGI 2022, это семинар по финтеху в AGI. На самом деле в рамках самого семинара AGI было не очень много, то есть в паре до тройки докладов торчали, если не уши AGI, то попытки притянуть AGI за уши. Но поскольку семинар проходил под эгидой конференции, поскольку эти следы притягивания AGI за уши где-то просматривались, то мы про это сегодня поговорим. Итак, чтобы немножко деперсонализировать повестку, я начну... У нас был список докладов. Первые три доклада были из моей команды. Последний доклад был из другой команды. Четвертый доклад был вообще из другой организации. Я начну с конца. И последний доклад Криса Пулина, он был... Честно говоря, мне он был не очень интересен, но я по нему быстренько пробегу, поскольку в этом докладе докладчик делал попытку как бы с высокой колокольни разобрать, а вообще о чем надо думать, если мы собираемся реализовать собственно, пресловутую систему искусственного интеллекта для финтеха. Причем сразу давайте мы оговоримся, что здесь под финтехом подразумевается все-таки то, что называется quantity finance, потому что Обычно тех, все-таки в расширительном плане, включают в себя в том числе банковские технологии, все, что связано с деньгами, кредитные системы. Мы сегодня и в рамках этого семинара поговорили и будем говорить, собственно, про численные финансы, то есть работу с финансовыми рынками с помощью технологий искусственного интеллекта. Но и основные элементы, где это может использоваться или с которым это связано – это постановка целей или учет целей управления финансовыми средствами, выбор источников данных, на основании которых мы это будем делать, соответственно, какие Данные мы будем брать, соответственно, какие фичи мы из этих данных в конечном итоге будем генерировать. Дальше, какие методы мы будем использовать для анализа рисков и построения предсказательных моделей. Какие метрики для оценки производительности предсказаний и, собственно, какие пороговые значения этих метрик мы собираемся рассматривать. Дальше, каким образом мы осуществляем анализ портфелей, оценивать состояние портфеля в текущий момент, каким образом мы будем осуществлять торги, то есть, каким образом мы будем изменять состояние портфеля методом ребалансируя различные инструменты, находящиеся в нем, либо увеличивать объем этих инструментов за счет различного торгов различного вида далее как мы что мы будем делать с операционными рисками и какие риски у нас могут быть ну и наконец как мы это все будем оптимизировать если пойти по порядку. Я буду на каждый доклад стараться не больше 10-15 минут отвести в качестве обзора. А в перерывах можно будет делать вопросы, может быть что-то обсуждать. вот соответственно значит когда мы говорим о том какие мы ассеты инструменты или финансовые ресурсы будем использовать значит соответственно это возникает вопрос либо это equity либо бонды либо валюты либо мы работаем с криптой Каковы наши метрики успеха? Каким образом мы собираемся выходить из инфекционных циклов? Это вопросы больше скорее к бизнесу, но в дальнейшем их нужно будет учитывать. Каким образом с этим связано? От того, какие мы берем инструменты, у нас связано, какие мы берем данные. Допустим, если мы работаем с обычными рынками, то очевидно, для фундаментального анализа нам нужно анализировать отчеты тех компаний с инструментами, с которыми мы работаем. То есть фундаментальный анализ должен составлять некоторую часть. А если мы работаем с криптой, то у нас бухгалтерских балансов Компании, выпускающих соответствующие инструменты нет, но у нас есть блокчейн. То есть, соответственно, мы можем брать информацию из блокчейна, и это является альтернативой и фундаментальному анализу в обычных финансах. Каким образом мы вообще подходим к задаче предсказательной аналитики? Либо, допустим, мы генерируем сигналы какие-то на покупку, на продажу и работаем по этим сигналам, либо мы это дело автоматизируем, то есть мы строим каких-то ботов, которые в автоматическом режиме управляют уровнями лимитированных ордеров, к примеру. А мы периодически оцениваем их производительность. Как раз на эту тему будет один из докладов, который мы будем разбирать. Или мы строим мультиагентную систему на искусстве, в том числе с автоматическими агентами, которые сами обучаются на торгах и о том, как правильно торговать. И сами успешно торгуют. Это, с моей точки зрения, на сегодняшний день из области фантастики. Каким образом мы оцениваем производительность? Каким образом мы разбиваем на тестовые и валидационные сплиты? Каким образом мы оцениваем, работаем ли мы с временными рядами или мы эти временные ряды каким-то образом символизируем? Либо, как я рассказывал на предыдущем семинаре, либо как это будет в следующем докладе, способ символизации этих временных рядов. И так далее. Дальше анализ портфелей. Каким образом? Либо мы пейпер трейдингом занимаемся, либо мы берем какие-то финансовые метрики. Либо пейпер трейдингом мы, получается, осуществляем торги на бумаге и пытаемся симулировать то, что происходило бы с нашим портфелем, если бы мы осуществляли торги. текущей динамики рынка. Ну а финансовые метрики это типа Шарпе и Сартина коэффициентов, которые позволят оценить собственно рисковость тех или иных финансовых инструментов. Ну и, собственно, торги. То есть, если нам нужно ребалансировать портфель и чего-то в корзине убавить, а чего-то добавить, или если мы хотим, чтобы то, что у нас лежит в корзине, оно активно крутилось, зарабатывало деньги. пусть даже с некоторой долей риска, то как мы собственно эти торги хотим исполнять. То ли мы это исполняем на обычной бирже, если мы работаем по обычным финансовым инструментам, и даже если мы работаем на бирже, здесь опять-таки возникает развилка, либо мы занимаемся маркет-мейкингом, то есть создаем ликвидность через торговлю, через лимитированные ордера, либо мы торгуем, как это называется, direct trading, прямые торги через рынок, market order, рыночные ордера по сигналам каким-то. Либо мы комбинируем то и другое. Но если мы в крипте, то там вариантов больше. Если на бирже на централизованной типа Binance у нас есть те же самые варианты, либо мы по каким-то маркетмейкинговым стратегиям работаем на лимитированных ордерах, либо мы торгуем по сигналам и по событиям обычными ордерами. Либо в крипте у нас есть возможность пойти и начать что-то делать на смарт-контрактах. Есть куча смарт-контрактов, которые позволяют тоже и торговать, и осуществлять ликвидность, создавать ликвидность через маркет-мейкинг. Забегая, делая отклонение в сторону, я, честно говоря, не очень понимаю, что там можно делать в последнем случае, потому что В последнем случае ликвидность на порядке меньше, чем на централизованной бирже. И основные деньги, насколько я могу судить, там зарабатывают на всяких мошеннических операциях с фронтранингом. Когда человек, который получает возможность намайнить конкретный блок, он анализирует транзакции, которые там идут через эти смарт-контракты и подменяя порядок транзакций, вставляя свои транзакции в нужные места, он соответственно обдирает тех людей, которые пытаются через эти смарт-контракты торговать. Из того, что я видел, у меня такое впечатление создалось. Соответственно, если там хочется зарабатывать деньги, то нужно куда-то туда идти, именно в активный анализ и обман смарт-контракта. Вот если это кому-то интересно. Ну и, наконец, операционные риски. Как мы учитываем возможные реакции на наши торги? Как мы отрабатываем проскальзывание цены? Если мы, к примеру, решили что-то купить по какой-то цене, а в этот момент выясняется, что кто-то по этой цене уже выкупил, то мы попадаем на другой уровень цен. по лимитированным ордерам. Какие опять-таки технологии Fintech мы используем для поддержки наших операций. Ну и всякие разные оптимизации. Тут я, наверное, уже не буду останавливаться. Не помню, что товарищ говорил. Ну и, собственно, вот краткий обзор. Соответственно, если есть какие-то здесь вопросы или комментарии, можно Быстренько обсудить. Если нет, то я бы двинулся дальше. Ожидаема нет. У меня, честно говоря, тоже не было. Мне такие общие слова были не очень интересны. Поэтому я перейду сейчас к более практическому докладу. который делал интересный молодой человек из Нью-Йоркского политехнического института. Ссылаясь на нашу работу, в том числе на AGI в прошлом году. Сейчас я найду его докладик. Вот он. товарищ как бы значит заявлял тему давайте сделаю view fullscreen да значит опс так не то не то не то не то делал fullscreen не надо слайда так view Получилось? Да. То есть коллега заявлял, что market prediction как task for AGI agents, но AGI на самом деле там есть что, что он как бы рассматривает, как я в своих некоторых докладах заявлял, что когда мы строим генерализованную систему reinforcement learning, которая может решать любые задачи на том или ином подходе, ведь мы решаем задачу AGI, но он посмотрит на это так, что если мы решаем задачу, которая генерализованно решает задачи предсказания любых событий и всего чего угодно, то есть строит универсальные предсказательные модели для чего угодно, то мы в каком-то смысле строим тоже AGI. Еще у него будет фишка, что он со мной попробовал наряду с разными нейросетями и статистическими методами NARS и еще и попробовал мультимодальное обучение. Я про это расскажу. Вот как его схемка. Она где-то похожа на другую схемку, которая будет в нашем докладе. Соответственно, вот у нас есть как раз сбор данных. То есть, что мы можем получить? Мы можем брать данные с новостей, социальных сетей, блогов, форумов. И он называет это фундаментальными данными. Я бы это фундаментально… Ну, окей. 

S00 [00:14:00]  : Он считает, что это можно рассматривать… Нельзя это фундаментально делать. 

S01 [00:14:04]  : ну я тоже согласен ну вот да то есть он окей вот вот он просто оппозиция то есть вот то что касается ну кстати да вот то что price history у него попадает в technical data economical indexes economical indexes да это наверное тоже technical data и graphical patterns а собственно фундаментальные данные этого случая блокчейна то, что происходит в плане майнинга и перетекания данных из кошельков, а в случае стандартных рынков это то, что происходит в бухгалтерии тех компаний. которые торгуют эти токены. Это вот мы получили два типа данных, потом у нас там есть очистка этих данных, собственно Data Reduction, это вот как раз та самая символизация, про которую я рассказывал в прошлый раз. И он будет рассказывать про свой подход к символизации. Feature Selection – это мы выбираем те фичи, которые нам нужны. Data Transformation какой-то. И потом у нас пошло построение моделей обучения, оценка этих моделей и, собственно, предсказания и уже работа по итогам этих предсказаний. Вот. Отправная точка для его исследований. Сразу смотрим, какие у нас baseline. Этот доклад не с криптой связан, он пытается работать с обычными финансовыми рынками. И сразу смотрим, что базовые accuracy у нас 0.7. 0.6 и до 0.7 с чем-то, да, вот в этом вот интервале. И тут у него, ну, в общем, все линейные регрессии SVM работают примерно одинаково. Тут же где-то XGBoost, нет, XGBoost уже отстает. В общем, лучше всего здесь работает линейная регрессия, самая простая SVM. Дальше, значит, он идет, собственно, Вот дальше он говорит. Мы строим универсальную задачу предсказания для AGI, которая является нейровой API в плане того, что мы предсказываем не все, что угодно, а все-таки market prediction. Мы как-то эту задачу формализуем. И, собственно, дальше мы пытаемся привести вот это распределение значений, в данном случае цены, колебаний цены, к некоторому символьному представлению, которое можно дальше заталкивать в алгоритм предсказания, чтобы работать на уровне символьной, грубо говоря, регрессии, а не количественных методов. И вот как раз задача. Если помните мой прошлый доклад, кто его смотрел, я вот такие фичи вообще не рассматривал. Если есть унимодальное распределение, я на данном этапе решил, что я использовать не буду, а он как раз пытается решить эту задачу через zscore-бакетинг. Да, вот я сейчас расскажу, что у него подразумевается под zscore-бакетинг. Это когда мы через функцию zscore разбиваем распределение нормальное на интервалы. либо положительное, либо отрицательное, где, значит, единичка попадает, грубо говоря, либо минус один, либо плюс один попадает на максимум, значит, минус двойка или двойка попадают на, значит, эти самые, как бы, на спады. распределения. Дальше минус тройка и тройка попадают на хвосты. Ну и все, что меньше минус трех и больше трех – это уже совсем дальние хвосты. Хвосты там какие-то аутлайеры или какие-то вообще аномальные значения. Соответственно, все распределения цен, которые ему поступают на вход, Он вот таким вот образом превращает либо минус один, либо плюс один, если это в случае нуля колебания, или вот больше. Либо, может быть, больше единицы, либо больше двух, либо больше трех. Ну и, собственно, берет данные по различным инструментам. И по этим инструментам, по всяким разным, каким угодно, он там как-то эти данные обрабатывает. И, собственно, дальше пересмотрим, что у него получается. Основные методы, которые он проверял на всем этом многообразии инструментов, это здесь multilinear regression, multilogic regression, SVM и нейросети. И вот у него получается результат, на самом деле, в моем понимании, достаточно распространенный в Quantitative Finance. что проще, что лучше всего работает банальная линейная регрессия. И он как раз говорит, что почему-то в тех результатах, от которых я отталкивался, SVM работал чуть-чуть лучше линейной регрессии, а у него SVM как раз работает хуже всего, а простая линейная регрессия лучше всего. Вот точность какая. Ну и дальше он попробовал НАРС. Мы же все-таки конференция AGI, а НАРС – это один из AGI. Надо отдать должное НАРСу, в отличие от других систем нарсоподобных. обоим Discovery Евгеньевича Витяева, а другая – это OpenCoke Бена Герцеля и компании. В отличие от двух последних систем, NARS можно просто взять из GitHub и использовать, получить результаты, что, собственно, товарищ и сделал. Но у него результаты получились на НАРСе гораздо хуже. Он пробовал разные методы НАРСа, но везде получилось существенно хуже, чем остальными методами. Причем, значит, он говорит, что вот я вначале удивился, а потом, говорит, вот в тот же день, когда происходил этот варшоп, проходил семинар по Нарсу. Вот он сказал такую вещь. Вот я, когда я посидел первую половину дня в семинаре по Нарсу, и мне стало понятно, почему Нарс не работает. Но времени обсуждать не было. В общем, если кому-то интересно, почему NARS не работает для Quantitative Finance, то одному человеку это стало очевидно из того семинара по NARS, который есть в записи и который выложен как раз ссылкой в нашу группу. Можно посмотреть. Потому что NARS это из трех подобных систем самая продвинутая хотя бы с точки зрения продуктизации. Есть GitHub, оттуда можно скачать, собрать, там выполняются примеры, есть куча документации, есть куча видео. Система с точки зрения оформления как продукта вообще на голову впереди всего остального. Ну, вот как бы некоторый итог. Соответственно, у нас линейная регрессия 64, логистическая регрессия 53. SVM с ошибкой написано хуже всего. Ну, и вот другие методы. NARS на предпоследнем месте, грубо говоря. а нейросети буквально чуть-чуть остаются на регрессии. Но при этом у Нарса есть Explainability. То есть, если мы удивляемся, почему он предсказывает, что цена должна пойти существенно вверх или незначительно вниз, он может рассказать, по каким правилам он это установил. Ровно точно так же, как в Discovery или OpenCog. Ну и последний пример, поскольку все-таки конференция AGI. Вот он продемонстрировал кейс, когда он это называет procrastinating nurse agent. Это вот агент, который может научиться всему, чему угодно, и в процессе обучения он увеличивает свой общий интеллект. Сначала он учил этого агента играть в любимый многими из нас Понг. и научился отбивать 85% мячиков. Потом он научился предсказывать S&P 500 с точностью 56%. А потом, когда попробовали его играть в Pong, он уже отбивал 88% шариков, потому что вот таким вот образом повысил свой общий интеллект. Вот все. Давайте сделаем небольшую паузу, если есть какие-то дальше вопросы. Алекс Бур говорит. Нон-прайс дейта. Смотрите, про нон-прайс дейта. Я буду про это говорить дальше. Нон-прайс дейта – это все-таки все равно. Есть, в моем понимании, есть market data, то есть рыночные данные, которые включают в себя как price data, так и non-price data. То есть, к примеру, объемы продаж, объемы покупок, объемы торгов, количество сделок и всякие производные метрики – это же non-price data, но это все равно market data. Соответственно, вот есть маркет-дейта, которая идет с рынка и описывает ходы торгов. А есть тогда уж нон-маркет-дейта, и он может разбиваться на фундаментальные данные. сошел сошел мидия дейта вот но это вот там в одном из следующих докладов как раз я буду эту перспективу разбирать вот а фундаментальные данные там можем разбирать данные так сказать бухгалтерские так сказать и данные там и он чейн дейта так называемая Да, фундаментальные данные – это обычные отчеты компании, отчеты правительства. Да, конечно. Да-да-да. Фундаментальный анализ – это макроэкономический индикатор, индексы деловой активности, отчеты компании. Да, всё верно. Так, коллеги, ещё какие есть комментарии, вопросы, прежде чем мы двинемся дальше? Нет? Да, хорошо. Да, хорошо. У нас 10 минут по докладу, поэтому я надеюсь, у нас всё будет оперативно. Это тогда я закрываю. И переходим, собственно, к трем докладам от нашей команды. Во-первых, доклад, который в большей, наверное, степени претендует на AGI, потому что он даже попал воральный, то бишь устный доклад на основной конференции. Называется это адаптивный агент, который занимается маркет-мейтингом, используя одновременно множество стратегий, причем в волатильных рынках. У нас первая работа была на конференции EGI в прошлом году. В этом году мы работу продвинули, улучшили тем, что, во-первых, проверили его на разных рынках. А во-вторых, на большее количество стратегий покатали в рамках этого агента. Архитектура, в принципе, та же самая осталась. Значит, как бы вдохновляет на эту работу Вот та моделька, которую я уже несколько раз тут показывал. То есть, у нас есть некоторая операционная среда, произвольная, которую мы описываем с помощью некоторой, можно сказать, онтологии, которая заземляет конкретного агента на конкретное операционное пространство. И в случае маркет-мейкинга или quantity finance это движение цены, изменение финансовых индикаторов, изменение социальных настроений в соцсетях – это то, что попадает в качестве восприятия окружающего мира. А действия, которые агент совершает – это формирование или отмена ордеров на покупку или продажу тех или иных. А внутри у него все как положено. Есть какие-то базовые ценности, есть построенные модели, есть наблюдаемые факты и последовательность совершенных событий. Есть предиктор, который предсказывает будущее, есть компрессор, который эти модели ужимает. Вот и есть принятие решения. В данной работе вырезано было почти все. Вырезан был компрессор, вырезан был предиктор, а в следующем докладе будет уже с предиктором. Был только десайдер. Собственно, система принятия решения сейчас будет обсуждаться. Моделей никаких не было, потому что он ничего не учился, он все время только адаптировался. Задача агента была... Давайте я дальше сейчас пойду, будет понятно, что осталось от того, что вырезали. Собственно, операционное пространство этого агента выглядит примерно так. Вот на входе у нас подается market data и media data, то есть мы разбиваем так. Есть рыночные данные, которые включают в себя фреймы open-high, open-close, high-low. Volume стандартное, мы их существенно расширяем, то есть у нас туда еще добавляются средняя цена покупки, средняя цена продажи, максимальная и минимальная цена покупки, максимальная и минимальная цена продажи, объем покупки, продажи и так далее. Больше метрик включается. Дальше весь объем сделок, то есть мы полностью мониторим все сделки и мы мониторим все изменения в структуре лимитированных ордеров по уровням. Соответственно, эту информацию теоретически бедный агент может всю переваривать, но это мы не такие злые, мы понимаем, что он с этим не справится, поэтому мы делаем некоторый препроцессинг этих данных, мы их агрегируем, формируя некоторое множество индикаторов. И работаем дальше уже с этими индикаторами. То же самое социальные сети. То есть, естественно, мы можем попытаться на этого агента лить потоки текстовой информации из соцсетей в расчете на то, что он каким-то образом включит это в свои модели. Мы понимаем, что мы этого не сможем сделать, поэтому на основе данных из соцсетей мы вычисляем некоторые метрики вроде сентимента и когнитивных искажений, про которые будет более подробно в следующем как раз докладе. Вот. И все это опять-таки подается ему на вход, переварив в предобработанном виде. А на выходе, соответственно, есть тоже два варианта. Один вариант как бы в лоб. Это, значит, агента можно на основе потоков вот таких вот предобработанных данных заставлять непосредственно делать ордера, создавать или отменять. Но мы опять-таки этого не делаем. Мы понимаем, что это не заработает, потому что пока что из тех статей, которые были в публикации, не видно было, чтобы это хоть у кого-то как-то работало. Поэтому мы идем другим путем. Мы говорим, что, собственно, торговать-то будут боты, у которых будут стратегии, где каждая стратегия описана некоторым набором правил. Простейшее правило. Если цена высокая сейчас, а потом будет падать, то продавай. А если цена низкая сейчас, а потом будет расти, то покупай. Но если мы не знаем, какая она будет, то правило другое. Buy low, sell high. Цена высокая – продавай, цена низкая – покупай. Самый простой агент у нас работает на такой простом правиле. Получается, собственно, для того, чтобы какой-то выход этому агенту подать из агента, нам нужно задавать некоторые параметры, которые уже специфицируют эту то, что мы называем макростратегию. То есть, если стратегия просто ставить лимитированные ордера на покупку либо на продажу в зависимости от текущего тренда, то, собственно, уточнение этой стратегии осуществляется за счет установки спреда, то есть какой разрыв между ценой ордера на продажу и на покупку мы устанавливаем, как часто мы отменяем ордера. То ли мы обменяем ордера раз в день, то ли мы отменяем ордера, к примеру, когда меняется направление цены. То ли мы отменяем ордера, когда цена меняется выше, чем на какой-то порог. И с какой частотой мы это делаем. Каждую минуту, каждый час. Соответственно, вот эти параметры, собственно, то есть изменение текущих параметров вот этой вот макростратегии с созданием текущей микростратегии как раз входит в задачу вот этого агента. Ну а дальше, как работает наш замечательный агент. Наш замечательный агент состоит из трех видов агентов. Во-первых, есть некий контроллер. Это как раз Decider. Агент, который принимает решения. И у него есть две команды. Или две популяции. Можно сказать, что у нас личность этого агента расщеплена на множество саб личностей. Где каждая саб личность, она, во-первых, имеет свою собственную стратегию. Во-вторых, часть этих сабличных, меньшая часть, с правой стороны, она осуществляет реальные торги на реальном экшене. Не торги в данном случае, а у нас фокус в этом проекте маркетмейкинг, то есть мы работаем не прямыми рыночными ордерами, а мы работаем с лимитированными ордерами, то есть выставляем ордера на покупку, на продажу с определенным спредом. то бишь разрывом цены между ордером на покупку и на продажу. Вот и соответственно вот часть агентов они работают на реальном. А часть агентов они работают в виртуальном пространстве. Откуда берется виртуальное пространство? Мы из реального экшенджа в реальном времени подкачиваем все данные, которые есть по совершенным сделкам и совершенным изменениям книги лимитированных ордеров. И на этих данных мы осуществляем так называемый бэктестинг, то есть мы эмулируем работу биржи на основе потоков данных из рынка и на этих эмуляции работы биржи мы к этим данным подмешиваем компанию наших виртуальных агентов которые в этом пытаются участвовать и соответственно что делает вот этот контроллер он смотрит как торгуют эти ребята он смотрит как торгуют эти ребята вот и время от времени там раз в день раз два там или три или в пять дней Он тех ребят, которые в реальном времени торгуют плохо, он их переводит в эту компанию, виртуальных. А если из виртуальных кто-то хорошо торгует, он их переводит в компанию активных. Вот как это работает на временной разверке. Здесь показано, грубо говоря, 4 интервала. где каждый вертикальный столбик из четырех – это один день, в течение которого там идут торги с какой-то частотой. Происходит обновление ордеров каждую минуту или каждый час в зависимости от настроек. Причем, верхние четыре колоночки описывают все возможные стратегии, исполняемые в виртуальном пространстве, а нижние столбики описывают состояние всех стратегий, исполняемых в реале. При этом подсостоянием стратегии обозначается прибытки или убытки за данный день. Соответственно, если мы в зеленом, то это мы стойко заработали. Если мы в красном, то это мы стойко проиграли. Вначале мы всем агентам даем равное число денег, запускаем только агентов, которые работают в виртуальном пространстве и смотрим, кто заработал, кто проигрался. вот тех кто заработал мы допускаем до реальных торгов вот и вот видим что вот мы вот этого выбрали вот он хорошо заработал всех кто мы тут выбрали хорошо все они хорошо заработали да для справки верхняя стрелочка верхняя полосочка это она дана для справки это холлер то есть верхние полосочки соответствует агенту который просто сидит на полученных деньгах Вот и если цена падает, он теряет. Если цена растет, он, соответственно, заработает. Ну и вот что мы видим, что по первому дню мы удачно выбрали, а вот по второму дню вот эти заработали и вот эти заработали. И вот из первого, что мы выбрали, он проигрался, а второго, что мы выбрали, он заработал. Вот. Ну и последний день. Последний день вот тоже видим. Кого мы выбрали предпоследним или не на последнем дне, он тоже заработал. Итог такой, что... Итоги я сейчас покажу чуть дальше. Что мы, собственно, сделали по сравнению с прошлым годом? Во-первых, в дополнение к очень простой стратегии buy low, sell high, с вариацией только спреда и политики отмены ордеров, то есть насколько часто мы ордера отменяем, протухшие, Наряду с этой стратегией мы взяли две стратегии. Одна – компания Neox из проекта Autonio Foundation, в котором эта работа начиналась. И вторая стратегия – это опенсорсная стратегия проекта Humminbot. которые мы сейчас начинаем активно использовать по причине тех результатов, которые мы чуть позже увидим, буквально на следующем слайде. И, кроме того, мы обкатали это на большом числе рынков, наиболее представительные примеры на трех видах рынков за различные месяцы. Каждый график... Так, коллеги, там у кого-то звук идет посторонний, если можно... чтобы не отвлекаться. Так, коллеги, у кого мют попросить сделать? Значит, первый месяц, это у нас цена идет достаточно сильно вверх, при этом волатильность не очень большая. То есть, относительно плавные изменения в основном. Второй месяц, Так, коллеги, я вынужден прерваться и кого-то насильно замьютить Владимира Смолина. Так. Продолжаем. Значит, второй месяц. Цена вырастает примерно же настолько. То есть, общее изменение цены, да, то есть, доход Ходлера, она вот в первом месяце и в втором месяце примерно одна и та же. Вот. А вот волатильность, она вообще бешеная. Вот. Ну и третий месяц. Значит, цена уже идёт вниз. Вот. Достаточно сильно. Причём, это вот, по-моему, как раз май прошлого года. когда все рухнуло. Ну и при этом еще волатильность такая средненькая. Ну и вот что мы получили на этих рынках. Опять-таки столбики большие. Это соответствует трем месяцам, на которых мы осуществляли торги. Значит, синенькие столбики соответствуют стратегии Ходлера. То есть, мы видим, что в первом месяце Ходлер заработал, во втором месяце Ходлер заработал, а в третьем месяце Ходлер проиграл, потому что цена упала, соответственно, все, что мы имели, мы потеряли. на пропорциональное падение цены. А дальше мы смотрим, как разные из трех перечисленных стратегий агентов отработали. Соответственно, оранжевая значит это Basic Agents, зелененькая это Neox Agents, а красненькая это как раз последняя группа стратегий Humminbot. Ну и чтобы долго не распространяться, получилось так, что агенты BASE и NEOX, когда рынок идет вниз со средней волатильностью, они Ходлера переплюнули. А вот на других рынках они, в общем, не очень хорошо себя показали. Либо хуже Ходлера, либо лучше, либо примерно вровень с ним, по-разному. А вот стратегии Хамминбота, они на двух месяцах, когда у нас волатильность большая, то они существенно переплёвывают и Ходлера, и во многих случаях другие стратегии. А когда рынок идёт вверх и мало меняется, то Хамминбот либо выигрывает, либо чуть-чуть отстаёт от Ходлера, но убытка всё равно не имеет. Ну и, собственно, вот те публикации, которые на тему этой истории на сегодняшний день имеются. А это по поводу того, что чем больше волатильность, тем больше денег можно заработать. Вот родился такой мем, что market volatility is your friend, you just need to cook it properly. То есть, волатильность рынка – это твой друг, если уметь ее готовить. С этим докладом все. Здесь какие-то вопросы будут. Нет. Хорошо. Тогда переходим к третьему докладу. Он как раз связан с нашими попытками позаниматься предсказанием цены. Я должен сказать следующее, что предсказание цены и для стандартных рынков задача не очень благодарная, как можно было видеть из тех цифр, которые мы видели в предыдущей презентации. А с криптовалютой там все гораздо хуже. Начать с того, что по своим характеристикам графики цен криптовалют это практически белый шум. во-первых. Во-вторых, если в этих самых ценах обычных рынков есть хотя бы какие-то последовательности, связанные с днями, если помните, Кто видел несколько моих предыдущих презентаций на слайдах Витяева, показаны закономерности, привязанные к дням недели. Но есть тоже ряд работ, где к дням недели, к часам дня есть закономерности, которые выявляют какие-то устойчивые паттерны, привязанные именно к календарю и к часам. Для криптовалют нам этого выявить не удалось. Я наблюдал большое число за прошлые годы проектов, имеется в виду внутренних проектов, где с предсказанием цены пока что Печально вот, и здесь надо сказать следующее, что вот я довольно часто встречаю, что вот там кто-то говорит, вот мы предсказываем цену, вот у нас там Accuracy 0.6 или там MAPE, Minimum Average Percentage Error, он там Сейчас давайте я до этого дойду, кстати. Да, я до этого все-таки договорю. Да, то есть, говорится, что у нас MILAN Average Percentage Error. Давайте я выйду на эту картинку с различными метриками, чтобы было понятно, о чем я говорю, а потом вернусь. Итак, вот смотрите. Вот мы говорим, что вот у нас там есть какой-то предиктор, вот у нас в верхнем ряду есть какие-то предикторы. И вот мы можем оценивать Directional Accuracy, которая, грубо говоря, считает Accuracy предсказание направления движения цены. Или у нас есть F-score или F-measure, которая тоже рассматривает предсказание цены как задачу классификации, либо цена пойдет вверх, либо пойдет вниз. и на основе соответственно фальс-позитив, фальс-негатив, трю-позитив, трю-негатив confusion matrix считает f-меру. Либо мы занимаемся предсказанием уровня цены и оцениваем minimum average percentage error. Вот мы смотрим на все эти метрики, ну и видим, что все эти метрики вот они вот такие вот, да, то есть вот они вот 0,5 там, Понимание 0.5 для Directional Accuracy или F-score – это монетку можно бросать, и у тебя тоже будет 0.5. Более того, там человек говорит, что вот у нас получился F-score 0.6. А теперь давайте подумаем, что если мы возьмем, к примеру, если у нас цена идет вверх на каком-то месяце, то у нас, и допустим она круто идет вверх, то у нас при крутом движении цены вверх большинство изменений цены будет в плюс. Соответственно, если просто мы возьмем в качестве предсказания цены простую линейную регрессию, линейную экстраполяцию, то она в среднем, в большем числе случаев, будет предсказывать, что цена идет вверх. Соответственно, если мы выберем такой интервал рынка, где цена идет устойчиво вверх, либо устойчиво идет вниз, то мы методом простой линейной экстраполяции, даже по двум точкам, даже не прибегая к линейной регрессии, в общем получим акуроси достаточно высокую. Чем круче цена идет вверх, тем круче будет наша оценка. Вот таким образом черепикинг в предсказаниях цены можно очень легко получить. И поэтому В подходе, который мы исследуем, у нас есть несколько бейзлайнов. Внизу как раз показаны три бейзлайна, которые мы применяем на тех экспериментальных данных, которые тут приводят для двух месяцев. Мы работали по ноябрю и сентябрю прошлого года по разным причинам, потому что для них были наиболее качественные данные, на которых можно было играться. А, собственно, какие-то данные я сейчас вернусь и расскажу. И на этих двух месяцах мы строили бейзлайн. Что такое LKP? Это так называемый Last Known Price. Это мы строим такой предсказатель, который просто говорит, что следующая цена будет такая же, как предыдущая. То есть, цена у нас меняется, а мы ее предсказываем очень просто. Мы говорим, что цена будет ровно такая же. И вот видим, что таким способом предсказание уровня цены вообще получается рекордное. То есть, минимальная ошибка. Вот только один предиктор в верхнем ряду чуть-чуть бьет. Да, а так в общем по всем остальным методам получается предсказание уровня цены оно просто самая лучшая. И я опять-таки забегаю вперед, я не видел ни одного, за последние полтора года, ни одного способа предсказания цены, который бы на криптоданных позволял предсказать цену выше, чем, собственно, last known price, уровень цены. Другой предсказатель Last Known Price Direction. Это мы говорим, что цена на следующем интервале изменится ровно настолько же, насколько она изменилась за предыдущий интервал. То есть, если на сегодня утром цена изменилась на плюс 2 пункта, то мы говорим, что завтра сторона изменится еще над плюс 2 кунта все очень просто да не нужны там никакие кластера значит самое с видеокартами вот просто добавили там столько же сколько вышли вышлось на предыдущем интервале Ну и здесь тоже все неплохо. То есть, здесь вот тоже сравниваем с тем, что получается на верхних рядах. И достаточно нормальное мапе получается. Directional accuracy вот тоже 0.6, 0.6, 0.6. ну и вот собственно вот эти вот last known price и last known price direction это вот что называется как мы называем dirt стандарт или грязевой стандарт то есть есть верхняя граница предсказать возможности нашего предсказания есть нижняя граница да вот это вот нижняя граница соответственно если ты предсказываешь ниже этого то вообще тебе нечего делать и Деньги на машинное обучение потрачены в пустую. А верхняя граница, она очень проста. Это называется Future History Lookup. Это мы на тех данных, на которых тренируемся, мы же всегда можем посмотреть, какая цена будет на следующий день. Соответственно, Accuracy, Direction, все Accuracy у нас тут единички, а MAPE тут ноль. Что за цифры в этих двух колонках, я чуть позже расскажу, когда дойду до этого места. Итак, это вот по поводу метрик. Теперь, какие данные? В соответствии с первой презентацией, первый пункт, какие данные мы берем? Какие данные мы брали? Для медиапредсказаний мы используем 18 метрик. Четыре метрики – это метрики сентимента. Сентимент анализа. Причем, мы берем не простую модель, которая обычно используется, где рассматривается либо положительный сентимент, либо отрицательный сентимент, либо нейтральный. То есть, мультиклассификационная модель. Либо хорошо, либо плохо, либо никак. Мы считаем, что это неправильно. Потому что когда человек говорит что-то типа, там, вчера все было хорошо, а сегодня все очень плохо, Это немножко не то, когда человек говорит, что сегодня и вчера все нормально. Когда сегодня и вчера все нормально, это действительно нейтрально. А когда вчера было хорошо и сегодня плохо, это то, что мы называем contradictiveness. То есть, мы на каждом тексте или на каждом интервале временом, в котором много текстов, мы оцениваем четыре метрики. Первое – это общее количество позитивного сантимента. Второе… А, нет, стоп, позитив. Общее количество позитивного сантимента. Первое. Второе – общее количество негативного сантимента. Третье – это, что называется, оверл сантимент. Это, грубо говоря, сумма плюсов с минусами, которые которая в конечном итоге может быть нулем, если плюсы компенсируются минусами. А вот четвертое – это контрадиктивность. Соответственно, чем больше, так сказать, разброс между объемом положительного и отрицательного, тем выше абсолютное значение вот этой вот самой контрадиктивности. То есть, мы, так сказать, увеличиваем размерность вот этих метрик для сентимента анализа. Кроме того, мы заимствовали еще 12 метрик из когнитивно-поведенческой терапии. Прочитав одну прошлогоднюю статейку, где товарищи исследовали как когнитивные искажения связаны с событиями в истории человечества за последние за последние сто лет по данным литературы и прессы вот и мы значит анализируем еще текст на предмет этих вот этих вот 12 метрик и делаем это по 77 каналам социальных медиа в Твиттере и Реддите релевантных для криптомаркета. Вот это, собственно, те медийные данные, которые мы используем. А вторая группа данных, которые мы используем, это, собственно, рыночные данные, включая цену. Из этих данных у нас мы получаем 111 производных метрик. Соответственно, то есть, это цена, производная цены, объём, логарифм объёма, производная логарифма объёма. То есть, всё, что можно посчитать, включая различные имбалансы. Например, соотношение объёма покупок к объёму продаж. Соответственно, он может быть больше единицы или меньше единицы. Соотношение объёма ордеров на стороне лимитированных ордеров на продажу и лимитированных ордеров на покупку. Соотношение тоже показывает дисбаланс. То есть средняя цена на покупку, средняя цена на продажу. Насколько ордеров насколько она близка они удалены от средней цены или средняя цена реальных покупок средняя цена реальных продаж насколько та и другая удалены от средней цены соответственно тоже вот есть еще два имбаланса то есть мы вот четыре таких основных имбаланса мы считаем еще ряд производных то есть и это все по девяти парам торговым парам на криптобирже. Это основные криптовалюты с наиболее высокой ликвидностью на сегодняшний день. Ну вот, соответственно, считайте 9 на 111 и 77 на 18. То есть, порядка тысячи фич мы получаем, насколько я понимаю. А теперь, внимание, вопрос для тех, кто занимался работой с временными рядами и предсказаниями. Если мы возьмем около тысячи фич, которые по своему виду похожи на белый шум, то, какую точность мы получим на тестовом наборе. То есть, если мы попытаемся с помощью этой тысячи фич, похожих на белый шум, мы попытаемся через линейную регрессию заоверфитить тестовый набор. Ответ простой. Мы получим accuracy, близкую к единице. То есть, мы, по сути, можем любую функцию допустим, цены, которые мы хотим предсказать, просто разложить в ряд. То есть можно раскладывать в ряд Fourier, можно раскладывать на ряд Вейвлетов, а можно раскладывать на полиномы, на полиномиальный ряд, а можно разложить просто на ряд случайных функций. Этот вариант мы очень быстро получили. на основе всех данных. Поэтому в конечном итоге был реализован пайплайн, про который я сейчас чуть позже скажу. Общая архитектура у нас примерно следующая. Если мы двигаемся по временной шкале, на которой нам что-то надо предсказывать, то у нас есть некоторый тренировочный интервал, на котором мы тренируем данные. Обычно это от месяца до двух. Дальше, этот модель на соответствующем тренировочном интервале обновляется периодически. То есть, каждый день модель не обновляется. Модель обновляется раз в 5-10 дней. Соответственно, в течение 5 или 10 дней у нас имеет место то, что мы называем prediction period. Вот, допустим, вот этот prediction period, он работает вот с этой моделью. Вот этот вот prediction period 2 работает с моделью, полученной на training interval 3. Prediction period 3 работает с моделью, полученной на training interval 4. Соответственно, когда мы модель тренируем, у нас еще на тренировочном интервале есть то временное окошко, которое мы отсчитываем назад для того, чтобы построить, сопоставить значение с текущей точкой то есть вот есть набор окон с которыми мы работаем вот но и собственно вот у нас здесь вот тренинг интервал покажем prediction period вот ну и показано вот наша кривая значит с помощью где мы предсказываем цену вот но его типичная картина для всех подобных алгоритмов видно что когда мы находимся на тренировочном интервале у нас все в среднем достаточно хорошо фитится то есть цена она достаточно в среднем повторяет исходную цену а когда мы выходим на собственно предсказание то у нас случается просто сдвиг То есть, на самом деле мы попадаем на функцию, которая больше всего похожа на пресловутый last known price. Причем это видно вот здесь, это видно здесь, что на тренировочном интервале все фитится хорошо, а на тестовом у нас случается last known price с некоторыми вариациями. Ну и вот опять-таки то же самое здесь. Вот это типичная картина для практически всех алгоритмов, по крайней мере, которые мне доводилось видеть. Чтобы минимизировать процесс оверфиттинга на тренировочных наборах и хоть как-то поднять точность на тех интервалах, где мы реально предсказываем, у нас была реализована процедура отбора фич. Соответственно, мы получаем на ход все эти метрики, которые я перечислил около тысячи. Отбираем эти метрики в соответствии с указанными интервалами, либо с шагом в день, либо с шагом в час, либо с шагом в минуту. А дальше мы просто считаем корреляции между целевой функцией, в данном случае это либо цена, либо объем торгов. То, что мы предсказываем. Сейчас мы предсказываем основную цену, будем предсказывать еще объемы торгов. Потому что они вроде как лучше предсказываются. Это я чуть позже еще покажу. Мы считаем корреляцию между этими фичами, исходными всеми и целевой функцией. И дальше у нас есть некоторый порог. Одним из гиперпараметров нашего фреймворка является порог для отбора вот этих фич. Грубо говоря, если корреляция между фичей и целевой функцией меньше чем 0.2, там были 0.3 в зависимости от порога, мы просто эту фичу игнорируем. И дальше уже отобранные фичи, они идут в предиктор. Ну, кстати, дополнительно мы еще можем фильтровать социальные сети. То есть, если новый фичер считается из социальных сетей, мы еще можем отбирать для анализа только те тексты, которые, к примеру, там включают в себя упоминание той криптовалюты, которую мы хотим предсказать, к примеру. И вот, собственно, наши результаты. Здесь вверху видно, давайте мы посмотрим на метрики точности. Direction, Accuracy, F1 и MAP. Вот мы что видим. вверху ноябрь-сентябрь и еще один ноябрь-сентябрь. И два вида предиктора – медиа и маркет. Маркет-предиктор – это тот, который предсказывает, отталкиваясь только от рыночных данных. А вот медиапредиктор – это тот, который предсказывает, отталкиваясь только от данных социальных сетей. Вот, ну и вот здесь вот мы видим, что точность предсказает, так сказать, лучше всего точность у медиапредиктора, который работает у медиапредиктора на основе рыночных данных в ноябре месяце. Она вообще, так сказать, самая лучшая среди всего, что можно было придумать. Лучше всего Directional Accuracy F1 и, значит, меньше всего MAPE. Вот, но в сентябре чуть-чуть похуже. Но accuracy – это не все. В конечном итоге к руководителю хедж-фонда ты не придешь со своим алгоритмом и не скажешь, что у меня крутой алгоритм, потому что у меня крутая accuracy. Менеджеру хедж-фонда или директору хедж-фонда ему нужно зарабатывать деньги. Поэтому его интересует Return of Investment. Что мы делаем? Какой бы хороший логаритм предсказания не был, мы его засовываем в систему бэктестинга, про которую я уже рассказывал. У нас скачиваются реальные рыночные данные, включая все торги, все ордера, и есть эмулятор биржи. в котором можно эмулировать любые стратегии. И мы туда запускаем коллекцию агентов, где первый агент для справки – Ходлер, с которым мы сравниваем все наши стратегии. Наверху видно, что он больше чем 500 долларов потерял за отчетный период за 30 дней. А вот куча разных других стратегий с разными спредами и в основном с разными методами определения спреда и с разными политиками, насколько часто ордера отменяются. И всем этим агентам теперь мы даем тот или иной предиктор из 10 перечисленных. вот и соответственно смотрим начать и вот мы видим что вот допустим при каком-то одном предикторе я сейчас не знаю какой вариант у нас все вот эти вот агенты которые зелененьким они столько заработали а все которые с красненьким они столько потеряли Вот. И, собственно, соотношение между тем, сколько в итоге ты заработал или потерял к начальному объему инвестиций, это считается как return of investment. И мы видим с удивлением, что медиапредиктор заработал не намного меньше, То есть, агенты, которые пользовались предиктором на основе данных соцсетей, они заработали немногим меньше, чем агенты, которые пользовались предиктором, основанным на абсолютном знании будущего. Сейчас мы, кстати, проверяем, не баг ли это. Выглядит слишком хорошо, но вот на момент доклада было вот так вот. Ну и вторая колонка, которую мы оцениваем, это ROI в случае использования нашего адаптивного агента. Помним, что у нас же кроме предсказания цены есть еще адаптивный multi-strategy agent, который умеет отбирать только выигрышные стратегии. А в данном случае только выигрышные стратегии – это те, которые зелененькие. И, соответственно, мы говорим, что вот если бы у нас еще был вот такой замечательный агент, который отбирал бы только выигрышные стратегии, у нас бы денег бы еще больше заработалось. Вот. Чем, так сказать, в общем случае? Дальше мы попытались поанализировать свои результаты. Во-первых, попытались посмотреть, какова связь Directional Accuracy с Return of Investment. Показалось, что корреляция есть. То есть, там есть аутлайеры на самом деле, но в общем, в среднем, если по альтернативе точки прямой, то если ты знаешь будущее, то ты зарабатываешь больше, чем если ты не знаешь будущее. Значит, это мы тут пытались подбирать параметры. То есть, это как бы подбирали гиперпараметры. Как раз на нижней шкале циферки это как раз пороги отсечения фич. Вот здесь вот видно, что если мы будем брать фичи только выше, с корреляцией только выше, чем 0.5, то мы ничего не напредсказываем. А если будем брать все фичи с корреляцией 0.2, то, в общем, точность у нас побольше. Хотя, в общем, много разных ярких пятен есть. В общем, с левой части не очень. Это все убедительно выглядит, слишком большой разброс. Это мы будем еще проверять, насколько большая дисперсия по этой карте. Ну, а по вертикали – это как раз интервалы тех периодов для обучения и для предсказания. Но для сравнения, как это выглядит. С левой стороны видно Last Known Price, знаменитый, который работает лучше всего и лучше всех трансформеров и LSTM и XGBoost на практике. И даже лучше линейной регрессии. вот вот last known price direction это по сути линейная интерполяция по двум точкам тоже в общем не намного хуже last known price ну и это вот что дает media predictor ну и видно что буквально там в двух-трех точках он дает предсказания более точные чем last known price direction и вот это вот это вот уже большой прорыв значит это результаты значит попыток делать предсказания цены на различных рынках да вот все рынки которые печатал вот они мы видим что вот только на биткоине мы получаем выше чем 06 вот она всех остальных это на уровне там бросание монеток плюс 05 плюс-минус К сожалению, на сегодняшний день мы пытаемся понять, с чем это связано. Основная гипотеза, что чем ликвиднее инструмент, тем меньше волатильность, тем больше скорость, тем точнее предсказание. Действительно, мы видим, что это так. Если мы посчитаем соотношение Directional Accuracy с объемом торгов в долларах, то мы получим корреляцию такую. И если мы посчитаем соотношение объема торгов с коэффициентом вариации этих самых изменений цены, то мы тоже получим где-то линейную зависимость на большом интервале. Хотя в области малоликвидных и волатильных валют тут сплошной разброд. Вот результаты бэктестинга, которые мы сейчас перепроверяем. Пока что так. Что мы здесь видим? Красненькое – это один месяц. Зелененькое – это другой месяц. Соответственно, два разных месяца мы проверяем. С левой стороны – это ROI, Return of Investment. С правой стороны – это точность предсказаний. Ну а дальше пара столбиков соответствует Future History Lookup, соответственно, что мы можем получить. Но предиктор – это если мы вообще предиктором не пользуемся, пытаемся торговать по старинке, как сейчас торгуют. Получается, что тут мы в сплошных убытках, потому что рынок вниз идет. вот если мы будем пытаться last known price last known price direction то мы тоже в сплошных убытках вот если мы пытаемся на рыночных данных предсказывать то вот почему-то несмотря на низкую точность у нас все равно значит что-то получается вот а если мы медийные данные будем использовать то получается для предсказания то получается как на удивление еще больше ну и вот что у нас получается значит по вот этим метриком. Вот опять-таки видим тут медийные данные, они у нас сопоставимы с Last Known Price Direction, а Market Data у нас существенно ниже. Точность. Это пример того, как выглядят предсказания всех агентов компании в зависимости от политики предсказания цены. Если мы взнаем цену, то любая стратегия, за исключением одной, оказывается выигрышной и превышающей возможности простого ходлера, потому что рынок идет вниз. если у нас нет предиктора или если мы ориентируемся на последнюю цену, известную цену, то почти все стратегии проезжены, за исключением трех. А если мы используем предиктор на основе рыночных данных, то у нас примерно 50-50 получается, чуть-чуть с перекосом в плюс по разным стратегиям. А на основе медийных данных, если предиктор построен, то почти все у нас выигрыши. Вот. Ну и вот мы пока не очень понимаем, почему, несмотря на низкое качество предсказаний, цены у нас с медийным предиктором получается хорошо торговать. И одна из гипотез заключается в том, что важно не то, как мы предсказываем цену, А важно то, когда мы ее предсказываем. И если мы правильно предсказали цену в тот момент, когда идет существенное увеличение объема торгов, то вот тут-то как раз мы и оказываемся в шоколаде. А если мы не угадали цену в тот момент, когда никто не торгует, то типа никто и не пострадал. Исходя из некоторых предварительных исследований, которые тут приведены, нам известно на сегодняшний день, что корреляция и предсказуемость объемов получше, чем предсказание цены. Что мы здесь видим? Здесь наверху показано движение цены. Это производная цена. Соответственно, если плюс, то цена растёт. Если минус, то цена падает. А оранжевым это показана комбинация трёх когнитивных искажений. Ну что такое когнитивное искажение? Например, если человек там считает себя лузером. Это когнитивное искажение. Или когда человек считает, что все плохо. Это другой вид когнитивного искажения. Или когда человек все принимает на свой счет. Это третье когнитивное искажение. Ну вот их 12 штук. И вот комбинация этих трех когнитивных искажений дает оранжевую кривую, где видно, что половина пиков предшествует положительным движениям цены. Но вторая половина не предшествует положительным движениям цены. Ну а если мы возьмем на нижнем графике, то опять-таки оранжевым это у нас там другая комбинация вот этих вот когнитивных искажений тут уже комбинация четырех факторов вот а синеньким это у нас объемы торгов его здесь мы видим что практически все суды сказать большие взлеты вот это вот этого когнитивного искажения они ровно там на один или на два дня предсказывают собственно изменение объема торгов и с чем мы Вот рассуждаем о том, что, блин, может быть мы просто думаем, что предсказываем цену, а на самом деле делим и предсказываем объём торгов. И за счёт этого у нас получается хорошо торговать. С этим будем разбираться. Соответственно вопрос на засыпку. Смотрим, что спрашивает Алекс Бур. Сейчас посмотрим. Тут много вопросов. Крипта почти не привязана к реальности. Обычные валюты более привязаны. Полностью согласен. Получим эффект «курвафит», «курвафитинг». Да, спасибо. Дайте мне пять параметров, и у меня слон будет махать хвостом или хоботом. Согласен. согласен да потом на то симплес лифта кофе токи так система бактестинга до системы бактестинга самодельная значит насчет бактестинга тут интересная вещь но во первых насчет бактестинга да то есть бактестинг бактестингу рознь то есть вы же как можете бактестинг делать вот вы можете смотреть на кривую и говорить, ага, вот здесь вот я столько-то купил, вот здесь вот я столько-то продал, а вот здесь я вот столько-то купил, а вот здесь вот я столько-то продал, и посчитать, какие у вас в итоге прибыли. Проблема в чем? Проблема в том, что на цене вы не видите распределения ликвидности. То есть, может быть, эта цена связана с каким-нибудь ордером на 5 копеек, и если вы, допустим, хотите купить или продать 10 тысяч, то вот вы этих 5 копеек быстро исчерпаете, а следующий уровень цены будет уже совсем другой. И вытаскать в итоге, если у вас будет директ ордер, то вытаскать у вас проскальзывание будет ого какое. Вот, соответственно, мы для того, чтобы этого избежать, бэктестинг у нас, если мы тестируем стратегии директ трейдинг, то есть на рыночных ордерах, то мы верифицируем возможность совершения торгов в данный момент наличием соответствующего объема на соответствующих уровнях в таблице лимитированных ордеров. То есть мы выбираем только ту ликвидность, которая реально есть на рынке в данный момент. Это если мы тестируем стратегии трейдинговые. Если мы тестируем стратегии маркетбейдинговые, то наоборот. Если мы эмулируем создание каких-то ордеров, то мы не закрываем их автоматически, как только рыночная цена достигает этого уровня. Мы реально считаем, а вообще были ли совершены в этот момент, за этот интервал времени сделки, по той цене, которая соответствует нашим ордерам. Но там есть большое количество вопросов к этой системе и есть понимание, что она, опять-таки, где-то не идеальная, но, по крайней мере, тот бэктестинг, который у нас есть, он делается на этой системе. К слову сказать, в какой-то момент, в прошлом году, вот тот HummingBot, как раз с которым мы сейчас работаем, и стратегии которого мы эмулировали, анонсировал, что у нас будет свой бэктестинг, все будут пользоваться. И мы так слегка загрузились, что как с кому конкурировать-то с ребятами. что типа наш бэктестинг теперь не нужен, но вот год прошел, а они его из какой-то ранней приальфы до сих пор в продакшен не выкатили, поэтому мы еще будем думать, может быть наш бэктестинг еще пригодится. Вот. Дальше вопрос на засыпку. Есть две монеты. Одна правильная, другая фальшивая. Фальшивая имеет вероятность выпадения сторон 0.0.4 и 0.6. Сколько бросков? Классика это смог и малыш. Вообще классика машинленинга и дейта-сайенса. Это читаем Джека Лондона. Я не помню, как глава называется. Если кто помнит, напишите, пожалуйста, в чат. Это очень хорошая тема. Про то, как Свокбелию с малышом разорили хозяевна рулетки в Доусоне. Просто методом машин-ленинга, который мой товарищ Смок Белли выполнял на бумажке. Первый пример Data Science в Финтехе описан Джеком Лондоном, классика. Окей. Еще какие есть вопросы или комментарии, прежде чем я потрачу последние 10 минут на последний доклад? Нет, спасибо. Ну и, наконец, тогда я перепрыгиваю на свой доклад собственный, который я оставил на сладкое, и быстренько пробегу по основным его моментам. Вот этот вот так. рассохшая рулетка была там, близко стояла к камину. Алекс, ну вот вы скажите, как голова называется, если вспомните, или если на гуглите, пока я буду рассказывать. Я, если не забуду, потом сам найду. В моем докладе тут будут отчасти общие слова, как и в первом, а отчасти некоторые практически интересные моменты. Во-первых, общие слова. В чем заключается задача Active Portfolio Management так, чтобы можно было как-то ее за уши притянуть к AGI? Если мы помним, исходя из того определения AGI про много параметров и сложные среды и ограниченные возможности, то мы понимаем, что задача AGI сводится к многопараметрической оптимизации. И чем больше параметров, тем она AGI. То есть, AGI соответствует количеству параметров. И в этом смысле вот как раз пример того, что мы можем рассматривать задачу активного управления портфелей как задачу оптимизации размещения средств. Скажем так, в трехмерном пространстве. Тут изображено двухмерное пространство, а я сейчас расскажу два измерения, а потом расскажу, где находятся третьи измерения. Первое измерение – это те финансовые активы, которые мы хотим держать в портфеле. Допустим, 30% эфира, 30% битка и 20%, 10% и 10% других менее ликвидных токенов. А по горизонтальной оси у нас идет то, каким образом мы сохраняем свои активы. Допустим, в первой колонке у нас ходинг. К примеру, 15% эфира и 5% битка мы просто держим под подушкой или в сейфе банковском. если это применимо к криптовалютам. Соответственно во втором, в третьем столбике это вот то, что мы торгуем через лимитированные ордера на Binance. Вот здесь 10 и 10, четвертый столбик, это то, что мы опять-таки вложили в swap pool на Uniswap и, соответственно, обеспечиваем ликвидность через смарт-контракт и зарабатываем на функциях обменника, реализуемый смарт-контрактом. Следует предпоследняя колонка. Это мы опять-таки через прямые ордера рыночные торгуем на Binance. А последнее – это мы тоже торгуем, но через Uniswap. Вот как бы разные макростратегии, что называются. А третье измерение, которое можно пририсовать – это в рамках каждой из этих стратегий либо маркетмейкинга, либо трейдинга. Мы же еще можем разные микростратегии с разными параметрами придумать, что мы можем на Binance. одну и ту же пару или один и тот же токен торговать с различными спредами. И у нас еще параметров подросло. И вот нам в этой трехмерной таблице нужно как-то свои фонды размещать. Вот вам, пожалуйста, задача многопериметрической оптимизации. Вот тут какую архитектуру можно нарисовать. Про нее я рассказывать не буду на том времени. Это значит уже у нас все было, это рассуждение на тепу. Это вот как раз слайд Витяева, который отчасти вдохновил на эти работы про то, что мы можем символизировать предсказание цены и выявлять некоторые закономерные последовательности движений цены. вверх и вниз, в данном случае привязанных к дням недели, что на крипте никак не получается. Сейчас пытаемся это сделать, используя какие-то продвинутые рыночные индикаторы с помощью той символизации, про которую я рассказывал в прошлый раз, но непонятно, что получится. Пока что не очень хорошо. Это как раз про что я говорил. Это как раз иллюстрация на тему того, почему важно анализировать социальные сети. Вот эта ситуация, которая имела место почти год назад, в сентябре прошлого года, что по всем онлайн-СМИ Соединенных Штатов прошел такой замечательный твит. что Walmart будет принимать платежи в лайткоине. И этот фейковый ньюс провисел аж 48 минут, пока его везде не выкосили. И пошел он из этого твита. Ну вот, соответственно, что происходило на рынке с ценой. Сперва улетели в космос, а потом хряпнулись об землю. Ну и, соответственно, сначала кто-то очень активно покупал, а потом очень быстро продавал. Соответственно, кто-то очень хорошо заработал. Вот особенность крипторынка, что мы можем, как раз анализируя публичные данные, которые есть в блокчейне, получать в регулярном режиме с каждым блоком дополнительную информацию, которая является аналогом фундаментальной информации на традиционных рынках. Грубо говоря, если там кто-то сжигает токены, то очевидно, что цена будет расти, потому что количество токенов уменьшено. Если кто-то там эти токены штампует, но очевидно, что цена будет падать в среднем, потому что динаминация происходит. Если у нас увеличивается число уникальных кошельков, по которым этот токен разложен, то это вроде как должна цена увеличиться из общих соображений, потому что больше людей пользуют этот токен, adoption вырастает. То есть, если мы не создали ботнет на эфире и не разложили туда своими руками по многим кошелькам, а потом бот какой-то это увидел, значит, решил, что цена выросла, что все кинулись и кинулся покупать, а это на самом деле был наш бот нет, то вот мы на этом можем хорошо заработать, кстати. Ну и так далее. Уменьшение числа уникальных адресов, то есть это получается, что все избавляются, это уменьшение цены, ну и так далее, да, то есть я анализирую эту информацию, мы можем получать дополнительные метрики, чего мы сейчас пока не делаем. Дальше, как мы на это все можем посмотреть с точки зрения OLAP, Online Application Processing, Analytical Processing. Представим себе, что у нас есть трехмерный куб. Вот, где по одной оси у нас идут источники данных, это либо рынки, соответствующие пары на соответствующих экшенджах или смарт-контрактах, да, вот сейчас вот у нас там от 10 до 100 их в данный момент. Новостные каналы – это, так сказать, соответственные фиды или сабреддиты или там РСС-фиды в социальных сетях, у нас их сейчас порядка 100. А по другой оси у нас, собственно, те метрики, которые мы всего из этого получаем. Соответственно, от около 100 метрик, которые мы извлекаем из рыночных данных, 4 метрики сентимента полярности, про которые я уже сказал, и порядка 12 когнитивных искажений. Ну и все это у нас отложено на временной шкале в первом приближении. То есть, вот у нас получается такой трехмерный куб данных, с которым мы можем что-то делать для предсказания цены в том числе или для бэктестинга. И что мы можем с этим делать? Мы можем попытаться заниматься корреляционным анализом, претендуя на то, что этот корреляционный анализ может давать некоторые некоторые подсказки с точки зрения каузального анализа или причинно-следственного анализа. Что я имею в виду? Предположим, что у нас есть вот такой синтетический пример. Значит, это синтетическая функция, которая просто была сделана в какой-то момент в ноутбуке именно для иллюстрации. Предположим, что у нас есть некоторая цена в середине. То есть, цена была одна, потом она пошла вверх, потом она пошла вниз, потом она была снова плавная, потом снова пошла вверх, потом снова пошла вниз. Вот внизу производная или price difference. В питоне говорим точка, диф, скобочки. Вот производную посчитали. Соответственно, вот взлет цены, вот падение цены, вот взлет цены, вот падение цены. А вверху у нас два некоторых синтетических индикатора. Один это называемый условно пампинг, а второй называемый дампинг. И мы создаём такие синтетические индикаторы, что пампинг всегда предшествует взлёту цены. То есть, вот у нас пампинг, вот взлёт. Вот у нас пампинг, вот взлёт. А дампинг всегда предшествует падению цены. Вот у нас дампинг, вот у нас падение. Вот у нас дампинг, вот у нас падение. По одной временной оси всё разложено. После чего мы берем и делаем следующую вещь. Мы считаем корреляцию одного графика с другим с различными сдвигами. Допустим, если сдвигаем цену назад на одну точку, то вот здесь у нас 0.77 корреляция с пампингом. А вот минус 0,77 – корреляция с дампингом. Вполне ожидаемо, потому что вот они как раз сдвиги. Вот сдвиг с пампингом, а вот сдвиг с дампингом. А во всех остальных сдвигах у нас значения получаются гораздо меньше. То есть, на этом отношении, в основании, глядя на эту картинку, мы говорим – ага, блин, у нас, значит, в большой части случаев изменения в пампинге предшествуют увеличению цену, а изменения в дампинге увеличение дампинга предшествует уменьшению цены. После чего мы начинаем этот куб трансформировать с помощью этих сдвигов. Например, берем со сдвигом минус один и считаем корреляцию между ценой биткоина и различными метриками. Смотрим, что метрики типа имбаланс у нас имеют высокую и отрицательную корреляцию с ценой. Вот они тут слева наверху. Ну не то чтобы высокую, минус 0.2 это на самом деле не очень высокая, но более-менее. А вот если мы возьмем корреляцию, допустим, между собой различных токенов, ну вот здесь вот она, по-моему, взята с двигом 0, потому что слишком высокие значения. без сдвига, то мы увидим, как коррегируют между собой изменения различных валют, как курсы различных валют корректируют с биткоином. А с правой стороны мы как раз видим ту же самую развертку, которую видели вот здесь. То есть, по горизонтальной оси у нас сдвиги. То есть, влево идет минус 1, минус 2, минус 3, минус 4, минус 5, минус 6, минус 7, а влево идут. А вправо, наоборот, плюсы. И вот что мы видим. Мы видим, что большой... А с левой стороны у нас как раз вот эти порядка сотни метрик, которые мы считаем на основе рыночных данных. по каждому рынку. И вот что мы видим, что в точке 0 у нас много чего с ценой коррелируется, а вот в точке минус 1 у нас почти ничего с ценой не коррелируется. Зато многое чего коррелируется с ценой в точке 1. То есть, какой мы из этого делаем вывод? Что цена мало, практически ничего цену не предсказывает из этих метрик. Зато сама цена очень хорошо на одну точку предсказывает изменения вот в других вот метриках. Ну и в том числе совпадает по времени с изменением этих метрик. Здесь показано, как мы в различных измерениях можем этот куб резать. Например, на точке минус 1 по вертикали у нас различные новостные каналы, а по горизонтали у нас различные метрики из этих, которые я называл, 4 метрики сантимента и 12 метрик когнитивных искажений. И тут мы видим, на самом деле, достаточно большие значения. Где-то тут 0,50 с чем-то есть. Вот, а тут где-то там аж минус 0,72 по некоторым. Вот здесь у нас другая картинка. Здесь мы берем только одно когнитивное искажение, шудминт, по разным каналам и смотрим, как оно играет на различных сдвигах. Да, соответственно, можно делать какие-то выводы, на каком расстоянии, во времени, какие метрики, какие когнитивные искажения, как могут быть связаны с ценой. Ну и вот такого рода разные анализы мы делаем. Ну и вот, собственно, к чему мы приходим в конечном итоге. Вот, собственно, наверное, самый интересный вывод из всей этой истории. Что здесь показано? Предположим, мы можем пытаться на основе вот этого большого числа различных метрик, порядка тысячи, часть из которых – сентимент, а часть из которых – это производные от различных рыночных данных, мы можем попытаться зауверфитить движение цены. Движение всего чего угодно мы можем заверфитить, но, допустим, возьмем цену. Будем пытаться заверфитить движение цены, подбирая некоторую суперпозицию метрик, соответствующими с плюсами или с минусами, которые будут максимально описывать движение цены. И после того, как мы, собрав суперпозицию всех этих метрик, мы их сложим, положим некоторый синтетический индикатор, и после того как мы этот заверфиченный синтетический индикатор получили, мы считаем его корреляцию со сдвигом по временной оси. Вот тем же способом, о котором я говорил. И вот что мы видим, допустим, для четырех видов метрик сентимента. Вот внизу мы берем только сентимент. Вторые столбики снизу – это только когнитивные искажения. Следующий столбик – это группа столбиков. Вторая сверху – это когнитивные искажения вместе с сентиментом. Ну а самый первый наверху – это еще и количество слов и количество постов в день, считаем. Ну и видим, что На минус один день у нас эверфитится все просто прекрасно. То есть, мы видим, что если мы берем сентимент вместе с когнитивными искажениями, то фитинг у нас получается аж до 0,8, а на всех остальных сдвигах ничего не получается. Из чего мы делаем его? В принципе, можно говорить о возможности предсказания цены по данным сентимента и когнитивных искажений. Вопрос в том только, что нужно правильную модель построить. с правильными методами. А с правой стороны мы пытаемся сделать то же самое на рыночных данных, причем на дневных, на часовых, на минутных и даже на секундах. И что мы видим? И видим, что на дневных данных, даже со всеми возможностями IR-фиттинга, у нас, во-первых, на минус один получается максимум 0,25. Соответственно, не очень высоко. Ну и примерно такой же IR-фиттинг у нас, корреляция за IR-фитченый индикатор у нас получается на нуле, только со знаком минус. В общем, так себе. А если возьмем на часах, то получается вот та картинка, которую я показывал, где у нас все случается после. Мы можем предсказать все, что связано с движением цены, но не само движение цены. Соответственно, мы очень хорошо можем закорренировать часовые движения сцены на момент этих движений и на момент и с тем, что будет происходить после. Но такой вот маленький хвостик невразумительный. На минутах то же самое, но и на секундах тоже все вот так. Забегая вперед, могу сказать, что если уходить на в эти самые на микросекунды. То есть, если работать на десятых долях секунды, то вот, скажем так, визуально, если зумить до долей секунды, то там все получается очень красиво. То есть, я как бы не считал, Но визуально есть ощущение, что на секундах у нас предсказуемость будет большая, но на одолях секунды работать, к сожалению, в существующих IT-реалиях невозможно. И даже если вы напишите софт, который будет делать фронт-раннинг на долях секунды, то Binance, я думаю, вас быстро притормозит, потому что фронт-раннингом они там сами очень хорошо занимаются, я думаю. Ну и, собственно, все публикации на эту тему. А, собственно, на этом все. Смотрим, какие еще есть вопросы. Так. Глава не помню. Быстро порадующая авторегрессия. Предсказание на одну точку. Я бы так сказал. В случае рыночных данных предсказание на одну текущую точку. То есть, на сейчас. Предсказать, что сейчас, очень легко. А предсказать, что будет завтра, гораздо труднее. Оптимальное предсказание, что было, то и будет. ну last known price да то есть вот с точки зрения minimum average percentage ROR пока что для крипты по крайней мере это baseline это state of the art но если не считать вот наш предиктор по медийным данным вот по медийным данным у нас уже все-таки получается чуть-чуть лучше это для классического SB Ну, да. То, что я сейчас вижу, мой опыт, то, что если мы берем социальные медиа, то блуждание получается уже не случайное. И если мы уходим на доли секунд, то оно тоже не случайное будет. Но на миллисекундных данных работать физически невозможно, а на социальных сетях, может быть, получится. Окей? Коллеги, есть ли еще вопросы? Кроме пожелания Алекса Бура порассуждать на тему бросания монет, а что там рассуждать? Я же говорю, если цена идет вверх, то предсказывать ее точно только практической ценностью. Чем круче цена идет вверх и тем меньше волатильность, тем проще ее предсказать. Только ценности от этих предсказаний немного. 

S00 [01:34:03]  : А вот знаете, тут такая ситуация. Вот вы сделали на основе своих индикаторов какую-то систему, фильтры наладили, что-то показывает она. Допустим, вероятность выигрыша 0.6 или вероятность лосса 0.4. И вы ее запускаете с продакшен на торги. И в какой-то момент она не показывает то, что требуется. Вопрос, когда ее надо отрубать? Это прямая задача. Это первый момент. Второй момент. Здесь вытекает, сколько требуется испытаний, чтобы убедиться, что система работает. То есть второй момент. И эти два краеугольных камня. 

S01 [01:34:51]  : Спасибо. Вы сказали очень важную вещь и напомнили мне сказать то, что я забыл рассказать. Вот смотрите, я когда рассказывал про нашего агента, Та архитектура, которая была предложена, где агент занимается беспрерывной адаптацией, а не reinforcement learning. Это возникло после того, как я прочитал достаточное число статей. где описывались попытки, если грубо говорить, то жалкие, сделать reinforcement learning для торгового бота. я просто вот здесь я понял, что это, так сказать, не прикладная задача, а вот в компании у нас проекты все-таки прикладные, вот поэтому, так сказать, хочется, так сказать, задача там не писать статьи для журналов, а задача деньги зарабатывать, вот, и я просто как-то понял для себя, что пытаться, значит, строить модели белого шума – это не очень практическо, Но что? Можно пытаться строить модели, которые будут адаптироваться и самонастраиваться на конкретные режимы. В этом смысле Adaptive Multistrategy Agent работает следующим образом. Есть текущий режим, И вот в рамках этого режима, пока этот режим такой, он подбирает те стратегии, которые оптимальны для этого режима, без всякого предсказания цены. Ну, если дополнительно есть какая-то информация закономерная, к примеру, из тех же самых социальных сетей, ее можно подтягивать, но пока даже без этого. Как только режим меняется, понятно, что в момент смены режима могут быть убытки, но при изменении режима после того, как режим изменился, мы снова на него настраиваемся и продолжаем работать в этом режиме. дальнейшее развитие этого направления которое как бы есть в головах это то что попытаться как раз попытаться вот решить задачу market speed segmentation выявить как раз вот эти вот режимы с тем чтобы когда значит мы знаем что ага вот на таких вот режимах работают такие стратегии на других режимах работают другие стратегии и если мы видим что режим меняется мы уже не пытаемся настраивать режим а мы по умолчанию берем те стратегии которые работали на том режиме который сейчас установился вот и вот только если эти стратегии не заработали вот тогда мы уже начинаем перестраиваться вот то есть вот я не уверен что это заработает если честно потому что есть такое понимание что устоявшихся режимов Да, спасибо, что это очень правильно вы написали в комментариях, но вот я пока что очень осторожно смотрю на возможность этого. Других комментариев нет. Коллеги, еще вопросы, замечания, предложения? Да, спасибо Алекс Буру за его замечание. Замечание очень ценное. С половиной, если не с двумя третьими, я согласен. Остальные я беру на осмысление. Они мне кажутся тоже очень полезными. Итак, всем спасибо и следите за анонсами. Кстати, я тогда сразу скажу, там я спрашивал, кто, кроме Игоря Пивоварова, готов будет рассказать о своих впечатлениях о конференции AGI. Вот, которая прошла, значит, соответственно, в конце прошлой, в начале этой недели. Вот. Я не знаю, по-моему, в последний момент я не видел, чтобы кроме Игоря кто-то еще вызвался. Соответственно, если Игорь готов будет один, рассказывает свои впечатления, то мы семинар проведем. Если Игорь сочтет, что одного от него недостаточно для обзора семинара, то мы, скорее всего, семинар заменим празднованием Дня Знаний 1 сентября. И тогда семинара не будет. Так что следите за анонсами. Ну и в любом случае, до новых встреч и спасибо за участие. Всем до свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
