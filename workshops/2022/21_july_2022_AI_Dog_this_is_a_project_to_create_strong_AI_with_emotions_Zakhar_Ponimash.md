## 21 июля - AI Dog — это проект по созданию сильного ИИ с эмоциями - Захар Понимаш — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/iG9JGm9DPVQ/hqdefault.jpg)](https://youtu.be/iG9JGm9DPVQ)

Суммаризация семинара:

Семинар посвящен разработке искусственного интеллекта с эмоциями. Основная тема доклада - эффективность обучения ИИ с использованием малого количества ресурсов. Обсуждается возможность обучения ИИ с мгновенным фидбэком или определением интервалов, характеризующих действия, приводящие к ревардам (наградам). Участник семинара рассказывает о своем проекте, в котором рассматривается возможность построения иерархий через многоуровневую сегментацию объектов. 

Проект нацелен на ускорение обучения с подкреплением, сокращение числа партий, необходимых для обучения. Рассчитывается, что скорость обучения будет в 100-500 раз выше, чем у PolicyGradient, и более стабильна, чем у QueryLink. Обсуждаются блоки, которые могут быть применены многократно, например, в разных модулях, таких как управление двигателями и ведение диалога.

В ходе семинара возникают вопросы по демонстрации проекта, в том числе по автоматической регулировке усиления. Обсуждается, как задача AGI может быть равна задаче reinforcement learning, и как методы реинфорсмент-ленинга, используемые сегодня, решают эту задачу плохо из-за высоких затрат и объемов данных на обучение. Стремление участника проекта - построить сильный AGI с помощью технологии, повышающей эффективность reinforcement learning, и сейчас он на этапе построения моделей, не включающих воздействие на среду, а только восприятие сигналов от среды.

Вопросы, поднимаемые в ходе семинара, касаются предельной сложности паттерна, на который алгоритм заточен, и возможности обучения роботизированной машины, которая учится обходить препятствия, например, детей, бегающих по дому. Обсуждается точность предсказания и устойчивость паттернов.







S02 [00:00:05]  : IDOC – это проект сильного искусственного интеллекта. То есть, так сказать, моя такая стратегия – я хочу сделать сильный искусственный интеллект. Почему он так называется? Основной задачей проекта является моделирование поедения животных, поэтому именно называется AI Dog, потому что собака – это такое животное, которое мы интуитивно считаем достаточно умным, но все же это животное, не человек. Мотивация. Я ее разделил на две части. Первая часть – это как слабая мотивация, то есть это то, что мотивирует меня работать над этим проектом. И такой мотивацией является желание создать алгоритм, который бы действовал в сходу с работой биологического мозга. А сильная мотивация – это польза для сообщества. Вот этот алгоритм работает в тех же задачах, где именно эта машина обучения с подкреплением. Обучение с подкреплением – его основное преимущество. является работа перед стрельбойми датчиками, планирование поведений и возможность предварительно обучаться без учителя реакции среды, то есть самообучаться. Мой проект ввелся с 2014 года. Изначально я концентрировался на чат-ботах, в основном основных на правилах, Потом поработал немного в области компьютерного зрения, в области обработки сигналов, ну там достаточно долго поработал. Ну и пришел к выводу, что нужно абстрагироваться в конкретной области, то есть не привязываться к конкретным словам, либо изображениям, либо сигналам. а работы с некоторыми эмбейтингами, то есть с векторами. Ну и открытые юридики есть по этому направлению. Это вот AI Framework библиотека. Ну вот здесь по этой ссылке можно найти ее актуальное состояние, а по этой ссылке, что ниже, можно посмотреть состояние, в котором она была там. Скажем, 4-5 лет назад. Просто для истории прикрепил. И также один из ботов, про который я вот говорил, что вначале занимался четботами, это вот быстро обучаемый бот, вот в 2016 году сделал, которое время диалога с человеком обучается реагировать на похожие фразы. Тогда это делал на модифицированном World2Vec. Ну, там делал World2Vec, потом регрессию на базе металлорежущей средней и использовал кнопку Madurai-Watson, чтобы собрать из нескольких ответов один вектор, а потом по нему найти подходящий ответ. Ну и вот по этой ссылке можно посмотреть демонстрацию работы. Похожие разработки, но это неростевые агенты, обучаемые генетическими либо эволюционными алгоритмами, также неростевые агенты обучаемые генетическими или эволюционными алгоритмами с локальной оптимизацией, то есть в основном агенты обучаются генетическими или эволюционными алгоритмами, но при этом присутствует в этой нервности некоторая функция ошибки, которая минимизируется медленным градиентным спуском. Басирующиеся на моделях алгоритмы, например, это вот Monte Carlo Time Step, это как раз таки… они тоже могут учиться без учителя, Там все чуть сложнее, потому что там рассматривается, строится модель переходов. Ну, очень похоже, кстати, на то, что я делаю. Строится модель переходов между состояниями, но имеется, скажем, ячейка, которая... Ну, получается такой трехмерный тензор. В нем... Ячейка по оси X может отражать состояние, в котором мы сейчас находимся, по оси Y – действия, которые мы сейчас делали, и по оси Z – то состояние, куда мы перейдем. Такие вот ячейки заполняются. Также университетовые RLE-агенты – это reinforcement learning, то есть обычно с подкреплением, это полис и градиент. Q-learning, DQN, A2C. В общем, там довольно много этих алгоритмов, но я выделил эти четыре, потому что pulse gradient наиболее простой для понимания. Q-learning сейчас довольно часто используется, но у него есть некоторые недостатки. жадный алгоритм, и он чаще всего сходится быстрее, чем польз играния, но бывает такое, что он просто не сходится по какой-то причине. У польз играния в этом плане чуть больше стабильности. И если говорить про A2AC, то это схема Actor-Critic, когда у нас есть некий критик, который смотрит и говорит, что мы вообще хотим получить в этой ситуации, скажем, в этом состоянии, какой мы можем получить выигрыш. А авторы уже выбирают действия, которые нужно предпринять. Есть еще алгоритм типа Q-Learning, но он также работает не как один алгоритм, а с некоторой политикой. Это SARS-алгоритм. Он, кстати, отличается от Q-Learning за то, что там применяется политика, а не заданный приз выбора конкретного действия в конкретный момент времени. Принцип работы системы iDoc следующий. Сигнал, в данном случае это вектор, поступая на вход из линии вектора во времени, интерпретируется как цирковой многомерный сигнал, где компонент вектора является отдельным каналом. То есть, если мы представим себе, что у нас есть какой-то вектор, например, мы берем данные с видеокамеры, картинку, прогоняем ее через ResNet и с какого-то слоя берем embedding, то этот embedding состоит из компонентов. И каждая компонента, так как картинки меняются, она меняется во времени. И мы можем представить, что у каждого компонента есть свой канал. Так как у нас есть постоянная частота кадров, мы можем эту частоту кадров в терминах цифровой проводки сигнала назвать частотой дискортизации для конкретного канала, где каждый компонент для вектора является отдельным каналом. После нормализации сигнал поступает на блок выделения состояний, из него в блок варианта аналогического вывода и в блок варианта решения. Также мы можем не просто наблюдать, но еще давать какое-то подкрепление, говорить, что вот сейчас он подпринял действие, которое привело к хорошему или плохому исходу. Хороший исход, который мы можем подать в систему, мы называем эмоцией удовольствие. плохой исход из трак. Об этом чуть попозже. Сам алгоритм применяется многократно. Ну, здесь, например, на слайде представлено, что у нас объект идёт с постоянной частотой дискретизации, но мы делаем прореживание. То есть, например, здесь он идёт с той частотой дискретизации, с какой идёт, и обрабатывается на высокой частоте. Потом здесь он идёт мы предполагаем, что у нас n равно 2, мы отразим с половиной частоты дискретизации. здесь четверть частоты дискретизации, здесь одна шестнадцатая частота дискретизации. то есть вот этот блок будет работать в одном времени, в другом. на больших диапазонах и на еще больших временных интервалах. Такое прореживание делается очень просто. Устанавливается фильтрование частот, и после него отбирается каждый n-ый элемент. Ну и самое главное — это селектор, который получает ноутбук, который решает, какое действие выполнить, потому что каждая стратегия дает свое действие. И вот он может быть просто работать как баггинг, то есть мы, например, возвращаем вероятности для каждого действия, а потом мы их складываем, вероятности, и выполняем функцию artmods. Понятно, что в таком случае надо как-то учитывать, что более высокочастотные, они менее важные. Можно как-то подбирать эти коэффициенты вручную, либо сделать обучаемую модель. И уже с помощью нее выбирать секретное действие. Ну и также сам argmax можно заменить на какой-нибудь поиск получу там. чтобы учитывать следующие возможные активации. Здесь рассматривается как раз таки предварительная обработка, то есть сигнал подается в ARU, это автоматическая регулировка выселения, либо по-английски автоматический гейн-контроллер, и модуль линейного предсказания. Ну, линейное предсказание, ну, ARU, понятно, оно работает так, что есть у нас разные диапазоны сигналов, например, у нас к какому-нибудь токометру приходят данные, где сигнал заменяется от 0 до 1000, а с какого-нибудь эмбеддинга, скажем, синкнета либо реснета у нас приходят сигналы, изменяющиеся в совсем небольших диапазонах, ну, в районе единицы. То как раз таки, применив каждую каналу ARU, мы приведем, если считать, что у нас распределение нормальное, то мы приведем от минус трех до трех вот в этот диапазон. Линейное предсказание применяется для двух целей. Первая цель позволяет заглянуть на несколько шагов дискретизации в будущее. А вторая цель, которая тоже очень важна, позволяет параметрически описать среду, в которой работает данный агент. То есть у нас подгоняются весовые коэффициенты, в модуль линейного предсказания, за счет чего мы можем описывать саму среду, где он применяется, через эти коэффициенты и их изменение в времени. Такое описание, кстати, было в книге Саймона Хайкина. Для описания радиолокационных признаков он описывал, что через авторегрессионные коэффициенты можно их описывать. Вот как раз-таки устройство ARU. Здесь прямая ARU применяется. Импульсная характеристика выглядит таким образом, что в полосе пропускаем нижние частоты. Желательно у нас, конечно, пропускать только одну нулевую частоту, тогда у нас здесь будет образовываться просто средняя. И когда мы здесь, получается, с знаком плюс пропускаем сигнал, вычисляем звено среднее, мы, получается, центрируем его, потом мы возводим за центрируемое сигнал в квадрат, опять-таки вычисляем среднее, но понятно, что здесь не будет одна нулевая частица, поэтому здесь будет отклонение от среднего, то есть здесь не совсем среднее будет. Также мы пропускаем, вычисляем среднее, корень квадратный из этого нам дает оценку среднеквадратичного отклонения. Когда мы делим сигнал на оценку среднеквадратичного отклонения, мы приводим его к тому, что у нас в каждом канале сигнал находится с нулевым математическим ожиданием и с единичным сквозом, с единичной дисперсией. алгоритм линейного предсказания мы сигнал на входе дифференцируем то есть берем разности t плюс один, сигнал момента плюс один минус сигнал момента t минус сигнал момента t просто а, нет, сигнал момента t минус сигнал момента t минус один берется такая вот производная После чего опять-таки фильтр конечной базовой характеристики. Здесь применяется также, но здесь уже это будет не фильтр fnch, это будет фильтр, который коэффициент фильтра синтезируется во время работы системы, чтобы предсказывать после интегрирования на выходе сигнал t плюс 1. Ну и, конечно же, мы можем во время обучения не пропускать гранит через функцию интегрирования. Это не нужно. Мы можем просто читать производные и прогнозировать сами производные, а не фильтры. Для чего это делается? Это в случае наличия линейного тренда такая процедура его убирает. То есть, если мы применяем Если мы применяем дифференцирование на ходе. Это один из довольно частых случаев нестационарности по математическому ожиданию. Понятно, что есть другие виды тренда, именно аддитивного тренда, которые не убираются таким способом. Но именно линейный тренд так можно убрать. Выделение состояний. Для выделения состояний можно использовать методы на базе модерированной гауссовой смеси, либо с помощью методов случайных проекций и тому подобных. В этом проекте комбинируется метод выделения на базе гауссовой смеси и случайных проекций. В чем заключается метод гауссовой смеси. Например, есть EM-алгоритм, где мы можем описать многомерное гауссовое распределение, оценивая параметры этого алгоритма. Потом на шаге EM мы можем расставлять индикаторы для каждого сэмпла таким образом с новыми индикаторами. То есть мы говорим, что у нас смесь общая. Надо было с этим начинать. У нас общая смесь. Распределение. Распределение, которое у нас есть, мы можем представить в виде смеси, где у нас есть некий вес у каждой компоненты, а компонентами является как раз-таки многомерный гауссовый процесс. Во многих вариантах этого алгоритма он довольно сильно упрощается. Например, предполагается, что гавариационная матрица является диагональной, тогда у нас алгоритм очень сильно упрощается, но он не учитывает повороты вот этой вот смеси. То есть, если мы говорим, что она диагональна, мы выделяем просто эллипсы, которые ориентированы по осям. Но если мы это не учитываем, нам, конечно же, приходится. работать с координационной матрицей, нам приходится ее обращать, но при этом мы можем учесть повороты, что он не ориентирован по осям, а развернут на них как раз-таки за счет того, что у нас, ну, это касательство упрощения. Таким образом, мы можем получить, во-первых, центроиды, это векторы от ожидания, мы, во-вторых, можем классифицировать с помощью того же метода, что на e шаге расставляют индикаторы, он уже может классифицировать вот функции arguments. Мы просто говорим, что вероятность принадлежности к классу кластеру 1 выше, чем кластеру 2, и тогда эти кластеры, они могут быть состоянием. Метод случайных проекций Звучит так, что мы случайным образом создаем 2 вектора на кибе и потом мы их генерируем случайным образом, а потом мы умножаем матрицу составляющую этих векторов на наш вектор, который мы получали на предыдущем шаге после этой обработки, умножая на этот вектор, мы можем получить новый вектор. И после этого берется функция знака. Вот здесь показано, что есть какая-то разделяющая функция. гиперплоскость, то с одной стороны мы можем сказать, что у нас 0, с другой единица, и тогда мы можем закодировать каждую точку в этом пространстве таким кодом. Брать случайно эти векторы нормалей оказалось, что не самая хорошая идея в том плане, что они дают довольно плохой результат. брать, скажем, именно как кастеризацию выполнять, тоже не очень хорошая идея оказалась из-за того, что нужно большое количество кластеров. И в итоге я пришел к тому, что беру сейчас мат-ожидание, центроватый кластер, получается, беру в качестве вектора нормали, а потом применяю вот этот вот метод, который, кстати, также, считай, ну, вот самый заметный формирующийся код называется LSH, это Local Sensitive Hashing, то есть это кэширование, чувствительное положение кэширования. И за счет этого как раз таки Получается, что если я, например, беру 5 кластеров, я из них могу получить 32 состояния. Ну, понятно, 6 кластеров 64 состояния и так далее. Еще одним методом выделения состояний можно считать Beta. По сути, тот же логин кластеризации. Если мы берем однослойную сеть, у нас есть механик конкуренции нейронов, Мы берем вначале необученную сеть, подаем в нее некий вектор сенсорный, который пришел к нам с ARU, а на выходе мы получаем разную активацию на каждой нейроне. Потом мы говорим, что если у нас победитель, например, нейрон 1, то мы все обучение отдаем ему. Он так и переводится, в принципе, видно в take all, то есть победитель забирает все, то есть все обучение отдается именно победителю, победившему нервам. Ну, таким образом обучаются сети, и на тестах она показывает примерно такие же результаты, как, например, показывает метка средних. но сам этот метод не представляет собой интереса, но есть его вариация. Когда мы берем двуслойную сеть, у нас получается что, причем первый слой может быть линейным, это скрытый слой. Когда мы берем двуслойную сеть, мы здесь получаем кластеры, а вот что мы получаем на скромном слое, это довольно интересно. Мы получаем, точнее на скрытом слое, мы получаем более интересное прообразование, то есть мы получаем признаки, которые мы можем дальше использовать для выделения состояния по той же логике. То есть у нас есть слой, есть у нас линейный слой без биос, то есть без смещения. Это у нас получается матрица. А далее мы можем точно так же вектор умножать на эту матрицу, через матрицу на вектор. и также функция знака – получать все те же вот эти вот коды. Ну вот, кстати, пример того, как работает алгоритм. То есть у нас есть вот эти вот плоскости, у нас есть положительное направление для каждой плоскости, И у нас, например, точка А имеет код 100 — это семерка, 300 — это ноль, 201 — это один. Ну почему-то семь, потому что это не бинарный код, это код игре. у них есть одно преимущество, что если у нас две вершины будут с последующими индексами, то, например, у нас будет вершина 7,8 или 6,7, то бинарные коды будут отличаться на один бит. Поэтому вот я их и использую. Ну, пример работы конкретно вот самого графа вывода. Здесь я в качестве состояния ввел обычные фразы, что из одного следует другое. После этого, кстати, формула, по которой происходит вывод. После этого я ввожу несколько начальных условий и смотрю, что порекомендуют алгоритмы, работающие по Вот эти правила надо сделать через один шаг. То есть один шаг мы пропускаем и через один шаг мы рекомендуем сделать. Например, возьмем вот здесь насморк. Смотрим, что насморк бывает при виле, бывает при простуде, но при простуде он бывает в два раза чаще. Потом мы говорим, что при простуде у нас рекомендация сидеть дома. как работает алгоритм, как он рассчитывает вероятность, все довольно просто. здесь у нас… вот если не брать во внимание, это по сути представление распределения вероятности через смесь распределений, то что у нас получается? у нас получается, что мы идем, если вдоль одной ветви графа Мы умножаем вероятность, если мы идем в параллельную тему графа, мы их складываем. Потом мы нормируем, чтобы у нас сумма вероятности была равна 1. Вот как раз демка, которую я уже сделал. Когда мы водим здесь курсором, мы записываем координаты x, y, здесь еще время записывается перемещение этих координат это и есть по сути ну здесь получается 50, 50-мерный входной сигнал это координаты x, y еще здесь 56 измерения отводится для кодирования времени Когда мы перемещаем мышью, мы кодируем x, y-координаты положения мыши в этот вектор каждого компонента, который, как я говорил ранее, представляется как свой канал сигнала. Это все отправляется на ARU, потом на модуль. Натуральное отторможение по сути представляет собой, что у нас модуль дает, он увеличивает отношение сигналов шума. То есть если у нас активация сразу по нескольким каналам, это вот биологический мозг, если активация сразу по нескольким каналам, то натуральное отторможение уменьшает активацию на соседних каналах. И активация более слабая, она либо затухает, либо вообще не доходит, и наиболее сильная только доходит. За счет этого всякие шумовые воздействия не проходят. То есть что-то вроде системы внимания. здесь используется метко средних, но по сути они очень похожи, только мы считаем, что дисперсия этого сигнала не изменяется, и там выделяются круги, а не эллипсы. Из центроидов составляется матрица. Видно, что здесь 5 центроидов. Матрица умножается на этот вектор. Получается активация, которая записывается. Для этого 0, 0, 1, 0, 0. И это превразуется в индекс вершины. которые равны 30. И когда мы идем дальше, он переключается на следующий индекс вершины и определяет эту связь между индексами. Здесь отмечена матрица с невероятностью графа, но так как у нас 32 состояния, то у нас матрица 32 на 32, и переход между состояниями, их вероятностью, отмечена на тепловой карте. Дальнейший план – это добавить эмоции и система планирования действий. Это в планах до середины сентября. В процессе систему сравним с другими метаномерами, так же до середины сентября. Ну и там, я договорился с Тимом, мне там поможет сделать у робота такую тележку, под управлением Raspberry Pi с двумя двигателями для тестирования, ну и камеры, для тестирования в реальных условиях. Вот, применимость. Где его вообще стоит применять? И стоит ли его применять в тех случаях, когда у нас есть предобработанный вход? Понятно, что можно напрямую подать данные значки, но так лучше не делать. Лучше все-таки их предобработать с помощью нейронной стены, например, не подавать напрямую значение яркости пикселей, а пропустить через Cloned ResNet, вот сейчас экспериментирую с ResNet-17, вот через него пропустить и уже вот эти эмбэнинги подать на вход. Ну и к тому же желательно, чтобы на выходе тоже формировались высоковыраженные команды. Потому что мы можем, конечно, сделать, что каждый выход — это, например, с два двигателя, мы можем с каждого двигателя сделать разные скважины. ну и направление движения, заставлять потом сразу на выходе этот сигнал давать широтному импульсному модулятору, который был привязан к двигателям, например, на какой-нибудь 555 микросхеме. Но этого делать тоже не стоит, потому что тогда могут быть рывки. Все-таки я считаю, что поручать работу двигателя лучше например, системам бид-регуляторов, которые обеспечивают постоянную скорость. Ну и также понятие «быстро» тоже может варьироваться в зависимости от различных условий. Желательно, чтобы система AIDOC выдавала высокоуровневые команды, был какой-то исполнитель, который бы их расшифровал и уже выполнял. Ну, преимущества от интерпретируемости. В принципе, возможно сделать, что вершины перехода будут интерпретированы. Например, если мы сделаем одно семантическое пространство с изображениями, с текстами, тогда мы можем как задавать текстами, ну да, с помощью текстов правила, то есть мы задали правила перехода, что если то, то это, вот это вот условие закодировалось в вектор, который был близок к вектору, полученному с камеры, ну и следствие также закодировалось в такой же вектор. Планирование поведения за счет вывода по графу. Можно планировать на несколько шагов вперед. Быстрая скорость обучения имеется в виду именно скорость обучения с подкреплением. То есть можно подать один раз эмоции или подкрепление и потом просчитать влияние этого подкрепления в разных узлах графа. Незасадки. То, что обсуждалось на предыдущей слайде, требует интеллектуальной подработки данных, потому что если подавать данные прямо из датчиков, оно будет работать, но будет работать хуже. Также требует умное устройство исполнения команд, способное их интерпретировать. Кстати, то, что обсуждалось на предыдущей слайде, что нам необходимо устройство, которое бы понимал, что в данном контексте является быстро ехать вперед, что это значит, то есть какую скорость сейчас выставить, и дальше какой-нибудь предрегулятор, который бы контролировал, что эта скорость не меняется, она нестабильно выставлена и она не изменяется. И третье высокое вычисление сложности. Конечно, у этого алгоритма, внутри него используются нейронные сети, он одновременно выполняет и прямые обратные проходы во время работы, что существенно более ресурсоемко, чем запускать просто нейронную сеть, которая бы обучилась, например, тем же A2C, актор-критикам. На текущий момент проработана практически вся теория, из которой реализованное процессирование было 40%. Реализация оставшихся 60% запланирована на конец августа, начало сентября. Тесты на конец сентября. В данной работе рассчитывается, что скорость обучения будет 100-500 раз больше, чем у PolicyGradient, а также больше стабильность, чем у QueryLink. И блоки можно применять многократно, например, в разных модулях. То есть мы можем взять сверхточную сеть и сделать выходы с разных слоев. Но это про уровень абстракции. А разные модули – это мы можем применять вот этот алгоритм в модуле управления двигателями и в модуле, например, ведения диалога. Есть у меня какой-то робот, который разговаривает. На разных скоростях то, что было написано, то, что было показано на одном из ведущих слайдов, что мы можем на разных числах дискретизации применять. И на разных уровнях абстракции, значит, вы говорите об этом, это когда, например, мы выводим данные с разных слоев нервной сети или от каждой, применяем этот алгоритм, а потом с помощью его селектора выбираем итоговую активацию какой есть и запустить. Ну вот, презентация на этом завершена. Сейчас отвечу на вопросы и, наверное, покажу демонстрацию. Так. Сейчас полосы посмотрим. А можете сказать, какая именно светком? 

S03 [00:35:25]  : Видим черный экран с очень маленькими буковками. 

S02 [00:35:28]  : Да-да, я говорю, если она закончится, я просто сейчас читаю вопросы, тут вот Витя спрашивает вопрос по красивой картинке. 

S03 [00:35:36]  : Может быть, у вас сколько? Если у вас немного времени осталось, может быть, все-таки демонстрацию сначала? 

S02 [00:35:41]  : А, ну давайте, демонстрацию сначала. 

S03 [00:35:43]  : Потому что у меня как раз вопросы связаны с тем, что непонятно, что мы делаем в конечном итоге. Поэтому, наверное, демонстрация частично ответит. 

S02 [00:35:54]  : Так, сейчас я переключусь. Так, я думаю, видно, да? 

S03 [00:36:11]  : Да. 

S02 [00:36:12]  : Вот. Ну, есть несколько тестов. Я, наверное, начну контроллерную анонимность показывать. Я начну с этого теста, который показывает автоматическую регулировку усиления. Что я имею ввиду? Ну, я думаю, что многие на нас не работали, поэтому не знаю, скоро будет интересно. 

S03 [00:36:36]  : Ну вот можно я тогда все-таки, раз вы рассуждаете о том, что было бы интересно, вот мне не очень понятно. То есть, мне понятно, что вы делаете, но непонятно, для чего вы это делаете. То есть, вы сказали, что вы хотите создать искусственную собаку, но для того, чтобы понять, что так подразумевается под искусственной собакой, нужно понять, каков ее функционал. что она кости приносит, бегает по комнате, поднимает лапку. Очевидно, это не очень связано с той картинкой, которая нарисована. Поэтому, если вы будете сейчас показывать тесты, хотелось бы рассказать, какая задача решается в каком из тестов. 

S02 [00:37:20]  : Хорошо, да. Смотрите, опять-таки, о чем я говорил в презентации, что конечная цель — это ускорить обучение с подкреплением. Вот если говорить именно про конечную цель всего проекта. То есть, ну, например, я занимался обучением с подкреплением, например, «Полисы границ», обучал, ну, самый простой пример, который я даже на YouTube выкладывал, я обучал играть в Пинг-понг, ну, агент обучал играть в Пинг-понг. И на поясе грани обучился довольно хорошо, но проблема в том, что на это потребовалось порядка 17 тысяч партий. Это довольно такой результат, который меня немного демотивировал в том плане, что огромное количество ресурсов тратится. И вот задача проекта – сократить число партий. требуемые для обучения. Ну, берем, например, ping-pong. Первый тест, кстати, был на тоже ping-pong. И я все-таки рассчитываю на то, что я получу такой результат, ну, примерно, за 100 пар. Объясню, почему я так считаю. Потому что данный алгоритм, он может как раз таки, модерируя переходы, ну, похоже, на то, что я показывал на одном из слайдов, где я рассказывал про модели обучения с подкреплением, то есть обучение с подкреплением на базе моделей. Это вот Монте-Карло таймстэп. Там тоже моделируются такие переходы, но они моделируются вместе с действием. Здесь действие как отдельная сущность закладывается, поэтому вот данная система может строить А потом, когда появится реакция среды, просто привязать, что вот такое-то состояние ассоциируется с негативным, такое-то с позитивным ощущением, и, ну, например, посчитать каждую вершину воплощения и распространить вот этот вот оценку в одной из вершин, ну их несколько, ну за 100 партий только сотни будет. Распространить эту оценку по всем остальным вершинам. Поэтому есть такая интуиция, что это будет намного быстрее. Как раз проверю я это осенью. 

S03 [00:40:06]  : Я правильно понял, что в этом контексте можно так это структурировать, что вы считаете, что задача AGI это примерно равна задаче reinforcement learning. Второе – вы считаете, что те методы реинфорсмент-ленинга, которые сейчас используются для реинфорсмент-ленинга, они решают эту задачу плохо по причине, которую вы обозначили – это высокие затраты и объемы данных на обучение. Соответственно, вы пытаетесь решить задачу построения сильного AGI как радикальное повышение эффективности reinforcement learning за счет вашей технологии, и сейчас вы находитесь в этапе построения моделей не включающие воздействие на среду, а только восприятие сигналов от среды и, соответственно, построение моделей среды пассивное. Но следующим этапом вы будете добавлять воздействие на среду и уже будете уточнять эти модели с учетом активного воздействия на нее агентом. Я правильно сказал? 

S02 [00:41:17]  : Да, все правильно. окей хорошо спасибо тогда давайте дальше вот ну опять-таки насчет первого теста я думаю что с ним наверняка многие работали поэтому очень бегло сейчас видно 

S03 [00:41:41]  : Видно собаку и видно курсор, но все по... А, да, то, что я запустил, не видно, понятно. 

S02 [00:41:48]  : Хорошо, сейчас переключу инструкцию. Весь экран буду показывать. Так видно? 

S03 [00:41:58]  : Так видно, но в сенсорном образе и синтезиоматическом образе все показано. 

S02 [00:42:03]  : Да-да-да, я это просто еще не запустил. Так. сейчас появилось. 

S03 [00:42:15]  : да, что-то бежит. 

S02 [00:42:17]  : вот, смотрите. да, вот здесь склонный сигнал. у него есть линейный мультипликативный тренд. ну, точнее, аддитивный мультипликативный линейный тренд. 

S03 [00:42:28]  : А вот можно тогда объяснить, что этот сигнал сейчас обозначает? 

S02 [00:42:32]  : Ну, как раз-таки то, о чем я говорил на презентации, кстати, тоже видно. Сейчас я просто мотаю на этот слайд. Ну, вот, кстати, эта схема. Вот у нас входной Вектор представляет компонент, и каждый компонент меняется во времени. Это модель того, если бы все сигналом было плохо. То есть, если бы он имел адективный линейный тренд… У вас сейчас выведена фотография собаки. 

S03 [00:43:12]  : Что является сигналом? Вот здесь, да? Да, вот то, что вы сейчас показываете. 

S02 [00:43:18]  : Вот здесь на вход поступает сигнал либо с датчика, либо с... Откуда он поступает? Либо с датчика, либо с нейросети. 

S03 [00:43:34]  : И датчик чего? Вы же какой-то пример показываете? 

S02 [00:43:40]  : Пример я именно, когда будет сигнал, покажу в этой демонстрации. Это то, как сигнал нормализуется. Этот тест показывает нормализацию сигнала. 

S03 [00:43:57]  : То есть у вас просто идет одноканальный сигнал? 

S02 [00:43:59]  : Да. И он нормализуется. 

S03 [00:44:04]  : То есть, нормальный сигнал он представлен как раз входным вектором. Правильно я понимаю? То есть, каждый вектор – это разряд в бинарной сетке? Какой сигнал? 

S02 [00:44:20]  : Представлю, что у вас есть... Ладно, давайте я начну с этого теста. 

S03 [00:44:25]  : То есть, если вы показываете примеры, вы уж тогда поясните, что же все-таки в примере подается на вход. 

S02 [00:44:30]  : Да-да, конечно. Сейчас я покажу на другой тест. Давайте с этого начнем. Здесь на вход подается, я вложу мышкой, вот она. Кодируется координата x и y. И как раз оно и подается на вход. Ну и плюс. Что подается на вход? Координата x кодируется и координата y. То есть это получается one-hot кодирование полярное, то есть там минус 1 и плюс 1. Здесь получается 25 измерений, и здесь 25 измерений. Вместе они дают 50 измерений при конкатенации. Ну и еще здесь 256 измерений дает время, но я могу, в принципе, его отключить. Да, наверное, отключу. Вот сейчас будет просто 50-мерный сигнал на входе. 

S03 [00:45:46]  : То есть, на вход вы оцифровываете оцифрованные координаты мыши? 

S02 [00:45:50]  : Да, в виде вектора. 

S03 [00:45:54]  : И какую-то задачу это решает? То есть, модель чего мы строим? Модель предсказания 10 человек. То есть, к собаке это никакого отношения не имеет? Сама фотография собаки там имеет какой-то смысл? Если вы будете водить мышью по белому экрану, что-то изменится? Нет. Окей. Просто эта собака сбивает с толку тогда. Лучше бы там была координатная схема. 

S02 [00:46:23]  : Но это просто логотип. 

S03 [00:46:27]  : Окей, ну вот как-то сбивая с толку, потому что я думал, что погладь пёсика написано, что вы считываете координаты пёсика и мышкой строите модель цветового распределения на этой картинке. 

S02 [00:46:44]  : Не, не, не цветового координата. У меня идея была в другом. чтобы к особым местам прикасаться, например, к носу или глазу, разные эмоции вызывать. Это идея в дальнейшем. 

S03 [00:46:59]  : Но сейчас же это не реализовано? 

S02 [00:47:01]  : Сейчас не реализовано, нет. 

S03 [00:47:02]  : Окей. Все-таки тогда расскажите, что реализовано и тогда… Да-да, я это расскажу. 

S02 [00:47:08]  : В общем, здесь происходит как раз кодирование в этот вектор кода. мыши находится сейчас, это когда-то по иксу, это когда-то по игре, где сейчас она находится. За счет, ну, это может стать паразитным, как бы, свойством ару, но в некотором плане, за счет переходного процесса мы можем увидеть историю перемещения. И вот оно все кодируется в вектор. После этого здесь вот как раз-таки происходит то, о чем я говорил, что мы формируем кластеры и берем матрицу из центроидов кластера и умножаем ее на этот вектор, который вот здесь. После этого перемножения мы получаем вот этот вектор, который отображен тут. Также мы переходы кодируем здесь. Например, здесь было 31, стало 10. Если я сейчас сюда, то 3. И он соединяет вот эти точки. Скорее всего, 1, 10, там 3, 21. И когда я вывожу мышлю, я соединяю вот эти точки, вычисляя на них оценки вероятности переходов. После этого здесь собирается статистика из сотни примеров. Что считается примером? Моя мышь находилась, скажем, в состоянии 10, и она перешла в состояние 2. А что мы предсказали? Какой переход мы предсказали? Мы предсказали, что в состоянии 10 мы перейдем в состояние 2, то значит мы добавляем плюс 1. Если мы предсказали какое-то другое состояние, а перешли состояние 2, значит мы не добавляем ничего. Мы потом на общее количество берем блоки по 100 примеров и на них считаем точность как парально предсказанные переходы к общему количеству переходов. И это своего рода метрика, показывающая адекватность логической модели мира. То есть если она правильно предсказывает переход, значит она более качественная, чем та, которая неправильно предсказывает переход. Задача повысить вероятность этого предсказания. для того, чтобы когда мы вводим мышью, она составляет расстояние при 33%, для 32-х состояний, а для детерминированных сигналов, когда я наблюдаю время, например, и если я не вожу мышью, то сигнал детерминированного она составляет, ну, практически, ну, около 100%. Я не могу говорить 100%, потому что хоть там единицы показывают, у нас есть. стандарт кончил последнего, из-за которой сказать 100% было бы некорректно. 

S03 [00:50:21]  : Скажите, пожалуйста, а вот в том, как вы водите мышью, там есть какая-то закономерность, которую можно моделировать? 

S02 [00:50:28]  : Да, конечно. Если я буду рандом наводить, она будет очень низко показывать. Ну, я сейчас буду, она там очень быстро упадет в эту точность. Ну, я, конечно, всем рандом наводил. Сейчас он наберет еще 100 примеров. Вот она. И оно-то будет падать. Уже по сравнению, я сейчас буду по сравнению, и то, что сейчас будет падать, там... А, ну я все по кругу. Надо как-то научиться рандомно водить. Сейчас я придумаю, как... Нет, у меня все равно не получается все рандомно. Ну, чем если не делать никаких вот фигур, а водить абсолютно рандомно, то оно падает. У меня иногда получалось... 

S03 [00:51:07]  : То есть вы хотите сказать, что когда вы водите мышью, то вы все-таки подсознательно водите не рандомно, а вы следует... Конечно, я часто замечаю, что я уже либо по кругу, либо по эллипсу. 

S02 [00:51:23]  : И он понимает примерно границы этого эллипса и предсказывает все равно с вероятностью выше, чем случайное угадывание. 

S03 [00:51:32]  : вот эта матрица смежности она как раз визуализирует ваш паттерн, то есть ваш подсознательный паттерн псевдослучайного вождения мыши, правильно я понимаю? 

S02 [00:51:46]  : да, правильно ну и опять-таки здесь если обратить внимание, то на вход подается не конкретно мышь, а именно вектор мы конкатенируем два вектора вместе и подаем на вход Также можно подавать абсолютно любые векторы. То есть можно составить вектор из значений датчиков длины, скорости вращения двигателя и всего остального. Либо не мучен конкретизировать вектор Embedded SyncNet, то есть та вот сеть, которая работает со звуком. и к нему еще можно координировать вектор с реснета. И вот, координировав все эти векторы, получить один вектор, который бы описывал бы все данные, которые мы посылаем на вход. И вот как раз-таки зачем делается вот эта вот ARU, потому что данные будут в разных диапазонах. То есть одни датчики дают данные в одном диапазоне, другие в другом диапазоне. Для некоторых диапазон может подходить, скажем, расширяться, уменьшаться. И вот чтобы это все свести к одному диапазону и чтобы с этим нормально работать, для этого применяется 

S03 [00:53:20]  : Захар? Да-да. Что-то вас не слышно? Ага. А, мне не было слышно. Сейчас слышно. 

S02 [00:53:28]  : Да, вот то, что я рассказал про аруму. Не было слышно. 

S03 [00:53:33]  : Была тишина в какой-то момент времени. 

S02 [00:53:35]  : А, я просто закончил. 

S03 [00:53:37]  : А, то есть, окей. 

S02 [00:53:41]  : Так что я готов отвечать на вопросы. 

S03 [00:53:43]  : Хорошо, давайте тогда пойдем по вопросам. Спасибо за доклад. Я сразу не могу удержаться от комментариев, что не очень понятно. То есть, как бы эта собака сбивает толку, там погладь песика. Я ожидал, что погладь песика это будет действительно что-то там, значит, оцифровка его изображения, предсказания цветов. Это еще в прошлый раз, когда его показывали, я пытался понять, что происходит. То есть, вам как-то надо все-таки сфокусировать то, что вы показываете. 

S02 [00:54:19]  : Я в прошлый раз говорил, что когенница-координатор. 

S03 [00:54:24]  : ну вот картинка она вот и погладь песик они как-то сбиваются хорошо значит вопрос от виктора значит вопрос по красивой картинке с цветком из точек с классикой с кластерами какая именно которая сута получена не которая смотрю Ну, Виктор, может быть, вы скажете, какую картинку умеете в виду? А, с цветком, с цветком, там где цветок, я понял. Вот, да, вот это, видимо, да-да-да, вот туда, вот сюда. Значит, это некоторый набор предсказаний положения мышки в первые такты ее движения? 

S02 [00:54:59]  : Нет, нет, нет, это из другого. Это я пытался предсказать, я с помощью моделей, следующие символы цифровой модуляции. Есть такая задача, есть КАМ-модуляция, здесь КАМ-16, и я пытался предсказать на основе истории символов модуляции следующие символы. И это я применил моделирование гаусса смеси к сигнальному созвездию и получил вот такие кластеры. 

S03 [00:55:44]  : И второй вопрос от Виктора по проходу по графу для логического вывода. Это же уже другой модуль. В нем не используется объединение двух методов проекции GMM. То есть вопрос о модульности системы. Этот пример является иллюстрацией того, что система работает с любой модальностью. В данном кейфе с графовым выводотекстовым. А могла бы работать как предсказание движения объекта. Вообще, каков перечень модальностей применения? 

S02 [00:56:19]  : вот смотрите, здесь это просто пример, потому что если я просто попробовал объяснить работу этого алгоритма своим знакомым, и у них возникал вопрос, ну и что, что там из строки следует четверка и что это значит, поэтому я написал только примеры, чтобы это были не вершины графа, а были вполне такие человеческие фразы, в которых есть хоть какая-то логика. понятно, когда я писал, я не особо задумался о логике, но чтобы было видно, что есть хоть какая-то лойка, что это причина связи. А насчет модальности. В принципе, все, что мы можем закодировать с состоянием, мы все это можем потом отправить в этот алгоритм и работать с ним. То есть, да, можно кодировать изображение. Я уже говорил, что сейчас экспериментирую с ResNet-17 через Unix. получаю вектор, потом так же настрою модель гаусс восьмидесят, и потом, выделяя вот по этим выделенным состояниям, прогнозирую, что вот если у нас такое изображение, а следующее такое, то такое вот будет следующее, ну то есть вот сейчас такое, такое, следующее. Вот это вот, да, можно. Можно работать со звуком. Например, использовать интернет. с нее и будем взять и так заработать. Ну или напрямую сделать за какой-то некий период времени лукмы преобразования в LCH от сигнала звука. И этот спектр закодировать в виде состояния, а потом рассказать состояние, которое связано с другим спектром. В этом плане тоже можно. на данный момент времени такой спектр, а потом он изменился, и вот изменения будут представлять разные коды, и переходы между ними тоже нужно смотреть. В принципе, все, что могут представить люди вектора, все нужно будет представить в этом виде состояния и в данном алгоритме прогнозировать. 

S03 [00:58:41]  : А вот тогда вопрос. Смотрите, причём этот вопрос как раз имеет непосредственное отношение для меня, по крайней мере, к той дискуссии, которая в группе идёт. Вот вы говорите, что если есть головная боль, кашель, насморк, повышенная температура, либо все вместе, либо одной из них – это уже отдельный вопрос. то вот с такой-то вероятностью по вашей матрице смежности будет нужно либо сидеть дома, либо пойти к врачу, либо ехать в травму. А ведь у нас головная боль может быть сильная. А может быть слабая, а может быть там еле заметная. И кашель тоже. Мы можем кашлять раз в минуту, можем раз в час, раз в день. То есть, как вы боретесь с тем, что у нас во входном векторе значения могут определяться не на бинарной шкале есть-нет, а на непрерывной шкале. 

S02 [00:59:40]  : Так он не работает на прерывной шкале, он не может. Какая нам разница, кто именно вектор. То есть у нас если будет непрерывная, то точно так же мы можем выделить центроиды, точно так же мы можем построить 

S03 [00:59:56]  : Я правильно понимаю, что если допустим мы головную боль измеряем по шкале от нуля до единицы. Мы на вход будем подавать значение по каждому параметру от нуля до единицы? Да, конечно. Окей, хорошо. То есть, я правильно понимаю, что если у нас, грубо говоря, вот в этой ситуации, если головная боль будет 1.0, то сидеть дома будет иметь, грубо говоря, вес там 69, вот как есть сейчас. А если головная боль будет 0.5, то сидеть дома будет там чуть-чуть поменьше. Ну, грубо говоря, там 30 с чем. 

S02 [01:00:37]  : Да, да. Ну, мы просто строго, как у нас говорится. То есть у нас в этом многомерном пространстве, например, головная боль или еще что-то, у нас будут кластеры находиться, мы их центрально выделили, провели гиперплоскости, мы можем определить, с какой стороны мы находимся относительно каждой плоскости. То есть вы... 

S03 [01:01:04]  : То есть, вы не осуществляете дискретизацию исходных функций типа головная боль, кашель, насморк на интервале какого-нибудь, не разбиваете их на диапазоны и у вас нет того, что головная боль – это может быть либо сильная, либо средняя, либо нет. То есть, у вас любой параметр – это число с плавающей точкой. 

S02 [01:01:28]  : Конечно, даже более того, если говорить про любые параметры, это не просто число с плавающей точкой, а это число с плавающей точкой с помощью этого алгоритма, приведенное в диапазон с нулевым математическим ожиданием и единичной дисперсией. То есть если оно нормально распределено, то по любому параметру, какой бы он не был изначально, то есть какой бы диапазон не был изначально, он придет в диапазон минус 3,3, если это нормальное распределение. То есть не нормально распределено, конечно. 

S03 [01:01:56]  : А если это ненормальное распределение? 

S02 [01:01:58]  : Вот это уже все намного сложнее. 

S03 [01:02:05]  : То есть, получается все-таки, если у нас, к примеру, там головная боль, она не характеризуется или там температура характеризуется ненормальным распределением. 

S02 [01:02:16]  : Если мы можем представить смеси нормального распределения, то в принципе алгоритм 

S03 [01:02:22]  : вот смотрите вот смотрите вот конкретный пример вот давайте температуру возьмем вот у нас температура есть грубо говоря 3 вот в моем понимании с практической точки есть есть три состояния температуры первое состояние температура это нормальная да там 36 и 6 Второе – это состояние температуры, когда это ненормально, это выше 37. От 37 до 37,5. А4, наверное. Потом следующее, начиная уже от 37,5 до 39. Ну и последнее – это уже выше 39, когда уже в реанимацию надо ехать. грубо говоря, или близко к тому. И тут же не нормальное распределение у нас? Нет, нет. 

S02 [01:03:12]  : Тут получается, наверное, можно смеси представить, где названные вами температуры будут на то же дальное. Мы как раз в такой смеси, моделирование, да, смеси вытаскивает. Ну, я думаю, надо работать с этим алгоритмом или рассказать. 

S03 [01:03:33]  : Окей, в первом приближении я понял. Спасибо. Следующий вопрос. Вы в слайде с песиком. Написано у вас, что там есть кластеры и образ у вас семантический. Вот вы можете пояснить, в пространстве решения, в онтологии, скажем так, или в операционном пространстве, где есть просто координаты и перехода из координат, вот чему соответствуют кластеры, то есть, что есть кластер? Это первый вопрос. И почему этот образ называется семантическим? Что в нем семантического? 

S02 [01:04:10]  : Во-первых, Вот философский ансамбльный образ представляет собой, мы работаем с модельными координатами, каждый координирует 25 измерений, то есть мы работаем в 50-мерном пространстве. В этом пространстве у нас есть некие сгущения, точек, где мышка бывает чаще всего. Вот эти сгущения точек, по сути, есть в кластерах. Понятное дело, что когда мы говорим, что найдем нам пять кластеров, а их может быть больше или меньше, то это не совсем правильно с точки зрения кластеризации. Локти используются еще для подбора оптимального количества кластеров. Изначально нужно знать, что мы хотим 32 состояния, то есть 5 кластеров. Вот мы и находим 5 изгущений. вот этих вот точек, то есть, где они ближе находятся. 

S03 [01:05:17]  : Вопрос, а все-таки чему они соответствуют? То есть, это к чему? К тому, что, грубо говоря, вы можете мышью водить в пяти областях экрана, рисовать? 

S02 [01:05:28]  : Смотрите, если вы вот так вот водите мыши, то понятно, что где вы больше времени проводите, там будет сгущение. Это ваше индивидуальное, где вы больше времени проводите. 

S03 [01:05:43]  : То есть, если мышкой долго держать в глазу, то кластер образуется на глазу, правильно? 

S02 [01:05:50]  : Нет, не образуется, но там по другой причине, потому что мы обновляем сигнал, только если в нем есть новизна. 

S03 [01:05:57]  : если вы будете крутить мышкой вокруг одного глаза, то сформировали в другом месте пластер, то 

S02 [01:06:08]  : Если мы будем прикинуть возле одного глаза, то он постепенно перетянется. Прекрасно. 

S03 [01:06:12]  : Хорошо. Прекрасно. Следующий вопрос. Вот вы водите как-то мышкой. Вот, к примеру, вы мышкой водите вокруг одного глаза, потом вокруг другого, потом вокруг одного глаза, потом вокруг другого. А параметр на число кластеров у вас задан 5. Соответственно, что получится? 

S02 [01:06:29]  : Сказать абсолютно точно, что получится, я не могу. Я могу сказать только, приблизительно. Ясно, что будет два кластера, вот эти два глаза. То есть не пять? Два кластера будут точно, эти два глаза. Потом из-за переходов какие-то шумовые точки, скорее всего, к ним потянутся остальные кластеры. либо вокруг одного глаза разобьется на несколько глаз. То есть, это надо экспериментировать. 

S03 [01:06:58]  : Вы понимаете, что это немножко не то, что нужно. То есть, вы понимаете, наверное, что если выводится мышью то вокруг одного глаза, то вокруг другого, то вокруг одного, то вокруг другого, то у вас в лучшем случае должно быть максимум четыре кластера. Один кластер на вождение одного глаза, второй кластер на вождение другого глаза и еще два кластера на переход от правого глаза к левому и от левого к правому. То есть пятый кластер. Это вот как раз задача. Задача кластеризации без определения числа кластеров заранее это вот священный грааль на самом деле. 

S02 [01:07:38]  : Вот, я же про это и говорю, что у меня есть раздумки по методу Моктера, например, и других методов для того, чтобы определить оптимальное число кластеров. Например, можно использовать лабиринт Фаррель. Но тут проблема-то в другом. Проблема в том, что тогда размерность графа будет динамически меняться. А вот с этим намного больше проблем будет, чем то, что... В общем, как бы из узора выбирается меньшее. И на данный момент мне кажется, что то, что у меня есть нижние кластеры, это меньшее зло, чем то, что если я буду динамически изменять число кластеров, то у меня будет изменяться размерность самографа. Я уже простроил здесь какие-то вероятности. поделились, а потом он резко раз, например, уже не 32 стал, а стал 16. Ну и что мне с этим делать потом? То есть, а потом он опять стал 32. И вот это вот будет более серьезная проблема, чем то, что какой-то классер разобьется на два. Да, это проблема, с этим нужно что-то делать, 

S03 [01:08:52]  : Но вот вы называете эти кластера семантическими. Вы же понимаете, наверное, что если один глаз разобьется на две половинки, а второй глаз на три половинки, то семантическим это будет назвать только очень с большой натяжкой можно. Да, конечно. Окей, хорошо. Следующий вопрос. Какое отношение реализованный функционал имеет к ИИ собаки? Если я правильно понял, до собаки еще пока что очень далеко. То есть, вы реализуете некоторые базовые вещи, которые потом когда-нибудь будут встроены в собаку, да? 

S02 [01:09:27]  : Именно платформа, которая будет ездить, она планируется на октябрь. На что? 

S03 [01:09:33]  : На октябрь. хорошо, а ездить она будет зачем? какова цель будет? какова, скажем так, вылью? какова ценность ездящей собаки? 

S02 [01:09:48]  : в общем, планируется как мы дрессируем собаку мы не говорим сидеть, а сами ее садим мы говорим стоять, а сами ее поднимаем то же самое сделать, например, сказать вперед Провести рукой, нажать кнопку, которая дает вознаграждение. Ну, типа, когда мы так говорим еще под камерой с собой. Провести вперед, нажать кнопку, дать вознаграждение. Потом сказать назад, провести, нажать кнопку, дать вознаграждение. По идее, за счет этого, когда я скажу вперед, машинка должна поехать вперед. 

S03 [01:10:21]  : То есть, вы хотите сфокусироваться ее голосом и сделать возможность дрессировки? Да. Окей, окей. А сразу тогда уже, извините, вопрос. Вот вы же изначально говорили, что у вас задачка была повысить эффективность reinforcement learning и ссылались на свои собственные эксперименты с жимом. А почему бы не, грубо говоря? собственно, решить основную задачу, почему бы не показать, что вы задачи того же жима можете щелкать гораздо быстрее, чем... Это план на сентябрь. А, то есть, это есть в планах, окей. Хорошо, спасибо. Следующий вопрос от Виктора, снова Носко. Значит, по демо тоже вопрос. Я писал его в чате. В общем, думаю, всем будет интересно. Это некая область применимости предсказания движения мышки по образу. В каком условно-дисперсном разбросе пикселов дается точность? 90%. Это 100 на 100 пикселов или 3 на 3? Какое время предсказания? Это секунда? 10 секунд? Это некий такт движения. Какова сложность паттерна движения предельная? Какой способен алгоритм предсказать? Например, если я стану двигать мышку зигзагами с увеличением амплитуды, какая точность будет? 

S02 [01:11:38]  : Давайте посмотрим. Начнем с конца. Просто буду двигать сейчас мышкой зигзагами. Виктор, может быть вы свой вопрос прокомментируете, если что? 

S01 [01:12:07]  : уточните. да, конечно. собственно, мой вопрос, он вообще, скажем, на понимание также как и первый. то есть я бы не хотел углубляться в какие-то технические детали. слышно уже, да? да. в технические детали, потому что их там понятно, что их много. но вот известно, что что такое интеграл, людям легче понятно, чем что такое производная. то, что это просто площадь, а что такое производная, я знаю, что многие люди не понимают. наоборот. ладно, я к тому, что физический смысл. физический смысл, что площадь – это люди понимают. место больше – это лучше. а там какие-то углы... пределы приращения, им тяжело это понять. И здесь я хочу понять, что, смотри, Захар, ты же сделал этот алгоритм, ты знаешь отличия, ты показал на слайде, что у тебя есть отличия данного алгоритма с другими алгоритмами, которые делали другие разработчики ранее. и у тебя, соответственно, однозначно наверняка есть какое-то свое предположение, даже если ты его там не полностью протестировал, о его эффективности и о его границах применения. 

S02 [01:13:14]  : в принципе, ты там уже ответил частично. 

S01 [01:13:19]  : на этот вопрос ранее, когда по вот этой демке, что на вход, что на выход. но я хочу понять предельную мощность, архитектурную мощность. когда мы критикуем gpt-3, мы все уже поняли в чем ее... минусы, да, что неконтролируемая генерация, она там просто пытается слова… научилась понимать статистику слов, подставляет их, а сущности, ключевые слова и смыслы тяжело улавливает, да, то есть намерение тяжело улавливает, цели нет и так далее. Вот я здесь хочу понять… каков предельный вот эта вот сложность этого паттерна, на который дан алгоритм заточен. и это же отсюда следует от этой сложности. сложность и, конечно, вот это, допустим, ты сделаешь роботизированную некоторую машинку, которая едет и которая там обходит какие-то препятствия, да? и вот, допустим, ты говоришь, утверждаешь, что мой алгоритм лучше, там быстрее обучается. тогда ты говоришь, что дети, бегающие по дому, быстро мимо этой машинки, эта машинка учится за 5 минут обходить этих детей бегающих, потому что она понимает, что они бегают с комнаты в комнату. Вот к чему этот вопрос. Казалось бы, у него далеко идущий такой ответ. Я понял вопрос. 

S02 [01:14:34]  : Смотри, отвечая на твой последний вопрос, я сейчас довольно долго, тем временем, что мы говорили в один из экзаменов, Точность скакала от 37 до 25. Вот, в принципе, я ответил на вопрос. По точности сегодня циглограмма с нарастающей амплитудой. Только скажи, я правильно выделил циглограмму или нет? Ну, то есть решили. 

S01 [01:15:01]  : я же не знаю зигзаги правильно или неправильно. это не так уж на самом деле сильно и важно. я хотел бы ответ. вопрос по устойчивости. по зигзагам, по кружочкам и по прочим вещам. то есть насколько сложный паттерн. 

S02 [01:15:16]  : я понял вопрос. так чтобы не собрать потому что я не тестирую это все спроси я могу сказать, как я считаю, как будет, но я этого не тестировал. если такой ответ устроит, я могу сказать. 

S01 [01:15:40]  : конечно, конечно. давай, хорошо. тогда добавляй просто, что не тестировал. 

S02 [01:15:43]  : я не могу говорить, что так будет. когда протестировал, я смогу сказать, что вот так получилось. но сейчас нет. то, что я считаю, что, в принципе, увеличивая ревард этот алгоритм сможет повышать собственную разрешающую способность таких конкретных цифр я не могу сказать потому что опять-таки я не тестировал еще осень отвечу на этот вопрос именно с цифрами но да он сможет повышать свою разрешающую способность это первое второй вопрос Если мы меняем паттерн, то, как я уже говорил, постепенно вот эти вот кластеры, они перетаскиваются, чтобы лучше описать новый паттерн. Ну и перестраивается, понятно, модель графика. То есть, если мы меняем паттерн, то Примерно через тысячу повторений оно перестроится полностью, но опять-таки эмоции, когда я добавлю, они будут влиять на скорость обучения. Если будет довольно сильное эмоциональное состояние, то скорость обучения будет увеличиваться. То есть, возможно, там за 10-15 операций будет перестроить происходить. Опять-таки, я протестирую, я скажу. Потому что сейчас я говорю о том, чего еще пока не протестировал, не знаю, как оно будет на практике. Но вот мое предположение такое. 

S03 [01:17:35]  : Спасибо. Спасибо. Следующий вопрос от Сергея Терехова. Неожиданно появился граф. Что за граф? Как подкрепления распространяются по вершинам? И почему РЛ обучение от этого ускоряется? 

S02 [01:17:51]  : Ну, граф это, как говорил Сергей, граф, чью матрицу мы здесь видим. Подкрепления распространяются по вершинам. 

S00 [01:17:57]  : Подождите, подождите, подождите. Вы сейчас говорили про кластеры. Кластеры живут своей жизнью. Есть пять кластеров, они живут своей жизнью. Граф, что такое? 

S02 [01:18:06]  : Смотрите, зачем эти кластеры вообще были нужны? Сейчас объясню. Кластеры были нужны, чтобы закодировать состояние. Когда мы закодировали состояние, мы из этих состояний переходим к вершинам графа. 

S00 [01:18:26]  : Непонятно. Как соотносятся различные коды состояния с вершинами графа? 

S03 [01:18:31]  : Сергей, можно я вставлю? Потому что у меня есть гипотеза, которая, возможно, поможет ответить на вопрос. Смотрите. Вот мой опыт работы с этим самым, на чем я остановился в своих экспериментах как раз с пресловутым пинг-понгом. Что есть огромный поток сенсорной информации, пикселов, которые надо перелопачивать в то время и просто нужны бешеные ресурсы для того чтобы этого делать для того чтобы решать задачу предсказания там сказать обучение и так далее но если у нас есть понятие шарик и понятие стенка и понятие ракетка то у нас снижается количество информации то есть мы понижаем объем информации переходя от пикселов к объектам 

S00 [01:19:18]  : Это да, если это семантический объект, то, конечно, да. 

S03 [01:19:21]  : Сейчас я закончу мысль, потому что тоже, извините. Таким образом, у меня есть гипотеза. Захар, заодно, может быть, вы ответите, что как раз повышение эффективности reinforcement learning на примере того же Pong вы достигаете за счет того, что вы просто снижаете количество тех объектов, с которыми вы имеете дело. То есть, вы имеете дело не с пикселами, а с ракеткой, с мечом и со стенками. 

S00 [01:19:51]  : Антон, ты сейчас рассказываешь о том, что такое кластеры. Про кластеры понятно. Я не понимаю, как возникает граф, в частности, в каком случае проводится ребро между двумя вершинами, а в каком случае не проводится. Вот такой простой ответ. Дайте, пожалуйста. если узлами вершины являются, вот если у вас есть 5 кластеров, то у вас есть там тридцатидвухмерный какой-то вектор, да? соответственно, у вас 32 узла кластера, правильно я понимаю? нет, у меня нет тридцатидвухмерного вектора. или 5, сколько узлов? 

S02 [01:20:19]  : 32 или 5? получается граф, в котором 32 вершины. 

S00 [01:20:25]  : 32 вершины, да, вот 32 вершины. теперь вопрос, в каком случае между 17 и 19 вершиной возникает ребро? 

S02 [01:20:33]  : Если после кластера 17 попали в кластер 19. 

S00 [01:20:40]  : Один раз или сколько? 

S02 [01:20:42]  : Один раз попали, мы получили игру с вероятностью 1 деленное на количество срабатываний всего по всему графу. 

S00 [01:20:52]  : то есть это правило хэба, усиление связи между графами. если вы переходите из нитры в вершинную нитру, то между ними усиливается связь. 

S02 [01:21:00]  : если вы работали с марковскими моделями, то знаете, как там тоже использовалось. 

S00 [01:21:10]  : это то же самое только в профиль. то есть, грубо говоря, граф это нечто, что отражает частоты переходов между парами кластер, между парами вот этих вот кодов 32. между пятимерными кодами. 

S02 [01:21:24]  : вот был один пятимерный код, 

S00 [01:21:34]  : теперь другой пятимерный код. первый код принадлежал у нас, оцифрован в номер кластера номер 9, а второй код оцифрован в номер кластера номер 17. если мы перешли из одного кода в другой, то есть мы этот факт оцифровали, огрубили как-то, то мы, во-первых, вводим ребро, если его не было, и если оно есть, то начинаем приписывать ему какое-то число, напоминающее вероятность. то есть граф это на самом деле у вас просто те переходы, которые были. это означает, что в принципе для сложного движения произвольного у вас будет полносвязанный всегда граф. все связаны со всеми. 

S02 [01:22:11]  : вероятно, но я не уверен. абсолютно все со всеми были связаны, я еще не получил. Ну, там не ребро, там получается дуга. То есть, если из 1... Например, если мы пришли вот в эту область пространства, или попали в эту область пространства, то у нас что будет? У нас будет вершина 7 и вершина 1 связаны, но из 1 в 7 мы не сможем упасть. То есть, это вот дуга. 

S00 [01:22:35]  : Ориентированный граф. Понятно, да. Ну, достаточно сказать, что возникает ориентированный граф, где ребра означают факт того, что я когда-то из этого в житую вершину перешел. дальше и так далее. вот теперь вопрос. вот этот есть ориентированный граф у вас есть. как по нему распространяются реварды? я еще раз говорю, еще раз подчеркиваю. если сцена произвольна, то есть если вы заранее не сузили количество различных сцен, которые вы будете анализировать, то есть если вы априорно не сузили свою задачу, то граф будет близок к полносвязанным. это факт. И в случае произвольной сцены он будет просто строго полносвязан, потому что из любого кластера всегда можно перейти в любую. Никто же не запрещал. Теперь вопрос, как реварды, до реварды мы сейчас дойдем, но допустим уже есть какие-то реварды, как они начинают распространяться по узлам этого графика? 

S02 [01:23:27]  : Хорошо, у нас есть ревард, который находится, например, в узле B. мы можем пройти из В в А, то мы можем сказать, что возьмем внутренний маркер, который находится на узеле В, умножим его на вероятность перехода в узел В, то, которое получилось в узле В, мы перейдем в узел А и умножим на эту вероятность. 

S00 [01:24:04]  : то есть вы распространяете реввард по тем связям, которые есть. возвращаясь к вопросу, что если у вас связи почти всегда полноосвязаны, то любой реввард мгновенно распространяется на весь граф. как возникает селективность? 

S02 [01:24:19]  : хорошо, оно везде распространится, но он же не равновероятен. 

S00 [01:24:24]  : почти равновероятно. вот смотрите, если вы предполагаете изначально, что у вас будет очень разреженный граф, то есть там число переходов нетривиальных будет мало по сравнению с общими возможностями перейти из каждого к каждой, то есть только в этом случае 

S02 [01:24:39]  : вы нетривиальным образом какой-то ревард из вершины переместите в относительно небольшой… вы хотите сказать, что у нас всегда вероятности будут… то есть у нас все вероятности будут одинаковые? 

S00 [01:24:52]  : в зависимости от сложности сцены. какая будет сложная сцена. если собака будет бежать в лесу и все возможные деревья и ветки, которые там возникают и все дорожки покрывают все пространство, то мгновенно вы получите полносвязанный граф и любой ревард мгновенно распространится на все узлы. если это будет собака ездить по рельсам только вперед-назад и только умеет останавливаться и только ехать вперед и только назад, только эти действия она может делать, то у нее очень фиксированная, конечно, сцена, она почти ничего не будет видеть и действительно тогда у вас вместо полносвязного графа будет там буквально считанные штучки этих связей. поэтому в зависимости от того, какую задачу вы хотите решить, вы вот если у вас есть механизм отсечения каких-то ребер, вы например запрещаете каким-то ребром быть? 

S02 [01:25:43]  : единственное, чему я напрещаю быть, это петли. петель не должно быть. все остальное... а как вы это гарантируете? 

S00 [01:25:52]  : вы вложите алгоритм, который там неизвестно. вот вы выберете ребро, оно возникло из-за перехода. дальше вы должны логикой проанализировать все возможные потенциальные петли, которые могут образоваться. и если хотя бы одна из них образуется, то это ребро запретить. так вы хотите сделать? 

S02 [01:26:08]  : ну, петля – это переход, завершив саму себя. 

S00 [01:26:12]  : а, вот в этом смысле. 

S01 [01:26:13]  : а то, что вы говорите, это цифра. 

S00 [01:26:15]  : да, я пытаюсь понять, а чем петли вам мешают. я нахожусь в этой точке, вот я стою, ничего не меняется. я в этом кластере нахожусь. 

S02 [01:26:24]  : это и дело, что если ничего не меняется, то алгоритмы не надо анализировать. то есть это для экономии ресурсов сделано, а если он не анализирует, значит он не простраивает связи, значит петель не будет. 

S00 [01:26:39]  : то есть вы петли убираете фактом того, что вы выяснили, что это петля. Ну я хорошо, я понял, ладно. 

S02 [01:26:47]  : То есть у нас алгоритм работает не каждый такт, когда пришло изображение, он отработал. А если есть надежда, то есть если у нас меняется входной сигнал, во-первых, должно ясно, А во-вторых, мы должны переходить между разными вершинами. 

S00 [01:27:05]  : Захар, тогда у вас будет проблема вот такая. Смотрите, вот вы сидите и ждете новизны. Вот вы находитесь в каком-то узле, в каком-то кластере и сидите ждете новизны. Пока новизны нет, вы ничего не делаете. Потом появилась новизна, вы переходите и начинаете описывать этот процесс вероятностью. Но дело в том, что есть проблема. 

S02 [01:27:24]  : сколько вы сидели в этом в этой вершине минуту день месяц или год этого я во всех демонстрациях даже вот это я сейчас покажу не они про демонстрации я пропустил вектор сенсора добавляю тайм-кодер который скажем, минута – это тоже новизна. то есть сменилось время, это новизна. 

S00 [01:27:51]  : понятно. тогда у вас возникает проблема, что такое масштаб времени для этой задачи. опять вы говорите, я рассматриваю задачи, у которых новизна должна возникнуть в течение минуты. не возникла? до свидания. 

S02 [01:28:01]  : нет, здесь многомасштабное кодирование. то есть здесь 56, это multi-scale encoder, он кодирует ни в одном масштабе. Он кодирует в масштабах кратных степеням двойки. То есть у нас есть 128 отчетов кодируется, потом у нас кодируется 64 отчета и так далее, и вот у нас 

S00 [01:28:29]  : хорошо, ну окей, я услышал. просто там будут вопросы, что считать вероятностями в зависимости от того времени, сколько вы сидели в узле, а потом перешли. то есть вероятность она же там для переходов, она переходов за какое-то время. вероятность перехода за микросекунду всегда равна нулю, а вероятность переходов за год всегда равна единице. вы в конце концов попадете. соответственно, вероятность она там времени не устраняется, если вы только специально не сделаете дискретное время какое-то. и тогда будет вероятность за один такт перейти. а если у вас нет дискретного времени естественного, то тогда возникает вопрос. ну хорошо, это допустим вы как-то там запрограммируете. с графом понятно? как только число кластера фиксировано, сразу фиксировано размер графа, вы показали, как вы понимаете наличие ребра, что это для вас означает, тоже понятно. тогда вот следующий мой вопрос такой. поскольку все, что вы нам рассказывали, касалось задач, для которых был известен правильный ответ. то есть из собачки вы сказали двигайся вперед, а соответственно, если она поехала вперед, вы знаете, что это есть правильный ответ. мышкой выдвигали, если вы попали в правильную точку, если модель сказала, что вы должны в этой точке находиться, то вы знаете правильный ответ. это означает, что вы используете алгоритмы обучения с учителем, потому что ответ известен. 

S02 [01:29:51]  : нет, это реакция среды. 

S00 [01:29:54]  : какая же реакция среды, если вы знаете ответ, вы знаете точно, тогда вы должны попасть. вы знаете следующую точку правильно, расположение мыши, вы ее знаете. И если вы попали в эту точку, которую вы знаете, то вы получаете, условно говоря, в ваших терминах ревард. А если вы не попали, то не получаете. 

S02 [01:30:11]  : Здесь ревард вообще ни при чем. Не попали, не попали – это совсем другая задача. То есть это предсказание, да, это с учителем. Я говорю про другое. Вот я говорю собаке, например. Едь вперед, двигаю ее рукой вперед, нажимаю кнопку, погладить. вот я нажал кнопку погладить после всех этих манипуляций. я вот дал ей ревард. 

S00 [01:30:37]  : потому что вы знаете правильный ответ. вот если бы вы давали ревард за то, что собака, например, выиграла в теннис за выигранную партию, разница очень большая между тем, что я говорю и тем, что вы планируете. дело в том, что то, что вы сейчас пока... вы понимаете вопрос? вопрос понятен мой или нет? конечно. да, понятен. 

S02 [01:31:01]  : не давать правильного ответа. чтобы она сама нашла правильный ответ и получила ревард. 

S00 [01:31:07]  : нет, чтобы она дала какой-то ответ, а вы, независимо от того, что она думает, оценили этот ответ и либо дали ревард, либо не дали. 

S02 [01:31:18]  : да, конечно. 

S00 [01:31:20]  : так это это это это очень большая сильная разница между задачами с мышкой которую показать и так далее потому что там положение точки правильно известно А вот если бы вы, например, давали ревард только в том случае, если пользователь найдет на экране какую-нибудь закорючку, и в этой закорючке мышку поведет вправо, а не влево. И вот это событие для вас ценно. То есть, во-первых, найти закорючку на экране, а во-вторых, с этой закорючки стартануть двигаться вправо. Вот это неочевидное сочетание, оно поощряется. Вот тогда это был бы реинфорсмент. 

S02 [01:31:52]  : Смотрите, я еще раз по дальнейшему плану открыл слайд. Здесь его видно. Здесь есть два пункта. Вот сейчас мы говорили про пункт второй. Я его планирую сделать до середины сентября. Есть пункт третий, о котором вы говорите, что я буду водить рукой. что я буду моей рукой давать правильный действие. Это третий пункт. То есть я собираюсь оба теста провести. Один – это как раз-таки игра с пинг-понг, то, что я делал с полиси-градиент. И второй тест – это как раз-таки сконструировать этого робота и дрессировать его, как настоящих собак мы дрессируем. 

S00 [01:32:40]  : Захар, два вопроса связаны, они на самом деле логически связаны. Они вот в чем состоят. В случае, когда ваша задача напоминает задачу обучения с учителем, то есть вы знаете правильно ответить, распространение реварда по ребрам графов и приписывание ревардов соседним ребрам имеет смысл, потому что там выполнено предположение непрерывности. то есть вы, грубо говоря, находите, говорите, ревард в близких областях пространства должен быть ближе. поэтому, соответственно, если я эти области могу между собой логически связать переходом, то я тогда могу логически перенести ревард. то есть в случае, когда обучение а-ля обучение с учителем, вот такой способ ревард пропагейшна, распространения ревардов, он работает. но когда у вас ревард отсроченный, редкий, то никакого основания считать, что если вы перешли из итой вершины графа в житую вершину графа, а в итой вы получили реварт, то этот ревард имеет смысл распространять на живую вершину, никаких оснований нет. более того, совершенно это ошибочный может быть переход. вы потом понимаете, о чем я говорю. то есть эта схема, если вы думаете, что вы получите ускорение в настоящие задачи обучения с подкреплением методом ревард пропагейшн по ребрам, то ждите, что немножко ваши планы могут быть отложены на более длительный срок. Я просто обращаю ваше внимание, если вы вот сюда еще не добрались, то вы это увидите. Reward Propagation и вообще как бы Reward Assignment, то есть это вот у вас полученный ревард, как его раздать на ранее проведенное расстояние в эти самые состояния и управление решением, которое вы приняли по ходу дела. Это задача, которая, если бы она была решена, было бы очень легко и хорошо на всем жить. вы получили ревард, это точно знаете. за что вы его получили в прошлом, за какое правильное действие вы его... в этом и есть смысл моей работы, чтобы это сделать. да-да-да, но только вот не по ребрам графа, не по вероятности. ну хорошо, окей. 

S02 [01:34:38]  : мне кажется, что будет работать. 

S00 [01:34:40]  : это здорово. мы должны во что-то верить, иначе мы не сможем двигаться. Спасибо большое за доклад и за ответы. 

S03 [01:34:48]  : Сергей, я прокомментирую то, что вы сказали. Я согласен с тем, что вы говорите, но понижение размерности за счет выявления объектов и закономерности – это, мне кажется, одна из важных частей. И у меня есть гипотеза. гипотеза, что может быть вот та история, про которую Захар обмолвился, что можно координатам добавлять еще и время, то есть включать время, рассматривать атрибут времени, может быть он поможет как раз вот именно выявлять закономерности временные и выбирать как раз именно последовательности событий, и в качестве объекта рассматривать как последовательное событие. То есть, если у нас траектория движения мяча от удара, к примеру, ракеткой до попадания в потолок описывается одним объектом, то потом на каком-то следующем шаге мы можем собрать несколько кусочков траекторий мяча в объект более высокого уровня. И вот из иерархии вот таких вот кусочков, собираемых из кусочков, собираемых из кусочков, мы уже можем прийти к каким-то сценариям, которые в конечном итоге подкрепляются. нам проще будет, то есть у нас будет за счет выявления более крупных элементов, как в пространстве, так и во времени, у нас будет сокращаться число элементов от подкрепления до того действия, которому это подкрепление предназначено. 

S00 [01:36:28]  : Антон, это долгий разговор у нас будет тогда. Дело в том, что это вот все хорошо, когда задачи там а-ля там пространственные и когда корреляции по времени имеют смысл. А если ревард дается за некое нетривиальное действие посредине, например, там клеточку надо было открыть или кнопочку нажать, а все остальное, все, что там вокруг делалось, оно нерелевантно этому реварду, то тогда вот это вот переходы и сжатия за счет иерархии, они неэффективны, потому что у вас нет укрупненного понятия, которое вы могли бы подкрепить. у вас подкрепленным является некоторое определенное действие, неизвестно какое-то точечное локальное действие, например, аритметическое вычисление безошибочное в каком-то месте. и от того, что вокруг очень много других вычислений. Если вы можете укрупнять естественно семантические, тогда конечно и реварды можно укрупнять. А если задача такова, что точные действия важны, то тогда, соответственно, ну вот мы с вами говорили, помните, там были проблемы с играми, у которых нужно было сначала взять там птичку, потом нажать кнопочку, потом вернуться птичку положить, а только потом откроется дверка. Вот эти вот отдельные точечные действия, независимо от того, что было между ними сделано и как долго между ними там время проходило, вот только их и надо подкреплять. Вот тогда раздать реввард на всю траекторию не получится. ну вот это нужна нужна смысловая симметрическая структура. 

S02 [01:38:00]  : Я тут немного не соглашусь с тем, что вы сказали, потому что траектории в разных ситуациях, в разных партиях будут разные. Раздав реварды по одной траектории, потом по другой, мы же их будем суммировать. То есть там, где они не имеют никакого смысла. 

S00 [01:38:15]  : Там будет диффузия. Вот, Захар, как только вы перейдете от пяти кластеров примерно, скажем, ну так стартовое такое количество кластеров, которое имеет смысл, это какой-нибудь там, не знаю, ну 5000, например, кластеров. 5000-2600. да-да, вот как только вы перейдете вот таким масштабом, на которых что-нибудь интересное начнется, вы сразу увидите, что ваши реальности будут просто дефундировать. ведь, собственно, почему марковские модели не пошли. вот если бы, вы понимаете, были байосовые сети. они хорошо развивались и были марковские модели и так далее. почему это все заглохло? ровно потому что как только сеть начинает содержать хотя бы сотню или две сотни узлов, все вероятности становятся 0.51 против 0.49 мгновенно. они все дефундируют полностью, почти константно. нет механизмов контрастировать. поэтому байсовые сети остались на задачках типа 5 кластеров, 32 вершинки, Вот на таких задачках дождь пошел, выключили кран и так далее. Это 5, 10, 20, может быть, какие-то сущности. И дальше они не обскелились. Не потому что компьютеров не хватало, а потому что технология раздачи вероятности диффузным способом приводит к тому, что информация после нескольких ребер полностью потеряла свою селективность. 

S02 [01:39:30]  : Я с вами не соглашусь. 

S00 [01:39:33]  : Хорошо, тогда поэкспериментируйте. 

S02 [01:39:35]  : Нет, я не согласен. Вы говорите, что марковские цепи потеряли популярность. 

S00 [01:39:46]  : для селективных задач. они остались для тех задач, для которых марковские переходы остаются марковскими. 

S02 [01:39:51]  : да, но смотрите, у нас есть же например те же GPT и прочие. то есть это по сути тот же марковский процесс только с учетом 2048 состояний. 

S00 [01:40:02]  : да, вот они ничего не могут понять, потому что они корреляции посчитали на таком объеме, они размазались. 

S02 [01:40:09]  : да, понятно, что немного претензий, но они все же работают. 

S00 [01:40:17]  : работают в том смысле, что программа не ломается. в этом смысле да, я согласен. программа не падает, поэтому да, они работают. на этом можно поставить точку в отношении понятия работы. Давайте, это уже совсем далеко нас убедит, конечно. Мы сейчас все-таки доклад обсуждаем. Про доклад мы поговорили. Спасибо еще раз большое. 

S03 [01:40:36]  : Хорошо, да. Возвращаясь к докладу, есть еще вопрос Виктора Носко по графу вывода. Так как в примере эксперт задал для кейса медицинные фразы и их вероятности для той или иной болезни, то вопрос более общий – это откуда в промышленном масштабе брать эти данные для графа? Похоже, нужно применять те же трансформеры, чтобы в том числе решать задачу перевода термина «высокая температура» в вектор, в зависимости от контекста конкретной ситуации, которая тоже векторизована. И тогда, как я вижу, может быть построен проход по графу вывода по типу как NARS. 

S02 [01:41:23]  : насчет трансформера. да, я думал о том, чтобы использовать полноценное распознание речи, например, и какой-нибудь сберд, который на предложение дает один вектор, и то есть вначале речь преобразовать в набор Речь превратилась в слова, а слова в токены, а токены уже в реактор с реактором. Об этом я думаю. Но сразу скажу, что сейчас, конкретно то, что касается эксперимента с роботом, я хочу все-таки использовать эмбэггинги синхронета, не преобразовывая слова и не вычерняя семантику. Но семантику, да, можно вычернить, преобразовать в вектор. Вектор также преобразовать в эти состояния и сделать логический вывод. Но с другой стороны, если у нас задача уже жестко определена, у нас есть конкретные Эксперты, которые говорят, какие вероятности у каких переходов, лучше применить классификатор и уже не самому придумывать, не автоматически получать эти кластеры, а применить классификатор, так что у нас здесь и говорится об этом симптоме. значит, под объектом классифицированность, мы напрямую привяжем соседа или просто нервы носить, обучить, чтобы классификатор работал. И уже вот это используют в качестве состояния. Так должно даже лучше работать, если у нас есть человек-эксперт, который может обучить. Тут-то речь именно о том, что у нас нет эксперта, который бы наполнял базу. Если у нас есть эксперт, то, да, лучше обучить классификатор, 

S03 [01:43:28]  : Спасибо. Коллеги, у нас кончились вопросы. Тут вот есть один комментарий и мне хотелось бы, наверное, уже подвести итог и тоже прокомментировать. Вот в том числе тот комментарий, который сейчас дал Алекс Бур. Такие ситуации, изложенные Тереховым, как отложенный ревард с нажатием кнопки, решается единственным способом. Моделями понимания агент должен понимать, что он делает, должен иметь модель мира и так далее. вот ну то есть тут вот и сергей согласился написала что осталось малая научить агента понимать вот я тут соглашусь вот и в моем понимании как раз вот то что захар рассказывает это вот некоторые минимальный шаг первый шаг на пути к пониманию. Потому что мы работаем не с пикселами, мы пытаемся работать не с пикселами и не с гармониками, которые меряются определенными датчиками на определенных частотах, а пытаемся выявлять какие-то закономерности и работать с этими закономерностями. Я в своем докладе про свою версию игры с пинг-понгом показывал, что можно очень эффективно обучаться с очень малым ресурсоспотреблением, если мы действительно либо имеем фидбэк мгновенный, либо если мы можем четко определять интервалы, которые характеризуют, собственно, некоторое действие, которое приводит к реварду. То есть, если мы знаем, от какого момента начинается некоторая полезная с точки зрения реварда схема, то нам диффузия не страшна. Если любая успешная игра завершается некоторым подкреплением, то вся эта игра получает ревард без всякой диффузии. Это как раз знаменитый пример Конрада Лоренца, когда у него гусь значит, для того, чтобы попасть в комнату Конраду Лоренцу, значит, сперва долбанулся об лестницу, вот, а потом, значит, попал в гости в комнату Конраду Лоренцу. И потом, значит, каждый раз, когда Гусь к нему проходил в комнату, он, значит, сперва шел, значит, бился об лестницу, ровно потому, что это вот, так сказать, Весь маршрут был заполнен целиком, и шараханье об лестницу было элементом того пути. Это как бы негативный пример, но есть масса позитивных примеров этому феномену. Другое дело, что дальше уже возникает необходимость строить иерархию. И одним из способов построения таких иерархий, как раз возможно, есть многоуровневая сегментация этих объектов. Несколько семинаров назад Он рассказывал о том, как можно сегментировать последовательности символов на слова, совершенно unsupervised. Возможно, потом можно таким же образом структурировать последовательности слов на предложения, последовательности предложения на какие-то смыслы. Тут, на самом деле, очень много. всего можно интересного сделать. Но у меня самый большой интерес, на самом деле, в том, что, рассказывал Захар, вызвала эта история про фиксацию фиксированной кластера, и что с этим быть, и насколько семантика, натянутая на заданную сетку, заданную размерностью этих понятие в антологии и возможного количества отношений в антологии, насколько это вообще применимо к реальным задачам. То есть, получается, что нам нужно для каждой задачи каким-то образом подбирать количество вот этих вот самых кластеров, которые в данной антологии может быть. И если это количество не соответствует размерности задачи, у нас могут быть проблемы. Потому что в одном случае у нас в зависимости от каких-то случайных переменных, которые затешатся на входе или в процессе, правый глаз раздвоится, а левый расстроится. А в другом случае у нас правый расстроится, а левый раздвоится. А в третьем случае у нас один глаз будет целиком, а другой – из четырех половинок. будет не очень хорошо. Но в любом случае, было интересно. Я думаю, Захар, что будем наблюдать за вашей работой и посмотрим, чем все это закончится, какие будут апдейты. Коллеги, всем спасибо и до новых встреч. 

S00 [01:48:06]  : До свидания. Спасибо. До свидания. 

S03 [01:48:08]  : До свидания. Захар, спасибо. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
