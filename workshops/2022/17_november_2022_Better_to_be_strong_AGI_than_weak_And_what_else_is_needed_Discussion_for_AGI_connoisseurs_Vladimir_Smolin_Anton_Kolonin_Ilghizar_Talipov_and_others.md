## 17 ноября - Лучше быть сильным ИИ чем слабым! А чего еще надо? - Дискуссия для ценителей AGI - Владимир Смолин, Антон Колонин, Ильгизар Талипов и к ним присоединившиеся — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/YiKSz4gGn9Y/hqdefault.jpg)](https://youtu.be/YiKSz4gGn9Y)

Суммаризация семинара:

Семинар обсуждал тему создания искусственного интеллекта (AGI), а также проблемы понимания и рефлексии в процессе познания. Докладчики поделились своими исследованиями и подходами к разработке AGI и проблемам, связанным с герметическим процессом понимания. В завершение докладчик выразил надежду на разработку новой архитектуры познающего интеллекта.

Ключевые моменты семинара:

1. Обсуждение необходимых компонентов деятельности мозга человека для создания AGI:
   - Владимир представил список компонентов, включая декомпозицию и локализацию.
   - Александр и другие участники предложили дополнительные компоненты и подходы.

2. Проблемы понимания и рефлексии:
   - Эльгизар представил концепцию герметического круга понимания, где происходит сборка понимания через архитектуру герметической спирали.
   - Были затронуты вопросы о том, как происходит сам процесс понимания, и сложность самой рефлексии.

3. Текущее состояние исследований AGI:
   - Участники обсуждали проблемы, связанные с формализацией процесса понимания, и отмечали, что в области AGI многие опираются на формализацию из-за возможности строгой формализации.
   - Владимир поднял вопрос о том, какие параметры мы при этом игнорируем и какие не игнорируем.

4. Вопросы и комментарии:
   - В обсуждении участвовали и другие коллеги, которые высказали свои мысли и замечания на тему AGI и герметического круга понимания.
   - Были затронуты различные точки зрения, в том числе и философские аспекты создания искусственного интеллекта.

5. Предстоящие шаги и презентации:
   - Был анонсирован семинар, где Виктор Уртюхов представит свои практические результаты в проекте АГИФа.
   - Евгений Павловский обещал рассказать о квантовом вычислении в области искусственного интеллекта и искусственном интеллекте, основанном на квантовых вычислениях.

Семинар завершился обменом мнениями и идеями среди участников, а также выражением благодарности за участие и интерес к теме AGI.







S03 [00:00:00]  : Трансляция включена. У нас сегодня свободное относительное обсуждение. Спасибо Владимиру, что он предложил поговорить на тему того, что нам нужно для AGI, и, может быть, заодно по поводу тех терминов, которые нам для этого нужны. Ну и я хочу выплеснуть некоторый поток сознания, связанный, во-первых, с дискуссией, которая у меня с Николаем Михайловским была, которая здесь, я вижу, присоединился. Может быть, он тоже выступит в комментариях, в вопросах-ответах. А также сегодня я как раз готовился к Эль Джорни, и тоже некоторые мысли возникли. Соответственно, я бы хотел поспекулировать на тему того, что последние годы периодически появляются статьи типа Внимание – это все, что вам нужно. Attention is all you need. Или reinforcement is enough. То есть, подкрепления достаточно. Есть у нас внимание или есть у нас reinforcement, и будет нам счастье для построения сильного или общего искусственного интеллекта. развития этой темы. Давайте посмотрим, где у нас сейчас стоит Udeart в области искусственного интеллекта. Вот эта вот картинка, которая была в этом году нарисована искусственным интеллектом, как говорится. На самом деле, она была не нарисована искусственным интеллектом. На самом деле, художник генерировал большое количество промтов. в Foundation Model Mid-Journey, которая была обучена на параллельном корпусе текстов и изображений. Соответственно, он писал много различных текстов в виде промптов. Она ему генерила на каждый текст картинки. И он из нескольких сотен, как минимум сотен, я не помню число, картинок отобрал ту некоторую картинку. И к этой картинке… Это картинка… Либо он придумал к ней название, либо этот текст фигурировал в том промте, который он генерировал. Картинка назвалась «Космический оперный театр». 

S02 [00:02:09]  : Антон, мы не видим картинки. 

S03 [00:02:12]  : А, да. Вы не видите картинку, потому что я не зашарил экран. Да, слава богу, что это сказали вовремя. пока я не дошел до середины презентации. Вот сейчас вы мой экран видите, да? Сергей, видно, да? 

S02 [00:02:32]  : Да, весь экран. 

S03 [00:02:35]  : Итак, вот мы имеем картину космический оперный театр, которая сгенерирована таким замечательным методом, который называется Prompt Engineering. Промпт инжиниринг – это как бы новый элемент технологии машинного обучения в области генерации изображений и генерации текстов, когда мы, значит, работаем системой искусственного интеллекта примерно так же, как мы работаем с гуглом да то есть если нам нужно найти что-то диковинное допустим по не просто там найти все сорта пива вот а мы хотим найти там все сорта пива которые имеют яблочный оттенок там и продаются значит магазинах определенного бренда нам нужно все-таки как-то постараться специфицировать свой запрос и и не всегда с первого раза это удается. То есть мы сидим в поисковой строке Google, подбираем слова, меняем у них падежи, меняем слова местами и ждем, когда в результате подобранного запроса в поисковой выдаче появится что-то, на что мы кликнем, и это окажется то, что мы искали. Примерно так же работают с глубокими нейросетевыми моделями, комбинируя промпт инжиниринг и то, что в народе называется черепикинг. То есть мы подбираем промпты, получаем некоторые результаты, ну а потом еще на самом деле есть определенные усилия, которые нужно сделать над пользователем. Убедить себя в том, что этот результат имеет какой-то смысл. Например, картинки, которую мы сейчас видим, к ней можно относиться как к космическому оперному театру, так и к вертикально ориентированным пятнам на фоне идеально круглой дыры из пещеры. Потому что если приглядеться внимательно, ничего похожего на людей, В этих вертикально ориентированных пятнах нету, кроме складок платьев. Ну и чем-то похожим, на самом деле, еще до изобретения глубоких нейронных сетей, с точки зрения как бы методологии, технологического процесса, занимались представительницы и представители древнейшей профессии, которые назывались гадалки и гадатели. Когда, допустим, нужно гадать, например, на кофейной гуще, мы много раз встряхиваем чашечку с кофе, Вот до тех пор, пока узоры на донышке, значит, кружки или там кофейные гущи и выплескательное блюдечко не принесут, не примут те формы, которые, в общем, мы готовы будем сообщить нашему клиенту, чтобы он нам заплатил деньги за процесс гадания. Соответственно, вот к данной картинке можно относиться в зависимости от того, какое у нас воображение, либо как грибы на берегу озера, либо как горящее нефтехранилище. Возможно, кто-то еще что-нибудь придумает. Или там город над обрывом. Соответственно, all you need – это не только проб инжиниринг, но еще и черри пикинг так называемый и известная доля воображения. Перейдя, собственно… Ближе к проблемам, которые, как мне кажется, предстоит решить наряду с тем, что мы, на самом деле, говоря о том, что система искусственного интеллекта рисует за людей, мы на самом деле говорим о некоторых системах искусственного интеллекта, которые в некотором человеком машинном комплексе просто позволяют людям генерировать большое число абстрактных соображений. А, кстати, насчет абстрактных изображений очень похожий процесс описывал Кончаловский. своей замечательной лекции про импрессионизм. Где-то в середине-начале этого года была прекрасная лекция Кончаловского, где он подробно на канале «Культура» разбирает историю, все детали импрессионизма. И он подробно на конкретных кейсах разбирает, что Не импрессионизм, а абстрактная постмодернистская живопись – это в известной степени феномен пиара, феномен рекламы, феномен бизнеса. с черным квадратом и с другими известными полотнами. В частности, он рассказывал, как бурлюк с каким-то еще товарищем готовились к выставке, которой им нужно было подготовиться за ночь. Они просто взяли большое число холстов, плескали на них краской. А потом под утро уже совсем обалдевшие просто сидели и придумывали тому что получилось название. Ну вот так же примерно мы делаем и сейчас. Перепрыгивая к одной из основных проблем, которая, как мне видится, уже с точки зрения прикладных систем, это пресловутая проблема оверфитинга, с одной стороны. Когда мы используем глубоко нейросетевую, а просто линейно-регрессионную модель, Кстати, как прозвучало на конференции DataFest Сибири, которая была около месяца назад, на ней выступал коллега из Huawei. Он делал хороший доклад, рассказывая про современность автоарт в машинном обучении и говорил такие простые вещи, которые мне были близки. Что с одной стороны, неважно какой у вас алгоритм, главное, чтобы у вас был хороший тренировочный набор. Мы говорим про прикладные примеры, то есть мы не говорим про какое-то искусство, где нужно картинки подгонять. или где нужно удивить восторженного некомпетентного пользователя, а мы говорим про совершенно прикладные задачи, связанные с распознаванием аудио, речи, номерных автомобильных знаков, размеров рыбы, отделения мух от котлета или пластика от металла. В этих задачах качество определяется в первую очередь невыбором алгоритма, качеством, объемом данных и качеством их разметки с одной стороны, а с другой стороны во многих случаях работают, лучше всего работают самые простейшие алгоритмы, грубо говоря, типа линейной регрессии. При этом важной, типичной является проблема пресловутого оверфитинга, когда мы очень хорошо аппроксимируем тот датасет, который у нас есть, но за рамках этого датасета мы получаем полную чушь. Вот как раз пример того, как это увидел, с моей точки зрения, Станислав Лем. Видимо, это уже было более полувека назад. Я не помню, как это описывал Станислав Лем. На самом деле, вот тот кадр, который мы видим, это кадр из интерпретации Тарковского Станислава Лема. По-моему, эпизода этого у Лема нет. А Тарковский приводит вот такой вот эпизод, если кто не смотрел, когда у главного героя, запертого на межпланетной станции, Океан Солярис, считывая его энцефалограмму или каким-то другим образом, получая содержимое мозга и мысли главного героя, этот океан по его мыслям восстанавливает ему то, о чем он думает, и в данном случае восстанавливает этой космической станции образ любимой девушки. главного героя. Вот он восстанавливает образ этой девушки вплоть до мельчайших подробностей того платья, которое на ней одето, включая шнуровку на спине этого платья. Но шнуровка платья не предусматривает, собственно, разрез, который этой шнуровкой скрывается. И когда главный герой пытается помочь девушке снять платье, выясняется, что платье приходится просто разрезать ножом. Вот как раз с одной стороны это пример оверфитинга, а с другой стороны, что мы, когда учим сколь угодно сложной нейросетью, сколь угодно большим числом слоев, сколь угодно точной аппроксимацией, мы на самом деле учим просто подгоняем ее под некоторые данные, не понимая вообще той структуры и тех глубинных, так сказать, функциональных связей того мира или того объекта, который мы пытаемся аппроксимировать. Вот пример, который мы с Витяевым приводим, периодически насуждая на эту тему, что мы, к примеру, можем там натренировать не рассеять, а спознавать китов и слонов. А когда случайно попадется слон, купающийся в море, он будет распознан как кит. Потому что что-то большое серое на синем фоне. А, соответственно, если вдруг кит окажется выброшенный волной на зеленую траву или на желтый песок, он будет интерпретирован как слон, потому что тоже что-то большое серое на желтом или зеленом. Соответственно, мы что-то распознаем, но мы не понимаем, что это такое. Ну и теперь я перейду, собственно, к некоторым примерам, к некоторой структуре. И перечислю принципы, которые с моей точки зрения и с точки зрения некоторых столпов современных в области искусственного интеллекта являются важными, если не критическими для дальнейшего развития данного направления. Первое – это то, что называется… Я, может быть, не буду соблюдать терминологию тех авторов, статьи которых тут приведены справа. Буду пересказывать это своими словами. В общем, cost efficiency – это про то, что мы должны строить модели, которые эффективны с точки зрения затрат. И даже усилие это с точки зрения энергозатрат. Причем это тезис, который впервые сформулировал Пиванг, с которым мы вместе работали с Беном Герцелем уже 24 года назад. И это как раз определение Пиванга входит в формулу канонического, с моей точки зрения, определения общего искусственного интеллекта – это способность достигать сложных целей в сложных средах, используя ограниченные ресурсы. Так вот, использование ограниченных ресурсов – это вот как раз то, про что теперь пишет товарищ Ликун, притом не слываясь на работы Пи Ванга 25-летней давности. И это первое. то, что тут у меня обозначено как структурное обучение. То есть, мы должны учиться структурам, мы должны учиться объектам, мы должны учиться взаимоотношениям между частями этих объектов. Их, не только их, так сказать, абстрактную, ну, как бы, хиерархию их классов, но и их структурным иерархиям того, из чего они состоят. Естественно, кто глубоко занимается глубокими нейронными сетями, сразу же скажет, что о нейронных сетях все это есть. То есть, у нас на нижнем уровне у нас шерстинки, на первом слое у нас шерстинки, на втором слое у нас части тела, на третьем части у нас уже целиком коты или собаки. Но на самом деле слоев уже много. Проблема только в том, что, во-первых, нейронная сеть не знает, на каком уровне у нее шерстинки, на каком у нее лапы. А потом еще у нее может оказаться, что у нее на одном слое лежат кошачьи лапы и собачья шерсть. То есть у нас те структуры, которые в неявном виде содержатся в структуре глубокой нейросетевой модели, они, с одной стороны, хаотичны, с другой стороны, они, с моей точки зрения, не отражают реальную картину мира. И, тем более, они имеют байос к тем датасетам, на которых они учились. То есть, если это не так, естественно, я буду рад, если кто-нибудь меня опровергнет. Помнится, когда Юрий Бабуров делал доклад, значит, по поводу интерпретируемости глубоких нейросетевых моделей, я думал, он что-нибудь про это расскажет, но ничего подобного он про это не рассказал, чем оставил у меня глубокое разочарование. Вот. Хотя я знаю, что в этом направлении люди пытаются работать, вытаскивать из глубоких нейросетевых моделей и структурами информации. Но теперь фишка в том заключается… И вот про это, на самом деле, в том числе пишет Лекур в своей вот этой, я бы сказал, манифестирующей работе. Там, по-моему, у него около полусотни страниц на эту тему пишется. Причем эти вот структуры, они на самом деле могут быть не только пространственные, они могут быть и временные. То есть мы можем выявлять на самом деле некоторые сегменты из некоторых исторических последовательностей, выявлять некоторые сценарии, выявлять некоторые эпизоды. и увязывать их в сценарии эпизоды более высокого уровня. Пару лет назад я рассказывал про подобное описание динамики временных процессов. Александр Балдачев тоже свою событийную антологию с похожими, в принципе, развивал. Ну, вот сейчас про это начинают говорить великие люди. И, в частности, у, опять-таки, знаменитого Юргена Шметхова, Хубера, который изобретатель LSTM, в этом году вышла работа про формирование временных абстракций при обучении с подкреплением. И про это тоже пишет Лекун, что нам нужно, на самом деле, планирование осуществлять в рамках иерархических структур, где предметом иерархии являются как структура объектов, так и событийная структура, разворачивающаяся во времени. Ну и последняя идея, которая уже совсем-совсем новая, и она мелькала активно только в этом году, хотя товарищ Фристон про нее начал говорить уже давно, А товарищ Пригожин про неё писал ещё раньше, правда, не в связи с искусственным интеллектом, а в связи с физикой и эволюцией всего на свете. Так вот, в этом году опять-таки вышла свежая книжка Карла Фристона, где он рассматривает основную функцию мозга, в том числе как задачу снижения неопределённости. Ну вот дальше мы сейчас про это поговорим. Тут может быть как раз очень интересная дискуссия. Но сейчас это уже подхвачено. Вот буквально вчера был семинар в Сберии, где как раз использование принципов снижения неопределенности в рамках Построение и использование глубоких нейросетевых моделей рассказывала группа из AIRI Сбера. Вот, кстати, если кто-то был на этом семинаре, может прокомментирует или перескажет. Так, я стараюсь двигаться вперед, потому что времени много. Ну и последний принцип, про который ни Лекун, ни Фристон не писал, но это фишка, на которую, мне кажется, очень важно заостряться, что сильный искусственный интеллект должен быть интерпретируемым. И он должен быть интерпретируемым не только потому, что этого требует современное законодательство. Он должен быть интерпретируемым просто потому, что в обозримой перспективе не интерпретируемый сильный искусственный интеллект, просто его нельзя выпускать к людям. Потому что если мы не знаем, что он будет делать с дроном боевым или с атомной электростанцией в непредсказуемых условиях, мы просто не можем ему давать управление. Поэтому искусственный интеллект, который применяется для чего-нибудь, кроме как в индустрии развлечений, мы должны иметь возможность, во-первых, верифицировать качество тех моделей, которые он сформировал в процессе обучения. Вот. Мы должны знать, чему он вообще научился. Действительно ли то, что он будет распознавать, как кошек, имеет там шерсть и лапы. Вот. А не имеет там колес и, не знаю. Ну и кроме этого, конечно же, он должен в случае необходимости объяснять свои решения, чтобы человек мог верифицировать правильность этого решения. Допустим, если мы говорим, что отрезать человеку правую ногу, то нужно хотя бы обосновать, почему именно правую, а не левую. Кстати, про это вчера говорили юристы на конференции по большим данным. Двигаемся дальше. По поводу энергозатратности. Почему важна энергозатратность и эффективность по отношению к этим затратам? Стандартная функция. Чем больше сложность системы, тем выше затраты на то, чтобы с ней что-нибудь делать. Например, мы знаем, что современные процессы конструирования самолетов сейчас втыкаются в то, что сложность разработки какого-нибудь самолета типа Boeing Она такова, что возникают большие проблемы с организацией самого процесса разработки. Это как бы из обычной индустрии. Не говоря уже о том, что современные глубокие нейросетевые модели для обработки текстов требуют таких ресурсов, которыми обычные компании не обладают. Теперь можно привести пример на эту тему. К примеру, если мы пытаемся оперировать с мячиком как с некоторой точкой. Мячик – это просто некоторая точка, которая перемещается по некоторой траектории, связанной, допустим, с действием закона гравитации. то у нас сложность очень маленькая. Простой это просто шарик. Соответственно, обсчитывать законы поведения этого шарика очень легко. Если у нас шарик начинает появлять какие-то характеристики, у него появляется какая-то расцветка, становится чуть-чуть сложнее. Возникает 2-3 кольца, ориентация этих колец. То есть, обработка усложняется. А если мы этот шарик уже представляем как некоторое облако пикселов, да еще и с большим разрешением, да еще и с большой цветовой глубиной, то у нас происходит экспоненциальный рост сложности и соответствующих вычислительных затрат. И это, собственно, как раз Мы демонстрировали в ходе эксперимента, про который я уже на этом семинаре рассказывал, поэтому я сейчас кратко повторю суть этого эксперимента. Мы учили нашу систему Игре в пинг-понг. Вот, где задача была в том, что нужно с нуля обучиться отбивать ракеткой шарик. То есть, вот у нас ракетка, вот у нас шарик. Соответственно, если шарик ударяется о пол, то нам делается плохо. А если мы шарик отбиваем, и он потом бьется в потолок, нам делается хорошо. Соответственно, нам на вход поступают некоторым образом информация о координатах шарика, координатах ракетки, о том, хорошо ли нам или плохо в данный момент. И, соответственно, у нас за кожаной эволюцией задача сделать так, чтобы нам всегда было хорошо. Ну и мы пытаемся там что-то дергаться до тех пор, пока дергание не приводит к тому, что мы начнем отбивать шарик. Мы запоминаем эти моменты, когда мы удачно отбиваем шарик. Классический Reinforcement Learning по постановке. Ну и с правой стороны видно, как мы успешно эту задачу решаем. Соответственно, если мы берем поле 2 пиксела на 6 пикселов, нам нужно 50 эпох, чтобы научиться всегда на каждой эпохе оказываться счастливыми. Вот, соответственно, красное – это когда нам не повезло, а зеленое – это когда мы добились счастья. На нижней картинке, опять-таки, нам на поле 6х8 нужно уже 1000 эпох. Вот, то есть, видно уже, опять-таки, можно наблюдать за экспоненциальной сложностью. экспоненциальными затратами по сравнению со сложностью задачи. Но, тем не менее, видно, что тоже в какой-то момент у нас красное исчезает. Мы начинаем получать только положительное подкрепление. То есть, мы обучаемся этой задаче в конечном итоге. Но обучаться этой задаче мы можем двумя способами. То есть, двух операционных пространств. То есть, физическая модель у нас одна. Но в одном случае мы описываем эту физическую модель на уровне объектов, то есть у нас есть объект-шарик, у которого есть координаты x и y, у нас есть ракетка, у которой координата x. И поток входных данных у нас описывается чисто вот этими ball x, ball y, rocket x, ну и их наличие или отсутствие счастья, либо несчастья. И в этой ситуации мы можем обучиться. и успешно. А в другой постановке у нас то же самое описывается в другом операционном пространстве, на уровне пикселов. В этом операционном пространстве та же самая физическая модель, тот же самый физический мир описывается без понятия мяч и ракетка. Он описывается просто некоторой сеткой пикселов, где одни пикселы отвечают текущему положению мяча, а другие пикселы отвечают текущему положению ракетки. Соответственно, пикселы могут там загораться и гаснуть. Соответственно, ракетки и мечи двигаются. И в этой ситуации мы, опять-таки, можем научиться. При этом мы можем обнаружить, что при равных размерах игровых полей, вот здесь вот идут 2х4, 4х6, 8х10 и так далее, мы обучаемся Здесь все колонки соответствуют равному числу эпох. По горизонтали идут различные алгоритмы. цифры соответствуют проценту успешных отражений ракетки при одинаковом числе эпох. И вот мы видим, что в среднем мы при одном и том же размере игрового поля по вертикали разными алгоритмами зарабатываем одно и то же количество очков. При том, что верхняя половинка слайда соответствует тому, что мы учимся в пространстве объектов, а нижняя половина слайда соответствует тому, что мы учимся в пространстве пикселов. То есть и там, и там мы обучаемся игре за равное количество эпох. Проблема в чем? Проблема в том, что за энергозатраты на обсчет и реализацию этих алгоритмов в пиксельном пространстве, они просто несоразмеримы. Если, работая с объектами, мы можем учиться играть в реальном времени физического мира, то, например, работая с пикселами на моем ноутбуке, мы обучиться этому в режиме реального времени не можем. Ну и да, и какой мы делаем из этого вывод, что для того, чтобы решать эту задачу так, как очевидно ее, опять-таки гипотетически, то есть тут мы переходим в область гипотез, как эту задачу решает человек, человек работает, значит, с одной стороны работает на начальном этапе, он обучается превращать облако пикселов в ракетки и мечи, На следующем этапе он обучается превращать некоторые последовательности отражений и падений, как некоторые законченные элементы. Допустим, мяч, падающий на землю, это одна история. Мяч, летящий в потолок, это другая история. Мяч, меняющий свою траекторию в точке отражения, это другая история. Мы формируем некоторые пространственно-временные абстракции в терминах товарища Шмидтхубера, отсылаясь той работе, про которую он говорил, и уже на уровне вот этих макроструктур, макрообъектов. И вот этих временных абстракций мы уже собственно осуществляем обучение с подкреплением, где превращение объектов в пикселов, оно осуществляется как бы в одном месте, а собственно вот обучение операции с этими объектами, то есть не превращение пикселов в объекты на одном уровне, а операция с этими объектами на другом уровне. И тем самым мы повышаем эффективность. Теперь, значит, перепрыгиваю на минимизацию неопределенности. Значит, что здесь имеется в виду? Значит, тоже здесь эта история спорная, история новая, но вот как я интерпретирую заявление товарища Фристона, как бы со своей колокольни, это то, что нам не столь важно какова вероятность той или иной опции, которую нам предлагает система, потому что в конечном итоге из нескольких опций мы можем выбрать все равно не ту. Например, система, которая генерирует, как работают современные нейросетевые модели. Они генерируют большое число различных вариантов в ответ на промпт. А дальше уже человек либо сам, либо с помощью какой-то еще дополнительной системы, поверь, должен отбирать множество этих вариантов. И соответственно вероятность, и эти варианты, предложенные системой в соответствии с вероятностной моделью, из них на самом деле может быть не очень много адекватных вариантов. Но человеку нужно выполнять работу по отбору этих вариантов. Так вот, качество системы можно рассматривать как минимум того числа вариантов, из которых система должна выбирать. Потому что, грубо говоря, если мы говорим о системе, как нам проехать в центр Москвы Из Новосибирска, вот, если мне система предложит пять тысяч маршрутов и скажет, пожалуйста, выбирай в навигаторе, да, наверное, это не очень удобно. А если система мне предложит один-единственный маршрут, и даже если она там где-нибудь в Казани или там в Свердловске, она его по какой-то причине поменяет, меня это, в общем, устроит. И вот как раз здесь два примера. С левой стороны мы набираем два слова. И Google нам сразу говорит, что можно выбрать только You, потому что других вариантов нет. Это вот то, что мне как пользователю нужно. А когда я набираю How Many, она мне предлагает сразу кучу вариантов. которые на самом деле меня раздражают. Я не хочу выбирать, потому что, к примеру, я знаю, что я сейчас нахожусь в контексте географии, и у меня тогда вариантов становится всего только два. How many states and how many countries. Соответственно, качество системы должно определяться с этой точки зрения минимальным числом переходов или выбор опций, которые на каждом шаге должно выбрать, чтобы их уже дальше выбирать с учетом какой-то дополнительной информации. Теперь переходя к тому эксперименту, который мы делали, и результаты, которые я сейчас дальше расскажу под занавес, они будут в декабре представлены на конференции МНЛП-22 в Абудабе. Я ее, кстати, на этом семинаре рассказывал, поэтому очень коротко. Мы пытались делать токенизацию без учителя самыми различными способами, понять, каким образом мы, не имея никакого знания изначального о том, какие символы что означают, какие символы являются гласными, согласными, какие знаками припинания, где у нас пробелы, то есть мы не знаем, что пробел там и буква О это принципиально разные вещи. Для нас это все там какие-то ASCII коды или UTF-коды. Вот мы пытаемся построить какую-то модель, которая разобьет токены на слова. И мы взяли в качестве основы несколько работ, и в тех работах, которые мы нашли, использовались такие метрики, как взаимная информация, условная вероятность, которая как раз используется в подавляющем большинстве НЛП-систем, и вот эта вот пресловутая свобода перехода, которая вот как-то удивительно напомнила то, про что говорит товарищ Фристон. Значит, на примере, который мы здесь видим, это как раз иллюстрируется. То есть, если вот у нас, к примеру, есть слово «how» в модели гугла, да, вот циферки здесь, кстати, соответствуют тому, что вы увидите в гугле, если будете пытаться поиск по этим словам делать. Вот мы можем прикинуть, исходя из частот того, значит, сколько у нас есть «to» после «how», и сколько у нас есть «do» после «how», и сколько у нас есть «are» после «are». Мы можем посчитать условные вероятности появления ту, ду, мени, лон, ки, ар после хау, исходя из этих частот. Если же мы после хау наберем мени или ар, то опять-таки после мени, мы видим, есть четыре варианта. При этом эти четыре варианта имеют такие частоты, соответственно, тоже можем посчитать условные вероятности. А вот после ар, Мало того, что у нас условная вероятность равна единице, у нас еще и свобода перехода равняется единичке, потому что после how и are есть только you. И дальше что мы сделали? Мы взяли вот эти условные вероятности для n грамм с различным числом n, униграмм, биграмм, триграмм и до семи грамм. И мы взяли как раз эти самые свободы перехода от н-граммы к н-грамму, от н-граммы к символу и попытались поделать токенизацию на различных текстах на русском, на английском и китайском. Вот что мы получили, что если мы будем работать на основе условных вероятностей, то какие бы гиперпараметры мы не подбирали, во-первых, мы будем, конечно же, безусловно, разделять все слова по пробелам то есть пробелами все хорошо вот между том и сет пробел между сет и джим пробел между райд запятая n пробел то есть пробел и прекрасно находится но вот кавычки не отделяются от слов запятые от слов не отделяются вот и более того кое-где у нас даже вот например вот вот первый вот здесь вот буковка t от буковки у оторвалась И тут тоже, когда буковка Т от буковки О оторвалась. То есть, у нас получается куча фальс-негативсов и есть фальс-позитивсы. А вот если мы перейдем на использование пресловутой свободы перехода, то мы обнаруживаем, что у нас и пробелы хорошо отделяются, и все кавычки и знаки припинания отрываются. Причем это происходит на униграммах, на энграммах и триграммах это получается несколько хуже. Итог данного исследования. Мы оценивали метрики двумя способами. Во-первых, мы считали в меру токенизации. Значит, соответственно, для английского мы получили 0.99. Для русского у нас получилась вообще 1.0, то есть идеальная безошибочная токенизация получилась. Для китайского получилась несколько хуже. Это вот просто сама токенизация. Но кроме ошибок токенизации мы еще пытались оценивать точность оценки оценки качества выявляемого словаря. То есть, грубо говоря, мы берем неразмеченный корпус, пытаемся с помощью токенизации выделить все слова, которые в нем есть, и смотрим. А эти слова есть вообще в словаре данного русского, английского или китайского языка? Или это какие-то обрывки и обрезки бессмысленные нагенерировались? И видим, что для английского практически все, почти все слова есть в словаре 0.99. Для русского вообще все идеально, все слова оказались правильными русскими словами. Ну, в общем, и для китайского хорошо. То есть, несмотря на то, что мы токенизировали не совсем так, как справочный китайский токенизатор, в общем, почти все слова, которые мы выделили, оказались правильными. то есть мы не придумали никаких новых частей речи и слов на китайском языке ну и подводя итог вот поскольку вот та модель которую вот я здесь описал ее можно характеризовать как графовая модель да то есть все вот эти вот свободы перехода и все значит условные вероятности даже мы их используем они описываются в пространстве графовой модели языка где у нас все возможные комбинации, все возможные переходы, естественно, с возможностью отсечения маловероятных, они описаны в виде графового представления, то мы можем строить пресловутые интерпретируемые модели. Вот здесь пример как раз того, как можно строить нейросимульную интеграцию. Используя, с одной стороны, нейросетевые представления, то есть мы можем учить нейросеть. Мы можем строить графовую модель знаний, оперируя единицами знаний как элементами либо некоторой онтологии, либо некоторыми конъюнктивными и дезюнктивными введениями элементов в этой онтологии. Соответственно, модель представления знаний с левой стороны – это то, что у Канемана называется медленная система, которая быстро учится, но медленно думает. То, что с правой стороны – это быстрая система, которая быстро думает, но медленно учится. Много данных, нужно длинное обучение, но потом быстро реагирует. А потом мы можем их объединять таким образом, что неявное знание полученной нейросетевой модели мы можем как-то, пока непонятно точно как, извлекать и формировать в интерпретируемом представлении, а также мы можем некоторую модель, интерпретируемую либо выученную, либо каким-то образом закодированную экспертом, загружать в нейросетевую модель для того, чтобы уже использовать на практике. Спасибо. И я должен очень сильно извиниться перед Владимиром, что я вылетел за регламент. Но я думаю, что время у нас еще есть. Коллеги, если вопросы до понимания есть принципиальные, давайте их зададим. Проформулировку Борису я ответил. Главное, критерий практики полностью согласен. Так, Владимир Радкевич. Интерпретируемость не избавляет AGI от возможности обмануть нас за счет этой интерпретации. Во-вторых, может генерировать слишком большой объем интерпретации, что не позволяет проверять ее человеком в реальном времени. Да. Значит, смотрите. Насчет интерпретируемости. Значит, вот так называемый explainable AI, который появился достаточно давно, примерно одинаково, одновременно с возникновением законодательных требований к объяснимости системы искусственного интеллекта, он, собственно, на практике так и работает. То есть, explainable AI – это про то, что когда от нас законодательство требует объяснить решения, принятые из системы искусственного мы берем и каким-то образом объясняем то, что мы получили, причем объяснение может не обязательно быть связано с моделью, то есть вот на одной из конференций я вообще слышал, видел объяснение explainable AI, что есть система нейросетевая, которая принимает решения, а рядом стоит система простенькая, тупенькая, значит, на основе case-based reasoning system, Которая, если человеку требуется объяснение, она ему генерирует объяснение. Но модели там разные. Мы просто выполняем формально требования закона, что должно быть объяснено. А связано ли объяснение с той моделью, на основе которой решение принято, это в законодательстве не прописано. Поэтому тут действительно можно обмануть как угодно. насчет генерировать слишком большой информации. Вот тоже пример приведу, который мы недавно разбирали с коллегами, обсуждая вопрос построения цифровых двойников. Вот смотрите, мы, например, строим систему управления Атомная электростанция, да, все время привожу этот пример. Мы не можем доверить управление атомной электростанцией и искусственному интеллекту, если мы не понимаем, как он моделирует поведение атомной электростанции. Но вот у коллег в Питере, причем это достаточно старая история, по-моему, года 4 или 5 назад я видел их доклады, Ребята построили, как они считают, оригинальную систему глубокого обучения, где в ядрах этой нейронной сети оказываются коэффициенты дифференциальных уравнений. То есть они в результате обучения глубокой нейросетевой модели получают систему дифференциальных уравнений, которую они могут уже принести физику. Они эту систему изначально писали для какого-то там Такамака под Питером в каком-то институте. Вот они приносят эту систему физикам, и физики смотрят на это дифференциальное уравнение и верифицируют. Естественно, если дифференциальных уравнений там 20-30 физики их могут интерпретировать, верифицировать. Если их 5000, то, наверное, нужно слишком много физиков и очень большой ресурс времени нужен для того, чтобы им это дело согласовать. Ну и вот есть гипотеза, что в этих ситуациях вместо того, чтобы применять искусственный интеллект, мы его просто не будем применять. То есть, вот, например, Насколько я знаю, в управлении объектами критической инфраструктуры именно по этой причине как раз искусственный интеллект и не применяется, потому что невозможно объяснить то, что система может придумать. Так, интерпретируемости нет и его сложных вычислений на обычных компьютерах. Да, конечно. Это теория сложности. Да. Хорошо. Дальше уже комментарии. Хорошо. Владимир, пожалуйста. 

S02 [00:40:19]  : Антон, можно одну минутку, пока Владимир включит микрофон? В зависимости от аудитории, я могу тебе еще добавить в коллекцию примеров. Тебе вот такой хороший пример. Помнишь мраморный телефон Старика Хатабыча? то есть он там создал, ну все, даже не буду дальше распространять. В принципе, ты можешь слайдик добавить к своей коллекции. Спасибо тебе большое. 

S03 [00:40:42]  : Спасибо. Да, и, Александр, пожалуйста, расскажите, как на кофе гадают на самом деле. Мне очень интересно. 

S01 [00:40:47]  : Да, Антон, добрый день всем. Я обратил внимание, что, читая вашу статью, что нужно вам это сказать. На кофе гадают, не подбирая ничего, просто переворачивают. Человек переворачивает кружку на блюдце, все стекает, гадалка берет и смотрит. Там нет вариативности никакой. Это пример нужно убрать. Хорошо, спасибо. А по поводу многих пунктов, которые вы сказали, я думаю, что если там где-то к концу будет время про интерпретируемость и про энергию и про вероятность, я хотел бы так минут 10 занять время. 

S03 [00:41:22]  : Хорошо, записали. Спасибо. Владимир, вам слово. 

S00 [00:41:27]  : Спасибо. извинения, как бы не понимаю, почему ко мне, а не ко всем должен быть направлен. А насчет меня вопрос, сколько в результате у меня времени осталось? 

S03 [00:41:39]  : Ну, как договаривались. 

S00 [00:41:42]  : Как и у вас. 

S03 [00:41:45]  : Давайте попробуем. 

S00 [00:41:46]  : Ну, смотрите, значит, нам нужно... Я, конечно, буду пробовать. Я что-то не на то нажал, прошу прощения. Сейчас я еще раз запущу. вот но пока на что-то открывается хотя достаточно открылся вот значит общая значит проинтерпретировать меня как бы особенно сильно задевает что Люди, которые совсем не понимают в искусственном интеллекте, они считают, что им это не надо, они принимают законы. Потому что зачем им понимать? Они в законах разбираются. Если их законы применить к людям, то все конструкторы любых систем, которые немножко сложнее велосипеда, Их всех нужно отстранить от руководства, потому что и на атомных станциях бывают аварии, и в интернет там что-то не работает, и компьютеры у нас зависают. Понимаете, неинтерпретируемые их действия, в принципе. То есть сложная система, мы не можем ее исследовать всесторонне, просто потому что она сложная. И, как бы сказать, требовать интерпретабельность, если мы начинаем от сильного искусственного интеллекта, а то давайте к остальным системам тоже применим. Машины там ломаются и самолеты падают. Любая сложная система подвержена авариям. С этим бороться пока не научились. И, соответственно, я понимаю, что хочется на чем-нибудь отнести душу, например, на искусственном интеллекте. Но все остальные сложные системы, они точно так же неинтерпретируемо себя ведут. Мы думаем, что они будут работать хорошо, вот, а как говорил наш Борис там, что у нас всё-таки получается, как всегда. И пока никаких идей, как от этого избавиться, ну, в общем-то, нет. Вот. Теперь, собственно, про то, о чём я хотел сказать, чего нам, собственно, надо для построения сильного искусственного интеллекта. Ну, собственно, план у меня большой, но я, наверное, только первую половину изложу, вторую, видимо, в 20 минут у меня может не уложиться. Самое главное, что нам нужно для построения сильного искусственного интеллекта, это прекратить обсуждать, что такое разум, как понимать понимание, что такое сознание. в чём смысл эмоций, потому что это разговоры ни о чём. То есть каждый, кто начинает про них рассказывать, он-то точно знает, что это такое, и у него самое лучшее понимание этого вопроса. Но у других почему-то другое понимание, и с этим надо что-то делать. А делать на этой точке зрения надо то, что не использовать эти понятия при определении интеллекта вообще, и тем более стране сильно достаточно интеллекта. Вот, то есть, конечно, значит, какие-то, также как вот мы построили, допустим, вычислительную машину, у нее там есть память. Ну, значит, она, конечно, не так устроена, как наш мозг, но выполняет аналогичную функцию, вот, и можно говорить, что вот она, как бы, выполняет аналогичную функцию, делает память. И, соответственно, когда мы будем строить интеллект или сильный искусственный интеллект, который решает какие-то задачи, конечно, там будут какие-то элементы, которые можно соотносить с сознанием, с эмоциями, с памятью и со многим другим. Но исходить из того, что вот там должна быть обязательно вот это, не зная зачем, или мне кажется, что вот поэтому, то это, собственно, на мой взгляд, непродуктивно. Вот. Ну и, собственно, пример самый такой простой и наглядный, который приводится, это вот, собственно, то, значит, что предлагает Тагмарк, как определять там сильный искусственный интеллект. Это, значит, как бы следующий этап развития, значит, процесса самоорганизации, и, собственно, была когда-то просто жизнь, потом появилась, значит, как он говорит, жизнь 2.0, то есть культурная жизнь, и, соответственно, Сейчас все идет к тому, что будет технологическая жизнь, то есть мы создадим сильный искусственный интеллект, который сможет сам себя совершенствовать, и, соответственно, это и есть, собственно, определение сильного искусственного интеллекта по тегмарку. Ну, то есть не мы пока не умеем, то есть вы, кстати, говорите утверждение о том, что человек может решать любую задачу, оно несостоятельно. Почему? Потому что сильный искусственный интеллект мы пока не построили, собственно, как бы сказать, за пределы солнечной системы как бы не очень знаем Когда сможем выйти или хотя бы простую управляемую термоядерную реакцию произвести, тоже не получается. Много чего на самом деле еще не умеем по мелочам. Сильный искусственный интеллект никогда не решит все задачи. Но если он научится сам себя совершенствовать и куда-то будет развиваться, то это уже будет некоторый критерий. Для такого типа определений никаких сознание, разума. Ну, в общем-то, не надо. Вот. Ну, значит, мой взгляд на процесс эволюции и цивилизации немножко другой. То есть, в принципе, это все процессы самоорганизации. Вот. То есть, есть там и в неживой природе какая-то самоорганизация. Есть, соответственно, и в растениях и в животных. Тут, кстати, Тегмарка можно по-разному понимать. То есть, вот эта культурная фаза жизни начинается с человека или уже животных. Я всё-таки больше склонен относиться к животным, но поскольку с Тегмарком я лично не встречался и не обсуждал этот вопрос, может быть, в его понимании всё-таки с человека начинается эта культурная революция, потому что, как сказать, культура у животных тоже, наверное, какая-то есть, но больше принято это всё-таки к человеку относиться. Вот. Ну и, собственно, сейчас мы живем в эпоху революции искусственного интеллекта. И, по моим прогнозам, где-то от трех до десяти лет осталось до строения сильного искусственного интеллекта и появления жизни 3.0. При этом, собственно, по Тегмарку произойдет то, что если раньше мы только поведение свое строили на основе своих знаний, то, собственно, структуру разумных существ мы тоже будем строить на основе своих знаний. Причем не обязательно, что это будет кремниевая жизнь. Мы сейчас, в принципе, ДНК редактируем. химия и всякие нанотехнологии, может быть, это будет и углеродная жизнь. Какой процесс пойдет эффективнее? Мы с двух сторон заходим. А нельзя совсем исключить, что есть какие-нибудь третьи подходы, то есть что-нибудь такое сильно квантовое или еще какой-нибудь физический эффект откроет. Но я-то, конечно, больше, поскольку сам занимаюсь, подхожу к реализации алгоритмов на кремниевых микросхемах, Вот. Я больше сторонник того, что по этому пути будет наибольший эффект. Но, как говорится, только жизнь может показать, как на самом деле будет. Вот. Ну и, собственно, что хотелось бы только отметить на основе вот этой схемы, что, соответственно, есть как бы цивилизация появилась, когда, собственно, Человек, может быть, раньше появился, чем 10 тысяч лет назад. Кто-то считает, что 200 тысяч лет назад, кто-то 3 миллиона насчитывает в жизни человека. Но цивилизация, по современным оценкам археологов, началась где-то 10-15 тысяч лет назад. И, соответственно, её развитие сильно отличается от развития животного мира. Значит, наше накопление знаний идёт... несколько по-другому, мы ими хорошо обмениваемся, а животные не то чтобы совсем не обмениваются своими знаниями, но не так интенсивно. И, соответственно, вот мое понимание, собственно, разума, интеллекта и цивилизации Оно относится к тому, что из развития жизни появился человек, который обладал способностью к развитию интеллекта, а интеллект появляется с развитием цивилизации, то есть на ранних стадиях развития цивилизации интеллект у членов этой цивилизации не очень развит, ну а, значит, по рамеру развития цивилизации, по крайней мере у отдельных членов цивилизованного сообщества, интеллект развивается достаточно высоко. Ну и чем выше уровень развития цивилизации, тем, собственно, этот уровень интеллекта и выше. Вот. Но, значит, я это не к тому, чтобы, значит, строить интеллект на основе вот этих определений, которые я предпризывал не давать, что такое интеллект, что такое разум, вот, а к тому, что, значит, есть как бы Два типа знаний. Те знания, которые мы получаем, скажем так, на основе больше личного опыта, а те знания, которые накоплены цивилизацией. Мы, конечно, на основе личного опыта можем книжку почитать, либо курсы какие-то послушать и тоже получить какие-то индивидуальные знания. Соответственно, важно, что у нас должна быть способность к развитию интеллекта. То есть, если мы кошку как раз предлагаем, давайте сделаем агента сильного искусственного интеллекта и будем его учить как ребенка. Если агент сильного искусственного интеллекта будет обладать разумом на уровне кошки или мышки, ну, вряд ли, если вы будете вводить в школу и тем более в институт кошку, то подготовите из нее специалист для работы на атомной станции, как предлагалось. А, соответственно, прежде чем заниматься обучением агента сильного искусственного интеллекта, нужно создать агента сильного искусственного интеллекта с достаточной степенью разумности, который может воспринять эти данные цивилизационные и, соответственно, их развивать. Важно, что надо разбить эти две задачи, что это разные вещи. Возможность жить в сложном мире и получать новые знания на основе личного опыта – это важная часть агента сильного искусственного интеллекта. Другая его важная часть свойств – это то, что он должен уметь получать, пользоваться и развивать цивилизационные знания. Вот, собственно, прежде чем этим заниматься, на мой взгляд, нужно создать способности этого агента, который, собственно, мог бы жить в сложном мире. Ну и там, поскольку сложный мир полностью, на мой взгляд, описан быть не может, то, соответственно, чтобы жить в таком мире, главная способность вот этого разумного агента искусственного интеллекта состоит в том, что он должен получать по обстоятельствам необходимые новые знания. Значит, может наличием опыта получить, может обратиться к цивилизационным знаниям, но, соответственно, понимание, что вот он что-то не знает, как делать, и, соответственно, может находить вот эти самые новые знания. Вот, в целом же, знание, что такое, это, собственно, Та информация, которая используется для преобразования входных данных в выходные данные. Причем это не только в агентах сильного искусственного интеллекта, но вообще говоря, во всех устройствах. Если обращаться к эволюции, то сперва там все начиналось с... эволюции, там ранка ДНК, потом, собственно, нервная система эволюционировала, и, собственно, она не только использовала данные из ДНК, но и те данные, которые, значит, получались на основе жизни наук и общения там со средой и, соответственно, со родичами. вот у людей все как бы еще сложнее происходит и собственно вот те знания которые накоплены цивилизации еще больше влияют наше поведение но соответственно у агентов они будут свои более широкие возможности поскольку там если мы создадим разумного агента, то некоторые, значит, его свойства можно сделать, которые превосходили бы человека, ну, например, скорость там обработки, нормация ее получения, там, ну, и ряд еще возможностей. Вот. Ну, соответственно, что такое действительно новые знания, там, я как-то, спрашивали, скажу, что там мог быть просто, там совсем действительно новое, но это, конечно, все достаточно условно. То есть вот то, что я сейчас рассказываю, для кого-то это просто новые знания, то есть, значит, как бы я поговорю, меня, слава богу, хоть там несколько человек послушают, и, собственно, никак на их поведение не повлияет. Для кого-то это будут совсем новые знания, если это, значит, что-то, значит, чем-то как-то изменит их представление строительство хотя бы сильного искусственного интеллекта. А если кто-то воспримет это как действительно новые знания, и это дойдет до того, что будет какое-то финансирование моей деятельности, ну, соответственно, это вот как бы уже будет воспринято как действительно новые знания, поскольку, значит, что-то есть от этого, может быть, какая-то серьезная польза, но это случится, если будет понятно, что действительно это что-то новое. ну вопрос что стоит о том а как лучше представлять знание то есть можно представлять как бы знание описывать простые случаи там достаточно мало вариантов и легко все описывается если объединять комбинировать эти простые случаи то соответственно вариантов становится больше но и можно учитывать больше взаимодействий но в целом как бы легко посчитать что такое описание займет больше, потребует больше информации, поскольку вот этих всевозможных взаимодействий получается сильно больше. Но если попробовать все заведите в одну кучу, там, значит, катастрофически много получится знаний, и, соответственно, общее представление такое, что, значит, все в кучу, объедините не удастся. То есть надо компромисс искать какой-то где-то в этой области, а пытаться, значит, все описать единым каким-то законом или правилами вот с этим как бы пока что хотя есть надежды там найти какие-то универсальные законы но вот этот философский камень там волшебная палочка и пока что в общем недоступны и никаких серьезных идей по этому поводу я не слышал вот ну значит сложность понятно что чем значит больше как бы сказать тем мы можем более статистически достоверно описать какое-то явление. если у нас, допустим, два параметра нужно связать, то хотя бы 100 пар соответствия нужно иметь, тогда у нас будет какая-то сколько-либо хорошая статистика. но если у нас больше переменных связываем, то, соответственно, число этих пар растет экспоненциально. если у нас этих переменных становится больше, их становится N, тогда мы очень быстро заходим за то количество данных, которое мы не можем переработать. То есть просто количество магнитной памяти, там где-нибудь больше 10 в 25, ну в общем-то уже это где-то превосходит, скажем так, расходы сша на военную военные расходы сша вот ну и в общем это уже такое не до недоступное количество памяти которые можем использовать для решения каких-то задач вот а 10 30 и там далее это уже превосходит там ввп там мировое годовое поэтому собственно все очень быстро заходит вот а соответственно если им там равно 15 то это уже 10 30 и поэтому как бы Сложные задачи, они вот именно из-за того, что всё очень быстро улетает за порог сложности, они, значит, в реальности не решаются. Вот. Но в целом, значит, наш, как бы сказать, цивилизационный подход основан на том, что мы используем имеющиеся у нас знания. То есть, если, значит, любое, там, берете школьный, там, или институтский задачник, там, значит, открываете любую задачу, в ней что написано? Условия. Кроме условий, вы должны обладать некоторыми знаниями, что вот там какие-то данные. Хорошо, если вы знаете, по какой теме, вы знаете, какие законы нужно использовать. И соответственно, эти данные, которые в условиях, подставляете в формулы, которые вы взяли из учебника, или откуда-то знаете их наизусть. И, соответственно, если в одном уравнении неизвестна одна переменная, то, как правило, можно найти, чему она равна из этого уравнения. Ну, собственно, если у нас есть сумма, там, как правило, все говорят, ну, десуммация же невозможна. Ну, если ничего не известно про сумму, то, конечно, невозможно. Но есть ряд случаев десуммации, когда, значит, эта сумма все-таки возможна. Десуммация возможна. Вот. Но, как бы, в целом, значит, принято считать, что вот наши априорные знания — это вот те уравнения, которые мы используем. собственно, evidence — это те условия, которые записаны в условиях задачи, значение параметров этого уравнения. Ну, а найти нужно неизвестный параметр, и, как правило, мы успешно это делаем. Форма усыбается, она немножко смещает априорные данные в область вот этих самых условий. То есть, если обычно мы считаем, что формула является априорными данными, то формуля b, соответственно, уже известная условная вероятность является априорной вероятностью, а мы ее подправляем на основе тех данных, которые наблюдаем, и, соответственно, находим новое значение, то есть стереорное распределение. развитие формулы BIAS состоит в том, что не конкретное значение вероятности используется, а переходит к распределениям, и все это с распределениями тоже для формулы BIAS работает. тут еще такая аналогия есть, что есть можно работать не только с отдельными числами, как мы обычно работаем в формулах, но и с распределением. в принципе, в обычных формулах тоже можно интегралы брать и работать не с числами, а с функциями. но, тем не менее, в BIOS все это достаточно. как бы популярно используется, ну и все знакомы. Причем хотел бы подчеркнуть, что всякий раз, когда я чем-то рассказываю, на кого-то ссылаюсь, надо как-то 10 раз, наверное, сказать о том, что я не реализую подходы байоса. То есть, допустим, Ветров, там Дмитрий Петрович, он там замечательно вызывает эти идеи, ну и как бы слать ему в руки, вот, но я этим не занимаюсь. Пожалуйста, не говорите потом мне, что вот на основе БАИСа у тебя ничего не получится. Я вообще не занимаюсь БАИСом. Вот, хотя интересуюсь, как, значит, им занимаются другие. Вот, ну, значит, почему я не занимаюсь БАИСом? Что БАИС работает с... соответственно, с объектами и параметры, которые выделяются и задаются человеком. Вот. А я пытаюсь делать это то же самое на основе картирования, которое, собственно, отличается от подхода BIOS тем, что и, собственно, объекты выделяются автоматически, и параметры на этих объектах тоже выделяются автоматически. Ну и, кроме того, картирование направлено на локализацию и линеризацию представлений и снижение размерности компонентов. Ну, если оно, конечно, иерархическое и основано там на конкурентной основе. ну и, собственно, общая идея получения знаний компонентов, то есть надо не просто работать с векторами, а надо работать с множествами, которые данные вектора характеризуют. если мы наблюдаем какой-то суммарный сигнал, то, соответственно, он представляет сумму этих компонентов. В двухмерном случае мы можем найти разные варианты, из каких компонентов сигнал собран, но чем более высокоразмерное наше пространство, тем больше вероятность, что эти подмножества находятся в ортогональных областях пространства, и, соответственно, выбор разделения суммы на компоненты становится все более однозначным. Чем выше размерность пространства, тем легче осуществить декомпозицию суммарного сигнала, если мы знаем описание компонентов, то есть какие бывают компоненты у тех сигналов, которые мы наблюдаем. но современные нейронные сети последние 10 лет дали большой прорыв в искусственном интеллекте за счет увеличения мощности. много данных, мы быстро их обрабатываем на очень больших сетях, многослойных, и соответственно вот эта модель, какие бывают вектора, у нас стало маленький, как может, человек, а она стала больше. И это, конечно, дало определенный прогресс. Но, собственно, если вспомнить, как это делает человек, то человек, как правило, чтобы решить сложные задачи, он ее разбивает на простые компоненты и уже тогда решает. Вот. Ну и, собственно, мой-то призыв состоит в том, что надо повышать эффективность декомпозиции, то есть я считаю, что и в современных многослойных нейронных сетях некоторая декомпозиция осуществляется. И, собственно, если посмотреть развитие архитектуры нейронных сетей, то там многое направлено на то, чтобы сигнал разбивался на части. Всякие свертки и гейты во всех этих бардах и прочих они все направлены, грубо говоря, на декомпозицию, хотя все пытаются от этого откреститься. Ну и если посмотреть историю эволюции, то и в ДНК экспрессия генов происходит по частям, то есть какая-то декомпозиция есть, и то, что мы программируем, там всегда есть программы, и то, что нейронные сети пытаются откреститься от декомпозиции, это скорее аномалия, чем как нормальный путь развития. Вот. Ну и, собственно, проблема в том, что, значит, как я говорил, что вот эта вот сложность, она растет, не только, значит, обрава получения, но и хранения этих знаний, там большие сложности. Но, на самом деле, значит, больше, конечно, сложно с получением, поскольку магнитная память, она у нас дешевая, хоть там вот, я говорил, что 10-25-ый, и больше нам, как бы, сложно получить объем памяти. Но. забить эту память данными, это еще сложнее, то есть получение всех этих данных очень большой процесс. Ну и, соответственно, если мы хотим описывать мир, то все его комбинации мы не можем запомнить просто потому, что их больше, по причине того, что нам памяти не хватит времени получить эти данные, ну и как-то их обработать тоже времени не хватит. Вот, а если мы, значит, про какие-то локальные взаимодействия описываем простые, тут, значит, не требуется такого длительного вычаяния. Простые задачи уже на современных нейросетях достаточно хорошо решаются. Вопрос только в том, чтобы, значит, помочь им перейти со сложных задач на решение более простых задач. Тогда, как бы, эффективность их работы сильно повысится. Ну и вот то, что... Антон Гернович приводил там с питом там или там вот с кем же лемом там с солярисом то есть вот если зайти на этот сайт which face is real то там собственно не требуется долгого обучения вы там где-то уже на первом десятке изображений легко будете разделять, что вот это вот сгенерированное изображение, а это реальное. Почему? Потому что детали всё-таки страдают. Они страдают именно потому, что нет разделения на компоненты в изображении. Если бы кит распознавался сам по себе, а не на основе той воды, которая вокруг него, а слон распознавался сам по себе, а не на основе травки или песка, на которых он гуляет, то, соответственно, От того, что вы слона поместили в воду или кита выбросили на берег, распознавание бы не страдало. Ну и, собственно, перехожу к первым выводам, а по вторым, как я говорил, вряд ли я подойду. Главное не задаваться вопросом, как могли бы работать мозги, а, собственно, какие проблемы нужно решить, чтобы можно было получать действительно новые знания, поскольку на основе имеющихся данных мы все значит решим, надо получать новые знания. Ну и строить управление в сложном мире. и, соответственно, кроме декомпозиции необходимо еще использовать локализацию, поскольку если мы разбиваем сложные сигналы на простые компоненты, то желательно их хранить и обрабатывать отдельно. Хотя многие это будут оспаривать, поскольку есть географическая модель обработки информации в мозге, но, с другой стороны, есть экспериментальные данные, которые говорят о том, что географическая модель не очень подтверждается. Хотя, конечно, в биологии ситуация такая, что под любое утверждение, в том числе и географическое, можно найти данные, что географические слои тоже представлены. Кроме того, еще желательно иметь линеаризацию, то есть если мы хотим оптимизировать какие-то на свои знания, то если нам удалось линеализировать какие-то представления, то процесс оптимизации сильно упрощается. то картирование, которое я пытаюсь продвигать, оно как раз реализует не только локализацию и линеризацию, но и позволяет реализовать декомпозицию. ну и, соответственно, как бы сказать, опыт по наблюдение за реальным миром это не единственный способ получения знаний есть собственно возможность моделировать взаимодействие тех простых объектов которые про которые мы получили знания и соответственно это вот как бы сказать, основа мышления, то есть мы моделируем разные ситуации, прикидываем, к чему это приведет. Мы, конечно, иногда ошибаемся, к чему это приведет, и желательно проверять на опте, а правильно ли мы подумали. Но в целом это тоже способ получения новых знаний, особенно если мы там говорим про какие-то абстрактные вещи, которые на самом деле в природе не существуют, и там, соответственно, Кроме мышления, мы никак, собственно, и пока что не можем, значит, получать новые знания. Вот. Кроме того, значит, если вот это вот мышление, оно есть, то, собственно, нужно, как правило, нам перебирать, действовать на основе интуиции или все-таки сперва подумать. И вот мое определение сознания, оно как раз связано с тем, что мы не, как сказать, Это не память, которая и без этого реализуется, это не обработка, которая и без сознания реализуется, а именно это свяжение о том, как переключить между мышлением и интуицией, то есть немедленным исполнением действий. И, соответственно, сознание должно естественным образом появиться в той модели, которую я пытаюсь развивать. ну и наконец векторное управление это то что не только значит вот есть мышление интуиция есть еще там различные скажем так форма поведения там поисковое поведение там избегание или наоборот стремление к чему-то это собственно ну разные формы поведения и вот собственно все вот эти гормоны которые у нас и прочие значит нейротропные вещества они направлены на как раз на управление этими режимами и их соответственно можно комбинировать в более или менее произвольных сочетаниях и это дает собственно векторное управление режимами работы нашей нервной системы и соответственно можно интерпретировать как эмоциональную окраску. Ну, что, собственно, с выбросом всевозможных гормонов коррелирует хорошо. Вот. А если бы говорить про алгоритмические модели, то, в принципе, вот эти гормоны, они влияют как на активацию, так и на алгоритмы обучения параметров нейросетей. Вот. И, соответственно, вот управление этими коэффициентами этих алгоритмов тоже можно рассматривать как некоторое векторное управление и соотносить, собственно, с эмоциями, которые наблюдаются у живых систем. Вот. Ну и, соответственно, вывод основной первый состоит в том, что как бы не только оптимизация, но еще и декомпозиция, локализация, реализация. То есть сейчас, повторюсь, основной путь развития НРСТ это ускорение различных способов оптимизации работы тех структур, которые сконструированы человеком. Вот. А, собственно, важно, чтобы значит, сказать, чтобы задача решалась, она должна быть не только, значит, как сказать, быть доступной для оптимизации структура, которая решает задачу, но хорошо бы, чтобы она разбивала сложную задачу на простые, собственно, компоненты, тогда было бы больше возможностей решения сложных задач. Но на второй вопрос, есть ли пути практической реализации того, о чем я рассказывал, ну, соответственно, как-нибудь в другой раз, поскольку там слайды у меня на эту тему есть, но не хотел бы занимать время. Если будут вопросы, я могу на них конкретно ответить. А так я уже, следуя примеру Антона Германовича, полчаса поговорил, ну и, наверное, с вашего позволения, закончу. 

S03 [01:11:17]  : Владимир, спасибо. Коллеги, есть вопросы к Владимиру или комментарии? 

S02 [01:11:24]  : Одну секундочку, можно? Конечно. Володя, спасибо большое тебе за сообщение. Я просто хотел обратить на него внимание. Вдруг ты пропустил, но так бывает. в дополнение к моделям картирования, которые основаны на фиксированном пространстве, в котором ты картируешь, типа карт Кахомин, есть уже интересные алгоритмы. один из разработчиков, Бернард Фрицке, растущий нейронный газ. Особенность состоит в том, что все то же самое, только количество возможных связей между соседями определяется самой системой процесса обучения. То есть все то же самое, как будто карта, но только изначально она не двумерно, не трехмерно, размерность не задана. а размер распроизвольной определяется самой задачей. если нужно тебе много соседей, то будет много. наверняка тебе это знакомо. 

S00 [01:12:18]  : я просто обращаю внимание, что если вдруг ты пропустил... я уже обращал внимание с Байосом, что если я упоминаю Байоса, это не значит, что я... я понимаю, что ты не Кахонина занимаешься. если я упоминаю Кахонина, то я понимаю непосредственно за ним следуя давно работаю сказать в энерном пространстве у меня есть алгоритмы как определить размерность вот этого облака замечательно все тогда тогда все все все отлично тогда вопрос на самом деле был уместен потому что ты нет нет я смог благодарен благодарен что вы задали поскольку я хотел бы это подчеркнуть все отлично спасибо спасибо еще раз 

S03 [01:12:58]  : Коллеги, к Владимиру есть какие-то еще вопросы короткие, явные? Владимир, тогда спасибо. У нас еще останется, я думаю, время на дискуссию. Ильгизар, вам слово. 

S04 [01:13:13]  : Здравствуйте. Добрый вечер. Добрый вечер. Слышно хорошо? Да-да-да, нормально. Так, сейчас надо презентацию запустить небольшой. Буквально два слайда есть. Демонстрация. Так, появилось. 

S03 [01:13:51]  : появляется сейчас видимо что-то должно произойти черный экран уже есть но презентации еще нету странно а пиццы не надо мы подождем немножко вопрос о все все теперь есть 

S04 [01:14:22]  : Так, добрый вечер. Так, у меня будет такое коротенькое сообщение. Здесь я хочу затронуть какой-то непростой для меня как IT-специалист, инженером вопрос. Поэтому как бы прошу извинить, если я буду заглядывать в заметки к сообщению. Путь Каги, как к универсальному решателю задач, вижу через поиск архитектуры понимания. В таком подходе возникает некий заколдованный круг, требуется понять, как происходит сам процесс понимания. И здесь получается такая сложность самой рефлексии. Здесь как бы на примере понимания в конкретной предметной деятельности нужно выделить этапы, увидеть, что нам мешает и помогает на этих этапах, а затем применить эту схему мышления и подход к задаче понимания природы самого нашего мышления. Эльгизар, мы видим только первый ваш слайд, если вы что-то… Да-да-да, у меня буквально два слайда всего. Я здесь не буду рассматривать какие-то вопросы с техническими, связанными решениями, с инженерными. Своеобразный металлологический аспект, связанный с проблемой, он называется герметический круг. Сейчас на следующий слайд перехожу. Здесь существует несколько разных схематических изображений. Вот здесь небольшие публикации. Я позаимствовал архитектурные представления в виде герметической спирали, которая предлагает проследить процесс сборки понимания. Из публикации приведены формулировки герметики, понимания и самого герметического процесса. Здесь стираль, она сходится к условному ядру. которые как идеал содержат в себе все необходимые аспекты знаний во всей целостности. По мере накопления знаний происходит как бы движение от абстрактного ядра к периферии конкретному знанию, происходят неизбежные наслоения спецификами предметных областей. Наше внимание сужается, Поэтому мы уже не в силах охватить полностью все контексты и движемся по периметру этого круга. В каждый момент сознания, мышления и деятельности мы погружены только в один из данных аспектов, и требуются специальные усилия и навыки, чтобы делать переходы, переключения на другие аспекты. Данная схема в своей многогранности довольно понятна и ясна. Наверное, для многих это уже не является чем-то новым. Довольно она интуитивная, поэтому здесь ее подробно разбирать не буду, каждую линию. Быстренько пробегусь по линиям. Линия диалог-интерпретация, она нам хорошо знакома по опыту участия в дискуссиях. Там мы знаем, что у каждого у нас есть свои определения, свои интерпретации. И здесь видно, что это является закономерным явлением, неизбежными издержками дискуссий и диалогов. Не нужно воспринимать все это как бы в штыки. Здесь нам что мешает? Мешает разная интерпретация, определение участниками дискуссии, нестыковка описаний, то, как мы их по-разному читаем. Немножко помогает наша работа, то, что мы делаем, составляем таблицу определений. Каждый участник пытается состыковать их в рамке своей картины мира. Следующая линия – теория и практика. ассоциирует, выражает связь между инженером и теоретиком. Есть интересно, что часто бывает так, что сама практика может существовать отдельно от теории, как бы не нуждается в ней. Особенно это тогда происходит, когда хорошей теории нет. В принципе, для задачи нашей АйГи во многом так оно и происходит. На самом деле, конечно, теория необходима. Но не всякую теорию можно проверить практикой. Для этого нужны необходимые зрелости технических решений, особый технологический уклад, на который, наверное, мы еще не вышли. И программные возможности, программные средства тоже. сегодня ограничены и не дают реализовать то что может быть уже есть в теории то что выражают отдельные теории в этом тоже есть как бы определенная проблема то что нам мешает следующая линия целая часть но это хорошо всем известно системное мышление Тут сложно охватить целое, найти в них части, сделать анализ и синтез. Здесь нужно хорошее системное мышление. Помогает теория организованных систем. Есть образ эмерженности, то что возникает при сборке из частей, но мы пока еще не знаем благодаря чему это происходит. В следующей линии понимание и предпонимание. Ясное понимание как бы всегда совмещается с долей визионерства, неформального знания в смежных предметных областях. Но само предпонимание есть неизбежный и необходимый этап в движении к знанию. То есть нечёткое знание само по себе неизбежно, необходимо, и тоже помогает формирование теории. Вот таким образом получается сходящаяся спираль понимания, познания в применении к самому познанию интеллекта, поможет двигаться к построению АГИИ. Через сборку достаточно сложной картины мира для архитектуры познающихся тем. И далее можно будет идти от такой парадигмы к разворачиванию инженерных решений. Хорошо бы исходить из набора Наоборот, хорошо бы исходить не из набора самостоятельных фрагментарных гипотез и парадигм в ядре, как это часто происходит сегодня, а из единой. Хорошо бы собрать все существующие парадигмы и провести их по такому кругу, сопоставить, выявить, что в каждой из них нам мешает и помогает. Вот такая получилась экстремальная картина процесса. Спасибо. 

S03 [01:24:08]  : Эльгизар, спасибо. Есть какие-то вопросы к Эльгизару или комментарии? Так, пока думаем, есть ли вопросы к Егизарову. От Александра Туманяна короткий вопрос спикером. Какие компоненты деятельности мозга человека вы видите обязательными для создания AGI? Ну, с моей точки зрения, те, которые я перечислил, плюс те, которые вроде как уже есть. Вот. Владимир, можете показать ваш слайд, на котором у вас, по-моему, где-то в начале был перечень этих элементов? У вас, по-моему, более полный список. 

S00 [01:24:55]  : У меня на самом деле список короче. 

S03 [01:24:58]  : Нет, у вас в конце короткий список. Декомпозиция, локализация. 

S00 [01:25:04]  : Вот, который план доклада. 

S03 [01:25:07]  : Да, вот я про этот, про план доклада. Пока Владимир ищет список требований к AGI, какие-то еще есть вопросы к эспикеру, текущему коллеги Зару? 

S01 [01:25:22]  : У меня только есть маленькое замечание. Не замечание, а такая реплика. Довольно часто в последнее время сталкиваюсь с использованием термина, понятия герминефтика, обращение к герминефтике совершенно за ее пределами. Ведь если посмотреть на первое определение, которое Эльгизард давал, герминертика касается только конкретно текстов, интерпретации при прочтении текстов. Берешь книгу, и ты занимаешься пониманием текста. И нельзя герминертику распространять на вообще все познание. Это узкая часть познания, занимающаяся интерпретацией текстов. И в последнее время очень часто, у нас даже в чатиках видно, что используется термин герминефтика в расширительном значении. 

S04 [01:26:07]  : Спасибо. Правильно, изначально оно появилось. Изначально так и появилось, но оно потом многими расширено к самому процессу понимания. 

S01 [01:26:23]  : Я не знаю, если посмотреть все словари и серьезные работы, то я сталкиваюсь только где-то так, на периферии. Есть познания, давайте говорить о познании, а германефтику оставить германефтике, которая занимается интерпретацией текстов. Еще исконно, исходя из интерпретации священных писаний и прочего, тогда появилась герминафтика, только относительно текста. 

S04 [01:26:52]  : Спасибо. Думаю, что логика такая. Текст – это язык. И тут есть разные толкования языка. То есть язык не ограничивается самим текстом. А язык – оно и есть мышление, язык – это и есть деятельность. 

S01 [01:27:14]  : Ну да, язык шире, но германептика не про язык, а про текст, конкретный текст. Берем книгу и начинаем ее интерпретировать, читать, понимать. И германептический круг именно касался того, что для того, чтобы понять книгу, нужно понимать, что в ней написано. А чтобы понимать, что вы не написали, нужно прочитать эту книгу. И вот этот круг бесконечный, что ты не понимая книгу, не можешь ее понять, вот в этом и заключается герметический круг. 

S04 [01:27:41]  : Но здесь тогда получается ограниченное понимание текста. То есть текст здесь видится как текст, независимый от мышление и знание, познание. Если же сам текст и язык понимать именно как проявление познания, возможности человека и способности, что для понимания текста необходимы все составляющие познающего субъекта, то геометрика расширяется. Нет, герминефтика не может расшириться. 

S01 [01:28:24]  : Понимаете, у нас есть эпистемология, у нас есть гносиология, есть герминефтика. И от того, что эпистемология занимается знаниями, научными знаниями, не общим познанием, а они становятся теорией общего познания, которая общего познания занимается поэтому есть термин устоявшийся и не стоит их переопределять. я не вижу смысла переопределения терминов. 

S04 [01:28:52]  : спасибо. я вот открыл экран, его видно? 

S01 [01:28:54]  : да. 

S00 [01:29:06]  : Ну, на самом деле, тут список по докладу больше. То есть, наверное, стоит сказать, что главное все-таки выделить то, что свойство искусственного интеллекта стоит в том, чтобы он мог получать новые знания. А эти знания, чтобы он не пытался получить в целом про весь мир, а про какие-то локальные задачи и различные варианты использовать. И, соответственно, Утверждение о том, что сильный искусственный интеллект может решать любую задачу, это и про человека неправильно, и про сильный искусственный интеллект тоже будет неправильно. Всегда будут такие задачи, которые пока непонятно, как решать, нужно получать новые знания, и, соответственно, эти знания, они, так сказать, никогда новые не кончатся. То есть, вот так, конечно, мы получили все абсолютно знания, по крайней мере, мое к этому отношение, такого, что это никогда не будет, поскольку мир сложный, там, взаимодействие между частями, все проверить никогда не удастся, и всегда будут появляться какие-то там... знания, которые приводят к синергии, к эмерджентности, как это принято говорить, и это процесс неостанавливаемый. Но еще о чем я не сказал, и, может быть, хочется сказать, что вот это представление философов о том, что мышление – это логика, оно, с моей точки зрения, к биологии имеет очень поственное отношение, то есть ряд животных обходится без логики, и многие люди обходятся без логики. Ну, там кто лучше, кто хуже, конечно, как-то, в общем, живут. И в целом мое такое впечатление, что логика – это достижение цивилизации, оно полезное, нужно это развивать и использовать. Но когда мы строим агента сильного искусственного интеллекта, пока что не обладающего, в перспективе только сможущего обладать интеллектом, когда мы его соединим с сознанием цивилизации, а изначально он должен уметь жить в этом мире, без явного использования логики основы вот этого строя иерархическую аналоговую модель окружающих его ситуации мира. Вот, но про это я сегодня чувствую времени. 

S03 [01:31:04]  : Владимир, а можно в качестве короткой дискуссии, прежде чем дать слово Александру Балдачеву, смотрите, я согласен с вашим тезисом, что если мы хотим сделать агента как такового, то мы его не обязательно должны наделять логикой, потому что он, в принципе, логику может обрести в процессе социализации с другими агентами, либо с людьми. Я правильно ваш тезис понял? Да, да, именно так. А у меня вопрос такой, что если у школи мы все равно понимаем, что мы выгодную сторону отличаемся от животных тем, что у нас есть логика, почему нам сразу не делать агентов с логикой, сокращая маршрут? Зачем нам делать агентов без логики, чтобы потом их учить логике? Давайте сразу делать агентов с логикой. 

S00 [01:31:54]  : Ну, вы же понимаете, что логика, она тоже не стоит на месте. Вот раньше там была аристотевая логика, а потом пошло много разных других логик. Какую будем закладывать? 

S03 [01:32:07]  : не знаю. 

S00 [01:32:10]  : давайте я отвечу. смысл, собственно, не в том, что какую-то определенную надо закладывать. можно, конечно, все существующие, но потом новые появятся. то есть каким-то логием придется учить. а главное, собственно, чтобы Агент искусственного интеллекта мог получать новые знания, в том числе обучаться логике. А заложим ли мы изначально какие-то его способности или не заложим – это вторичный вопрос, на мой взгляд. 

S03 [01:32:39]  : Хорошо. Давайте сейчас дадим возможность Александру Балдачу. 

S00 [01:32:44]  : Да, я все сказал. Пожалуйста. 

S03 [01:32:49]  : Вы попробуйте ответить на этот вопрос, а потом перейдите к своим. 

S01 [01:32:53]  : Хорошо. Кстати, укладывается и во весь пафос моего короткого выступления. Антон, животные действуют логично? Логично. Логично. Они знают логику? Нет, логика. А скажем так, другой вопрос. Люди в Древней Греции и в Египте говорили логично? Логично. Но при этом, что такое логика, они не знали. Логику только придумал Аристотель. То есть логика в том смысле, в котором мы используем именно Аристотель и другие логики, это лишь способ фиксации закономерностей, которые существуют до и вне. Скажем, до открытия закона Ньютона закон притяжения действовал. И само знание закона Ньютона в принципе не помогает людям функционировать. Никак. То есть они прекрасно живут без знания закона Ньютона. То есть он нужен только в редких случаях, когда нужно рассчитать полет спутника или там астрономии. То же самое с логикой. Большинство людей действует логично или в какой-то степени алогично, но не потому что они не знают логику, потому что они так действуют. И поэтому, если мы сделаем, скажем, аги на уровне домохозяйки, которая будет логично смешивать различные ингредиенты на кухне и действовать при стирке логично, этого будет достаточно. Это будет величайшее достижение. Для этого логику закладывать не нужно. Это один момент. А второй момент. С помощью логики, в принципе, ничего не было достигнуто за время существования этой логики. Вот сколько существовало аристотической логики, она никак не помогала делать ни научные открытия, ни инженерные открытия. То есть большинство людей, которые занимались созданием нового знания, они ориентировались не на силогизмы и правила логики, а на что-то совершенно другое. Поэтому я полностью согласен здесь с Владимиром, что логика – это внешний продукт деятельности, внешнее описание, а не само содержание, не сама суть. И вот сейчас я хочу перейти, уже опираясь на ваш изначальный доклад, приблизительно с этой же мыслью. Скажем, мы можем взять… кулинарию, упомянутую уже, и начать анализировать химический состав продуктов, не продуктов, а блюд шикарных приготовленных, и не шикарных, разных, разных, и выявить там очень вполне ясные закономерности. Но вот эти закономерности нам никак не помогут понять, что такое кулинария и как вообще производятся эти блюда. Вот приблизительно то же самое мы сейчас производим с текстом. Когда мы в NLP, когда мы занимаемся расчетом статистическим, после этого знака будет вот этот знак, будет пробел, коллерируют эти знаки, не коллерируют знаки, мы выявляем некие закономерности. Мы совершенно не приближаемся к тому, чтобы понять, а как сам этот текст появился. И когда мы генерируем свой текст, когда я сейчас говорю, генерирую текст или когда я пишу что-то, я совершенно не задумываюсь, какая статистика, после какого слова должно по статистике идти чаще другое слово. И то же самое касается вопросов энергозатратности, минимизации неопределенности. Если мы говорим про энергию, которую нужно минимизировать, то тут прежде всего всплывает принцип наименьшего действия. И с помощью которого мы можем рассчитать поведение физической системы, газа или просто механической системы, вывести какие-то законы. Но самое интересное, что принцип наименьшего действия ничего не объясняет. Вообще ничего. Он просто констатирует, что вот какие-то процессы, какие-то действия ему удовлетворяют. И то же самое, что когда кто-то выделяет какие-то закономерности, связанные а-ля с энергией минимизации на деятельности интеллектуальной какой-то или в текстах, то это всего лишь констатирует, что вот то, что мы производим, что человек производит некую деятельность, производит некий текст, удовлетворяет этим требованиям, но никак не объясняет, откуда это взялось в самом человеке. То есть принцип наименьшего действия, принцип наименьшей энергии, принцип сохранения энергии ничего не объясняет. Он просто констатирует, что продукт подчиняется таким-то законам. И несколько слов хотел бы сказать по поводу объяснимости. Здесь есть вообще, а ну прежде всего отвечу Владимиру по поводу его замечания, по поводу объяснимости. Владимир, вы говорили про отказы. Да, есть отказы и на машине, есть отказы в компьютере, есть отказы и на атомной станции, есть что-то случающееся. Но когда мы говорим про объяснимость и проблемы с объяснимостью, мы говорим о штатной его работе. Именно о штатной, когда вот он полностью, стопроцентно отработал и сказал, где резать, какую ногу отрезать. Там ничего не сболило. Поэтому здесь нужно четко различать, когда мы ставим проблему о штатной работе, когда мы боремся с какими-то багами, с ошибками, с ненадежностью. А теперь по поводу объяснимости ИИ еще раз такой момент. Здесь есть некая такая подмена. Ведь, Антон, если вспомнить исходное определение ИИ, которое давалось там лет 30-50 назад, ну не определение, то есть понимание, там же разделялась ИИ, под ИИ подпадали и экспертные системы, и нейронные сети. Поэтому все-таки корректнее было бы говорить о объяснимости нейронных сетей. Именно нейронных сетей. Но если у нас стоит задача автоматизации управления атомной станцией, то можно просто сказать, что нельзя нейронную сеть ставить на автоматизацию атомной станции. Потому что она непригодна для этого. Для этого нужно делать, скажем, энергоэкспертную систему, автоматическую систему, которая объяснима, интерпретируема. Насколько она будет... Можно ли ее назвать интеллектуальной? Это уже другой вопрос. Ну, скажем, мы можем назвать Перельмана интеллектуальным человеком. Да. А можем ли допустить Перельмана для управления атомной станцией? Нет, конечно. Но большинство людей, обладающих интеллектом, и даже чем более антиинтеллектуальный какой-то рассеянный профессор, тем менее он пригоден для управления сложными процессами, тем менее он интерпретируемый. Поэтому здесь нельзя говорить про интерпретируемость ИИ, а нужно просто говорить про интерпретируемость конкретного технического решения на уровне нейронных сетей. И то, что эти нейронные сети по своей структуре, по своей сути, они не пригодны для каких-то работ, выполнения работы. Как и у человека, который распознает что-то, он может всегда ошибиться в распознавании, какого-то образа, и нельзя на основании распознавания образов делать какие-то управленческие выводы на уровне управления станцией. Поэтому там все переведено в символы, в знаки, в лампочки, чтобы не дай бог что-нибудь перепутать. Ну вот, наверное, и все. 

S00 [01:40:37]  : Хорошо, спасибо. Поскольку мой подход критиковали, я бы хотел защититься. Всякая система проверяется. Мы спроектировали, допустим, операционную систему или управление атомной станцией, и мы ее на все режимы гоняем, какие нам доступны. А все режимы нам недоступны. И если вы скажете, что вот эта атомная станция нам так спроектирована, что раз в 10 лет она будет взрываться. Вам же ее не примут. И то, что она взорвалась, это, конечно, не штатная ситуация, но она заложена была в эту конструкцию, понимаете? И в обучение персонала, и все это так сработало, что она взорвалась. Поэтому я понимаю, что вы не любите нейронные сети. 

S01 [01:41:20]  : Почему? Кто сказал, что я не люблю нейронные сети? Кстати, вы несколько раз об этом писали, я никогда этого не говорил. 

S00 [01:41:27]  : Хорошо, но по вашему поведению ощущается, что вот нейронные сети, они сложные, их невозможно понять. А вот алгоритм, вот Hello World мы написали, точно будет напечатано Hello World. Но если мы пишем посложнее программу, там, значит, есть бригада тестировщиков, которые с разных сторон ее тестируют, и все равно она, значит, как бы во всех сторон, то есть каждый раз нужно отслеживать работу этой системы, поскольку в эксплуатации всегда выявляется ряд сбоев, которые не были предусмотрены. поэтому нет принципиального различия между экспертными системами и нейросетями. есть принципиальное различие. простая система и сложная система. если в нейросети три нейрона, то она от экспертной системы вообще ничем не отличается. И в экспертной системе, если 3 блока, то все прекрасно работает. Мы все варианты посмотрели, и с нейросетей то же самое. А когда в нейросети там миллион элементов, или, например, в вашей экспертной системе или системе управления миллион элементов, то все то же самое. Я не буду с вами спорить, каждый, конечно, может остаться при своем мнении, но чтобы вы понимали, в чем отличие наших людей. 

S01 [01:42:35]  : Тоже не буду. 

S03 [01:42:37]  : Александр, у меня короткая ремарка. Спасибо за Ваш комментарий по поводу кофейной гущи. Видимо, опять-таки, профдеформация, потому что я как бы... Этим не занимались. Да, да, да. Для меня было очевидно, что гадалки поступали Они не притрагиваются к кружке. 

S01 [01:43:02]  : Чашку переворачивает пьющий, а они берут и только гадают на картину. 

S03 [01:43:08]  : То есть они гораздо более честно поступают, чем специалисты в области маркетинга системы искусственного интеллекта. Да, да, да. Хорошо, спасибо. Сергей? 

S02 [01:43:21]  : вы хотели высказаться добрый вечер еще раз всем коллеги я хотел несколько несколько слов сказать вот о чем но поскольку вопрос который поставлен сегодня настолько широкий и настолько как бы ну вот многоплановый что мы в общем на самом деле можем только с разных сторон немножко этого этого слона так сказать потрогать но ясно что мы не можем ответить позвольте мне начать немножко в отношении вот отчасти комментариев к вопросу о том что там мозг делает и там что что что можно с мозгом я вот такую покажу картиночку значит демонстрация экрана поделиться и вот такую вот картиночку покажу и Есть такой замечательный человек, наверняка многим у вас знакомый, Дилип Джордж, это тот человек, по диссертации которого, собственно, диссертация которого лежит в основе всей Нементы, то есть это он-то придумал на самом деле вот эту методологию. Так вот, он в Твиттере опубликовал такое замечательное вот такое сообщение, что самая большая Самое большое открытие всей этой деятельности вычислительными нейронами состоит в том, что мозг настолько пластичен, то есть пластичность мозга, что он всегда подстраивает свои механизмы очень часто под текущую парадигму, которая доминирует в области машинного обучения. Смысл шутки понятен, но в каждой шутке есть доля шутки, как известно. И вот я хочу просто сказать о том, что я на самом деле придерживаюсь серьезной части вот этого сообщения, состоящего в том, что мы настолько мало знаем о механизмах вообще живого, не только мозга, а вообще живого. Это показали и вирусные последние вещи, это показали и показывают многие аспекты, связанные с реакцией нашего организма на изменяющиеся условия, что практически, когда ученый-математик делает отсылку о том, что вот у нас есть такая модель в мозге, вот так вот, и поэтому у меня уравнение, так сказать, вот так вот и так далее, то вот читайте эту замечательную цитату вот этого Дилипа Джорджа. Хорошо. Это было, так сказать, наполовину шутка. Теперь в отношении того, что хочется сказать немножко об искусственном интеллекте. Значит, я, в отличие от многих вас, видимо, многих участников, которые здесь присутствуют, не занимаюсь такими вопросами искусственного интеллекта и сильного искусственного интеллекта. Я занимаюсь приложениями, прикладной математикой, гораздо более традиционными вещами и рассматриваю методологии, которые созданы в рамках искусственного интеллекта. как, естественно, расширение. то есть тогда, когда теорема там перестает работать, а нужно достигать результат, то можно немножко продвинуться в сторону, использовать расширенный подход, который менее обоснован, но зато более адаптивен. так вот я просто хочу предложить некий такой очень спорный тезис. Если бы мы с вами были в реальной аудитории, то, возможно, вы бы набросились на меня с палками сейчас все. Но я воспользуюсь тем, что мы виртуальная аудитория, поэтому вот так, да? Мой тезис стоит в следующем. Зачем людям мог бы потребоваться искусственный интеллект или сильный искусственный интеллект? Вот когда происходит какой-то финансовый кризис, на рынке там что-нибудь такое шарахнуло, произошло там какой-то дичайший скачок, мудрый старый руководитель банка вызывает к себе аналитика самого главного, самого ответственного человека, с которым они работают уже много десятилетий, и задает ему вопрос. И вопрос этот звучит не так «что мне делать», звучит так но расскажи мне теперь что же там произошло то есть на самом теле хочется или может быть разумно или мирно и спокойно делать искусственно интеллектуальные машины алгоритмы которые все равно обучаются только на том что уже сейчас есть заниматься задачей не принятие решений в новых условиях не замены несения ответственности за возникновение принятия новых условий, а заняться тщательнейшим объяснением уже принятых решений, то есть объяснением той текущей ситуации, которая есть, с возможностью Математически, благодаря тому, что мозг искусственного интеллекта осведомлен, может быть, по крайней мере, теоретически осведомлен о гораздо большем количестве аспектов того, что произошло, чем любой из людей, соответственно, такой искусственный интеллект гораздо больше учитывает аспектов того, что происходит в этом окружающем мире, чтобы он мог построить модели альтернативных. Не только, что произошло, а что могло бы произойти, если бы мы поступили по-другому. но обращаю ваше внимание это все обратить в текущее явление не в прогнозирование будущего не в принятие решений в которых мы никогда не сможем обеспечить его безопасность никогда не сможем его доверять любые попытки его как-нибудь объяснить это это очень такие частные вещи сегодня объяснили из объяснить в каких терминах Потому что термины надо выбрать. А если сложная очень ситуация, то все равно это объяснение будет понятно очень мало людей. И это скорее будет не объяснение, а какое-то просто успокоение. Немножко успокоились. Типа как бы мы объяснили. В действительности мы до конца, по большому счету, пока он не биологический, пока он не нашего вида, мы ему доверять не сможем никогда. А вот попросить его осмыслить все вокруг, что происходит, и рассказать нам концентрированно о тех аспектах, которые мы не видим, не можем благодаря нашей ограниченности, наших сознаний. А также еще попробовать попросить промоделировать, а что было бы, если бы мы или кто-то другой приняли какие-то альтернативные решения. И вот такое знание очень ценно. То есть если человек будет иметь вот такого советника, который рассказывает ему о текучей ситуации с разных сторон, в том числе и в контрафактических условиях, которые не реализовались, то это позволит человеку потом более обоснованно принимать решения, больше учитывать факторов, вообще говоря обучаться на этих ситуациях, то есть учиться этому опыту. И это мирное сосуществование, потому что мы не просим искусственный интеллект, принимает решение нажимать кнопку или нет кнопку нажимает человек или не нажимает а вот помочь ему разобраться в текущей ситуации в тех аспектах которые недоступны человеческому сознанию это было бы очень ценно и очень важно это вот такой тезис То есть, соответственно, искусственному интеллекту ни места ни в каком реальном мире. Ему не надо бегать в кухню и пытаться сварить кофе. Ему не нужно учиться какие-то действия делать, которые он автономно будет делать и принимать решения. От этого всего его нужно убрать. И поручить ему только одну единственную задачу. Осмысляй то, что окружает нас. Рассказывай нам. Рассказывай нам о наших ошибках, которые мы сделали. Расскажи о возможных альтернативных, более правильных решениях и так далее. Но не надо за нас принимать решения. Вот, коллеги, спасибо. Это такое у меня сообщение. 

S03 [01:51:02]  : Сергей, огромное спасибо. Удивительно своевременный комментарий. Почему? Потом у меня еще вопрос будет. Потому что буквально вчера я разговаривал с достаточно серьезными людьми, которые занимаются достаточно серьезными задачами. И мы говорили о том, какие методы AI можно применять для решения этих серьезных задач. И в результате разговора практически прозвучало то, что вы сказали. То есть нам нужен инструмент. который, когда все навернется, то он нам расскажет, а почему она все навернулась. А какие кнопки давить, мы как-нибудь сами разберемся, потому что, по крайней мере, мы будем знать, с кого нам потом шкуру спускать. А вторая задача – это История из области цифровых двойников, что если мы хотим сделать какую-то систему автоматизации чего-то, то для того, чтобы убедиться, что мы закрыли все возможные состояние этой сложной системы на предмет того, не сломается ли она в этих ситуациях. Нам нужно иметь возможность, фиксируя поведение системы в штатных, в конечном наборе параметров, получить некоторую ее модель. и посмотреть, как она может вести себя в каких-то точках, в которых мы ее не гоняли. Попытаться как-то проинтерполировать состояние системы на предмет испытания ее поведения в рамках той системы, в которой мы... Я даже добавлю, позволить ей самой провести такой эксперимент. 

S02 [01:52:47]  : Мы можем даже не знать, какой эксперимент провести, а попросить ее, а ты еще сама себя поисследуй, где-где-где ты как бы считаешь, что нам нужно было бы что-то посмотреть, то есть это было бы вот это вот. 

S03 [01:52:58]  : И вот тогда вопрос, тогда вопрос теперь к вам, а вообще тут надо ли вообще говорить с каком-то AGI, может быть надо говорить, может вообще AGI вот в том виде? 

S02 [01:53:09]  : Надо обязательно, нужно обязательно, потому что здесь должен быть реализованный глубокий перенос информации и знаний из одной области в другую. То есть здесь вот этот уровень экстраполяции, ведь экстраполяция она не только в будущее, не только по времени в будущее, она еще между любыми состояниями. Вот даже есть такая классическая шутка кого-то из старых статистиков, что задача прогнозирования очень сложна, особенно прогнозирование будущего. На самом деле он имеет в виду, что в основном-то решается задача прогнозирования текущего состояния, другого какого-то, альтернативного состояния в других условиях, не будущего, не обязательно по времени будущего. И вот правильно переносить с учетом всего комплекса знаний информацию, синтезировать из разных источников ее на одно пространство, это без сомнения функция очень глубокого такого сознания, которое просто даже не представляю себе, как его там сделать. Поэтому, конечно, надо. Он должен мыслительно, в каком-то смысле мыслительно синтезировать очень большое количество разных источников информации. Не про будущее, а про текущее. 

S03 [01:54:17]  : И тогда, извините, я увидел противоречие. То есть, вы произнесли слово прогнозирование. То есть, у тебя нет возможности прогнозировать. 

S02 [01:54:27]  : Прогнозирование – это слово, которое не относится к будущему. Прогнозирование относится к другому состоянию, например, в прошлом. 

S03 [01:54:34]  : А почему состояние не может быть в будущем? 

S02 [01:54:38]  : потому что будущее предполагает прогноз прогноз это по определению про будущее глубокое заблуждение ровно вот это вот моя фраза об этом статистике говорит слово прогнозирование это перенос от одной точки в другую не обязательно по времени но и по времени в том числе по времени это отдельная выделенная ось я сейчас о ней не говорю я сейчас говорю о чем она отличается тем, что, еще раз говорю, часть неопределенности, которая касается будущего, принципиально не снимаема. А вот часть неопределенности, которая касается перепереходов между состояниями, потенциально снимается. 

S03 [01:55:18]  : Но, по-моему, это то, про что как раз я говорил. Ты нам расскажи, какие варианты есть, а выберем уж как-нибудь мы сами. 

S02 [01:55:25]  : Какие варианты были? какие варианты были и что было бы если бы мы вчера поступили по-другому не завтра поступим то есть не пытайся угадать будущее решение вот это не нужно делать потому что ты будешь его это ты всегда будешь делать ошибки ты но ты не можешь нести ответственность за эти ошибки ты это имеют искусственный интеллект поэтому ты ты всегда обучаешься на той информации которую тебе сейчас доступно и занимайся обсуждением именно ее. Хорошо. 

S03 [01:55:58]  : Ну и Сергей второй тогда ждать, чтобы не занимать чужое время. Последний тогда аргумент. Хорошо. А если мы хотим сделать робота, который там будет, к примеру, заниматься спасением чего-нибудь в какой-нибудь радиоактивной зоне или на каком-нибудь пожаре, где просто у него не будет возможность людей, которые будут дистанционно, он должен действовать автономно, у него не будет возможности, у него не будет человека, который будет принимать за него решение. 

S02 [01:56:30]  : Этот робот должен действовать по заранее спроектированным программам с минимальной адаптацией и спасти как можно больше людей стандартным способом. Ровно так, например, поступает врач. у которого есть клиническая рекомендация о том, как лечить данное заболевание. Даже в случае, если он видит, что вот этому больному можно было бы там какой-нибудь там с ним эксперимент провести, давай-ка тебе таблетку дам. Нет. Врач использует клиническую рекомендацию, потому что его задача вылечить из тысячи больных 995. А не, ну то есть понимаете, о чем я говорю. То есть вот робот, который будет сам думать о том, кого его там спасать и так далее, такого робота делать не надо. В принципе, таких активностей порученных роботом не должно быть. Робот может действовать в новых условиях, еще раз подчеркиваю, адаптируясь, например, при перемещении по ступенькам, он не должен спотыкаться, потому что ступеньки кривые или камни на ступеньках, то их надо балансировать. Да, адаптация, да. но не принятие решения в новых условиях. Это моя точка зрения. 

S03 [01:57:35]  : Спасибо. 

S02 [01:57:37]  : Спасибо, Антон. Спасибо, Сергей. 

S03 [01:57:39]  : Владимир, как я понимаю, вы хотите сказать что-то? 

S00 [01:57:42]  : Да, я потрясен, насколько разноплановая личность Сергея Александровича. С одной стороны, он идеалист, верит, что можно давать точные прогнозы в сложных ситуациях. С другой стороны, он как бы пессимист, что никогда не будет создан таких систем, которым можно будет что-то доверять. Как бы это у него прекрасно уживается. 

S02 [01:58:04]  : Но самое главное... Володь, я ни про первое, ни про второе не говорил. Извини. Ни про первое, ни про второе я не говорил. 

S00 [01:58:10]  : Ну как? Вы же говорите прогнозы давать. Прогноз? Еще раз. Для сложных ситуаций. 

S02 [01:58:16]  : Антон уточнил, я еще раз разъяснил. 

S00 [01:58:18]  : Слово прогноз как слово... Я же не сказал про будущее, я же не сказал про будущее, я сказал про прогноз. Я про будущее вообще ничего не употреблял. Пессимизм состоит в том, что такие системы, которым можно что-то доверять, их никогда не будет. Будут, будут, но надо их уничтожать. Это тоже интересно. Доверение нельзя, раз надо их уничтожать. Вот. А то, что вы конкретный практик, это говорит о том, что надо делать прогнозы в прошлое. И такие прогнозы, они замечательны. Это даже лучше, чем продавать загробную жизнь. Почему? Потому что, когда я делаю прогноз за прошлое, его никогда нельзя проверить. Я могу делать любые прогнозы. Вы никогда не проверите, что правильно я сделал прогноз, неправильно. Прошлое было и прошло. Понимаете? И такие прогнозы очень классно делать. Именно вот на такие задачи надо брать. Они очень практические. 

S02 [01:59:10]  : Какой бы прогноз вы ни сделали... Володя, смотрите. Спасибо большое, что вы брали на это внимание. Я специально употребил слово фунтерфактические. То есть это та часть мышления, которая касается вымышленной ситуации, которой не было и не будет в реальном мире. суждения в отношении контрфактических ситуаций, если придерживаться вашего взгляда, который вы говорите, то взгляд говорит следующим образом. Контрфактического мышления вообще не должно быть. Почему? Потому что непроверяемо. Я же не могу в прошлом организовать другую ситуацию, которой реально не было, и в ней проверить. Следовательно, тезис о том, что контрфактический анализ нужно исключить и вот если если максимально воспринимать ваши слова только лишь на том основе на той основе что не проверяя очень сильно сузит наши возможности против анализа 

S00 [02:00:07]  : Я говорю напротив про то, что это очень практически выгодно делать прогнозы на прошлое, потому что их никто не проверит. А если на основе этого фактического анализа сделать прогноз на будущее, это очень рискованное занятие, поскольку ваш прогноз может не подтвердиться. 

S02 [02:00:29]  : Володя, дело не в том, что лично я пострадаю, моё я или моё эго. Планета пострадает. 

S00 [02:00:35]  : Здесь ничего личного нет. 

S02 [02:00:36]  : Речь идет о том, что система, которая занимается принятием решений относительно будущего, она должна нести ответственность за эти решения. Мы об этом многократно говорили. Вот эту составляющую ответственности роботу мы будем получить, да, Антон? 

S00 [02:00:59]  : Ну, значит, ситуация же, понимаете, какая, что вот мы все думали, что, значит, вот появились мобильные телефоны с камерой, и преступность должна резко пойти вниз. Почему? Потому что каждый, вот вы там начали хулиганить, а я вас снял на камеру. Или, допустим, войны прекратятся, потому что начался какой-то конфликт, его заснимают, видно, кто что делает. И как бы на будущее все будут знать, что будет ответственность за эти преступления, и никто не будет в преступлении. Как вы знаете, это совсем не так. Ни преступность не снизилась, ни конфликты не прекратились. 

S02 [02:01:29]  : Хорошая система искусственного интеллекта должна была бы проанализировать эту ситуацию и сказать, что, ребята, вы не спасете ничего, потому что смотрите, вот вам куча вариантов, альтернатив, при которых не улучшается ситуация. 

S00 [02:01:43]  : Видите ли, если ваша система скажет вашему руководству такую вещь, а моя система скажет, что вот при таких действиях улучшится ситуация, конечно, мою кучу. я согласен, что джинсы всегда побеждают и можно любую идеологию проповедовать. 

S03 [02:02:11]  : но молодежь пойдет покупать джинсы хоть и тресни мы и мы были когда молодые мы ездили на беговую может быть уже не так молод ну вот да поэтому сам так антон поднимал руку на самом деле да то есть я хотел вам в какой-то момент возразить но решил не отнимать время уважаемой аудитории но вот мои возражения тут уже накидали вот я просто зачитаю Вот, что с одной стороны робот. управления, который управляет космическим зондом или, значит, какой-нибудь робот, добывающий руду на каком-нибудь астероиде, ему приходится принимать решение, причем не только по постановке ног, ему приходится принимать куда как более сложное решение уровня того, которое человек принимает, шахтер принимает в шахте, а там робот ту же самую работу выполняет. И никто за него эти решения принять не может, потому что сигнал с земли идет очень далеко. Это вот дальний пример. 

S02 [02:03:09]  : Он же не влияет на общество. Он там что-то добывает, пусть добывают. 

S03 [02:03:13]  : Да. С другой стороны, светофоры не несут ответственности, но включаются и выключаются в зависимости от нахождения машин на дороге. Вот и штрафы выписываются людям тоже на основании данных с камер без всякого участия человека. 

S02 [02:03:32]  : Это про прошлое все. 

S03 [02:03:34]  : Не, ну как, они воздействуют на поведение людей в будущем. 

S02 [02:03:40]  : Простите, Антон, вот тот самый мудрый аналитик, который пришел к этому мудрому руководителю банка и рассказал ему, что произошло, воздействует на будущее решение этого руководителя. Естественно. 

S03 [02:03:55]  : Он просто их не диктует. Хорошо. Вот давайте все-таки насчет про ступенек. Я не буду с вами спорить. Я просто еще от себя принесу то возражение, которое я сделал. 

S02 [02:04:04]  : Я очень рад, что вызвал дискуссию. Да. 

S03 [02:04:06]  : Вот смотрите. Вот про ступеньки. Вы очень хорошо сняли с языка. Но вот у нас есть робот. Извините меня за аллюзию с наборевшей зубах вагонеткой, но вот у нас есть робот, у которого, как вы сказали, есть задача – спасти как много больше жизней. И вот он идет в дыму, в пламени, переставляет ноги по ступенькам. Вот, поднимается там наличную площадку, а там лежат задыхающиеся бабушка и там мальчик или дедушка и там девочка. Ему надо принимать решение, кого брать. У него должен быть алгоритм. Окей, там будет алгоритм, значит, нужно выбирать бабушку. Окей, может быть. Но у алгоритма тоже будет какой-то порог. То есть, да, решение будет делаться на основании какого-то порога, но это все равно будет решение, что вот это вот бабушка, и мы ее спасаем, и в итоге это повлияет на человеческую жизнь. То есть, мы можем Ну то есть, я хочу сказать, что когда дело доходит до математической реализации, то мы обнаруживаем, что в конечном итоге на уровне алгоритма разницы между выбором того, на какую ступеньку ногу ставить, и того, кого нужно спасать, а кого оставить на следующий раз, и он может быть погибнет, математической разницы нет, алгоритмической разницы нет. Это разница только 

S02 [02:05:33]  : с точки зрения нас когда мы интерпретируем те или иные действия все мой комментарий просто нет но я согласен с твоим комментарием абсолютно он абсолютно он абсолютно как бы правильный то есть вопрос касается того что такое принять решение содержится ли в акте принятия решения элемент свободной воли вот если вот в момент принятия решения задействован элемент свободной воли то есть задействована может быть задействована мораль может быть задействована какая-то там значит какие-то аспекты там какие-то сложные там нетривиальные и вот в этот момент на основе свободной воли принимается какое-то решение, вот в таких ситуациях машину допускать нельзя. То есть она должна действовать без свободной воли. Если у нее есть программа спасения количества людей процентов такого-то возраста, то она идет и тупо перебирает все подъезды этого дома, спасая в сумме пропорционально весам которые заложены количество людей разного возраста вот-вот как она должна действовать при этом при спасении каждого конкретного человека она должна предпринимать все варианты по адаптации не попадать под камень не споткнуться не забыть энергию там с собой перезарядить там и так далее так далее то есть то есть вот это вот но не должно быть свободной воли вот спасибо спасибо 

S03 [02:06:58]  : Согласен. Егизар, пожалуй, согласен с практической точкой зрения, с практической, юридической и социально-коммунитарной. 

S02 [02:07:08]  : Не померить иначе людей с интеллектом, иначе всегда будет с точки зрения одного он действует так, с этого так, и, в общем, это будет война вечная. 

S04 [02:07:15]  : Спасибо. Игорь Александрович, я вот хотел бы по той гипотезе о возможности однозначной интерпретации прошлого. 

S02 [02:07:31]  : Многозначной, там принципиально именно наоборот. Однозначная она уже произошла, та, которая была. 

S04 [02:07:37]  : вот интересно какие еще альтернативные могли бы быть прошлые если бы мы действовали по-другому многозначные это принципиально многозначные но все равно получается они зависят от посылки от позиции того кто хочет получить интерпретацию И невозможно хоть какая-то объективная интерпретация прошлого. Даже человек, когда вспоминает своё прошлое, это замеченные факты, делаются эксперименты, записаны факты, но при каждом воспоминании строит совсем другую теорию прошлого, как происходило. 

S02 [02:08:27]  : Да, но это будут частные мнения. То есть вот конкретно он сейчас в хорошем настроении построил одну модель своего прошлого, завтра он в плохом настроении или еще книжку прочитал, другую модель построил, с кем-то поговорил, тот на него повлиял, третью модель построил. Это все понятно. Я говорил совершенно о другом. Я говорил о ситуации такой. Вот произошла вчера какая-то проблема. Вопрос. Она могла бы не произойти, если бы. И дальше как максимально всесторонне изучить все аспекты. Можно ли было вчера избежать этой проблемы? Что надо было вчера сделать? И вот ответ на такой вопрос мог бы давать робот. Он же человек не может. Человек находится все время в состоянии доминанта. Вот вы совершенно правильно говорите. он все равно будет какие-то очень небольшие количество альтернатив рассматривать под воздействием своего всего культурного наслоения морали там всего чего угодно он не может от этого освободиться а нужен беспристрастный анализатор который может изучить все возможные потенциальные триллионы этих разных аспектов, которые были в прошлом и ответить на вопрос, можно ли было, например, что-то избежать или можно было бы достигнуть более хорошего или какого-то другого результата. 

S04 [02:09:43]  : Да-да-да, я так и понял. Большой вопрос возможности этой беспристрастности. Все равно необходимо будет настраивать эту систему АГИ под теории, концепции пользователя, кто хочет получить. 

S02 [02:10:06]  : Это очень принципиально. У этой системы нет цели. Вот вы сейчас говорите о системе целевой. Цель есть у разработчиков. У разработчиков, да, к сожалению, она есть. Это ничего не поделаешь. Но эта система должна быть свободна от цели. Когда проводится анализ... Хорошо, Володя. Вот вы занимаетесь математическим анализом. Вы построили модель функций непрерывной. проверить эту модель во всех точках невозможно, потому что их континуент, слава тебе господи. поэтому эту модель не проверяем. 

S00 [02:10:38]  : есть модель теорема отсчетов. 

S02 [02:10:41]  : теорема там, в общем, да. но прямо визуально она не проверяем. и вот алгоритм, который занимается построением модели непрерывной функции, проходящей через какие-то точки, он без пристрастия, но он не преследует никакой цели. его задача построить единственное решение, если оно здесь существует. К нему нет претензий к этому алгоритму. Никаких. Ни моральных, ни аморальных. Никаких. И проверять никто его не будет поточечно. Вот ровно примерно об этом я говорю. То есть вот тот самый беспристрастный аналитик, у которого нет личной цели. Никакой. У него есть цель максимально просто... Но, в общем, вы идеалист. 

S00 [02:11:17]  : Мы живем в стране, которая характерна своей непредсказуемой историей. У нас не только история непредсказуемая, но и настоящее состояние не определено. Другие считают, что у нас все в класс, но в России. Другие считают, что все очень плохо. будет еще хуже вот соответственно как я говорил один параметр то мы конечно можем посчитать смотреть все когда параметров много мы не можем начать не сами не с помощью машины не с помощью машины которые через сто лет будут созданы при условии что закон мура будет продолжаться она все равно не сможет смотреть все варианты Поэтому вот эти предсказания сложных систем, они всегда субъективны. По необходимости. И, соответственно, ваш этот реальный взгляд нам скажет, как на самом деле должно было быть. А на самом деле с той точки зрения. Понимаете? Потому что примеров просто куча. Знаете, врач, как известно, его чмутит, что не навреди. А каждый врач, если с ним стакан принять, он рассказывает, что кому надо в первую очередь не навредить. Себе не навредить. потому что если дашь врачу, пациенту что-то не по инструкции, то кому ты навредишь? Себе. А то, что пациенту навредит, ну зато другим поможешь. Вот. И тут вот, понимаете, все очень важно знать. 

S02 [02:12:34]  : Володя, совершенно правильно. Единственное, у меня вопрос только, вернее вопрос, а комментарий. Вот ты сказал большой текст, в котором я одно только слово хочу обратить внимание. Ты сказал все равно субъективно. Вот этот выбор, что анализировать, а что не анализировать, он может быть сделан формально, например, на основе теории Тихонова, а именно наилучшее решение на суженном пространстве. это не есть субъективность. Мы берем степень полинома, уменьшаем последовательно, вложено и все уменьшаем. Куча формальных способов. 

S00 [02:13:10]  : По какие параметры мы при этом игнорируем, какие не игнорируем? 

S02 [02:13:15]  : Володь, послушай меня. Вложенное пространство теория она известна. хорошо тебе известно и подможество там и так далее. ты тоже самое делаешь с нейронами. 

S00 [02:13:24]  : для одного там 5 или даже 10 параметров это работает. для 100 параметров нет. 

S02 [02:13:30]  : значит я далек от мысли что я предложил какой-то алгоритм. я сейчас не был алгоритмами предложил согласитесь. и даже не постановку задач. Я предложил некий взгляд, который может привести к способу, который бы позволил нам не пытаться интерпретировать систему искусственного интеллекта для тех задач, для которых они никогда не будут нашими друзьями. Они никогда не будут нашими союзниками. Они будут решать, если мы им будем ставить цели и давать свободу воли, они не будучи биологическим видом под названием человек никогда не будут нашим союзником. поэтому и не надо их туда пускать. вот это утверждение оно философски как бы даже мировоззренческий что ли характер носит. 

S00 [02:14:14]  : Это ваше субъективное мнение, а мое субъективное мнение, что все нормально. Замечательно. 

S02 [02:14:20]  : Вот, собственно, мы обменялись мнением. Да, но я рад, что оно произошло. 

S04 [02:14:25]  : Савелий Иванович, можно я еще одну короткую замечание высказать? 

S03 [02:14:29]  : Да, давайте Альгизару высказаться и Александру Балдачеву, и будем подводить уже итог. Спасибо, коллеги. Альгизар, пожалуйста. 

S04 [02:14:38]  : Здесь есть ловушка. Вы не случайно, по-моему, два раза именно и оговорили о формализации и формальной. Это именно возможно в областях, в которых возможна строгая формализация. И эта ловушка, многие на нее попадают, что если я могу формализовать в какой-то математике, физике, в каком-то процессе физическом или наблюдении в каком-то реакторе, если я могу предсказать, стечение обстоятельств и событий, это все описать и получить математическую модель, то, значит, возможно такая модель АГИ, которая сможет нам помогать в каких-то уже жизненных ситуациях, где присутствуют не только законы, механики, математики, строгие формулы, но где участвует еще человек как субъект. И как только человек включается в этот процесс, уже само течение и объяснение этого самого процесса приобретают форму неформальную. Там уже невозможно получить какую-то объективную картину, с которой согласятся несколько субъектов, независимых субъектов или даже один и тот же субъект, находящийся в разных позициях по времени или в контекстах. Я согласен, но это опасная ловушка и на нее многие опираются. 

S02 [02:16:17]  : Только я не согласен словом ловушка. Это аспект неопределенности, который нужно учитывать. Это не ловушка. Только наивный школьник скажет, что я сейчас напишу уравнение из квадрата равного А и это уравнение опишет Луну. ему скажешь, ну ты попал в ловушку, она реальная, а твое уравнение какое-то абстрактное. это не ловушка, это просто фактор, который обязательно нужно учитывать. то есть наличие людей в цикле принятия решений, это естественно это же социальное будет явление, это прежде всего социальное явление и врачебные какие-то явления, конечно там есть люди. Я же далек от мысли создать теорию, которая формулами опишет все варианты. Мне не надо их воспроизводить. Мне нужно сказать на вопрос, что могло бы быть. Но спасибо большое, что обратили внимание, что человек всегда неустраним из цикла. Из любого такого анализа он неустраним. Его влияние непредсказуемо, неформализованно. Это абсолютно точно совершенно. Это понятно. И даже никто не пытается это сделать. конечно это означает что такие как вещи как социальные какие-то системы они всегда будут эти все предсказания они вернее не предсказания эти вот описание что ли как назвать они всегда будут значит не полными там всегда можно там предположить, что будет кто-то там с дубиной, который там нарушит всю там логику и так далее. да, конечно, это действительно так и есть. спасибо большое. 

S00 [02:17:40]  : я только хотел подобать, что может быть у них не очень получается, но маркетологи всегда выделяют фокус-группы и прекрасно планируют вашу реакцию. может быть они не всегда попадают, но по крайней мере они пытаются. 

S02 [02:17:53]  : Да, поэтому я не беру телефон. 

S03 [02:17:55]  : Да, коллеги, спасибо. Давайте Александру дадим возможность еще высказаться. Александр, пожалуйста. 

S01 [02:18:01]  : Я, конечно, на стороне Сергея Александровича. И по многим параметрам и причинам. Ну, прежде всего, нужно понимать, пока мы живем в социуме, пока есть гекоэкспреденция и законодательство, то есть ответственность за любые действия. И на данный момент, и я думаю, что еще очень долго, ответственность всегда должен нести человек. Когда мы сможем включить робота в законодательство и как-то решить эту проблему, что нести ответственность может быть машина, и как она может быть наказана, не наказана, пока эта проблема не решена, то есть вообще обсуждать нечего. Всегда будет человек. И в некоторых случаях решение человека можно перенести на плечи машины, как Антон сказал по поводу шифрования камеры. Когда у нас есть однозначный датчик, которому мы доверяем, который фиксирует скорость, он выписывает штраф. То есть решение принимает человек, который запрограммировал. Все равно человек принимает. Если он неправильно запрограммировал, нести бы человек, не датчик. Раньше стоял регулировщик и сам решал, в какую сторону ехать машинам. Потом поддоверили светофору. Мы доверились этому алгоритму, и уже человек не принимает никаких решений, принимает решение автомат. И как-то год-полтора назад я сказал такую фразу, помню, что Сергею Александровичу она очень понравилась, что если у вас есть желание заместить человека роботом, заместить человека машиной на каком-то рабочем месте, то лучше просто убрать с этого рабочего места человека. То есть нельзя замещать человека. Нельзя замещать. Нужно просто автоматизировать, выбросить оттуда человека. И это будет по-другому. То есть я помню, что это я рассказывал, когда говорил про машины, управляемые искусственным интеллектом, и которые заменяют человека и пытаются разглядеть. плохие, забрызганные грязью, знаки, жесты водителей, сложную обстановку. То есть здесь нельзя заменить человека, потому что он принимает решение, несет ответственность, если он задавил. 

S02 [02:20:22]  : А вот как решить все проблемы? Александр, мы тогда говорили о том, что надо создавать новые процессы, в которых с самого начала нет человека. 

S01 [02:20:28]  : Да, да, нужно создавать новую деятельность, в которой не будет знаков. в которых не будет жестов, которая будет управляться полностью автоматически. Можем себе представить, скажем, когда мы транспорт убираем под землю, жесткие рельсы и жесткое регулирование автоматическое. Вполне это возможно сейчас сделать. Все проблемы, которые у нас связаны сейчас с вождением автомобиля, связаны с тем, что мы автомобиль сделали а-ля повозка с лошадью. Вот мы, как бы он был, четыре колеса, поставили двигатель и водим, поставили человека. Только вместо этого человека, то есть вместо лошади поставили двигатель, но вместо человека не нужно ставить робота. Нужно убрать телегу вообще, убрать телегу и решить проблему транспорта, перемещения груза из точки А в точку Б, человека из точки С в точку Д. Просто решить проблему иначе, автоматизировав. И точно так же, как я говорил с атомной станцией, не нужно ставить вместо человека, который следит за какими-то лампочками и что-то там принимает решение робота, а нужно автоматизировать сам процесс, где это возможно. А вот где нужно принять решение, там пускай принимает решение человек. И здесь я полностью согласен с Сергеем Александровичем, что нужен консультант, И чаще всего, заметьте, у людей тоже так. Самые умные люди, самые толковые, самые интеллектуальные, решающие сложные задачи, они никогда не принимают решения. Они являются серыми кардиналами, они являются консультантами. А принимает решение обычно среднего ума человек, который берет на себя ответственность, который имеет какие-то опыты автоматического регулирования себя и ситуации. А умный человек начнет думать, а если так, а если это, так робот тоже начнет думать. Поэтому не нужно интеллект встраивать в принимание решений. Вообще интеллект, любой, машинный, человеческий. Принятие решения – это совершенно отдельная профессия. 

S03 [02:22:28]  : Хорошо. Александр, спасибо. Коллеги, я предлагаю на этой высокой ноте закончить. Я очень рад, что мы не дошли до технологии. 

S00 [02:22:36]  : Я бы пару слов только сказал. Что-что? Все-таки некоторый идеализм в этом представлении присутствует. То есть на самом деле решение принимают не те, кто готов принимать эту ответственность, а тот, кто знает, как от нее уйти. Вот они как раз и идут принимать ответственность за свои решения. Никто никогда ответственности не сделает. Это во-первых. А во-вторых, история, допустим, развития лифтов, она, собственно, какая? Что сперва, помните, ездили с лифтером. А потом сказали, а зачем лифтер? Так будем ездить. И не значит, чтобы лифт стал безопасным. В России каждый год погибает 30-40 человек в лифтах. И ни разу производители за эту ответственность не понесли. Никто производить лифты не перестал. И с автомобилями там все еще хуже, конечно. Там погибают не десятки, а тысячи человек. И от того, что это автоматизируют, влияет на это. Все-таки я хотел бы Сергею Александру обратить внимание, что их взгляд очень идеализирован, что они ставят, что человек никогда не сравнится с автоматом. Ну, в каких-то вопросах может быть, но есть много вопросов, где автоматы прекрасно заменяют человека, и лифты работают в среде с людьми, и людей возят, и ничего как-то работает. 

S03 [02:23:48]  : Хорошо. Коллеги, у нас уже закончилось время. Большое всем спасибо. Я очень, опять-таки, рад, что у нас неожиданно получилась дискуссия, несмотря без практической демонстрации прототипов работающего AGI, но, тем не менее, с серьёзным обсуждением возможностей, условий и рамок практического применения гипотетического AGI. И очень хорошо, что мы не дошли до обсуждения терминов и говорили по существу. Коллеги, всем большое спасибо. У нас, кстати, практические результаты будут представлены через семинар. Виктор Уртюхов будет рассказывать, чего он достиг в своем проекте АГИФа. А в следующий четверг у нас Евгений Павловский будет рассказывать про квантовое вычисления в области искусственного интеллекта и искусственный интеллект, основанный на квантовых вычислениях. Всем до встречи и всем спасибо за участие в сегодняшнем обсуждении. Всего доброго. 

S02 [02:24:49]  : Спасибо. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
