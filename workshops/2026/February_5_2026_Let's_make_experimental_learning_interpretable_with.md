# 5 февраля 2026 - Сделаем экспериментально-опытное обучение ... интерпретируемым (с подкреплением и без) пожизненно! - Антон Колонин - семинар AGI
[![Watch the video](https://img.youtube.com/vi/joEFrLvWyfs/hqdefault.jpg)](https://youtu.be/joEFrLvWyfs)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239243)
- [видео в Telegram](https://t.me/agitopics/53344/69326)
- [видео в RUTUBE](https://rutube.ru/video/ea4e7b7015502d3ef4e680558f3d28fd/)
- [презентация](https://github.com/aigents/iai/blob/main/docs/2026/interpretable_experiential_kolonin_ru.pdf)
- [расшифровка](https://github.com/agirussia/agirussia.github.io/blob/main/workshops/2026/February_5_2026_Let's_make_experimental_learning_interpretable_with.md)
- https://arxiv.org/abs/2509.07009
- Making experiential/reinforcement learning interpretable life-long!
---

## Основные тезисы доклада

### Часть 1: Интерпретируемое обучение на основе опыта (Experiential Learning)
Докладчик представил результаты работы над проектом, нацеленным на решение проблем классического обучения с подкреплением (RL): медленного обучения, катастрофического забывания, отсутствия объяснимости и энергоэффективности.

*   **Концепция:**
    *   Используется подход **Experiential Learning** (обучение на опыте), где подкрепление — лишь частный случай опыта.
    *   Архитектура базируется на **системах Канемана**: Система 1 (быстрое, интуитивное, подсознательное) и Система 2 (медленное, рассудочное, символьное).
    *   **Нейро-символьная интеграция:** Использование тензорной логики (по идеям Педро Домингоса), позволяющей описывать символьные знания и нейросети в едином математическом формализме.
    *   **Ключевое решение для непрерывного обучения (Lifelong Learning):** Хранение в тензорах не только значений, но и степени уверенности (evidence/confidence). Это позволяет системе понимать, насколько представительна выборка (видел одну зебру или миллион лошадей), и избегать перезаписи важных знаний новыми случайными данными.

*   **Эксперименты (игра Pong/Arkanoid):**
    *   Агент обучался играть, получая на вход либо пиксели, либо координаты объектов.
    *   **Результат:** Обучение на уровне объектов (координат) требует на порядки меньше ресурсов и времени, чем работа с пикселями, при той же эффективности. Агент смог превзойти по очкам запрограммированного робота-эксперта.
    *   **Инновация:** Система учится не только на наградах, но и запоминает переходы между состояниями (граф состояний), что позволяет обучаться быстрее (One-shot learning для маршрутов).

*   **Применение в промышленности (АСУ ТП):**
    *   Предлагается использовать интерпретируемый ИИ в промышленности, где классические нейросети («черные ящики») запрещены.
    *   ИИ может работать параллельно с контроллерами, обучаться на действиях операторов и предлагать оптимизацию логики (суперкомпиляция) или предупреждать об аномалиях, не вмешиваясь в управление напрямую до момента верификации.

### Часть 2: Архитектура на основе социального доказательства
Вторая часть доклада посвящена моделированию агентов, действующих в социальной среде (для персональных ассистентов или управления коллективами).

*   **Структура:** Используется четырехдольный граф:
    1.  Абсолютные истины (онтология).
    2.  Социальный граф (связи и доверие между агентами).
    3.  Граф фактов (evidence) с привязкой к источникам.
    4.  Граф воображения (расчет вероятностей/ожиданий).
*   **Результаты симуляций:**
    *   В группе с **низкой социальной открытостью**, но высокими когнитивными ресурсами происходит **кластеризация** (образование эхо-камер, группы расходятся по интересам).
    *   В группе с **высокой открытостью**, но ограниченными когнитивными ресурсами происходит **слияние** (консенсус, «единая религия»), но часть знаний утрачивается.
    *   Подтвержден психологический **эффект новизны (recency effect)**: при принятии группового решения мнение последних высказавшихся весит больше.

### Дискуссия (Q&A)
Участники обсудили ряд философских и технических вопросов:
*   **Система 1 vs Система 2:** Обсуждалось обучение вождению. Сначала процесс идет через сознание (Система 2), затем «закачивается в подкорку» и становится автоматическим (Система 1).
*   **Врожденное vs Приобретенное:** Пример с кошкой с перерезанным спинным мозгом (ходит по движущейся ленте рефлекторно) и жеребенком (встает сразу после рождения). Вывод: некоторые модели «преконструированы», но требуют дообучения.
*   **Сны и сознание:** Является ли принятие решений во сне работой Системы 1 или Системы 2? Гипотеза о том, что во сне мы можем не принимать решения, а лишь наблюдать сгенерированный видеоряд о принятии решений.


## Расшифровка доклада:


S01 [00:00:01] : Коллеги, всем добрый вечер. Перед началом сегодняшнего семинара я сделаю небольшой анонс, который будет в конце этого семинара. Дело в том, что мы с вами присутствуем на уникальной площадке, которая исключительно в основе самоорганизации уже более пяти лет проводят практически еженедельные семинары, посвященные тематике общего и сильного искусственного интеллекта, но несмотря на Интересные дискуссии и доклады, которые у нас здесь случаются, мы решили создать более такую узкую, более целенаправленную на именно содержательную разработку общего и сильного искусственного интеллекта группу, где, собственно, авторы проектов смогут общаться с другими авторами проектов уже более содержательно и предметно. И в конце этой встречи я сделаю некоторые дополнительные анонсы и еще более подробный анонс будет через несколько дней у нас в группе. Вот, а сегодня я давайте расшарю экран и сегодня я попытаюсь сделать своеобразный отчетный доклад, чем я занимался этой осенью и расскажу про последние результаты двух проектов. Оба этих проекта я представлял на наших семинарах. Один проект, посвященный когнитивной архитектуре на основе социального доказательства и ресурсосбережения, я делал в прошлом году. Доклад, посвященный искусственной психике, мы с Владимиром Крюковым делали в этом году. Ну и сегодня я расскажу самые последние результаты в развитии этих двух проектов. У меня будет просьба, поскольку материала очень много, если вдруг возникнет ощущение, что я где-то говорю слишком очевидные вещи, то просьба смело... включается и говорит, что тут наверное можно проехать, пропустить и промотать вперед. А если наоборот будут какие-то вещи, которые будут неочевидны и потребуют пояснения, то опять-таки можно меня спокойно тормозить и я буду заостряться на соответствующих моментах. Итак, первый проект или первая часть доклада будет сделана под лозунгом «Сделаем экспериментально-опытное обучение интерпретируемым пожизненно». О чем идет речь? о том, что концепция того, что сейчас выросла из так называемого обучения с подкреплением или Reinforcement Learning, на самом деле первый раз я с этой концепцией столкнулся 25 с лишним лет назад, когда понятия Reinforcement Learning еще не было, и в проекте Бена Герцеля «WebMind» 1997 по 2001 год, который существовал было понятие experiential learning, то есть обучение на основе собственного опыта, где собственный опыт совершенно не обязательно подразумевает подкрепление. подкрепление это только частный случай опыта и агент или субъект или система обладающая искусственным или естественным интеллектом может учиться не обязательно подкрепление да то есть она может просто запоминать какие-то значимые последовательности и строить на основе их модели среды для осуществления своей деятельности она может В случае адекватности этих моделей и сильной и достаточной предсказательной способности этих моделей, сама себя гладить по головке и говорить, ой, молодец, ой, какую хорошую модель построил, как хорошо все предсказал, значит, сама на тебе конфетку сам себе. Ну и, наконец, действительно, может быть и в явном виде или не явном подкрепление со стороны окружающей среды. Вот, соответственно, подкрепление на собственном опыте в общем случае является тем, что сейчас, кстати, этот термин снова вернулся и появились статьи уже, которые так и называются Experiential Learning. Мы статью про Experiential Learning написали 2020 году я на эту статью сегодня буду ссылаться. Вот, то есть термин сейчас снова пошел в массы. Вот, ну и не говоря о том, что даже существующие решения на основе reinforcement learning они используют понятие implicit reward и explicit reward, где implicit reward это явная награда, которая вот конфетка, которую тебе среда дала за то, что ты такой молодец, вот, а implicit reward это те награды, которые агент сам себе дает, если, допустим, он хорошо предсказывает, если его модель хорошо предсказывает реакции или поведение окружающей среды, или наоборот, если агент открывает какие-то новые явления. Значит, на что, на решение каких проблем направлен Тот проект, о котором мы сегодня будем говорить в первой части доклада. Во-первых, это проблема медленного обучения. То есть, допустим, если мы решаем проблему reinforcement learning методом deep pool learning, то нам требуется огромное число итераций, большое число вычислительных затрат для того, чтобы, повторяя одно и то же действие, обучались правильному поведению. Вот мы не можем, допустим, получив правильную инструкцию один раз или узнав откуда-то правильную инструкцию один раз, сразу же ее выполнять в подходящей ситуации. Нам нужно, чтобы эта инструкция повторилась или эта ситуация появилась несколько раз. Дальше, мы не можем объяснять свои решения, то есть если мы построили какую-то модель в результате тренировки, мы получили там какое-то количество параметров в какой-то нейросети, но мы не можем понять, почему вот если ситуация оказывается такая, то рекомендуется такое действие. И почему? И опять-таки на сегодняшний день есть два понятия в области того, что называется объяснимый искусственный интеллект или интерпретируемый искусственный интеллект. Есть понятие глобальной интерпретируемости, есть понятие локальной интерпретируемости. Локальная интерпретируемость – это то, что называлось и сейчас еще называется объяснимый искусственный интеллект или explainable AI. То есть локальная интерпретируемость – это когда для конкретного случая мы можем объяснить, вот сейчас принято такое-то решение, вот потому что такие-то, такие-то фичи были обнаружены вот в такой-то, такой-то ситуации, и вот поскольку эти фичи, они так-то связаны с таким-то решением, вот мы рекомендуем то-то и то-то. А глобальная интерпретируемость, она позволяет интерпретировать модель в целом, она позволяет вообще сказать, а какие у нас есть фичи, какие у нас есть действия, какие у нас есть варианты соединения этих фич с этими действиями, с тем, чтобы мы до того, как модель нам что-то рекомендует, скажет или сделает, чтобы мы заранее могли понимать вообще, что эта модель знает и что она умеет. Следующая проблема, это проблема катастрофического забывания, когда мы натренировали модель на что-то, а потом, значит, так она оказалась в другой ситуации, научилась вести себя как-то в другой ситуации, а потом, когда она оказалась в передней ситуации, она это забыла, например, потому что у нас недостаточно большая глубина или толщина или ширина нейросети, и у нас новое обучение на новых данных перетирает старые данные. Ну и последняя проблема – это проблема энергоэффективности, потому что если, допустим, нам для того, чтобы научиться там решать какую-то задачу прикладную, которая требуется, требует решения в полевых условиях или там на мобильном телефоне или на каком-то компактном и малогабаритном промышленном оборудовании для обучения и решения этой задачи требуются графические карты, которые требуют большого энергопотребления, то мы не можем применять эти методы, существующие методы обучения с подкреплением, которые требуют больших вычислительных затрат. Прежде чем двинуться дальше, мы зафиксируем некоторое определение. Базовое определение Бена Герцеля, а также Пи Ванга, Шейнлегга и Маркуса Хуттера, что интеллект – это достижение сложных целей в различных средах, в условиях ограниченных ресурсов. Когда мы интерпретируем это определение, мы полагаем следующее, что если мы говорим о сложной цели, мы говорим о том, что цель – это вектор. То есть нам нужно не одну функцию целевую удовлетворить, а некоторую суперпозицию целевых функций. То есть у нас в векторе может быть, допустим, такая потребность как удовлетворение голода, потребность как воспроизведение потомства, потребность как комфорт. Ну и нам, соответственно, нужно максимизировать некоторую комбинацию значений этого вектора. Для того, чтобы решать задачи в условиях ограниченных ресурсов, нам нужно бороться со сложностью. Если среда сложная, то для того, чтобы обсчитывать все параметры этой среды, нам нужно много ресурсов. А если мы сможем упростить эту модель, редуцировать количество переменных к меньшему числу, понизить размерность пространства, в котором мы описываем модель, мы будем задачу решать более эффективно. Опять-таки, если мы хотим делать это в разных средах, то мы должны, в принципе, иметь возможность не терять информацию, которую мы приобретаем в новых условиях. То есть, грубо говоря, если мы выучили какое-то поведение и затратили на это какое-то количество памяти, если нам нужно обучиться новому поведению, А память уже занята тем подсуществующим поведением, мы не можем просто переписать эту память новыми ситуациями, новыми действиями, мы должны иметь возможность наращивать память. Хотя, естественно, с точки зрения ограниченности ресурсов, мы должны возможность и забывать. То есть, если слишком много информации возникает, если слишком много ситуаций мы должны поддерживать, то и ресурсов по памяти у нас недостаточно, мы должны иметь возможность как-то поджаться, либо, допустим, забыть то поведение, которое у нас не востребовано, либо, если оба поведения востребованы, то как-то поджать точность обоим видом поведения чтобы мы могли и то и другое делать но может быть не так точно не так эффективно И, кстати, что важно, что в качестве точки, так сказать, в изложении и в постановке Пи-Ванга под ресурсом подразумевается не только количество тех ресурсов, которые мы сжигаем для решения той или иной задачи, а и временной ресурс, потому что временной ресурс предполагает, что если есть задача, допустим, по принятию решения. Если мы, например, работаем в рамках какой-то промышленной системы, где есть определенное требование на быстродействие и при выдаче управляющего сигнала в ответ на какое-то состояние среды должна быть осуществлена в течение 100 миллисекунд, к примеру, то В течение 100 миллисекунд мы должны принять какое-то решение. Оно может быть не супероптимальное, оно может быть субоптимальное, но решение должно быть принято. В рамках концептуального и архитектурного фреймворка мы рассматриваем следующую модель, которая была летом в прошлом году представлена нами с Владимиром Крюковым. То есть мы имеем некоторую систему, это может быть искусственная система, это может быть естественная система, некоторый интеллектуальный агент. внутри которого есть то, что мы называем психикой. Психика, на самом деле, это просто система принятия решений, которая принимает решения в рамках некоторого пространства-состояний, которые как раз и описывают вот ту среду, в которой эти решения принимаются. То есть, пространство-состоянии, может быть, это, по сути, некоторое пространство переменных. Эти переменные могут быть, условно говоря, разделены на три категории. Первая категория – это некоторые ощущения, которые агент воспринимает посредством восприятий, получаемых сенсоров, которые собирают эту информацию из внешнего мира. Это некоторые потребности, которые агент удовлетворяет, или некоторые целевые функции, которые либо заложены эволюцией, либо запрограммированы оператором, либо они могут на самом деле возникать в процессе функционирования самого агента, как некоторые промежуточные потребности, которые агент формирует сам, понимая, что удовлетворение этих потребностей в краткосрочной перспективе позволит удовлетворять более долгосрочные потребности или целевые функции в долгосрочной перспективе. И, наконец, это действия, выполнения которых или невыполнения которых агент фиксирует в процессе взаимодействия с окружающей средой. Каким образом Агент работает в этой схеме. Информация воспринимается через сенсоры, попадает в значения переменных, которые в пространстве состояния описывают ощущения. Соответственно, есть текущее состояние вектора потребности. Да, естественно, ощущения, потребности, действия – это все вектора, потому что одновременно мы можем ощущать много всего, хотеть много всего, и действий можем совершать одновременно массу. Соответственно, в зависимости от того, какие ощущения потребности у нас есть, возникает некоторая эмоциональная потребность принять какое-то решение. Это решение принимается либо подсознательной системой, системой одинка, немана, так называемая, интуитивная, которая позволяет принять решение быстро, если решение хорошо соответствует какому-то имеющемуся опыту. Если же быстрое решение интуитивно не принимается, то включается система 2, которая медленно и верно пытается подобрать оптимальный сценарий поведения, включается так называемое рассуждение, и система принимает решение. Соответственно, система говорит, что вот нам нужно, вот мы приняли такое решение, нужно вот двинуть такой рукой или такой ногой. Соответственно, эти решения передаются на актуаторы. Ну и в пространство состояния передается вектор ожиданий того, что эти действия будут совершены. Соответственно, если эти действия действительно совершены, то это может быть некоторая обратная связь, которая позволит зафиксировать, что соответствующие действия совершены. Значит, концепция быстрого и медленного мышления, она хорошо ложится на концепцию многоуровневого интеллекта Марвина Мински, представленного на этой схеме, где показана вот некоторая иерархия, что мы идем от некоторых нижних уровнях Начиная с нейросетей и того, что нарвомински называют keylines, а в коре головного мозга это, по-видимому, соответствует колонкам. Дальше у нас идет уровень некоторых семантических сетей и того, что Анохин называет гиперсетями или гиперграфами. Вот. Дальше у нас возникают некоторые как раз переходы из состояния в состояние, о которых мы сегодня как раз больше всего будем говорить. То есть то, что Минский называет «трансфреймс», значит, некто пикчо-фреймс. Вот каждый пикчо-фрейм – это некоторая картинка, виртуальная картинка некоторого состояния. состояние, да, картинка условно, да, потому что картинка может быть звуковая, картинка может быть аудио, картинка может быть сенсорная, то есть некоторая комбинация сенсорных входов и некоторое состояние в пространстве состояний, вот, и из одного состояния в другое есть переходы, а все эти цепочки переходов, они могут соединяться в то, что Минский называет narrative stories, или истории, или последовательности, которые вот описывают уже некоторые сценарии поведения. И взаимодействовать, и работать с окружающей средой в этой картинке мы можем либо в медленной системе, в быстрой системе, извиняюсь, на нижнем уровне, когда у нас на вот этом вот нижнем уровне уже натренированы или накачаны какие-то стимулы на какие-то реакции, на какие-то стимулы. Вот это система быстрого принятия решений, но медленного обучения. Либо мы, если на этом уровне решения не принимаем, мы делаем это на верхнем уровне. Соответственно, если у нас есть какие-то правила, которые мы на уровне правил и в ДНЛ-сов каких-то, либо каких-то сценариев поведения, допустим, там, значит, садимся в машину, сперва выжимаем, смотрим в левое зеркало, потом выжимаем сцепление, потом, значит, включаем передачу, потом выжимаем сцепление, давим на газ. мы эту поведенческую схему один раз услышали, потом можем многократно воспроизводить. Соответственно, быстрое обучение, но медленное исполнение, потому что для того, чтобы быстро исполнять, надо натренироваться, чтобы это работало на уровне безусловных рефлексов, условных или безусловных рефлексов. Значит, по-другому немножечко на эту двухуровневую систему можно посмотреть с точки зрения представления любой информации, с которой мы работаем на уровне некоторой когнитивной системы в терминах-графах. То есть, предположим, что у нас все, что мы знаем, что мы умеем формируется и хранится в некоторых графах, Вот. И то, что Kaniman называет «системой один» или на английском языке называется «subsymbolic reasoning», это находится где-то на нижнем уровне, где вершины графов не размечены и ребра графов не имеют лейблов или этикеток, то есть это подсознательное знание, знание, которое мы не осознаем, что знаем. то на верхнем уровне у нас находится осознанное знание или символиное знание. Это то, что является предметом действий системы 2. Система, где мы знаем, что мы знаем, потому что мы знаем, как это называется, и мы можем назвать любые элементы знания своими словами и любые правила можем выразить с помощью либо слов, либо диаграмм, либо каких-то табличек, либо стрелочек в какой-то формализованной системе и осознанно принимать какие-то решения. Идея так называемой нейросимвольной интеграции или соединения вот этих двух систем, показанные на вот этой картинке, она была опубликована в нашей статье, по-моему, лет пять назад, вот, на конференции EJI-20, по-моему. Что здесь нарисовано? Здесь нарисовано, что мы можем одно и то же знание, в данном случае это знание классификации животного, в данном случае по некоторым признакам, оно может быть при одной и той же структуре закодировано двумя разными способами, грубо говоря. С левой стороны мы берем некоторую нейросеть с двумя скрытыми слоями, четырехслойную, и некоторым образом с помощью некоторых коэффициентов, то что называется параметры нейросети, кодируем связи между некоторыми нейронами, в данном случае суммирующими, и некоторые, вот здесь даже написаны веса этих нейронов, и если мы пытаемся проследить и поскладывать веса этих нейронов в зависимости от наличия копыт, хвостов и цветов, которые мы видим на картинке, мы можем убедиться, что правильное сложение этих нейронов при пороге возбуждения около единички дадут нам выстреливание вот этого нейрона, который нам скажет, что мы на картинке видим лошадь. Но то же самое мы можем описать с помощью логической системы. То есть в данном случае скобочками мы описываем некоторое логическое выражение в стиле, допустим, в некоторой беспоподобной записи. Так, сейчас, секундочку, кажется, почему-то не могу убрать. Ладно, край экрана почему-то не виден. Мы можем описать вот это знание о том, что лошадь это то, что имеет копыта и хвост, и не является красным, а является либо белым и черным, либо является коричневым. Мы можем написать некоторое логическое выражение, которое в зависимости от входных переменных формирует некоторую иерархию предикатов с коньюнсами и дизюнсами. Более того, мы можем эти предикаты снабдить некоторыми вероятностными оценками. То есть мы можем ту же самую логическую запись сделать не символно-логически, а вероятностно-логически, как это делается, допустим, в вероятностной логике Евгения Витяева или вероятностной логики Бена Герцеля или в неаксиматической логике Пейванга. Эта картинка предполагает, что мы можем формировать знания в виде символьных систем, ассоциативных систем, системы 2 и 1, и мы можем между ними как-то эти знания передавать. мы говорим, что если мы выучили медленно и печально тренируя нейросеть, получили некоторые параметры, то мы из них можем извлечь некоторое символьное представление, таким образом осуществив глобальную интерпретируемость нейросетевой модели, а также мы можем символьное представление тоже каким-то образом выучив загрузить в нейросетевое представление, таким образом осуществив трансфер ленинг и символьного представления в ассоциативное. Вот эта концепция, долгое время непонятно было, как ее реализовывать, и вот в конце прошлого года, точнее осенью прошлого года вышла замечательная работа Петро Доминкоса, которая называется «Тензорная логика. Язык искусственного интеллекта». где товарищ Петро Домингес показывает, что можно создать некоторый формализм математический, в терминах которого можно описать как любые символьные логики, начиная с программ на прологе. кончая любыми нейросетевыми архитектурами, включая самые современные трансформеры. И это все делается в рамках одного математического формализма, в рамках одного и того же языка. И это хорошо ложится на то утверждение, что на самом деле, когда мы говорим о нейросетях, А когда мы говорим о нейросетях, мы на самом деле говорим о тензорах. А когда мы говорим о многослойных сетях, мы на самом деле говорим о некоторых тензорных представлениях. И мы можем говорить о том, что это эквивалентно графам. Если у нас вершина графа – это некоторое измерение, ребро графа – Вектор, а сам гиперграф просто является тензором. Его здесь показано, как мы можем с точки зрения тензоров справа, так и с точки зрения графов слева описать некоторую гетерархию лингвистических знаний, с помощью которых строятся языковые модели. Вот, что интересно, и этого явно нету в работе Петра Домингоса, но вот эта идея, она в общем напрашивается. Интересно то, что если мы описываем некоторую структуру тензорном пространстве, где эта структура может описывать некоторую символную логику, а-ля Пролог или там некоторая конструкция Ивда Нелса. И в этой ситуации у нас значение тензоров является булевыми. То есть, если мы, к примеру, описываем ту же самую лошадь, и у нас двумерное пространство, где по горизонтали отложено животное, а по вертикали некоторые свойства, допустим, полосатость, то вот конкретная точка булевская в этом двумерном пространстве будет нам говорить, либо лошадь полосатая, либо она не полосатая. Но и в данном случае, поскольку большинство лошадей на свете не полосатых, в терминах этой булевской логики, у нас значение в этой точке будет false. А если мы возьмем и натренируем нейросеть на большом количестве лошадей со всего мира, размеченных на полосатость, то мы получим тоже в этой точке некоторое численное значение. В зависимости от того, как мы это кодируем, то ли мы это в вещественной точке кодируем, то ли целыми числами, то ли четырехбитовыми числами, то ли двухбитовыми числами. У нас будет некоторая численная оценка, и здесь полосатость лошади будет обозначаться некоторым числом. С плавающей точкой или с фиксированной точкой, но вот некоторая оценка будет. Причем, что интересно, если мы начнем заниматься Нейросети сначала до 8 битов, потом до 4 битов, потом до 2 битов. Если мы в какой-то момент понизим до 1 бита, мы на самом деле получим то же самое булевское тензорное пространство, которое является просто логическим. Но это не самое интересное. Самое интересное, что мы можем вот эти вот точки в этом тензенном пространстве записывать на самом деле распределение того, а какие у нас на самом деле есть в данном случае лошади, полосатые или не полосатые. Например, если мы знаем, что у нас из всех лошадей, которые есть на свете, 60 миллионов лошадей не полосатые, а 750 тысяч полосатые, являются зебрами, то мы на самом деле можем получить как вот это число, 0,01% зебр. Так и на самом деле оценку того, насколько представительно у нас это измерение. Представьте себе, что мы, допустим, сходили бы в зоопарк и увидели там одну зебру и одну обычную лошадь, и ни разу бы не были бы нигде на природе, где бы видели лошадей. После посещения такого зоопарка, где есть одна зебра и одна лошадь, у нас было бы один и один. И, соответственно, во-первых, здесь было бы 50, а во-вторых, evidence, или доказательная база, или доказательность, или уверенность, или confidence, как это называется в концепции Пи и Ванга, про которые сейчас мы еще поговорим. оно было бы очень низкое. И одно дело, когда мы изучили 60 или там 61 миллион лошадей и знаем вот эту вот оценку, либо мы изучили там 2 или 3 лошади в своей жизни и делаем какие-то заключения. И вот как раз вот эта вот возможность записывать уверенность или представительность, или, так сказать, evidence, доказательность полученной информации, вот вершины или точки вот этого векторного пространства, в моем понимании, как раз является ключом к решению проблемы lifelong learning. Потому что у нас обучаемость различных точек векторного пространства и различных параметров сети будет зависеть от того, насколько полно мы знаем распределение включенности или выключенности тех или иных измерений, которые использовались при оценке этой точки. Вот пример того, как это работает в вероятностной логике Пиванга. Предположим, у нас есть некоторый вероятностный граф, где мы пытаемся соединить плохое питание с ослаблением иммунной системы, с инфекцией и с простудой. И предположим, что у нас есть некоторые клинические записи о том, что в 60 случаях из 100 плохое питание было связано с инфекцией, в 90 случаях из 100 ослабление иммунной системы было связано с инфекцией, и в 9 случаях из 10 плохое питание было связано с ослаблением иммунной системы. Ну и так далее. И в этом случае мы можем оценить на самом деле не только вероятность, 0.9, 0.6, 0.9 и 0.6. Значит, вот этих связей между различными понятиями и временем. Но мы можем оценить еще и confidence. То есть, допустим, вот здесь вот у нас confidence низкий, потому что всего 100 записей. Вот здесь вот у нас конфиденц низкий, потому что всего 10 записей. И вот здесь вот у нас конфиденц низкий, потому что тоже всего 10 записей. А вот здесь вот у нас конфиденц высокий, потому что 100 записей. И, соответственно, вот в системе вероятностной логики Пиванга оценка Вероятности отсутствия вообще не рассматривается, у него есть понятие, как бы два разных понятия. Есть понятие силы вероятностной связи и уверенности этой вероятностной связи. И, собственно, логический вывод идет в пространстве этих двух понятий. Переходя к концепции, в рамках которой мы сейчас развиваем систему и к экспериментам, которые дальше будут показаны, напоминаю, что мы строим систему на основе некоторых последовательностей состояний, где мы можем брать некоторый набор состояний из прошлого, где состояние каждое, повторяюсь, состоит из ощущений и потребностей с действием. И мы можем фиксировать, к каким новым состояниям это приходит. И анализируя взаимосвязь, возможные переходы из прошлых состояний в будущее, некоторым образом вычислять то, какие для нас состояния в прошлом могли, во-первых, имели место быть, то есть мы знаем свое прошлое, мы можем зафиксировать, в какие состояния мы могли переходить из тех состояний прошлого и какова была полезность или каково в конечном итоге было подкрепление при переходе вот в это вот новое состояние. И важным концептом, который мы в рамках этой модели используем, является понимание глобального подкрепления. Концепция глобального подкрепления заключается в том, что если мы обучаем систему полезности перехода из некоторой последовательности состояния в новое состояние, то мы считаем эту полезность не от нового состояния, то есть нам важна не сама полезность нового состояния в зависимости от предыдущих состояний, а мы можем все совокупность переходов, которые соответствуют некоторому фрагменту поведения, допустим, весь путь по дороге к ресторану, допустим, захотели есть, мы идем, ищем дорогу к ресторану, здесь повернули направо, здесь повернули налево, и вот она вывеска, да, вот в неизвестном городе мы когда оказались, вот, значит, по карте мы первый раз когда прошли, да, значит, глядя в телефон, значит, все нужные повороты, значит, мы правильно прошли по карте, увидели наконец вывеску кафе, поели, получили положительное подкрепление и вот вся эта последовательность, которая у нас в краткосрочной памяти сформировалась к тому моменту, когда мы принялись за еду, она у нас запоминается. То есть нам не нужно сто раз ходить по тому же маршруту для того, чтобы наконец его запомнить. Достаточно сходить один-два раза и мы его уже запомнили. Недавно проверял, когда в Бишкеке решал проблему питания. Следующую схемку я, наверное, рассказывал в прошлый раз, я, наверное, здесь ряд схемок пропущу. Перейду к тому, как мы хотим строить, собственно, модели среды и как мы с этими моделями хотим работать. В классическом машинном обучении обучение выглядит примерно следующим образом. У нас есть некоторый набор тренировочных данных, либо это статические данные, которые в рамках бэтч-ленинг используются, либо это данные, которые поступают в рамках reinforcement-ленинга. Но так и иначе на множестве этих данных мы формируем некоторую модель. После того, как мы эту модель сформировали, мы переходим в режим inference. Допустим, в случае большой языковой модели у нас есть некоторый контекст, который мы можем предварительно загнать в эту модель или промпт. Мы формируем вопрос, и этот вопрос через этот контекст попадает в модель, и мы получаем свой ответ. Значит, данные при этом отсутствуют. Соответственно, если вдруг у нас в процессе работы с системой, если мы не только вопрос задаем, а говорим, что вот твой предыдущий ответ был плохой, и вот правильный ответ, и вот тебе новое данное, которое ты, пожалуйста, используй при следующих взаимодействиях со мной, максимум, что система может сделать, это положить эту новую информацию в контекст, эта информация будет болтаться в контексте, пока она из него не выводится, потому что контекст ограничен. А сама модель в процессе взаимодействия меняться не будет. Поэтому сейчас, допустим, в мире больших языковых моделей делаются различные ухищрения. Допустим, к модели добавляются некоторые инструментарии или tool chain на основе фреймворков типа LangChain, которые позволяют подцепить некоторую базу данных. которая либо будет автоматически или там не автоматически в процессе жизненного цикла системы пополняться какими-то сторонними знаниями или, может быть, даже как вот это было в докладе Ивана Бондаренко, система может непосредственно в процессе взаимодействия с пользователем эти данные непосредственно получать из диалога с ним. Соответственно, модель как-то интегрирована с инструментами, инструменты как-то ходят в данные, и возможность динамического пополнения этих данных как-то компенсирует то, что модель у нас статическая, замороженная и необучаемая. Мы попытались генерализовать подобную архитектуру следующим образом. Во-первых, у нас остается некоторый вопрос или предъявляемая системе ситуация, в рамках которой нужно дать ответ или сформировать некоторое предсказание. или рекомендовать некоторые действия. Естественно, может быть некоторое расширение вот этой текущей ситуации в виде некоторого контекста, который мы можем с точки зрения психологии и нейрофизиологии ассоциировать с тем, что называется short term memory или краткосрочная память. И у нас есть данные, вот сразу перепрыгну через уровень модели, у нас есть некоторые данные. Это наша долгосрочная память, это наше знание, которое мы приобрели, это те эпизоды, те ситуации, те сценарии, которые мы помним, пока помним. Память тоже ограничена, но мы их помним. А вот доступ к этим, так сказать, доказательным данным или фактическим данным, которые мы зафиксировали, они осуществляются через модель, где модель может быть нейросетевая. Да, и описано просто некоторым набором нейросетевых коэффициентов, параметры модели. А это может быть модель и символьная. Да, это могут быть некоторые правила, которые сформированы в терминологии системы 2 Канемана, условно говоря, пролог, или там некоторые графы вероятностной логики. Пиланга, Бена Герцеля и Евгения Витяева. Это могут быть некоторые инварианты, некоторые обобщенные ситуации. Допустим, мячик летит не просто вниз в левом углу или вниз в правом углу или вниз посередине, а просто мячик летит вниз. Если мячик летит вниз, мы ждем, что он упадет на пол. Неважно, справа, слева или посередине он лежит. Это инвариант. Некоторые индексы могут быть, которые могут позволять для того, чтобы получить ответ на вопрос, для того, чтобы понять правильную поведенческую схему или правильное поведение в конкретной ситуации, мы можем просто проиндексировать эти данные в долгосрочной памяти, и подглядеть, соответственно, правильный им вариант, а если нас интересует, чем этот вариант подкреплен, насколько он действительно имеет право на существование, мы можем поднять все прецеденты, которые находились в долгосрочной памяти. Ну и что важно, что у нас по вертикальной оси как вопрос, так и контекст, так и модель, так и, собственно, долгосрочная память, они имеют два измерения. Во-первых, они имеют модальность, насколько много у нас параметров там есть, то ли мы работаем только с текстовой информацией, то ли только с какими-то временными рядами, то ли с видео, то ли с аудио, то ли со всем вместе в какой-то комбинации. А с другой стороны, насколько точно мы с этим работаем, то ли в плавающей точке, то ли сохраняем только важные сигналы, удаляем неважные, с какой частотой, то ли мы измерения проводим каждую секунду, то ли каждую микросекунду, то ли вообще одного раза в час достаточно измерять, соответственно, временная точность и количественная точность. Ну и по горизонтали у нас тоже все ограничено. То есть у нас есть параметры модели, размеры модели, размер контекста, размер вопроса, той контекстуальной ситуации, которую мы подаем на вход. И в конце концов у нас есть понятие размера долгосрочной памяти. И если мы строим некоторую когнитивную архитектуру, которая содержит вот это вот все. И вот эти длины стрелочек, как по горизонтали, так и по вертикали, так и слева направо, они на самом деле являются некоторыми динамическими параметрами системы, которыми может управлять либо оператор, либо сама система может некоторым образом регулировать эти параметры в зависимости от своего гемеостаза, то мы получаем некоторую систему, которая в зависимости от ситуации может приспосабливаться, как некоторые животные, допустим, зимой замерзают. А летом размораживаются, допустим, мало у нас вычислительных ресурсов, мы поджали retention period, забыли то, что было в прошлом году. Много памяти стало, мы начали запоминать больше, расширяем свои возможности по хранению предыдущих эпизодов. Ну и, соответственно, работает это все так, что мы из вопроса и контекста мы задаем вопросы, которые идут либо к модели, либо к правилам инвариантам, индексам. Соответственно, в режиме реального времени идет до обучения обновление новых данных в долгосрочной памяти и одновременно, если требуется ответ на поставленный вопрос или реакция на какую-то новую ситуацию, то идут ответы. Перейдем к практическим переменам. Одно из применений, где такой подход мог бы быть полезен, на мой взгляд, является сфера промышленной автоматизации, где на сегодняшний день искусственный интеллект по большому счету не применяется вообще в силу достаточно жестких требований к прозрачности этих систем. То есть если мы возьмем типичную схему некоторой автоматизированной системы управления технологическими процессами, вот у нас есть процесс, с него идут некоторые сигналы с поля и сверху над него идут некоторые управляющие воздействия. Управление идёт на двух уровнях. В первом приближении, на так называемом нижнем уровне системы SUTP, управление идёт в автоматическом режиме с помощью так называемых контроллеров программируемой логики. которые программируются в соответствии со спецификациями данных технологических процессов на специально предназначенных для этого языках программирования линейки IEC 6131 и IEC 6161. 499 там есть текстовые языки, там Pascal подобные, Assembler подобные, есть графические языки, типа UML нотации. Ну а поскольку не все можно автоматизировать, то у нас данные еще попадают в среду человека-машинного интерфейса, и из среды человека-машинного интерфейса уже оператор на верхнем, так сказать, уровне системы автоматизированного управления может давать какие-то, также подавать управляющие воздействия в зависимости от тех сигналов, которые он видит на красивых панелях. ну и поскольку значит обычно то что здесь происходит в этом технологическом процессе это ответственная и критически и экономические, и часто жизненные процессы, то высока степень ответственности тех людей, которые отвечают за безопасность, качество и надежность исполнения этих процессов. И постановку туда, в этот контур некоторых нейросетей, которые являются черным ящиком и которые требуют тренировки на каких-то данных, которых во многих случаях просто нету. более того, в тех условиях, когда параметры технологического процесса часто меняются во времени, и если мы обучили некоторую гипотетическую модель на чем-то месяц назад, то в следующем месяце она может быть уже совсем другим, потому что там качество бензина поменялось, или там качество угля пошло не то. Вот. На практике, на сегодняшний день, системы нейросетевого искусственного интеллекта здесь не применяются, а системы, про которые мы говорим, может быть. Дальше я про это еще скажу. Но поскольку никакой конвейера или атомной электростанции под рукой нету, то в данной работе мы развлекаемся с OpenAI Jim, про который Игорь Пивоваров рассказывал. несколько семинаров назад. Соответственно, вот слева у нас есть наш агент, которому даны некоторые правила вознаграждения, и внутри него он может иметь некоторую либо интерпретируемую, либо не интерпретируемую систему искусственного интеллекта, который получает некоторые наблюдения из виртуальной среды. Ну и в ответ на наблюдение этой виртуальной среды он генерирует некоторые действия, которые идут на эту среду. Что мы из среды получаем? Из среды мы получаем набор переменных, где каждая переменная – это цветовое значение некоторого пикселя. А действие, которое мы подаем на эту среду, это одно из четырех действий. Либо действие-недействие, то есть мы ничего не делаем, либо мы двигаем вот эту ракетку влево, либо мы двигаем ракетку вправо, либо мы берем и ракеткой запускаем мячик, чтобы он полетел вверх. Вот, собственно, четыре возможности, которые у нас есть, в единицу времени. Ну и задача, значит, разбить все кирпичики в верхнем ряду и не допустить мячику падения вниз. Соответственно, если мячик падает вниз, нам система говорит, ай-яй-яй, больно, значит, ты потерял жизнь. А если мячик разбивает кирпичик после долгого пути наверх, Система нам говорит, ты молодец, на тебе конфетку, вот тебе получи очко, вот тебе это новое очко записано. Обращаю внимание, что это так называемое отложенное подкрепление, то есть мы получаем конфетку или очко не в тот момент, когда мы отбили мячик, а только тогда, когда этот мячик проделал долгий путь и разбил кирпичик. Притом, если мячик вдруг прилетел через дырочку в разбитых кирпичиках, то конфеточку мы получаем только когда он сверху, отразившись от потолка кирпичика, разбил. Какие способы решения этой проблемы? Классическая архитектура реинформ в Метлеоне, Нартер Критик. Из среды мы получаем состояние, у нас есть некоторая политика, которая осуществляет действия в зависимости от этих состояний. Эта политика нам говорит о том, какие действия мы совершаем. И есть некоторая value function, которая корректирует политику в зависимости от награды, которые мы получаем из среды. Но обычно полис – это некоторая нейросетевая модель. Вот есть система Евгения Евгеньевича Витяева, архитектура Discovery, где опять-таки мы получаем некоторые состояния, вот у нас есть возможность некоторого синтеза возможных переменных этих состояний, принятие решения в связи с возможными исходами, предсказание некоторого результата, положительного либо отрицательного, ну и Соответственно, оценка эффективности, насколько результат действительно был положительный и отрицательный. Ну и, наконец, там модель, которую мы представляли пять лет назад на конференции GI. Вот это модель агента, который как раз вот работает на графах последовательности состояний. У этого агента есть, он работает в пространстве большого числа предикатов. Вот напоминаю, что мы любое пространство состояний можем описывать либо в графовом представлении, и тогда, значит, это просто пространство некоторых предикатов, допустим, x, y зеленый, x, y красный или x, y черный. Либо мы это описываем в тензорном пространстве, где x, y и цвет описывает некоторый пиксел в некотором тензорном пространстве. Соответственно, вот у нас есть некоторый сегмент этого пространства предикатов, где мы храним наши ценностные функции, допустим, наша цель – быть счастливым или наша цель – получать положительные очки. У нас есть набор предикатов, которые описывают логику, что, допустим, в случае того-то происходит то-то. У нас есть некоторые наблюдения, проиндексированные по времени, полученные наблюдения, база данных того, что мы видели, и база данных того, что мы сделали, по сути, лог того, что мы получили на входе, и соответствующий лог того, что мы получили на выходе. Ну и вот результаты, которые как раз были представлены сначала пять лет назад на AGI, вот это то, что продвинутую некоторую версию представляли в прошлом году на статье с Владимиром Крюковым. Вот у нас этот агент, он как раз может играть в некоторую простую версию пинг-понга, это упрощенный аналог игры Atari Breakout, про которую я Перед этим говорил, вот просто здесь мы эту модель закодировали сами, вот точно так же отбиваем мячик, получаем отрицательное подкрепление или отрицательный фидбэк, если мячик ударился о пол и получаем положительное подкрепление, если мы либо отбили мячик, сразу получаем немедленное и неотложное подкрепление в простом случае, либо в усложненном случае отложенного подкрепления получаем подкрепление, когда мячик ударился в потолок. Ну и вот здесь вот показан фрагмент того, как мы этим мячиком управляем. Вот мячик, вот ракетка, вот тут вот генерируется счастье, импульсы счастья, импульсы несчастья, импульсы новизны, импульсы ожидаемости, наличие обратной связи. И что важно, то что собственно решение задачи о вот управлении этим мячиком для максимизации счастья, полученном в результате отбивания его, либо ударов его об потолок, мы можем решать в двух разных пространствах. Одно пространство – это пространство, описываемое пикселями, то есть на вход мы получаем только значение пикселей, в данном случае черный-белый, то есть наличие либо мячика, либо ракетки в конкретной точке кодируется пикселями. Либо мы ту же самую физику аппроксимируем всего тремя значениями, вертикальная координата и горизонтальная координата меча и горизонтальная координата ракетки. То есть два пространства, после чего мы берем один и тот же самый алгоритм и с помощью одного и того же алгоритма Мы пытаемся научить одну и ту же модель, ну просто вот состояние, ну то есть один и тот же алгоритм, работают с двумя разными потоками входов и выходов. Выходы на самом деле одни и те же, потому что на выходе одни и те же действия, а вот потоки входов разные. И мы обнаруживаем следующую интересную вещь, что эффективность обучения с точки зрения как бы качества и в том и другом пространстве одна и та же. То есть вот здесь вот показано на верхнем уровне зелененьким справа обозначено это обучение в пространстве объектов, когда мы работаем просто с координатами в трехмерном пространстве x, 2x и 1y. X-ракетки, X-мячика и Y-мячика. А внизу показаны те же самые скорости обучения для различных параметров игрового поля по горизонтали для работы в пространстве пикселей. И видно, что если мы увидим, что скорость обучения показаны этими циферками по вертикали, идут просто разные варианты алгоритмов. Они, в общем, одни и те же. То есть при одном и том же размере игрового поля у нас в принципе обучаемости равные получаются. Но что разное-то? А разное получается то, что вычислительные затраты, которые несет агент, и скорость, которую с которой агенты осуществляют вычисления, они отличаются в разы. То есть, если, допустим, на уровне объектов мы можем бесконечно долго увеличивать размерность поля и будем продолжать сохранять возможность обучения, то в случае работы с пикселями у нас по мере увеличения размеров поля будет все больше и больше расти вычислительные затраты и в какой-то момент мы просто не будем успевать обсчитывать картинку в режиме реального времени на одном и том же оборудовании. И, кстати, собственно, на чем 5 лет назад это исследование закончилось, на том, что когда мы попытались реально обрабатывать данные из OpenAI ATA режим, ну просто вычислительные ресурсы не позволили тогда это делать в реальном времени. Сейчас мы это смогли, и про это я чуть позже расскажу. Смогли мы это таким образом, что мы как раз стали решать задачу понижения размерности с одновременным повышением дискретности. Что я имею в виду? Я имею в виду, что если у нас изначально состояние описывается в пятимерном пространстве, красный, зеленый, синий составляющие цвета пикселя и две координаты для каждого пикселя, то мы, во-первых, на первом шаге мы можем переопределить это пространство, свести его к трехмерному, заменив, допустим, перейдя от RGB к серой шкале. Потом, мы можем упростить это еще дальше, сказав, что нас вообще шкала не интересует, нас интересуют просто координаты мяча по Х и ракетки по Х, а вертикальная координата вообще не влияет. Вот это может показаться удивительным, но вот, например, в наших экспериментах, которые мы сделали для конкретной игры, оказалось, что вертикальная координата действительно, по крайней мере, не критично влияет. То есть, возможно, сейчас мы ее не используем, но, может быть, использовали было бы лучше, но и без нее, в принципе, получается. Более того, в какой-то момент мы можем сказать, а нас вообще не интересует точность, допустим, 144 по вертикали, 178 по горизонтали, как это имеет место в оригинальной игре, мы можем вообще все это дело подрезать до плюс-минус 50 и вообще считать только не иксы мячика и ракетки, а считать просто относительную координату одного относительно другого, то ли мячик правее, то ли ракетка левее. Ну и следует, как работает вся эта конструкция. Мы берем некоторое состояние, описанное определенным образом в пониженном пространстве. В нашем случае мы работаем вот в этом пространстве. X и меча и ракетки и в общем-то все. Ну и плюс подкрепление и плюс то действие, которое мы совершаем. Соответственно, вот у нас есть некоторое текущее состояние. Это текущее состояние лежит наверху некоторой пачки предыдущих состояний. Мы пробовали с одним текущим состоянием, с двумя состояниями, текущее и предыдущее, и с тремя состояниями в последних экспериментах. И на основе опыта и взаимодействия с окружающей средой мы можем знать, что у нас может быть переход такой, что мы ракетку двигаем влево, и тогда мячик бьется о пол, и мы получаем подкрепление в итоге. В этом случае мы получаем отрицательное подкрепление, потому что мы теряем жизнь, потому что мячик на пол упал. Или мы можем двинуть ракеткой вправо, и тогда ракетка подхватит мячик, и тогда, спустя какое-то количество состояний, мячик ударится в потолок, и мы получим подкрепление. Но, возможно, другой исход. Мы можем двинуть ракетку вправо, А ракетка не двинется. По правилам игры, там нет полной предсказуемости среды с точки зрения действий игрока. То есть мы можем сказать, двигая ракетку вправо, а ракетка может застрять. И все равно мяч может удариться на пол, и мы можем не получить своего желаемого подкрепления. Ну и то, что мы должны были бы делать, но в текущей ситуации пока не делаем, это, собственно, построение этих инвариантов для генерализации и для получения более эффективной, вычислительной, еще более компактной модели. То есть, если сейчас мы запоминаем переходы о конкретных состояниях с конкретными координатами, допустим, вот переход из вот этого положения мячика с ракеткой здесь сюда – это один переход. Переход с тем же самым относительным положением мячика и ракетки в другой части экрана – это другой переход. А в принципе-то, если бы мы могли выучить некоторый инвариант о том, что вот ракетка относительно мячика здесь, вот, и нужно просто для того, чтобы его подхватить, двигать вправо, это вот получается некоторая ситуация инвариантная к горизонтальной координате, вот, и выучив ее, мы могли бы получить более компактную модель и осуществлять более эффективное вычисление с меньшими энергозатратами в большей степени в режиме реального времени. Перейдем к результатам по этому проекту. Первое, что мы сделали, мы попытались понять, а вообще, если мы такую модель построим и научимся, выучим ее каким-то образом, сможем ли мы эффективно принимать решение, что называется, делать инференс на предыдущей модели. Что мы сделали? Мы закодировали робота, который знает правила игры, заранее. И он генерирует некоторые переходы с учетом знания этих правил игры. И далее ему проиграть 100 игр, записав все возможные состояния. В результате этих 100 игр мы получили синенький график. То есть он играл стабильно на уровне выше 450 очков за Но максимального количества очков 864 синий график ни разу не достиг. После этого мы эту модельку сохранили, и мы дали этому модельку агенту нескольким вариантам агентов, которые могли уже дообучаться. И мы обнаружили, что в зависимости от конфигурации агента, агент очень быстро за первые 10 или за первые 20 игр дообучается до того, вот это, соответственно, красная и зеленая линии на верхнем и нижнем графике агента обучается до того, чтобы играть на максимально качественном уровне. То есть вот здесь на уровне 800 и даже один раз до 800, в верхней планке 864 очка удалось добиться. То есть мы увидели, что не только мы можем на предобученной модели получать адекватную производительность, но мы можем даже дообучаться и превосходить эффективность запрограммированного робота. Дальше мы начали учиться с нуля. Вот, допустим, в начале мы стали учиться на переходе из одного состояния в другое состояние, ну и ожидаемо мы получили очень плохие результаты. То есть если уровень человеческой игры это где-то порядка 30, по-моему, 31, человек эксперт средний уровень, то вот иногда мы его побивали, но в основном все варианты ниже. Это понятно, потому что когда мы переходим из одного состояния в другое состояние, мы, глядя на одно состояние, вот допустим, как здесь нарисовано, мы видим, что мячик вот здесь, вот ракетка здесь, но мы не знаем, куда мячик летит. То ли он летит вот так вот, то ли он летит вот так вот, то ли он летит сверху вниз. А от этого зависит, куда двигать ракетку. То есть нам нужно знать либо скорость и координату движения мячика, либо нам нужно знать два состояния, из которых это можно вычислить. Поэтому после того, как мы увеличили количество состояний до двух, у нас сразу же получились результаты лучше. Вот здесь мы сразу же видим, что мы превосходим уровень человека. И на разных экспериментах с разными параметрами нам удалось, если эти карты складываются хорошо, не только превосходить средний уровень человека, но и превосходить средний уровень, который получается с помощью дипкулёнинга, и даже превосходить топовый уровень, который получается с помощью дипкулёнинга. К сожалению, стабильность у нас пока невысокая, то есть у нас есть удачные запуски, когда дело в том, что эта игра рандомизирована, и поэтому ход игры заранее неизвестен. Точнее, ход каждой последующей игры, он случайен. А мы увидели, что у нас очень важно с точки зрения, по крайней мере, в той модели, которая есть сейчас, И в том алгоритме, который сейчас очень важна скорая эффективность обучения в начальной части, то есть у нас в начале обучения, то есть у нас после того, как агент выходит на какой-то уровень, он стабилизируется, сейчас это уровень 400 с небольшим, но вот есть случаи, когда агент очень быстро идет в гору, допустим, здесь за 50 игр он вышел практически на максимальный уровень. Тут он на максимальном уровне вышел за 500 игр, а в некоторых запусках он оказывается от рождения туповат, или жизнь у него не складывается, или среда у него образовательная или жизненная получается неудачная, и вот он не обучается. Ну вот то же самое мы попробовали до 50 тысяч, точнее, до 5 тысяч игр. И дальше мы попытались сравнить результаты с предшественниками. Тут, правда, мы обнаружили, что мы неправильно ставили эксперимент, потому что предшественники меряют обучаемость не относительно количества игр, а относительно шагов или фреймов, на которых это обучение происходило. Рекомендация тем, кто будет заниматься подобными экспериментами, прежде чем ставить в известной области эксперименты самостоятельно, не полениться, а посмотреть, каковы будут все-таки условия эксперимента предшественников, чтобы с ними было проще сравнивать. Тем не менее, на этой картинке мы попытались сравнить наши результаты, отнормировав максимальные и средние очки, которые мы достигали при разных запусках, на количество фреймов, на которых происходило обучение. Здесь показано, что, допустим, DQN на 50 миллионов фреймов получает такое число. А у нас лучше результат на меньшем числе фреймов получает, вот еще большее число средний счет. Соответственно, вот у нас красным показан более продвинутый алгоритм Rainbow, который выходит еще на более высокий уровень, но уже на 200 миллионов шагов. Ну а мы видим, что у нас получается квазилинейная зависимость. Чем больше количество шагов мы учим, используем при обучении, тем лучше у нас результаты. Соответственно, есть надежда, что когда мы начнем масштабировать свое обучение на количестве шагов, мы уйдем вверх, но это нужно еще верифицировать. Соответственно, что по этому проекту у нас дальше? Значит, стабилизация обучаемости, то есть сделать, дорабатывать, исследовать алгоритм до такого состояния, чтобы у нас от запуска к запуску результаты не так сильно отличались, как мы только что видели. Значит, научиться интерпретируемому понижению размерности. Значит, я забыл сказать, что сейчас для того, чтобы понизить размерность от поля пикселов до координат меча и ракетки, мы используем некоторый примитивный алгоритм машинного зрения. Ну, это в некотором смысле читинг, потому что правильное применение алгоритма машинного зрения. С одной стороны, конечно, мы когда вот смотрим на все-таки, когда мы сами работаем с изображением, мы как люди, у нас все-таки существенная часть обработки осуществляется там, она не обучается, она, так сказать, захардкожена архитектурой зрительного тракта. в голове. Но все-таки того, что мячик это мячик, а ракетка это ракетка, и что это два важных объекта, а на всяких там птичек и мух внимания обращать не надо, этому все-таки учимся. То есть если мы играем в пинг-понг, а кругом летают комары, мы понимаем, что на комаров реагировать не надо, а нужно сфокусироваться на мячике. Соответственно, мы должны уметь автоматически формировать вот это понижение размерности в зависимости от разных сред. Где-то нужно горизонтальные координаты, где-то вертикальные, где-то объекты, где-то их четыре. Соответственно, вот это за решение задачи интерпретируемого понижение размерности, она должна быть автоматизирована, а не захардкожена, как в нашем случае. Следующая задача – это, естественно, опробовать вот тот логаритм, который у нас сейчас есть на разных окружениях, там в том же самом Atari режиме только Atari Games, игр Atari там несколько десятков, а есть еще куча всяких разных окружений других, включая виртуальных роботов. Следующая интересная задача, которая непосредственно важна для практического применения данной истории, это кластеризация и сегментация пространства-состояния. То есть, если у нас, ну, к примеру, если мы хотим решать задачу с потоком переменных, которые описывают некоторый технологический процесс или там даже какой-нибудь умный дом, допустим, то у нас там может быть несколько турбин, несколько котлов, несколько контейнеров, конвейеров разных. несколько разных приводов, у каждого из них свои датчики, и пытаться, значит, вот все это пространство состояний, все эти переменные, которые соответствуют разным физическим объектам с индивидуальными процессами, описать каким-то одним состоянием и работать с переходами, значит, из этих состояний в эти состояния – это, естественно, бред. То есть мы должны как-то выделять, что вот это переменное, которое описывает один объект, и у него свой цикл переходов в состоянии, а вот другой объект, у него свой цикл переходов в состоянии, причем там еще по времени это может быть по-разному сегментировано, то есть временные функции переходов могут быть разные, где-то переходы происходят ежесекундно, где-то ежеминутно, а где-то каждую микросекунду. Ну и как раз когда я этот доклад готовил, я придумал очень забавное базовое усложнение существующей задачки. Это пинг-понг по-македонски. Для того, чтобы отработать возможность разделения пространства-состояния на разные логические сегменты, мы можем создать виртуальную игру, где есть два мячика и две ракетки, или даже два мячика и одна ракетка. или один мячик и две ракетки, тут уже варианты, и соответственно научиться некоторым образом выделять два потока данных и индивидуально работать с двумя этими потоками данных. Естественно, интересно бывает уйти из области игрушек и найти некоторое прикладное применение, например, в промышленном автоматизации или в каких-то еще задачах. Значит, решить задачу, собственно, построения иерархии пространства-состояний, да, то есть если мы делаем некоторую сложную игру, где у нас там есть не только, допустим, мячик и ракетка, а есть там еще, так сказать, партии, да, и где, может быть, там для того, чтобы выиграть там войну, нужно проиграть конкретное сражение, да, то есть строить более сложные иерархии пространства-состояний. Ну и, значит, еще очень интересная задачка есть, это к вопросу как раз об интерпретируемости, что если сейчас, значит, вот в той архитектуре, которую мы реализуем, интерпретируемость, она как бы есть, как бы это сказать, Она есть в том плане, что мы, получив любую инструкцию или получив любое решение, можем понять, на основе какого состояния и каких альтернатив вот это решение рекомендовано. То есть, либо это фактические состояния, как это делается сейчас, либо это некоторые инварианты, которые мы выучили. То есть мы говорим, что вот у нас есть такой инвариант, допустим, мячик справа, ракетка слева, и вот ему в нашей модели соответствует движение ракетки в такую-то сторону. И более того, вот, пожалуйста, все прецеденты, которые подкрепляют в нашей долгосрочной памяти обоснованность вот этого инварианта. А можно еще что сделать? Можно еще гипотетически использовать технологию так называемой суперкомпиляции, которая на основе потоков данных может строить на самом деле программу. В данном, допустим, применительном случае к промышленной автоматизации это будет анализ перехода в состоянии на предмет корректировки существующих программ на соответствующих языках программируемой логики в модифицированные программы, оптимизацию управляющих программ или написание новых программ для каких-то новых устройств или модификацию этих программ для изменения параметров этих устройств. Вот так вот, например, это может выглядеть для задачи промышленной автоматизации. Так, я думаю, уже что-то... Да, я надеюсь, что я успею за полтора часа уложиться, академический час-два точнее. Значит, вот у нас предыдущая схемка промышленной автоматизации, где, как мы знаем, применение искусственного интеллекта на сегодняшний день законодательно запрещено. Куда мы можем пойти? Вариант первый. Если у нас есть сигналы с поля и есть некоторые управляющие сигналы, которые на сегодняшний день генерятся вот этими программируемыми логическими контроллерами, мы можем снимать эти сигналы. И подавать эти сигналы в пространство состояний некоторого интерпретируемого искусственного интеллекта, который будет как бы принимать решение. Он будет говорить, что вот в этой ситуации нужно такое управляющее воздействие, а вот в этой ситуации нужно такое управляющее воздействие. Он не будет их посылать, мы будем запрещать ему посылать, потому что закон тюрман, нельзя по существующим регламентам. Но мы можем сравнивать то, что говорит нам в существующей ситуации контроллер, и то, что говорит система. И если в процессе работы этого контроллера система выучит нечто, что в какой-то момент начнет говорить о том, что контроллер, ты себя ведешь неправильно, то как минимум оператор может вот эту вот информацию получить в качестве некоторого предупреждения, И на самом деле пойти посмотреть, а в чем дело, не изменились ли у нас параметры, допустим, оборудования технологического или не сбили ли нам случайно настройками параметры управляющей программы, так что нужно либо пойти перенастроить программу, либо пойти что-то сделать с оборудованием. Это один вариант, когда мы это делаем на нижнем уровне. Второй вариант, когда мы это делаем на верхнем уровне. Опять-таки, у нас есть оператор, который посылает управляющие воздействия, у нас есть сигналы, мы это все дело снимаем, перехватываем все эти сигналы, передаем их на верхнем уровне на систему интерпретированного искусственного интеллекта, который обучается. И опять-таки, конечно, мы могли бы предложить, что вот если оператор заснул, то чтобы система сама давила нужную кнопку, но если по, на сегодняшний день, юридическим Основанием этого делать нельзя. Мы опять-таки можем там включить какую-то сигнализацию аварийную, чтобы оператор там проснулся и нажал эту чертову кнопку. Потому что давно пора ее нажать. Ну и самая последняя история невозможная, что если мы снимаем сигналы либо с этого, либо с этого уровня и строим здесь некоторые модели, то если у нас на основе этих моделей на основе всех накопленных переходов в состоянии возникает возможность использовать суперкомпиляцию для модификации, оптимизации, доработки программной логики методом суперкомпиляции, то вот это вот еще одно интересное перспективное направление, на мой взгляд. Ну и быстренько, буквально, Материалы по второй теме, по той теме, про которую я сейчас рассказывал, мы статью написали, подали на конференцию ECML, посмотрим, что из этого будет. А эта работа тоже была в прошлом году подана в журнал. Рецензируемые рецензенты работу одобрили положительно, но попросили делать некоторые доработки, про которые я сейчас расскажу. В чем суть этой работы? Я в прошлом году, уже позапрошлом году рассказывал про когнитивно-поведенческую архитектуру на основе социального доказательства и ресурсного ограничения. О чем идет речь? о том, что если мы хотим смоделировать некоторого агента, который будет давать рекомендации пользователю или принимать действия за пользователя, вот пресловутый автономный агент, который живет у пользователя на компьютере и делает за него все, что нужно. то для того, чтобы адекватно удовлетворять пожеланиям пользователя, агент на самом деле должен иметь модель этого пользователя у себя внутри. Более того, если этот пользователь действует не просто, так сказать, как не в игру играет какую-нибудь, или не на велосипеде едет, а взаимодействует с людьми в реальном мире, то агент должен понимать, а в какой социальной среде этот человек работает. То есть для того, чтобы давать рекомендации на действия человеку, действующему в социальной среде, агент должен на самом деле иметь модель социальной среды. ценностей, интересов, уровней доверия, социальных взаимоотношений между людьми, уровнем экспертизы различных людей при принятии ими различных решений или передачи ими каких-то сообщений. То же самое верно, если мы строим некоторую систему управления предприятием, которая должна обучаться на основе действий персонала. То есть, если у нас, допустим, некоторое действие совершает, грубо говоря, сеньор, эти действия запоминаются в системе, и какое-то другое действие совершает джун, и это действие тоже запоминается в системе, то, очевидно, действие, которое делает сеньор, оно должно запоминаться системой с некоторым большим весом, тем действием, которое И для того, чтобы формализовать эту подобные два класса систем, либо однопользовательские системы, основанные для индивидуального пользователя, действующего в социальной среде, либо для того, чтобы формализовать построение систем коллективного интеллекта для автоматизации предприятия, Мы разработали архитектуру, основанную на четырехдольном графе, где есть некоторый граф, описывающий абсолютные знания или несомненные истины в то, что мы верим, допустим, некую базовую онтологию. Он описывает социальный граф, где описываются уровни доверия между пользователями или уровни отношений между ними. Есть некоторый evidence graph, где набор идёт некоторых фактов или утверждений или событий, которые аннотированы, во-первых, временем, а во-вторых, источником этих событий, кто что сказал, кто что написал, кто что предложил, кто что зафиксировал. Ну и, собственно, предмет вывода. или предмет принятия решений, или предмет формирования ожиданий на основании всего этого дела. Здесь дело называется Imagination Graph, который рассчитывает некоторые вероятности или предпочтительности, или же ожидаемости, или степень того или иного утверждения действия или события с учетом того, какова базовая онтология конкретного человека или конкретной организации, каковы уровни отношений между субъектами в этой системе, в том числе с этим базовым графом, ну и какими субъектами фиксируются какие утверждения или какие действия. Есть некоторая базовая математика, про которую я рассказывал, эта математика вписывается в два этих графа, что на основе несомненных истин социальных связей и фактов, которые атрибутированы источниками этих социальных связей, мы можем вывести некоторые оценки доверия к данным фактам с учетом источников доверия уровни доверия к источникам этих фактов в контексте того, чего мы верим. И точно так же мы можем это делать не для фактов, а для действий. То есть мы можем оценивать предпочтительность и несообразность некоторого действия, в зависимости от того, какие мы ожидаем реакции на данные действия наших социальных, так сказать, рефери, с учетом нашего доверия этих реферий, да, то есть вот если мама сказала не купаться в луже, вот, и мы очень уважаем маму, то мы не будем купаться в луже, даже потому что наш друг Вася, значит, предлагает вместе искупаться в луже, потому что маме мы доверяем больше, чем другу Васе. Ну и что самое интересное, что в какой-то момент мы обнаружили, что с помощью этой системы можно описывать не только поведение тех агентов, которые мы пытаемся строить, а также можем мы моделировать поведение личности. Например, мы подумали, обнаружили, что на уровне, так сказать, вот как это называется, моделирования, умозрительного моделирования, мы можем предсказать такое явление, как социальная кластеризация, когда при начальном, некоторой начальной гетерогенности сосума и отсутствии каких-то серьезных внешних давлений, которые бы этот сосум консолидировали, сосум имеет тенденцию распадаться на Кластеры, да, грубо говоря, так сказать, вот если у нас есть одна группа наверху, да, которая, так сказать, имеет между собой что-то общее, есть другая группа внизу, которая имеет между собой что-то общее, и при этом, значит, у них есть, значит, некоторый общий участник, который связан с той, с другой группой. Если начинается общение, то есть некоторая динамика, которая показывает, что, во-первых, в силу вот этой математики, которую мы здесь закладываем, во-вторых, в силу того, что эта математика также предполагает, что каждый субъект, пытается, во-первых, имеет ограничения физические по количеству тех социальных связей, которые он может обработать. Ну, например, там знаменитое число Донбара, что мы там больше чем 150 или около того связей не можем обработать. принципе вот и пресловутое число 7 значит что эффективно руководить одной командой значит больше чем 7 человек менеджер не может вот единственное исключение это воинское подразделение где в результате там воинской дисциплины можно число солдат в отделении увеличить до 10 вот и И в силу вот этих вот ограничений, как по количеству связей, так и по той энергии, которую мы потребляем на свои мыслительные, когнитивные процессы при обработке информации, и мы не можем обрабатывать все, а мы должны чем-то жертвовать, что-то мы должны забывать, что-то мы должны игнорировать, вот в результате этого возникает некоторая кластеризация, то есть мы обнаруживаем, что ментальная близость вот этих трех товарищей она становится больше со временем и ментальная близость этих двух товарищей внизу тоже становится больше и они разделяются постепенно все дальше и дальше на две различные группы но вот собственно одно из замечаний рецензентов которые к нам было предъявлено что вот вы это хорошо на пальцах показали и А вот теперь давайте-ка допилите свою статью, сделайте вышлительный эксперимент. Что мы, собственно, и сделали. Что мы сделали? Я уже заканчиваю. Мы построили вот тех же самых пятерых агентов, мы загнали вот в такую матрицу. По вертикали здесь номер агента от 1 до 5, а по горизонтали вот некоторые предметы веры. ABCXYZ – это некоторые концепты или предпочтения агентов, их хобби, если угодно, или любимое музыкальное произведение, или любимые артисты, про которые они могут говорить друг с другом. А внизу написана матрица близостей. Здесь внизу и по вертикали агенты, и по горизонтали агенты. Значит, мы в этой матрице видим, насколько каждый агент близок друг к другу. И мы запускаем три итерации, когда каждый агент говорит с каждым и хочет ему что-то сообщить, а другой агент либо это воспринимает, либо не воспринимает. Вот с учетом той модели, которую я рассказывал в прошлом году, а сейчас более подробно очень быстро проскакал. При этом мы закладываем разные параметры. Например, вот в этой симуляции мы говорим, что агенты ограничены в социальном плане, то есть не очень имеют ограниченные возможности общаться с друг другом, предпочитают маленький круг общения, но при этом у них большой когнитивный ресурс, они могут много информации переваривать. Вот в этом экспериментальном сетапе мы обнаруживаем, что после трех итераций у нас формируется, во-первых, два кластера агентов, то есть вот возникают два агента с высокой близостью и три агента с высокой близостью. При этом они оказываются практически изолированы с точки зрения интересов, то есть у этих агентов внизу справа все интересы ограничиваются X и Y, а у трех слева вверху интересы ограничиваются A и B. Если же мы возьмем другие когнитивные параметры у всех агентов, максимизируем социальную открытость, соответственно все очень коммуникабельны но когнитивные ограничения, то есть имеем ограниченные возможности к запоминанию и перевариванию информации. Здесь возникает другая ситуация. После тех же трех итераций все агенты сливаются в единое, так сказать, когнитивное пространство, все выравниваются, все, так сказать, похожи друг на друга, но при этом у них проходит некоторая потеря некоторых знаний, то есть у них все фокусируются в данном случае на X, И понемножечку на A, B и Y. А про C и Z вообще все дружно забывают. То есть происходит некоторое выравнивание, при этом, что интересно, мы обнаружили следующий эффект. пошли смотреть, читать литературу, оказалось, что этот эффект в психологии известен. Эффект следующий называется ресенси или эффект недавности, что когда все агенты, допустим, когда идет обсуждение некоторой темы, то на принятие решения, консенсус, на консенсус максимально влияют в среднем те агенты, которые говорят последним. И мы как раз это подтверждаем. Например, в этом эксперименте в первую очередь агенты говорили по очереди на каждой итерации. Сперва этот, всем, потом этот, всем, потом этот, всем, потом этот, всем, потом этот. Я прошу прощения. И выяснилось, что вот консенсус в этой ситуации сдвигаются к интересам последних двух агентов X и Y. Вот X и Y было в начале у пятого и четвертого, вот, и вот большинство, консенсус клонился в область как раз пятого и четвертого, X и Y. А если мы будем агентам давать говорить в рамках каждого раунда дискуссии в обратном порядке, у нас все сместится в первую. И я сразу же вспомнил, что есть такие руководители, которые в начале встречи дают высказаться всем, а потом произносят свое веское слово, тем самым перевешивая консенсус. Такой интересный аспект мы тоже подтвердили. Спасибо за внимание. Я уложился в полтора часа. Я молодец. Какие будут вопросы? 

S03 [01:24:13] : Ситуация на последних минутах. Я думаю, что нужно будет просто в записи посмотрим. 

S02 [01:24:24] : Алло, меня слышно? 

S01 [01:24:26] : О, у меня звук был выключен. Я извиняюсь, оказывается у меня был выключен звук, я ничего не слышал. 

S02 [01:24:33] : Да, и презентация там пропала. 

S03 [01:24:37] : Это где-то последние 10 минут. 

S01 [01:24:39] : Ой, ой, ой, какой ужас, какой ужас. Давайте тогда снова. Да, вот это вот обидная накладка. Да. Вот, то есть, давайте я тогда быстренько выбегу. С какого момента презентация пропала? 

S02 [01:24:56] : Ты даже не сразу заметил, как бы слушал, а непонятно было, что показывали. 

S01 [01:25:07] : Да, это печально. Да, это вот у меня скринсейвер сработал, вот, и в скринсейвере все погасилось. Ну, значит, смотрите, да, давайте тогда вопрос. 

S00 [01:25:19] : Вот это видели. 

S01 [01:25:22] : Это видели? 

S00 [01:25:24] : Так, это видели. 

S01 [01:25:27] : Давайте я тогда здесь быстренько повторюсь, чтобы связать то, что я говорил, с тем, что на картинке. Здесь как раз иллюстрация того, что если мы строим некоторого персонального ассистента или коллективного ассистента корпоративного, то он должен иметь в себе модель. членов социума, с которым он работает или который окружает конкретного пользователя. Соответственно вот у нас в реальном мире есть люди с отношениями друг между другом. Вот у нас есть агент, у которого есть некоторые данные и часть этих данных она отводится собственно представлению социальной среды. Дальше вот собственно как раз вот этот вот четырехдольный граф где у нас есть наверху несомненные истины, в которые мы верим и не подвергаем сомнению социальные связи, на основе которых мы делаем оценки поступающих фактов. При этом эти социальные связи могут быть как между людьми, так и между людьми-источниками информации. То есть я могу социальные связи и уровни доверия записывать как между там Вася и Петя, так и между Васей, допустим, какой-нибудь газетой или каким-то научным журналом или каким-нибудь телеграм-каналом, к примеру, да, вот. Ну и есть некоторый процесс вывода, значит, того, что мы думаем на самом деле, что мы хотим делать на основе того, той информации, которая находится вот в этом графе. В этом графе, допустим, у нас есть информация о том, какие есть напитки. Если мы строим рекомендательную систему, в социальном графе у нас есть наши друзья. и отношения с нашими друзьями. Маша это наш лучший друг, Петя это просто наш друг, а Вова это друг Пети, но не наш друг. Вот и есть предпочтение вот всех этих людей в нашем социальном графе. Исходя из предпочтений наших друзей или там знакомых или друзей, друзей и знакомых, знакомых и наших отношений с ними, мы можем строить, грубо говоря, некоторую рекомендацию того, Что мы будем заказывать в ресторане, когда мы пойдем вместе с ними в ресторан. В данном случае, исходя из того, что мой лучший друг Маша, и Маша любит джу и любит сок, я буду заказывать себе сок, а не пиво. Соответственно, вот есть математика, которая это все описывает, которая есть в слайдах, которые я посылал и рассказывал в прошлом году, и вот эта математика вот так вот ложится на этот граф. Вот, собственно, как раз структура социума, которую мы моделируем, что на старте мы имеем более-менее однородное сообщество, где есть некоторые как это, социальный хаб, который объединяет двух товарищей наверху и двух товарищей внизу, а в результате общения между ними, значит, если вот этот вот товарищ в середине все-таки ближе к этим двум, он к ним смещается со временем, а эти двое остаются сами по себе. И чем дальше, тем больше, если нету никакого внешнего давления, допустим, если там нету каких-то, допустим, угроз, которые объединяют это сообщество в целом или там общих целей очень сильных, которые их должны объединить, то постепенно они расходятся на различные социальные кластеры. И здесь как раз иллюстрации, про которые я говорил. Слева направо у нас исходное состояние и три различных итерации. по горизонтали идут идеи или концепты или предпочтения, которые есть у агентов, по вертикали агенты, вот карта распределения вот этих вот концепций или предметов верования или интересов агентов. Соответственно, вот в одной настройке, когда есть социальная ограниченность и высокий когнитивный ресурс, у нас со временем, значит, формируется два кластера, агенты 1, 2, 3 верят в А и В, а агенты 5 и 4 верят в X и Y. Вот, соответственно, по горизонтальной оси мы видим матрицы Сходство билифов или, так сказать, систем убеждений разных агентов. Мы видим, что вот в конце итерации в нижнем ряду у нас вот справа первый, второй, третий агент сливаются в один кластер, все между собой похожи. Агенты 4 и 5 сливаются между собой, а друг с другом они мало пересекаются. А в другой установке, когда высокая социальная открытость и нижние и ограниченные когнитивные ресурсы, то в результате вот этих вот последовательных итераций у нас все сливаются в единое когнитивное пространство, обретают, так сказать, пресловутую единую религию, но при этом некоторые значимые вещи из их общей новой картины мира выпадают, концепты C и Z оказываются утеряны в культуре данного социума. Извиняюсь, что пришлось повторить. Еще раз вопросы. 

S02 [01:30:37] : У меня есть вопрос. Вы вначале сказали, что когда мы обучили вождение, то есть педаль, машина, рычаги, то этот обученный паттерн находится во второй системе. Если это так, то что тогда остается в первой системе? 

S01 [01:30:59] : Смотрите, возьмем этот пример. На одном из семинаров, несколько лет назад мы его как раз разбирали. Представьте себе, что мы пришли в автошколу. Нам говорят, ты садишься, сначала сел, потом посмотрел в зеркало, потом завел мотор, потом ты включил передачу, точнее выжал сцепление, включил передачу, потом ты выжимаешь сцепление, давишь на газ и при этом еще за руль держишься. И мы очень тупо, очень медленно это делаем, у нас там глохнет мотор, то есть мы напрягаемся и какое-то количество раз мы это повторяем мучительно, как бы проговаривая себе вслух или мысленно эту схему, но постепенно у нас эта схема Она в результате многократного повторения, вспоминаем, что система 1 – это обучение в результате многократного повторения для последующего быстрого принятия решений. Вот при проследовательном многократном повторении, сначала медленном, потом чуть-чуть побыстрее, потом чуть-чуть быстрее, у нас вот эта вот последовательность, она, что называется там на жаргоне, закачивается в подкорку. А в реальной жизни она просто происходит тренировка нейронов, которые находятся ближе к мозжечку, ближе к спинному мозгу. И чем дальше, тем больше мы решения, в какой момент сцепление выжать, в какой момент газу подать, мы их принимаем уже автоматически. И после того, как мы прошли школу вождения и пару месяцев поездили, мы уже, садясь в машину, можем разговаривать по телефону, разговаривать с женой, слушать аудио, вообще не думая о том, что мы двигаем и что мы переключаем. То есть идея заключается в том, что эти две системы действуют комплементарно. Более того, есть эксперименты, есть статья из нейрофизиологии, в группе я ее даже скидывал, если кому интересно, можно будет найти, где показано, что эти две системы конкурируют между собой. Бывают ситуации, что эти две системы говорят разное. Грубо говоря, хочется одного, а разум говорит другое. Это как бы предельный случай. Или интуиция подсказывает быстрее, чем разум. И разум потом подтверждает, что интуиция была права. 

S02 [01:33:42] : Ну, смотрите, мы, допустим, когда не вождение учим, а логику изучаем или какую-нибудь науку, ведь у нас все равно она остается во второй системе, она на первую не переносится. Ну, я к чему это все? У меня просто другое немножко представление, поэтому, как бы... 

S01 [01:34:06] : Вы хорошо сказали, но что оно не переносится в первую систему – это очень интересный вопрос. На самом деле, хорошую тему подняли, потому что я могу предположить, что вот пресловутые озарения, они возникают как раз тогда, когда данные из логической системы перетекают в ассоциативную, да, и неожиданные, так сказать, открытия, они возникают в результате вот, так сказать, некоторых неосознанных галлюцинаций, которые, так сказать, проступают уже вот в логическую систему и непонятно откуда, да, вот нас осенило, что вот оказывается так можно сделать. Мы поставили эксперимент, действительно можно было так сделать. 

S02 [01:34:53] : Да, это интересно. Я просто немножко по-другому это воспринимаю. Я думаю, что первая система это наше бессознательное, а вторая система это как раз-таки сознательное мышление, которое обучает бессознательное. А у вас получается, что именно вождение, оно всегда в первой системе. 

S01 [01:35:11] : Я не говорил, что вождение всегда в первой системе. Когда мы начинаем учиться, вождение, конечно, всегда в первой системе. А потом, значит, когда у нас нет стресс-ситуа, а потом у нас оно постепенно переходит, оно в процессе обучения, любая повторяющаяся активность, она из второй системы постепенно переходит в первую. То есть вот тезис. 

S02 [01:35:36] : Так, я что-то запутался. Первая, вторая, может я ошибаюсь? 

S01 [01:35:40] : Значит, первая система по классике – это подсознание. Это подсознание, долгое обучение, быстрое принятие решений. Вторая система – это сознание, быстрое обучение, медленное принятие решений. Быстро воспринимаем, долго думаем. Это вторая система, сознательная. 

S02 [01:36:08] : Ладно, Антон, я не хочу задерживать. Я еще подумаю на эту тему. Я вам отдельно выскажу свое мнение. Хорошо. 

S01 [01:36:21] : Так, коллеги, еще вопросы? Ну, если вопросов нет, тогда я подведу итог анонсам, про которые я говорил в начале. То есть, как я уже говорил, у нас сообществу уже более 10 лет. Достаточно уникально то, что у нас последние пять лет еще и практически каждую неделю семинары проходят, где такие выдающиеся люди, как Сергей Шумский, Игорь Пиваров, Александр Балдачев рассказывают свои концепции. Но нам захотелось сделать некоторый формат, где разработчики, которые находятся на раннем этапе своего пути, могли бы взаимодействовать как друг с другом, так и с экспертами более высокого уровня для обсуждения своих собственных проектов. Через несколько дней мы сделаем анонс у нас в группе и пригласим всех участников нашего сообщества к участию в таком узком, закрытом, более сфокусированном на достижении каких-то практических результатов формате. 

S02 [01:37:36] : Антон, можно еще последний вопрос? Да, давайте. Скажите, а вот переход из второй системы в первую – это вообще что такое? То есть, допустим, мы обучаем, мы думаем о том, что делать, мы тренируем нашу мышечную память, как бы, да, мышечная память – это как раз первая система. А когда переход, когда мы выучили, что происходит, как, или это процесс непрерывный, что вторая система? 

S01 [01:38:04] : Давайте я отвечу. Во-первых, есть точка зрения, что это все первая, вторая система, что это все спекуляция. что совсем не так, с одной стороны. С другой стороны, я соглашусь с тем, что этот процесс непрерывный, вот как я пытался на этих слайдах показать, что четкой границы между ними нет, что у нас знания, которые находятся во второй системе, пресловутые символы, Они, на самом деле, привязаны к ассоциативному через пресловутый имбеддинг. То есть, что такое символ? Символ – это подпомеченный некоторым понятием имбеддинг, построенный либо на некоторых других символах, либо на некоторых сенсорных данных, которые не имеют своего именования. и которая находится, собственно, вот в этой ассоциативной памяти. Соответственно, во-первых, четкой границы между ними нет, то есть эта граница плавная. Во-вторых, динамика процессов, как минимум, в коре головного мозга такова, что у нас все нейроны, любая группа нейронов, она в единицу времени может самостоятельно функционировать. Соответственно, если у нас возникает некоторая активность, то у нас поиск решения может осуществляться как на верхнем уровне, условно говоря, так и на нижнем уровне, так и в совокупности. Весь вопрос в том, на практике, да, если мы возьмем человеческий организм, что если, ну и это, кстати, значит, на семинаре с Антоном Морозовым это тоже, значит, вопрос обсуждали, что много, я вот, кстати, вот даже пример приведу, значит, что ставили эксперимент такой, значит, брали кошку, несчастную, заранее предупрежу. И ставили эту кошку на тренажер, где лента движется. И ставили эту кошку в некоторый станок, чтобы она не могла убежать, чтобы она была вынуждена идти по этому станку. И вот кошка шла по этому станку, по движущейся ленте. После чего кошке там где-то в верхней части перерезали позвоночник, Таким образом, что она не могла идти, если движущаяся лента не двигалась. Если она стояла на полу, и кошки показывали еду, она не могла идти. Но если ленту включали, кошка начинала перебирать лапами, как будто она идёт. То есть смысл какой? Что вот некоторое базовое, поведение, да, оно у данной конкретной кошки, оно управлялось в этом эксперименте на уровне спинного мозга, да, базовое сгибание-разгибание ног, а вот управление, допустим, целенаправленное, значит, того, значит, в какую сторону идти, передним вперед или назад, оно требовало уже включения ленты или наличие действующей связи спинном мозга. Дальше возникает интересный вопрос, а вот это вот поведение по перебиранию лапами было ли оно за хардкожено и предопределено структурой нервных связей, которая уже находится что называется на своем месте при рождении кошки, вот, или это вот, когда она была котенком, она этому обучилась и приобрела это знание, это знание вот закачалось туда, так сказать, даже не в подкорку, а, так сказать, спиной мозг. Вот, это вопрос интересный, вот. У меня есть большое подозрение, что когда мы в одном из своих докладов несколько лет назад, я пример как раз с автомобилем давал в свете обучения всяким акробатическим трюкам во всяких экстремальных видах спорта. Так вот, получается в моем понимании, что когда осуществляется какая-то сложная физическая деятельность, скажем так, требующая высоких скоростей реакции, то определенные технические элементы спортивные, их просто невозможно выполнить в силу скорости ограничений. То есть невозможно выполнить, что называется, через центральную нервную систему, потому что в силу большой скорости. То есть, по-моему, там нервный импульс проходит что-то, значит, один метр там в какую-то долю секунд. Соответственно, если нужно решение принимать за доли секунды, то через мозг прокачать этот канал, допустим, от ноги до головы и обратно просто не успеешь. Соответственно, нужно обучаться, вгонять в подсознание, не только в подсознание, но и в мозжечок, а еще и в спинной мозг какие-то базовые реакции, чтобы они осуществлялись на уровни сенсорики и мышечной памяти, конечно, потому что мышц памяти нет, но на уровне спинного мозга. 

S02 [01:43:23] : Ну, ответ, наверное, может быть захардкоженный или нет. Будет ответом, что когда мы рождаемся, у нас-то нету... Ну, мы не умеем ходить, ни кошка, ни мы. То есть, мы об этом обучаемся. Поэтому, я думаю, что это не захардкоженный. 

S01 [01:43:39] : А вот, смотрите, значит, вот как раз давайте... Хороший, на самом деле, вопрос. Приведу пример. Значит, Евгений Евгеньевич Витяев в своих докладах рассказывает, дает пример, что жеребенок, как только родился, вот новорожденный жеребенок, он сразу встает на ноги и, пошатываясь, подходит к тому месту, где у мамы можно молока пососать. То есть получается, что в какой-то степени он уже предконструирован до какого-то уровня, как я показал. То есть мы, допустим, даем агенту на старте некоторую предварительную модель, но он дальше уже очень быстро ее дообучает. 

S02 [01:44:30] : Но сам факт, что он шатается, уже говорит о том, что модели еще нет. Она предобучена, но не полностью. 

S01 [01:44:37] : Да, но она не предобучена, потому что предобучаться ходить в животе не может, она как бы преконструирована, но она дообучается. Но ее нет. 

S02 [01:44:50] : Но ее нет. Ну окей, я другое хотел еще спросить. Можно к первому слайду? 

S00 [01:45:06] : Так, вот это? 

S02 [01:45:08] : Нет, вот там, где, ну, там, где... Можно это, можно это стать, да. Смотрите, мы, когда спим, у нас мышления нету, но в то же время мы переворачиваемся, когда, ну, там у нас, не знаю, как сказать, пролежни, или когда у нас что-то, отлежали ногу. Но системы второй нет. Тут тоже вопрос, это за хардкожено или нет. Руки-ноги двигаются. Если сердце, можно предположить, что у нас за хардкожено. то есть мы не управляем сердцем, то мышцами мы и можем управлять, и в то же время наша бессознательная может управлять этими мышцами. То есть вы сказали, что эти две системы как бы это одно, и они не отдельные. Все же мне кажется, что они как-то отдельные, потому что когда мы выключены, системы второй нет. 

S01 [01:46:12] : Я не знаю, правильно я... Я понимаю, про что вы говорите. Если или нет вторая система, это вопрос интересный. Вот, потому что, если здесь можно на эту тему... У меня нету определенного мнения, я просто некто рекомендацию дам. Значит, во-первых, допустим, мы видим сон. Вот когда мы видим сон, мы же часто бывает, что мы во сне принимаем какие-то решения, Так вот, сейчас я договорю, возможно два варианта, у меня нет убедительного ответа, либо мы действительно принимаем эти решения в некотором виртуальном мире, просто эти решения никак не доводятся до наших органов чувств, органов действий, то есть мы как будто решаем, что мы куда-то встали и куда-то идем во сне, но на самом деле мы лежим, то есть мы приняли воображаемое решение, которое не дошло до актуаторов. Это одна гипотеза. Вторая гипотеза, что на самом деле мы просто смотрим некоторый видеоряд, где в этом видеоряде записано, что мы приняли решение. То есть мы на самом деле не принимаем решение в виртуальном мире, а на виртуальном мире нашего сновидения сообщается о том, что мы приняли решение. Что является истинным, на самом деле, я не знаю. Есть гипотеза такая, что мы даже в реальном мире на самом деле принимаем решение до того, как оно принято и нам просто сообщается о том, что мы якобы его приняли. Есть такие точки зрения. Но точно я сказать не могу. 

S02 [01:47:52] : Когда мы просыпаемся и пытаемся проанализировать этот сон, чаще всего это какой-то бред оказывается. То есть, если бы в этот момент мозг, у нас было логическое мышление, этот сон был бы абсурдным. Ну, я не знаю, может быть, не все сны абсурд, но большинство. 

S01 [01:48:13] : Я вам дам другой пример. Смотрите, я вам точно могу дать свой собственный аргумент, что на самом деле сознательное поведение есть. Дело в том, что в какой-то момент я научился сознательно просыпаться, когда мне начинали сниться кошмары. То есть периодически мне снились кошмары, Вот, и в какой-то момент я понял, что вот когда совсем плохо, да, я просто, я думал, что ага, я же сплю, но я же сейчас могу проснуться, и я просыпался. Причем я этот, в какой-то момент я этот трюк достаточно четко отработал, и я всегда просто мог просыпаться, когда вот дело становилось очень плохо во сне. 

S02 [01:48:56] : Ну, просто система 2 обучила систему 1, что просыпайся, когда тебе 

S01 [01:49:02] : Нет, я просто помню, что это осознанно, то есть это вот именно осознанная мысль о том, что я хочу проснуться, то есть сейчас мне будет плохо, но я понимаю, что это сон, и поэтому я должен проснуться. Опять-таки, вы можете аргументировать, что на самом деле это мне подкидывается видеоряд, да, то есть меня система начинает, меня система 1 начинает будить и, значит, сообщает и делает вид, что это я сам принял это решение, подкладывает мне этот, так сказать, мой поток сознания. Может быть и так, не знаю. 

S02 [01:49:38] : Да, только предварительно система 2 обучила, слушай, если ты будешь там сняться, как бы, кошмары, это плохо, значит, надо что-то с этим делать. И вот этот факт обучил первую систему, когда будет сниться кошмар, ты там просыпайся. Ну, я так... Может быть. 

S01 [01:49:58] : Но опять-таки мы приходим к тому, что эти системы могут быть действительно разные, но у них, скажем так, единое сенсорное поле. То есть вот видите, как здесь нарисовано, пространство системы – это они разные, но пространство одно. То есть они работают в одном и том же пространстве. Опять-таки, это пространство может быть как-то сегментировано, то есть, грубо говоря, сознание не работает с сердцем, а интуиция не работает с тензорной логикой, потому что оно слишком далеко от таких абстракций, как математические символы. Но какие-то вещи, допустим, бег, ходьба, еда, они находятся в общем поле. Они доступны и той и другой системе. 

S02 [01:50:52] : У меня другое представление, потому что я думаю, что это разное пространство. Ощущение как раз... Ну ладно, это уже про мою систему. Не в этом, наверное, видео. Я считаю, что разные пространства и разные уровни, потому что, например, у нас есть эмоции и ощущения, а, например, чувства – это уже пространство мышления. Ощущения и эмоции – это результаты работы системы, а не сенсорные данные. Но это уже моё видение, не хочу навязывать. 

S01 [01:51:29] : Окей. Коллеги, еще вопросы или комментарии? Ну, тогда всем спасибо. Во-первых, напоминаю ждать анонса по поводу приглашения в закрытую группу у нас в семинаре. Следующую неделю семинара не будет, потом у нас будет конференция OpenTalks.ai. Ну, а в марте месяце мы продолжаем семинары. Всем спасибо за участие, за вопросы и до новых встреч. 

S04 [01:52:31] : Антон Германович, отлично, мне кажется, прям прекрасно прошел сегодня. 

S01 [01:52:35] : Да, да, сейчас, секундочку, я сейчас пытаюсь как-то запись остановить. Угу. Сейчас, что-то мне это не дается. Так, стоп. О! 







---

https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html


