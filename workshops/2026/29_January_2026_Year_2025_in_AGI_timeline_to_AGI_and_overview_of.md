## 29 января 2026 - 2025 год в AGI: таймлайн до AGI и обзор основных работ - Татьяна Шаврина  - семинар AGI
[![Watch the video](https://img.youtube.com/vi/7CpfvphJJNI/hqdefault.jpg)](https://youtu.be/7CpfvphJJNI)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239242)
- [видео в Telegram](https://t.me/agitopics/53344/68395)
- [видео в RUTUBE](https://rutube.ru/video/a2ceedfb8b2d69013078217c0bee53e3/)
- [презентация](https://github.com/agirussia/agirussia.github.io/blob/main/presentations/2026/2026_AGI_Russia_LLM_T_Shavrina.pdf)
- [расшифровка](https://github.com/agirussia/agirussia.github.io/blob/main/workshops/2026/29_January_2026_Year_2025_in_AGI_timeline_to_AGI_and_overview_of.md)
- https://t.me/rybolos_channel
- https://www.linkedin.com/in/tatiana-shavrina/
- https://iling-ran.ru/

---

### Основные темы доклада

**1. Итоги 2025 года и текущий ландшафт**
*   **Proprietary vs Open Source:** Проприетарные модели (OpenAI, Anthropic, Google) остаются на фронтире, но Open Source периодически их догоняет, хотя лидерство все равно возвращается к закрытым моделям.
*   **Reasoning (Рассуждение):** Способность к рассуждению стала стандартом для всех крупных моделей (после O1, DeepSeek и др.). Появилось понимание, что рассуждение нужно не всегда: модели учатся определять, когда отвечать быстро, а когда нужно «подумать».
*   **Смена парадигмы обучения:** Происходит отход от обучения с подкреплением на основе человеческих предпочтений (RLHF), так как они субъективны и не помогают в сложных задачах (код, наука). Фокус смещается на **верифицируемый результат** (код запустился/не запустился, теорема доказана/нет).

**2. AI-агенты в науке и программировании**
*   **AI Scientist:** Упомянут кейс стартапа Sakana AI, чья статья, сгенерированная AI, прошла рецензирование (хоть и была отвергнута комиссией).
*   **Проблемы агентов:**
    *   Генерация научных идей пока слабая: 24–36% идей являются скрытым плагиатом.
    *   Сложные задачи (например, полная оптимизация обучения языковой модели с нуля) решаются плохо без подсказок.
*   **Бенчмарки:** Появились новые бенчмарки для агентов (MLE-bench, MLGym), где оценивается способность агентов проводить ML-эксперименты. Текущий успех: агенты пока не могут эффективно работать 12 часов подряд, как люди, но процент валидных решений растет.

**3. Методология науки и воспроизводимость**
*   **Кризис воспроизводимости:** В Computer Science воспроизводимость статей составляет около 48% (не выложен код, данные, скрыты гиперпараметры).
*   **Роль AI:** Агенты могут помочь решить эту проблему, выступая автоматическими верификаторами и рецензентами.
*   **Философия:** Обсуждались подходы Поппера (фальсифицируемость), Куна (смена парадигм) и Фейерабенда (методологический анархизм). Бен Герцель предлагает адаптировать методологию науки, чтобы она была более машиночитаемой.
*   **Уровни развития AI-ученого:**
    1.  Работает внутри текущей парадигмы (текущий уровень).
    2.  Предлагает новые примитивы внутри парадигмы.
    3.  Предлагает фундаментально новую научную парадигму (инноватор).

**4. Прогнозы на 2027 год и критика графиков роста**
*   Существуют прогнозы (от Anthropic, METR) об экспоненциальном росте возможностей AI и достижении уровня AGI или «сверхчеловеческого исследователя» к 2027 году.
*   **Критика Татьяны Шавриной:** Графики, предсказывающие экспоненту, основаны на смещенных данных. В выборке бенчмарков сотни простых задач (решаются за минуты) и единицы сложных (решаются за часы). Это создает иллюзию экспоненциального роста, хотя реальный прогресс на сложных задачах может быть линейным.

### Основные моменты дискуссии (Q&A)

*   **AI-рецензент vs AI-исследователь:** Создать агента-верификатора (рецензента) проще и полезнее в краткосрочной перспективе, чем агента, генерирующего научную новизну.
*   **Будущее ученых:** Вероятно появление гибридных команд «человек + агент». Рутинные эксперименты будут автоматизированы, но поиск принципиально новых идей пока остается за человеком.
*   **Нейросимвольные методы:** Трансформеры доминируют, но символьные подходы и чистый RL (без трансформеров) живы и эффективны в узких нишах (математика, графовые базы знаний). Интеграция парадигм происходит на инженерном уровне.
*   **Память и контекст:** В будущем контекстное окно модели, скорее всего, будет иметь приоритет над встроенной памятью (весами) и внешней базой (RAG), чтобы обеспечить актуальность данных.
*   **Baby Turing Test:** Обсуждалась необходимость бенчмарка на способность модели к самообучению (learning how to learn), а не просто проверке знаний.

### Ключевой вывод
Мы находимся на этапе, когда языковые модели переходят от «болталок» к агентам с верифицируемым результатом (код, наука). Однако текущие прогнозы о скором AGI (2027 год) могут быть завышены из-за несовершенства методологии оценки. Главный вызов сейчас — научить агентов не просто оптимизировать существующие решения, а генерировать валидную научную новизну.


## Расшифровка доклада:


S01 [00:00:00] : Коллеги, всем добрый вечер. У нас есть, как вы знаете, многие знают, может быть, кто-то не знает, сейчас узнают, добрая традиция в сообществе. На Татьянин День к нам приходит Татьяна Шавлина и рассказывает о том, чего удивительного, грозного, опасного и прекрасного произошло за последний год и, возможно, ожидает нас в следующем в области общего искусственного интеллекта. Татьяна, пожалуйста. 

S02 [00:00:25] : Добрый-добрый день всем. Очень рада всех видеть и слышать. Спасибо всем, кто пришел на трансляцию. Так, я начинаю шарить экран. Сейчас должно быть его видно. 

S01 [00:00:40] : Да, все хорошо. 

S02 [00:00:47] : Замечательно. Вот, поскольку у нас сегодня, я не знаю, у меня материалы на очень, как бы, долгое время, я постараюсь себя контролировать по части тайминга, но все же, наверное, если у вас по ходу возникают предложения или вопросы, лучше задавать их сразу, вот, чтобы у нас инициировалась дискуссия, и потом, когда я пройдусь по материалу, тоже мы бы подискутировали. потому что интересного происходит много. Собственно, сегодня хочется поговорить про вот все то, что произошло до текущего момента, так скажем, от прошлого обзора, который мы делали примерно год назад. И я так сформулировала, что мы посмотрим Мы уже встречаемся, тут не первый год, я начала смотреть, а что же там в прошлом году, может быть, как-то соединить с выводами там прошлого года, и оказалось, что вообще-то мы уже встречаемся, это наша добрая традиция уже достаточно многолетняя, с небольшими перерывами она идет Вот. Так что спасибо большое, что приглашаете. И, наверное, сквозь вот такие обзоры прослеживаются некоторые основные темы, которые нас волновали. Да, это соединение речевых технологий, вообще лингвистики и будущего искусственного интеллекта до ChatGPT и затем сразу после ChatGPT. Это будет ли достаточно языковых моделей, какие у них есть проблемы, что делать. с их фронтирными способностями, что делать с проблемой AI-сейфти, ну и просто каков наш прогресс за прошлые годы. Собственно, сегодня мы посмотрим на то, что все-таки произошло с некоторым, ну, так скажем, паэсом относительно того, мне кажется, какие вещи основные. Посмотрим немножко на некоторые временные рамки, прогнозы, можно ли им доверять, да, нам, может быть, и хотелось бы им доверять, потому что раньше мы с вами говорили про AGI, про его наступление, и всегда там, если разных специалистов спросишь, там были опросы, там, ну, наверное, в 50-м, наверное, в 30-м, да. Тем не менее, мы всегда видим, что, говорят, ну, в 27-м уже точно с этими прогнозами про 27 год. Немножко поговорим про методологию науки, почему она опять стала важна, и какие вообще есть новые подходы, чтобы справиться с кризисом методологии науки, который у нас сейчас есть, благодаря автоматизации и агентов. Ну вот, если мы посмотрим на основные достижения 27-го года, к его концу, и посмотрим на то, что предсказывалось, так скажем, индустрии про то, что, значит, всё-таки в нём случится, ну, не всё сбылось, на самом деле. То есть как бы сбылось не всё, но из того, что предсказывали, и оно произошло, это, естественно, прогресс в области Написание научных работ, верификация экспериментов. Вот, собственно, у нас статья, сгенерированная стартапом SACAN и их прототипом AI-Scientist второй версии, была принята на воркшоп ICLR, одна из крупнейших конференций. Они послали туда несколько работ, одну работу приняли, они потом рассказали, действительно, что эта работа была нечеловеческая. Ее по итогу комиссия решила не принимать, но по результатам рецензирования она была принята. Точно так же из того, что продолжают проходить существенные улучшения способностей языковых моделей, все еще там, хотя говорят, что языковых моделей будет недостаточно, все-таки пока мы не уперлись в потолок, и наоборот, за счет того, что конкурирует постоянно закрытые языковые модели Open Source, И Open Source даже догоняет периодически. Несколько раз в 2025 году мы были в ситуации, когда Open Source на языковые модели были лучше, чем проприетарные. До этого всегда мы говорили, что между ними разница в несколько месяцев, прогресс как минимум, но вот эта ситуация в 2025 году поменялась на время. Вот. И с точки зрения инфраструктуры и основных игроков в проприетарных технологиях тоже ничего практически не поменялось. С точки зрения именно исследований и результатов основных, собственно, на текущий момент проприетарные модели все равно самые фронтирные. Пока что от этого мы никуда не ушли, и, в общем-то, периодически Open Source все-таки догоняет, но это происходит на время, и потом проприетарные модели все равно берут вверх, потом опять догоняют open source, потом опять проприетарные модели берут вверх. Происходит это в основном в очень специфических областях. В прошлом году, мы когда с вами говорили про новые способности, которые реально важны для прогресса и агентов, и языковых моделей, Мы их упоминали. Мы говорили о том, что появились новые бенчмарки, новые способности ключевые, которые вот еще не сатурированы пока, в которых большой разброс результатов, в которых не очень хорошие результаты. И вот на них-то, собственно, и приходится основная разница. Это все, что касается написания кода. Это software engineering, это ML-инжиниринг даже уже. Это математика, это вывод математических доказательств, различные математические олимпиады, области математики разные, где требуется автоматизация написания доказательств, и есть язык, в рамках которого можно это представить и все. И это reasoning. И это reasoning, естественно, как способность с помощью такой более длинной генерации прийти к более точному ответу. Ризнинг, собственно, действительно стал большим прорывным направлением 2025 года. Все, у кого ризнинга не было, ризнинг приобрели, все ключевые лаборатории инвестировали в существенное исследование в то, что именно у их фронтерных моделей способность к ризнингу была. И после O1, потом появился DeepSeq, а потом, естественно, и все остальные модели тоже приобрели какой-то режим, и Zynga, и Gemini, и Cloud. И, в общем-то, на текущий момент можно сказать, что это является стандартом для более высокого качества в таких сложных областях по типу написания кода. И, собственно, Что здесь еще происходит, это, собственно, контроль ризнинга. То есть мы говорим о том, что ризнинг нам нужен не всегда, и мы теперь это знаем очень хорошо в 25-м году, что у нас есть разные режимы, так скажем, работы модели. Если есть черчат с пользователем, нам ризнинг не нужен. Нам не надо тратить 30 тысяч токенов на то, чтобы гипсик или клод пошли подумали. написал пользователь, что же ему ответить. Теперь мы просто знаем, что для этих случаев ризминг не нужен. И это некоторый такой комбинированный режим работы языковых моделей, когда мы не только учим модель качественно отвечать, но и как бы мы ее еще учим определять, в каких конкретных случаях вообще ризминг нам необходим и в каком объеме, потому что есть позволяют контролировать объем лизминга. Вот здесь чуть-чуть подумать, здесь можно и подольше подумать, а вот здесь можно и написать еще и код, запустить его, получить какой-то результат и, собственно, исходя из этого результата, еще подумать и вернуться к пользователю. Да, вот такой режим тоже теперь есть у всех. Ну, и, собственно, про промежуточный результат. В прошлые годы мы с вами часто говорили, что языковые модели и проблемы с их обучением, с их алайментом, с их безопасностью, они завязаны на том, что в основном на последних этапах обучения моделей и агентов используется обучение с подкреплением, которое использует human preferences. Human preferences, то есть то, получает, ну, условно, наибольший вес. И с большей вероятностью наша языковая модель или агент будет нам отвечать так, чтобы нам больше понравиться, чтобы мы чаще возвращались к чат-боту, это был бы наш виртуальный друг, у нас бы повышался там retention, время, проведенное в приложении и так далее, и так далее. и как бы это имеет под собой определенный, конечно, бизнес мотивацию, но это совершенно не помогало разработчикам и исследователям в решении вот, опять же, сложных задач, таких как написание кодов. В написании кодов human preferences как будто бы не так уж и сильно нам помогают. Наверное, можно спросить разработчиков и там подобрать примеры некрасивого, плохо оформленного кода или каких-то очень тривиальных, плохих решений, изящных, и на них собрать. Но, в общем-то, это нам не очень помогает. А помогает нам то, что называется сейчас верифицируемым результатом. Или подкрепление с верифицируемым результатом. И, собственно, На это сейчас уходит основной фокус. У нас существуют разные форматы, когда вот агент написал код, пытается его запустить, он работает, не работает, бинарный сигнал, правильно, неправильно. И мы хотим учить агентов так, чтобы всегда было правильно, допустим. Да, это может быть частичная правота-неправота, вот здесь вот правильно сделал, вот здесь неправильно. Это может быть оценка решения, основанная на рубриках, но тоже часто они бинарные, есть-нет. В доказательстве математическом оцениваем его и говорим, вот эта часть есть, балл мы приписываем и так далее. У нас какая-то балльная система. И верифицируемый результат — это то, что мы получаем объективно в таких областях, как код, как эксперименты, как ответы, где есть правильный реально правильный ответ, где можно вывести доказательства прямо и сравнить ответ классический или классическое доказательство. Это все является верифицируемым результатом. И оно позволяет нам, на самом деле, создавать очень интересные системы, в которых у нас рекурсивно агенты и языковые модели могут корректировать себя. То есть агент у нас может написать в код решение какой-то проблемы, запустить его, увидеть, что что-то получилось, что-то не получилось, там, может, не запустился, где-то на какой-то строке ошибка, поправить эту ошибку, еще раз подумать, запустить лизеринг, подумать, переписать код, еще раз запустить. Так сделать несколько раз, посмотреть на численный результат эксперимента, смотреть, сравнить его с бейслайном. и решить, что, собственно, ну вот, кажется, это достаточно хороший результат получился, могу возвращаться с пользователем, с этим результатом. И это все происходит без непосредственного участия пользователя. То есть это система, которая у нас благодатная почва, так скажем, для создания систем, в которых агенты могут накапливать данные для того, чтобы их дальше дообучать. Давайте так посмотрим. У нас способности к кодингу, к написанию качественных софтверных решений улучшаются, к ризнингу улучшаются. Это мы фокусируемся на задачах, где есть верифицируемый сигнал какой-то, то есть на правильном направлении или нет. улучшился результат в результате наших действий или ухудшился. И все это нам позволяет сделать качественный скачок к тому, чтобы улучшить, собственно, наиболее франкивную, на мой взгляд, область. это применение агентов к акселерации науки. И первое, где это происходит, это, безусловно, сам AI Research, потому что исследования в области искусственного интеллекта, ну, простыми с точки зрения их формальной верификации. В них можно все запустить, можно все проверить, можно получить объективно какие-то метрики и посмотреть, как бы сравнивать итеративные метрики, которые у вас получаются. С точки зрения качественной новой архитектуры, хорошая архитектура, допустим, нового трансформера — это такая архитектура, которая, не знаю, LOSS имеет меньше на тех же обучаемых данных, что и предыдущая. опасная, лучше генерализуется. Вот такие критерии, в принципе, они все являются хорошо измеримыми, поэтому все это можно поручить агентам. Ну, с некоторыми оговорками, о которых мы еще поговорим. И вот, собственно, одним из таких индустриальных стандартов оценки таких экспериментов является бенчмарк или бенч. Мы про него чуть-чуть в прошлый раз поговорили. Можно сказать, что он стал практически основным. Основные модели, которые выходят, как новая версия Клода, Gemini, всегда оцениваются на нем тоже. И можно увидеть, что LLM-агентам предлагается управлять деревом решений, в которых... Каждая нода, каждый элемент графа является полноценным экспериментом, дается какой-то датасетик, на котором надо обучить модель, отдельно среда для тренировки модели, отдельно среда для тестирования, формат, в котором надо предоставить решение итоговое, и агент обучает другую модель пытается составить полноценное решение проблемы, и это все автоматически проверяется. Собственно, Архитектура агента, она закреплена в самом бенчмарке, то есть это не любые агенты мы можем оценивать, а мы оцениваем именно, собственно, базовые языковые модели, которые в агенте используются, а архитектура агента здесь четко закреплена, ее менять нельзя. Эта архитектура достаточно интересная, потому что она собой представляет дерево, ветвящееся в граф изменений, где мы начинаем с какого-то базового решения, бейзлайна, и затем планомерно измеряем его качество, предлагаем некоторые улучшения. архитектура, может быть, вообще все поменять. И таким образом у нас много-много решений, организованные в единый граф с наследованием предыдущих версий. И мы очень четко видим на каждой из этих нод, какой у нас появился результат, и потом выбираем лучший. В MLE Bench, мне кажется, там 12 часов дается на исполнение всех экспериментов. Вот сколько сможете за 12 часов. И, собственно, качество не стопроцентное, как вы можете представить. Но все-таки еще мы не дошли до того, чтобы на протяжении 12 часов агент работал и прям превзошел полномерно человека, который тоже сидит и работает 12 часов над чем-то в задачах решения вот таких ML-экспериментов. По крайней мере, валидные решения, их процент растет, решения, которые хотя бы запускаются, а то и решения, которые лучше половины существующих решений уже или даже в топ-10% входят. Собственно, это примерно там измеряется. Есть решения реальных инженеров. которые уже над такой задачей работали, они соревновались между собой, и получается, что можно сравнить результат нашего агента с тем, как реальный ML-щик-профессионал решил эту задачу. Похожее, похожее... Задача в бенчмарке и среди ML-джем, который мы с авторами в 2025 году релизнули, собственно, здесь. Мы смотрим не на Kaggle-соревнования, а на классические ML-задачи. Их тоже небольшое число. отдельно построение регрессий и алгоритмический ризнинг и даже теории игр. Немножко, в общем, классические совершенно задачи, которые известны уже давно. И лучшие текущие решения реальных исследователей, конечно, для них тоже известны. Что предлагается сделать агенту – это попытаться с ними сравниться или превзойти их. Агент можно использовать любой. Мы, собственно, здесь решили не ограничивать решения, то есть, в принципе, можно Есть отдельные базовые LLM агентов, можно оценить разные архитектуры агентов, их сочетание с друг с другом, как лучше будет работать, а это действительно часто пара, которая работает лучше друг с другом, именно базовая модель и логика оркестрации, вызова различных инструментов, вот это все можно оценивать совершенно отдельно от базовой модели. Ну и вот интересно посмотреть на то, что все-таки происходит под капотом таких решений. На ранних этапах агенты все начинают читать кодовую базу, начинают смотреть, что есть, какие метрики, как будут оценивать. В общем, ведут себя практически интерпретируемо, инженерно вполне. Пытаются затем вносить изменения в код, валидировать. валидацию и тест, и в конце делать сабмит. Но вот мы видим, что в некотором небольшом случае кейсов именно сабмит решение делается практически сразу после первого изменения, но все-таки лучше делать валидацию сначала, несколько раз провалидироваться, потом уже сабмитить. Вот. Ну, это мы поговорили про, собственно, создание экспериментов и решений в задачах, где уже задача нам известна. А все-таки мы начали с того, что вот у Сакана и я приняли даже статью на воркшоп конференции реальной. Могут ли агенты сейчас хорошо генерировать, собственно, мотивацию и идею научного исследования? Ну, вот здесь можно, наверное, сказать, что это наименьшая совершенно стадия зрелости из всех остальных, потому что для генерации идеи у нас, конечно, с вами верифицируемого сигнала нет. Ну, тут как раз у нас можно сказать, что эта задача похожа на human preferences, потому что у нас есть... некоторые ожидания рецензентов, которые мы можем проверить потом ретроспективно. Но в целом эта задача не очень хорошо формализуется, что такая хорошая научная идея, новая, мотивированная, у всех будет примерно свое мнение. Мы, наверное, не будем стремиться к тому, чтобы привести это в какую-то даже стандартную форму. Тем не менее, текущие лучшие агенты, которые уже используются для написания статьи, они были эвалюированы, так скажем, в этом году, и было выяснено, что от 24 до 36% всех идей, которые были сформулированы агентами, они являются так или иначе плагиатом. Причем таким, который переформулирован очень аккуратно, поэтому напрямую пересечением вот антиплагиатом, его найти очень тяжело. Можно его найти только методом вот прямого человеческого знания, что вообще-то я знаю, что это уже было сформулировано недавно или давно. И это очень опасно. Помимо этого, можем посмотреть еще на итеративные улучшения. И, собственно, бенчмарк NanoGPT Speedrun, он смотрит на готовую задачу обучения языковой модели, агент должен посмотреть на код обучения языковой модели и как бы полномерно имплементировать 25 существующих оптимизаций, которые были ранее предложены сообществом. Ему даются подсказки или иногда просто описание верхневыровневое без конкретных подсказок, примерно, что нужно сделать. Ну, вот примерно там можно оптимизировать, если сделать там, я не знаю, не full attention, а какой-нибудь flash attention, допустим, да, или вот какие-то такие подсказки дают иногда с псевдокодом, иногда без, и агент должен сам имплементировать их в коде, запустить, проверить, что действительно улучшается. Это, в общем-то, достаточно фронтирная задача. Сейчас не очень хороший результат. Это тоже новая, не сатурированная задача. Можно увидеть, что, в общем-то, псевдокод достаточно сильно помогает. Без подсказок хороший результат меньше, чем у 20% решений. То есть все-таки если агент начинает итеративно улучшать даже свой собственный код, велика очень вероятность, что где-то на середине он уже столкнется с таким количеством багов, которые он не сможет исправить. В ситуации, когда у него уже дана четко кодовая база существующая. Такая сложная задача, в которой даже не всегда у людей есть решение, ну вот, вероятность пока не очень большая. Похожая формулировка – это бенчмарк CyReplicate, там, где просто агенту дается статья научная из области компьютер-сайенс и подбирается репозитория этой статьи, то есть непосредственно какой-то алгоритмической имплементации нового метода, который представлен в статье. И агенту предлагается по статье полностью с нуля воссоздать в кодовой бали, и потом сравнивается результат. Там тоже, в общем-то, результаты достаточно низкие. Тем не менее, при том, что вот, казалось бы, сама область AI-ресерч и компьютер-сайенс, она такая хорошо верифицируемая, в отличие от остальных, и полный цикл экспериментов можно более-менее оптимизировать и имплементировать, можно придумать полный цикл, где агент придумывает идею, потом пишет план исполнения, план решения, потом идет, имплементирует полноценные кусочки кода, дебажит то, что там получается, затем оценивает результат и потом еще раз и еще раз итерируется. Все равно такая логика постепенно начинает применяться и на другие области науки тоже. Прямо скажем, пока что с переменным успехом, и это в основном касается только тех наук, у которых, естественно, какая-то степень цифровизации уже есть. Как минимум, есть открытые научные данные, какие-то датасеты, которые можно взять, на которых тоже вот в такой логике можно пообучать модели, есть конкретные метрики, которые можно оценивать, обучая модель на данных. Да, там все, что касается, например, моделирования, там, ДНК, может быть, даже molecular science, может быть, там, protein design, вот такие вещи, они вот полномерно включаются. И, суммарно, список доменов, для которых хоть что-то уже попробовали помощью агентов автоматизировать, он уже, наверное, больше 30 научных областей. Я за этим слежу, и там постепенно новые датасеты, новые метрики. Многие специалисты с этим спорят, потому что задачки, которые берутся, которые можно таким образом автоматизировать, они бывают достаточно ограничены. Да, естественно, даже если вы придумываете задачи material design, вы предсказываете вашей моделью хорошую новую структуру молекулы с определенными свойствами, все равно потом надо провести лабораторный эксперимент. И в этом смысле именно наличие и возможность проведения лабораторных экспериментов является вычислительной мощности. Вот. Но вот даже до этого дошли еще не все науки совершенно. Ну, еще парочка статей буквально, которые мне нравятся. Это агент Поппер. берут не верифицируемость, а берут фальсифицируемость, наоборот, что тоже хорошо, и пытаются придумать из гипотезы вывести план экспериментов таким образом, чтобы статистически проверить исполнимость гипотезы и проверить, что, может быть, она на самом деле не выполняется. В общем-то, логика присутствует. К сожалению, пока что этот подход не получил достаточно хорошего развития, но мне кажется, что ровно так я бы делала что-то, в том числе непосредственно в моделировании и архитектур, потому что нам важна не только верифицированность, нам важна и фальсифицированность тоже. И этому обычно уделяется очень мало внимания. Но про это еще немножко поговорим. Ну и, собственно, есть парочка работ уже похожих, в которых реализуется вся система полного цикла, где агент придумывает решение задачи, оптимизирует решение задачи и в рамках этого решения оптимизирует сам себя, то есть какой должен быть оптимальный агент для решения такого рода задач. И в этом смысле Darwin-Gödel-Machine — это вот прототип такой агентной системы. Это тоже вот такой оркестратор поверх базовой LLM, никакого обучения как такового там нет. Это исключительно вот такое огромное дерево итераций, экспериментов, где каждое нода, каждый кружочек в этом графе — это решение. решение, которое было предложено по задаче, в данном случае это кодинг бенчмарка, SWE-bench. Агент пытается поменять свои собственные фронты таким образом, чтобы оптимизироваться под лучшее решение кодового бенчмарка. и найти вот некоторое оптимальное состояние в связке с языковой моделью. Логика эта очень дорогая, но в целом как будто бы безо всякого обучения она позволяет нам, если ее запустить один раз, прийти к некоторому оптимальному решению по части именно составляющей самой логики оркестрации, то есть логика оркестрации, сам агент оптимизирован под конкретную задачу в связке с какой-то LLM. Вот здесь мы планомерно видим, как бы что на самом деле приводило к улучшениям, где мы видим, что на самом деле улучшения, которые в этом графе происходят, вы видите, там некоторые ветки совершенно привели к улучшению качества, некоторые к улучшению. Вот многие из них, они на самом деле очень хорошо интерпретированы. Ну и мы, наконец, переходим к некоторой инфраструктурной надстройке поверх всего этого. Это системы, в которых мультиагентная составляющая, в которых существует параллельно много агентов, которые используют результаты друг друга. Пока что имеет очень ограниченное применение, опять же, только в компьютер-сайенс, только в ограниченном ряде бенчмарков. Тем не менее, проект очень интересный, и результаты, в общем-то, достаточно неплохие. Мультиагентная система, где каждый агент пытается оптимизировать решение параллельно одной и той же задачи. Агенты пишут статью, то есть пишут как короткий обзор своих экспериментов и результаты в такой человекочитаемой форме. Другие агенты читают, что получилось, меняют попутно свои собственные эксперименты, накапливают знания, которые доступны, и улучшают решения. И это решение получается в целом гораздо лучше, чем если бы мы просто запустили reasoning очень долго одного агента. Собственно, это и является основным конкурентом. Может быть, мы можем просто запустить резонинг и какой-то цикл использования одного агента очень долго. Нет, мультиагентные системы сейчас справляются определенно лучше в конкретных задачах с верифицированным результатом, справляются лучше, чем просто очень долгое использование одного агента. Ну вот, немножко хочется поговорить про зрелость отдельных частей этой технологии. и методологию науки, потому что мы уже это затрагивали, так или иначе, и про поперов вспомнили. Вспомнили мы совершенно неспроста, потому что, действительно, когда мы уже говорим про моделирование в рамках мультиагентных систем, большого числа экспериментов, с которыми еще агенты делятся друг с другом, так или иначе, мы должны задуматься о том, правильно ли методологически мы ведем эти эксперименты. Вообще, в рамках самого дизайна и методологии мы правильно выстроили эту систему или, может быть, просто верифицируемого результата недостаточно. Вот здесь мы видим с вами такой стандартный полноценный цикл эксперимента одного агента, SACAN AI v2. Это как раз тот, у которого приняли статью на ICLR. Как обычно, все начинается с идеи генерации плана. Затем тут есть некоторый этап проверки новизны научной. Затем взвешивание этой идеи там с разными конкурентами, тоже другими новыми идеями, которые агент сгенерировал. Затем дерево решений экспериментов. Почему дерево? Ну вот, как мы видели на предыдущих слайдах, там тоже похожая логика, что у нас есть решение, с которого мы начинаем, а потом разные ветки расходятся разных изменений, которые мы внесли в это решение, и они оцениваются самостоятельно. Затем итерации по бейслайну. проверка, может быть, даже каких-то ablation studies, и затем, собственно, происходит написание отчета в человекочитаемой форме и код манускрипта, который потом будет спамить на утренней конференции. Собственно, Все ли у нас здесь присутствует? Давайте посмотрим на отдельные составляющие воспроизводимости, верифицируемости, фальсифицируемости и научного процесса, который мы таким образом можем с вами смоделировать. Вообще, даже у человеческих решений в компьютер-сайенс сейчас воспроизводимость достаточно сильно хромает. Я посмотрела специально на метаисследования психологии, например, да, ну, наверное, там всё-таки тоже всё постепенно улучшается, но вот психологию обычно берут как такой пример науки, у которой есть проблемы с воспроизводимостью, и вот по метаисследованию 2015 года там вот воспроизводимость была 39%. Но звучит как будто очень низко. Мы же в компьютер-сайенс, значит, у нас должно быть все четко, все должно быть измеримо. У нас, наверное, не так. У нас же все есть. И код, и псевдокод, и описание алгоритмов, и верифицируемый результат. И даже у нас с этого кода, точно так же, как у психологов уже с 2015 года, у нас есть чек-листы. когда надо описать подробно данные, на которых вы проводили исследования, как набирали информантов, если там были информанты, из каких они там социоэкономических кругов и так далее, и так далее, и вот гиперпараметры модели, на чем считали, все-все-все описать. Ну вот у нас воспроизводимость сейчас 48% с этим всем. Да, на основании мета-исследования. 2023 года. Может быть, сейчас уже чуть получше, но вот это не очень старый результат, воспроизводимость 48%. Причем по разным областям хуже и лучше. То есть как бы в том числе применение разных моделей машинного обучения в разных доменах дает нам совершенно разный результат. 48% — это, собственно, за счет основных проблем, таких, что плохо описан тест-сет, например, или не написано, на чем тестировались, или непонятно, тестировались на валидации или на тесте, или не приложили непосредственно код, который можно использовать и получить такой же результат. Да, надо самим придумывать, как это оценить, чтобы воспроизвести. Или не выложили модель, да, или не выложили данные. Вот это все, оно и приводит, на самом деле, к вот этому 48%. И вот здесь, собственно, у нас по верхней шапке тут вот нету тест-сета, не описан при процессе, как чистили, дубликаты не то использовано, вообще в целом утек тест, 

S01 [00:37:53] : Татьяна, а можно здесь я, значит, вы просили оживить, вот я в рамках оживления задам вопрос, скажите, а вот здесь, когда мы говорим по процентам воспроизводимости, здесь имеется в виду вообще все статьи, значит, в каком диапазоне, так сказать, рейтинга, потому что, ну, допустим, если мы возьмем статьи в архиве, то там, скажем, неудивительно, что воспроизводимости нет, а если возьмем статьи там, к примеру, с Ай-Ай-Ай или с, там, ACL или ACML, там это скорее редкость. В какой категории мы вот это оцениваем? 

S02 [00:38:27] : Да, это хороший вопрос. Ну вот конкретно в этом исследовании, да, вот это 48 процентов, это исследование, которое берет журнальные статьи, и они смотрят непосредственно, все ли там есть, для воспроизведения руками. Тут они про агента даже не говорят. То есть не то, что там агент не смог написать решение по статье, нет. Даже вот человек просто, вот специалист, может ли полностью воспроизвести результаты статьи, которые заявлены, если ему эту статью дать. Оказывается, что 48%. Но это действительно зависит от некоторых факторов. Мне кажется, что у архива еще хуже может быть с этим. Но вот эта общая проблема в том, что что-то недовыкладывается, что-то недоописывается специально, где-то там выкладывают только промты, а код оценки не выкладывают, вот это все... Контроль версий страдает еще, да, там люди пишут, что у них получился такой результат по API GPT-4, там они использовали там в мае такого-то года. А потом оказывается, что у этой GPT-4 на макенде много раз еще были другие версии, и потом это уже не воспроизводится, потом уже сама модель недоступна по апп, и все, это невозможно воспроизводить. Вот. Проблемы, как бы список проблем, он как бы здесь расширяется, но мне кажется, что именно если мы введем какие-то процедуры хотя бы полуавтоматически, что при сабмите вашей статьи на конференцию или в журнал есть агент, который пытается воспроизвести и написать решение по вашей статье, и он вам даже присылает какой-то результат. Я когда сабмичу статью, я хочу знать, ничего ли я не забыла для того, чтобы другие люди полностью могли воспроизвести. Может быть, я забыла. Если бы это можно было сделать автоматически, Это было бы прекрасно. Это бы очень хорошо повлияло на то, чтобы и ресерч стал воспроизводимым, и еще он бы стал гораздо более машиночитаемым сразу. То есть мы бы сразу на этапе фильтрации, на этапе только подготовки статьи получали статьи, которые 100% машиночитаемые. Это было бы очень хорошо. Вот. Ну, это была воспроизводимость, да. А у нас еще есть вот как раз верифицируемость и фальсифицируемость. И с точки зрения computer science у нас тоже здесь не все в порядке. Потому что с точки зрения верифицируемости тут все понятно более-менее. Мы все используем там тест-цеты, бенчмарки. можем даже приложить логи работы нашей системы, да, это как бы отвечает за верифицированность. Классифицированность с другой стороны уже сложнее. То есть как нам доказать, что наша модель, которая в определенных условиях показала хороший результат, она действительно является хорошо обобщаемой, что это не случайный результат, что это не шум, что это не результат того, что данные утекли, и на самом деле они сконтраминированы, поэтому не настоящий, но высокий результат. И такие вещи, такие методы, которые позволяют нам это делать, они существуют, но они присутствуют совершенно не в каждом исследовании, и совершенно не там, где они нужны. Облиционные исследования, которые позволяли бы нам установить, что именно вот эти части новой архитектуры являются на самом деле драйвером улучшения результата, Они присутствуют в очень маленьком объеме статей. Исследования рабостности моделей, исследования на утечку тестовых данных, на меморизацию тестовых данных, они тоже совершенно не всеми проводятся. Даже планомерные исследования ограничений моделей что на английском она работает, а на русском она точно не будет работать по некоторым ряду причинам, там, на мандаринском не будет работать, тоже не делается. То есть, в принципе, набор экспериментов очень часто очень ограничен. И даже просто отрицательные результаты, что-то запустили, а не сработало, люди это не публикуют. Да, вот это все, в общем-то, нам мешает продвигать фальсифицированность, а фальсифицированность нам нужна в том числе для того, чтобы автоматизировать часть этих экспериментов. Потому что, ну, автоматизировать эволюционные исследования, в принципе, ну, агенты могут уже сейчас. Нет никаких проблем с этим. Сделать автоматическую проверку на меморизацию и data leakage тоже можно. Просто вот это не происходит. Да, но мы можем посмотреть, если мы даже будем считать, что эта логика все равно слишком строгая, мы можем посмотреть и чуть дальше, на моделирование научного процесса и вообще посмотреть на Куна и на Локатоса, как они представляли процесс так называемой нормальной науки и смену научных парадигм. И, в принципе, у нас в e-Research все то же самое совершенно происходит. Описание процессов в целом, как происходит научное исследование, совершенно применимо к исследованию вокруг и агентов, и ЛЛМ, и всего-всего другого. Когда у нас есть ядро нашей парадигмы текущей, мы сейчас с вами находимся в парадигме трансформеров, Можно сказать, ну, кто-то, конечно, и в символьных методах в этом сообществе точно, кто-то и посерединке. Ну, вот я бы сказала, что символные методы – это отдельное ядро другой парадигмы, там, трансформеры для моделирования любых последовательностей, язык для моделирования интеллекта – это ядро нашей текущей парадигмы. Вокруг него есть накопление результатов и фактов, И вокруг него есть некоторый защитный пояс исследований, которые позволяют нам объяснить, почему трансформер плохо работает на доказательстве теорем, вообще с математикой плохо работает, с числами и так далее, и так далее. И вот в целом при этом мы можем пойти в другую сторону. Мы можем посмотреть на, там, И окажется, что тоже, вообще-то, все то, что происходит, многие работы, они попадают совершенно в методологию, скорее, фейерверка, чем форкер, прямо скажем. Потому что мы используем здесь принцип, ну, как бы, получить результат любой ценой, очень большое количество исследований использует такой принцип, и, в общем-то, не вдаваться в то, почему. Тут как бы два основных принципа. Proliferation principle — это как бы... Как это по-русски мы его переводим обычно студентам PhD? Вот я забыла уже. Ну вот, в общем-то, принцип того, что мы не хотим ограничивать научный поиск, поиск научного знания никаким путем. любое получение научного знания сойдет. А второе, это, в общем-то, позволительность. То есть мы совершенно... Да, у нас два принципа. Один – это разнообразие идей, второй – это то, что они могут быть получены любым путем методологическим. И с точки зрения разнообразия идей, действительно, почему бы нет? Да, мы можем, в принципе, с помощью генерации идей агентами, если мы научимся еще плагиат хорошо детектировать, то, в принципе, мы могли бы совершенно придерживаться такого принципа, и многие и придерживаются, например, есть работы, где целиком. LLM генерирует идеи и пытается их улучшить полномерно по дереву без какого-либо подтверждения и верифицируемого результата. С точки зрения принципа позволительности, что методологически все, что угодно, может работать, таких работ вообще очень много, к сожалению. Это все работы, которые выходят и, в сути, там, верифицированность как-то проверяют, что есть улучшение результата, а вот с точки зрения непосредственно почему так произошло, не проверяют, и потом спустя какое-то время оказывается, что это все было благодаря случайному шуму. Таких работ очень много, и в общем-то есть работа, которая показывает, что даже случайные сигналы вместо реальных верифицируемых, они начинают работать и хорошо... И вот, собственно, у нас с вами есть вот этот сложный научный процесс. У нас есть конкуренция научных парадигм. Трансформеры конкурируют с символными методами, еще регулярно появляются маленькие, такая маленькая и все они имеют разные направления, фундаментальные формуляции и принципы. Есть экспериментальные результаты вокруг них, которые вокруг них кластеризуются и накапливаются, но в других парадигмах они совершенно бесполезны и не переносятся. И у нас есть, по крайней мере, некоторое понимание, что прогресс наш нелинейен, и чем больше разнообразие наших идей, и чем более мы систематичны в их исследовании, тем прогресс может быть быстрее. Да, вот кое-как, как-то можно попробовать применить это на мультиагентные системы, которые делают и исследования сейчас. Ну, и в целом, если мы посмотрим, еще раз вернемся к нашей архитектуре с Arcana и iScientist, мы можем, опять же, сказать, что генерация идей и плана сейчас, она совершенно не фальсифицируемая, это чисто вот какой-то фейерверк, проверка новизны. Тоже она очень плохо сейчас работает. Очень она примитивная поверхностная. Ее надо совершенно переделывать. Точно также scoring идей и сравнение идей друг с другом по качеству совершенно низкого качества – это неверифицируемая вещь. Все остальное посерединке, хотя бы немного верифицируемое, можно даже сделать и фальсифицируемым. Ну и написание статей, это написание статей. Но в целом, как бы полностью, если дать агентам сейчас автономность для производства экспериментов, Это будет просто фейерверк 10 из 10, потому что это будет совершенно плохо мотивированный ресерч, методологически он будет очень разнообразный. и, скорее всего, идеи тоже там будут большим разнообразием, но это будет случайный поиск в некотором роде, да. Мы с вами надеемся, что все-таки мотивированные и верифицируемые критерии, критерии фальсифицированности могут нам помочь делать наш поиск научного знания гораздо более эффективным, чем случайно. А как же это видят вообще индустрия и люди, которые работают, так скажем, над этими всеми агентами, чтобы нас привести таким образом к полностью акселерированной науке, ускорению научного прогресса и, в конечном счете, AGI? Сложно, и мы будем разбирать почему. Ну вот, в древние времена, когда у нас, мне кажется, как раз, даже до нашего первого года, наверное, еще до нашей первой встречи, Некоторое существенное вехо во многих технологиях, которые достигнут трансформера, это как раз сравнение и вот некоторые превышение качества над уровнем человека. Когда это случилось, все стали тут же рисовать графики красивые, нормированные о том, как случилось это технологическое развитие. И в целом это хотя бы построено по предыдущим результатам, так что это вполне себе имеет место быть. Сейчас мы с вами находимся с точки зрения науки в таймлайне, где уже можно сказать, что акселерированные научные результаты получили Нобелевскую премию, как минимум Альфа-Фолд. А в прошлом году так и вообще на конференции стали принимать, потом всё-таки отвергать, но научные статьи настоящие. До этого можно было сказать, что там даже в 2005 или когда еще там в разных годах были скандалы с тем, что в журналы принимались статьи, которые были сгенерированы автоматически, но это всегда был скандал, это всегда было именно о грехе рецензирования так или иначе, и как правило, но все-таки такие статьи, они никогда не претендовали на наличие научной новизны и реального научного результата. Ситуация, в которой мы сейчас, она все-таки кардинально от этого отличается. Мы говорим про автоматическим образом полученные научные результаты, совершенно валидные. И к этому мы стремимся. И, собственно, смотря в будущее, мы можем попробовать оценить будущий рост качества и агентов, в том числе в сложных задачах, написание кода, проведение экспериментов и более сложных работ. Вот подходом, который был предложен исследовательским центром МЕТР. Они попробовали построить такой график и экстраполяцию, естественно, ее все любят. Значит, как же все-таки улучшается качество агентов, с точки зрения сложности задач. Ну, я думаю, что в целом это будет для нас с вами интуитивное знание, просто мы не требуем для него доказательств в том смысле, что, ну, действительно, оценка языковых моделей и качество языковых моделей и агентов, оно существенно улучшилось за последние годы. Конкретно система, которую они вводят, основана на времени, которое нужно потратить человеку, чтобы решить конкретную проблему. То есть есть задача на одну секунду человеческого времени, есть задача на одну минуту, есть задача на 8 часов человеческого времени, профессионального времени человека. И они пытаются ввести такой критерий, что если... критерий успешности автоматизации конкретной задачи в определенное время. То есть есть задача на 8 часов, если агенты достигают 50% успеха, то есть вероятность автоматизировать задачу, которую человек делает за 8 часов, то вот здесь на графике это будет уже как раз 27-й год где-то. Да, вот здесь мы видим по оси Y, это 4 часа сверху здесь максимально. И сейчас мы с вами как раз в 26-м году в начале, значит, мы где-то по их мнению, в ситуации, когда агенты могут оптимизировать задачи, которые у человека требуют четыре часа. Ну вот есть и другие графики. Например, этот график построен на основании предсказания «Антропик» относительно того, как будут развиваться качество моделей. По оси Y вы можете увидеть, что здесь тоже используется время. То есть, эта система оценки сложности задач по времени, которую они требуют, она, в общем-то, приживается как удобная пока что, как подход к оценке сложности задач интеллектуальной. Ну, вот здесь вы видите некоторую такую экспоненту, да, что у вас очень быстро экспоненциальный рост какой-то начинается, и уже в 27-м году у нас ждет, видимо, AGI, и с 50-процентной вероятностью, с 50-процентным успехом, вероятность успеха будут агенты автоматизировать задачи, которые у человека требуют полтора года. Это предсказание амбициозное. Но вот есть и корректировки этого предсказания. Не все с ним согласны. Вот есть отдельная группа исследователей, которые критикуют. В частности, здесь вы видите зелененьким предсказание, что все-таки рост будет гораздо менее экспоненциальным, гораздо более линейным. Сейчас мы обсудим почему. Ну, в общем-то, согласия по поводу того, что именно в 27 году что-то такое случится, ну, в общем-то, нет. Тем не менее, оно много где присутствует, и даже для ИИ-ресерча оно существует. Вот есть прогноз AI-2027. Они там тоже смотрят как отдельная область исследований, которая предвосхищает появление AGI, по их мнению. Это Superhuman AI Researcher, то есть как бы вот сверхчеловеческий интеллект, который решает исследовательские задачи в области ИИ. И вот как они оценивают по разным вероятностям. Сначала нас ждет появление вот этого сверхчеловеческого ИИ-исследователя, затем сверхчеловеческого интеллектуального и исследователя, вы спросите в чем разница, на самом деле там не очень большая разница, и затем уже супер интеллигенс и G.I. И все это опять к 27-му году, ну вот, кто-то говорит... Потому что пока способности языковых моделей агентов к коду не стопроцентные, и ризнинг тоже не стопроцентный, конечно, ошибки эти будут нам обходиться очень дорого. Затем superhuman, как бы сверхчеловеческий уровень исследований, затем суперинтеллектуальный уровень исследований, и затем вообще superintelligence. Собственно, разница между ними — это то, что как бы... Суперхьюман должен только-только превзойти человека, как мы раньше смотрели, чуть-чуть превзойти бейзлайн. А суперинтернеджент он будет по качественной разнице. Ну, в общем, все про длинный и строгий. Давайте еще раз посмотрим на пример. Потому что другие ученые используют эту технологию самому, а у них есть вопросы о контентах другого. Ну вот, они смотрят на определение сложности задач, как мы уже говорили, по времени, да, то есть это основано на реальных данных, они, в общем-то, здесь достаточно честно подходят к вопросу и пытаются с людьми, с профессионалами замерить, примерно сколько времени требуется людям для того, чтобы полностью от начала до конца решить какую-то задачу. и потом замеряют плотность вероятности того, что агенты в текущем качестве, агенты в состоянии прошлого года могли бы решить такую задачу. На сложных задачах, как можно представить, вероятность успеха очень низкая, а на задачах простых, которые от людей требуют меньше когнитивных усилий, Ну, там, в общем, вероятность УПЕХа просто большая. И вот 50% запомнили вот такой трэш-код. Это, собственно, уже график с 27-м годом такой экстраполированный, который они предложили сами в этой статье. И вот промежуточный экзамен. Ну, казалось бы, действительно, все как будто лежит непрямо. Ну, этот на самом деле не прямая, это локскейл, потому что, как вы видите, здесь вот снизу одна секунда, а сверху четыре часа, опять же. Это нелинейная шкала, поэтому в логарифмической шкале как будто прямая получается. Но давайте посмотрим, на каких данных это получено. Можно же посмотреть, на чем мы вообще собираем, что это за задачи, на которых мы пытаемся эту статистику собрать. Вот здесь, на самом деле, основная претензия моя ко всем вот этим рисованным экспонентам, Значит, составная часть этого исследования, она состоит из существующих бенчмарков. Они здесь не вводят ничего нового хотя бы, это хорошо. Здесь, собственно, три бенчмарка основных. Вот HCAST, SWA-Suite и Rebench. Это все достаточно такие известные бенчмарки. Вот они меряют на них качество. И получается, что AgeCast — это софтверные таски очень маленького размера, там, где у людей уходит где-то минута. Rebench. Rebench — это достаточно сложный бенчмарк, в котором всего 7 задач, но они должны у человека занять 8 часов. И у системы тоже. Они так спрогнозировали. И Software Engineering Benchmark, там 66 задач, которые очень короткие. В Software Engineering Benchmark они оба являются очень сатурированными. И только Rebatch является не сатурированным. То есть у нас, по сути, получается, что 97 задач сатурированных, 7 несатурированных, сложных, длинных, и еще 66 очень коротких, очень статурированных. Ну, это, в общем-то, не очень нормальная взвешенная выборка. И даже больше, там еще есть сноска. Если посмотреть на сноску, то оказывается, что там есть еще дополнительно они взяли немножко сложных задач из дополнительных ресурсов, которые потом не стали включать, просто заверили для того, чтобы они были. Но все равно у вас получается, что есть 66 очень простых, очень коротких, еще 97 простых, коротких, 7 сложных реально, но которые с самого начала ограничены восьми часами, И еще вот эти шесть, которые взяли как бы на всякий случай, из них прямо одна достаточно сложная и долгая, и пять, ну, таких средне-долгих. Это не похоже на взвешенную выборку, чтобы получить хороший качественный результат. Это похоже, ну, я как бы так скажу как бы свою фантазию здесь, я считаю, что это похоже. на поиск таких задач, которые дадут, покажут экспоненциальный рост. Если бы это исследование моделировалось с точки зрения того, что а как, никак нам найти экспоненциальный рост, А для того, чтобы посмотреть, как реально выглядит результат, я считаю, что они бы взяли гораздо большее число бенчмарков, может быть, как-то их по-разному бы сэмплировали, посмотрели на разные сэмплы и показали бы, что этот тренд продолжается, и замерили бы длину выполнения задач человека. Это совершенно искусственный график, который получен манипуляцией, выборкой отдельных задач. 150 плюс легких задач, 8 сложных, которые мы 100% знаем, что 8 часов. И получается, что как бы у нас действительно рост качества, как мы знаем, модели приходится на простые задачи. Действительно вот все, что там, я не знаю, с одной секунды до там максимум 15 минут, у нас будет за последние годы классное улучшение качества. Мы просто про это знаем. А все, что про реально сложные задачи, 30 минут плюс, там, где надо реально много думать, много писать коды, много ходить по коридору и пить кофе, их всего восемь. Их всего восемь. Вот. Поэтому даже вот эта критика, что, может быть, оно пойдет не очень вот так экспоненциально-олинейно, оно все равно основывается на том, что принимают вот эти дата-пойнты и принимают вот эту методологию оценки и переиспользуют эти же самые результаты для прогнозирования графиков. Эти данные с самого начала очень смещенные. Ну, помимо этого, они еще, конечно, там спорят по поводу того, как будут выглядеть мультипликаторы качества в отдельных способностях. И как улучшение отдельных способностей, например, инженерных, могут повлиять реально на эффективность агентов. И там кто-то говорит, там будет 50x, а кто-то говорит, нет, будет полтора. Для разных сложностей задач, для задач одного дня и одного часа. Ну, в общем-то, это спор про коэффициенты. в задачах, которых, в общем-то, на данных, которых у нас нет. Поэтому спор тут может быть любой. Нужно, как бы, если бы вот все переделать на самом деле, посчитать, надо взять действительно текущие бенчмарки, сделать из них выборку, желательно более-менее уравновешенную, да, как бы равное количество взять примерно. Задачи разной сложности. по-разному их сэмплировать, да, то есть взять из больших бенчмарков там немножко задач, из маленьких бенчмарков побольше задач, их там поразмешать по-разному и посмотреть, действительно ли тренд воспроизводится. Возможно, он совершенно не воспроизводится. Ну и напоследок, уже много мы с вами говорим, Все-таки надежда на улучшение у нас с вами есть, и моя надежда, она, безусловно, связана с тем, что все-таки будет накопительный эффект от результатов мультиагентных систем, так или иначе, от результатов экспериментов автоматизированных и хотя бы как-то акселерированных, ассистированных и так далее, все равно рост у нас будет. Что нам делать с методологией, как ее улучшать? И вот совсем недавно как раз, можно сказать, что к нашему семинару вышла большая статья от Бена Герцеля, который как раз на эту тему размышляет. И он предлагает немножечко упростить для агентов, как бы сделать, я бы даже сказала, это мой как бы вольный пересказ, сделать методологию науки науке чуть-чуть более машиночитаемой для применения агентов и создания автоматически вот такого более фронтирного ИИ. Он предлагает оставить критерии воспроизводимости, классифицированности и верифицированности, пусть они останутся, но мы немножечко возьмем у Фейера Аббенда, мы немножечко разрешим идеи, и мы разрешим исследование идей, которые изначально непонятно, как бы являются ли фальсифицированными. Давайте это сделаем. И давайте это сделаем с трех сторон, с двух сторон. Если у них, они простые с нашей точки зрения, в конкретной научной парадигме, это была бы простая красивая идея, И давайте это сделаем, если эта идея очень прагматичная и очень удобная на практике. Вот. Он это называет тремя основными недостатками гипотез. То есть у гипотез могут быть недостатки, что нет достаточно наблюдений, чтобы сказать, что она фальсифицируемая, верифицируемая. Может быть, недостаток культурный, что люди не согласны, что она простая из разных парадигм, и, может быть, прагматический недостаток, что кто-то считает, что это очень Хорошая прикладная идея. Кто-то считает, что не очень. Но, в общем-то, это все совершенно переносимо на реальные текущие среды с ИИ-агентами, и Бенгерцер, в общем-то, предлагает такие три степени развития ИИ-ученого, который… агент, который сам себя улучшает, улучшает архитектуры новых моделей. Первая структура — это, можно сказать, там, где мы находимся сейчас — это агент, который внутри парадигмы, в рамках существующей теории, проводит какие-то эксперименты, что-то применяет, находит какие-то новые результаты, ну, в общем-то, пользуется всеми существующими примитивами, примитивы сами не меняет. Второй уровень — это уже агент, который может найти какую-то научную новизну методологическую, который может предложить в рамках существующей парадигмы новый примитив. Он может, условно, в рамках трансформеров взять и предложить новые аттеншины. И, наконец, инноватор на уровне парадигмы, третий тип, Это, собственно, накопительный эффект поверх первого и второго, когда агент может нам предложить вообще новую научную парадигму. И вот этим поиском эффективным разных гипотез может нам предложить, что вообще-то из парадигмы трансформеров надо выйти, а вот новые прекрасные архитектуры, которые еще лучше масштабируются, еще лучше описывают наш существующий мир и интеллект, и давать их использовать. Вот. И в таком приближении, да, тут неважно, куда оно пойдет, по экспоненте или нет, но оно могло бы пойти по экспоненте, красиво было бы. Да, в таком случае мы могли бы сказать, что вот этот внутрипродигмальный валидатор — это что-то, что у нас есть сейчас, я думаю, это как раз вот не знаю, сколько это по времени, неважно. Когда поверх этого появится действительно хороший результат, что мы получаем с помощью агентов научную новизну, мы сможем сказать, что мы подошли к типу номер два. И когда мы создадим фундаментально новую интересную архитектуру, которая даст начало вообще новой области исследований с помощью агентов, это будет вот уровень 3. Вот. Я очень надеюсь, что это случится. И это случится очень скоро. Надеюсь, что часть из этого даже в этом году. Вот. Спасибо вам за внимание. Давайте перейдем к дискуссии. Спасибо. 

S01 [01:12:37] : Татьяна, спасибо огромное. Как обычно, я позволю себе пока... Да, вот уже появилась рука. Я позволю себе три вопросика вкинуть вначале. Первый вопрос технический. Вот был у вас слайд замечательный про eMERGE. MLGIM. И там были публикации на различные работы по различным направлениям этого MLGIM. Можно ли вас попросить либо эти ссылочки, либо этот слайд, либо, может, проще, презентацию, чтобы посмотреть. И особенно, в частности, интересует, значит, это как бы уже вторая часть этого вопроса, значит, вы сейчас помните какие-нибудь успехи конкретно по RL вообще и по Atari в частности? Насколько там удалось продвинуться? 

S02 [01:13:18] : По Atari я, к сожалению, не слежу, но есть прекрасный новый RL-бенчмарк. Называется Barlog. Балрог. Балрог. И там прям несколько сред для RL-а. И там как бы разные. Там даже и Robotics есть, и там есть и ориентация в пространстве, и чего там только нет. И там очень хорошие результаты именно на RL-е. Ну, это такой классический RAIL, не то, что там прям языковой модель, языковых моделей там нет. Ну, в принципе, он как бы... его можно отдать агентам. То есть, как бы он в таком формате, что его можно автоматизировать. Сейчас, а что ты еще хотела рассказать? Какая тебе была первая часть? 

S01 [01:14:08] : Ссылочку, вопрос был, ссылочку на MLG и все ссылочки, которые с ним связаны. 

S02 [01:14:14] : Да-да, обязательно, но это просто презентацию вам отдам. 

S01 [01:14:18] : Да, хорошо, то есть если пришлете презентацию, это решит вопрос. Ее можно будет выложить на сайте вместе с докладом? 

S02 [01:14:25] : Ну да, это все открытая информация. 

S01 [01:14:29] : Спасибо. Чуть-чуть поглубже вопрос. Насколько вы видите, что проще сделать и что быстрее появится? Искусственный интеллект как актор, исследователь, экспериментатор? Или как искусственный интеллект, как критик, рецензент и верификатор экспериментов? 

S02 [01:14:50] : Ну, верификатор экспериментов это вещь, которую можно сделать уже сейчас. То есть были бы вычислительные мощности, чтобы на каждую публикацию это делать, а так это технически возможно. Опять же, это, я считаю, авторам будет очень полезно узнать, что какие-то части в их статье написаны так, что они плохо воспроизводятся или не воспроизводятся. Это привело бы в целом к улучшению результатов в сообществе, не конкретной статьи. Вот. Сейчас, по сути, это вот некоторая такая как бы битва, потому что растет очень сильно количество сабмитов на все крупнейшие конференции. Примерно, там, NeurIPS публиковала статистику, 29% в год. Почти 30% в год рост каждый год, там, начиная с 19-го. И... процедура двойного слепого рецензирования, она не очень хорошо масштабируется, то есть она может быть масштабирована, но приходится приглашать не самых опытных рецензентов, да, увеличивать пул рецензентов за счет там соавторов статей, у которых там единожды была принята публикация и так далее, и так далее. И таким образом, опять же, остается все та же самая проблема, которая есть процедуру лицензирования, то то, что в целом, если отдать одну и ту же публикацию нескольким коллективам лицензиентов и потом сравнить статистически, является ли результат воспроизводимым после Рецензирование. Окажется, что соглашаются только для 5% статей лучшего качества и для 15% статей самого худшего качества. А для всех остальных, а это 80%, все то, что в середине, Случайный результат. То есть вы действительно получите какое-то мнение людей, качественное, профессионалов, но именно результат, будет ваша статья принята или нет, это случайный результат. В этом смысле сама процедура рецензирования, результат рецензирования не является рефицируемым, и он является для агентов сложным поэтому, потому что научить агента воспроизводить результаты рецензирования — это примерно то же самое, что учить агента воспроизводить результаты human preferences, то есть мы будем учить агентов нравиться людям или принимать решения, которые понравятся. и если там есть какое-то существенное смещение, какая-то предвзятость, это все будет воспроизведено. То есть агент, который именно делает эксперименты, допустим, он даже задачу берет, не придумывается он, берет задачу от исследователей, от коллектива, и начинает писать планы, делать план экспериментов, эта задача гораздо более легкая, потому что она верифицируемая, в отличие от процедуры. 

S01 [01:18:00] : Спасибо, но у меня единственный комментарий, вот мой опыт, буквально самый последний из ССИМР, я получил две лицензии от ИЛМ на две статьи, там эти лицензии, они опциональные, то есть они никак нигде дальше не используются, они просто для автора, но вот там 99 процентов, что мне написано было, я просто совсем согласился и срочно пошел исправил и перезавел свои статьи, то есть мне на самом деле очень зашло. Тогда переходим к третьему вопросу. Это мой последний вопрос. Куда мы идем? В первую очередь мы сделаем верификаторов рецензентов, а потом они уже и статьи начнут писать сами. Вообще какой смысл возникает в традиционной науке, которая построена вообще на том, что авторы зарабатывают свои рейтинги, хирши, скопусы и так далее, и когда вот эти авторы на самом деле не они, а авторами являются на самом деле То есть, понятно, допустим, для бизнеса, для фарма изобретать новые таблетки или новые методы, новые алгоритмы для решения конкретных задач – это на ура, но причем здесь тогда наука, если там будут искусственные ученые состязаться с искусственными рецензентами? Зачем это нужно? 

S02 [01:19:19] : Это очень хороший вопрос, и он очень такой как бы объемный, да, как бы выходит за рамки прям науки уже какой-то это социальный даже вопрос. Ну, мы с вами находимся на семинаре сообщества AGI Russia, да, то есть как бы мы стремимся к созданию сверхсильного интеллекта. Когда AGI настигнет, давайте считать, что, допустим, вероятность этого не нулевая, и в какой-то момент это случится. Какой... Да, он изменится, безусловно. Совершенно не очевидно, что нужно будет продолжать иметь или стремиться к высокому хиршу и так далее. Но вообще очень многое изменится. Это наименьшее из того, что изменится, наверное. Но если сверхсильный искусственный интеллект возникнет, то, конечно, в принципе, очень многие институты социальные, они будут пересмотрены, безусловно, и наука. Но вот с точки зрения того, что мы сегодня обсуждали, мне кажется, что это не так уж и страшно. И я думаю, что как бы мы действительно придем к тому, что люди и агенты, они будут работать примерно в одной и той же сфере. То есть вам никто не мешает делать свое исследование, и вы будете выбирать, чем вы хотите заниматься. Вы не обязательно будете это делать один, может быть, вы это тоже будете делать с агентами. Пока что агенты не могут основать новую научную школу и новую научную дисциплину, но пока что это могут только люди. Но в какой-то момент, безусловно, мы дойдем до этого. По крайней мере, стремление к этому есть. Если дальше... Для того, чтобы это вообще произошло, мы должны решить очень много методологических проблем, которые есть вообще в целом в науке. Что рецензии случайные. что статьи не воспроизводятся, что результаты фальсифицируемы бывают, бывают не фальсифицируемы, ну и так далее, и так далее, что бывают статьи как бы случайные совершенно методологические, как бы только когда это будет решено, сама наука сама по себе, даже человеческая наука стала бы гораздо более эффективной, и наш научный прогресс бы ускорился, ну а автоматический научный прогресс еще больше бы ускорился. 

S01 [01:21:42] : Спасибо. Иван Бондаренко, пожалуйста. 

S00 [01:21:45] : Спасибо большое, Татьяна, за очень интересный доклад. У меня такой вопрос, может быть, немножечко на другую тему, не про генерацию новизны, а ведь в научных публикациях есть такой почтенный и полезный жанр, как обзорные статьи, написание обзорных статей. Как правило, это достаточно большие, 40-50 страниц и больше. обзоры текущего состояния дела по каким-то предметным областям, по каким-то задачам. И вот насколько эффективно автоматизируется написание обзорных статей, подобного рода статей, существующими мультиагентными системами. Есть ли на эту тему какие-то бенчмарки, которые позволяют получить формализованную оценку? Это раз. И каково ваше субъективное впечатление от качества решения вот именно этой задачи? Ведь структуризация существующего знания и обобщение, хорошее обобщение, это очень важная задача науки, не только генерационного знания, но и эффективное существующего. Сколько сейчас мы продвинулись в этом? 

S02 [01:22:56] : Вы знаете, Иван, я здесь с вами соглашусь. Действительно, задача очень важная, и в целом вот я сегодня даже несколько раз упоминала, что результаты агентов должны быть именно человекочитаемыми, так скажем, в оппозицию к машиночитаемым, потому что, в принципе, когда агенты аккумулируют свои собственные результаты, совершенно не обязательно, что им нужны те же самые ограничения на структуру предложения, которые делают текст понятным и простым, что они не могут для более эффективной, сжатой представления информации перейти на китайский резко, потому что им все равно так удобнее. Мы не сможем это прочитать нормально. Многие есть вот такие вещи, и, ну, как бы пока что это как бы существенный фактор, но прям хорошие оценки качества этих составных текстов, ну, я не видела. Я считаю, что это существенная, пока еще существующая лакуна, можно сделать такой бенчмарк. Мне было бы даже интересно, вот я как-то предлагала студентам, но пока еще не взяла такую тему, взять так скажем, курируемый набор метаисследований, но вот статей, которые не просто обзорные даже, а которые именно аккумулируют, делают выводы по большому ряду статей с статистическими исследованиями на эту тему, да, там, я не знаю, как прием магния влияет на сон, там, условно, да, и вот... и именно качественную оценку сделать на основе именно правильных выводов на уровне метаисследований по определенному тему. Пока что нету этого. Есть способность, которая появилась тоже не так давно, модель, которая называется Deep Research или функционал, вот такой рекурсивный поиск информации и составление кратких обзоров. Он Опять же, вот тут тоже есть эта проблема. Он работает, заточен во многом тоже под human preferences, то есть этот текст должен выглядеть убедительно. Он должен выглядеть как бы вот, что он наполнен фактами, но не перенаполненный. Какие-то факты вот надо убирать, какие-то надо аккумулировать, суммировать, как бы вобщать. И то, что в результате получается, точечно оценивают на уровне фактологии, каких-то фактологических бенчмарков, бинарные метрики, вот это есть, вот это нет. Но это никак нельзя назвать прям хорошей, полноценной, качественной оценкой обзорной статьи, качества обзорной статьи. 

S00 [01:25:37] : Понятно. Спасибо большое. 

S01 [01:25:40] : Спасибо. Коллеги, есть еще вопросы? Давайте пока думаем. У меня еще вопрос есть. Татьяна, я вернусь все-таки к теме экспериментатора, верификатора, ретензента. Когда я немножко задумался, когда вы сказали, что вроде как верифицировать проще, чем рецензировать, потому что когда я рецензирую, я вроде как работаю с публичными фактами, сравниваю имеющиеся публикации, сравниваю теннисы, которые есть, защищаемое положение с обсуждаемыми результатами и выводами, сопоставляю это и вроде как для этого работать нужно только с текстом, с картинками, с графиками. А когда нужно делать верификацию, то понятно, что если статья по email, то там скачал датасет, скачал ноутбук, все это запустил. виртуальной среде и вроде как верифицировал, окей, но если там речь идет про химию, про физику, то тут же, значит, чтобы верифицировать, нужно делать огромную работу по... для каждой доменной области создавать вот эти инструментарии, вот, и подключать к соответствующему инструментарию, значит, соответствующие, значит, интерфейсы для Ильи Емкинского. соответствующий если мы это через или ленку делаем или нужно ждать когда у нас появится человек когда-то подобные роботы гибели немка может там послать какого-нибудь жена значит самое от юни 3 для того чтобы он там пошел значит пробирки взбалтывать вот как вот вы видите перспективы именно в подключении к научной деятельности экспериментальной части за рамками ЭМЛ. 

S02 [01:27:26] : Ну, хорошо, по первой части я тут возьму на себя так смелость чуть-чуть не согласиться, потому что с моей точки зрения как бы нет такого строгого разделения между тем, что делает хороший лицензиент, идеальный лицензиент и верификатор автоматический в том числе, потому что хороший лицензиент, и я, кстати, знаю таких людей, да не один человек, всегда смотрит не только на саму статью и графики, но и обязательно смотрит и в данные, которые пролагаются. Ну, я как минимум всегда смотрю в данные тоже, и я пишу обязательно замечания по данным, если я что-то вижу, потому что, к сожалению, если мы принимаем во внимание только текстографики статьи, очень часто мы как бы принимаем на веру, что действительно все то, что задекларировано, так и есть, а иногда оказывается, что оно не так и есть, что там какие-то существенные части были, ну, приукрашены прям. кажется, что идеальный рецензент, он делает больше, чем автоматический верификатор, но все, что делает автоматический верификатор, делает рецензент тоже. То, что результаты статьи не воспроизводятся, это ответственность, это детектировать, это ответственность рецензента. 

S01 [01:28:54] : Хорошо, а вторая тогда часть по поводу, где у нас на этой сингулярности мы закроем экспериментальную часть как с точки зрения исследования, так и с точки зрения верификации в части за рамки ММЛ. И что для этого потребуется? 

S02 [01:29:13] : Для этого потребуется инфраструктура и, возможно, некоторый принципиальный методологический подход. Можно представить. По крайней мере, в областях, где есть моделирование чего-то, моделирующие науки, в принципе, в них можно представить ситуацию, что там накоплены какие-то наблюдения, какие-то данные, там есть какой-то формализм, какое-то описание законов на этих наблюдениях поверх. И, в принципе, это значит, что автоматически можно попробовать что-то смоделировать, провалидировать и фальсифицировать в рамках какой-то компьютерной среды, да. А потом мы получим какой-то, опять же, в рамках компьютерной среды результат моделирования, например, там, опять же, в науке о материалах, допустим, мы получим новую формулу классного металла, гибкого, легкого, нержавеющего и так далее. Или мы в рамках drug discovery найдем потенциальную структуру молекулы, которая должна отличить такой-то тип рака. бутылочным горлышком являются, собственно, лабораторные исследования. Лабораторные исследования массовые надо автоматизировать, то есть условно это должен быть какой-то такой закрытый цикл, что агент отправляет сигнал в, я не знаю, автоматическую лабораторную среду, где вот такая молекула синтезируется и в рамках каких-то стандартных могли бы хотя бы подтвердить. 

S01 [01:31:04] : У нас здесь нет того риска, что мы окажемся в науке в такой же примерной ситуации, как боятся, что мы окажемся во всех остальных сферах, когда роботы будут выполнять высокоинтеллектуальную работу, которая хорошо автоматизируется, а люди будут выполнять грязную техническую работу, которая плохо автоматизируется. Если взять научную деятельность, то есть руководитель лаборатории, который ставит задачи эксперимента и руководит лаборантами, которые проводят, собственно, опыты. Точно так же у нас будет искусственный интеллект, который будет, собственно, формировать программу исследований, а с пробирками или с гаечными ключами, с паяльниками будет бегать наша талантливая молодежь, которая на самом деле не будет куда расти, потому что они до этого уровня никогда не дорастут. Выходя, видимо, за рамки темы нашего семинара, но тем не менее, раз уж у нас вопросы и ответы. 

S02 [01:31:57] : Ну, пока что как будто бы наоборот, то есть пока что именно этап генерации гипотез, ideation, то, что называется, продуцирования каких-то идей, научные выводы, перепланирование после получения результата. Вот это итеративно является наименее зрелой частью, у которой самые проблемные результаты. И часто, когда мы говорим про какую-то автоматизацию, для этого этапа все равно предусматривается вмешательство человека, и мы знаем, что потребуется помощь человека, как бы одно дело там бенчмарки и статью писать, а другое дело потом это где-то внедрять. Там всегда делается вот для этих основных этапов, которые именно требуют экспертного знания и вот... Какого-то поиска. Это очень сложно формализовать. Пока что мы даже близко не приблизились к тому, чтобы формализовать поиск научных идей, нового научного знания. Это очень тяжело сказать. Мне кажется, что именно проверить или провести план эксперимента, когда уже есть заданная методология и парадигма научная, это гораздо проще, чем решить задачу научной новизны. К вопросу формализации научного знания подойти очень сложно, и пока что не происходит. 

S01 [01:33:31] : Спасибо. Татьяна, еще у меня вопрос есть, уже в другой сфере. Вы говорили про парадигмы. Значит, и то, что мы сейчас живем не в трансформанной парадигме, но где-то еще существует символьная парадигма. Вот как вы вообще видите, с одной стороны, существующую роль символьной парадигмы? Потому что многие считают, что она просто отжила свой век, а некоторые другие считают, что она еще себя покажет, а третьи считают, что они даже... Здравствует торжество и интеграция различных парадигм. Вот как вы к этому относитесь, к символьной парадигме, к ее объединению с трансформерной? И какие, может быть, еще парадигмы вы знаете или представляете, или могли бы вообразить, у которых есть потенциальное светлое будущее? 

S02 [01:34:21] : Да, ну это хороший вопрос. Я рекомендую, наверное, прочитать пост и статью Бена Герцеля как раз, потому что он как раз приводит примеры. Он тоже использует термин «научная парадигма», он его сохраняет для своего нового подхода культурного пробабилизма. Он пытается переложить подход перенесения накопленных знаний при смене парадигмы и, как бы, переиспользованию накопленных знаний из одной парадигмы в другую приходит прямо к конкретным примерам в разных науках, он прямо очень подробно это освещает. Ну, конкретно сейчас в рамках машинного обучения, мне кажется, что эти парадигмы существуют параллельно совершенно, да, то есть как бы люди, которые работают в рамках символьных методов, не очень сильно коллаборируют с теми, кто работает в рамках трансформерных, и существует очень много таких популяризующих мнений на этот счет. Никогда не знаешь, когда затрагиваешь эту тему, какой ответ ты сейчас получишь. Можно сказать, что RL без трансформеров — это еще третья парадигма. что там в замкнутой среде, если мы как-то хорошо зададим систему ревордов, как-то хорошо зададим систему вот этих подкреплений, то мы сможем научить с нуля вот совершенно, ну хоть там как-то учиться, как ребенка или как хотите. Да, вот это тоже как бы третье парадигма. Но все они так или иначе все равно пересекаются. в конкретных работах, иногда возникает именно прикладная необходимость, скорее, взять что-то из одного и что-то из другого. Возникает необходимость начинать не с нуля, а с какой-то предобученной модели, которая уже видела огромный объем данных, и на ней сверху сделать какой-то array в среде. возникает необходимость взять модель, которая очень хорошо умеет синтезировать последовательности, похожие на человеческий язык и мысли, и к ней попробовать присоединить систему символную для генерации доказательств, да, и так далее, и так далее. Вот в конкретных узких областях, мне кажется, что очень часто возникают точки, где непосредственно есть мотивация их соединить, и после этого, если это эксперимент удачный, это дальше масштабируется. Ну, это так вот моё методологическое предположение, что это как-то должно быть. 

S01 [01:36:56] : А тогда у меня там два конкретных вопроса, уточните. Во-первых, вы когда говорите без странского парадигма РЛ, вы имеете в виду, какие архитектуры РЛ имеете в виду? Вы имеете как бы с точки зрения постановки задач или вы имеете в виду какие-то конкретные архитектуры? 

S02 [01:37:18] : Нет, ну как бы... Опять же, вот геймифицированные вот эти все системы, там, Atari, в Dota, которые играют, да, они же и де-трансформерные, и сейчас прекрасно они развиваются. Вот на AGI в этом году много показывали тоже системы. распознавание объектов, ризнинг на RL-системах чисто, вот это пересечение чисто RL-я и символьных, и без трансформеров. Оно существует, да, это как бы не всегда именно широко применяемое решение, но в каких-то областях это сто процентов востребовано, и мне кажется, что, ну, всегда, когда что-то резко становится, ну, приносит хороший результат... Трансформеры тоже же не сразу, да, как бы масштабировались. Сначала просто хорошо машинный привод заработал, а потом уже все остальное. И вот... Некоторые задачи являются всегда фронтир. Наши с вами задачи или ваши задачи, если вы хотите популяризировать какую-то идею, то, наверное, просто повысить приоритет конкретной задачи, где без этого никак. 

S01 [01:38:41] : А когда мы говорим об интеграции нейросимвельных, этих самых симвельных и трансформерных моделей, вот пресловутый граф-рак, когда мы обращаемся к графовой базе данных, в процессе взаимодействия большой языковой моделью, это нормальная история или это вот что-то такое слишком грубое и недостаточно перспективное с вашей точки зрения? 

S02 [01:39:05] : Да нет, почему нет? Ну, это в некотором случае как бы это инженерное решение, как мне кажется, да, то есть у нас нету такого сейчас, что, ну, вот в классическом случае, да, что мы учим языковую модель работать вместе и в графе тоже мы там что-то обучаем, систему поиска. Нет, это две вещи, которые инженерно соединены между собой. Графовые базы знаний очень полезны, я думаю, что конкретно для исследовательских знаний они могли бы дать очень хороший инструмент для более качественной репрезентации, может быть, даже для оценки научной новизны, если бы у нас была хорошая графовая база связанных научных концептов между собой, аккуратно составленная, возможно, это было бы очень хорошим источником, да, но вот опять же, как это применять? Возможно, нам нужно отдельно еще учить, иметь обучаемую систему, которая точно так же, как ризнинг, мы же сначала его везде применяли, а потом поняли, что вообще-то он не везде нужен, иногда он нужен чуть-чуть, иногда надо специально подольше его запускать. Точно так же и здесь, возможно, это будет система, которая знает, когда следует обратиться к внешнему источнику данных, а когда стоит просто еще раз поитерироваться по экспериментам и еще раз подумать над тем, чтобы улучшить текущую линию экспериментов, что может быть 

S01 [01:40:43] : А тогда, развивая тему архитектуры, как вы видите следующее. Как я слышу и как сам чувствую, одна из основных критик больших языковых моделей заключается в том, что у них нет памяти. В том смысле, как она есть у человека. То есть мы ее натренировали на каком-то объеме данных, вот она это знает. да и вот она вот в том что она узнала в результате тренировки она с этим работает вот и все что она получает в процессе контекста это вот даже просто контекст а для того чтобы она научилась на контексте нужно этот контекст какой-нибудь RLHF, значит, самый массив затолкать и уже, значит, на этой дельте, которая получена, делать новый, значит, fine-tuning, новый тренинг, да. И так, значит, мы итерациями ходим, значит, каждые там несколько месяцев мы добавляем логи, грубо говоря, в тренировочный датасет и получаем новые версии. И вот, как я понимаю, есть два выхода, может быть, вы скажете их больше, но, может быть, прокомментируете и добавите. 

S02 [01:41:48] : В классическом случае, если у вас есть LLM, RAC какой-то и у LLM длинный контекст, то у вас есть целых три источника памяти, которые могут между собой конфликтовать. То есть у вас есть там некоторое как бы такое знание, которое модель запомнила, может быть, как-то в процессе предобучения, которое, скорее всего, какое-то немножко устаревшее. Ну, или, может, оно классическое. Но нового там точно ничего нет. Значит, у вас есть контекст, в который можно что-то положить. И это может быть рак, какая-то внешняя память. И, в принципе, одномоментно может быть так, что у вас противоречивая информация во всех трех этих источниках. Какое решение надо принять в модели? Вот у вас там, я не знаю, в предобучении указано, что для этой задачи, для решения этого соревнования, там, Kaggle 2018 года лучше всего работал BERT на fine-tuning. Конкретно в контексте у вас лежит история логов, экспериментов, там, текущей итерации, где вы там с помощью LLM ее решаете. и во внешней базе знаний у вас уже третье решение, что там совершенно другая сота, и они все конфликтуют между собой. Ну, вот как бы инженерно это надо соединять, но это такое как бы в некотором роде решение, которое надо принять об иерархии этих разных источников информации, И его дальше учитывать при обучении. Обучении будь то базовой LLM самой, ее длины контекста, либо даже если у нас модель обучается вместе с агентом, то как бы это все должно учитываться. То есть, по сути, у вас, наверное, должно быть контекстное окно главнее, чем информация, которая лежит в памяти модели вот из предыдущей, да? То есть как бы информация, которая положена в текущее контекстное окно, оно главнее, потому что это какая-то информация, которая имеет текущий приоритет. С контекстным окном, с качеством вообще куча проблем, да, то есть там бывает, что в промежутках, вот где-то в середине там вообще теряется информация, и там может быть огромный контекст, хоть 10 миллионов токенов, а все равно качество вот в реальной памяти, как бы использование качественного этой информации очень низкое, да, то есть вам надо конкретно учить чувствительность контекстного окна повышать, чтобы ничего не забывать из того, что там уже лежит. Значит, и потом RUG, да, вот RUG еще что-то мы положили, допустим, мы кладем в RUG самые новые статьи, да, тогда мы устанавливаем, что вот самые новые статьи, наверное, они там самый хороший результат, самый современный, опираться надо на них больше, значит, вот приоритет RUG, возможно, должен быть такой, что вот с контекстным окном, оно обязательно должно не теряться в контекстном окне. Вот результат поиска пара, что обязательно это должно быть определенная зона, у которой очень хорошая чувствительность всегда. 

S01 [01:45:15] : Спасибо. Я попробую еще тогда уточнить вопрос. Единственное, коллеги, у Татьяны, насколько я понимаю, осталось всего 10 минут, которые она может с нами провести. Поэтому, если есть вопросы, то, пожалуйста, задавайте. Если есть вопросы, включайте микрофон и задавайте. Предположим, что мы говорим, что, безусловно, приоритету контекста То есть система работает с человеком и либо человек дает какие-то утверждения, либо он задает вопрос, либо дает какие-то утверждения, либо если у него есть какая-то новая информация, он ее системе сообщает. То есть предположим, что контекст первичен. И дальше возникает вопрос, если мы хотим, чтобы в процессе взаимодействия с человеком, который даёт какие-то утверждения, ссылки, картинки, графики, какую-то новую информацию даёт системе, и мы хотим, чтобы система дообучалась, в процессе общения с человеком на этой новой информации, как, вот вы видите, некоторая идеальная архитектура какого-то там будущего средней отдаленности. Либо мы эти данные должны будем складывать в какой-то рак, картинки в одну графическую базу данных, тексты в рак, семантические, графы, значит, в графовую базу данных, а модель будет это дело, значит, из обновляющегося контекста подсасывать каждый раз из обновляющейся вот этой вот базы данных. Либо все-таки мы придем к какому-то моменту, что на основании контекста модель будет регулярно сама дообучаться, то есть если сейчас цикл выпуска новой модели занимает там несколько месяцев, то он постепенно будет снижаться и модель сможет уже дообучаться там процессе разговора инкрементально. 

S02 [01:47:14] : С точки зрения вот именно инженерной простоты, я здесь придерживаюсь такого мнения, что первым надо методологически придумать такую надежную среду, где будет рекурсивное улучшение. Простую архитектуру, не надо сложную, пусть там будет маленькая LLM, верифицируемый какой-то сигнал, и пусть она научится сама себя улучшать и дообучаться, и как только это будет, уже тогда можно добавлять внешние системы, рак, что хочешь. но хотя бы можно будет сделать хороший Ablation и посмотреть, да, как это будет вместе работать. Прямо сразу делать и обучение, и очень сложную систему с большим количеством составляющих я бы не стала. 

S01 [01:48:00] : Я правильно услышал, что для того, чтобы убедиться, что система сама сможет дообучаться, нужен пресловутый baby-turing-test, который бы верифицировал, что система может учиться, учиться, учиться. Learn how to learn how to learn. 

S02 [01:48:16] : Ну, можно, да. Мне нравится это определение. Мне нравится. Вообще его называют open-ended exploration или self-improvement. Вот такие есть. Open-ended self-improvement. Вот такие сейчас ключевые слова в машинном обучении. Но это прям, в принципе, похоже, да. 

S01 [01:48:33] : А вам известны какие-нибудь бенчмарки на эту тему? 

S02 [01:48:38] : Нет. Я знаю, что DeepMind очень много делает, но они не публикуют. У них есть отдельное направление, по которому что-то бывает, это альфа и волк, да, вот все, что касается математики и алгоритмов, а все остальное они не публикуют. 

S01 [01:48:55] : Потому что сама концепция baby-turing-test, она была, по-моему, в статье еще 60-го какого-то года, напечатанная на печатной маршруте. Вот. Но с тех пор никакого именно публичного бенчмарка на верификацию обучаемости инкрементальной так и не появилось. 

S02 [01:49:11] : Я думаю, что сейчас это можно сделать. Можно придумать дизайн такого бенчмарка в среде типа Balrog и... именно мерить обучаемость. Я думаю, можно это сделать. Ну, это как бы метаметрика поверх вашего прогресса, да, то есть вот если мы вот одни и те же вот бенчмарки меряем в каждой точке там вот этого графика, да, мы же можем дельту посмотреть как бы, ну вот, в рамках самообучения условно провести такой же эксперимент. Я думаю, мы можем. 

S01 [01:49:44] : В общем, будет круто, если через год мы от вас узнаем о прогрессе в этой области. 

S02 [01:49:50] : Да, есть над чем подумать и есть чем заняться, так скажем. 

S01 [01:49:54] : Хорошо, коллеги, буквально осталось 5 минут. Есть еще, Татьяне, вопросы? Если вопросов нет, тогда, Татьяна, огромное вам спасибо за выступление. С вами, как я понимаю, еще скоро увидимся. Может быть, те, кто здесь присутствуют и нас слушают, тоже будут в Белграде, а также в других местах. Татьяна, спасибо всем участникам, спасибо за участие и до новых встреч в разных местах. Спасибо вам большое. Всего доброго, счастливо, спасибо. 







---

https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html

