## 24 апреля 2025 - Защищенное распределенное хранилище уникальных данных и большие языковые модели - Александр Болдачев — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/SRqw6fP1aZA/hqdefault.jpg)](https://www.youtube.com/watch?v=SRqw6fP1aZA)


Суммаризация семинара:


В семинаре Александр Балдачев представил свою разработку — семантический workflow-движок BLT для исполнения бизнес-процессов, создания и исполнения моделей документов. Основные аспекты презентации и обсуждения:

## Ключевые компоненты системы

1. **Событийная онтология** — оригинальная разработка Балдачева, на которой построен движок. В отличие от стандартных RDF-OWL онтологий, она основана на событийной модели данных.

2. **Направленный циклический граф** — хранилище данных, связывающее события по концептам, атрибутам и отношениям. Граф является также темпоральным, с причинно-следственными связями между событиями.

3. **Модельный подход** — события в графе могут появляться только на основе заранее созданных моделей, что обеспечивает валидность данных.

## Демонстрация работы с LLM

Балдачев продемонстрировал взаимодействие движка с большими языковыми моделями (ChatGPT):

1. **Создание исполняемых моделей** — в ChatGPT были загружены:
   - Спецификация BNF (формальный язык описания исполняемых моделей)
   - Словарь терминов для конкретной предметной области
   - Шаблон договора аренды
   - Описание документоцентричного подхода

2. **Генерация модели** — ChatGPT автоматически создал исполняемую модель договора аренды на языке BLT.

3. **Валидация и исправление** — были продемонстрированы типичные ошибки, которые делает LLM, и как их можно исправить с помощью движка, который сразу выявляет семантические ошибки.

## Работа с договором аренды

После создания модели документа Балдачев продемонстрировал:

1. **Создание экземпляра договора** — заполнение данных на основе модели
2. **Подписание сторонами** — переключение между разными акторами (арендодатель и арендатор)
3. **Автоматическое обновление статуса** — при наличии обеих подписей

## Peer-to-peer сеть и DLT

Была представлена концепция распределенного хранения данных:

1. **Кластеризация данных** по предметным областям и моделям
2. **Топиковая организация** — узлы подключаются только к тем топикам, с которыми работают
3. **Консенсус** может настраиваться в зависимости от важности данных
4. **Архивация данных** с сохранением связей между начальными и результирующими событиями

## Обсуждаемые технические аспекты

1. **Хранение данных** — движок работает с данными в памяти, с параллельной синхронизацией в постоянное хранилище

2. **Транзакционность** — система обеспечивает транзакционную целостность через консенсус

3. **Запросы к данным**:
   - По модели — для получения актуальных данных индивидов
   - По структуре событий — для аналитических запросов

4. **Эффективность** — параллельная обработка независимых потоков событий

## Ключевые отличия от традиционных подходов

1. **От RDF/OWL** — строгий модельный подход, где модель первична, а данные могут появиться только в соответствии с ней

2. **От блокчейнов** — отказ от блоковой структуры в пользу событийной модели с распределением по кластерам

3. **От традиционных БД** — темпоральность данных с сохранением истории изменений

## Применение LLM

1. **Как инструмент ускорения разработки** — LLM помогает быстрее создавать модели и запросы, но всегда требуется валидация человеком

2. **Документоцентричный подход** — документ сам является процессом, а не просто объектом

3. **Формализация текстов** — был продемонстрирован драфт-язык для структурирования текстов на естественном языке

Семинар включал активное обсуждение с участниками, которые задавали вопросы о производительности, масштабируемости и сравнении с другими подходами. Основная идея Балдачева — создание семантической системы, ориентированной на моделирование бизнес-процессов и исполняемых документов, с использованием LLM как инструмента для сокращения времени разработки.







S03 [00:00:09]  : Коллеги, всем добрый вечер. У нас сегодня снова в гостях Александр Балдачев, и мы поговорим, может быть, не столько про AGI, сколько по достаточно прикладные, как мне кажется, с одной стороны, а с другой стороны очень интересные, по крайней мере мне, очень интересные. А также я точно знаю, что несколько людей либо сейчас смотрят эту трансляцию, либо посмотрят ее потом, у которых есть совершенно практический интерес. К тому, что Александр будет рассказывать, у меня, наверное, будут тоже совершенно практические вопросы. Поэтому мы сегодня поговорим о больших языковых моделях и распределенных графовых хранилищах, и о том, как это можно и зачем соединять. И про это нам все расскажет Александр Балдачев. Александр, пожалуйста. 

S02 [00:00:56]  : Добрый день. Значит, месяца два назад у меня был доклад, и мы остановились на том, что я не показал, как работает LM-ка с движком, о котором тогда я рассказывал, с схематическим движком. И сегодня, значит, у нас будет не доклад, а демонстрация, совершенно практическая, с чего я начну, и потом плавно передумаю уже действительно к теоретическим каким-то частям, а может быть опять и практически мы посмотрим, может как работает сеть, если будет интересно, запустим, и я рассчитываю, как и прошлый раз, на вопросы от Антона. То есть что-то было в большей степени живой разговор, что интересует Антона, потому что много чего я уже рассказывал, но не показывал сегодня, что буду показывать. И поэтому вопросы приветствуются. Так. И, значит, я делюсь своим экраном. Так, экран виден, да? Значит, я отключаю здесь лишнюю панельку, которая меня всегда очень раздражает. Отключил эту панельку. Так, значит, у нас сейчас, если кто смотрел предыдущее мое видео, это движок, workflow-движок, семантический workflow-движок для исполнения бизнес-процессов, создания моделей документов, исполнения этих документов, создания моделей бизнес-процессов и исполнения этих бизнес-процессов. По сути, насколько я знаю, проводил исследование, это единственный сейчас такой движок. То есть семантических движков больше в явном работающем виде нет. Есть много статей, которые только планируют и пытаются реализовать, но реализовать на объектной онтологии, то есть на RDF-OIL. Этот движок реализован на моей событийной антологии, оригинальной событийной антологии, которой я занимаюсь уже больше, наверное, десятка лет. И вот мои усилия как бы пришли к тому, что сейчас создан этот движок. в бета-версии. Он доступен для тестирования, свободного тестирования сейчас. Немного людей, правда, тестирует, но работают с ним. И сейчас этот движок работает на peer-to-peer сети. Тестовая сеть, она пока закрыта, она не открыта для тестирования, но мы работаем в этой сети. Движок используется как Виртуальные машины, можно сказать, если про эфириум говорить. То есть это движок, на котором запускаются так называемые смарт-контракты, создаются, запускаются и исполняются. И напомню, что у нас есть здесь сам событийный граф. в котором последовательность событий здесь изображена последовательностью, но понятно, что если мы кликнем на любое поле, мы попадем на события, которые связаны в графе S, тем событиям, на которые я кликнул. И плюс, кроме того, что этот граф предметный, то есть связывает события по концептам, атрибутам, отношениям. Это граф также и темпоральный, потому что есть в поле события поле под названием каос, которое связывает, темпорально связывает, причинно связывает с событиями, которые поступили, были причиной совершения вот данного события. Значит, что мы сейчас будем показывать? Значит, у меня есть некое состояние этого движка в котором есть реестр персон и есть реестр квартир. Значит тут персоны, две персоны заведены, минимальные данные заведены и есть значит две, две персоны. И есть одна квартира, которая заведена, вот какие-то данные о квартире есть. И в этой квартире указан один из персон, овнером. Мы сейчас возьмем шаблон договора аренды. Вот сейчас посмотрим, как он выглядит. Значит, Вот у нас есть простой договор аренды, который я скачал там с какого-то сайта, стандартный. Вот он таким образом выглядит. Есть какие-то поля, есть для заполнения. Мы его закрываем. И у нас есть уже подготовленный, чтобы долго не создавать его вместе с LLM, этот словарик создан LLM, словарик терминов. которые фиксированы, то есть, по сути, всегда работая с каким-то текстом, работая с договором в некой предметной области, нужно иметь словарик утвержденный, зафиксированный, ну, в принципе, как это и положено в семантике, в семантических, так, в семантических технологиях. И мы переходим в chat.gpt. Есть сейчас уже связь через API, но она не очень там надежно работает, и поэтому я буду непосредственно и лучше показывать даже в режиме чата. И что мы в него загружаем в ChatGPT? Прежде всего мы загружаем саму спецификацию. Вот у нас есть файл спецификации, в котором описан язык, описаны примеры, описана грамматика, некие правила создания модели. И мы его загружаем в ChatGPT. 

S03 [00:07:14]  : Можно сразу здесь уточнить, вот сейчас у вас чистая сессия, то есть никакого промта нет? 

S02 [00:07:20]  : Да, вот чистая сессия. Давайте еще раз, чтобы прямо на глазах показать, что я создал. А, нет, ну она как бы есть. Вот чистая новая сессия. Да, ничего в ней нету, я загружаю непосредственно в эту сессию, значит, спецификацию загрузил, загружу, значит, и так, больше там ничего не нужно здесь. и загружу те данные, которые нам нужны для создания договора этого. Сам простой документ вот этот, только переведенный Markdown, то есть не Wordовский документ для простоты. Мы его туда закидываем. И закидываем еще словарик. словарик. И закидываем еще один текстик, который не относится к грамматике, но относится к идеологии создания документов в технологии BLT. Сейчас мы попросим, чтобы сам ChatGPT нам рассказал про него, но он там несколько строчек скажет и станет понятно. 

S03 [00:08:35]  : А можно эти файлики все-таки тогда посмотреть, чтобы... Да, хорошо. 

S02 [00:08:39]  : Значит, вот в этом файлике, вот он коротенький. Здесь текст, просто описание документоцентричный подход к моделированию бизнес-процесса в BLT. Есть несколько соображений, которые лучше знать. Он и без него создаст, но здесь и есть именно описано совмещение бизнес-процесса с документом. Сейчас мы отдельно об этом поговорим. А словарик я уже показывал. Вот словарик. В нем просто описан атрибут instance endData, startData, monthlyPayment, totalAmount и тип данных. тип данных, здесь, значит, вот, скажем, статус, тип данных enum и перечисленные, предзаданные значения, вот, и, значит, еще какие там есть отношения, отношения landlord, tenant, apartment, owner, вот, роли, роли какая tenant и landlord. И описаны еще концепты, которые уже созданы у меня, чтобы они создавать. То есть это те концепты, которые существуют уже в движке. Вот то, что я показал, персона и квартира, апартаменты. То есть, вот это все загружено. 

S03 [00:10:07]  : Можно еще сразу здесь вопрос? Смотрите, вот вы загрузили четыре документа, каждый из которых имеет определенный смысл вашего диалога. Вы будете ей пояснять, какова роль? 

S02 [00:10:19]  : Нет, не буду ничего. Вот смотрите, что я пишу. Вы понимаете. Содержание. документов. Нам это просто нужно, можно было это не писать, нам это просто интересно, чтобы для самих разобраться. То есть, чтобы вам было понятнее, я-то знаю, что, значит, для понимания содержания документов, значит, BNPhi грамматика содержит полную формальную спецификацию языка описания исполняемых моделей в системе BLT, определение концептов, атрибутов, отношений, моделей, выражений, запросов и синтаксис BNPhi, структура строго иерархична от словарей, моделей до выражений, исполнений и условий активации. Простой договор, просто содержание договора, пишется квартира, срок, сумма. Словарь. Содержит глобальный словарь, свойства, атрибуты, отношения для концептов, персон, апартамент, lease, контракт, а также определение ролей. Все свойства типизированы, большинство ограничений соответствует рекомендациям спецификации. Вот. То есть все, что он как бы сам понял, что существует в этих словарях. А, я не забросил... Да, вы про четвертый документ. Про четвертый, да. Я не забросил, так, простой договор. Я не забросил... А, сам документ, да. По... Так. Это вот то, что я говорил. Документоцентричность. Да, я понимаю, в нем сформулирована концепция документно-центричного подхода в системе VLC, согласно которой документ сам является процессом, а не просто объект, под которым выполняется действие. Все взаимодействия, изменения, согласования и транзакции фиксируются в рамках одного индивидуального документа с сохранением полной темпоральной истории вместо выделения отдельной сущности для бизнес-процесса. Ну и ключевое положение здесь. Так, и теперь, значит, я беру… А, я уже все загрузил, да, то есть мне просто нужно написать «Создайте, используя словарь, исполняемый договор Аренды. Аренды. На языке. Краткую пропустили. Кто? Ой, это им без разницы. Для него это без разницы. Исполняемые. Да, спасибо. Да. Я уже переключился. Так. Мы. Исполняемые. Да. Мы. Исполняемые. 

S03 [00:13:28]  : Не-не-не, использование словаря. 

S02 [00:13:33]  : Исполняемый. 

S03 [00:13:34]  : Да, в другом месте. Исполняемый договор в другом месте. 

S02 [00:13:40]  : Договор аренды языка до исполнения. А, вот здесь, да. А, я два раза написал. А, с использованием. С использованием. Да, всё правильно. Исполняемый. Это без разницы. Они так... И так понимают. Да, да, да. Это как бы ошибки грамматические. Значит, он пишет, что он собирается делать. поля какие будет добавлять использовать то и вот он создает сходу то есть я ничего не объяснял загрузил только спецификацию он сам пояснил что там есть значит и специально под эти договоры я не делал никаких пояснений, правил. И он периодически ошибается. Но это я специально оставил для того, чтобы эти ошибки, чтобы их можно было исправить. У вас на глазах какие типовые ошибки он делает и как их можно исправить. Но здесь я вот смотрю, он игнорировал так. Так, не лучший вариант. Каждый раз, когда создается договор, он создается по-разному. Вот. И поэтому, ну вот скажем, вот он совершил ошибку в статус, он вставил неизменяемое, когда статус должен меняться перманентно. Поэтому я ему сейчас напишу, что статус должен быть изменяемым. Да, вот он ограничение вот это понял, да, что он ошибся, потому что setValue меняет значение, поэтому нужно, вот, убрал, да. Значит, плюс, значит, здесь тоже он совершил ошибку, но эта ошибка не криминальная, он две строки сделал обычно. Так, а, тут есть вообще ошибка. почему он ну ладно хорошо давайте тогда я скопирую и сразу внесу значит вот этот модель Здесь у нас есть, это для работы аналитика, можно руками вносить, а это для ввода текста именно символной записи. Я вписываю эту символную запись и вижу, что есть ошибки. То есть он определяет семантические ошибки. Какая здесь семантическая ошибка? Это то, что он разбил запрос на строке. Хотя там написано, но он это проигнорировал, но это бывает. Напомнишь, скажешь, а, да-да, извините. Ну, значит, здесь стоит сказать то, что никогда, скорее всего, по моему опыту, нельзя получить стопроцентную гарантию выхода правильных моделей. То есть всегда аналитик должен проверить, просмотреть. Вот, значит, уже пропала одна ошибка, осталась вторая ошибка. Да, а вот он... Это тоже ошибка, нужно убрать. И смотрите, здесь он зашел в ошибку, значит повторяется дефиниция модели. То есть действительно, здесь она уже определена, а я еще раз копировал. То есть нужно убрать ее. Все, ошибок нет. И что еще здесь можно сделать? 

S03 [00:17:14]  : Можно здесь сразу вопрос? Просто вы сделали отступление. Я задам вопрос, а вы либо сейчас ответите, либо потом к нему вернемся. Посмотрите, вот то, что вы сейчас продемонстрировали, то, что вы сказали, это как бы злободневная очень тема, что всегда нужно проверять. И у меня здесь возникает общая мысль, что это как с копипейстом. Когда люди начинают копипейстить, есть типичная ошибка копипейста, которая на самом деле очень больная. Потому что мы копипейстим, и потом найти ошибку в том, что ты закопипейстил, практически невозможно. Потому что ты большой кусок куда-то влупил. а нужно и забыл и должен был исправить там в правильных местах но не везде исправил и потом значит найти это невозможно а тут ситуация получается еще более страшная то есть как бы ты попадаешь значит у тебя там 99 раз все сошлось вот ты уже привык перестал проверять а потом хобана и ты попадаешь там на большие деньги в лучшем случае а иногда на что-то большое вот вы как-то видите вообще вот решение этой проблемы доверие и проверяние и затрат вот этой проверяния. Нет ли такого, что вот либо мы попадаем просто на очень серьезные ошибки, либо мы оказываемся в ситуации, когда проверяют, когда проще все-таки писать самим, чтобы... Да, смотрите, Антон. 

S02 [00:18:37]  : Можно потом. Нет, нет, нет, лучше прямо здесь, потому что это именно вот здесь актуально, можем и задержаться. Мы сейчас, то есть вообще принцип работы с LLM, я вижу для себя все-таки немножко иначе. Не закидывать промты в LLM, и чтобы она генерировала какой-то текст, а использовать LLM для создания исполняемых каких-то моделей, для каких-то графов, для того, нечто формально проверяемого. Текст проверить невозможно. А вот то, что он сгенерировал сейчас модель заключения контракта, это можно проверить. Фактически сейчас я исправил две ошибки, которые были зафиксированы движком как синтаксические ошибки. Дальше возникнут еще несколько ошибок, и я их буду исправлять. То есть у меня на выходе в любом случае получится работающая модель. То есть и смысл здесь использования LLM в том, что если бы я писал вот это все руками, я бы затратил бы несколько часов. Особенно составляя вот эти вот запросы. Это еще не самые сложные запросы. А если вот сейчас без объяснений я бы делал сразу эту модель, это заняло минут 15. То есть это просто инструмент для сокращения времени, но на выходе получится то, что я хочу. То есть я должен подставить свою подпись. Скажем, если я делаю какой-то смарт-контракт, то использую LLM-ку, то я ставлю свою подпись, что как будто я это написал. Я отвечаю за каждую строчку. Но в отличие, скажем, от того, что видите, я эту каждую строчку могу видеть, она семантически определена, она вот видна, а это не какой-то код, еще потом еще скомпилированный. 

S03 [00:20:27]  : Я правильно понимаю, что вы утверждаете две вещи. Первое, что в среднем проверить всегда будет дешевле, чем написать с нуля. И второе, что то, что человек перестает проверять и начинает доверять, это его личная проблема. 

S02 [00:20:47]  : Личная проблема. То есть это касается любой работы СЛН. Когда юрист подает какие-то документы в суд, И потом выясняется, что они были сочинены ЛМК. Он отвечает абсолютно полностью. То есть он имеет полную юридическую ответственность. Бабушка ему сказала на скамеечке о чем-то, музыка навеяла или ЛМК. Это никого не волнует. Ты принес документы и ты за него отвечаешь. И это должно быть главным правилом работы с языковыми моделями. Продукт выдаёт всегда человек, подписывает всегда человек. 

S03 [00:21:21]  : Ну это как на самом деле с джунами, да? То есть темлит отвечает за работу джунов. И то, что джуны накосячили, а темлит не проверил... Да, да, да. 

S02 [00:21:30]  : То же самое здесь, то же самое. То есть используем вместо джунов эволэнки. Но здесь гораздо проще, здесь формальный движок, в нем ошибки быть не может, в принципе не может. Сейчас вот увидим, что они все исправляются эти ошибки. Я еще упрощу нашу работу. Здесь есть некоторый момент с пермишенами. Я вот лишние пермишены удалю. Здесь написано, что каждое поле может заполнить одна из ролей. Но это как бы здесь не актуально. А вот актуально будет при подписании. Да, а там дальше оставлю. Так, хорошо. Значит, вот. И мы переходим к отображению уже графическому редактору, в котором бы я создавал. Вот. То есть мне нужно было вот это бы все заполнить, все вот эти вот ограничивающие свойства. То есть за меня это сделала сейчас LMK. Единственное, что мне сейчас, наверное, нужно подправить, это будет роль. Пропустил какая-то роль у нас. Выбрать роль. Движок немножко не соответствует спецификации. Вот здесь еще роль добавить. Так, и сохранить. Значит, смотрите еще вот про роли. Значит, у нас есть application-организация, проект-организация, сообщество, то есть вот где мы работаем. И в ней вот в модели прописаны роли, которые могут быть. Они действуют на все приложения. Роли действуют на все приложения, а не на одно конкретное, вот не на конкретный договор, а на все приложения, которые вот в данном пространстве цифровом. И на каждую роль назначается один, два, три, четыре. Вот сейчас у нас, значит, Иванов и Петров назначены на две роли. А сейчас мы вообще под гостем почему-то, ну это без разницы. Переходим в наше приложение подписания договора и создаем индивиду договора номер один. Мы создали модель, по которой можно создать любое количество договоров. То есть мы, по сути, что сделали? Если мы говорим о предприятии, есть куча шаблонов договоров. Я сейчас за 15 минут взял и забросил один из договоров с маленькими правками, с согласованием. Сейчас, может, что-то еще, наверное, подправим в хранилище данных, в граф, и дальше этим договором можно пользоваться ежедневно. Договор 1. Вот он как выглядит. Уже это интерфейс для заполнения договора. Это интерфейс сейчас админский. Принцип работы движка изначально был принят такой, что все можно сделать в админском интерфейсе. Пользовательский интерфейс исключен из бизнес-логики абсолютно. Здесь есть такая кнопочка, к которой можно переключиться на пользовательский интерфейс. Потом еще покажу, как он работает. Это как бы примитивнейший пользовательский интерфейс, он просто убирает все лишнее. Но мы полностью заключаем договор, полностью производим всю бизнес-логику в админском интерфейсе. Значит, можем пропустить стартапы, да, то есть это все можно пропустить, не заполнять. Нам важно заполнить. Вот мы берем наши апартаменты. Так. ожидаемая ошибка, потому что запрос, который написал chat.jpg, он возвращает массив. Значит, нам просто нужно в апартаментах вот здесь добавить, что значение будет multiple. Возвращаемся назад. Я ее не стал исправлять, чтобы показать, что вот когда я начинаю работать, возникают какие-то ошибки, на которые движок пишет, и он говорит, значит, я вот опять беру апартаменты, значит, выделяю, сохраняю. Вот. И что получилось? Движок исполнил что? Он обратился к апартаментам один, прочитал, что Овнер Петров, и вставил Петрова в лорд. И выбираю Иванов. Так, и теперь статус у нас spending, да, и подписываем. То есть вот эти все данные можно заполнить, сейчас заполнять там бессмысленно, потому что они ничего не делают. Хотя один раз сегодня ChatGPT, он написал запрос по датам, он рассчитал полную стоимость за время ежемесячного оплаты. Этот не стал делать почему-то, но я его не просил, должен был попросить. Сейчас я даже, наверное, покажу, как это выглядит. Что вот total amount, часть GPT составил полный запрос. опросил даты и условия при каких этот запрос должен работать. Но этот не стал. Ну и бог-то с ним. Нужно было попросить, он бы сделал. Значит так. И мы теперь должны подписать пароля. Значит нужно переключиться на Иванова. Значит, в сети, когда работает в сети, это каждый работает под своим ключом и под своей ролью. Это как бы локальная работа сейчас, и поэтому я переключаюсь. Значит, я переключился на Иванова, стала доступна его подпись. Значит, я не вставил значение, здесь булевое значение, значит, единичка. Ну, здесь же по ходу можно показать, как это все вот То есть вот вся наша работа, вот она отображается, заполняется граф. Переходим к нашему Петрову, который у нас владелец квартиры. И сейчас смотрим. Так, вот у нас есть время подписания и статус. Я сейчас, значит, ввожу единичку. Так, подписано, подписано и время введено. Значит, можно посмотреть, как это реализовано. Значит, статус у нас некий запрос. который проверяет состояние других свойств. Вот подписи. Если две подписи подтверждены, он меняет статус на подтвержденный. Ну а время тоже есть запрос, который проверяет статус, и если статус подтвержден, а здесь он вторично проверил, обычно нужно проверить статус, а не проверять вторично подтверждение. Ну и выводит дату. 

S03 [00:29:02]  : Александр, а можно в этом месте вопросик? Вот формулки там у вас какие? У вас какой-то язык для формульных описаний? 

S02 [00:29:11]  : Я прямо рот раскрыл, чтобы пояснить. Сейчас используется JavaScript подобный язык запросов. 

S03 [00:29:22]  : А можно еще точнее? Это все-таки ваш язык или вы используете какой-нибудь стандарт? 

S02 [00:29:30]  : Нет, наш. Потому что специфика самого графа не позволяет использовать существующий допрос. Во-первых, это направленный циклический граф. И есть еще такой момент, что граф создается всегда только по моделям. То есть мы заранее знаем, какие отношения в предметном графе могут быть. Вот если мы создаем RDF-граф, там может быть все что угодно, любые отношения. И поэтому там язык запросов соотносится именно с этой вольницей. Он просто проходит по всем узлам, и выискивает то, что нужно. Нам это делать не нужно в нашем графе, потому что я не могу написать запрос, не соответствующий модели. То есть если в модели вот в этой есть такой-то концепт, и он так-то относится к другому концепту, к индивидуу этих концептов, то я прямо пишу запрос по модели. И он сразу же находит по модели, где лежит данные этой модели, и находит значение этого отношения. Поэтому специфика из запросов совершенно другая. И она проще, быстрее. Сейчас я покажу в документации, как выглядят запросы. 

S03 [00:30:51]  : А этот запрос, он входит в ту спецификацию? Да, да, да, обязательно. Он же пишет. Да, да, он пишет. BNF языка у вас там есть? Да, да, конечно. То есть, я правильно понимаю, что сейчас GPT по ходу еще интерпретатор на ходу порождает? Да. 

S02 [00:31:11]  : Барсер и генератор, точнее. Смотрите, здесь есть еще такой момент. Я давно проводил эксперименты и использовал ChatGPT и как интерпретатор, как движок. То есть я создаю модель. Модель остается в нем. Я не выгружаю ее. Говорю ему, сгенери по этой модели столько-то документов, индивидов. Он сгенерирует. Потом создаем модель анализа этих документов. Он создает модель, в котором пишет количество, кто создавал и кто подписал. И потом, когда я ему пишу, создай еще один документ, он переписывает значения индивида, которые по анализу. То есть он добавляет там единичку, сколько у нас документов увеличилось, и кто подписал этот документ, кто его создал. То есть сама LLM-ка может работать как интерпретатор, то есть по сути можно различными пронтами, то есть один агент сделать как создатель модели, другой агент как контроллер, контролирующий создание модели, а третий агент, который будет исполнять. Но вот тут, конечно, исполнение все-таки не настолько надежно, поэтому нужно все-таки использовать движок. Вот, значит, вот такой вот язык, значит, есть язык выражений, используя condition, вот сложные выражения различные, есть простые там, вот, дата рождения больше, чем 18, да, что секс мужчина, да, и выражение И запросы, вот такого типа, что найди события по модели персон, у которых нейм Смит и верни нам имя его. Такие совершенно банально читаемые глазами. Вот верни всех персон, кроме Смита. Хорошо, давайте перейдем дальше. Да, и эти запросы все-таки в ближайшее время мы заменим на синтаксические, то есть на символьные, чтобы был не JavaScript скрипт, а более человекочитаемые и составляемые. Но в принципе сейчас, когда подключена LLM-ка, то проблема составления запросов, ну, отпала. То есть вот действительно, раньше мне вот составить вот такой вот запрос, да, ну там какой-то, ну, я мог сидеть минут 10-15, а то еще больше какие-то. Сейчас ИЛМ, как вы видели, она за секунду эти запросы написала. При этом с нуля совершенно просто по спецификации. Так, ну и что мы получили? Все, мы здесь на этом примере. Можно было бы более сложный пример взять, но еще раз я повторю. Вот у нас есть приложение заключения контракта. В этом приложении есть словарик. Так, а почему не подключен словарик? А, ну он не подключен, потому что мы автоматом загружали. Вот есть словарик, этот словарик. Есть, значит, персоны и сами квартиры. Да, ну можно, значит, показать, допустим, мы захотели к персоне сделать какой-то комментарий, да, вот добавить. Что мы делаем? Мы идем редактировать модель. Идем, значит, в словарик. В словарик добавляем еще одно свойство. Ну, скажем, коммент. Коммент. Текстовый. Добавили коммент. Вернулись Так. Еще раз. В модель. И к фулнейму мы добавим наш комментарий. А, здесь множество было. Вот он, коммент последний был. Добавили его. Сохранили. И после этого у нас вот появился комментарий, который можно заполнять, посмотреть, вот он появился, вот мы добавили к комментарии, создали новый, добавили его в модель, к fullname, и записали в него некоторые значения. Можно добавить, да, сейчас еще один интересный, самый главный принцип, значит, вся работа в движке. Вот вся, полностью. Никакой другой нет, заключается только в задании ограничений на конкретное событие. То есть вот есть вот эта вот панелька, которая записывает ограничения на предметные события, и аналитик работает только с ней. Больше ничего. После того, как ты создал концепт, создал модель, просто поименованно создал словарики, после этого ты свойства загоняешь в модель и начинаешь с ней работать. Что мы здесь можем? Мы сделать, может быть, обязательность. Обязательно сделать. Можем сказать, что у нас значений этого свойства может быть множество. То есть мы вносим, сохраняем, и теперь у нас появляется… А я что, не сохранил, наверное? Нет, comment, multiply, да, все в порядке. Интересно, почему у меня не сработал. Иванов. А, вот, да-да-да. Там, наверное, можно создавать любое количество. При этом, значит, что интересно. Вот эти события сейчас были сохранены в граф. Вот они все. Но вдруг мне захотелось... Нет, давай-ка оставим один комментарий только. Я беру и устанавливаю по умолчанию. Устанавливаю по умолчанию, возвращаюсь, последний коммент. Все они остались, но актуальным, согласно работе движка и согласно семантике, заданной на ограничивающие свойства, актуальным является последний. Но всю историю можем посмотреть. То есть по сути я ввел одну единицу, а отрезал предыдущие события, которые остались в графе. И аналогичным способом мы можем... Так, это я зашел в модель персоны? Или да, в модель персоны. Почему от меня не отражается? Неизменяемые условия, когда можно ввести коммент? Любые условия, скажем. Коммент может ввести с 10 утра до 10 вечера. Или только, значит, Петровым, когда Иванов на работе. То есть любые Если что-то зафиксировано в графе, то можно ввести это в condition, и тогда будут заданы условия. Value condition – это условие на значение. Скажем, у нас есть 100 персон, да, мы можем ввести их все в value, а можно взять значение, что только мужчин или только женщин, или только те, у кого там день рождения с такого-то по такой-то дату, и это ограничит на выбор value. Permission. задается либо произвольным запросом, также можно такой-то актор или такая-то роль с таких-то сроки, либо просто будет текущий какой-то из ролей. Set value задает значение по читаемой из графа, то есть значение может быть загружено пользователем, а можно читается из графа, как у нас статус был. статус прослушивает записанные данные в граф и меняет значение конкретного события статуса. Ну здесь уникальные-уникальные в зависимости и setRange опять же Да, ограничивает значение только уже в отношениях и дефолтное значение, то есть понятно. Вся работа сводится по очереди, нужно зайти в каждую модель, в каждое модельное событие и настроить. Совершенно независимо, даже не по очереди, независимо, как захочешь. Потому что движок работает на дата-флоу в архитектуре, он прослушивает появляющиеся события и задает возможность срабатывания или несрабатывания какого-то одного из событий, который подписан. Так, коротко теперь покажу еще один фокус. Значит, есть 

S03 [00:41:00]  : У нас был ChatGPT, а теперь мы в ПЛАВУ перепрыгнули. 

S02 [00:41:05]  : Бывает иногда, что-то КЛОД лучше делает, что-то ChatGPT, скажем, работает с так называемой так называемый драфт семантикой лучше работает код, поэтому покажу. Что такое драфт семантика? Я вот файл открою. Тоже некая спецификация, некие шаблоны и грамматика, но только предназначенная для записи произвольных текстов. неисполняемая. Вот в отличие от BLT обычной грамматики, она исполняемая, то есть она строго исполняемая движком. Драфт, семантика неисполняемая служит для формализации текстов. Значит, что мы берем? Мы берем исходную грамматику, все-таки кидаем вот исходную грамматику, чтобы он понимал о чем идет, вот драфт о чем. И вот драфт, семантику тоже закидываем и спрашиваем. Вы понимаете содержание документов? Так, грамматика, спецификация формального языка, документ детально объясняет синтаксис, а вот draft – это спецификация формата, который является компактным форматом для событийного моделирования текстов на естественном языке. Этот формат ориентирован на описание действий, событий и состояний из текста в структуренном виде. Оба документа связаны с обычайно ориентированными модельными данными и моделированием данных и процессов, но имеют разные цели применения. Значит, сейчас применение. Просим, чтобы не заползали другие. У нас Джемине. Напиши рассказ. Короткий. Два. обзаться о походе семьи в ресторан. Ну вот, в субботу вечером семья Петровых решил устроить себе небольшой праздник. Ну, не будем сейчас всё это читать, потом сравним. Так, скопировали. Создаем multidraft запись. Запись по рассказу. Чистая сессия, здесь действительно ничего нет. Вот он начинает писать в драфт-записи. Как видите, это формальная запись, она сейчас без словарей, но должна работать также словарями. То есть здесь должны быть все термины, которые используются по предметной области, должны быть определены в словарях, тогда она будет вообще ценная. Эта запись структурирует информацию из рассказа, выделяя основные события, действия, намерения, оценки участников. Так, значит, мы берем и копируем. создаем новый чат пустой кидаем в него наши файлики draft и целостную грамматику вот И мы его, значит, вот этот draft текст сюда забросили. Тут нужно сказать, что сам язык создавался с помощью лэмки, то есть самому это практически невозможно. Ну можно, то есть может как создавались какие-то другие языки, то появляли лэмок, там для лаборатории годами сидели. Так, ну, нужно, наверное, сравнить. Так, семья Петрова, включая родителей дочь Маши и Сашу, посетили итальянский ресторан на набережной в субботу вечером. Ресторан находится недалеко от моря, был новым для них, имел уютную атмосферу с видом на море и огни города. Они сидели за столиком окна. Ну, дальше не будем. Сейчас мы... А, нет, у нас же он здесь. Суббота вечером семья Петрова пришла устроить себе небольшой праздник и отправилась в новый итальянский ресторанчик на набережные. Дети Маша с Сашей прикушали вкусную пищу и ароматную пасту. Родители мечтали спокойно. О, сократил, поэтому нужно увеличил. Поэтому нужно прочитать подольше. То есть он иногда факты не в последовательности, а по как бы 

S03 [00:46:54]  : Ну, Александр, извините, вы же там-то помогли бы попросить его пересказать тоже в двух абзацах. 

S02 [00:47:00]  : Да, да, да, да, я не попросил. Да, да, да. Ну, в общем, если дело касается договора, договора, вот того, который мы смотрели, он практически дословно его пересказывает, когда формальный текст. Это неформальный текст, я специально взял неформальный текст, но он практически все элементы переносит. Но, смотрите, здесь еще какой момент самый главный. Это нотация. Вот этот вот драфт язык он не приспособлен, он не нужен для того, чтобы его переводить назад в текст. Это не нужно делать. Он предназначен для того, чтобы зафиксировать, формально зафиксировать содержание текста и по этой формальной записи делать поиск. То есть, скажем, мы берем некое произведение литературное или какой-то документ юридический, в котором описано, вольным текстом описано происшествия. И вот после того, как по словарям будет записана, и по моделям еще, не только по словарям, по словарям-моделям будет создана семантическая запись, по этой записи можно делать формальный поиск. Формальный поиск с помощью запросов, а не полнотекстовый поиск, который там делается в текстовых редакторах. По ключевым словам или как-то. То есть это совершенно разное направление. То есть не то, что мне нужно потом восстановить этот текст. Хотя можно попросить восстановить этот текст. Перескажи мне о чем, если вдруг потерялся источник. Но задача такая. Источник остается. Каждая фраза в источнике, или предложение, или абзац связывается идентификаторами с драфт-записью, и, найдя в драфт-записи что-то, я могу обратиться к источнику. И это, по сути, что я сейчас рассказал, это называется BOLD-CLM проект, на который уже подана заявка. Создание постоянной памяти. 

S03 [00:49:11]  : Можно пояснить, какая заявка? Что значит заявка? Куда подходит? 

S02 [00:49:14]  : Заявка на изобретение в штатовские агентства. Да, кстати, по самому движку BALSEE полная заявка принята полгода назад, но на рассмотрение она там где-то год-два будет рассматриваться, но заявка принята, полностью оформлена. Хорошо. в час уложились на вопрос, который, скажем так, он непосредственно не касается peer-to-peer сетей, но он нам помогает, и LLM, но он нам помогает понять, в чем здесь как бы собака порылась, и что здесь прежде всего для нас важно. То есть мы посмотрели, как работает движок, с чем он работает движок, да, и Как нам теперь вот это использовать для двух целей? Одна цель – это постоянная память LLM, и вторая, в принципе, это одна и та же цель, и использование направленного циклического графа, семантического событийного, тоже как память в peer-to-peer сети. С чего начнем? 

S03 [00:50:33]  : Смотрите, я вот что предлагаю. Я предлагаю сейчас попытаться ответить на вопросы. У меня есть несколько вопросов по первому блоку. Возможно, у кого-то еще будут вопросы. И по итогу ответов на вопросов мы поймем, что с этим делать дальше. Как вы относитесь к такому предложению? Александр. 

S02 [00:50:58]  : Да, да, да. 

S03 [00:50:58]  : Смотрите, у меня несколько вопросов. Давайте я сначала пойду. Первый вопрос. Вы сказали, что это единственный и неповторимый. А вы знакомы с работами Дельта-0SL? Это упоминалось на наших семинарах. работы Свириденко и компания. Вот Мансевода есть еще такой из Иркутска тоже у него семантический движок тоже с документами работает. То есть у них там это не событийные семантики, но это полноценные семантические движки. То есть вы просто про них не знаете или они не событийные и поэтому вы их не рассматриваете? 

S02 [00:51:39]  : Нет. Дело не в событийности. Дело в исполнении бизнес-логики. 

S03 [00:51:44]  : Но там исполняется бизнес-логика. 

S02 [00:51:47]  : То есть можно взять любой бизнес-процесс и смоделировать его на этом движке, и он будет исполняться точно так же, как коммунда? Ну да. не встречал. Честно говоря, весь поиск и весь анализ, прочесанный, не вводит данные на них, как на исполняемые движки бизнес-логики. Я могу сейчас взять PPM-схему, засунуть в ChatGPT, и он мне создаст модель, исполняющую эту схему. 

S03 [00:52:24]  : Ну окей, я вам просто кину ссылку, вы там потом можете... Там, скорее всего, с документами только. 

S02 [00:52:30]  : Да. А я говорю о исполнении любой бизнес-логики. 

S03 [00:52:34]  : Давайте не будем тратить время. Я вам кину ссылку, а вы потом примете решение. Если захотите, прокомментируйте. Вы упомянули про смарт-контракты. Я правильно ли понимаю, что то, что вы подразумеваете под смарт-контрактом, это некоторый семантический подграф? который определяет собственно логику смарт-контракта, то есть это смарт-контракт у вас как граф, а не как текст, правильно? 

S02 [00:53:04]  : Смотрите, сам термин смарт-контракт он совершенно неправильный, неверный, он и не смарт, и не контракт по большей сути. Смарт-контракт это либо приложение, либо скрипт. Некий скрипт, который написан в каком-то языке, исполняется на ноде пертуперсити. И любая модель, модель, исполняющая бизнес-процесса, может назваться смарт-контракт. Нет вообще никакой разницы. То есть исполняемая модель, это может быть исполняемая модель бизнес-процесса, голосование, скажем, какого-то, а может быть исполняемая модель, в которой зафиксированы какие-то права и которые автоматически исполняются с переведением токенов, при выполнении условий. И это работает. Я уже моделировал это множество раз. Что такое смарт-контракт? Это исполнение бизнес-логики при некоторых условиях. А это просто модель, обычная модель, которую сейчас я сделал модель, часть же пяти нарисовал эту модельку и она является по сути, то есть по сути она, я сейчас и показывал спарт-контракт, если бы я там еще ввел условия утверждения кем-то или условия какие-то по курсу валюты, что можно исполнить этот контракт только в таких условиях. Это был стандартный смарт-контракт, то есть если в condition где-то было прописано некое значение события, которое нужно контролировать, как только оно исполнится, исполнится этот контракт. 

S03 [00:54:37]  : Александр, извините, я уточню тогда. Смотрите, все-таки смарт-контракт, это, насколько я понимаю, по крайней мере, в эфире, да? Это некоторая сущность, к которой вы можете обратиться. То есть, это просто, по сути, хранимая процедура. 

S02 [00:54:50]  : Ну да. Нет, это исполнение смарт-контракта такое, да? А по формату, по сути, что делает смарт-контракт? То есть он ожидает на вход некое событие и совершает некое действие, некую процедуру, некую запись, некую отсылку токенов в зависимости от условий. Вот. То есть и, скажем, да, я, чтобы пояснить еще присутствующим, я работал четыре года, пять, над созданием блокчейн-проекта в виде как архитектора. Поэтому блокчейн, я знаю, эксперт, в те времена считался экспертом, много публикаций и профильных, и непрофильных журналов, выступления на конференциях и специализированные статьи на эту тему. 

S03 [00:55:38]  : Хорошо, спасибо. Следующий вопрос вот конкретно про ЛЛМ-ку. Смотрите, значит, вот то, что вы показывали, загрузили документы, значит, там общаетесь с ней. Вопрос, не возникает ли в какой-то момент ситуация, что эти документы оказываются где-то на границе окна контекста, вываливаются оттуда, И начинается непонятно что, и мы как-то должны это контролировать, там время от времени подбрасывать эти документы снова. Вот как быть с длиной контекста? 

S02 [00:56:10]  : Смотрите, если речь идет о прикладных задачах, которые решаются на данном движке, и задачах, которые могут решаться с этими пресловутыми смарт-контрактами, то вопрос о контекстном окне уже не стоит. То есть нет никакого контракта, которому потребуется томик там в 300 авторских листов, которые сейчас загружаются. То есть это всегда документы вполне ограниченного размера, в несколько страниц, ну в 100 страниц. То есть здесь, даже в 100 страниц. То есть здесь, скажем так, эти вопросы возникают при работе с документооборотом. И то, когда множество документов Сейчас поясню по поводу все-таки контекстного акта. Не нужно загружать все документы, если у нас есть фиксированные модели, по которым анализируются эти документы, если есть фиксированные словари, по которым анализируются эти документы, и фиксирована семантика и грамматика, по которой это происходит, то нам без разницы, будет один документ занесен в граф сам по себе, один, в одном такте, в взаимодействии с ЛЛМ, либо будет десятки документов, которые будут попытаться загрузить сразу. Они все равно будут обработаны одинаково. И связи между ними, отношения между ними будут установлены нормально, семантически, если правильно составлены словари. То есть если, скажем, мы прочесали эти документы предварительно и вынули из них все поименованные сущности, связанные, то мы можем их загрузить в граф, они будут загружены в граф в виде словаря, скажем, и использовать этот словарь для установления отношений между этими документами при их последовательном загрузке. 

S03 [00:58:03]  : То есть я правильно понимаю, что все-таки сценарий такой, что мы загружаем нужный комплект документов, решаем задачу в этом контексте, после чего уходим и, если что, открываем другую сессию? 

S02 [00:58:19]  : Нет, я бы еще сказал, что все-таки нужно... Цикл обработки документа должен быть локален. Я не представляю необходимость загрузки огромного количества текстов. Если текст один, документ какой-то, он имеет начало, конец, он имеет фиксированную структуру, он имеет, если даже это однотипные документы, они все имеют структуру и должны по Скажем так, как описана процедура работы с документами, предварительно мы берем некую выборку этих документов и используем их как, скажем так, обучающий, но она обучается не Лемко обучается, а для создания словарей. То есть мы используем эти документы, то есть я уже проводил, сейчас не покажу, то есть взял десяток документов банковских и выудил из них все концепты, все отношения, которые релевантны данному тексту. Лемко с этим справляется хорошо. Нужно все равно проверить руками. Дальше составляются модели. То есть есть некоторые типовые отношения в документах, для которых нужно составить модели. Даже примитивно. Модель адреса, модель выходных данных каких-то, модель взаиморасчетов. Они обычно фиксированные. В них фиксированные присутствуют отношения и фиксированные атрибуты и концепты. Составляется модель. И дальше, когда мы имеем уже словарь, имеем модели, мы уже начинаем загружать документы. То есть мы предварительно готовим. И сначала мы загружаем новый документ, мы определяем, это относится к этой модели, этот документ к этой. Берем эту модель, к нему такой-то словарь подходит к этой модели, такой-то. И уже по словарю и по модели мы парсим документы. Не просто лэмка там из себя чего-то делает. А она подводит, ну, скажем, пример хороший вот с этим же рестораном. Сейчас у меня не сделан, но правильнее было бы иметь словарик ресторанных терминов, и все блюда, и все, то есть, словарик событий, которые могут произойти, акты, которые могут там происходить, и модели. Модели, по которым происходит действие в ресторане. Они вполне стандартны. То есть, скажем так, человек имеет сам эти модели всегда. Он, если ни разу не был в ресторане, не знает типовые отношения, типовые акты и причины и следствия в ресторане, он вообще не поймет, где он находится и что нужно делать. Вот ЛЛМке нужно дать тоже модель. И после этого появляется, если появляется новый текст по защищению ресторана, где-то в литературе, Герои зашли в ресторан, она отфильтровывается, весь текст, который не касается ресторана, и делает выжимку по модели, по словарю, что заказали то-то, то-то, расплатились так-то, так-то, это не понравилось, это написано. И плюс наличие модели позволяет делать некие запросы, интерпретировать то, что не было сказано. Ну, скажем, он махнул рукой, да? То есть, если просто интерпретировать этот текст при старании, то ни одна лампа не интерпретирует это как что, пожалуйста, счет там, да? А если модель есть, и модели уже прописаны, какие-то типовые действия, то это легко расшифровывается. Это вот именно ответ на то, что не закидывается просто текст и куча текста. Сначала составляются словари, сначала составляются модели, и поступающие тексты анализируются уже по готовой семантике данной предметной области. Далее мы составляем либо драфт, либо фиксированный. То есть и драфт, и фиксированную семантическую, индивид этого текста записываем в драфт с сохранением связи с текстом. Текст кладем в обычное хранилище, текстовое хранилище, в реестр текстов. Ищем по графу. Ищем по графу. Найдя в графе нужные нам данные, часто, если это фиксированные данные, цифровые или строчные какие-то значения, можно прямо из графа выводить. Если это более сложные, то можно запросить текст, совместить с данными графа и попросить LLM дать ответ, но лучше всего вывести на экран целиком, а попросить суммаризацию как опционную. То есть я, например, когда работаю с текстом, мне не нужна суммаризация вот прямо, ну, непосредственно. Я хочу посмотреть глазами, с цитатами, а потом, ну, ты мне поясни. Или вы и ICM в культуризации не ясны. Дай цитаты. То есть, давайте сформулирую базовый концепт. 

S03 [01:03:16]  : Либо я чего-то не понимаю, либо, вы не поняли, неудачно сформулировал свой вопрос. Смотрите, значит, вот все, что вы делаете, вы делаете в каком-то контексте. То есть, например, в контексте вашего БНФ, правильно? То есть, вы определили… Ну, да. То есть, вы определяете… Нет, некие правила, да. БНФ, правильно? Да. Вы затолкали этот БНФ, он оказался в контексте Леемких. Но вы потом в ходе работы вы этот контекст постоянно пополняете. Туда-сюда идёт всё новое, новая информация. 

S02 [01:03:57]  : И вот тот... Антон, не совсем верно. Смотрите, есть два контекста, два уровня контекста. ВНФ и движок. Он семантик не содержит. Там нет семантики никакой. Там только работа, данные для обработки семантики. Там как обрабатывать концепт, как обрабатывать отношения. Но это один раз. Это 70 килобайт. И больше он расширяться не будет. Не будет никогда расширяться. А дальше есть блок семантический. Есть семантическая модель и словари, соответствующие предметной области. Вот они будут меняться. Скажем, для ресторана это будет одна модель, один словарь. Для документа, подписания договора. Вот сейчас я подгрузил словарик. Будет другой словарик и другая модель. 

S03 [01:04:51]  : Александр, я уточняю вопрос. Вы можете управлять тем, что Элли Лемко держит в контексте? Конечно, конечно. 

S02 [01:05:00]  : Я прямо сейчас изображал. Когда я загрузил текстик про ресторан, я загрузил драфт. Когда я создавал фиксированный документ подписания договора, я загрузил основную семантику и еще словарь договора. То есть я должен, прежде чем загрузить что-то в ЛМКу, определить тип того, что я определяю, предметную область. 

S03 [01:05:28]  : Я про это говорю, то есть каждый раз, вы каждый раз, когда хотите работать с новым документом, вы должны определить, загрузить. 

S02 [01:05:36]  : Но это делает ЛЛМКа сама успешно без меня. То есть если у меня лежит в графе готовые, то есть у меня есть, скажем, модель, в котором реестр, в котором есть соответствие тематика, словарь, модель и еще какие-то. И когда я кидаю текст, первый шаг LLM делает, определяет, типизацию дает. Классификацию. Она классифицирует текст, берет нужный ей контекст, подгружает этот нужный. Это без меня. Я могу и руками сделать. 

S03 [01:06:07]  : Что значит без вас? Как это без вас? Как это она? 

S02 [01:06:10]  : Ну как? Допустим, я вот сейчас загружу в ЛЛМ-ку текст про ресторан и текст договора. Она не определит, 

S03 [01:06:19]  : где договора где я имею ввиду еще раз я вот я все-таки не могу видимо эти коммуникации чуть-чуть смотрите вот допустим вы хотите решить 10 задач в рамках вот болт си семантики да да вот если вам нужно один про ресторан там значит самое там про аренду там там про шарик и подшипники там по продажу да да да да и И каждый раз, каждый раз вы загружаете новую пачку документов. Один из них это описание вашей фундаментальной антологии. И второй раз уже доменная антология. Каждая сессия начинается с загрузки пакета, из которых одна, так сказать, обязательная часть самого верхнего уровня. Все, я про это спрашивал, окей. 

S02 [01:07:08]  : Да-да-да, но я еще рассказывал, что создать их нужно предварительно, то есть я должен взять образцы документов, проанализировать с помощью LLM, выделить там модели, выделить словари, выделить модели и сформировать пакет для данного домена. 

S03 [01:07:26]  : хорошо хорошо все я я все понял там еще сейчас у нас вопросы у алексея незнаного возникли но давайте сейчас у меня еще один вопрос есть насчет проверки смотрите значит вот мы вот эту вот тему вы же видели доклад павла соловского да вот активно тут в нескольких кругах эту тему обсуждаем вот и значит основной интерес Я, кстати, сразу дам некоторую реакцию. У меня будет отдельный следующий вопрос. Как вы относитесь к тому, что Соловский рассказывал? Я доклад Соловского переслал Потапу и Алексею. Что, дескать, смотри, до чего прогресс дошел у коллег. Потапов очень скептически отнесся к тому, что было показано, потому что он сказал, что разобраться в том мусоре, который сгенерит ЛЛМ в качестве онтологии – это отдельная история, доверять этому нельзя, и какова практическая польза от этого совершенно непонятна. С одной стороны. С другой стороны, когда мы это обсуждали в кругах, которые, наверное, сейчас семинары слушают в ютубе или потом послушают, была такая идея, что окей, мы, конечно, можем генерить мусорных антологий, но если мы эти мусорные антологии верифицируем каким-то внешним прувером, то мы можем этот мусор отфильтровать. Допустим, у нас лежит какая-то базовая онтология или мета-онтология отдельная или подгружается. И там есть некоторый текущий контент. И когда мы приождаем новый контент на основе каких-то входящих документов, то мы можем всегда верифицировать непретвердчивость и совместимость того, что система нашла, с тем, что мы уже знаем. Если оно совместимо, то мы его загружаем, увеличиваем объем растущих знаний, а если не совпало, мы даем команду оператору, чтобы он вмешался и принял решение, что с этим делать. Вот. Соответственно, два вопроса сразу же получается. Как вы относитесь к теме формальной верификации того, что вы сейчас делали руками? Вы же сейчас руками это все правили. Можно ли вот ваши формальные выхлопы, точнее форма те выхлопы, которые вы получаете сейчас от Лемке, формальные в рамках вашего синтексиса и модели онтологической верифицировать? Это первый вопрос. Ну а второй вопрос, раз уж я промолвил, как вы относитесь, то что вы делаете с тем, что Соловский рассказывал на прошлом семинаре? 

S02 [01:10:13]  : Я соглашусь с Пением Потаповым, что разгребать это неблагодарное дело. Я плохо отношусь к объектно-ориентированным антологиям, к РДФ. И вследствие того, что граф получается произвольный и нет никаких ограничений на обнесение данных вот исходно в самой спецификации, в самом языке, нет никаких ограничений ни на размер, ни на содержание. То есть исходно семантик век был предназначен для того, чтобы любой веб-мастер на своей странице сделал разметку и добавил к любым узлам любые узлы. И именно поэтому, зная вот это, зная семантику еще с тех времен, то есть я пошел другим путем, что ни один узел, ни одно событие в графе событийным не может появиться без модели. Только по модели. Оно верифицируется по модели, создается по модели и извлекается по модели. То есть исключительно модельный подход. Поэтому ничего, а модель, она верифицируется движком. И если, поэтому получается так, что не валидного события там появиться не может в принципе. И немножко другой все-таки подход работы с событийным графом и вообще с событийной семантикой не ставилась задача создания графов знаний, вот именно просто наполнения какими-то данными, которые через отношения или каким-то образом связаны с друг с другом. Ставилась задача создания, описания бизнес-процессов, А граф получается автоматом. То есть он получается, я его не строй, я делаю бизнес-процесс, но в результате бизнес-процесса у меня получается связь квартиры с Овнером, документа с подписавшими сторонами, сумма перевода с подписавшими эти стороны, значит, с каким-то законом, который был процитирован в данном документе, то есть и поэтому совершенно Задачей такой вот взять википедию и загрузить в семантический граф не стоит, потому что это бессмысленно. Это не бизнес-логика, это не деятельность, это просто набор данных. Но если потребуется, скажем, реестр недвижимости какой-то сделать, реестр контрактов сделать, то делается модель. Она делается руками человека, потому что он понимает, он специалист. Она может быть сделана, быть за 15 секунд ЛЛМкой, но тоже проверена человеком, а после этого она работает и через нее проходят только верифицированные данные. Поэтому здесь совсем другой подход и принцип, назначение другое. То есть я исхожу из того, что, конечно, нужно и есть такая задача взять все тексты, сгенеренные когда-то человечеством, прогнать его через что-то и загрузить его в семантический граф. Но считаю, что это как бы приоритетная задача, приоритетная задача все-таки научиться, скажем так, сначала научиться работать с текущими данными. с текущими данными. То есть организовать бизнес-процесс в какой-то деятельности. И там не стоит задача перегнать документы. Стоит задача создать документ, который будет регламентировать деятельность. И в самом этом документе будет еще сама прописана бизнес-логика для его работы самого документа. 

S03 [01:13:51]  : Я правильно понимаю, что без участия человека вы всю эту историю не видите? 

S02 [01:13:57]  : Нет, не вижу абсолютно, потому что... Нет, бизнес... Как можно вообще деятельность без участия человека? Разные цели, разные задачи. 

S03 [01:14:07]  : Оба-то на Луне сами добывают полезные ископаемые, отжимают у друг у друга... Нет, ну смотрите, здесь вопрос возрастает без участия актера. 

S02 [01:14:17]  : То есть действительно, вот сейчас мы разрабатываем, работаем над платформой мультиагентской, то есть идеологией. Да, пожалуйста, некий агент может задать промпт LLM, который сгенерит новую модель, нового агента. И перифицировать. Да, кстати, по поводу верификации. Я вот сейчас там как опытный создатель моделей сразу сказал, вот здесь неправильно, здесь неправильно, здесь нужно это поправить, а вот здесь это... Но я в принципе могу эти все знания перенести в промты. То есть список проверок, которые сама же ламка сделает. Кстати, я сегодня проводил такой эксперимент. Я увидел ошибки. У тебя в этой модели есть ошибки. Найди их. И он нашел. То есть когда специально написано «найди ошибки», он прогнал еще разочек и нашел. Если бы я еще специальный промп написал на поиск ошибок, вероятность нахождения ошибки была бы еще там под 90%, но потом, когда они загрузились в движок, То есть у меня на выходе, когда я создаю индивид по этой модели, я не могу работать с невалидной моделью. Она обязательно заткнется. Видите ли, ошибка выпала сразу. Я специально ее оставил, чтобы показать, что вот она, ошибка выпала. А, там написано где ошибка, я иду, правлю, или это LN-ка сама могла пойти поправить. То есть автоматизация может быть, но автоматизация должна быть не на основе каких-то там априорных правил, а непосредственно в самой работе движка, семантики. 

S03 [01:15:59]  : Хорошо, спасибо. Еще вот здесь вопросы от Алексея Незнамого. Почему сначала документы – это ограничения, а потом только про маленькие документы говорим? Понятно вопрос или непонятно? Нет, не понял. Может быть вы голосом встрянете, потому что мы убежали, возможно, от того момента, как вопрос... Нет, я помню, я просто не расслышал первую фразу. Почему сначала документы – это ограничения, а потом только про маленькие документы говорим? 

S02 [01:16:30]  : Документы. 

S03 [01:16:30]  : Я, наверное, лучше встряну. 

S02 [01:16:32]  : Модели. Модели ограничения, не документы, а модели. 

S03 [01:16:34]  : Давайте Алексей уточнит вопрос, чтобы... Да, да, да, Алексей, пожалуйста. 

S00 [01:16:39]  : А меня слышно? Да, да, да, очень хорошо. Замечательно. Добрый день, коллеги. Дело в том, что сначала там был в конце рассказа кусок про то, как именно мы работаем с теми документами, на которых как раз проверяют модели. Потом был вопрос от о том, как можно на основе стандартных BPM-систем с BPM-эном делать, в общем-то, произвольные выполнимые модули. Я тоже могу таких две ссылки прислать, с одной непосредственно работаю. И там было замечание, как они живут с документооборотом с документами. А потом хлоп, и всю рекламу делаем мы тоже на маленьких-маленьких документах. вопрос почему я думаю сейчас будет реклама того что мы можем например до загнать по телеметрии за последние 20 лет и что-нибудь сделать но нет опять маленькие маленькие документы 

S02 [01:17:39]  : Нет, нет, нет. То есть, скажем так, вот на данный момент технология не предусматривает никаких загонки больших документов. То есть, смотрите, здесь есть такой момент. Есть движок. который работает с моделями по созданию индивидов и реагирует на изменения в графе по кондиционеру, то есть может выполнять какую-то бизнес логику. Если перед нами будет стоять задача обработать большой массив, то, скорее всего, будут созданы какие-то специально оркестрирующие модели, которые будут работать с сотнями движков, которые будут заносить данные и некие еще другие движки, ну тот же движок по другим моделям будет их как-то окучивать. То есть здесь нужно строго различать, значит, возможности непосредственного самого инструмента, ну как продажа, да, у него есть какие-то функции, он выполняет. И вот семантический визуал сейчас именно вот на такой стадии. Но если я вижу задачи, которые стоят над окучиванием большого объема данных, их можно решать, но я думаю, что это не профильное решение. То есть профильное решение движка – это работа с существующими данными. в существующем бизнес процессами, а не обработка, то есть, скажем, обработка текущего потока данных от датчиков. То есть, я делал такой профконцепт в одном предприятии по безопасности. Они вот использовали мой движок для того, чтобы, кстати, с Горшковым вместе мы проходили этот профконцепт, для анализа потока данных. Вот для этого движок, а не то, что мы сначала загрузим на своих архивах, а потом мы разгребать. Это разные задачи. То есть просто я не решаю такую задачу. 

S00 [01:19:37]  : Окей, тогда противопоставление тем более непонятно, но это как раз теперь как постулат ясен. Ну а следующий сразу же отсюда вопрос, да? А это если как раз у нас есть по-марковски, то есть с точки зрения марковских процессов, большое запаздывание, например, как минимум на десятки тысяч шагов. Что в таком случае делать? 

S02 [01:20:08]  : Бежоук работает дата-флоу в архитектуре. Это дата-флоу, это не контрол-флоу, это не машина по неймингу. Поэтому не Тюринг машина. И такую задачу вообще даже поставить невозможно. Если какое-то событие не сработало, значит следующее не сработало. Если речь идет о параллельных процессах, которые идут в параллельных ветках, параллельных моделям, то нужно ставить оркестрирующую модель, которая будет контролировать задержки, что после такого-то события нужно ожидать было 5 минут, другое событие не произошло, нужно либо делать оповещение, либо вставлять новые события, которые продвинут процесс дальше. 

S00 [01:20:51]  : Да, но на практике у меня ни разу еще не было такого, чтобы без полноценной темпоральной логики это сработало. Вот пока что все примеры, которые я видел, они, кстати, реально очень хорошие теперь стали у вас, они все в этом смысле наивные, поскольку не используют никакую темпоральную логику от предшествующих событий. Планируете ли вы ее добавить? 

S02 [01:21:15]  : Нет, это неверно. Смотрите, здесь два ответа. Первый ответ. Сама семантика исключительно темпоральная. Исключительно темпоральная. То есть именно обработка текущего события идет на основе предыдущих событий. То есть не IF и потом дальше, а именно, скажем, пишется condition, у каждого события модельного есть, ну не у каждого, то есть где нужно, пишется condition, который срабатывает под подписки про поступление необходимого количества событий и с определенными значениями, какие условия. Это один момент, но это не полностью обработка темпоральных событий. Дальше запрос будет работать еще, не написаны эти запросы, но они как бы видите, как легко пишутся, это запрос по последовательности событий. Можно condition написать, что сначала появилось событие A, потом B, потом C, потом опять A. Вот при таком последовательности событий сработает condition. Это как бы нет проблем, потому что в графе события частично упорядочены. Частично именно те, которые находятся в одном потоке, они упорядочены. Но весь граф, естественно, не упорядочен. Частично упорядочены. И еще плюс, сейчас не введено, но это тоже дело с техникой, просто программисту нужно загрузить, будут введены события временные. То есть по которым можно синхронизировать. То есть можно будет ввести в кондишн еще события отсчета времени. То есть ну там скажем через каждую секунду, зависит от процесса, от минут, через час. И вот таким образом можно будет отслеживать темпоральность событий, их последовательность и даже от разных моделей. И их привязку к абсолютному времени. 

S00 [01:23:05]  : Да, продолжительность у них будет, то есть появится свойство продолжительности. 

S02 [01:23:09]  : Сейчас нет, сейчас абсолютно синхронная работа, но при внесении специальных событий, меточных, их можно много разных ввести, но одни из них – это события, именно задающие длительность. 

S00 [01:23:28]  : Ну да, вот я к чему, собственно, и веду. Я работаю с системой BPM с ELT плюс логикой, то есть дескриптивка с Action Time Logic. В общем-то, вот это все и начинаю в кавычках иметь. 

S02 [01:23:46]  : Вопрос, а чем тогда будет это отличаться? Ну, с тем, что вы перечислили три технологии. Я говорю, у меня на одной технологии это все сразу. 

S00 [01:23:55]  : Да, но сейчас как можно написать, как раз, как вы говорите, condition, который, если она появится, да, использует темпоральную логику на последовательностях предыдущих событий, которые распределены по набору входов. 

S02 [01:24:12]  : просто элементарно, то есть ни в каких проблемах. Сейчас просто не написаны эти запросы. Если я поставлю задачу сейчас программисту написать запросы по последовательности события, они будут написаны, то есть у меня программист уже сам предлагал, давай мы напишем, я говорю, пока это не правильно. 

S00 [01:24:25]  : Все, я вот тогда супер заинтригован. Так вот, на это очень большое спасибо. Вот, а следующий вопрос у меня последний, он был про те самые правила и модели, потому что У меня тоже был очень богат опыт. И начиная с того, что как только мы приходим в ресторан, у нас появляется очень серьёзный уровень неоднозначности, например, в тональности высказываний, за которым должно следовать некое событие. Мой любимый пример, да, с тёплым пивом и тёплым приёмом. Тёплое пиво – это хорошо или плохо, да? А тёплый приём – хорошо или плохо? И как надо отреагировать? Ну и очевидно, что как только мы Говорим, что у нас есть документы текстовые, которые надо разобрать, то получается, что в модели такого вида приходится тянуть все снятие амонимии, синонимии, тональность высказываний и все остальное. Вопрос, как вот эти простые модели могут в этом помочь? 

S02 [01:25:22]  : Прежде всего сам подход ориентирован на полное отстранение от эмоционального временного содержания текста каких-то отношений вне действия. То есть если там действительно появятся какие-то заигрывания глазами или еще что-то, то я с этим не работаю. И основная задача стоит в том, что если в тексте есть посещение ресторана, то вызывается модель, в которой максимально строго прописаны все события, все акты и их причинная зависимость, которые характерны для данной ситуации, положения дел. Да, и здесь вопрос действительно, что-то можно упустить, но если сказать так, что модель помогает создать валидный индивид, валидный экземпляр этого действия, хотя может пропустить что-то существенное поотносительно теплоты. Вот здесь самое главное не ошибиться, не вставить лишнего. Плюс есть еще такой момент, что модель позволяет вскрывать пустые слоты. 

S00 [01:26:44]  : У меня есть. 

S02 [01:26:47]  : Да, и он был пропущен, да, то тому же агенту Лемке ставится задача найти то событие, которое было в тексте описано, которое послужило как бы сигналом совершения, да, вот тот же теплый прям, теплое пиво, и интерпретировать его уже в данной модели, что вот этот слот, он послужил тому, что набили морду. 

S00 [01:27:08]  : Окей, то есть это индикаторный принцип, да, вот это как раз хорошо понимаю, спасибо. Огромное, кстати, спасибо за уточнение контуров. Но на самом деле тогда дальше было бы исключительно интересно, это, наверное, уже не сейчас, посмотреть на базовую модель непротиворечивости в смысле согласованности. Тогда бы это очень четко дало понимание, в какой логике потом обрабатывать текущее состояние этих индивидов. Спасибо огромное. 

S02 [01:27:34]  : Здесь ответ по поводу согласованности однозначный, потому что он задаётся моделью, если событие сгенерено, если событие предметное появилось в графе, это однозначно, что оно соответствует всем условиям, которые прописаны в модели. Движок не пропустит ничего, что не соответствует модели. И поэтому дальнейшая проверка уже не нуждается, он как бы есть, записывается в событие. 

S00 [01:27:55]  : Нет, здесь абсолютно изначально не согласен, я прошу прощения, потому что в реальной жизни нам надо работать с распределенной системой. И как только ваша система запускается как распределенная, то все, в ней должна быть какая-то базовая модель согласованности на уровне как раз данных индивидов. 

S02 [01:28:12]  : А, нет. Ну, можно сейчас поговорить как раз о peer-to-peer, даже могу показать, как peer-to-peer сеть работает. 

S00 [01:28:18]  : Ну, просто это будет долго. Давайте господина Колойнина спросим. Да, да, да. 

S02 [01:28:23]  : Нет, нет. 

S00 [01:28:24]  : Ну, это очень интересный вопрос, да. Он прям вытекает из того, что сейчас вы сказали, да. 

S02 [01:28:29]  : Это длинная история, которую сейчас решаются, пытаются. Одна из целей ближайшая — запустить публичную сеть peer-to-peer на движке с семантическим графом в качестве хранилища. Она работает уже, сеть. 

S00 [01:28:44]  : А, то есть и тогда и смарт-контракты в реальном определении. 

S02 [01:28:47]  : Они сейчас все работают, да. 

S00 [01:28:48]  : То есть не в том, который выдавали, а в том, который обязательно включает. 

S03 [01:28:52]  : слова криптографические да тоже будет вмешаюсь поскольку меня упомянули смотрите значит мы на самом деле действительно с одной стороны исчерпали тему или лемок а с другой стороны подошли к теме распределенности вот и соответственно у нас есть развилка либо продолжить серьезно сейчас залезть в историю распределенности Вот, значит, мы сейчас уже полтора часа в эфире, но, соответственно, мы, так сказать, сможем еще, так сказать, серьезно углубиться. Вот. Это один вариант, да? Если есть присутствующие, у которых есть силы. Вот. Ну, или это отложить на следующий раз, но на следующий раз это будет не скоро, потому что тут начинаются каникулы, потом у меня будут разъезды, у нас, так сказать, на... 

S00 [01:29:37]  : как минимум на пару недель будет перерыв поэтому вот если как минимум александра алексей вы готовы продолжать серьезно серьезно это надо как раз начать тех самых базовых моделек и посмотреть как коллеги у себя вводят тоже базовую логику именно согласованности да я имею ввиду интегрить с точки зрения математики да и поэтому сходу сейчас это наверное не так интересно лучше я Как раз зашлю вам и коллеге пару ссылок, он тоже как раз скажет, как они математически это делают, в том числе со ссылкой на Каптиарему, потому что Каптиарему мы здесь вообще не обойдём никак, и это будет самое важное, пожалуй, да, потому что нужно будет понять с точки зрения как раз конуса причинности по тем самым действиям, потому что как только мы этот граф, да, говорим, что сразу весь нельзя обозреть, то у нас получаются многозначные зависимости между конусами причинности. И вот это будет главное при реальном внедрении. То есть я на это просто уже несколько раз наталкивался с разными системами, и некоторые модели согласованности явно лучше других. Но сейчас тогда, я думаю, это не надо. 

S02 [01:30:46]  : Да, тем более, что я предупреждаю, что я не только не программист, но и не математик, и вообще в большей степени как бы станируется как философ. 

S00 [01:30:59]  : Спасибо, что стали понятны дополнительные контуры. Вот это прям замечательно. 

S02 [01:31:04]  : Может, сейчас станет еще более понятно что-то. Я могу использовать последние 15 минут на короткий рассказ про дел, типа пир-то-пир. 

S03 [01:31:15]  : Давайте тогда, Александр, сделаем так. Сделаете введение, соответственно, обменяемся краткой информацией, и если возникнет желание, то продолжим уже после какого-то... Да, да, да. 

S02 [01:31:28]  : А можно даже не продолжить. Дело в том, что я уже рассказывал про DLT, семантику и LLM, для доклада был. Но он как так прошел незамеченно. Сейчас смотрите, как я ставлю вопрос. Есть существующие блокчейны со всеми своими плюсами, со всеми своими минусами. Стоит задача, значит, оставить все плюсы. Дезентрализованное хранение, криптозащищенность, подписывание транзакций, смарт-контракты, ну и в принципе, наверное, все, консенсус, да, консенсус для создания валидной цепочки данных. И у нас есть один плюс – это семантика. Берем семантику чисто и смотрим, как семантика нам может решить огромное количество проблем, которые связаны с современным DLT-системами, стандартными блокчейнами. Ну, прежде всего, отказаться от блока, от блоковой записи данных. Почему возник блок? Исходно у Сатоши понятно, почему возник, потому что все данные однотипные, все транзакции совершенно одного формата, одного типа, это перевод некого токена, и для того, чтобы не гонять их по сети, лучше закинуть блок и делать консенсус по целому блоку. Но сохранившись вот эта технология у эфириума и уже блокчейнов со смарт-контрактами, она как бы оказалась очень странной. То есть мы в один блок запихиваем и финансовые транзакции на миллион эфириумов и какие-то мусорные прокотиков и все что угодно. Но поскольку у нас есть семантика, то мы можем все эти транзакции разделить на отдельные потоки и Обрабатывать практически независимо друг от друга, потому что мы знаем, что если, я несколько раз повторяю, каждая транзакция, каждое событие формируется по моделям. Если они формируются по разным не взаимодействующим моделям, то мы их можем в параллель запустить. И расширяя этот принцип, мы можем разделить на тематические кластеры по предметным областям, которые в принципе никогда не будут обмениваться данными. Эти кластеры не жестко физические, а по взаимодействию с моделями. То есть, скажем, есть набор моделей, которые занимаются недвижимостью, и это кластер недвижимости, к нему может подключиться любой узел. Вот когда он подключился к этому узлу, он работает только с данными по недвижимости, по данным конкретной модели. И данные по этому кластеру, они идут определенной веткой графа, И сохраняются совершенно независимо от других кластеров, скажем, спортивного кластера. Что мы решаем? Мы решаем проблему. У нас нет необходимости хранить все данные на всех полных узлах. Узлы, которые работают в сети, могут работать только с теми данными, с которыми они работают, с которыми модели, по которым они совершают какие-то действия. И вот модельный подход и семантика позволяют нам, во-первых, разделить, естественную кластеризацию ввести, и плюс сделать распределенное хранение, не децентрализованное полных данных, а распределенное хранение только внутри кластера. И даже внутри самого кластера, при работе с определенными моделями, мы можем модели тоже пускать независимо обрабатывать, если они не взаимодействуют. У нас сейчас так решено, что есть модель, по модели строится тупик. То есть админ, начиная работать с какой-то моделью, моделью голосования, он создает топик, вписывает туда модель и задает свободный доступ к этой модели, значит контролируемый доступ к этой модели или там закрытый. Нет, несколько способов доступа к этому топику. И работающие в этом топике, работающие в этой модели, это может быть 2-3 человека, 10 человек, 100 человек, они работают, обмениваются данными только в рамках этого топика. Эта сеть позволяет, библиотека Липпертупир, да, она это позволяет сделать из коробки. Вот у нас получается не только кластерное разделение, кластер — это вот то, что я говорил, организация, проект, значит, еще какое-то любое нечто цельное, да, а внутри организации еще топики, которые независимо тоже работают между собой. Плюс у нас еще появляется возможность, да, и говоря о топиках, если это... небольшой топик, то вполне возможно, скажем так, более-менее средний, то вполне возможно обойтись консенсусом внутри данного топика. Если это не очень важные данные, если это важные данные, то можно подключить ресурсный узел, специальные ресурсные узлы, которые нанимают работать, играть в консенсус. То есть мы подписываем с кем-то втроем некий контракт, мы понимаем, что сохранения этих данных на наших узлах недостаточно, мы не доверяем друг другу, мы наменяем еще семь консенсусных узлов, ресурсных узлов и подключаем их к нашей модели. Они не участвуют по ролям в самом бизнес-процессе, у них запрещено это делать, но они сохраняют все данные и валидируют эти данные и играют в консенсус. И тут мы получаем еще один плюс, то что поскольку у нас данные симметрически окрашены, каждое событие имеет симметрическую окраску, то мы можем назначать концентрус разный на разные события. То есть вот когда я заполнял данные контракта, я мог бы использовать консенсус, скажем, с лидером какой-то, совершенно безопасно, потому что если что произойдет, ну мы перепишем. А вот когда нажимал кнопку подписи этого контракта, то на эти события можно полный BFT консенсус запустить, и он отработает, пускай дольше, и задать на него 15 узлов консенсусных ресурсов, чтобы они отработали. И плюс еще направлено от циклического графа то, что предметные события имеют в качестве идентификаторов хэши. И когда я говорю, что я генерю новое предметное событие только со ссылкой на предыдущее событие, то эти хэши вписываются в текущее событие. То есть каждое событие в графе, это вот сейчас уже, да, каждое событие в графе, оно имеет хэш одного из предыдущих, вот сейчас еще решение принимаю одного или нескольких, может быть нескольких, чтобы соблюсти именно графовость, нескольких предыдущих событий. И поэтому переписать этот граф практически невозможно, еще с учетом того, что каждое событие подписывается ключом актора, который указан в этом же событии. 

S00 [01:38:53]  : А можно маленький вопрос? 

S02 [01:38:54]  : Да. 

S00 [01:38:55]  : А вот с точки зрения этого ХША будут ли еще матричные отметки времени? Ну или любые другие надежные распределенные отметки времени? 

S02 [01:39:03]  : Нет, они не нужны, именно вследствие того, Что? 

S00 [01:39:08]  : Из-за топиковости? 

S02 [01:39:10]  : Нет, нет, они не нужны из-за того, что есть упорядоченность событий в самом графе. Во времени. И поэтому никакой дополнительной указания времени здесь не... Скажем так, если есть необходимость указания времени конкретного, то это просто новое событие. 

S00 [01:39:31]  : Но ведь до того, как мы протянули соответствующую стрелочку, мы же как раз никак не можем утверждать, что она протянется вовремя и обеспечит отношение предшествования. 

S02 [01:39:39]  : Так, и для этого существуют модели. То есть, если, скажем, есть модель какого-то чатика, где не имеет вообще никакого значения последовательности, то они вообще брандкастятся. Эти события могут вообще идти бродкастом без консенсуса. Если это модель бизнес-логики, в которой обязательно должна быть последовательность, она задается моделью. То есть по сути получается, что каждый узел не сможет получить, сгенерить последующее событие, если нет консенсуса предыдущего. 

S00 [01:40:13]  : А как тогда бороться с остановами и гонками? 

S02 [01:40:18]  : Все регулируется моделью. То есть ты должен, то есть аналитик должен так составить модель, чтобы никаких гонок не было. 

S00 [01:40:26]  : Так, мышка же кабель может перегрызть. 

S02 [01:40:29]  : Ну, перегрызет, но консенсус все равно принимает. 

S00 [01:40:33]  : Остановка. А, то есть вы имеете в виду, что у вас любое совершенно событие при стыковании стрелочки, это обязательная процедура консенсуса. Консенсус, обязательно, да. А, понятно. Вот теперь понял. 

S02 [01:40:44]  : Спасибо. Дело в том, что вот если это неважные события, то скажем, вот я в чате говорил, когда мы к одному топику прицепляем десятки различных реакций, то есть там можно и без консенсуса, потому что кто-то Кабель перегрызли, не пришел, пришел позже, присоединился позже. Здесь еще нужно сказать так, что в самом событии есть метка времени, но она не является семантической, она является просто служебной. Когда сгенерено событие, там пишется локальное время, но оно не учитывается в семантике, оно может учитываться только при анализе. 

S00 [01:41:24]  : Нет, здесь как раз понятно. Лучше дальше про согласованность. То, что граф явный, это круто, это понятно. 

S02 [01:41:33]  : И плюс еще, я уже упоминал, что если ресурсный узел получает события на обработку и на сохранение от разных топиков, от разных кластеров, он может обрабатывать их параллельно, он может запустить сотню движков. Он понимает, что это разные кластеры, которые никак не влияют. И еще один плюс. Допустим, сразу на примере. Вася поступил в институт, в МГУ. Есть событие записано за поступлением в институт. Есть события окончания института, значит, подписания его экзаменационной комиссии. В общем, какое-то событие, которое подписывает его диплом. Вот и событие получения диплома, скажем так. И есть целый поток событий, которые описывает его обучение. экзамены, зачёты, ещё что-то. И вот эти события, они учитываются как семантические, как значимые во время учёбы, но после подписания конечного события, вот этого действия, поступления и окончания, они становятся мусорными по сути, служебными. И при определенных силодвижениях с подписывающими ключами есть возможность оборвать эти действия, повесить эту ветку, значит, висящей и протянуть семантическую и топоральную связь от первого события к последнему и эту ветку сдать в архив. Она будет доступна по запросам в принципе, но более длинным. Она становится валидной, она проверяемая, но она убирается с узла, на котором происходила эта деятельность. На узле остается только два события – инициации и результата действия. То есть возможность архивации с сохранением полной валидности графа, в смысле данных распространения в пертупер-сети. Ну, наверное, все, там куча еще деталей всяких, да, ну вот это основные базовые такие представления. Да, ну и понятно, что узлом сети и сейчас может быть мобильник, то есть узлом сети является сейчас, ну, есть и серверное решение, и есть браузерное решение, в браузере есть узел. есть движок и хранилище в браузере, и запускается сеть из браузеров, может, с мобильника, и настройку хранения данных тоже можно регулировать, то есть насколько ты хранишь только те данные, с которыми ты сам работал, или большее количество данных, если сохраняешь, И при необходимости, вот как и в предыдущей технологии сбраса в архив, можно сбросить свои данные в архив на ресурсный узел, которые остаются доступными, но как бы не загромождают твоё устройство. Ну, наверное, всё уже по времени. 

S00 [01:44:34]  : Спасибо. То есть тогда для истории стало понятно про разделение кластеров и как раз то, что в основе лежит та самая топиковость. Дальше, что всё, что касается связности отдаётся на откоп согласованию. И, соответственно, мы, с одной стороны, упираемся в теорему о византийских генералах, с другой стороны, зато универсально. И как раз осталось понять как раз про надёжное хранилище и уровни согласованности с точки зрения узлов. Ну и как раз я там ссылочку кинул. Мне кажется, что это одно из лучших описаний того, какие сейчас уровни считаются стандартными и как работают в чате. Вот, она всего одна, да? Вот я бы к ней потом привязал обсуждение того, а как сами графы, которые по сути задают отношения не только причинно-следственной связи, но еще и предшествования, автоматически на это дело влияют, и какой получается вывод. Спасибо. 

S02 [01:45:29]  : Спасибо, да. Ну, это отдельно. То есть можно документы почитать? То есть по семантике есть статья OpenDat? Нет? 

S00 [01:45:39]  : Вы про ДЛТ, да? 

S02 [01:45:41]  : Нет-нет-нет, именно по семантике, про движок сам событийный. А про DLT, кажется, опубликованный... Я потому что именно вот в этом изводе не читал, на удивление. 

S00 [01:45:54]  : Хотя сам узнаю. Если скините тоже просто в чат-антологию, например, стандартный наш, я бы очень был благодарен, спасибо. 

S02 [01:46:02]  : В смысле, по семантике, по событийной семантике? 

S00 [01:46:04]  : Да. Потому что именно в этом изводе, как вы сейчас его упоминали, я вот в таком разрезе почему-то не читал. Да, я буду признателен. 

S02 [01:46:13]  : Да, хорошо, я скину. 

S00 [01:46:15]  : Спасибо. Большое-большое. 

S03 [01:46:17]  : Спасибо. В самом деле у меня вот еще есть ряд вопросов. Надеюсь, у нас есть время на них ответить. Значит, смотрите. Насчет распределения по узлам. Возьмем следующий пример. Мы, допустим, строим документооборот, систему управления документооборотом, где мы проводим товарные накладные, которые у нас должны проходить по некоторому складу, и проводим некоторые проводки, которые должны проходить по бухгалтерии. И все это обрабатывается в контексте некоторых контрагентов, которые должны проходить по CRM, и обрабатывается некоторыми сотрудниками, которые должны проходить по HR и по payroll, а payroll должен проходить по бухгалтерии. Вопрос. Как мы это все будем распределять по нескольким узлам? 

S02 [01:47:23]  : Один актор, один узел. Только так. 

S03 [01:47:27]  : Что значит один актор? 

S02 [01:47:29]  : Каждый актор, который участвует в этой деятельности – это узел. Хорошо. Со своей ролью в конкретной модели. Что значит актор? Это может быть датчик, это может быть человек. 

S03 [01:47:45]  : Мы делаем систему документа оборота. Актор – это значит человек. 

S02 [01:47:50]  : Какой человек? Человек, который что-то делает в этой системе. Который сидит перед экраном. 

S03 [01:47:56]  : Хорошо. Человек, который проводит, принимает накладные и контролирует оплату, он актор? 

S02 [01:48:07]  : Ну, любой акт, то есть, скажем, каждое событие. 

S03 [01:48:12]  : Александр, я буду совершенно конкретно, потому что это мне очень важно. Совершенно конкретный кейс. Я делаю систему документов оборота. Мне нужно, чтобы какой-то сотрудник оформлял накладные, Сотрудник, значит этот сотрудник на своем устройстве должен хранить всю информацию, которую я только что перечислил. Данные о проводках, данные о товарных накладных. данные о контрагентах, то есть все это должно быть на его физическом устройстве, правильно? 

S02 [01:48:51]  : Не обязательно. Я упоминал момент, что при наличии узлов, дополнительных узлов, ресурсных узлов, на которых хранятся полные реестры всех данных, конкретные узлы могут оперировать только необходимыми последними данными, которые действительно актуальны. Мы знаем, когда закрылась некий квартал или что-то не нужное. Но при этом сохраняется возможность по сети сделать запрос. Скажем так, ресурсный узел будет представлять виртуальную память, виртуальное хранилище для этого узла. То есть если запрос выходит за пределы данных, которые находятся на этом узле, он транслирует на этот узел и получаются данные от него. Но эти данные верифицированные, проверенные, сохраненные, он их проверяет также по моделям, что они действительно валидны и используют. 

S03 [01:49:44]  : Смотрите, все-таки конкретный пример. Человек проводит проводку. Вся информация, точнее проводит документ, ведет к какому-то клиенту. То есть все проводки, все документы, все файлы, которые связаны с конкретным клиентом и всеми товарами, которые от него получены или ему отгружены, и всеми платежами, которые от него получены. и от него, значит, и ему ушли, это все хранится на устройстве конкретного человека. Нет, нет, нет. Я же только что сказал, Антон. Вы же сказали актор, вы сказали вся информация, которая проходит... Нет. 

S02 [01:50:22]  : Кто делает это? Это делает актор. У себя на узле. И это полноценный узел. Значит, смотрите. В этой деятельности, которую вы описываете про ветку, есть ветка графа. Есть ветка графов, в которой есть все данные для осуществления этой деятельности, и в которой сохраняются все текущие события, последние события, кто-то подписал, кто-то ввел какие-то данные, кто-то что-то отклонил, что-то загрузил. Они поволняют этот граф. И этот граф, этот граф хранится, выделяется несколько, если чисто практический, скажем, вот этот ваш, выделяется 3-5 узлов по необходимости, а может и один, который хранит весь граф. Все остальные участники данного бизнес-процесса, акторы, которые генерят события, они получают только те данные и хранят те данные, которые необходимы для текущей генерации событий. Если кто-то работает с одним клиентом xxx, то у него загружены данные клиента xxx. Кто-то работает с… 

S03 [01:51:25]  : с клиентом Y, у него данные по клиенту Y. Я это понял еще раз. Но все данные всех типов у него хранятся, правильно? 

S02 [01:51:36]  : Нет, я только что сказал, что не все. А, нет. Здесь, смотрите, опять же вопрос такой. 

S03 [01:51:43]  : Хорошо, Александр, давайте я уточню тогда. Смотрите, чтобы мы просто, иначе очень долго будем. Смотрите, я сейчас, значит, вы в какой-то момент сказали, что мы можем специализировать узлы по типу информации. Да. Сейчас то, что вы сказали, я слышу очень противоречия, потому что я вижу специализацию не по типу, а я вижу специализацию по как бы сегменту. Давайте все-таки, потому что мы по кругу ходим, давайте пропишу все-таки проблем, противоречия, которые я вижу. Значит, у нас, если в системе есть разнородная информация разных типов. Вот есть клиент, у него есть проводки, у него есть документы, у него есть какие-то юридические реквизиты. Это информация разных типов. Если у меня конкретный аккаунт менеджер работает с данным клиентом, Он не может не видеть информацию всех различных типов. И значит, на данном узле у него должна быть вся информация, связанная с данным клиентом. У него может не быть информации, связанной с другим клиентом, как я понял из ваших пояснений. Она может доходиться на устройстве другого аккаунт-менеджера. Но он должен обладать всей полнотой информации с точки зрения типов. 

S02 [01:53:16]  : Антон, ответ очень простой и однозначный на подобные ответы. И все определяется с моделями, с которыми он работает. Если модель, с которой он работает, требует данные разных типов, значит эти данные будут у него подгружены. Если модель требует только частично данных по какой-то, будут эти подключены. Все задается моделью. По этой модели загружаются данные сервера с узла, на котором они хранятся полностью. 

S03 [01:53:49]  : Правильно ли я понимаю, что у нас к каждому физическому узлу привязана та модель, с которой данный узел работает? 

S02 [01:53:59]  : Нет, абсолютно. При подключении к ТОПИКу, подключению к топику какому-то, он может сам подключиться, либо его админ может подключить. Он загружает модель. Модели только те, в каких топиках он работает. Модель – это именно пропуск, шаблон подключения на топик. 

S03 [01:54:17]  : Вы сейчас повторили то, что я сказал, что узел прикрепляется к конкретной модели. 

S02 [01:54:25]  : Я подумал, как будто навсегда. Неправильно тогда. Не узел прикрепляется к конкретной модели, а узлы подключаются к моделям. 

S03 [01:54:35]  : Хорошо. Дальше идем. Значит, правильно ли я понимаю, что если я на конкретном узле сейчас, допустим, вот я сейчас вот нахожусь на узле в роли бухгалтера, да, и владею определенной моделью, в рамках которой мне не попадает, ну, допустим, там личная информация сотрудников, потому что она мне не нужна, мне нужна только зарплата, да, я не HR, я 

S02 [01:54:59]  : Переключатель вкладки в интерфейсе на другой топик. 

S03 [01:55:02]  : В момент, когда я переключаю вкладку, у меня из локальной памяти затирается вся бухгалтерская информация. Почему затирается? 

S02 [01:55:15]  : В зависимости от объема памяти. 

S03 [01:55:19]  : Допустим, она перестает подгружаться в операционный контекст, но камня через сетку подкачивается. Нужно по другой модели. Это я понял. То есть модель фиксируется операционным контекстом текущего узла. Следующий вопрос. Допустим, мы фиксируем свою роль в качестве бухгалтерского узла. Мы обрабатываем проводки. Вопрос. У нас может быть проводка между Васей и Петей, а у нас может быть проводка между Петей и Васей, а у нас может быть проводка между Васей и Машей, а дальше может быть проводка между Машей и Сережей, а между Сережей может быть и Катей. И таким образом, если мы хотим обрабатывать, поддерживать баланс бухгалтерский, аналитические счета считать, нам по сути все проводки должны быть в данной конкретной машине. То есть мы не можем сделать так, чтобы одна машина обрабатывала, допустим, половину проводок, а вторую половину проводок, потому что у нас не получится баланс. То есть мы должны всю полную информацию хранить на одном узле. Правильно или нет? 

S02 [01:56:33]  : И да, и нет. Все зависит от того, какой объем памяти, ресурс этого узла. Если это бухгалтерская машина и она действительно проводит большие какие-то расчеты, то естественно она должна иметь большую память и большой диск, чтобы работать. Но если это небольшой ноутбук чьи-то, то он также сможет работать с полным объемом, но он должен будет подгружать его по частям. В любом случае проводка между двумя людьми осуществляется, но ты получаешь данные по этим двум людям. Можно предусмотреть модель, в которой участвуют сотни человек, но это как бы приборник. 

S03 [01:57:15]  : Хорошо, я получил ответ. Следующий, плавно переходящий. Какую базу данных вы используете для работы с этими объектами? Это у вас какое-то собственное решение или вы используете 

S02 [01:57:34]  : Сейчас движок работает с памятью, структура данных в памяти специально создана под событийную модель, под граф с индексами по использованию модели, то есть она специально оптимизирована для работы с моделями. и симпатийной семантикой. И все, что сейчас, все модели, с которыми происходит работа, граф находится в памяти. И при, значит, параллельно поступлении новых событий, событие поступает в память и одновременно добавляется в хранилище, обычное киевское хранилище, то есть Сейчас еще нет определенного хранилища типа Postgres это будет или файл. Скорее всего это будет. Разные варианты на разных устройствах, но именно при записи события синхронизируется хранилище постоянное, которое остается при выключении устройства и со события в память. При сбое устройства загружается из хранилища опять в память. 

S03 [01:58:41]  : Правильно ли я понимаю, что если в памяти обновляется информация, эта информация начинает сохраняться на диск, часть информации на диск сохранился, тут случайно кто-то нажал кнопку питания или свет моргнул, на диске оказывается карапнутый файл, который наполовину сохранился, наполовину нет, все можно выкидывать и восстанавливать из бэкапа? Антон, это уже мой вопрос, мы его уже начинали. Здесь это уже как раз чисто техника. Мне как раз это интересно. 

S02 [01:59:15]  : Сейчас, когда я подключаюсь к сети и по топикам, на которые я подписан, ко мне подгружается информация из сети. 

S03 [01:59:24]  : У вас есть транзакции в этой системе? Да. Еще раз, если у вас не полностью записала, если у вас память не синхронизовалась в процессе подкачки данных. 

S02 [01:59:36]  : Идет ошибка, то есть считается, в интерфейс ко мне приходит значение, которое я ввел только после того, после того как прошел консенсус по сети, Узлы обеспечивающие консенсус сохранили и только после этого они дают добро на записи от напражения на экране. Значит у меня будет ошибка. 

S03 [02:00:00]  : То есть у вас сохранение информации на диск проходит по консенсусу сети, правильно? 

S02 [02:00:08]  : Если я работаю локально, то мне движок даст данную информацию, что транзакция прошла, непосредственно в интерфейс даст. После записи. 

S03 [02:00:22]  : То есть у вас транзакция есть? 

S02 [02:00:25]  : Дело в том, что там без транзакции никак не обойтись, потому что происходит проверка подписок. Идет проверка подписок, совпадение всего. Если в это время что-то оборвется, то, естественно, идет ошибка сразу же. А фронтовые события не приняты. 

S00 [02:00:39]  : Да, универсально же для всех графсхемных языков. То есть, выход ноды графа – это транзакция. 

S03 [02:00:45]  : Понятно. Но при этом есть ограничение, что вот эта база данных должна умещаться в памяти, правильно? 

S02 [02:00:54]  : Локальная. То есть, локальная. Не совсем. То есть, все, опять же, зависит от деятельности. То есть, модели обычно маленькие. Можно и данные. То есть, они аж не вся загружается в память. 

S03 [02:01:06]  : Смотрите, я вернусь. Вот мы договорились, что, значит, у нас контекст, операционный контекст конкретно... Ну, если есть, то в память должна, да. 

S02 [02:01:15]  : То есть если мы сохраняем только нужное, а ничего другого, то это все нужно и нужно загрузить. 

S03 [02:01:23]  : То есть если мы работаем в рамках какой-то модели, то есть грубо говоря, если мы работаем в рамках модели, допустим, я не знаю, там приемщика заказов, то нам хватает памяти телефона и у нас модель. Если мы хотим на этот телефон подгрузить модель банка, она нам скажет, что нить у вас не хватает. 

S02 [02:01:48]  : По идее, чисто теоретически и по схеме можно и с телефона работать, но это будет непрерывная подгрузка по частям с серверной ноды. Но это не работа. Фактически это должно работать. Сейчас так не работает. 

S03 [02:02:10]  : Хорошо. Предпоследний вопрос. Я не совсем понял. Вы сказали, что может работать и на мобильном, а потом сказали, что есть серверная и браузерная версия. 

S02 [02:02:26]  : На мобильном в браузере работает. 

S03 [02:02:28]  : На мобильном браузере, окей. 

S02 [02:02:29]  : Да, тогда я запускаю, подключаю мобильный к сети и могу там, ну, месседж, что-нибудь, такие самые простые приложения, они работают. 

S03 [02:02:39]  : То есть хранилище, то есть на мобильном вы используете хранилище браузера? 

S02 [02:02:44]  : Браузерное, да. Сейчас типовое решение – это браузерное, но есть и серверное, где серверные ноды, релейная нода, которая для запуска сети, они работают на сервере. 

S03 [02:02:58]  : У меня вопросы кончились, спасибо. Алексей? 

S00 [02:03:03]  : А это было же в ту же степь. Это как раз я себе пометил еще два маленьких кусочка, еще про техническую согласованность на физическом уровне. То есть надо будет все концептуально, логически, физически рассмотреть стандартно, и вот эта ссылочка еще больше приобретает, которую я прислал, ладно, важность. 

S02 [02:03:21]  : Я посмотрю, спасибо. То есть тут вопрос именно еще вот в чем. То есть я являюсь как бы архитектором и идеологом самой продукта, но у меня компетенция уже все на пороге. То есть там нужно привлекать специалистов, но сейчас идет в эту сторону движение, и на многие вопросы я не могу ответить. 

S00 [02:03:48]  : Но, кстати, глядите, Александр, у вас же Там вот эта часть, да, она не специфична для семантики процессной любого типа, она, скорее, специфична для графсхемного программирования. И языки графсхемного программирования многообразные, и для них уже наработаны очень хорошие, лучшие практики работать с согласованностью надежных хранилищ. Ну вот прямо по сегодняшнему докладу, если. Поэтому я бы туда как раз глянул. Если что, обратитесь, я несколько хороших ссылочек себе уже имею, поскольку с ними работал. Спасибо. 

S02 [02:04:18]  : Спасибо. 

S03 [02:04:21]  : Смотрите, я предлагаю еще, прежде чем мы разбежимся, есть еще большой вопрос от Александра Крикуненко. Я предлагаю, как минимум, его еще рассмотреть. Александр, может быть, вы прочитаете или мне прочитать? 

S01 [02:04:36]  : Да, коллеги, добрый день. Спасибо, что вы такие мероприятия проводите. Я, как человек начинающий, Я терпаю знания и каждый раз понимаю, насколько я ничего не знаю. Но прогресс есть, поэтому полезно. Смотрите, вопрос мой какой. Я занимаюсь направлением автоматизации поиска. Вот, и к этому вопросу пытаюсь подойти с разных сторон. И вот сейчас есть такая идея, что, ну, представим, что у нас есть реляционная база данных, в этой базе данных, ну, в таблице у нас, не знаю, миллион каких-то записей с текстовыми описаниями этих сущностей. Ну, неважно сущности, там, не знаю, диваны, там, автомобили, просто какие-то текстовые неструктурированные описания этих сущностей. Подход следующий. Мы с помощью LLM извлекаем триплеты которые описывают эти сущности. Просим LLM выявить атомарные триплеты. Потом из этих атомарных триплетов мы извлекаем сущности, которые в них есть. Там субъект, объект, связь. Потом через LLM мы пишем определение этих сущностей. Почему? Потому что там есть инженер. Инженер может быть в настройке, программист, химик и так далее. То есть это все разные инженеры, разные определения. Мы пишем определение для всего. Далее через векторную базу, через какие-то general, какие-то embedding, не знаю, TextRelarge, ищем в векторной базе такие определения, если они у нас есть. Если такой сущности у нас в векторной базе нет, мы эту сущность создаем. Если она у нас есть, не создаем. И как только мы создаем какую-то сущность, мы также эту сущность создаем Третья база данных добавляется сейчас в графовую базу данных. То есть у нас в графовую базу данных попадают только те сущности, которые, по сути, прошли процесс дедубликации ранее через векторную базу. То есть мы нашли, допустим, мы создали новую сущность или поняли, что такая сущность в графе есть, мы добавляем в граф. Так вот, постепенно перерабатывают десятки, сотни тысяч, миллионы таких объектов текстовых, по которым мы делаем поиск, мы выявляем какое-то бесконечное количество этих сущностей, дедуплицированных, которых мы вектор загрузили с определениями со всеми. И, я не знаю, это что-то, наверное, не онтология, но какой-то такой граф, получается, И потом есть идея, когда мы делаем какой-то поиск, этот поисковой запрос, его также разделять на триплеты, также в них появляются сущности, и эти сущности по сути искать в нашем большом графе, который мы построили. По сути, все тексты, которые там миллион мы разметили через вот эти вот сущности, членов граф, просто мапить, получается. Мы сделали запрос, вывели триплет, в графе итоговом из унифицированной сущности нашли похожие. Я хочу понять, насколько это вообще идея живая или это... Ну, как бы, не очень. Скорее, возможно, такие подходы были уже, там, ну, поумнее, как бы, вот. Ну, в общем, какая-то обратная связь. 

S02 [02:07:51]  : Ну, одним словом, мёртвая идея. Ну, в смысле тем, что она, как бы, уже опробована множество раз. Никогда не работает свалка, единая свалка всех данных. Просто не работает. То есть, плюс вы заткнетесь сразу же на первых шагах ввода, на языке запутаетесь, а потом запросы к этой графу работать не будут. 

S00 [02:08:21]  : На самом деле будут, просто не во всех задачах. На самом деле, на дате Fusion на прошлой неделе была целая секция по этому вопросу. И там очень хорошо её обмусоливали. Это было понятно, что там с точки зрения хайпа-рага, но на самом деле там и другие вопросы вот именно в эту тему обсуждались. Спасибо. Анна Александровна, извиняюсь. 

S02 [02:08:42]  : Да, смотрите, то есть я схожу из совершенно другой идеи. Ну, во-первых, к этому и ЦИК пришли, да, по поводу региональных, нет, не региональных, как у них называется это. теории, локальных теорий, но неважно, вот, что нужно исходить из деятельности, конкретной деятельности, конкретной предметной области и организовывать данные согласно тому, что происходит. не просто набор какой-то данных, а именно по деятельности. То есть и ценнее всего, даже не результат этой деятельности, который потом можно распарсить, а нужно парсить деятельность. Сегодня у меня, кстати, была подготовлена презентация, которую я делал в 2015 году, а исходно в 2012 было все это написано по парсеру деятельности и как и должна быть организована кластерная онтология, и работать можно только в некой предметной области с заданными моделями, с заданными словарями. Но как человек? У нас человек никогда не может искать все везде и все знать, он должен быть специализирован в какой-то определенной области, знать терминологии этой области, знать типовые ситуации этой области, принципы построения каких-то действий в этой области, и тогда он сможет и найти, искать и действовать. И поэтому основу должна быть не свалка, составлять, откуда мы ищем основу, должно составлять модели деятельности и модели словарей. 

S01 [02:10:26]  : Александр, а разве это не является формированием словаря? Объясню вопрос. Допустим, у нас есть две фразы. Я программирую сайты и я разрабатываю веб-приложения. По сути, программируя сайты и веб-приложения, сайты и веб-приложения, это, по сути, очень близкие сущности. И, возможно, надо подумать про склеивание, но мы склеиваем. Разрабатывая и программируя в данном контексте, это тоже одна сущность. То есть, я как раз говорил, что мы через векторную базу ищем близкие сущности, и если они близки, то мы их склеиваем. 

S02 [02:11:02]  : Это типовой рак. Он сейчас так работает. И работает плохо. 

S00 [02:11:08]  : Зависит от задачи. 

S02 [02:11:09]  : Иногда очень неплохо. Ну, в целом, скажем так. Я пытаюсь сейчас разработать систему отлично от РАК, которая ориентирована больше на событийный модельный подход. и не ответа по фрагментам текста, и без векторной поиска. Ну, скажем так, на мой взгляд, вы описали стандартные поиски, которые ведутся уже лет 20. И они еще не привели к однозначному хорошему решению. 

S00 [02:11:44]  : Но к очень хорошо продающимся привели. Ну продаются, да. 

S03 [02:11:49]  : Просто семантическим поиском. Коллеги, спасибо. Александр, у меня на самом деле есть еще один вопросик, на который я надеюсь получить ответ. Смотрите, вот если я правильно понимаю, Особенностью вашей событийной онтологии заключается то, что мы любые изменения, которые проходят в том, что мы называем объектом, в том, что называется в объектно-ориентированных системах называется объектами, мы оформляем через события, через транзакции. Вот. Вопрос заключается в том, насколько это эффективно с точки зрения вычислительных ресурсов и ресурсов хранения, что мы для того, чтобы получить текущее значение некоторого объекта, должны проигрывать историю всех изменений, которые происходили. Я сформулирую, потому что исходя из того, что вы рассказывали на предыдущих семинарах, у меня сложилось впечатление, возможно неправильно его сейчас поправите, что вот как мы допустим в блокчейне, для того чтобы узнать значение счета какого-то кошелька, Мы должны в худшем случае развернуть какую-то ноду и проиграть весь блокчейн от нулевого блока? Либо в худшем случае раззиповать какой-нибудь блокчейн с архивированной с какой-то ноды на какой-то момент времени и проиграть все блоки от того блока, до которого была заархивирована эта нода, для того чтобы получить текущее значение соответствующего кошелька, любого кошелька. Что очень неэффективно в моем понимании. особенно учитывая ограничения по памяти да то есть сейчас для того чтобы понять надо чтобы развернуть поднять у себя эфирную ли биткоиновую ноду я не знаю там наверное 64 гига нужно как минимум вот а то и больше соответственно вопрос вот у вас это как решается ну смотрите на первый вопрос-ответ 

S02 [02:14:13]  : То есть любая запись в искреннюю таблицу или в графу – это некий набор данных с метаданными какими-то, некий пакетик такой. И вопрос только в его формате. Да, это может быть JSON какой-то, да, а может быть вот именно событийный формат, в котором четко прописаны эти данные, и он чуть-чуть больше, чем RDF, да, то есть не намного больше, чтобы это кардинально увеличило количество объема памяти, плюс я еще не говорил про Экономичность событийной записи, она подразумевает запись, которая может сохранить огромное количество узлов, уменьшить за счет, я ввел такое понятие, как семантический сахар. То есть много событий, которые записываются в графе, они являются семантическим сахаром, они не являются несущим. а данные, записанные в событийном формате через акты, оно минимизирует запись. Это с одной стороны. Второе. Это по объему памяти. Немного больше. Плюс то, что я сказал, что объем памяти увеличивается за счет темпоральности. Нужно хранить все данные. Но там, где это не нужно, это и не нужно применять. Но во многих сферах темпоральное хранение всей истории, оно важно. Да, ну хотя можно и существенно сократить эти данные за счет архивации через тот механизм, который я говорил. 

S03 [02:15:53]  : Теперь по поводу... Александр, можно здесь сразу? А про какой механизм архивации вы говорили? 

S02 [02:15:58]  : Механизм, когда конечно результирующие события замыкаются семантически и криптографически на инициирующие события. Поступил в институт, закончился, получил диплом. Мы всю ветку обучения сдаем в архив. Окей. 

S03 [02:16:14]  : Человеческое долговое состояние. 

S02 [02:16:17]  : То есть мы получаем данные, которые нам нужны в бизнес деятельности и вообще по деятельности. Они криптозащищены и семантически связаны, но при этом выкинули целый фрагмент данных, которые нам не нужны, в архив сдали. 

S03 [02:16:31]  : У вас есть понимание понятия снапшота? 

S02 [02:16:35]  : Нет. 

S03 [02:16:37]  : То есть у вас нельзя взять и получить текущее состояние какого-то объекта? 

S02 [02:16:43]  : Нет. Скажем так, это можно сделать, но это не является снапшотом в полном смысле. То есть я могу взять некое событие и получить связанный с ним. Не по всему графу. Граф не является частично упорядоченным. 

S03 [02:17:09]  : Александр, можно конкретный пример? Вот смотрите, я хочу получить полуперсональные данные Александра Балдачева из защищенной HR-системы предприятия, где работает Александр Балдачев. Физически какие действия я должен совершить? То есть вся информация в базе данных есть? Что мне нужно сделать, чтобы вывести форму? Вы же показывали в начале доклада. 

S02 [02:17:32]  : Это следующий мой вопрос был. Следующий ваш вопрос по получению данных. Они в графе. Я беру модель. модель, по которой эти данные созданы. Сейчас, и скорее всего так и останется, в самом событии прописана модель, по которой она создана. То есть я могу сделать выборку просто самую элементарную выборку такой-то параметра этой модели, такое-то свойство этой модели, и получить все значения, и такой-то индивид, да, и получить всю историю значений по этому индивиду. И могу еще сделать вот темпоральные пока он… сейчас какие-то и актуальные данные получаются, но будет 

S03 [02:18:17]  : Я вынужден получать историю, а если мне не нужна история? 

S02 [02:18:20]  : Нет, сейчас запросы работают с актуальными данными. Сейчас запрос, когда я делаю запрос, я получаю актуальный, последний. То есть, если человек несколько раз менял цвет прически, сделав запрос цвет прически Иванова, я получу последний. 

S03 [02:18:37]  : То есть, вы, грубо говоря, по каждому атрибуту получаете топ-1, да? То есть, грубо говоря, делаете... Последний, да, последнее значение получаю. 

S02 [02:18:44]  : В зависимости от кардиналити. Если кардиналити прописано 5, я получу 5 последних. 

S03 [02:18:50]  : Если в том кейсе, что мне нужно вывести на экран паспортные данные какого-то человека, то этот запрос делается с кардинальной т1, правильно? 

S02 [02:19:01]  : Да, и делается совершенно элементарно по его модели, по его структуре. А если нужно... Да, и это момент по получению данных. Данные получаются просто... То есть два типа запросов. Один запрос по модели, который работает с индивидами. Второй тип запросов, который работает непосредственно со структурой событий. То есть я независимо от модели могу задать запрос, скажем, с таким-то отношением, такой-то объект, такой-то концепт, с таким-то отношением, со значениями больше-меньше. Из всех моделей, из всего графа я получу эти события. То есть просто события, типизированные по запросу, независимо от модели. Но это редкий случай, это аналитика. А для работы модели обычно ты получаешь конкретные значения по текущей деятельности. И еще один момент по поводу производительности. Да, есть некоторый момент, связанный с подпиской на события, то есть для того, чтобы сгенерировать события, нужно движку проверить подписку на события, на какие события подписаны, в какие кондиционеры подписаны эти события, чтобы сработать. Но здесь проблема решается масштабированием. потому что dataflow архитектура, она параллельная и по независимым событиям можно запустить множество движков и этим решить проблему нагрузки. 

S03 [02:20:40]  : Спасибо. Александр, последний вопрос. Надеюсь, короткий ответ сможете дать. Поясните еще раз основание вашей критики РДФ, что это помойка. Правильно ли я понимаю, что проблема заключается в том, что если мы в РДФ описываем схему через УВЛ, то эта схема она одна и она жесткая. А вы можете описывать разные модели, где один и тот же граф может проецироваться на разные модели в зависимости от сценария. То есть дело не в том, что РДФ это... СВЛ это помойка, а в том, что это слишком жестко, а вы предполагаете некоторую гибкость. 

S02 [02:21:26]  : Здесь по поводу, я не упомянул еще, то что на один концепт возможно построить множество моделей. То есть один концепт персона, можно создать модель отдела кадров, модель семейная, модель хобби, модели участия в партийной организации. Это будут разные модели, и у нас будет к индивиду Иванов приписано множество различных отношений, атрибутов, но они будут считаться порциями, срезами в зависимости от моделей. 

S03 [02:22:03]  : А с ОВЛ мы этого не можем сделать? 

S00 [02:22:10]  : Конечно, можем. Постоянно делаем так. Ролевой состав. 

S02 [02:22:13]  : Но это как бы не заложено в саму спецификацию, а можно это сделать. А вот в BoltC это заложено исходно, потому что ни одно событие не может быть сгенерено без модели. Модель первична. Я создаю сначала модель, а потом по модели генерю события. И всегда ясно, какое событие с грейном, какой модель. И поэтому… Именно. 

S03 [02:22:44]  : Александр, еще раз, Алексей… Именно, он сказал, Алексей, именно. 

S00 [02:22:48]  : Нет, я просто как раз это самое главное. То есть мы говорим, что у нас есть предопределенная имманентная потребность в куске семантики, которая заставляет нас делать этот процесс. 

S02 [02:23:01]  : Ну и, конечно, самое большое преимущество – это темпоральность, то есть возможность моделировать бизнес-процессы с нуля, не наворачивать что-то сверху на РДФЛ. на объектную семантику, а именно исходно с коробки получается генерация моделей бизнес-логики. Любую бизнес-логику можно смоделировать на самодельных моделях. А еще плюс один, который я не упоминал, но он как бы понятен, это асинхронность вообще работы всей системы по типу микросервиса. То есть каждая модель это как бы некий сервис, который пишет что-то в граф, а другие модели реактивно через подписки реагируют на эти события. То есть сами модели друг к другу не реагируют. А еще плюс такое, что я могу модель по-живому менять. То есть, скажем, Добавлять точно. То есть я могу в существующую модель добавлять любые модельные события, и этим никаким образом не нарушу целостность ни графа, ни работоспособность модели. Это за счет dataflow архитектуры. То есть несколько человек могут строить одну модель, даже не зная друг друга, и при этом модель будет рабочая для каждого из них. 

S03 [02:24:28]  : Да, пока они не создадут две ортогональные версии, две ортогональные модели, описывающие одно и то же в терминах, индивидуальных терминах. 

S02 [02:24:39]  : Это как мы подразумеваем, что словарь – это словарь, это все закон. Без словаря здесь ничего не будет. Словарь – это стандарт. Каждый себе может создать все, что угодно, но тогда теряется все преимущество семантики, что мы сможем обмениваться данными. Да, кстати, про DLT, когда я говорю про сеть, я не упомяну, что понятно, что когда я посылаю сеть данные с температурой и с координатами в каком-то месте, то это прочитают все, кому есть доступ. Поскольку это семантика, поскольку есть модель, модели доступны. Модели должны быть доступны, распространяемые по сети. Ну, какие-то, может, закрыты, какие-то открыты. Я должен скачать модель температуры в каких-то координатах, управления погодой, и по этой модели прочитать, в графе найти те данные, которые меня интересуют. Благодаря тому, что есть модели, есть словари. 

S03 [02:25:33]  : Спасибо. На этой высокой ноте предлагаю закончить. Большое спасибо. 

S02 [02:25:38]  : Спасибо. 

S03 [02:25:39]  : Очень было полезно и интересно. Интересно, полезно, интересно. Всем большое спасибо. До свидания и до новых встреч. До свидания. 

S02 [02:25:49]  : Всего хорошего. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
