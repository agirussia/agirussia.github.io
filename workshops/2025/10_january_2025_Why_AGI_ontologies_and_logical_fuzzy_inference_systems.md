## 10 января 2025 - Зачем AGI онтологии и системы логического (нечеткого) вывода - Антон Колонин — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/5pQf9zib7-Y/hqdefault.jpg)](https://youtu.be/5pQf9zib7-Y)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239207)
- [видео в RUTUBE](https://rutube.ru/video/aa3f5363da69d205466816a492933c52/)
- [слайды](https://aigents.com/papers/2025/ontologies-back-2025.pdf)

Суммаризация семинара:

Семинар посвящён вопросам искусственного интеллекта, в частности, обучения систем на основе языковых моделей (LLM) в течение всего жизненного цикла. Обсуждаются принципы lifelong learning и incremental learning, а также их применение в реальных бизнес-процессах.

Основные тематические блоки


 1. Необходимость обучения в течение всего жизненного цикла
- Обсуждается, что системы LLM должны обучаться не только в начале, но и в течение всего жизненного цикла.
- Приводится пример цикла обучения, включающего сбор данных, их анализ и повторное обучение на основе обратной связи от пользователей.
- Указывается на важность метода Reinforcement Learning with Human Feedback для улучшения качества системы.

 2. Различия между человеческим мозгом и системами LLM
- Анализируется, насколько необходимо воспроизводить работу человеческого мозга в системах LLM.
- Обсуждается возможность использования метода количественного увеличения производительности обучения для инкрементального обучения на лету.
- Указывается на отсутствие в существующих архитектурах механизма перекачивания контекста из краткосрочной памяти в долгосрочную.

 3. Семантические графы и их роль в AGI
- Рассматривается важность семантических графов в системах искусственного общего интеллекта (AGI).
- Обсуждается, что семантические графы позволяют лучше понять и интерпретировать результаты работы системы.
- Указывается на преодолимость противоречия между семантическими графами и нейросетями.

 4. Верификация и интерпретируемость в LLM
- Приводится пример верификации работы системы LLM на основе инструментальных механизмов.
- Обсуждается проблема интерпретируемости результатов работы нейросетей и предложения по её решению.
- Упоминается о необходимости учета нарративных связей в текстах для улучшения работы LCM.

 5. Критика и альтернативные точки зрения
- Критика представленных идей со стороны одного из спикеров, который считает, что семантические сети и нейросети могут быть полезны, но не всегда необходимы.
- Обсуждение возможных альтернативных подходов и методов, которые могут быть использованы в системах LLM.

Вывод

Семинар показал, что вопросы обучения и интерпретируемости систем на основе LLM остаются актуальными. Обсуждались различные подходы и методы, включая семантические графы, верификацию и интерпретируемость. Также поднимались вопросы о необходимости воспроизводить работу человеческого мозга в системах LLM и о роли нарративных связей в текстах. Семинар подчеркнул сложность и многогранность задач, стоящих перед разработчиками систем искусственного интеллекта.







S09 [00:00:09]  : Коллеги, всем добрый вечер. После длинного перерыва начинаем заседание семинаров русскоязычного сообщества разработчиков сильного и общего искусственного интеллекта. Случилось так, что мы несколько месяцев собирались очень редко, а 1 января вдруг пошли активные дискуссии сразу по двум темам. Одна тема эта пошла в основном в группе онтологий. по поводу антологий самих, по поводу DSL, по поводу редакторов антологий, что лучше, что хуже, зачем это нужно в век или в эпоху чат GPT. И потом эта дискуссия перекинулась в чат AGI Russia. Ну, а вторая тема, соответственно, возникла в чате AGI Russia по поводу того, Вот у нас есть часть GPT, уже почти AGI или не почти AGI, и что с этим дальше делать, чего не хватает, есть ли куда еще расти и куда расти. Есть две темы, все, естественно, охватить нельзя, но у нас получается сейчас плотное расписание семинаров. Сегодня мы поговорим про онтологии прежде всего. 13 января у нас будет доклад Михаила Киселева про реализацию обучения с подкреплением полностью на спайковых или импульсных нейронных сетях. Потом 16 января мы снова возвращаемся к антологиям и Алексей Незнанов расскажет про систему управления базами знаний в контексте управления данными. А 3 февраля Максим Кулишев и Дмитрий Балашов расскажет про дифференциальную феноменологию, динамические онтологии, мета-онтологию и свой оригинальный и в том числе продуктовый подход. Ну а сегодня мы начнем с разговора про онтологию, поскольку я не знаю, насколько участники сегодняшнего обсуждения готовы выступить. Предлагается следующая схема. Я вначале сделаю некоторый позиционный наброс по поводу того, как я вижу сейчас проблему AGI, LLM и онтологии в целом. И, возможно, после этого сразу переключимся в дискуссию. Если дискуссия сразу не получится или если она быстро завершится, то у меня есть еще некоторое продолжение. Я так понял, тоже есть интерес к этим вещам в группе. И с Денисом здесь присутствующим мы тоже это обсуждали. Я могу рассказать для поддержания дискуссии о своем опыте как раз редактора онтологии и DSL и мета-онтологии, что такое правильная мета-онтология, что такое неправильная мета-онтология. Тоже можно будет на эту тему поговорить. Итак, я начинаю тогда со вводной, а потом сделаю паузу и можно будет пообсуждать, куда двигаться дальше. Показать экран. Вот он мой экран. Вот она моя презентация. Видно слайды, да? Да. Итак, о явных и неявных графах или эксплицитных и имплицитных онтологиях. Начнем с того, что вроде как в результате 50-летнего соревнования символьного и сабсимвольного подходов победил символьный подход. Вроде как у нас есть системы глубокого обучения с трансформерами, с помощью которых как говорят некоторые участники, традиционный НЛП умер, символьный искусственный интеллект умер, что все можно делать вроде как с помощью трансформера. Ну а на практике оказывается, что есть нюансы. Например, если мы возьмем широко известную в узких кругах компанию Palantir, Для тех, кто не знает, это продуктовая компания номер один в мире в области бизнес-разведки, разведки военной, а также боевого искусственного интеллекта. Американская компания, основанная в том числе одним из основателей PayPal. И эта компания тоже на сегодняшний день использует трансформеры, но для того, чтобы эти трансформеры у них решали реальный бизнес задачи, им приходится делать массу костылей, в основе которых стоит их собственная система графознаний, или, как они открыто ее называют, эта система, основанная на антологиях. И она используется множеством различных способов, которые здесь показаны самыми разными стрелочками. Начать с того, что на основе имеющейся у них антологии и частных антологий, которые они разрабатывают для конкретных прикладных задач. Кстати, вот здесь внизу слайда есть ссылочка на статью, где они описывают, как они с этим работают. И из этой статьи есть ссылочки на другие ссылочки в их же блоке по конкретным аспектам того, что нарисовано здесь на этом слайде. В общем, на основе того графа знаний, который они реализовывают, у них есть так называемые функции или тулы. Я их называю grounding functions и grounding tools, потому что они позволяют заземлить или осуществить grounding того, что делают распределенные представления нейросети с некоторыми реальными операциями в реальном мире или с некоторыми реальными данными или с некоторыми реальными структурами данных которые есть в подстилающих вот эту вот нейросетевую языковую модель базовых данных. И с помощью этих функций или этих тулов они осуществляют множество различных операций для того, чтобы снизить масштабы и критичность того, что называется галлюцинацией. Значит, первое, что они делают, они могут насытить Prompt некоторыми онтологическими структурами, в контексте которых осуществляется обработка запроса. Это то, что с левой стороны называется Ontology Injection. Соответственно, мы насыщаем Prompt некоторыми структурами данных, в контексте которых должен обрабатываться запрос, после чего обрабатываем запрос в этом контексте и получаем соответствующий ответ. Второй вариант – это когда мы запрос пропускаем через некоторый пайплайн с помощью технологии типа ланчейн. И существует ряд других технологий, которые обеспечивают что называется мультиагентные фреймворки, которые позволяют множество специализированных агентов или специализированных тулов объединять. для взаимодействия между собой на основе одной модели. С помощью этих тулов, во-первых, идентифицируются, какие тулы нам нужны. То есть, когда мы посылаем запрос в LLM, мы, исходя из этого запроса, определяем инструменты, которые нам понадобятся, в том числе функции, которые нам нужно выполнить, и аргументы этих функций. После этого осуществляется вызов этих функций и получаются некоторые результаты. Результаты этих функций дальше погружаются в Prompt. И на основании этого Prompt идет обработка запроса. На самом деле, здесь вариантов существует много, как это делать. В общем, схема такая, что мы так или иначе подключаем к генерации Prompt и обработке запроса результаты исполнения конкретных функций. Ну и, наконец, третий вариант – это мы, собственно, в самой LLM при расчете, например, семантической близости между различными элементами, которые на которых она построена, там непосредственно встраиваем туда функции, которые могут выполнять расчеты непосредственно при работе самой LLM, то есть на самом низком уровне можем подцепить некоторое издемление на конкретные вызовы к семантической базе данных, а в принципе это может быть любая база данных, про это я сейчас еще пару слов скажу. Ну и, наконец, последний способ, про который нам в своем одном из докладов рассказывал, по-моему, Виктор Носко, это семантическая фильтрация запросов. Когда мы получаем множество запросов, которые имеют большую или меньшую насыщенность галлюциногенными или галлюцинирующими проявлениями, мы имеем возможность некоторым образом оценить осмысленность этих запросов для того, чтобы Либо оценить, насколько запрос актуален, и если, допустим, запрос не актуален, то принять соответствующие меры. Например, результат запроса отправить в промт с контекстом того, что мы не смогли выполнить этот запрос, и тогда следующая итерация с LLM сможет какими-то понятными пользователями словами сказать, что я не смогла. сгенерировав некоторое количество запросов, отобрать из них наиболее актуальный и уже этот актуальный запрос вернуть пользователю. Таким образом, существует множество различных способов, с помощью которых в Palantir борются с галлюцинациями и делают систему полезной не только для мозговых штурмов или набросов, брейнстормов, про которые вчера или сегодня писал товарищ Спайдал, был репост соответствующий его обсуждения, но и для решения конкретных прикладных задач. То есть для удовлетворения запросов конкретных конечных пользователей на естественном языке. К следующему слайду мы как раз сейчас придем. toolchain или многоагентная технология, когда мы каждый tool можем оформить в виде одного из агентов, то сделав его специализирующимся в какой-то области, какие-то агенты могут быть специализированы, допустим, по работе с графами, какие-то по работе с табличными данными, какие-то по работе с файловой системой, какие-то по работе с поиском в интернете, а какой-то агент может заниматься сбором и оценкой результатов от этих агентов, а какой-то другой агент может заниматься формированием некоторого сборного ответа. И есть такое движение, что у нас есть так называемый Retrieval Augmented generation, когда мы, на самом деле, просто имея некоторые базы данных различным образом представленные, получаем из этих баз данных ответы. Значит, или это онтологии, или это таблицы. Ontology Augmented Generation это UAC, Table Augmented Generation это TAG, Retrieval Augmented Generation это RAC, В проекте, про который я сейчас пару слов скажу, мы работаем с Time Series DB, современными базами данных, там у нас получается Time Series RAG, ну и можно придумать много разных RAG, можно объединять их в Tool Chains и строить эти конструкции поверх LLM, ну и вроде как это все Что нам нужно? Рак плюс 2 чейнс из all unit to create AGI. Вот здесь показан некоторый демонстрационный пример того, как это работает, кто непосредственно с этой технологией не сталкивался. То есть, мы можем оформить два тула. Допустим, если мы хотим заставить систему разговаривать на тему цен и волатильности курсов криптовалют, то мы можем определить некоторую функцию. которая сейчас, вместо того, чтобы лезть в реальную базу данных, она просто возвращает заглушку. Это элемент просто тестовой системы. Допустим, если у нас биткоин, мы знаем, что мы возвращаем эту цену, а если это эфир, то мы знаем, что мы возвращаем эту цену. Ну и тоже самая волатильность. Для биткоина всегда возвращаем 5, а для эфириума всегда возвращаем 10. В случае промышленной реализации в месте этих реторнов будет идти запрос к обычной базе данных с получением актуальных циферок в заданном временном окне. Эти функции дальше привязываются к движку. ланчейновскому, ну и дальше мы генерим запросы. И вот, пожалуйста, запросы, которые возвращаются, соответствуют уже всей системе, системе в сборе. Надо сказать, что если вот этого не сделают, то будет возвращаться всякая фигня. поскольку никаких реальных данных нету один раз значит от раза к разу система говорит я просто ничего не знаю в другой раз она говорит что вот пожалуйста сходи в интернет и поищи информацию в другом случае она предлагает код на питоне для того чтобы использовать там один API в четвертый раз она предлагает код на питоне чтобы вытащить эти данные с другого API Можно сказать, что она галлюцинирует, но я считаю, что неправильно это называть галлюцинацией, потому что на самом деле то, что мы называем галлюцинацией, по сути, это дело креатив. То есть, можно сказать, что Менделееву тоже в свое время пригрезилась в его галлюцинации таблица Менделеева во сне, которая потом оказалась правильной. Ну а то, что ему снилось и то, что оказалось неправильным, об этом история умалчивает. Но мы обращаем внимание, что при том, что мы задаем Определяем вот эти вот правильные возвращаемые значения на уровне встраиваемых во framework функции. Мы получаем правильные числа. Вот у нас цена биткоина возвращается. Вот у нас волатильность биткоина возвращается. Вот у нас цена эфира возвращается. Вот волатильность эфира возвращается. Но при этом система не может удержаться. и дает волю своей фантазии, рассказывает нам много всякого интересного на тему этих циферок. Иногда по делу, иногда не по делу, иногда она скромно молчит и после точки ничего не появляется. В некоторых случаях она полит всякую лажу и здесь как раз возникает та ситуация, когда мы понимаем, что мы не можем в таком виде просто отдать это конечному пользователю, если этот пользователь не исследователь LLM и не какой-нибудь брейнстормер. В данном конкретном случае проблема решается тем, что мы можем попробовать применить некий специальный промпт, который предполагает, говорит фреймворку и LLM, что, пожалуйста, так что-то произошло так что-то у нас произошло не видно слышно и видно и слышно на презентации нет ага сейчас видимо давайте снова видимо я заговорился и экран отключился так видно так видно снова да так это не та презентация стоять так где моя презентация где моя презентация так сейчас секундочку это чудеса Так, что-то с презентацией случилось не так. 

S09 [00:18:19]  : Мы говорили о том, что есть способы, которые могут снизить вероятность либо галлюцинации, либо ненужного креатива, либо некоторого дополнительного креатива, который возникает поверх полезных ответов, но ненужных в контексте данного пользователя. Ну и теперь перейдем к тому, что вообще, кроме галлюцинаций, нам не хватает от больших языковых моделей для того, чтобы построить то, что мы называем AGI. Ну, про борьбу с галлюцинациями мы только что поговорили, и как раз это подведет нас к теме необходимости онтологий, на основе которых мы с этими галлюцинациями будем бороться, и к вопросу о том, откуда эти онтологии вообще взять. То есть, мы поняли, что хорошо, языковые модели большие есть, но для того, чтобы осуществить им граундинг, нужны пресловутые графы знаний, нужно есть верифицированные символьные знания, но как их создавать? Соответственно, либо нужны опять-таки редакторы антологии, про которые мы, может быть, сегодня поговорим или в следующий раз, если сегодня не хватит времени, или нам нужны какие-то системы, которые будут автоматически создавать антологии на основе Те методы, которые, например, разрабатывает Евгений Евгеньевич Витяев, здесь присутствующий. А потом автоматически сформированные онтологии будут уже заводиться в редакторы онтологии, где С помощью этих редакторов эти данные могут верифицироваться, удаляться несоответствующей реальности артефакты, добавляться недосозданные артефакты, имеются в виду сущности отношения. И в этом случае способы автоматического создания антологии, редактирования и создания антологии вручную становятся актуальными. Следующая проблема, которая оказалась достаточно интересной, это способность инкрементального обучения. То есть, системы ЛИЛЭМ, как, наверное, здесь почти все присутствующие знают... Вы нам презентацию хотите показывать или пока так рассказываете? Разве не видно презентацию? 


S09 [00:21:33]  : Сейчас видна презентация. Хорошо. Мы из этого слайда прошли, перешли к этому слайду. Итак. Мы поговорили про галлюцинации и следующий вопрос про необходимость обучения в течение всего жизненного цикла. То, что называется lifelong learning и incremental learning. Если системы на основе LLM сейчас работают по такому принципу, берем, собираем очень много данных, потом в течение длительного времени, может быть месяца, может быть двух, их тренируем. Потом запускаем их в продакшен, собираем в продакшене некоторую обратную связь. от пользователей. Формируем некоторые дополнительные результаты этой обратной связи. Где-то пользователи говорят, что ты молодец, ты хорошо ответила. Где-то пользователи говорят, нет, ты плохо ответила. Или где-то пользователи просто что-то говорят. То есть мы формируем результат некоторого интерактивного взаимодействия системы первой версии с пользователем. И вот этот лог взаимодействия системы с пользователем мы добавляем к исходным тренировочным данным, которые использовались для тренировки первой версии системы. И снова тренируем систему. И снова проходит какое-то время, неделя, месяц или два. Мы на основе этих исходных данных и дополнительных данных генерируем систему версии 2. реализуя, тем самым, так называемый Reinforcement Learning with Human Feedback цикл и получаем систему версии 2. После чего мы снова можем выкатывать ее в продакшн, снова собирать результаты взаимодействия с систем-использователем и, возможно, какие-то подкрепления правильности и неправильности ответов. И дальше заводить это на третий цикл, изгенерировать систему с учетом reinforcement learning with human feedback версии 3 и так далее. Но это немножечко не так, как работает человеческий мозг. Другой вопрос. Нужно нам обязательно воспроизводить так, как человеческий мозг работает? Или нам достаточно того, что я сказал? Может быть, если мы, например, научимся перетренировать всю телелем не за 2-3 месяца, а за 15 секунд, то, допустим, каждые 15 секунд, собирая Весь фидбэк, который случился за эти 15 секунд по всему миру, снова перетренировывая ее с этим фидбэком, мы будем получать следующую версию, потом каждые следующие 15 минут мы будем собирать другие инкрементальные результаты взаимодействия системы и снова перетренировать ее в принципе может быть таким способом как бы методом количественного увеличения производительности обучения мы можем прийти вот тому что называется инкрементальное обучение на лету Вот. У человека это работает немножко по-другому. У человека есть так называемая краткосрочная память. Человек то, что он получает в ходе текущего взаимодействия, погружает в краткосрочную память. И эта краткосрочная память, некоторый операционный контекст, в ходе который он как бы осмысляет и который актуализируется в его в текущем состоянии с помощью механизма эмоций со временем перекачивается долгосрочную память. То есть у человека есть механизм перетекания контекста из текущей памяти, из оперативной памяти, из short-term memory в долгосрочную память. И этого механизма на сегодняшний день, по крайней мере, в той аналогии, как мы говорим про человека, у существующих архитектур нет. Там есть контекст, но у нас нет механизма перекачивания этого контекста в саму модель, иначе как через механизм reinforcement learning with human feedback, который по архитектуре потекущей выполняется на долгосрочных циклах, на долгосрочных итерациях. ну не существенно не в режиме реального времени то есть мы не можем сказать системе что вот а вот теперь то что ты знаешь неправильно все должно быть по-другому и используя это во всех взаимодействиях со всеми остальными пользователями мы этого сказать не можем мы можем затолкать эту информацию только в текущий контекст и рассчитываться рассчитывать на то что контекст окажется достаточно большой чтобы что в течение всего нашего взаимодействия с системой эта информация из контекста не вытолкнется, ну а если вытолкнется, иметь механизм, который будет это время от времени туда подталкивать. Ну и, наконец, последняя проблема, которую предстоит решать, собственно, ресурсы. То есть мы можем, конечно, решать задачи с помощью чат-GPT, подключившись к нему через VPN или к соответствующей системе Сбера или Яндекса. Но если мы находимся где-то в условиях отсутствия интернета или если мы являемся дроном, который куда-то летит и должен что-то сделать, без доступа интернета и в условиях, когда интернет недоступен, то тогда у нас нет никаких ресурсов, чтобы выполнять соответствующее взаимодействие на основе ланчейна. Мы не можем развернуть систему на питоне, на бортовом компьютере и с помощью нее взаимодействовать с инфраструктурой чат GPT или любой другой сети и даже поднять достаточно большую нейросетку. На самом деле сейчас в этой области прогресс идет. Буквально несколько дней назад NVIDIA демонстрировала по-моему 128 гигабайт памяти. На ладонном устройстве, которое в принципе уже может ставиться на борт компьютера. Но 128 гигабайт – это не такая на самом деле большая модель для того, чтобы решать те задачи, которые решает человеческий интеллект. Ну и, наконец, проблема интерпретируемости. Если мы хотим систему, основанную на том или ином искусственном интеллекте, устанавливать на каком-то объекте критической или, упаси бог, военной инфраструктуры, то мы, конечно же, должны быть уверены, что там галлюцинации не будет. То есть, мы должны понимать, какие знания в этой системе содержатся. Может быть, мы можем верифицировать адекватность этих знаний методом экзаменов, то есть, в конце концов, каким образом мы решаем проблемы с людьми. Если мы, допустим, доверяем человеку работу на соответствующем критически важном или опасном объекте, мы же не осуществляем аммутрепанацию мозга и не верифицируем формально не противоречивость сигналов и связей каждого отдельного нейрона, мы проводим человеку экзамен. Мы гоняем его по всем билетам и убеждаемся в том, что он знает предмет И, в принципе, можно рассуждать, что мы можем для допуска больших языковых моделей или соответствующих систем на объекты критической или военной инфраструктуры просто экзаменовать их соответствующим образом. Но, соответственно, эта технология тогда требует проработки, как нам полноценно осуществлять экзамен со всеми контрольными заданиями по конкретной тематике для соответствующей системы. Было проведено у нас небольшое голосование в группе, что нужно сделать для AGI, на смартфоне или на борту дрона уметь делать выводы языковых моделей. наделить их сознанием и телепостановкой, обеспечить инкрементальное быстрое обучение и переобучение в течение жизни, наделить их интерпретируемостью, ну и сделать все перечисленное без больших языковых моделей. Тема инкрементального и быстрого обучения и переобучения в течение жизни оказалась на втором месте, а на первом месте, на самом деле, к удивлению для меня, оказалось, как сделать все перечисленное без больших языковых моделей. вот и если здесь есть присутствующие кто сголосовал за то что нужно вообще от больших языковых моделей избавиться в принципе то у меня мне было бы интересно узнать есть ли какие-то аргументы вот в пользу этого пункта кроме как энергоэффективность да потому что если допустим мы будем рассчитывать на рост экономической эффективности вычислений больших языковых моделей экспоненциальной, то может оказаться, что вычислительных затрат через лет 10 будет хватать даже на наборные оборудования. То есть мы знаем то, что мы сейчас имеем в смартфоне, это несколько десятков лет назад была Super EV. Ну и, соответственно, какими способами мы будем бороться с галлюцинациями? Это графы и мультиагентная система. Это то, над чем, по-моему, сейчас работают практически все, кто работают с большими языковыми моделями. Каким образом инкрементально обучаться или дообучаться? Это, очевидно, все-таки нужны новые архитектуры. Но если вдруг не окажется, что все-таки железо настолько быстро растет, что можно будет реинфорсовывать learning with human фидбэк делать в коротких циклах без остановки самой системы и обновлять большие языковые модели на лету. Ну и как тренировать AGI на смартфоне и как доверять им Критический объект – это либо опять-таки нужно новое, гораздо более высокопроизводительное желебо, либо все перечисленное вместе взятое, либо вообще все вместе взятое. Теперь переходим к графам. Первая мысль на тему того, как мы можем скрестить одно другое, она исходит из концепции, которую, по-моему, кто-то тоже недавно в группе высказал, что все есть предикат. То есть, в конечном итоге, всё можно свести к предикату. Формальную схему нейрона можно свести к предикату. С другой стороны, Стивен Вольфрам сказал, это тоже пару лет назад, что всё есть граф. Соответственно, всё есть под граф. А под граф – это суть предикат. Соответственно, все можно выразить либо графами, либо предикатами. При этом не обязательно эти графы или предикаты должны быть четкими, бинарными. Они могут быть небинарными. Вот здесь, как на этой картинке, как раз применительно к НЛП показана вот та идея, с которой я несколько лет ношусь уже, что мы одно и то же лингвистическое знание можем выразить с правой стороны, либо с помощью сетей глубокого обучения. И здесь показаны слова, и на верхнем слое показаны конкретные слова, и только на нижнем слое показаны грамматические категории. И между ними есть два слоя, и мы можем с помощью определенных весов нейронных связей в этой четырехслойной нейронной сети описать, как закодировать идентификацию слова SO как существительного. второго слова «со». Первое слово «со» – это глагол, а второе слово «со» – это существительное. Вот здесь весовые коэффициенты показывают, как второе слово «со» может быть идентифицировано как существительное. А с левой стороны показана примерно такая же структура, то есть тоже токены или слова на верхнем слое, но дальше два промежуточных слоя описывают структуры семантические в терминах грамматики связей. На втором уровне идут связи, линграммар, а на следующем слое идут так называемые диджанты, грамматики связей. При этом в грамматике связей есть понятие костов, Которая соответствует весам связи, чем выше кост. тем ниже сила связи с точки зрения нейронной сети. Но, тем не менее, мы с помощью этих кастов можем, в принципе, описать то же самое нечёткое знание по поводу грамматического соответствия второго вхождения слова «сов» в предложение для идентификации его как существительное. Да, вижу руку Андрея Ковтуненко. Андрей, пожалуйста. 

S03 [00:35:12]  : Если мы говорим, что предикаты могут быть нечеткими, как мы эту нечеткость построим? Если они по мощности равны с нейросетями, мы эту нечеткость строим обучением обратному распространению ошибок. А в предикатах как это мы будем устраивать? 

S09 [00:35:32]  : Да, вот сейчас дальше как раз к этому идём. Да, всё правильно, всё совершенно в тему. Как раз если мы говорим про линграммар, там всё этим очень плохо, потому что косты связям подбираются вручную методом тестирования, то есть сами грамматики создаются вручную в линграммаре лингвистами. которые сидят и день и ночь эти связи кодируют, и если они видят неоднозначность или некорректность существующей грамматики в каких-то случаях, они подбирают эти косты таким образом, чтобы обеспечивалась корректность. Идея как раз заключается в том, что да, с нейросетями у нас все хорошо, потому что мы методом обратного распространения ошибки можем эти веса подобрать, но мы не можем заглянуть внутрь и понять, а где у нас связи, а где у нас фразы. А в грамматике связей тоже по-своему все хорошо, потому что мы знаем, где у нас какие типы связей, где связи между существительным объектом и субъектом, где между глаголом и объектом, где между глаголом и субъектом. Но мы не знаем, как эти связи получить. И идея как раз заключается в том, что если бы мы умели с одной стороны методом обратного распространения ошибки извлечь вот эту вот интерпретируемую семантическую, в данном случае грамматическую информацию, грамматика здесь выступает как составная часть семантики. То есть, семантика абстрактного понятия, абстрактного уровня включают в себя частные семантики. Семантика парагматическая – это объекты и сущности, концепты, а семантика грамматическая – это, собственно, структура языка. Мы можем из этой распределенного представления получить некоторую грамматику. формальную ее верифицировать, а дальше мы можем, возможно, дополнить эту грамматику и загрузить ее в соответствующую нейросеть для того, чтобы дальше уже эту нейросеть дообучать и совершать с ней то, что называется inference уже стандартными средствами. Соответственно, вот стрелочка налево говорит про explainability, или объяснение, или про интерпретируемость нейросетевой модели, представлением её семантическом виде. А transfer обозначает transfer learning, то есть передачу знаний в нейросеть. Да, но мы можем на самом деле из одной нейросети выгрузить и в другую передать. как, собственно, и работает человеческий мозг. То есть, для того, чтобы передать данные из одной человеческой нейросетки в другую, мы извлекаем данные, семантическое представление, либо в виде графа, либо в виде таблицы, либо в виде слов, а потом загружаем это в нейросетку другого человека. Ну вот пример того, как я уже про это рассказал, как устроены семантические графы в грамматике связей. Вот как устроено это в нашей собственной нечетко символьной модели описания естественного языка. Ну вот, собственно, иллюстрация ответа на вопрос Андрея. и расшифровка тезиса того, что все есть граф и все есть предикат. Следующая концепция. Мы все можем сказать, что у нас все есть граф. В нижнем слое у нас есть неявное знание или то, что называется subsymbolic knowledge. И это так называемая система 1 Канемана. Система медленного обучения и быстрого вывода. То есть, инференс быстрый, а трейн очень медленный. И это то, про что Канеман с точки зрения психологии, когнитивной психологии, нейрофизиологии как раз описывает как систему быстрого человеческого мышления. А наверху у нас... Антон, презентации нету. 


S09 [00:40:13]  : Сейчас я тогда переключусь обратно на слайды. Где у меня онтология? Соответственно, внизу у нас система один канемана, система медленного обучения и быстрого принятия решений или быстрого вывода. И система неинтерпретируемая. Это наша интуиция. Что-то мы решили, быстро решили, быстро что-то сделали, почему сами не поняли. А наверху у нас явное знание или символиное знание. То есть, это знание, о котором мы знаем, что мы это знаем. И мы знаем, что мы это знаем, потому что мы это выражаем слова. То есть мы знаем, что моё это май, что я это ай, что мы это ви, и я знаю, что стоит за этими словами. А раз я знаю, что стоит за этими словами, я знаю, что я это знаю. И это тоже может быть описано графом, в том числе это может быть описано нечётким графом, то есть связи между этими словами или концептами, или именованными сущностями, или именованными вершинами, они тоже могут быть нечёткими. от какого-то концепта или от какой-то сущности отношение к другой может быть более или менее выраженным в моей системе веры, в моей онтологии, в моей собственной belief system. Но что важно, что имеет место граундинг одного к другому. То есть у нас с одной стороны имеет место граундинг вот этих символов на некоторые распределенные векторные представления. связанное с некоторыми мутными ассоциациями, движениями моего тела, какими-то запахами, какими-то тактильными ощущениями. И это всё связывается с какими-то символами в той или иной степени. Ну и, с другой стороны, вот эти все неявные интуитивные ощущения, они тоже как-то связаны с какими-то словами. То есть у нас есть взаимосвязь между вот этим явным знанием И вот этим вот неявным знанием. И обучение, где под обучением в общем смысле мы подразумеваем некоторое получение нового знания. о том, как вести себя в окружающем мире. Оно может происходить с двух сторон. С одной стороны, у нас есть опытный experiential grounding, то есть grounding, основанный на собственном опыте активного действия или тактильного поведения, когда мы получаем некоторое взаимодействие с окружающим миром. Накапливаем их методом распространения ошибки или того, что в человеческой голове имеет место быть вместо обратного распространения ошибки. Тут тоже имеет место отдельная дискуссия из области. Но вот эти вот неявные интуитивные знания, они могут подвергаться концептуализации. То есть, мы можем пытаться нащупывать, и мы это делаем, как вот эти новые отношения между новыми нечёткими сущностями, которые мы выучим в процессе взаимодействия с окружающим миром, как они соотносятся с конкретными понятиями в нашем языке. и в тех концептах, с помощью которого мы осознанно пытаемся описать окружающую действительность для окружающих с помощью языка и для самих себя, в том числе с помощью внутреннего языка. Это вот восходящий процесс обучения на собственном опыте и концептуализации. Но с другой стороны, у нас есть встречный процесс, когда нам сообщают какую-то информацию концептуально. То есть, прежде чем мы съели каку на улице, нам мама говорит «не ешь каку». Еще раз мы встретили эту каку на улице, тоже к ней потянулись, мама говорит «не ешь каку». И если мама нам несколько раз сказала «не ешь каку» на уровне слов, то постепенно повторение вот этого «не ешь каку» через автоматизацию, я не смог подобрать обратного слова, концептуализации, когда некоторые концепты превращаются в некоторые имплицитные или неявные интуитивные схемы – это обратный процесс. То есть мы вот это символьное знание каким-то образом тоже можем загружать в свои ассоциативные сети, с помощью которых мы осуществляем автоматическую и активную, но бессознательную деятельность. Это, собственно, вся вводная часть. Поэтому, если есть желание, то… Давайте я сейчас по вопросам пробегусь, и потом Так, не нужно, интересно, иметь альтернативы. Точность задачи инструкции. Криадобанк, поясните ваши вопросы про проблему капитан очевидность, точность задачи инструкции. 

S02 [00:45:20]  : Добрый день, меня слышно? Да-да. Значит так, это еще одни соображения по поводу LLM. Например, что было бы интересно иметь альтернативу, которая не LLM, а как-то по-другому работает. Это всегда интересно для информатики. Так вот, какая еще критика LLM, с моей точки зрения? Это невозможно задать абсолютно точно, что ты хочешь, чтобы нейросеть сгенерировала. Это вообще касается нейросетей. Та же самая проблема, что для нейросети с картинками. Например, трудно, если... Я, например, сейчас как хобби занимаюсь, например, разработкой игры. И вот мои попытки сделать персонаж, да, чтобы один и тот же персонаж был на разных картинках, в разных, как бы, позах, очень... не очень хорошо работает, потому что она постоянно рисует кого-то другого персонажа на другие детали. И вот это к тому, что если мы вообще... вообще я как бы начал считать, что если мы задаем инструкции естественным языком, то тогда инструкции как бы неточные. И нейросеть сама чего выдумывает к постановке задачи и выдает ответ, какой попало, так сказать. И второе, проблема капитана очевидность, то есть она выдаёт наиболее очевидный ответ, который не даёт вам ничего полезного. В этом случае я смотрю механизм онтологии как средство, то есть встраивание какого-то прорывного мышления, которое генерирует инновации. Потому что нейросеть это, судя по всему, не делает. Она просто делает интерполяцию того, что у неё есть. Спасибо. 

S04 [00:47:03]  : Но это не все нейросети в зависимости от архитектуры. 

S02 [00:47:09]  : Ну, ладно. 

S04 [00:47:12]  : Есть даже нейромашины Тюринга с постоянной памятью и так далее. 

S02 [00:47:19]  : Это не нейросеть? Вы кроме нейросети еще дополнительно что-то встроили? 

S04 [00:47:23]  : Нет. 

S02 [00:47:24]  : Дело в том, что сами нейросети. Нет, но не все это нейросети Тюринга. 

S04 [00:47:29]  : Да, поэтому здесь тогда нужно ограничиться каким-то классом нейросетей. Но это потом. Сам тезис понятен. 

S09 [00:47:41]  : Окей, спасибо. Егор? 

S10 [00:47:45]  : Да, у меня, Антон, был вопрос по последнему слайду. Интересный момент с граундингом. Там две системы Канемана, первая и вторая. Но там же Канеман обращается к более подсознательным вещам, которые быстрые, потому что они избегают рефлексии медленно человеческой. А как вы тут предполагали, что же может быть experiential? Какой experience? Модели, которые обучены на одном и том же тексте, только там одни на символах, грубо говоря, другие на производных графах, наверное, не тянут на слишком разные системы. В чем же граундинг? Куда граундиться быть? 

S09 [00:48:37]  : Ну, под граундингом я на самом деле, может быть, я использую термин «граундинг» слишком свободно, Под граундингом я подразумеваю привязку концептов или, скажем так, структур, которые участвуют в когнитивном процессе более высокого или более абстрактного уровня, к структурам более низкого уровня. То есть, или, может быть, даже сказать более вовсе, структур одного уровня, да, не обязательно более, потому что где более высокий, где более низкий, значит, тоже можно подискутировать. В общем, структура одного уровня к структурам другого уровня. То есть, допустим, если у нас есть некоторый свободный текст LLM, Если мы хотим его привязать к некоторым конкретным задачам, допустим, получения цены или получения волатильности конкретного токена, то мы привязываем этот текст к результатам исполнения конкретной заземляющей функции или grounding function. в системе OpenCog для этого есть понятие grounding predicate node то есть у них вот этот вот мета-онтология и онтология значит там тоже у них значит это вот уже как бы продолжение дискуссии значит есть концепция того что все сверху до низу описывается одной одним метаграфом от более высокого низкого до более узкого уровня и вот есть определенная типы. Вот предикат. Все есть предикат в этом спейсе. И вот есть особый тип предикатов, который называется Grounded Predicate Node. То есть это те предикаты, которые возвращают конкретное значение истинности, зависимости от тех аргументов, которые к ним привязаны. То есть если мы этот предикат связываем там биткоин, связывает биткоин с текущей датой, то значение будет одно, а если PDK связывают эфириум с другой датой, то значение будет другое, к примеру. Это вот один процесс. С другой стороны, под граундингом, на той последней картинке я подразумеваю связь некоторых абстрактных понятий, допустим, слов. или картинок, иконок или иероглифов с конкретными действиями или событиями, где действие или событие или какой-то образ с точки зрения восприятия или с точки зрения того, как он отпечатывался в эпизодической памяти конкретного человека или искусственного агента, Он описывается в распределённом векторном пространстве всех его ассоциаций. То есть, кошка – это комбинация запахов, комбинация тактильных ощущений, комбинация всех мяуканий, всех кошек, которые я когда-нибудь видел. Это всё большое количество нейронных кластеров, которые в своё время были возбуждены и запомнили свои состояние возбужденности. И все это собирается для меня к этому векторному пространству различных ассоциаций в конкретный символ конкретной кошки. То есть есть ког кошка, который основан на большом количестве точек по различным осям многомерного векторного пространства так вот связь вот этой вот сказать абстрактной кошки значит привязка его вот как ко всем этим осям в этом векторном пространстве вот я тоже пытаюсь назвать может быть слишком свободно называю grounding может быть это неудачный термин немножко продолжить или 

S10 [00:52:24]  : На другую тему перескочим. 

S09 [00:52:26]  : Я не знаю, у нас все высказались? Есть еще какие-то вопросы или мысли на эту тему? 

S04 [00:52:34]  : Я бы с точки зрения вычислительности дополнил и одновременно спросил про граундинг с точки зрения соответствия некоторой модели, которая существует в реальном мире. Почему? Потому что я очень часто это воспринимаю с точки зрения внедрения через цифрового двойника. И, соответственно, мне важно, чтобы Digital Twin был именно Twin'ом. Поэтому для меня граундинг, в первую очередь, это оно. Но получается, что у нас граундинг уже получил четыре основных инкарнации. Кстати, инкарнация — это один из лучших противопоставлений концептуализации. в смысле обратного оператора, потому что у класса, как у примера концепта, есть инстанциация, а в целом в концептуализации есть инкарнация. Вдруг пригодится. И, соответственно, у граундинга, в моем понимании, главное это все-таки то, что есть схема валидации. А вы сейчас рассказывали очень интересный кусок, который я, в принципе, не представляю, как вычислительно валидировать. Не могли бы отметить что-нибудь на тему попыток этого вычисления? 

S09 [00:53:41]  : Смотрите. Два очень хороших момента. Не забудьте убежать в разные стороны. Во-первых, двух уровней. Буквально на днях обсуждалась история про large concept model. где описывается подход, основанный на двух уровнях, на двух сетках. Одна сетка генерирует трансформеры, которые позволяют строить распределенные векторные представления или имбединги. А вторая сетка уже на этих имбеддингах осуществляет, это тоже трансформер на имбеддингах, который уже на высоком концептуальном уровне делает свои предсказания следующего концепта. То есть он предсказывает не следующий токен, а он предсказывает следующий имбеддинг, где имбеддинг соответствует концепту. И вот как бы эта архитектура Large Concept Model в той статье, которая проходила несколько дней назад, выступает в качестве следующего поколения, того, что приведет нас к HDI. Это одна история. Вторая история – это история как раз про валидацию. Я тут сегодня говорил, и раньше тоже на эту тему говорил, что чем хороша интерпретируемость символьных моделей, тем, что мы можем верифицировать истинность этого знания. И аргумент, который против этого часто предлагался – это то, что, окей, если у нас передикатов 5, Да, там мама мыла раму, и мама не могла есть раму, да, соответственно, вот мы легко можем доказать все множество операций, которые мама может совершить к маму, имея антологию... Это не педикаты ни в одном глазу, они же не истинностное утверждение. Но я имею в виду тезис такой, что если у нас этих предикатов станет 5 миллиардов, если мы начнем оперировать с количеством предикатов в соответствующем количестве коэффициентов большой языковой модели, то мы все равно ничего не сможем доказать. Буквально на днях была работа, я ссылку в группу EGRussia скидывал, появилась работа, что ребята как раз занимаются математической формализацией истинности данных, находящихся в нейронной сети. Я туда не успел провалиться, но такая работа есть. Можно просто рассматривать множество… По-моему, здесь Андрей Ковтуненко присутствует. По-моему, с ним мы спорили недавно, можно ли считать, что нейронная сеть является формулой. Я по-прежнему не согласен, что нейронную сеть можно описать одной формулой, но я согласен с тем, что ее можно описать множеством формул или системой уравнений. И если мы можем описать нейронную сеть, систему уравнений, сколько угодно сложности, то, имея достаточно вычислительной мощности, мы можем провести аналитические исследования вот этой системы уравнений на непротиворечивость некоторой или на соответствие некоторой внешней функции, которую мы на это наложим. Это ещё одна мысль. И, наконец, отвечая на вопрос про доказуемость, в моём понимании всё-таки научный метод – это практика критерий истинности. И по этому поводу… Опять-таки, здесь присутствует Евгений Гениевич Витяев, который автор вычислительного метода и системы искусственного интеллекта на основе теории функциональных систем, где утверждается то, что система в любом случае, когда принимает какое-то решение, она переходит в состояние подтверждение либо опровержение адекватности этого решения, и получая обратную связь, в зависимости от того, осуществляется ли подтверждение ожидания или происходит опровержение того, что ожидалось, система меняет свое поведение для следующей итерации. Вот эта прямая обратная связь, даже если конкретно расшифровать, как я к этому отношусь с точки зрения этой картинки, которую я показывал в контексте ответа на заданный вопрос. Например, как можно рассматривать гипотетическую идеальную архитектуру? Допустим, если я получаю знания из своего непосредственного опыта и концептуализирую их. Это история с концептуализацией на основе собственного жизненного опыта. Но если я понимаю некоторую дидактическую информацию, то есть если я получаю информацию от мамы, что там не ешь каку, то все-таки эта информация, она в конечном итоге во многих случаях требует подкрепления. То есть либо подкрепление в той информе, что я не съел каку, и мне хорошо, я дожил до конца дня, не испытывал никаких неприятных ощущений, либо если я не послушался к маму и все-таки эту каку съел, то я получаю дополнительное подкрепление того, что маму надо все-таки слушаться. Или если мне мама говорила, вот сделай утром зарядку, и у тебя будет весь день бодрое и хорошее настроение, я послушался маму, и у меня действительно было весь день бодрое настроение, опять-таки я получаю положительное подкрепление, то есть по результату положительной обратной связи на предсказанное и выполненное действие. То есть вот эта вот инкарнация, в моем понимании, она для дополнительного закрепления вот этого дидактического или как бы внешне. То есть, на самом деле, наверное, граунинг здесь неправильный. Это я уж как бы тут, наверное, нафантазировал, что с двух сторон граунинг приходит. Наверное, граунинг все-таки должен приходить снизу, должен подходить через именно подкрепление, либо через в качестве исходной информации. либо в качестве акцептора результата действия, а то, что к нам сверху приходит, это вот просто некоторая директивная информация, которая требует еще граундинга на основе собственного опыта. 

S04 [01:00:41]  : Тогда сразу понятно, потому что получается, что здесь на 99% граундинг – это вознаграждение. 

S09 [01:00:49]  : да и здесь можно подискутировать либо это вознаграждать то есть либо это все-таки просто опыт То есть, либо это действительно вознаграждение за какое-то действие, либо это вознаграждение за правильно угаданное действие. То есть, у нас важным является то, что даже если я ничего не делаю, а просто ожидаю чего-то, что оно произойдет, то есть выстраиваю некоторую предсказательную цепочку и ожидаю, что произойдет что-то, и оно действительно происходит, то У меня всё равно, по идее, срабатывает акцептор результата действия, я получаю подкрепление за то, что я правильно это предсказал. И я мысленно, осознанно или неосознанно глажу себя по головке, говорю, вот молодец, всё правильно предсказал, в следующий раз доверяй своему внутреннему чувству, как ты думаешь, так оно и будет. 

S10 [01:01:56]  : «Граундинг» – это не очень верное слово. Я эту тему несколько лет назад пропахивал. «Граундинг» – это про то, как соотносить символ с некоторой физической моделью. В более сложных доменах, таких как антологизация права, есть прототипическая семантика. То, что вы описали с непосредственным опытом, там сложнее, потому что там чрезвычайно абстрактное понятие. И вот там другие подходы к граундингу. Есть сенсорно-моторный граундинг. который близок к этому. Но это опять же вопрос, как связать абстрактную часть с более конкретной, и это обсуждается в разных очередях. Можно свести к проблемам бытия и сознания. Шаллаберс говорит про супервентность, но это все одно и то же. У вас была тема с интерпретационностью, с претируемостью символа. 

S04 [01:03:06]  : Нет. Объективность отдельно. А здесь же очень четко разделил часть, которая говорит о том, что у нас одна формальная модель на другую каким-то образом накладывается. Отдельно, что из первых принципов мы нормально получаем то самое заграундирование, задемление. то, что их много, я как раз очень согласен. да, в разных областях это заявление с точки зрения других принципов может быть произвольным. главное, что это не из такого же рода модели другого типа сделано. или есть примеры, когда это не так? это, кстати, интересный вопрос. 

S10 [01:03:48]  : из модели другого типа? да, потому что все примеры... вот сенсор на моторной grounding. Там берут робота, пускают его в какую-то среду и потом связывают это с какими-то паттернами. 

S04 [01:04:04]  : То, что вознаграждение, которое приходит прямо из реальной среды. 

S10 [01:04:13]  : Но там получаются только очень несложные концепты пока. потому что роботы ограничены именно в своей сенсорно-моторной реальности. Но и там проблем хватает. Вопрос о движении между этими уровнями очень интересный. Когда я говорю про внимание, это про то, как двигаться между этими уровнями. 

S09 [01:04:49]  : На самом деле, если использовать термины более высокого уровня и докрывать всё большим зонтиком, наверное, единственно правильный термин – это ассоциирование. И ассоциирование сигналов или концептов одной модальности с сигналами или концептами другой модальности – это ассоциирование разных модальностей. Ассоциирование низкоуровневых сигналов. или концептов, или понятий с более высокоуровнями – это ассоциирование, grounding. Наверное, все-таки слово «ассоциирование» здесь более правильное в качестве широкого термина. 

S10 [01:05:33]  : Я скажу, что здесь не очень правильно, потому что ассоциация… Мы можем говорить только, когда мы рефлексируем эти две системы. Вот они у нас где-то сделаны, потом мы их отрефлексировали, положили их, как у вас на слайде, на одну плоскость, и тогда начинаем их связывать, ассоциировать. Но в реализации это две разные системы, и отношения между ними совершенно разные в зависимости от реализации. что он может быть интерпретирован исполняющей системой. Здесь две системы, одна более абстрактная, вторая менее абстрактная, но на самом деле эта абстрактность нам ближе к интерпретации. Так или иначе, вы говорили именно про это, на мой взгляд. В VGI, наверное, это особенно проявляется. 

S09 [01:06:27]  : Я когда говорю про граундинг или про ассоциирование, я имею ввиду установление некоторой физической связи. Под интерпретируемостью мы же не подразумеваем создание физической связи. 

S10 [01:06:45]  : У вас прохождение сигнала все равно должно быть снизу вверх или сверху вниз. разбирать на самом деле более подробно. 

S09 [01:06:54]  : Да, тут возникают уже терминологические нюансы. Андрей, вы руку подняли? 

S03 [01:07:01]  : Да, у меня два таких простых наивных вопроса. Вот первый вопрос заключается в том, что если у нас случается, если говорить об интерпретируемости системы построенной, как вот вы продвигаете на lingrammar и при том с нечетким выводом, да? Ну, нечеткий вывод, получается, у нас построен на каких-то коэффициентах, о которых мы там поговорили, да? И, получается, верификация тоже будет какая-то нечеткая, так? 

S09 [01:07:36]  : Смотрите, что мы имеем в случае нечеткости линграммер, конкретно. То есть, мы имеем возможность на некоторый вход построить некоторое количество деревьев. Допустим, если мы с помощью Lingram разбираем некоторый текст и хотим выставить его грамматическую структуру, установить связи между токенами или назначить грамматические категории, связи между словами и семантические и грамматические роли этим словам, то мы можем построить множество деревьев. И нам нужно понять, какие деревья являются более правильными. И у нас возникает ситуация, что более сложные деревья – это более неправильное. То есть мы всегда постараемся построить более простое дерево. Но дальше возникают ситуации неоднозначности. У нас может возникнуть, что на одни и те же слова мы можем построить несколько деревьев. И вот тут возникает уже необходимость считать пресловутые косты. Возникает потребность найти то дерево, которое является более дешевым. А дешевизна дерева в терминах этой самой больших языковых моделей, она характеризуется минимизацией энтропии. То есть то дерево, которое имеет с точки зрения большой языковой модели меньшую энтропию, оно имеет соответственно более низкую стоимость. Есть вопрос в том, что эти коэффициенты, позволяющие минимизировать энтропию и максимизировать вероятность предсказания следующего токена в языковой модели, подбираются в результате backpropagation. А в Lingramary они подбираются вручную. И не существует механизма получить эти косты автоматически. То есть, у нас был такой предмет. Мы этим занимались. Более того, мы занимались этим разными способами. В том числе пытались извлекать эти коэффициенты из больших языковых моделей. Но потом, к сожалению, на проекте кончились деньги. 

S03 [01:10:10]  : Исследования прекратили. Даже если бы это получилось, получается у нас есть какие-то деревья, их набор там какой-то мега огромный, ну и от этого, мне кажется, страдает интерпретируемость в принципе вот в плане вычислительного ресурса. Вот допустим, ну да, мы как бы Задним числом, когда, допустим, наша модель выполняет какую-то полезную работу, можем проинтерпретировать, что она сделала. Почему она это сделала в моменте, мы это проинтерпретировать чисто вычислительно, мне кажется, не сможем. Это первый вопрос был. А вот второй вопрос касательно TLCM, то есть Large Concept Models. Смотрите, как вы сказали, получается у нас уже идёт трансформер уже на эмбэдингах, я так понимаю, да? А сами эмбэдинги, они в принципе как бы не то чтобы интерпретируемы, да? И получается, ну, как, что я хочу сказать, то что эмбэдинг это уже получается в словах невыразим, а он только потом с инференсом куда-то на какое-то там, не знаю, токенное пространство приземлиться, вроде понимаемое для нас. И вот плюс LCM в чем, как мне кажется, это вот в радикальном сокращении вычислительного ресурса. А как это будет выглядеть на Lingram? Как будет вот этот embedding, который LCM не выразим в словах. То есть мы получаем LCM, который у нас будет по производительности намного лучше, но мы при этом хотим интерпретируемость. А как вот аналог вот такого вывода на эмбейдингах будет в link-граммар? То есть там это что-то будет какое-то словесное что-то там непонятное или что как-то будет концепт, вот именно концепт выглядеть. 

S09 [01:12:15]  : Смотрите, ответ на первый вопрос достаточно простой. Естественно, для того, чтобы проинтерпретировать сам процесс вывода, наверное, потребуется решительных ресурсов не меньше, чем сам вывод. Наверное, это практически нецелесообразно. В данном случае интерпретированность предполагает то, что сама модель является интерпретируемой. То есть, мы можем посмотреть на грамматические правила и увидеть, что у нас там нет какой-то ерунды, у нас там нет какого-то мусора, что там какие-то существительные затесались в глаголы, а какие-то глаголы затесались в существительные. Вот под интерпретируемостью я подразумеваю, прежде всего, что сама модель может быть исследована на адекватность. То есть, в нее можно ткнуться пальцем, посмотреть, а вот это слово действительно соответствует всем образом кошек или там затесались какие-то собаки. На второй вопрос. Готового ответа нет. Очевидно, что когда мы переводим из этого векторного представления с одной стороны в высокоуровневое символиное представление, мы какую-то информацию должны потерять. Более того, существует некоторый прунинг. Вот, это раз. Второе, значит, очевидно, что тот же самый линграммар в чистом виде, он совершенно непригоден практически, потому что у нас определенное... Нам для того, чтобы сгенерировать правильное выражение, недостаточно грамматических правил. Нам еще нужен тот самый контекст, которая дается трансформерам. То есть, на самом деле, для того, чтобы отбирать из множества деревьев, которые мы можем построить на некотором наборе слов, допустим, cat – кошка, мышка – бежать. Вот у нас есть три слова. Вот у нас структура грамматических связей между кошкой, мышкой и бегом зависит от того, кто является жертвой, а кто является преследователем. В зависимости от контекста, кто за кем бежит, у нас будут разные грамматические структуры, и в разном порядке мы эти слова будем соединять. В трансформерах как раз этот контекст есть. Проблема контекста в линграмере не соединена, и здесь как раз возникает необходимость некоторых дополнительных надстроек. над символьными структурами, но при этом все равно интерпретируемость предполагает, что те элементы, из которых мы эти структуры строим, они могут быть интерпретированы. То есть у нас, грубо говоря, в модели должно быть понятие подлежащее, сказуемое, глагол, приставка, суффикс, которые мы можем верифицировать на предмет валидности. Ну, не обязательно. У нас должна быть такая возможность, если мы хотим, допустим, внедрять эту систему в какой-то, условно говоря, в задачах критической инфраструктуры, где мы хотим гарантированно валидировать адекватность самой модели до того, как эта модель начнет что-то генерить, что нам потом придется задним числом интерпретировать. 

S04 [01:15:54]  : Можно маленькое замечание. Дело в том, что коллеги, которые ближе находятся намного к авторам LCM. Кстати, LCM уже с точки зрения сокращений к минимуму 10 штук, даже в нашей области. Они очень не рады тому, что там пока вообще нет ничего с точки зрения учета напрямую нарративных связей. Дело в том, что у нас же очень эффективные есть алгоритмы построения базовых нарративных связей в тексте, и уже были модельки, которые их использовали. И народ удивлен, что это не объединено. И очень хотят сейчас это объединить. Почему? Потому что у нас есть же дискурсивные связи четырёх типов. Они давно используются. Очень хорошо работают на практике. Индустрия их очень любит. Вот. И есть более сложные нарративные связи. А там они просто их теряют. И народ как раз там сейчас это очень активно обсуждает. Единственное, что никакой статьи ещё по этому поводу не было. А очень хочется. Спасибо. 

S09 [01:16:49]  : Спасибо. Владимир, вы что-то хотели сказать? 

S05 [01:16:58]  : Я в некотором сомнении. Вы со своей религией собрались о том, что семантические сети и больше ничего не нужны. И я вполне понимаю, что критерий истинности ваш состоит в том, что то, что вы рассказываете, можно продать менеджерам. А если менеджерам продать можно, то это и есть то, что нужно. Это центральный посыл, против которого я не могу возразить. А так, если брать теоретического взгляда, мягко говоря, про все я могу рассказывать, что это не так. Ну, не уверен, что вам это интересно. Я могу там несколько пунктов назвать, которые меня особо удивляют. Но если хотите. Если не хотите, я не хочу портить вашу идею. Почему? 

S09 [01:17:42]  : Раз уж вы взяли слово, то расскажите. 

S05 [01:17:44]  : Ну, во-первых, вот, собственно, все семантические и прочие схемы и графы Они так или иначе направлены на попытку создать универсальную таблицу описания всех возможностей. Даже если брать настольные игры, то для них не существует универсального пути, если брать крестики-нолики на поле 3х3. то уже шахматы, не говоря уже про ГОА, там вот такой универсальной таблицы, как выиграть, нет. Подождите, подождите. Альфа-0, она ничего не решила, то есть она вот эту универсальную таблицу не создает. Но есть способы, попадая каждый раз в новую ситуацию, строить новые пути, которые приводят к достаточно разумным результатам. То есть, в принципе, мифологический недостаток всего, о чем мы говорили, состоит в том, что вроде бы есть некоторая абсолютная истина, к которой надо стремиться, и идти по тому, что даже ее можно достичь. Я не против того, что надо стремиться к истине, но, во-первых, все истины, они относительные, и абсолютную истину достичь никогда не удастся, просто потому, что это недостижимый идеал. А, собственно, для того, чтобы решать конкретные задачи, нужно уметь быстро получать знания под новые условия. То есть появилась какая-то новая ситуация, которой никогда не было. А наша вся жизнь состоит из таких ситуаций, которых никогда не было. И, соответственно, получать под эту ситуацию новые знания и их использовать. Второй противоречий, который вы говорите, о том, что все эти дискретные словесные модели, они хорошо интерпретируемы. А нейронные сети, они плохо интерпретируемы. Они как раз позволяют получить знания, но нет их интерпретируемости. А здесь сложно получать новые знания для систематических графов. Но зато они хорошо интерпретируются. Но проблема не в том, что... Что? 

S02 [01:19:46]  : Почему сложно получать новые знания для семантических графов? 

S05 [01:19:52]  : Ну как вам сказать? 

S02 [01:19:54]  : Ну смотрите, возможно некое решение, которое будет просто читать текст, переводить его в семантический вид и помещать его в семантический граф. 

S05 [01:20:06]  : Это будет быстрее и легче, чем помещать. Вот. А калькулятор, он сразу дал новые знания. Он получает новые знания. Понимаете? 

S02 [01:20:13]  : Но... Калькуля... Ну... Это не новые знания, что ли? 

S05 [01:20:18]  : Вот и я про то, что это не новые знания. И те знания, которые вы получаете в семантических сетях, они тоже не новые. 

S02 [01:20:23]  : Так, а семантические сети не работают, как калькулятор? Во-первых, у меня есть вопрос по вашему... Я могу найти 10 отличий, я не спорю. У меня, во-первых, есть вопрос, что вы имели в виду под универсальными таблицами и почему они есть или должны быть в семантическом графе? 

S05 [01:20:39]  : Я утверждаю, что универсальные таблицы невозможны. 

S02 [01:20:42]  : Нет, во-первых, объясните, что это такое, а во-вторых, почему вы думаете, что они должны быть в семантическом графе? Поскольку я потом скажу, что я представляю под семантическим графом. 

S05 [01:20:55]  : Ну да, это будет интересно послушать. Вот, собственно, я хотел сказать про другое. 

S02 [01:21:00]  : Нет, скажите что-то, что такое универсальная таблица. 

S05 [01:21:03]  : Послушайте, вы когда будете рассказывать, я вас послушаю, я с удовольствием. Я же не против того, чтобы вы говорили. Но дайте я расскажу, что я хочу. А вы бы расскажите о том, что вы хотите. 

S09 [01:21:12]  : Хорошо, Владимир, вам задали вопрос. Вы начали с универсальной таблицы. Что вы подразумеваете под универсальной таблицей? 

S05 [01:21:20]  : Я понимаю, что это некоторый объект, который не может быть построен. Это некоторая волшебная палочка, которая в природе не существует. Вот, скажем так. 

S09 [01:21:29]  : Это понятно? Нет, не понятно. То есть, вы говорите, что это невозможно, но не говорите, что невозможно. То есть, что конкретно не может быть построено? 

S05 [01:21:37]  : Сколько бы вы не находили правил, найдете бы их миллиард, триллион, пентиллион. Но этих правил будет недостаточно для объяснения рационального поведения в любой ситуации. Чем больше вы построите правил, тем в больших случаях они сработают. Но для всех ситуаций вы никогда не построите универсальную систему правил. Вот простое утверждение. Вот и все. 

S02 [01:22:00]  : Но это такое немного голословное утверждение, которое стучат в себя очень общие понятия для всех. Хорошо, Владимир, вы объясните. 

S12 [01:22:06]  : Я совершенно про другое. 

S05 [01:22:16]  : Вот тут мне однократно было сказано, что у семантических графов всё понятно, а в нейросетях ничего не понятно. Дайте поговорить, а потом поговорите, я помолчу, вы поговорите. 

S09 [01:22:28]  : Сейчас, коллеги, коллеги, Владимир, давайте так, Владимир, значит, давайте вы сказали... Вопрос к Владимиру, можно? Владимир ответил на вопрос, что такое универсальная таблица и объяснил, почему ее нельзя построить. Владимир, закончите ваш тезис и двинемся дальше. И будет вопрос. 

S05 [01:22:50]  : Пожалуйста. Я много тезисов рассказывать не буду. Я расскажу один простой тезис, который может быть вам послужит. Закончите, пожалуйста, ваш тезис. Смысл стоит в том, что поскольку в современных нейросетях декомпозиция сложных сигналов осуществляется неявно, то понять, что там происходит, сложно. А в графических, семантических сетях, там декомпозиция осуществляется явно. И, соответственно, там все просто понятно. Именно поэтому, а не потому, что там правила грамматика, а там этих правил нет. Если мы в нейронных сетях осуществим декомпозицию явно на простые объекты и сможем приписывать, то можно с каждым простым объектом легко понять, что происходит. Потому что простые объекты, особенно если это одна переменная, строим график и получаем полное представление. Там 2, 3, 4 переменные, еще что-то можно понять. Если там уже больше 10 переменных, все, понять нельзя. И если вы словами что-то пытаетесь про 10 переменных описать, то там тоже ничего не будет понятно. Вот разница именно в том, что явная декомпозиция, которая есть в семантических графах, она позволяет хорошо понять. Если явную декомпозицию осуществлять в нервных сетях, то они, во-первых, будут быстро обучаться, поскольку эти простые объекты достаточно легко статистически достоверно выявить их свойства. Ну а второе, что их можно будет понять. Поэтому это противоречие, оно не, скажем так, не принципиально, оно в принципе преодолимо. Просто в этом движении пока что менеджерам не удается объяснить, что надо делать. Ну вот и вся разница. Пожалуйста, я вас слушаю. 

S02 [01:24:24]  : А я хочу спросить, чем вы занимаетесь в этой области? У вас есть какая-то своя деятельность? Можете немного рассказать? Вы занимались нейросетями или символьными решениями? 

S05 [01:24:38]  : Нет, я больше занимаюсь нейросетями. Символные решения. Не то, что я их игнорирую, но я не считаю их... Тут было сказано, что что-то есть полезное, что-то вредное. И нейросети полезны, и символиные решения есть полезные, и калькуляторы полезны, и, допустим, книги полезны. И то, что лошадей в свое время приручили, это тоже было очень полезно для развития науки. 

S02 [01:25:01]  : Возможно, понимаете, человек, который не занимается чем-то, у него могут быть, извините меня, неполные представления, что это собой представляет. 

S05 [01:25:08]  : Ну, значит, в отличие от вас, я еще занимаюсь системным образом, поэтому у меня более широкие представления. 

S09 [01:25:13]  : Владимир, коллеги, значит, у Владимира у нас есть много семинаров, значит, можно их найти и посмотреть, чем занимается Владимир. Давайте, значит, двинемся дальше. Давайте сейчас еще пройдем, какие вопросы были. Про однозначную трактовку. В какой системе исчисления мы будем формализовывать? Ким Артамонов. В какой системе исчисления мы будем формализовывать? Что будет фундамент? Метамоделью описания. Ну, значит, и вот дальше здесь вопрос, про единой кошки не существует. Да, вот здесь вот смотрите, значит, мое видение ответа на этот вопрос. То есть, у нас, не знаю, кто видел, кто нет, недавно было обсуждение того, значит, как связаны язык и мышление, да? может ли быть мышление без языка, может быть язык без мышления, или это две неразрывно связанные сущности. Моё понимание следующее, что формализация, она предполагает описание чего-то в некоторых осознаваемых символах, которые мы можем передать куда то. То есть формализация подразумевает, что мы формально описали кошку, сказав, что кошка это живое существо, у которого есть четыре лапы, хвост, треугольные уши и которое мяукает. И мы это выразили в конкретные слова, понятные другим участникам коммуникации. 

S06 [01:26:58]  : Понятно и кому. Антон, извините, я не знаю, как у вас по отчеству. Скажите, как у вас по отчеству. Антон Герванович. Антон Герванович. Вы просто, когда говорите про кошку, понятно, пример хороший. У нас коллега сказал про свой кейс, описание того, чтобы повторялось воспроизводство персонажа. Об этом мы и говорим. Вы когда начнёте описывать, вот кошка, я понял так, он понял так, когда мы говорим, что есть какое-то формальное описание, мы предполагаем, что есть какой-то идейный способ описания, во-первых, того, что кошка, она всегда одинаковая, что всё сводится, что она даже у нас на доформальном уровне. Она у нас одна-единственная, что это не какое-то множество кошек. Второе – это о том, что у нас есть какая-то метамодель, какой-то формат описания кошки, который понятен и человеку, что эти две метамодели – это одна и та же метамодель, между ними не надо делать преобразований. Ну и про то, что формальность – это если мы говорим про доязыковой уровень, постязыковой уровень, то есть формальность – Я вспомнил тут Левенчука. Это шкала формальности. Она не единая, она не линейная. У нас поскольку нет одной кошки, поэтому и приведите. Мы не можем ее двигаться вправо. Я вот здесь с Анатолием Игоревичем не согласен. о том, что это не только не шкала, но это еще шкала, разбитая в спектр. Поэтому тут вот этот вопрос сам по себе, я не стал тут много разговаривать, брать слово, потому что слишком много всего можно сказать, но в смысле фундаментально здесь есть вообще, на мой взгляд, кардинальные проблемы с такой даже постановкой идеи. 

S09 [01:28:37]  : Смотрите, как я к этому отношусь. В любой команде работающие над минимально сложным проектом, требующим работы по некоторым общим спецификациям, которые, как понятным и продукт-тонерам, и архитекторам, и разработчикам, и тестировщикам, предполагается, что виджет все понимают одинаково, гаджет все понимают одинаково, Протокол все понимают одинаково, и терминологическая таблица – это неотъемлемая часть любого документа – архитектурного, технического, ТЗ, где одни термины описываются в терминах других терминов. И вот это вот как раз описание одних терминах в других терминах формирует замкнутую онтологию, описывающую конкретную предметную деятельность, например, разработка конкретного продукта. Вы не сможете обеспечить взаимодействие продуктовнеров, аналитиков, разработчиков, тестировщиков, продажников, не имея общего языка для описания одного продукта. 

S06 [01:30:01]  : Да, я вам об этом и говорю, о том, что вы можете это дефинировать и определить в рамках команды. Ну окей, может быть, даже вы можете сильно напрячься и сделать это в рамках какой-то группы команд, какого-то большого проекта, но это не может быть в рамках, допустим, даже одной страны, что мы можем дефинировать какие-то принципы взаимодействия продуктов, тонеров. Да, Конституция, ну я как человек, тоже занимающийся управлением права, есть такая трактовка правоприменителя, да, вот если Егор Фюреллс тут, я думаю, много может привести примеров, здесь это некорректный пример, то есть здесь мы говорим о том, что просто, да, есть формализация, которая обязательно внутри агента, я вас к этому подвожу. о том, что мы должны биться не формализации объекта, то есть описать формально кошку с точки зрения того, что она формально описана как вот всем критериям кошки, а описана она должна быть на том уровне формализации, на котором работает агент, к которому мы отправляем. Соответственно, когда вы работаете с продакт-тоунером, вы должны формулировать не в языке как бы абстрактно-фундаментального понимания вселенского, в том, что вы не можете добиться от нейронной сети консистентности генерации персонажей, это не проблема в том, что вы, допустим, не можете добиться консистентности генерации персонажей, это не проблема в том, что вы не можете добиться консистентности генерации персонажей, это не проблема в том, что вы не можете добиться консистентности генерации персонажей. Она не понимает вашего суперформального языка. Вы общаетесь с ней не на том языке, на котором она понимает. Вы не знаете, какой язык нужен ей. То есть язык целевой определяет агент, которого вы отправляете, а не то, что мы можем говорить о том, что объекты нам дают какой-то фундаментальный бэкграунд, на котором мы можем опираться. 

S09 [01:31:44]  : Но! Но! Для того, чтобы передать агенту коммуникации свою понятную ему часть своей онтологии, для того, чтобы перевести частную онтологию свою на частную онтологию агента, вы с этим агентом должны иметь общую мета-онтологию. То есть, если вы с агентом не сможете договориться о том, что такое класс, что такое интерфейс и что такое атрибут, вы не сможете агенту объяснить, как классы вашей частной онтологии соотносятся с классами его частной онтологии. — Вы согласны с этим? 

S06 [01:32:29]  : — Да, абсолютно. Об этом и речь, о том, что мы сопоставляем частные. И тогда у нас с отправной точкой на самом деле... Многие говорят о том, что как мы будем интерпретировать действие. Она на самом деле прекрасная. Я и против вообще идеи о том, что она галлюцинирует. Я считаю даже, что она не галлюцинирует. Просто мы задаём вопрос. Представьте, что вы задаёте вопрос абсолютно структурированной, формализованной пятикласснику, вот что-то из того, что определяется здесь. И он вам отвечает, и вы говорите, что он галлюцинирует. Нет, вы просто не смогли ему объяснить, что вы хотели, а он ответил так, как он понял. Но он выдумывает. Он не выдумывает, он ответил так, как он понял. Допустим, я же услышу ваш ответ, ну вы же мне задаете вопрос, я вам отвечаю, и вы не можете гарантировать, что я вас правильно понял. То есть здесь никакой верификации нет, вы никогда ее не получите. Вы можете, ну и, конечно же, воспринимать... Практику, как критерий верификации, это тоже довольно смутный критерий. Верифицироваться тут так себе стратегия. Здесь мы можем как-то состыковать. Я про то, что основой является мультипарадигменность, заранее заложенная. Когда вы показываете дерево-онтологию, оно выглядит, как будто бы оно единое, разворачивается из одной точки. Я все жду, что меня подхватит Александр Балдачев, о том, что оно все-таки не разворачивается с одной точки. Это мульти-вселенная и кошки одной не способны. 

S02 [01:33:55]  : А можно я подхожу еще немножко? А вы возьмите мульти-вселенную и приведите ее к общему корню. Он будет с одного корня разворачиваться в ваша мульти-вселенная. 

S08 [01:34:03]  : Господа, можно немножко вклиниться? Да, пожалуйста. На самом деле, очень хороший пример прошкольника. И этот пример очень хорошо описал Грибоедов. А нет, извиняюсь, Фанвизин, я оговорился. Фанвизин в произведении «Недоросль». Когда вот этого недоросля спрашивают, что такое существительное, что такое прилагательное, он отвечает, что вот эта дверь только существует, а вон там она уже приложена. к месту, где она уже стоит и двигается. По-моему, очень хороший аналог с галлюцинацией нейронной сети. То есть, когда реального знания нет, А вместо реального знания предлагается какая-то типа аппроксимация, что-то сходное, что-то похожее, потому что предлагать – значит предлагать, существительное – значит существовать. 

S02 [01:35:04]  : Ну это да, но есть еще другие моменты. Например, она не понимает детали указания, которые ты даешь, она детали просто проглатывает. И еще, может выдавать просто неверные фактические данные. То есть просто может игнорировать то, что написано немного выше и противоречить этому? 

S08 [01:35:23]  : Она выдает неверные фактические данные, потому что она этих фактических данных не знает. Она пытается фактические данные Генерировать, то есть произвести из несуществующих данных методом каких-то аналогий, аппроксимации и так далее. 

S03 [01:35:46]  : А почему бы ей не вывести просто данные, понятия, я не знаю, это в кавычках было. Это же самая очевидная аппроксимация, когда энтропия расплывается по следующим токенам. Почему не воспроизвести концепт, я не знаю. Он же как раз за эту энтропию отвечает, или нет? 

S09 [01:36:11]  : А потому что этого вопроса не было в тренировочном наборе. 

S04 [01:36:15]  : Наверное, так никто не тренирует просто. Нет, все сложнее. Дело в том, что как только вы хотите, чтобы интерпретация включала в себя отказ от решения, например, в классификационных моделях, отказ от классификации, это все сразу на порядки усложняет реализацию. Почему? Потому что надо туда включать часть реальной логики, с учетом как раз нечеткости решений и порогов на срабатывание каких-то, например, классификаторов или деревьев и так далее. Поэтому как только мы туда идем, то мы говорим, что у нас всегда неявно предполагается мультимодальность. Об этом очень многие забывают, студенты все вообще забывают в течение года, через несколько лет только привыкают. И в данном случае мы говорим, например, когда о контрасте между несчастной сетью, допустим, семантической и несчастной нейросетью, которая якобы не семантическая, то это неправильная дихотомия, абсолютно неверная. 

S03 [01:37:18]  : Я с вами согласен насчет мультимодальности, потому что, мне кажется, только с помощью настоящей мультимодальности можно вывести вот такое свойство, как бы эмержентное, вот этой модели, чтобы она выстраивала взаимоотношения с объектами. Объектов вообще даже в понимании в каком-то, не знаю, даже в Гегелевском, там может перетекание объекта в снятой форме другой объект. Даже вот такие концепции она может вывести из мультимодальности настоящей, мне кажется. 

S04 [01:37:49]  : Вот вам определение окошки, вот вам фотография окошки. 

S03 [01:37:53]  : А касательно отказ от решения, я тут немножко не согласен, потому что я не знаю, это не отказ от решения, это тоже концепт, как и все остальные, который тоже может быть обобщен. 

S08 [01:38:10]  : На самом деле, если вы говорите о возможности отказа от решения, что она должна сказать «я не знаю», то в этом случае она должна практически всегда говорить «я не знаю», потому что кроме явных ответов, уже имеющихся у нее в базе данных на вопрос, Все остальное она не знает. Заметьте, все остальное она не знает и просто пытается как-то породить по аналогии с тем, что она имеет в базе данных. Поэтому если мы говорим, что она должна отвечать, я не знаю, она должна отвечать, я не знаю, практически всегда. 

S04 [01:38:52]  : Вы про что сейчас говорите, про нейросеть? 

S08 [01:38:57]  : Да, я говорю про нейросеть, которая поращилась. 

S04 [01:38:59]  : А у неё откуда база данных, если в том понимании, которое исходно сейчас было? 

S08 [01:39:05]  : в каком-то смысле. То есть фактически то, что она делает при порождении, генеративные эти сети, они занимаются экстраполяцией. То есть они не сообщают то, что они действительно знают, они порождают нечто, чего они не знают. И то, что они порождают, является в большей или меньшей степени правдоподобным. 

S04 [01:39:32]  : И про что я и говорил, потому что нам нужны те самые пороги, да, и отказ от, например, порождения того, что она в кавычках не знает, это вопрос скорее не знания формального, да, а знания тоцитного в данном случае. У неё же есть шикарнейший объём тоцитного знания, да, она же всегда тебе картинку сформирует из шума. Причем, возможно, разную. Вопрос, как сделать эти пороги аутоцитного знания, чтобы их либо превратить формально, либо отказаться от этого превращения. 

S07 [01:40:08]  : Добрый день, давайте я немножечко тут же скажу. 

S09 [01:40:10]  : Сейчас, Александр, давайте по порядку. Сейчас Владимир Смолин подел руку, потом вы. Давайте, Владимир, потом вы. 

S05 [01:40:17]  : Ну, я хочу сказать, что да, нейросети, естественно, все время занимаются не экстра, а аппроксимацией, которая может быть как интер, так и экстраполяцией. И эту аппроксимацию можно рассматривать как получение новых знаний. Когда вы просите там три раза нарисовать кошку, она по-разному апоксимирует разные кошки, и, соответственно, то, что они получаются разные, это не должно вас удивлять. Даже если попросили создать такую же кошку с другого вида, она все равно создает то есть несколько другую, поскольку она специально не запоминала те параметры, которые характеризуют ту кошку. И это длительное время было проблемой при генерации видеороликов. Но за последний год в этой области значительное успехи и способность именно фиксировать параметры отдельных объектов в изображении, которое генерируется, новое, которого никогда не было, оно позволяет строить видеоролики. То есть вот SORA и сейчас есть ряд других приложений, которые строят видеоролики, и они позволяют фиксировать. свойства той кошки, которая нарисована, или других персонажей, которые есть в видеоролике, домик где-то, мимо которого мы проезжаем, или автомобиль, который куда-то едет. Если бы не удавалось фиксировать параметры этого сгенерированного автомобиля, то, естественно, видео было бы плохое. А поскольку эта проблема уже в значительной степени решается, то это позволяет строить. 

S03 [01:41:45]  : А как она решается, мы же не знаем, может быть это RAG какой-нибудь. Что еще раз? Ну мы же не знаем как решается, это же закрытая модель. Может быть это RAG, то есть Retrieval Augmented Generation. То есть мы кадр сформировали, занесли его в базу и на основании него уже передаем его как промпт к следующему кадру. 

S05 [01:42:05]  : Технических деталей мы не знаем, но если немножко подумать, то понятно, что вот эти параметры конкретных объектов, которые генерируются, можно фиксировать. То есть можно фиксировать их, скажем так, внешний вид, а, соответственно, позиции менять. Это одно. А можно менять и то, и другое. Тогда, естественно, видео будет плохое. Ну, собственно, знаем мы, не знаем. Алгоритм процесс такой. 

S02 [01:42:32]  : Можно ли это тренировать как ГАН, например? 

S04 [01:42:36]  : Конечно, это и есть ГАН. 

S05 [01:42:39]  : Нет. Это в некотором смысле GAN, конечно, но там мы управляем не только генерацией различных объектов, но и фиксацией некоторых их свойств. Вот, собственно, что важно для генерации вида и последовательности. 

S03 [01:42:52]  : Интересно, а именно это нейросеть делает? 

S05 [01:42:55]  : Или это... Как правильно было сказано, программа закрытая, посмотреть ее нельзя, но мое мнение, что это делает нейросеть. Может быть, я ошибаюсь. 

S04 [01:43:07]  : Можно же посмотреть на частный случай, который, собственно, Ильюх в основу, это перенос стиля. И все принципы абсолютно те же, просто как раз доведенные до некоторого уровня общности для этой нейросети. Здесь я полностью соглашусь. 

S05 [01:43:24]  : Ну, стиль, конечно, это больше некоторые общие свойства фиксируются и переносятся на другое изображение. А можно и какие-то более частные свойства? Можно очень часто, да. Генерацию видеопоследовательств и их воспроизводить. 

S04 [01:43:35]  : Да, причем сначала научились в пространственной, да, потом уже во временной области это делать. Во временной, конечно, намного сложнее, чисто из-за динамики, но принцип понятен. 

S09 [01:43:48]  : Спасибо. Александр Балдачев, пожалуйста. 

S07 [01:43:52]  : Добрый день всем. Было очень интересно. Да, я хочу несколько слов сначала сказать по поводу последних обсуждений, что знает или не знает нейронная сеть. Большая языковая модель. Вот последние опыты, которые я проводил, привели меня к такой мысли, что она знает все. И проблема именно в этом. То есть, скажем, судя по количеству параметров, то все возможные сочетания слов, все возможные сочетания мыслей в ней уже есть. И довольно часто можно тут такую… При правильном подборе промта она выдает те знания, которые не могла почерпнуть ни из одного текста. То есть я могу это продемонстрировать и показать. Я вывел такой лозунг, что каждому по ему промпту. Каждый получает ЭТЛМ согласно своим промптам. Он даже может не замечать, насколько бывают дурацкие промпты, насколько будут простые. Если вы получаете очень простые ответы ЭТЛМ и очень банальные, это значит, виновата не она, а вы. Если вы хотите получить интересные и инновационные ответы, то нужно работать с промтом, ну скажем, но чаще всего так, если вы сами не знаете, то вы и не получите новые знания от нее, а скорее всего, даже если получите, просто их не заметите. Просто не увидите. То есть для того, чтобы увидеть новые знания, полученные от ЛМ, нужно уже их иметь у себя, то есть попытаться их разглядеть. Но это вообще банальность, потому что когда вы берете сложную философскую книжку, да и достаточно сложную, и начинаете читать, вы читаете там Бильберду. Но при этом вы знаете, что огромное количество людей в этой книжке вычитывают очень глубокие мысли. И виновата не книжка, а виновата вы, что вы не готовы к этому прочтению. То есть это вот такое замечание, потому что она знает и не знает. И поэтому она не может ответить «я не знаю». Это в принципе не может, потому что каждый промпт заводит LLM в некую тропинку, некий троп, некую линейную последовательность токенов, которая в ней уже есть. Она не может определить, что его нет. 

S03 [01:46:09]  : Не, ну так концепт я не знаю, он же такой же, как и все остальные концепты. Почему она на него не натыкается? 

S07 [01:46:17]  : Нет, нет у нее такой концепта, я не знаю. 

S03 [01:46:19]  : Нет. А в чем отличается от других концептов, которые она обобщила? 

S07 [01:46:26]  : Я не знаю, это, во-первых, если говорить о понятии, я не знаю, это характеристика, скажем так, есть в логике, даже в философии представления о том, что истинность это не атрибут, это не свойство. Так вот, я не знаю, это тоже не свойство, это не атрибут, не свойство, не предикат, а вот нечто такое. 

S10 [01:46:53]  : Оксандр, можно подскажу тебе, это рефлексивное понятие, то есть это ситуация саморефлексии, когда она осознает свое состояние. 

S03 [01:47:04]  : Тогда это хороший маркер, если она начнет отвечать я не знаю, значит у нее саморефлексия какая-то, да? 

S07 [01:47:09]  : Ну, скорее всего, да. Хотелось бы вернуться все-таки к теме нашей общей, которая была заявлена Антоном. Я хотел дать маленькое уточнение. Это моя фраза, что НЛП умер, но это касалось исключительно анализа текста. То есть никаких не результатов, которые мы можем получить в конце, а именно то, что методы, которыми анализировался текст NLP и NLU, они все, в принципе, действительно оказались неудел. И все, что мы можем извлечь из текста, можно извлечь с помощью LLM. правильно написав промпт, правильно поставив какие-то ограничения, можно и извлечь. Но именно тот результат, который был получен, конечно, результат не всегда удовлетворительный, который мы хотели бы получить, скажем, от НЛО. И по поводу, также есть такая заметка по поводу криминального обучения, У меня давно такая мысль была, что в принципе современные ЛЛМ уже не нуждаются до обучения. Скорее всего наоборот. То есть стоит задача снизить уровень их знаний. То есть научить до операционного какого состояния, а потом вычистить лишние знания, и эти лишние знания уже выдавать в готовом виде, конкретно, ну как мы сейчас прончо РАК делаем. Но это, наверное, не совсем правильное решение РАК, некорректное с точки зрения, что поиск того, о чем должна ответить ОЛМ-ка, делается системой на порядок менее интеллектуальный. Ну это как, скажем, сидит профессор в читальном зале, задает какой-то вопрос, принесите мне книги по такой-то теме, и школьник приносит ему книги для анализа. А школьник не понимает этого вопроса, просто по аналогии где-то там подбирает какие-то книжки и приносит. А у самого профессора нет возможности ничем другим воспользоваться, кроме того, что принес школьник. Вот рак это вот это. 

S03 [01:49:12]  : А что вы думаете по поводу LCM? Мне кажется, вы говорите, что надо упрощать знания, а LCM, что вы об этом думаете? По-моему, это и есть такое упрощение, нет? Которое с одной стороны упрощает, а с другой стороны делает обобщение более плотным и эффективным. 

S07 [01:49:32]  : Давайте продолжим. Наверное, да. Я сейчас не хочу. Даже, наверное, и не знаю. И тут действительно появляется тема графов, семантики. И основная проблема, которая должна решаться с помощью семантики, это, наверное, три. Это прежде всего то, что всем так очевидно, это хранение знаний, формальное хранение знаний. То есть ни один человек не хранит формально знаний, и любой человек, когда он отвечает на какие-то вопросы, может ошибиться. Любой человек может ошибиться, потому что забыть, перепутать, он будет уверен, что он знает. Во многих случаях человек знает. Поэтому необходимо при языковой модели некое хранилище формальных знаний, которое может состоять из двух частей конкретной тексты. Потому что мы никуда не денемся от конкретных тех. Мне нужен, вот я когда работаю, мне нужен конкретный текст, конкретные цитаты, а не выжинка в ЛЛМ. И некая индексация, некая индексация этого текста, которая должна сделать сама ЛЛМ. То есть сама NLM должна получить текст, прочитать его, индексировать по моделям, формальным моделям, которые должны быть заложены в систему, и вычислить дубликаты, вычислить, пессимизировать повторы, пустые тексты, обзоры различные, и выделить тексты оригинальные. и их индексировать и положить отдельно текст, и со ссылкой их семантическое описать, их семантический как бы слепок. И когда будет задаваться вопрос какой-то LLM, она должна значит войти сначала в тему, по тему найти, то есть классифицировать этот вопрос, сравнить с какими-то близкими текстами и найти те конкретные тексты, которые ближе всего, и ответить, и, может быть, с цитатами, что, в принципе, сейчас уже умеют делать. Джемини отлично работает с текстами, выделяет цитаты. То есть это первый момент, это хранилище данных. Второй момент, который просто без чего нельзя обойтись для работы, это наличие сценария. То есть не просто свалка графа знаний, который представляется вот сейчас мы имеем в виде графа знаний, когда все свалено в одну кучу, все концепты, все индивиды связаны с кем-то будут связаны, а нет конкретного разделения на деятельности, действия, сценарии, конкретные сценарии. И сценарий даже не столько именно для того, чтобы понять текст, а сценарий, по которому может пройти сама Леленко. Я проводил эксперименты событийной семантикой, обучил Лэмку понимать язык событийной спецификации, и когда она строила модели, она сама же проигрывала эти модели. Есть некий набор правил в моделях, который проигрывает движок, он спешком работает, все в порядке, и я просил Лэмку проиграть эту модель, И выполнить какие-то действия, она вот сама меняла значение в индивидах. То есть у нее записаны были индивиды, добавляла новые события с новыми предметными, новые предметные события в индивиды. И во многих случаях, во многих случаях проигрывание моделей, семантических моделей может происходить и без программирования. Ну и третья, за чем нужна семантика, то сегодня тоже упоминалась, это верификация. То есть семантик должна быть на входе, семантик может быть в середине при проигрывании моделей, и семантик должна быть на верификации. Потому что если мы не имеем строгую модель, строгую инструкцию, вот Антон упоминал, что когда человек приходит на предприятие, какую-то должность, его как-то экзаменуют, спрашивают его знания, но даже после этого он может ошибаться, и всегда есть какая-то инструкция, по которой можно проверить, правильно ли он совершил какие-то действия. На выходе тоже должны быть семантические модели. А все, что связано с пониманием текста, переводом текста в эти модели, с поиском данных, с выдачей данных и с различными предложениями по управлению, это может делать ЛМК. А в начале, в середине и в конце должны быть семантические модели. Единственное, что современные объектные графы для этого не очень годятся. то есть смоделирует бизнес-процесс на эти графы. А, да, есть еще один момент, сейчас Кин поднял руку, я вспомнил, нужно ответить Владимиру прежде всего, что да нет такого представления, что семантика должна быть строго однозначна, одна для всех и истинна. То есть для каждой конкретного действия, для каждого конкретного кейса, для каждого конкретного актора это может быть разная модель и разный набор данных. Не важно то, что это должно быть истинно и верно. Важно то, что должно быть вписано в действие, конкретное действие. И даже если это действие неправильное, антизаконное. Люди очень часто действуют не так, как Но это все равно должна быть семантика описания этого действия. Если кто-то рядом делает по-другому, это будет другая семантика, другой граф, другие модели и другие данные. Будут стоять несколько датчиков, и они будут генерировать разные данные. Мы должны все учитывать. Анализируя уже потом каким-то образом, какие правильные, какие неправильные. Поэтому, конечно, вопрос однозначности семантики, ну, такой. Не то, что надуманный. Сейчас есть многие-многие люди, которые пытаются создать единую общую семантику для всех, на все случаи жизни, забыв о цике и истории с ним. Нет необходимости в этом. Ну вот, наверное, всё. Спасибо. 

S09 [01:56:10]  : Александр, спасибо. У меня к вам огромное количество вопросов, а именно 6 комментариев. Я позволю их себе задать. Вот, я думаю, с продолжением доклада, естественно, мы сегодня делать не продвинемся. Вот, вижу две руки. Но давайте сначала вопросы Александру. Во-первых, значит, по поводу частных онтологий. Это на самом деле тема, про которую я хотел затронуть в продолжении доклада. И, наверное, это повод сегодняшний разговор чуть позже продолжить. Это первый комментарий. Второй комментарий по поводу верификации. Вы можете в двух словах на следующий вопрос ответить? Как вы видите верификацию того, что дает LLM. Я поясню вопрос. Допустим, в той истории, в которую я сейчас копаюсь, когда мы строим рак на основе LLM, я могу верифицировать совершенно инструментально то, что система разобрала мой вопрос и правильно идентифицировала функции, или тулы, которые нужно позвать, и их аргументы. Потому что есть механизм, с помощью которого фреймворк говорит, что я вот нашла в твоем запросе такие и такие функции, и вот у них аргументы. И зная, какой запрос задал, я могу, грубо говоря, настроить там тестовый процесс, который будет верифицировать, что разбор произошел правильно. Когда я выполняю эти функции, я тоже могу построить тестовый фреймворк, что я могу верифицировать, что мои функции или тулы правильно исполняются. Но потом, когда система генерит ответ, она может на один и тот же запрос сгенерить большое бесчисленное число ответов. И как мне верифицировать то, что все ответы в среднем будут более-менее правильные? Я сейчас не знаю. Как я это сформулировал недавно в посте, для того чтобы обеспечить QA LLM с интеллектом уровня N, я должен иметь сверху LLM уровня N плюс 1, для того чтобы она могла верифицировать качество выводов LLM с интеллектом уровня N. Как вы видите верификацию? Не слышно, не слышно вас. 

S07 [01:58:47]  : Смотрите, здесь есть, все-таки хотелось бы разделять две области. Есть область деятельности, конкретной производственной, еще какой-то деятельности, бизнесовой деятельности, которая в достаточной степени регламентирована. в которой есть какие-то инструкции, есть какие-то положения, установки. И вопрос именно в том, что нужно перевести вот этот весь регламент деятельности в семантический вид. И тогда с его помощью можно будет регламентировать те, верифицировать те действия, которые предлагает ЭЛЭ. А то, что касается языковых ответов, конкретных языковых ответов, мы никак не можем даже человека переференцировать. Правильно мы сказали, неправильно. Поэтому здесь либо нужно всегда человека предупреждать, либо человек должен понимать, что любой человек, любой текст, он всегда может содержать ошибки. Поэтому, когда я говорил про верификацию, здесь, скорее всего, имелась в виду верификация именно формальных действий. Хотя, хотя, скорее всего, если мы переводим множество текстов в семантический вид, то мы можем при помощи этих текстов проэлифицировать и сказать, что вот этот ответ соответствует вот таким-то текстам, такому-то мнению такого-то ученого или такой-то энциклопедии. Вот это соответствует энциклопедии, и перевести цитату. Либо это соответствует, скажем, если это какой-то колл-центр, у нас есть множество тысячи правильных ответов, мы всегда можем верифицировать с помощью правильных ответов, и при этом это соответствует этому правильному ответу. Но в свободной речи верифицировать невозможно ни человека, ни машину. 

S09 [02:00:46]  : Спасибо. Следующий вопрос. По поводу того, что вы сказали, инкрементальность не нужна. Смотрите, мы автоматизируем бизнес-процесс. Допустим, продажи. У нас каждый день могут появляться новые товары. У нас могут появляться новые сотрудники, у нас могут появляться новые точки продажи, у нас может появляться новое всё что угодно. Как без инкрементального обучения? Мы можем обойтись. 

S07 [02:01:15]  : Это все формальные знания. Это все формальные знания, которые записываются в виде формальных моделей и загружаются не в параметры ЛЛМ, а именно в рядом стоящее хранилище знаний. Вопрос именно в том, что ЛМК найдет однозначно хороший поисковик, она среди этого знания найдет новый товар, подберет из нескольких товаров и выдаст пользователю. 

S09 [02:01:44]  : То есть через РАК мы делаем тул? Только не РАК, это не РАК. 

S07 [02:01:49]  : Ну тул. То, что мы помещаем. Это так называется. Когда я говорил, что не нужно инкрементировать, не нужно обучать ЛЛМ, который уже достаточно понимает, понимает гораздо лучше, чем человек текст, и обещать всем текстам новым. Нужно просто иметь тул, который предоставит ЛМКе возможность найти новые знания, которые будут храниться в формальном виде. Знания должны храниться в формальном виде. Именно и только так. Не нужно обучать ее ничему. То есть обучение ЛМКе до какого-то порога шло, скажем так, обучение нейронной сети до какого-то порога шло в направлении закачки знаний. Отличить кошечку от собаки, отличить какие-то слова, но с LLM мы перешли другой уровень, мы перешли порог, когда уже не знания важны, а понимание ее текста. Поэтому знаний брузить туда не нужно, А можно освободить от лишних знаний, чем уменьшить количество параметров, но оставив тот порог понимания, а знания грузить отдельно. Но знание грузить в том виде, в котором она сама понимает и сама загружает. Не мы как-то по своим соображениям. То есть нужен какой-то tool, нужен какой-то семантический язык, который она сама понимает, хорошо изучила, формально может верифицировать и на этом языке свои ответы. И на этом языке она должна перевести тексты в формальные какие-то модели. 

S01 [02:03:31]  : Слово DSL. 

S09 [02:03:33]  : Да-да-да. Я правильно понимаю, что это можно сделать двумя способами. Либо этот DSL должен быть в тестовом наборе, либо его каждый раз нужно подкачивать в промпт. 

S07 [02:03:44]  : Ну, может в тестовом наборе. Один раз обучить можно. Если мы получим некий универсальный язык, то можно обучить один раз. Хотя желательно все-таки иметь спецификацию формально подгружаемой, чтобы действительно исключить всякие галлюцинации. Тем более с нынешним окном, уже с современными окнами, сама спецификация, вот опять же на своем опыте, если три с половиной, когда я его обучал, то есть меня потрясет несколько часов, и я много-много объяснял и загружал всякие тексты, то уже четверка, Да, а особенно клод 3.5 достаточно просто было человеческую спецификацию загрузить. У меня есть спецификация языка, но просто обычная спецификация, которую вот людям даешь. Просто загрузил, после этого сразу пишет модель. 

S09 [02:04:34]  : Спасибо. Еще буквально несколько вопросов, чтобы отпустить. Насчет индексации графа знаний текстом или текста графом знаний. Я правильно понимаю, что вы говорите по сути о мультимодальной foundation model, которая тренируется на текстах и одновременно графам знаний. На структурированных знаниях и на текстах, ассоциированных между собой. Это не мультимодальная модель? 

S07 [02:05:14]  : Я про мультимодальную модель не говорил вообще, хотя это отдельная тема. Я имел ввиду в своем рассказе только тексты. 

S09 [02:05:22]  : Нет, а что значит индексация? Вы говорили, что проиндексировал? 

S07 [02:05:25]  : Индексация текстов. Перевод текста какой-то статьи в симматический формальный вид, по которому нужно быстро поиск. Через tool? Через tool. А, окей, то есть вы имели в виду tool. То есть здесь вопрос именно в том, что мы не можем заставить ЛЛМку шерстить тексты. Они очень большие. Но если у нас есть, скажем, многоуровневая, несколькоуровневая модель текста, на первом уровне, скажем, просто заголовок, на втором уровне там тема, подтема, еще какой-то, следующий уровень содержит ключевые идеи, еще следующий уровень содержит еще более развернутые какие-то тезисы, вот, и имея вот такой индекс, скорее всего, статьи, да, то по ним может быстро пройтись НЛМ-ка и выбрать, сначала по первому укусь собрать, потом, перейдя на второй уровень, еще отбросить лишние статьи, еще, перейдя на нижний уровень, выбрать 2-3 статьи, их уже прочитать и ответить по ним с помощью, используя цитаты. То есть мне нужно для работы, мне нужно, чтобы быстро нашелся текст, и те ответы, которые по нему будут, были подтверждены цитатами. Кстати, вот эта верификация есть. По сути, верификация текста заключается в том, что я не должен получить ответ LLM. Мне не нужен ее ответ. Мне нужен, чтобы она нашла тот текст и отвечала цитатами из этого текста. Вот так верификация будет. А какая-то еще, я только проверил, действительно эти цитаты есть там. 

S03 [02:07:11]  : Это же, по-моему, рак и есть в азиумведингах. 

S07 [02:07:14]  : Это не рак. 

S09 [02:07:15]  : Ну это как бы продвинутый рак. То есть классический рак – это мы текст режем на куски, а тут все-таки предполагается какая-то структуризация. 

S07 [02:07:23]  : А можно уточнить? И самое интересное, что я рассказываю, это то, что сама ЛЛМ-ка должна создавать этот индекс, создавать это хранилище, а не внешний какой-то тул, который тупее ее на порядке. 

S09 [02:07:38]  : Но таких инструментов в сегодняшний день нет, правильно? 

S07 [02:07:43]  : Нет. Я провожу сейчас эксперименты. В принципе, что-то работает. 

S02 [02:07:48]  : Можно уточнить? То есть, в принципе, на этапе тренировки LLM ей может даваться возможность, чтобы она сама читала документы и помечала то, что хочет? 

S07 [02:07:59]  : Нет, это не на этапе тренировки, именно нет. Когда уже полноценная LLM есть, когда она уже достигла того уровня, который сейчас топовые модели, вот уже они должны проводить индексацию текстов. 

S02 [02:08:14]  : Откуда она будет знать, что и как индексировать, если ей не давали обучаться? 

S07 [02:08:19]  : Почему обучаться? Она прекрасно читает любой текст и прекрасно создает модель любого текста. Я расскажу еще. 

S02 [02:08:29]  : Как вы изначально проверите, что она правила создает индексы, то есть вы включите LLM, она будет создавать индексы, но в этом всегда есть определенная доля ошибки, понимаете? 

S03 [02:08:38]  : Не в ошибке дело, я хотел спросить, а это индексация, так это разовая задача, да? Сначала вы разово просите индексировать, а потом уже общаетесь. 

S07 [02:08:50]  : Один текст один раз индексируется. Я отвечу. Дело в том, что если вы задали формальный язык анализа текста, то она нормально пользуется этим языком. Она ошибиться может, но для этого и существует вот конечная моя фраза, что мне не нужен пересказ текста, а мне нужна цитата из текста. Нет, общий пересказ нужен, конечно, да, конечно, общий, общий, но потом, когда я буду использовать, я должен работать с цитатами. А, и расскажу коротенький еще эксперимент, который я проводил, то есть я обучил две ветки, две сессии чата G5-4,5, это было тогда еще, вот работе с событийной семантикой и подбрасывал текст одной ветки, создая модель этого текста на событийном языке, он писал формате нормально, там как требуется, и скармливал вот эту формальную запись другой ветки. И она, что здесь написано, она пересказывала уже на естественном языке, очень близко к тексту. То есть очень близко к тексту пересказывала то, что было закодировано в спецификации. 

S09 [02:10:10]  : Спасибо. Александр, ещё буквально два коротких вопроса вам и двинемся к Владимиру Егору. По поводу того, что пора уже убавлять количество знания, начиная с какой модели вы считаете, что уже достаточно? 

S07 [02:10:34]  : Современных еще нет, наверное, со следующего поколения. 

S09 [02:10:38]  : Чуть-чуть не хватает. Вы говорите только про ЧАД-ЖПТ или то, что через Яму доступно? 

S07 [02:10:47]  : Клод, Джемини и ЧАД-ЖПТ. То есть, три модели топовых, которых вышли. Единственный ЧАД-ЖПТ OpenAI, который за 200 долларов типово был. 

S09 [02:10:59]  : Опенсорсные модели вы не рассматриваете? 

S07 [02:11:02]  : Я с ними не работал. 

S09 [02:11:04]  : Вы просто не знаете. Там всякие лямы по 7 миллиардов параметров. 

S07 [02:11:12]  : Насколько я понимаю, они не превосходят топовые платные модели. Не превосходит. Не превосходит. Вот сегодняшний уровень Клода 3,5, он вполне себе уже может много сделать. Вообще, если вообще пофантазировать, чего не хватает в современных топовых моделях, ну прежде всего не хватает того, что он не помнит все, с чем работал со мной. Это глобальный недостаток, потому что каждый раз приходится переходить на новую ветку, на новую сессию. И второй глобальный недостаток, который, я считаю, когда он передалеет вот этот уровень, тогда, наверное, мы перейдем на принципиальный этап. Это то, что я работаю только с этой моделью и больше никто не знает, что я делаю. Я могу как бы дать ссылку, но когда я, поговорив с моделью, обсудив какую-то тему, Я разрешу ей это использовать, и она, отвечая на вопрос Антона, она спросит, а вот Балдачев вчера написал вот то-то. Вот когда она вот так начнет работать, это будет грандиозный перескок. 

S09 [02:12:30]  : Но это же как бы решается технически. Вы можете сделать свою собственную надстройку со своими собственными сессиями. 

S07 [02:12:38]  : Это вопрос не когда я сделаю. Почему я сейчас не стремлюсь никаких делать надстроек и не пытаюсь с кем-то там вести переговоры, чтобы что-то сделать. Потому что понимаю, что вот я сейчас делаю, но через месяц нужно будет все это выкидывать. И все раги нужно будет выкинуть, которые сейчас делаются. Вот все, что сейчас делают, в целом я прекрасно понимаю, что все это будет выкинуто через год. 

S09 [02:13:01]  : Александр, последний вопрос насчет того, что для того, чтобы получить любой ответ, нужно сформировать правильный промт. С практической точки зрения это не сужает радикально применимость Потому что у нас нет случаев, в большинстве случаев, если вы не разработчик и не исследователь ЧАД ЖПТ и не специалист по промптом, вы никогда не знаете, какой вам нужен промп для того, чтобы удовлетворить конкретный запрос. Как вот из этого противоречия выйти? 

S07 [02:13:33]  : Но это не противоречит. Дело в том, что когда я говорю вот получить вот тот единственный ответ, это имеется в виду очень высокоуровневое знание, высокоуровневые структуры, высокоуровневое понимание. Для большинства людей нахрен это не нужно. Для большинства людей нужно получить данные с соседней магазины или где-то дешевле какую-то услугу сделать. Или ответить на конкретный вопрос из Википедии. 

S09 [02:13:59]  : То есть вы говорите, что на конечное число случаев можно написать конечное число правильных промптов с помощью Промпт Инженерии. 

S07 [02:14:10]  : То есть, по сути, если выполнить вот тот проект, который я говорю, что загружая тексты, создавать модели этих текстов, то в итоге получится гиперграф. семантический грейпер граф, который будет содержать практически все знания. И вопрос именно в том, что мы создаем этот граф при помощи LLM, и она же по нему уходит. То есть не нужно граф создавать извне где-то. Граф должен быть тот, который она сама создаст и будет знать, как по нему ходить. Почему меня натолкнула эта мысль, что LLM все уже знает? То есть вот та проблема, когда мы получаем разные ответы от лэмки на один и тот же вопрос, это там просто подкручен генератор случайных чисел. То есть если взять лэмку в чистом виде и задавать ей один и тот же промпт, мы получим один и тот же ответ. 

S09 [02:15:09]  : Там нет никакой эстахистической... Александр, там могут быть ситуации, какие-то неоднозначности, когда датчик случайных чисел позволяет какому-то... Я говорю без датчика случайных чисел. 

S07 [02:15:25]  : Если я получаю какой-то ответ, который я точно знаю, что она нигде не могла прочитать, Вот не могла знать она вот это, то, что вот я сейчас ее спрашиваю. Значит, это в ней уже есть. То есть, скажем, это перебор всех возможных вариантов, всех знаний, которые мы еще не знали. И проблема не в том, что она должна что-то вывести, выводить. Она ничего не выводит. Там нет логической машины. Мы просто должны каким-то образом завести ее в ту область, в которую мы... У нее она есть уже, эта область. Но мы туда даже не попадаем. То есть мы крутимся на какой-то маленькой области наших знаний, которые мы можем спросить и мы можем понять. А многое мы и понять не можем. Ну, допустим, ситуация, если мы с XIX века что-то спросили у нее, навели ее на ту область, в которой у нее есть там тропы по квантовой механике, она бы ответила, ну, совсем сдурела машина, какая-то волна частиц несет. А она может знать еще чуть того, что для нас тоже кажется галлюцинацией, а это просто мы не понимаем, что она говорит. 

S09 [02:16:34]  : Александр, спасибо огромное. Давайте еще три последних спикера или вопроса, чтобы уже закругляться минут через 10. 

S07 [02:16:42]  : Владимир, пожалуйста. Спасибо за вопросы. 

S09 [02:16:49]  : Владимир, вас не слышно. Владимир, вас не слышно. 

S05 [02:16:55]  : Виноват, да. Собственно, вот это утверждение о том, что ЛЛМ уже всё знает, оно отражает такое милое представление философов, что есть пространство идеи, где все идеи уже существуют, а мы оттуда выбираем. Ну, видимо, ЛЛМ тоже оттуда выбирает, потому что примерно такое же представление философов про калькулятор, который знает, какой будет результат любого действия с любым числом, которое входит в разрядность. Но кто в курсе конструкции калькулятора, там не так. Там все-таки есть правила преобразования чисел, и они работают с любым числом. И на самом деле альфа-зеро отличается от калькулятора только тем, что он не... Правила в него, игры в ГО, устанавливались не программистами, а он сам в процессе обучения нарабатывал эти правила. Но все равно все возможные комбинации ГО, даже при законе МУРа, если он будет несколько сот лет действовать, все равно не хватит, чтобы составить таблицу на все возможные комбинации ГО. Примерно то же самое с ЛМ. Он может давать ответы на совершенно разные тексты, которые вроде бы он и не мог читать, в смысле на содержание, которое он не мог знать, но это просто он использует те правила, которые наработали в процессе обучения нейронной сети. На счет того, что, значит, если брать там запросы в магазины или какой-нибудь там спросить, какая будет завтра погода, Это тоже немножко наивное представление, что все возможные вопросы могут быть сведены в таблицу. Мы с вами всегда найдем способ задать вопрос, который не войдет в эту таблицу. Возвращаясь к тому, к чему посвящена наша встреча, о роли семантических моделей в Собственно, я не считаю, что они не нужны. То есть, также какой-то калькулятор может сейчас не очень активно использоваться, но это полезное устройство. И оно позволяет нам повысить наши интеллектуальные возможности. И почему это не является сильным искусственным интеллектом? Потому что мы не можем исключить человека в работе калькулятора. Калькулятор не может работать без человека. Все вот эти языковые модели, они, конечно, сильно больше имеют возможности, чем калькуляторы, просто по вычислительной мощности, по тем данным, которые есть. Но они опять-таки не позволяют включить человека. То есть все вот эти данные, которые получают большие языковые модели, они человеческие, человеком были созданы. Хотя Александр предлагает, наоборот, ограничить знания, есть другой взгляд, что сейчас, допустим, половина текстов, или там уже две трети текстов, большим языковым моделям используют в преобучении. Но осталась одна треть. Давайте ее скормим. А дальше что? Ну, конечно, мы там с вами еще какие-нибудь статьи напишем, кто-то там поэму новую опубликует. Но понятно, что вот эта вот скорость добавления человеческих текстов, она невысокая на фоне того, что было сделано за всю историю цивилизации. И, собственно, проблема как раз в том, что вот эти языковые модели как на нейронной, так и тем более на семантических сетях, они построены, а как обязательный элемент предполагают использование человека. То есть это не может быть сильным искусственным интеллектом именно потому, что не может без него обойтись. 

S09 [02:20:23]  : Спасибо. Егор? 

S10 [02:20:28]  : Да, я продолжу. традицию возвращаться к истокам топика сегодняшнего. Поддержу отчасти тезис Александра Балачева, он несколько проскочил, но я уже не буду точности поменять. Для чего онтология для Ижай? И здесь вот был спор между Антоном и Кимом, я затаил возражения. проскочил, на мой взгляд, не очень такой, скажем, не развлечение определенное, которое важно, на мой взгляд. Антология – это средство коммуникации в первую очередь, то есть это средство транспорта каких-то, я не люблю это слово, но для краткости скажем, транспорта смысла между агентами, транспорта. можно так сказать. Если мы используем это внутри, как это часто принято, да, строить внутреннюю агентскую процессию на антологиях, ну скорее это такая дань ограничениям технологии. Я так уже предполагаю, что накопленный опыт за последние там сколько там уже, 70 лет, показал, что символные вычисления, они имеют очень сильные ограничения. То есть Real Base Systems, там экспертные системы рухнули. Антология, там трагические есть просто эпизоды, как вот с антологиями права, тоже где-то они 20 лет просто бодались-бодались и просто закрылись. Внутри, как вот Александр упоминал, как и вы говорили, Антонов, для агента онтологии могут быть наблюдаемой знескорее. То есть это эмержентная онтология, мы можем констатировать, что существуют определенные аттракторы, можно сказать, семантические, или там лучше по-другому определить, которые мы распознаем как онтологические позиции. но они должны подняться из каких-то элементов более распространенно. Гораздо большее количество параметров должно создавать эти аттракторы, иначе мы никогда не прилюбимся никакому UGR. Когда мы сейчас воссоздаем эти онтологии в той или иной степени emergent на основании LLM, мы получаем эти лэмп все-таки из текстов. В этом есть некоторое ограничение и такая сходимость перспективная, очень перспективная, когда мы не выйдем за рамки этих текстовых аттракторов, связанных с семантиками, с синтаксисами, с семантиками текстов, языков. Для человека, если мы говорим про сильный искусственный интеллект, который как-то там близок к нему, вот эта нижняя часть в стеке, она возникла не на основании языка. Канеман, собственно, про это и говорит. Она настолько мощная, что она доязыковая. И она возникла из других, вот, многих-многих итераций, там, тысячелетий, миллионов лет сенсорно-моторных практик. Очень сложных, в том числе в рамках социума и так далее, и так далее. Я думаю, что пока вот этот путь сенсорно-моторный не будет пройден по-честному, ну, скажем так, с отрезанием углов, но тем не менее, мы никогда не получим, скажем так, эквивалента сколь-нибудь близкого к человеку. ну, опять же, как в какой-то норме. сейчас мы уже получили весьма близкого эквивалента в каких-то там перспективах, но мы уже видим эти ограничения. на мой взгляд, вот такое дело. 

S09 [02:24:37]  : спасибо. Егор, спасибо большое. 

S03 [02:24:41]  : Андрей? ну, я что хотел сказать. Александр Балдачёв упомянул про то, что Лелемки сейчас всё знают. Есть такая абстракция, наверное, все про неё слышали. Орхе Луи Борхеса, называется Вавилонская библиотека. Там тоже есть все знания мира, которые расположены на конкретном шкафу, на конкретной полке, в конкретном ряду. Проблема лишь только знать координаты этого ряда, и можно прочитать все тексты, которые уже написаны или не написаны, еще будут написаны и так дальше. Но проблему-то это не решает. Проблема у нас не в том, чтобы найти такое хранилище знаний, а в том, чтобы получить ответ на свой вопрос. И желательно без сложного какого-то промта. Как вы все знаете, О-3 сейчас прошел арктесты, где совершенно простейшие вопросы задаются на совершенно простейшие задачи. И там Cumed, модель, которая за одну задачу простейшую тратит полторы тысячи долларов на вычислительный ресурс, это еще тюнт, да, что она прям научена была на них, то есть, ну, какое подозрение, то, что никакого логического движка там все же нет, а его хотелось бы иметь, вот. И как его заполучить? Вот предыдущий оратор Егор сказал про сенсомоторный путь, ну, мне кажется, вот этот там путь, он заключается вот мультимодальная насмотренность. У нас вот текстовая насмотренность есть, вот у Эли Лемак, а мультимодальной, вот честной мультимодальности у нас пока еще нет. И вот как раз-таки вот эта логика отношений между объектами, как абстракциями, она как раз-таки вот в этой мультимодальности, притом которая будет скорее всего, как мне видится, произведена на каком-то embodied AI, который будет работать в физической среде, вот тогда там логику он сможет построить. Почему? Почему это невозможно или слабо возможно в ле-лемке? Собственно, строго говоря, для языкового пространства, в котором ле-лемки функционируют, вот логика формальная, она необязательна. Есть вот такие понятия философские, как мыслимость, представимость. Вот если сейчас лилемки спотыкаются на что? То, что там какая-нибудь внучка, бабушки, прадедушки, кто к тебе приходится, лилемка тебе может нафантазировать и сказать, что она твоя внучка или дочка. И по сути, с точки зрения фантазии, это представимо. Фантазия — это и есть то, что представимо, мыслимо. И для языкового пространства вот такой ответ, он никакого противоречия в себе не несет. А вот на выборке именно логичных текстов и фантазийных текстов, там смесь, я даже не знаю, в чью пользу вообще, вот в этом интернете, когда было обучено. Но с точки зрения грамматики, естественно, с точки зрения человекоподобности, это все будет правильно. Но с точки зрения конкретной логики – нет. И тут как раз Егор сказал, что должен быть пройден мультимодальный или насмотрен мультимодальный сенсорный путь, и тогда отношения между объектами, именно логика как концепт сформируется. У меня все. 

S09 [02:28:20]  : Спасибо. Хорошо. Спасибо, Андрей. Егор, самое последнее слово. 

S10 [02:28:28]  : Да, я как раз хотел бы найти правильное слово для того, о чем Андрей говорил. Он говорил про мысли, представимость и так далее. На самом деле, более технологично говорить все-таки про модели. Это модель ориентированной инженерии, ее борьба с текстом. документа ориентированной инженерии, это десятилетие, она более-менее успешная. Здесь примерно та же самая эволюция, борьба с текстом. И мы придем рано или поздно тем самым паттерном внимания, на который я пытаюсь обратить внимание, к аффордансам, к схемам, к более общим структурам, которые именно возникают, вот их архитектура из глубинных сенсорно-моторных сценариев, которые проживает каждый конкретный там индивид, и мы на них опираемся, то есть наше пространственное мышление на них опирается. Если мы строим AGI, который смог бы разговаривать с нами, с такими же животными, которые тоже мыслят пространственно, мыслят объектно, то мы должны его тренировать как объектное существо, которое живет в некоторых рамках. Но так как тренировать до этого уровня сложно, просто натаскивать его как робота Атласа, кубики таскать, этого может быть еще недостаточно и слишком долго. Здесь открывается большой вызов. Но, по-моему, без этого нельзя. 

S09 [02:30:05]  : Хорошо. Егор, спасибо. Коллеги, большое всем спасибо за участие. Мы достаточно основательно изучили вопрос по применимости, необходимости, нужности, полезности или бесполезности онтологии для построения EGI и практического применения LM. Мы совершенно не успели поговорить про редакторы антиорудогии DSL. Соответственно, я, наверное, вброшу еще опрос, кто готов продолжить разговор на эти же вытрепещущие темы и обозначим дату и время. по итогам этого опроса. В частности, на затравку смогу рассказать про свой конкретный проект, а желающие смогут рассказать о своих конкретных проектах. На следующей неделе мы в понедельник говорим об импульсных нейронных сетях. обучении с подкреплением на их основе. В четверг Алексей Незнанов выступает. Ну и дальше по расписанию. Всем спасибо и до новых встреч. 

S00 [02:31:18]  : Большое спасибо. До свидания. 

S07 [02:31:20]  : Спасибо, до свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
