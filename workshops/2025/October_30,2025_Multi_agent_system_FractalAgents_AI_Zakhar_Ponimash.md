## 30 октября 2025 - Мультиагентная система FractalAgents AI - Захар Понимаш, Виктор Носко ("Аватар Машина")- семинар AGI
[![Watch the video](https://img.youtube.com/vi/btDsmXzxwRU/hqdefault.jpg)](https://youtu.be/btDsmXzxwRU)


### Обзор мультиагентной системы Fractal Agents AI-MAS

Виктор Носко и Захар Понимаш представили свою разработку — мультиагентную систему Fractal Agents AI-MAS. Проект, находящийся в стадии закрытого тестирования, предлагает новый подход к решению сложных задач с использованием кооперации нескольких интеллектуальных агентов.

**Проблемы существующих систем и предлагаемые решения**

По словам Виктора, современные большие языковые модели (LLM) имеют ряд недостатков при решении многошаговых задач. Пользователям часто приходится самостоятельно составлять план решения, подбирать промпты и выстраивать цепочки из нескольких моделей, что приводит к накоплению ошибок и требует технических знаний. Такие системы, как ChatGPT, DeepSeek и GigaChat, перекладывают на пользователя ответственность за выбор правильных инструментов, например, "мышления" или "поиска", что не всегда оптимально и может приводить к удорожанию и замедлению процесса.

Fractal Agents предлагает систему, которая берет на себя декомпозицию задачи и планирование вызова различных агентов и инструментов. Это позволяет пользователям формулировать сложные запросы на естественном языке, а система автоматически подбирает оптимальную последовательность действий.

**Ключевые технологии и подходы**

Система Fractal Agents основана на следующих принципах:

*   **Различные топологии вызова агентов:** В зависимости от сложности задачи система использует разные подходы, такие как REACT и REWO, для проверки и улучшения ответов LLM, что позволяет оптимизировать стоимость и качество результата.
*   **Динамический выбор агентов:** Система автоматически выбирает наиболее подходящие из 15 доступных LLM и 8 специализированных агентов (включая поиск в интернете, суммаризатор и систему для ответов по документации), основываясь на критериях качества, скорости и стоимости.
*   **Графовая структура:** В основе системы лежит граф агентов, который эволюционирует в процессе выполнения задачи, позволяя эффективно маршрутизировать запросы.
*   **Собственный язык и модель GCR:** Для взаимодействия агентов и достижения консенсуса без экспоненциального роста контекста был разработан внутренний язык Kumaso и подход "Генератор-Критик-Ревьюер" (GCR).
*   **Иерархическая долговременная память и онтологии:** Система способна запоминать контекст диалога на длительных промежутках и извлекать связи между удаленными сообщениями.

**Практические кейсы и сравнение с конкурентами**

Докладчики представили результаты тестирования системы на различных задачах:

*   **Маркетинговое исследование:** Система успешно нашла 100 компаний с их контактными данными, в то время как конкурент нашел меньшее количество.
*   **Математические задачи:** При решении уравнений система показала более высокую точность по сравнению с такими моделями, как Claude Opus и Claude Sonnet.
*   **Редактирование текста:** Система генерировала текст в заданном стиле с меньшим количеством "галлюцинаций" и информационного мусора.

**Бизнес-модель и пользовательский опыт**

Fractal Agents планирует предоставлять свои услуги через чат-интерфейс и API. В ходе обсуждения был поднят вопрос о возможных временных задержках из-за многоуровневой архитектуры. Разработчики заверили, что для простых запросов используется быстрый классификатор, который оперативно направляет задачу нужной модели, а полная мультиагентная система задействуется только для сложных задач. Также была затронута проблема многословности LLM, которую предлагается решать через уточнение в промптах требуемого количества символов.

**Перспективы развития**

В будущем планируется расширять количество доступных агентов и LLM. Система будет обучаться на основе взаимодействия с пользователями для улучшения качества работы, при этом у пользователей будет возможность запретить использование их данных для обучения. Разработчики также рассматривают возможность решения более сложных задач, требующих длительных вычислений (до нескольких суток).

Желающие могут записаться на закрытое тестирование системы.



**Расшифровка доклада:**




S01 [00:00:00] : Да, коллеги, всем добрый вечер. Начинаем очередное заседание сообщества, русскоязычного сообщества разработчиков общего и сильного искусства интеллекта. Сегодня у нас в гостях Виктор Носко и Захар Понимаш. Они уже неоднократно рассказывали у нас на семинарах о своей разработке, и сегодня они расскажут о мультиагентной системе Fractal Agents AI-MAS. Виктор, пожалуйста. 

S02 [00:00:27] : Да, всем привет. Действительно, мы заявили о том, что мы делаем мультиагентную систему уже более чем полтора года назад. На текущий момент есть прогресс и есть что показать. Можно с точки зрения Продукта. Сейчас идет закрытый тест. И на этот тест можно записаться и попробовать кооперацию, коллаборацию агентов, то, как у нас это реализовано, и посравнивать с топовыми, известными игроками. Отдельную ссылку потом пришлем. Если кто-то сделает такое желание, то это вполне возможно сделать. Но сегодня расскажем про технологию, какие мы используем подходы, как мы модифицировали известные подходы к маркетизации агентов, ну и покажем, собственно, как это работает в типовых кейсах, в обычных задачах наших, наших ежедневных задачах, которые мы все пытаемся решить. используя ChGPT, DeepSeek, GigaChat, но и вы все знаете эти LMK. Вообще, в целом, давайте я начну с того, что проговорю некоторые моменты. Думаю, что их и так все знают, но на всякий случай, если кто-то не в курсе текущего развития технологий, особенно LMK, не следил, то важно понимать, зачем нужна вообще говоря мультиагентная система, почему эта концепция, она имеет такой большой существенный хайп в интернете, выходит большое количество статей. Ну и вы видите в телеграме, там каждый день выходят какие-то решения для кодинга. Почему, собственно, такой существенный интерес прикован к этой теме? Во-первых, в мультиагентной системе вы можете просто на естественном языке сформулировать задачу, и вся работа по декомпозиции этой задачи, по планированию очередности вызова различных агентов и тулов, Всю эту работу может взять на себя мультиагентная система, в отличие от известных LN, где вы вынуждены часто писать промпты, формулировать и строить эту цепочку самостоятельно. Но это достаточно тяжело. У вас есть естественный языковой интерфейс, то, что мы называем просто поле чата, куда вы можете вписывать достаточно сложные задачи, достаточно сложные промпты, которые могут содержать в себе много задач. через запятую или несколько предложений вы описываете эти задачи. Есть ROLM языковые модели, не только ROLM, которые обрабатывают ваш запрос. Есть логический вывод, есть, извините, как вы знаете, размышления, планирование. и по-разному оно может быть реализовано, и есть, собственно, агенты. Под агентами мы понимаем модули, которые способны договариваться, кооперироваться, быть достаточно автономными для того, чтобы решать пользовательские задачи. Ну и частный такой случай агентов – это тулы, которые можно вызывать в доступ к каким-то сервисам. То есть агенты могут быть неинтеллектуальными, ну и не очень интеллектуальными. Я здесь подсвечу некоторое количество проблем, с которыми люди сталкиваются, когда они пытаются ставить задачи в известных сервисах. Часто многошаговые задачи требуют несколько LN. Одной LN вы не можете решить задачу, нужно использовать несколько. Когда вы используете несколько языковых моделей, переключаетесь, например, между интерфейсами или используете какой-то конструктор, где вам нужно мышкой, собственно, повыбирать эти разные ленки, то у вас возникает проблема того, что ошибка нарастает при увеличении количества шагов, которые у вас присутствуют в вашей задаче. Часто пользователь вынужден сам составлять план решения конечной задачи. Типовой пример, когда вам нужны ответы по документации, но вы не разбираете, что такое векторная база и, собственно, не можете понять, в какой момент нужно вызывать этот тул. То есть даже когда конструктор у вас есть, в принципе, нужно обладать все-таки знаниями того, как выстроить план решения для того, чтобы все это технически работало. Подбор составления промтов. Все мы с этим сталкиваемся. Действительная проблема. Я сам часто ленюсь писать оптимальный промт. Хотя я знаю, что есть статьи о том, как для каких торслей правильно писать промты, как там указывать роли. Но эта задача достаточно такая муторная и рутинная. И несмотря на то, что я технически подкован, знаю, как это делать, Ленюсь это делать, уверен и просто знаю по отзывам, что многие люди просто не делают этого тоже. Просто говорят, реши мне вот эту задачу и не пишут, что ты там великий математик, ты великий стратег. философ и прочее. Соответственно, они получают хужее решение, чем то, которое мы на самом деле могли бы получить, если бы использовали такие модификации. Ну, естественно, забегая вперед, понятно, что агенты могут это все делать, они могут у себя взять эту задачу. Ну и существующие сервисы-конструкторы типа Flowwise, QAI, Luchain, они тоже вам помогут в этом, потому что нужно в этом разбираться, нужно правильно устраивать цепочки. Ну вот здесь визуально показано то, где возникает проблема. Это один из сервисов, где вы можете с помощью конструктора собрать себе некоторое типовое решение, но к сожалению более 80 процентов работы в SLM вы потратите на рутинные задачи, на то, чтобы сформулировать пункты, на то, чтобы проверить результаты, потому что результат у вас хороший сразу не получится, поэтому вам нужно будет делать несколько тестов, тираться, то есть вы по сути превращаетесь в такого разработчика. Да, конечно, это low-code или no-code разработчик, но в целом вам нужно правильное соединение различных моделей сделать самостоятельно. Но это трудоемкая задача. Если вы посмотрите на квен, дипсик, chargePT, то у них есть такие кнопки как мышление и поиск. Сейчас базовое решение всех современных сервисов это то, что вы можете в принципе выбрать. мышление поиск или вместе но когда и в какой момент это сделать часто на самом деле мышление не требуется или вам не требуется поиск и опять же на пользователя сбрасывается ответственность на правильный выбор на правильное включение по сути вот этих вот агентов для того, чтобы получить конечный результат. Если вы просто будете всегда включать, чтобы получить более крутой результат, то это означает, что да, вы получите более качественный результат. Скорее всего, это часто будет вам не нужно и вы будете ждать просто дольше. А если вы используете какой-то платный инструмент, это будет в действии 300 раз дороже. Просто дороже по деньгам. Поэтому на самом деле не стоит всегда включать мышление, ризнинг, чтобы он там работал и чтобы это self-reflection постоянно себя перепроверял. Это часто не требуется. Далее о технологиях и подходах, которые используются у нас в разработке. И здесь я давайте сейчас кратко скажу, что сделано у нас на текущий момент и передам слово уже Захару. Он расскажет про технические детали. У нас сейчас на текущий момент подключено 8 агентов. Это агент поиска в интернете, это у нас есть суммаризатор, у нас есть РАК-система, продукт, который у нас ранее был уже разработан. То есть все темы для ответов по документации. И в целом преимущества вообще нашей разработки относительно остальных, они в следующем заключаются. Здесь такие основные базовые тезисы. Первое это топологии. Мы используем различные топологии вызова агентов в зависимости от сложности задачи пользователя. то есть вот эти подходы REACT, REW, когда можно перепроверить выдачу, ответ LM, для того, чтобы его улучшить, например, или сделать действие и построить цепочку в зависимости от той информации, которая была найдена, например, в интернете. В общем, эти топологии могут быть разными, они имеют разную стоимость, и важно выбирать их правильно и оптимально в нужный момент времени, чтобы это просто было не очень дорого. То есть, если это дешево, то вы можете получать некачественный результат своей задачи, но вы просто как пользователь будете злиться, что я попробовал какой-то известный сервис, но он мне нашел просто не те сайты. Релевантность неправильная. Я часто с этим сталкиваюсь, например, в перплексите. Он просто находит не те сайты. И это означает, что агент, который отвечает в целом за релевантность моей отрасли в кейсе с моим запросом конкретным, он отрабатывает недостаточно хорошо. И вот этот цикл улучшения, обогащения моего, например, запроса правильное обобщение моего запроса для того, чтобы мы правильно поискали. Вот этого цикла не происходит, и поэтому я получаю результат хуже, чем мог бы получать. Мы классифицируем задачи по сложности, ну и в зависимости от сложности Используем разные подходы, которые или дороже, или дешевле, соответственно, выигрыш здесь очевиден с точки зрения стоимости. У нас выбираются агенты. Агенты у нас выбираются динамически. На текущий момент это 15 LLM. То есть это количество небольшое, мы будем это количество расширять, но в целом это уже в принципе неплохо. Это топовые LLM, которые вы все знаете. Они отличаются, конечно же, по качеству, по скорости до первого токена. Важно выбирать эти агенты в зависимости от запроса пользователя. Критерии, по которым мы этих агентов выбираем, мы выбираем, оценивая качество, скорость и время выполнения задачи пользователя. вот решение гипре счетч например да где вы можете полчаса ждать какого-то огромного отчета окей вы можете получиться ждать но я неоднократно видел в интернете жалобы на то что я прождал полчаса и там получилось чепуха вот конечно люди не хотели бы с этим сталкиваться так дальше я передаю слово хорошо 

S00 [00:11:31] : Да, я слышал. Да. Здесь показано преимущество мультивалентной системы по сравнению с LLN workflow. Основное преимущество заключается как раз таки в том, что в нашей системе есть такая вещь, как баланс качества, стоимости и времени запроса. То есть мы выбираем, она считается лишней суммой, качество и стоимость, деленные на время. Коэффициенты подбираются с помощью координатного метода, что обеспечивает соответствие пользователя ожидаемым качеством, которое хочет пользователь. То есть меньше денег тратится в среднем, при этом получается более качественный ответ. Кроме того, из-за того, что в системе есть маршрутизация на большое количество LN внутри каждого агента и на большое количество агентов, мы можем довольно сильно масштабироваться и выполнять узкоспециализированные задачи на агентах, которые хорошо выполняют, например, только эту маленькую задачу, а остальные могут плохо выполнять или вообще не выполнять. но при этом у нас будет среднее качество ответа нашей системы по максимальному качеству ответа каждого агента, что существенно повышает качество по сравнению с другими подходами, в которых среднее качество ответа, оно просто равно среднее качество ответа какой-то LN, либо чуть выше при использовании таких подходов, как тот же Moa. Следующий слайд. Здесь приведена схема нашей мультиагентной системы, базовая. Мы базируемся на таком понятии как граф. У нас есть граф агентов, который эволюционирует во время выполнения задачи. И здесь эта схема показывает, как устроится изначальный граф. То есть у нас есть некий запрос, естественный языковой интерфейс, который оценивает провод и понимает, каким параметрам должен соответствовать ответ системы. Далее генерируется обобщенный граф, а потом генерируется в участвительных графах. Ну, в определённом графе у нас группы агентов, представленные ребрами, а в участвительных у нас это депошутизация на конкретных агентах. И далее у нас идёт блок запуска вычислений. Также мы находим необходимые нам инструменты для выполнения вычислений и собираем непрерывно датасет, который показывает основные метрики системы, позволяя, ну, в тюнинге, как я уже говорил, коэффициенты качества, скорости, стоимости работы и другие подобные гибрид-параметры системы. Следующее. Здесь показано, почему навигационная система, это будет На мой взгляд, следующая большая такая система, которая следующий этап произойдет искусственно-директор, поскольку у нас до этого, вот, предыдущий этап, он был сконцентрирован на LLM, потом на агентах, и вот сейчас мы видим, что идет переход к новигенную систему, где Больший фокус смещается на правильный выбор агентов. Дело в том, что выбрать нужного агента – это довольно сложная задача, поскольку, например, может быть такое, что у нас есть 3-4 более агентов, с одинаковым описанием. Либо может быть такое, что описание нового агента намного лучше, чем описание другого агента, особенно, когда вы пользуетесь добровольцами своих агентов. Но при этом, вызывая одного агента, мы добьемся более высоких результатов, даже если его описание было более скромным. И вот здесь, чтобы правильно выбирать этих агентов, кроме того, чтобы вести переговоры между агентами без экспоненциального расширения контекста, требуется новый метод, который мы, в принципе, и разработали. И вот мы видим, что это очень большая проблема правильного выбора агентов и трассировки задач у агентов. Следующий. Здесь показано исследование рынка, то есть Мы видим, что вклады и агентов для ОВП составят порядка 2,64 миллиона к 2030 году. Это у нас следующий шаг. Получается, это многоагентная система. То есть, чем лучше, конечно, многоагентная система, чем лучше каждый агент, тем лучше и многоагентная система в целом. Но кроме того, нужно учитывать также, что все-таки очень большую роль играет наш оптимизатор. мы можем иметь довольно слабого агента во всех областях, кроме какой-то одной области. Именно вопрос из этой узкой области, она может быть также, ну, как бы, ее описаемой ключевочайством, естественно, результатом, с чем промпли не справятся. Но вот именно маршавизация туда приведет к тому, что мы получим наилучшие результаты. И вот основная проблема — это все-таки создать систему, которая позволяет маршрутизироваться на лучших агентах для каких-то больших узких задач. Поэтому что важно для того, что сейчас идет рост количества агентов, то есть можно выключать чужих агентов в нашей системе. Кроме того, вторая важная вещь, которая решена была. Мы полностью сделали спецификацию на агентах, что такое агент, из чего он состоит, его модули, и упростили его анборнинг. То есть сейчас мы можем своих агентов делать очень быстро анборнинг, и в будущем мы смогем сделать так, чтобы люди могли созвать на нашей обоенной системе тегивы агентов, тоже выполняли очень быстрый онбординг. И опять повторюсь, что AssignLions работал с более точной маршрутизацией, недостижимой только правдами. Следующий слайд. Технологии подхода агента, на каких основаны агенты в нашей системе, это в основном реакты или U-подобные технологии. Здесь показаны примерно, как они работают, их блок-схема. То есть реакты небольшое-то произношение, после чего выбирается инструмент, выполняет действие, здесь возвращается результат, выполняет действие, и вот такая цепочка, она довольно долго может идти, но это обычно ограничивает какие-то ассоциативные шаги. Реву изначально строит большую цепочку вызова инструментов, после чего они вызываются и после этого переходят в для этой категории решений. Reboot тратит примерно 8 раз меньше токенов, чем React, при этом не сильно уступает ему по качеству. Кроме того, как я уже там показывал ранее, что у нас есть граф решений, для того чтобы его построить, мы используем свой внутренний язык Kumaso. Multi-Agent System Leverage, который мы разработали специально для этой задачи. Так, следующий. Кроме того, существуют и такие подходы, как MOA — это Mix of All Agents. Данный подход основан на том, что у нас есть, по сути, многослойная архитектура, где в каждом слое находятся LLM либо агенты, после чего есть некий агрегатор с слоем, и результаты вот этих вот... то есть у него есть оркестратор, модели, которые решают задачи. Например, может быть там одна, например, гейминг, другая, там, сонет или еще какая-нибудь. и на выходе происходит агрегация решения. После этого таких блоков может быть довольно много, и каждый следующий блок улучшает выходы предыдущего. Что можно отметить, что в такой системе, в отличие от классических многогетных прокладов, нет так называемой проверки достижения консенсуса. Также данные теряются в определенном контексте, и вот с согласованием происходит разным способом. Например, один из способов — это логинженшин, это судья, либо агрегация с разных выходов, что может привести в некоторых случаях к регалистрациям, особенно в тех случаях, когда ответ агентов разный. Следующим. Следующим подходом является модель дебатов. В данном подходе уже есть модель датевых консенсусов. Это находится несколько агентов из KLM с различными ролями. То есть может быть роль критика, который не согласен с решением. Роль, которая выдает гипотезу. И цитрически происходят переговоры по поводу одной задачи. Проблемой Такого подхода является при его дополнительной реализации, что у нас эксконенциальная сложность переговоров и к тому же быстро растущий контекст, поскольку каждый с каждой переговаривается, если мы этот контекст передаем дальше, то у нас Общая сложность, нужно сказать, что если есть некоторая сложность самого решения, то есть это вызов на длине контекста L нейронки, то общая сложность будет как сложность этого вызова на длину... на количество раундов и на количество вызовов. Есть подходы, которые позволяют уменьшить такую сложность, например, ограничение контекста. Когда контекст ограничивается... контекст ограничивается некоторым объемом, и тогда не происходит роста самого контекста. Другой подход — группировать в блоки, что тоже позволяет избежать кондиционерного роста, но рост идет уже по количеству блоков. Так. Следующий слайд. Также имеется подход, когда объединяются модели в ансамбле. По сути, мы это видели также в подходе Mo, когда тоже были объединены в ансамбле несколько моделей, после чего принималось решение о том, какая модель именно отвечает. Точнее, какая модель была права, либо MOA может отреагировать и ответить на нескольких моделей в один ответ. Здесь примерно та же самая задача стоит перед самой моделью следующей. Возвращаясь к MOA, иногда говорят, что эта архитектура родственная к архитектуре MOA, это Mixed Role Experts. Но на самом деле это не так, поскольку в архитектуре Mixed Role Experts имеются не различные агенты, а различные модели машинного отключения, которые объединены вместе. в отличие от агентов, это не выход какой-то решенной задачи, а получается каждая... ну, если мы берем там стандартно, как было предложено Moe, именно для агрегации моделей, это была задача распознавания образов. то выход — это были роботисты классов, которые соединялись уже с алисами, выставленными вот этим вот MixOfExperts моделью Routing, что существенно отличается от работы агентов, когда внутри происходит рассуждение, и мы не просто соединяем какие-то разные алисами, а выполняем условную задачу, Мы используем свой подход, назвали его GCR. Это генератор критик ревьюе. Также у нас есть генератор критик, как в Slot Reflection подходах. И далее ревьюер, который может переписать выход этого генератора критика для того, чтобы согласовать его с следующим словом. У нас также есть разделение, поставим как FOMO. Единственное, что генератор наших агентов либо в формате React, либо в формате Rule, после чего корректика оценивает и сам подход, и как используется инструмент, насколько правильно. Далее, когда эти цифры завершены, называется rewrite, после чего мы передаем это на следующий шаг. Кроме того, мы используем алгоритм достижения консенсуса, который мне предполагает переговоры на естественном языке, переговоры с маслом, что позволяет нам уйти от экспоненциальной сложности, не потеряв контекст. Мы протестировали нашу систему на нескольких Один из кейсов — это импортитолог, где мы попросили найти ровно 100 компаний, найти их адреса, почты, ну и сравнивали это с P2P-системой. В результате вот наша система запрос выполнила на P2P-системе. Нашло меньшее количество компаний. Следующий. Кроме того, тестировали на вопросы с математикой, сравнивали с топовыми HLM. То есть здесь показан запрос, когда попросили учителя. сравнивали с такими LN, как Cloud Opus 4.1, Cloud Sonnet 4.5, получили доступ через OpenRoute и нашу систему. Далее вот здесь показаны сами решения. И анализ, насколько у нас альтернативное выравнение выходит от нуля. То есть если мы берем Cloud Opus и Cloud Sonnet, это в районе двух усоединений по трем корням. То есть мы брали в ограниченной-то степени, у него получается два вещественных корня. комплексы с аббревированными корнями. Мы взяли одно из комплексов с аббревированными, поэтому здесь еще три, и получили, что наш агент решил вот с точностью 0.016. При этом округление мы брали до одного и того же знака после запятой, что дает нам более точное решение. Существует другой подход, когда ставится капитал Пайден и решается с помощью него. Но у нас в агентах используются послеспециализированные инструменты, что позволяет уменьшить вероятность галлюцинации, в отличие от написания на Пайден дословной задачи. Кроме того, Более безопасная следа и больше параллельности можно обеспечивать у запросов, поскольку сами эти инструменты достаточно легкие, и каждый агент обладает либо одним, либо несколькими инструментами, которые он может использовать. Так, следующий. Следующий фейс, который мы тестировали, это редактор. То есть мы можем запросить генерацию текстов в денном стиле, после чего получаем такую генерацию. Пробовали то же самое делать на других LLM, то есть мы использовали Clang, в результате В этом мы выделили довольно много галлюцинаций и информации, мусор, который не генерирует наш вент. Далее. Здесь мы сравнили несколько подходов. Это количество сборок при одном и том же количестве агентов. Сравнивали наши решения с решениями Lama Workflows, Serena Remising, Agent Flan, Harbinger PT и Movasi AI. Мы получили, что у нас сборок примерно настолько получается, сколько и у но при этом они автоматически собираются. Быстрый анборнинг агентов возможен. Время адаптации под пользователей новостей происходит за счет обучения как старых агентов, так и системы маршрутизации. на базе событий будут построены, и адаптация не происходит. Agent, Optimizer, Agent Client. Там есть, получается, оптимизация. Huggins, GPT, может быть, оптимизации нет, поскольку ориентируется на количество звезд, полностью сейчас используется модель. И Flowwise собирается вручную, поэтому в оптимизацию стандартической сборки тоже не приходится. Геометрия галлюцинации мы используем в своих подходах для контроля галлюцинационных уменьшений, обеспечивающих самую низкую галлюцинацию. LAMA индекс также позволяет задействовать квалификации, поскольку они используют довольно плоский представительный граф, переход, по которому они заценили, ну, по сути. Agent-analyzer, Agent-LAMA, у них чуть повыше эти квалификации, и Helen GPT, А на среднем уровне, по конкретной сценации, flowwise может быть между средним и низким уровнем. Потому что зависит от человека, который собирает цепочки, как он заценивает цепочки. Если человек опытный, то будет. Практически не будет. Если неопытный, то будет довольно часто. Автосборка по задаче, да, у нас есть, это основная наша фишка. В llama-индекс, там добавится, видимо, граф, это происходит. Далее, вот, adding-optimizer там используется, reflection. и tagging-repetitive-wise, там это все сделано. Именно для длинных цепочек и цепей графа. Метод обеспечения гибкости графа – это наш подход с коннекторами, плюс мы используем OOM-слушатель для того, чтобы базовую топологию какие-то расстройки, потом уже по ним устроена графика символями. То есть на базе обычной логики. Далее у нас LamaX используется. В Edge Optimizer используется только LN. без какой-то валидации и улучшений на базе графов. Проходящих идти LLN. Плюс используются здесь коры для инструментов для различных колонок, которые входят в состав LLN-графа. И HoloLens получается соединяется. Число типов коннекторов сейчас 15 используется вообще неограниченно. И измерение гей-графов, агентами выследств и фидбэка у нас веридованно. В остальных нет. Ну, и в PagedOptimizer, и в ng-plan частично, поскольку там есть некие получаемые модели. Следующее. Какие технологии мы разработали? Это, получается, У нас есть поиск документов, агентов и прочего. Мы включаем метрику, которая обучается пользователям, сами агенты, которые, например, пользуются переговорами на нашем внутреннем языке. что позволяет уменьшить длительность нации и избежать экспоненциального роста контекста и времени выполнения задач. Ну, а также есу, так сказать, входит в плане задач. Точность отцветов у него также внедрена для отцвета галлюцинации. Он внедрен для системы поисков по документам. На данный момент внедряем и диозы, и диагенты для того, чтобы избивать галлюцинации внутри своих рассуждений моделей. Реализовали иерархическую долговременную память. что позволяет улучшать качество работы у нас и помнить, во-первых, долгую последовательность, во-вторых, вот он, дальше, где-то 9-й пункт, у него также включили онкологию, которая позволяет строить связи на большое, чтобы при развернутии текста в нескольких слоях можно встретить общение. Сделали кэширование. Это алгоритм, который позволяет очень сильно ускорить выдачу ответов и вычисленность. Также применяли алгоритм детекции аномалий для того, чтобы определить, что может решить кэшер, а что не может. Суммаризация. Разработал алгоритм для суммаризации очень длинных контекстов. Я понимаю контексты размерами в несколько сотен тысяч слов. И антологии. Как я говорил, вы извлекаете далекие связи, В следующий слайд. 

S02 [00:39:56] : Ну да, здесь основная идея, я думаю, что нас многие знают, чем мы занимаемся. Но в целом мы занимаемся исследованиями, ресерчем. И выпускали в подсобственной библиотеке, в частности, где диабетические галлюцинации. Библиотека открыта. Конечно, она не такая популярна там, как решение антропика, который тоже занимается этой проблемой. Но, тем не менее, библиотеку могут использовать независимые разработчики, скачивание у них есть. Собственно, различные делали проекты, и коммерческие, и сейчас, в общем, сосредоточено на том, что хотим сделать мультиагентный искусственный интеллект. И доклады не только в нашем вашем сообществе AGI Russia, мы делали на самом деле по агентам на конференции AI Journey, делали конференции Сбера. раз тоже по агентам там рассказывали про математического агента но это было уже сколько полтора года назад вот собственно все я сейчас отправлю ссылку на тест если кто-то захочет можете ставить заявку на тест очень простая формата очень легко и запомнить ну и собственно готовы ответить на вопрос 

S01 [00:41:18] : Да, коллеги, спасибо. Если у кого-то из присутствующих есть вопросы, то у нас народу немного, поэтому просто включайте микрофон, задавайте. Вот, пока включайтесь, у меня вот здесь вот несколько вопросов. Значит, первый вопрос, вот то, что вы предлагаете тестирование, а вот то, что вы делаете, значит, я понимаю, это же бизнес, как полагается, да? Бизнес-модель у вас какая? То есть вы будете предлагать чат-интерфейс? И АП, правильно я понимаю? 

S00 [00:41:47] : Ну, по сути, да. 

S01 [00:41:50] : Окей, вот. Следующий вопрос, пока других нету. Вот смотрите, значит, у меня, да, вот мой собственный опыт, который есть в процессе работы с большими языковыми моделями, значит, это то, что это очень медленно, да. То есть, допустим, моя история такая, что если раньше я хотел получить какой-то ответ на свой вопрос, Вот, я набирал, значит, я видел некоторую выдачу, вот, и у меня, значит, возможно, проходило какое-то время, значит, на то, чтобы найти нужную ссылку, и, возможно, первая ссылка оказывалась нерелевантной, и я ее приходилось брать вторую, и на второй ссылке, возможно, приходило проматывать страницу, значит, и находить это все. Но, по крайней мере, я чувствовал себя, что я занят, да, вот, и не было, значит, ощущения потраченного времени. А сейчас практически всегда, когда я задаю какой-то вопрос, я сталкиваюсь с тем, что система очень долго печатает и очень много. Я задаю простой вопрос, как мне, грубо говоря, сделать, решить какую-то грубо говоря, как воспользоваться какой-нибудь питоновской функцией. И она начинает писать сочинение о том, что с этой питоновской функцией можно сделать в одном случае или в другом. И это медленно набивается на экране. Вот я сижу и жду, когда же она наконец хочет писать. И это, в общем, выбешивает, честно говоря. То есть мне проще было бы наткнуть stack overflow или получить мануал. И воспользоваться этим. Вот, соответственно, вот первый мой вопрос, значит, что если мы поверх вот этого всего еще и навешиваем мультиагентность, да, то есть сначала мой вопрос идет в мультиагентную систему, которая решает, а кому достанется мой вопрос, а потом это идет к тому агенту, а потом от этого агента возвращается вам, а потом от вас возвращается мне. не возникает ли здесь негативного пользовательского опыта, связанного именно с временными задержками? 

S00 [00:43:53] : На данный момент у нас сейчас обучаются классификаторы, которые будут еще быстрее работать, но сейчас есть классификаторы, которые мы смогли сделать где-то в 12-100 раз быстрее, чем классификаторы просто на базе LLM мы сейчас тоже используем LLM в качестве основы, но мы не генерируем ETX. Поэтому сама классификация происходит быстро, а дальше уже идет выбор конкретной, получается, модели, на которую маршрутизация происходит. Если вопрос простой, то мы отвечаем быстро на него. Про свою модель довольно короткий ответ. Если вопрос... то, да, запускается полностью у нас, либо один агент запускается, но это зависит от того, насколько сложный поиск будет. 

S01 [00:44:47] : Я правильно понимаю, что в простом варианте, когда нужно просто сделать редирект какой-то или лемке, вы используете простой векторный поиск, и это будет, это предполагается быстро? 

S00 [00:45:01] : Ну, не векторный поиск, потому что по-другому, но в целом, да. 

S01 [00:45:04] : Окей, а тогда уж сразу заодно, значит, у меня там в другом месте был вопрос записан, а вообще вот вы видите как-то проблему решения, значит, вот этой многословности LLM? Я просто в одном из проектов сталкивался с этим, да, то есть я там пытался сочинять промпты, что типа, пожалуйста, be concise, там, значит, мы не пиши лишнего, вот, ну, в общем, это не всегда удается, да. Иногда она действительно отвечает лаконично, а иногда ее прорывает, и она начинает писать сочинение. Есть какой-то опыт решения этой проблемы? 

S00 [00:45:39] : Да, есть. Во-первых, на уровне промптов это нужно сделать. На уровне чего? Ну, первая часть, там, можно сделать на уровне промпов. То есть не писать промп, что лаконичное, или еще что-то, а писать там в логических какое-то количество символов. Ну, там, сто символов, тысяча символов. И тогда, как бы, ответы чаще всего действуют по логическому количеству символов. 

S01 [00:46:12] : Спасибо. И тогда про промт еще один вопрос. Вы говорили про искусство написания промтов. А вот по вашему опыту, насколько эти промты переносимы? То есть, грубо говоря, если мы соптимизировали промт для клода, Условно говоря, насколько переносим этот промпт, окажется, если мы его захотим использовать в запросе для Квена, и насколько у вас эти промпты универсальны, либо наоборот, каждый набор промптов специализированных под каждого агента. 

S00 [00:46:48] : Я могу задать этот вопрос. Промпты практически непереносимы, поскольку оптимизированный промпт в конкретной модели, он будет как бы давать средний результат на всех своих моделях. Поэтому у нас большая такая, такой пласт работы — это выбрать группы агент-промпт, потому что Если у нас оптимизация по одному модели, то он по другому же не будет работать. Объясняется это очень просто, поскольку промпы в конечном итоге преобразуются в последовательных короб, и веса модели, они всякие различаются, и вот эти вот векторы, какие они преобразуются, могут выдавать, имеют вообще другой какой-то смысл. Если есть доступ к самой модели, то, конечно, есть более правильный подход. Это подход, вызываемый питюнингом, когда заменяется, вместо брампа, просто несколько векторов, либо один вектор, и дальше Берется датасет, в котором есть входные задачи, выходные ответы. Вся модель заморавливается целиком, и обучаемо заверяются только эти векторы. Дальше обучаются так, чтобы эти векторы выполняли роль промта. И тогда, конечно, идеально соответствуют свои конкретные задачи. 

S01 [00:48:20] : Угу, спасибо. И тогда уже разу вопрос еще, извините, про промты. Я правильно понимаю, что есть как минимум два кейса у вас, поправьте меня, если я не прав. Первый кейс, я, допустим, не хочу там заморачиваться с промтами, Я говорю, хочу код ревью на плюсах. И вы смотрите на этот запрос с помощью векторного поиска, находите, что код ревью на плюсах лучше всего делает, допустим, Клод. У вас уже пригодна она fine-tuning промпт, который делает код-ревью на плюсах, вот, и вы, соответственно, перебрасываете мой запрос соответствующим промптом к коду. Это первый кейс, как я вижу. Вот. А второй кейс может быть такой. Я говорю, что я хочу сделать код-ревью, допустим, с помощью чат-жпт. Вот. Напиши мне на плюсах, да, пожалуйста, напиши мне промпт для значит, код ревью к лодам на плюсах, и вы смотрите, кто сделает этот запрос, выясняется, что этот запрос лучше всего делает Квен, вы присылаете мой запрос Квену, Квен пишет мне, ну, допустим, Квен, да, Квен пишет мне промпт, и я радостно с этим промптом ухожу, значит, к своему клоду или там, кому я, значит, сказал, и даю, попрошу его этим промптом сделать код ревью. Правильно я понимаю? 

S00 [00:49:47] : Со вторым нет, поскольку, ну, именно в этом ревизии этого нет, поскольку это довольно сложная задача написать пронты. В большинстве случаев используются, ну, всякие подходы, по-моему, билдера, которые предполагают, что генерация пронта может занять, там, сутки и больше. То есть, как это работает, генерируется некая генерируется некоторая популяция промков, имеются некоторые задачи, после чего выполняется сревой, как вы сказали, NGPT. Вот в NGPT выполняются все эти задачи, оценивается результат, потом происходят мутации, скрещивание вот этих вот промков. И вот таким образом повышается качество выполнения этого результата. Вот этот подход называется промблендорф. И так как сами лмки они медленные, а все мутации и скрещивания не происходят именно на лм, то из-за этого меня спромта могут занять очень большое время. 

S01 [00:50:57] : Ну то есть, функцию написания промта вы сейчас не предоставляете, правильно? У вас нет агента? 

S00 [00:51:04] : Нет, если вы задаете вопрос, он, конечно, напишет, но говорить, что он будет оптимальный, мы не можем, потому что для того, чтобы сделать его оптимальным, как я уже говорил, эта задача может выполняться на сутки или даже больше. Вот наивысший алгоритм, который позволяет решать эту задачу, они базируются на, получается, генетических алгоритмах, генетических англограмм и прочее. А генетические алгоритмы предполагают, что фитнес-функция, что функция процедура, скрещивание точки, функция мутации, они все будут сделаны на базе LLM, и LLM довольно долго это выполняет, и поэтому такая задача, чтобы она именно оптимально решилась, то есть нужен критерий оптимальности, который, ну, это как раз-таки фильтры с функциями, может быть, с какими-то приоритетами, то есть какая-то функция, которая берет вывод, в общем, Выход от LN-ки оценивает скорость. Есть теоретики по скорости еще. Чтобы это все учесть, нужно довольно много времени на саму обработку. Мы сейчас рассматриваем задачи, которые можно решить до двух часов работы. То есть задачи, которые решаются на сутки, двое суток, мы пока не рассматриваем, но в будущем планируем. 

S01 [00:52:37] : Ну, то есть, сейчас у вас это функционало по-честному нередизовано, правильно? 

S00 [00:52:42] : Да, просто как обычная ллм-ка напишется. 

S01 [00:52:45] : То есть, она найдет какую-то ллм-ку, которая с вашей точки зрения оптимальна для написания промптов, но вы не будете гарантировать, что это промпт адекватный, правильно? Да. Хорошо, вопрос от Лины Бессоновой. Будут ли агенты обучаться обновлять свой личный скилл на основе своего участия в бизнес-проектах и решения вопросов? 

S00 [00:53:09] : Отлично. Вообще, по умолчанию, да, будут, но мы планируем сделать такую галочку, которая больше может запретить использовать его. в обучение мгновения, если он запретит, то не будет. А если не запретит, то будет. 

S01 [00:53:26] : То есть я правильно понимаю, что у вас реализовано то, что, значит, не знаю, как это принято называть, кстати, может быть, подскажете, да, вот, обсуждали эту тему на семинарах, на семинаре, точнее, Павла Соловского, да, я это называю, значит, активный рак, да, когда мы не только из контекста, значит, беседы подсасываем информацию в промпт и в контекст, А когда, ну, то есть, либо подсасываем ее в контекст, либо, так сказать, формируем ее в пронт, что, по сути, примерно одно и то же, как я понимаю. Тоже поправьте меня, если я не так. Но и извлекаем информацию из сессии, да, то есть, грубо говоря, если мы получили какую-то информацию из запроса пользователя, из ответа LLM, мы ее помещаем в некоторую долговременную память или там из нее извлекаем какие-то, значит... Да, в долговременную память она помещается в любом случае. 

S00 [00:54:18] : Вопрос в том, что если другой пользователь задаст вопрос, то долговременная память, она для конкретного пользователя. А если этот пользователь, с кем был диалог, он поставит, что он разрешает использовать данные для обучения, то долговременная память, которая у него есть, она не передается никому. Ну, то есть нет никакой передачи, даже если вот там разрешить, не разрешить, потому что это вообще не эти черты. происходит именно оптимизация самих параметров вызова. То есть вот параметры вызова на его задачи обучаются, но это, получается, всякие одна там... ну, там, несколько матриц и векторов, которые, ну, напрямую данные о задаче не хранят. Но если он откажется, чтобы его данный прикорд поучаствовал в улучшении системы, то этого не будет происходить вообще. 

S01 [00:55:08] : Я правильно понимаю, что по умолчанию вы контекст пользователя записываете в пользовательскую сессию и храните там, условно говоря, вечно как долговременную память, привязанную к пользователю, значит, если пользователь там не скажет, что, пожалуйста, не храните мою память, правильно? А в каком виде вы это храните? Вы храните просто логи и как-то их анализируете? 

S00 [00:55:33] : Я показывал на слайдах, что используются антологии для длинных взаимосвязей. То есть вы можете сказать в одном предлоговении часть информации, Пройдет 10, 20, 30 сообщений, тысяча. Вы скажете, что большинство информации соединится за счет того, что антологии хранятся. Это вот еще сам религийский дневный бинокл. А вторая часть это когда хранится в виде иерархической памяти. Иерархическая память? Иерархическая память. Просто логи если хранить, то не получится вертолетец обеспечить. Мы больше понимаем, что это ЛМТ. 

S01 [00:56:28] : Вы из этой памяти в контекст подсасываете информацию, которая соответствует контексту текущего запроса, правильно? Конечно. Хорошо, спасибо. Вопрос от Дмитрия Свириденко и Шелест. Мозгами ваших агентов являются ЛЛМы. Думали ли вы в сторону ролевых задач, где роль состоит из автономных, адаптивных, киберфизических агентов? 

S00 [00:56:59] : Киберфизических имеется ввиду роботов? Ну, видимо, да. Думали, но сейчас это не реализовывается. Ну, мозга является не только LLM, но и алгоритм, который на базе формальной логики работает. Потому что только LLM часто функционирует, мы комбинируем эти подходы. 

S01 [00:57:25] : А у меня еще такой вопрос. Вот вы используете, вот вы сказали там 15 или 20, сколько у вас разных агентов используется, значит, это все… 8 агентов, 8 LLM. 

S00 [00:57:36] : А, 8 агентов, 15 LLM. 

S01 [00:57:39] : Восемь агентов, пятнадцать ЛЛМ. А как это восемь агентов на пятнадцать ЛЛМ? 

S00 [00:57:48] : Агенты включают в себя не только ЛЛМ, но и внутреннюю базу знаний, методы расследования. либо Ригу, либо еще кто-то. Каждый агент может вызывать любую из 15 ЛЛМ. 

S01 [00:58:14] : То есть вы подбираете, куда направить запрос в двумерном пространстве, где по одной оси агенты, а по другой оси ЛЛМ. То есть, грубо говоря, вы можете послать агент код-ревью, сделать агент код-ревью в Ляме, а можете сделать код-ревью в Квене, правильно? Да. И тогда вопрос, вот эти 15 лием, это все облачные или какие-то у вас в кустах есть? 

S00 [00:58:43] : У нас есть на нашем сервере, но пока облачные используем, поскольку мастерировать сложно. 

S01 [00:58:55] : Понятно, окей. У меня все вопросы. Коллеги, есть какие-то еще вопросы в нашем виртуальном зале? Нет вопросов? Да, хорошо. Если вопросов нет, тогда всем спасибо за доклад. Спасибо, Виктор. Спасибо, Захар. Спасибо всем участникам, которые задавали вопросы и слушали. Будем ждать новых встреч с вами в следующем году с новым развитием вашего проекта. Большое спасибо, до свидания. 







https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
