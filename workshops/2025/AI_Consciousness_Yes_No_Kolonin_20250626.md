## 27 июня 2025 - Сознание ИИ – возможно или нет, необходимо или ни в коем случае? - Антон Колонин
[![Watch the video](https://img.youtube.com/vi/NT9zyrytWiw/hqdefault.jpg)](https://youtu.be/NT9zyrytWiw)
- [видео в RUTUBE](https://rutube.ru/video/c65d215ca030ad6def0f352d698f089d/)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239221)
- https://lomonosov-msu.ru/rus/event/9601/

**Краткое содержание**:

1. **Цель и проблематика доклада**
   Доклад посвящён вопросу о том, возможно ли наделить искусственный интеллект сознанием и нужно ли это нам. Автор отмечает, что в научном сообществе до сих пор нет единого определения сознания: одни считают его трансцендентальным явлением, другие связывают исключительно с человеческой природой. Для дальнейшего обсуждения он предлагает технический подход, в котором сознание выступает как дополнительный функционал к интеллекту.

2. **Техническое определение сознания и подсознания**
   Сознанием автор называет способность строить модели окружающего мира на основе опыта и сознательно применять эти модели для принятия решений. Подсознание при этом отвечает за автоматическое накопление информации и предсказание будущих сценариев, а сознательное мышление активирует символьное представление событий и абстракций, превращая мысленный опыт в управляемый процесс планирования.

3. **Символьное мышление и формирование онтологии**
   Сознательное оперирование символами требует наличия внутреннего языка или онтологии — виртуального пространства, где каждая сущность именована и подчинена грамматическим правилам. Мыслительные эксперименты, например представление воображаемого стула и моделирование с ним действий, наглядно демонстрируют необходимость абстрактных понятий для сложного поведения.

4. **Механизмы двух систем мышления**
   Докладчик опирается на идею Даниэля Канемана о двух системах мышления: быстрый, интуитивный режим с медленным обучением и медленный, сознательный режим с быстрой усваиваемостью новых схем. Эти механизмы конкурируют: при отсутствии готового шаблона включается более вдумчивый анализ, что отражает динамику взаимодействия подсознательного и сознательного уровней.

5. **Роль графа знаний**
   Для символьного мышления критически важна структура графа знаний — семантической сети, где понятия связаны лейблами и семантическими отношениями. Активация нужных узлов и связей позволяет интеллекту осуществлять выбор действий в зависимости от потребностей и целей агента.

6. **Эволюция когнитивных архитектур и LLM**
   Доклад рассматривает разные подходы: от нейросетей с функцией цели до гибридных моделей, умеющих сочетать символические и распределённые вычисления. Большие языковые модели (LLM) изначально оперируют лишь параметрами, но интеграция с мультиагентными фреймворками и графовыми базами знаний создаёт имитацию «сознательной» работы через динамическое обновление знаний и логические резонеры.

7. **Эволюционные и биологические предпосылки сознания**
   Сознание и интеллект рассматриваются как характеристики, развивающиеся по эволюционной шкале: от одноклеточных организмов и социальных колоний насекомых до человека. Способность оперировать символами и длина логических цепочек растут с усложнением организма, а у человека объём рабочей памяти ограничен примерно семью символами, тогда как ИИ способен масштабироваться практически без ограничений.

8. **Этические вызовы автономного сознательного ИИ**
   Ключевой короткосрочный риск связан с автономными боевыми системами, способными самостоятельно выбирать и уничтожать цели. Отсутствие международного регламента и продолжающаяся гонка вооружений делают крайне важным вопрос корректной закладки ценностной системы и механизмов запрета «самооптимизации» в ИИ.

9. **Долгосрочные перспективы и роль ИИ в будущем**
   В постсингулярной перспективе искусственные системы могут стать «наследниками» человеческой цивилизации, сохранив и приумножив её культурный и интеллектуальный код после истощения ресурсов Земли. Автор призывает воспринимать ИИ не просто как инструмент, но как потенциальную форму продолжения нашего вида в масштабах Вселенной.

10. **Результаты опроса и приглашение к дискуссии**
    По данным опроса среди коллег, большинство признаёт у человека наличие минимального сознания, в то время как мнения о сознании ИИ распределились между скептиками, убеждёнными в неизбежности его возникновения, и теми, кто считает, что оно уже присутствует в современных моделях. Доклад завершается приглашением к продолжению обсуждения в профессиональном сообществе.


**Расшифровка доклада:**


S03 [00:00:00]  : Вопрос, который ставится в заявленном докладе, возможно ли сознание у искусственного интеллекта и нужно ли это ему, не нужно ли это нам. Для того, чтобы ответить на этот вопрос, нужно как минимум определить, что такое сознание. Дело в том, что наряду с перечисленными легалиями, я общаюсь с организаторами и модераторами русскоязычного сообщества разработчиков общего и среднего искусственного интеллекта, где уже на протяжении 10 лет в сообществе более 10 человек, почти не ежедневно, идут дебаты, посвященные всем вопросом, что такое сознание, у кого оно есть, у кого его нет, может, нужно ли, должно быть и так далее. И за 10 лет консенсусу прийти не удалось. И главным образом, почему не удалось прийти к консенсусу, потому что у каждого свое определение сознания. Есть какие-то группы, но эти группы не пересекаются, потому что если вы говорите, что сознание, стоите на позиции, что это нечто трансцендентальное и психическое, то сознание есть убулыживатель в каком-то объеме. А если оно есть убулыжник, то почему его не любят смартфоны, которые сделаны из этих убулыжников? Если наоборот, вы стоите на жестких антропоморфных по определению то, чем обладает человек, а если это не человек, то оно не может обладать сознанием. Опять-таки, разговаривать, в общем-то, не о чем. И вопрос очевидный, можно презентацию закрывать. Поэтому, для того, чтобы попытаться ответить на эти вопросы, я большую часть сегодняшнего разговора потрачу на свое видение, на некоторое техническое определение того, что мы называем подсознанием в некоторой группе. в некоторой понятийной сетке. Порассуждаем о том, возможно ли в этой понятийной сетке то, что мы определяем в сознании в системах искусственного интеллекта. Затронем вопрос, является ли измерение способности обладания сознательной или сознательности качественно и поколичественно. Каких системах, кроме человека, оно возможно? Самый главный вопрос, возможно ли оно в системах искусственного интеллекта, и нужно ли это нам, если это возможно. Следующий слайд, пожалуйста. Сознание, в моем понимании, и рядом моих коллег, не делимо от понимания искусственного интеллекта. частным является некоторой составляющей или тем, чем обладают системы, обладающие искусственным интеллектом. Мы можем обладать искусственным интеллектом, но не обладать сознанием. Например, если мы обладаем интеллектом, то мы можем обладать сознанием в том числе. Интеллект, по определению Бена Герцеля, это достижение сложных целей в сложных средах, это определение дополняется расширением Шейн-Лейнга и Маркес-Хартвера, что не просто сложные среды в сложных средах, а в различных сложных средах. И Иван поточняет, что еще и в условиях ограниченных ресурсов. Обращу внимание, что мы можем на самом деле редуцировать расширенное определение до сложного, потому что различные сложные среды большая сложная среда, в которой есть много разный цвет, которые между собой различные, но это одна среда, и таким образом мы все сводим к сложным средам. Точно так же ограниченные ресурсы мы можем тоже упаковать в короткое определение, потому что если мы стараемся работать в ограниченных условиях ограничения ресурсов, то учет ограниченных ресурсов, это одна из сложных целей, одна из подцелей нашего поведения и таким образом тоже подписывается короткое определение. Следующий слайд, пожалуйста. Вот. И для того, чтобы вот осуществлять вот эту вот когнитивную функцию достижения сложных целей в сложных средах, мы в том числе можем включить некоторый дополнительный функционал, который Что мы подразумеваем подсознанию? Это способность строить некоторые модели окружающей среды на основе опыта для предсказания сценариев будущего, для совершения некоторых действий сознательно. То есть мы осознанно говорим, что вот я сегодня утром встану и пойду делать доклад. Это мое принятое решение. Можно говорить о том, что оно предопределено тем, что если я не пойду делать доклад, то я не получу некоторые доли самоутверждения, и поэтому мой поход на доклад утром он предопределен окружающей реальностью, но тем не менее в моей голове я делаю этот выбор осознанно, я являюсь субъектом свободной воли, когда я могу пойти, а могу не пойти, я принимаю решение пойти. У меня есть как минимум иллюзия того, что я совершаю осознанное действие. Если мы возьмем некоторого сферического агента вакууме, которого запустили по параболической траектории, соответственно то вот, значит, если у этого агента есть свободная воля и возможность принимать решение включать или не включать, например, антигравитационные движения, которые он обладает, вот он долетит до решения параболической траектории, предскажет, зная опыт свой собственный, а также модели окружающего мира из книжек по артиллерийской подготовке, которым изучил. предскажет, что если он полетит дальше, то он упадет, ему будет больно, и он принимает осознанное решение. Я включаю антигравиационный двигатель и улетаю в космос. У меня там будет хорошо. Осознанное решение. Идем дальше. Пример. Мы спим, и когда звонит звонок, мы рефлекторно просыпаемся, то есть при пробуждении позвонку будильника у нас нет сознания. Но после того, как мы пробудились, мы начинаем рассуждать о том, что ага, вот у меня в определенное время и встреча, и выступление. И несмотря на то, что мне очень хочется полежать в постели, я знаю, что если я пролежу в постели больше, чем время, после которого у меня не останется времени на то, чтобы добраться до офиса или до места проведения конференции в нужное время, то я пойду по красному сценарию и провожу это мероприятие, а если я вовремя встану и В этом случае я пойду по зеленым стрелочкам и приду на мероприятие вовремя и получу положительное подкрепление от совершения акта самоутверждения в процессе донесения своему иску, уважаемому аудитории. На основании вот этого логического вывода я принимаю осознанное решение. Вставай, завтракай, одевайся и вперед. Следующий слайд, пожалуйста. В еще более узком трубе у людей, с которыми я работаю, есть понимание о необходимости еще большего сжатия вот этого определения сознания, то есть мы говорим о том, что нужно не просто построить эту модель, А мы говорим о том, что для того, чтобы построить эту модель, она должна быть сильной. Что такое абстракция? Абстракция – это некоторый символ. То есть, если мы говорим о некотором стуле, который я могу поднять и могу отпустить. Я должен иметь возможность промоделировать эту ситуацию. Я должен в своем сознании поставить мысленный эксперимент по своей манипуляции с некоторым воображаемым стулом. И вот эти мыслительные эксперименты с абстрактными сущностями, они могут производиться в некотором виртуальном пространстве, которое описывается некоторыми абстрактными сущностями. То есть, по сути, я должен построить некоторую Я должен обладать некоторой предметной областью, смоделированной какими-то абстрактными символами и понятиями, то есть, по сути, я должен иметь некоторое онтологическое пространство. В этом онтологическом пространстве я должен иметь возможность оперировать некоторой лексикой, соответственно, каждые сущности должны быть каким-то образом именованы, чтобы я их мог идентифицировать. И, предположительно, я должен обладать некоторым языком. Может быть, это внутренний язык, может быть, это явный язык. Есть люди, которые мыслят на русском, есть люди, которые мыслят на английском, есть люди, которые могут свою активность вести на таком или другом языке. И, по сути, этот язык – это некоторое правило операции с этими онтологическими сущностями, на которые навешены некоторые вопрос о том, что происходит в голове у математики, он мыслит не на русском, он мыслит не на английском, он мыслит на том языке символов, которые он выучил в высшем учебном заведении с применением тех правил, операция с этими символами, которые, опять-таки, он изучил в учебниках по математике. И вот, например, когда происходит формирование сложных поведенческих навыков которые в принципе не могут быть выучены рефлекторно, то есть я могу рефлекторно научиться там уворачиваться от летящего у меня камня, или научиться рефлекторно поддерживать равновесие. Но если мне нужно произвести какую-то сложную поведенческую схему, ну допустим начать водить машину с ручной коробкой управления, Или совершать всякие трюки, когда спортсмен на кайфборде одновременно меняет направление движения, прыгает и вращается. Для того, чтобы обучить такие, выучить такие сложные поведенческие схемы, необходимо эту схему запрограммировать. И это программирование, оно декомпозируется на некоторой, в некотором пространстве. ног, пяток, носков, толканий, притягиваний, которые не имеют ничего общего с тем, что происходит в окружающем пространстве. Изменение траектории, вращение прыжков. И соответственно, когда вот этот вот субъект в символьном представлении строит программу некоторого поведения, он вначале на уровне вот этих вот элементарных акций выстраивает эти программы, поведение ее тестирует, а потом, когда он научился это делать, он делает уже на автомате. Вот заставляя себя правильно переключать, выжимать сцепление и переключать передачи, мы уже через годик начинаем делать это на автомате и разговаривать с пассажирами и слушать музыку. Можно следующий слайд, пожалуйста. Пример того, как мы можем описать данное поведение спортсмена в некотором пространстве понятий, определенной некоторой лексикой, соответствующей онтологии, ну и соответствующей грамматикой, которая описывает правила взаимоотношения между глаголом и существительным. Следующий слайд, пожалуйста. Значит, проблема рефлекторного или интуитивного с одной стороны и осознанного или мыслительного поведения. Она была, в общем, определена, насколько я знаю, впервые четко Даниэлом Хенниманом, который выдвигает гипотезу положения о двух видах мышления. Быстрое мышление, когда мы интуитивно принимаем простые решения, где под простыми могут быть либо элементарные решения, либо на самом деле могут быть сложные решения или сложные поведенческие акты, но которые мы достаточно хорошо усвоим. Мы можем делать их быстро, решать их быстро, но им очень долго учиться, то есть мы нейронную сеть очень долго тренируем, вот сейчас по последним данным на тренировать нужно порядка двух месяцев. Но потом она очень быстро отвечает на ответ. Это интуитивное и быстрое мышление с медленным обучением. А есть еще медленное мышление с быстрым обучением. Вот нам один раз сказали, что ты когда должен вести машину, ты сперва посмотри в зеркало, потом выжми сцепление, а потом двигай передачу. И в принципе, если у нас над когнитивными способностями все нормально, мы эту поведенческую схему из трех действий сразу заучим. У нас будут проблемы отработать механику и рефлекторность вот этого поведения. Но в принципе, последовательность действий мы усваиваем с первого раза. Нам не нужно в течение нескольких дней смотреть на то, как люди садятся в машину и начинают ехать. Обучение медленно. Обучение быстро. Но это медленно. Сначала я делаю зеркало, смотрю, потом я дверцу закрываю, потом я передачу выдал. Ага, теперь можно ручку двигать. Следующий слайд, пожалуйста. Для того, чтобы осуществлять вот это поведение в символьном мире. наполненных символами, нужно то, что принято называть граф знаний, то, что раньше называлось семантические сети, или сейчас принято называть графы знаний, это вот некоторая система понятий, у которых есть этикетки или лейблы в том или ином языке, которые связаны между собой определенными семантическими отношениями, ну и как бы совокупность вот этих знаний, которые мы можем активировать, явно определяет область операции нашего сознания, то есть системе терминологии, о которой мы сейчас говорим. Подмножество этого индивидуального мира, оно связано непосредственно с субъектом поведения, оно определяет, соответственно, самосознание. Ну и безусловно, вот эти, так называемые, абстрактные понятия, симольные понятия, они очевидны в реальном живом организме, они связаны с неосознанными поведенческими схемами, с комплексами рефлекторных действий, которые находятся в подсознании. то, что у канемана называется система 1 интуитивного или быстрого мышления, непосредственно связана или, как говорятся на английском языке, grounded или заземлено на явные понятия, которые размещены в области осознанного или сознательного мышления. При этом, как показывают некоторые экспериментальные Эти две системы, они на самом деле действуют конкурентно. То есть, когда субъект интеллектуального поведения, так скажем, расширительно, скажем, сталкивается с некоторой проблемой, одновременно запускаются два механизма. Соответственно, если находится быстро интуитивное решение Оно реализуется, если оно вдруг не срабатывает, то у нас к этому моменту уже прошло какое-то время, когда мыслительная активность проработала альтернативный сценарий, и мы уже в более замедленном режиме пытаемся категорически найти более правильный вариант. Следующий слайд, пожалуйста. К вопросу о том, почему мы говорим о том, что в нашей эпидемиологической сетке говорим о том, что сознание оперирует обязательно символами. Почему, может быть, не символами, а сознанием. Это проистекает из гипотезы о том, что как интеллект, так и сознание в рамках этого интеллекта, это продукт некоторой коэволюции, живого организма и того социума или общества, в которой социальные организмы формировались. Что имеется в виду? Для того, чтобы решать интеллектуальные задачи в социальной среде, нам нужно с этой социальной средой коммуницировать. Соответственно, те субъекты, которые получают осуществляют более эффективные коммуникации в социальном среде, как получая из нее дополнительную информацию, так и навязывая свою волю другим участникам этой среды, они получают конкурентные преимущества в процессе эволюции вообще и эволюционного отбора участниц. Но для того, чтобы общаться, нам нужны коммуникации. Для того, чтобы коммуницировать, нам нужен язык. Соответственно, а как только у нас появляется язык, у нас появляется возможность не только называть какие-то вещи какими-то инсикетками или лейблами, не только обменивать информацию с участниками, но и из того, что у нас появляется в голове, мы получаем возможность строить модели и с этими моделями оперировать, и за счет этого мы получаем еще одно дополнительное преимущество, Мы оказываемся не более конкурентны в социальных коммуникациях, за счет того, что у нас появляются еще и более большие возможности когнитивные. С помощью, благодаря возможности работы с этими ритуальными моделями у себя в голове, а не только обменом с ними, с окружающими, мы получаем еще одно. То есть получается такой вот круг положительной обратной связи, вот в этом вот кольце, который позволяет развиваться как интеллектуальным способностям, так и в том числе возможностям осознанного или сознательного мышления на в примере человеческой хомосакры. Следующий слайд, пожалуйста. Идея о социальной природе сознания и самосознания, в частности, она хорошо раскрывается, моему взгляду, в книжке Владимира Дефемра. Настоятельно рекомендую, книжка очень короткая и очень емкая. Вот, ну и здесь для дальнейшей дискуссии предлагаю некоторую схему, которую мы недавно для подобных коммуникаций разработали с моим коллегой Владимиром Крюковым. Предлагается следующая схема для бесобсуждения. Если мы возьмем некоторую интеллектуальную систему, который мы называем интеллектуальный агент, у которого есть некоторые сенсоры и артуапы для связи с окружающим миром. При этом обратим внимание, что если мы говорим о человеческом организме, то на самом деле вот эта вот система интеллектуальной в коре, внутри черепной коробки, потому что сенсоры и актуаторы, они воздействуют с точки зрения мозга не только на окружающий мир, но и на внутренний орган мышцы, то есть актуаторы, они на самом деле приводят в действие мышцы, а сенсоры, они снимают сигналы с сетчатки, с других сенсорных клеток. Соответственно, внутри этого интеллектуального агента у нас дальше находится то, что мы называем психикой или операционной системой, которая управляет, собственно, этими сенсорами и актуаторами. Где у этой психики, с одной стороны, есть некоторое пространство потребностей или целей, или ценностей, которые мы должны будем творять, достигать, либо которые мы должны соответствовать. Мы про это сейчас чуть-чуть еще поговорим. И в соответствии с тем состоянием этих потребностей, целей или ценностей, удовлетворенность, престижение или востребованность осознается в данный момент, у нас возникают некоторые эмоциональные стимулы в систему принятия решений, которые мы называем интеллектом, которые что в свою очередь мотивируют принятие некоторых решений, а вот то, какие именно решения принимаются под действием тех одинных эмоций, определяется кататься теми двумя системами Канемана, про которые я говорил предыдущий. Соответственно, у нас с левой стороны красит непомеченное то, что называется подсознание, интуиция, система Канемана, один быстрого мышления, и с другой стороны у нас есть второй комплементарный механизм, это Сознательное мышление и система 2 медленного мышления понимания. Обратите внимание красный и зеленый цвета, которые обозначают весь систем мышления и пространство в ответственности лица, и об этом дальше поговорим. Следующий слайд, пожалуйста. Пространство потребностей мы можем о нем говорить бесконечно, можно смотреть на все с точки зрения пирамиды Маслова, которая выглядит так, можно смотреть с точки зрения других концепций, чтобы не спорить о том, что находится вверху, что находится внизу. такой или наоборот перевернутой, мы ограничиваемся тем, что говорим, что мы можем потребности, цели или ценности, с одной стороны, разделять как на физиологические, которые поделены просто физическим устройством и особенностями организма, либо биологического, физического, искусственного интернета, либо психологические, которые как бы сформированы социумом и тем символьным восприятием мира, который возникает на основе физиологии или физики. Это с одной стороны. С другой стороны, у нас есть некоторые бытовые потребности, либо поесть, либо зарядиться, либо отправить какую-то потребность, а есть еще и бытийные, или экзистенциальные, которые связаны со смыслом жизни организма. Так вот, что важно, что у нас даже казалось бы, физиологические или физические потребности, они могут быть в том числе экзистенциальные, в том числе, потому что если мы говорим о такой высшей ценности или высшей цели, как, допустим, жертвование человеком своей жизнью ради спасения этих окружающих или ради спасения ребенка, да, это на самом деле может быть определяться не только его сознанием, да, или его воспитанием, это может определяться в том числе тем генетическим кодом, который заложен в соответствии с, например, концепцией Докинса о том, что задача живого существа, это перенос гена данного существа к следующему поколению. И тут дальше возникает вопрос, максимизирует ли определенный генетический код определенного человека передачей генетического кода либо отдельного индивиду, это максимальный эгоизм персональный, либо на уровне социума или семьи, это следующий уровень социального альтруизма, либо на уровне всего рода или вида. Это уже максимальный социальный альтруизм на генетическом уровне. Следующий слайд, пожалуйста. Да, и соответственно, когда мы дальше будем говорить о том, может ли быть сознание, системы искусственного интеллекта видимо не может быть, нужно оно или не нужно, надо понимать о том, что если оно возможно, если оно неизбежно, и если мы считаем, что оно нужно, то в этой ситуации нужно говорить не о том, как это сознание ограничить, а о том, как правильно определить вот это вот пространство ценностей, целей, потребностей базовых или фундаментальных вот этого искусственного существа, с которым, или искусственной системой, с которой мы собираемся взаимодействовать. И, с одной стороны, с другой стороны, можем ли мы, если можем, то как обеспечить невозможность перепрограммирования этой системы самим этим существом или самим этим агентом. Итак, переходим к вопросу, возможно ли и нужна для сознания система искусственного интеллекта. Самый первый пример – обучение основ крепления большой языковой модели или простой системы глубокого обучения. что мы видим что у нас есть так называемая схема вот мы видим что у нас есть функция function и функция оценивания это очевидно соответствует кислородной матрице потребности да то есть такую модель функцию заложен тому это искусственное существо и будет стремиться вот а с другой стороны у нас есть то что называется полисе это коэффициентов, которые мы выучиваем в процессе обучения модели, ну и соответственно мы видим, что тут у нас никакого сознания нет, тут у нас наша система MQC в большой нейросетевой модели, а в середине у нас просто функция цели. Следующий слайд, пожалуйста. Если мы возьмем когнитивную архитектуру на основе вероятности логики, я не меньше Мы опять видим то, что отвечает за оценивание результата взаимодействия с окружающим миром, на основе некоторой системы целей и системы ценностей, определенной в соответствующем антилогическом пространстве для данной предметной области, а принятие решений о том, что будет дальше в результате демагистры, которые акченируют, и что должно быть сделано. Оно осуществляется на основе вероятности на логике. Соответственно, здесь мы имеем дело в чистом виде смышления. Следующий слайд, пожалуйста. Третий пример когнитивной архитектуры. Значит, эта когнитивная архитектура разработана мной тоже с коллегами. Здесь, опять-таки, есть некоторое количество слоев, да, то есть у нас есть некоторая база данных, где мы храним денежную последовательность действий, мы храним последовательность наблюдений. Об окружающем мире у нас есть набор моделей, которые связывают наблюдения и наши действия с последующими наблюдениями. Вот. Ну и у нас есть некоторый набор базовых функций, которые мы должны, или базовых ценностей, которые мы должны например, быть счастливым или собрать яблоко или не брезгаться в стол, в принципе, все время соблюдать разметку. На основе чего мы осуществляем постоянно либо предсказание того, что произойдет в следующий момент, либо мы принимаем решение, а что нам нужно делать с учетом данного предсказания. Причем модель такова, что мы для принятие этих решений и предсказаний можем использовать как символьные модели и таким образом действовать в сознательной среде, либо мы можем иметь распределенные нерасситиваемые модели и таким образом работать в интуитиве. Следующий слайд, пожалуйста. Теперь перейдем к модной теме ЛЛМ. Больших языковых моделей, ЧАД-ЖПТ и того, что на их основе, как в них могло бы быть вписано понимание того, что мы называем в контексте сегодняшнего разговора сознанием, в рамках вот тех когнитивных архитектур, я учту архитектуру, которая сейчас известна. Как устроены большие языковые модели. То есть вот у нас есть большая языковая модель, с которой общаются пользователи. Соответственно, пользователи посылают запросы. Эти запросы хранятся в некоторых логах. И они получают некоторые ответы. Внутри там у нас только коэффициенты. Соответственно, никаких символов, никаких логических операций с абстрактными символами в явном виде там нет. То есть чисто в виде интуиции. При этом модель, естественно, не обучается с подкреплением, она статична, выучена в процессе длительного периода обучения порядка двух месяцев. Пространство, набор коэффициентов хранится в параметрах модели, если мы должны каким-то образом дать этой модели новый опыт, с которым она могла бы работать, мы должны ее переобучать сначала. Для того, чтобы решить проблему практического применения такой модели, чтобы она могла работать с какой-то более актуальной и часто обновляющей информацией, мы можем ей прикрутить такой дополнительный блок, который реализуется с помощью так называемых мультиагентных фреймворков или инструментальных фреймворков, тут фреймворк, так называется, это toolchains, Вот, где одним из примеров является так называемый граф-рак, или графовый интерфейс графовым базам данных. То есть мы можем некоторое динамически обновляемое знание об окружающем мире видеоспецифической предметной области, с которой данная языковая модель должна работать, мы можем этот граф загрузить в графовую базу данных, мы можем периодически эту графовую базу данных обновлять, и в том числе мы можем в эту базу данных закодировать некоторые цели или ценности, достижение которых или удовлетворение которых или в соответствии которых большая языковая модель должна которым вся система в целом должна склиниться. И, соответственно, когда у нас идут некоторые запросы, мы в большой языковой модели подключаем эти инструменты, и она умеет как при определенных контекстах и определенных запросах забирать информацию из вот этой вот динамически обновляемой базы данных, Возможно получать результат некоторого логического вывода, который осуществляется внутри того, что мы можем называть резонер или система логического вывода, которая работает по нержаву и по заданным. И результаты этого логического вывода могут дальше возвращаться в большую языковую модель и трансформироваться в тот текст, который выдается человеку в ответ на его запрос. Но современная версия вот таких вот архитектур, они позволяют не только пополнять эти графовые базы данных и преднастраивать их резюме, но и наполнять их в результате общения с большой цифровой моделью. Там, правда, возникают вопросы, как это все реабилитировать, сделать и фиксировать, но это тема отдельного разговора. Следующий слайд, пожалуйста. Вопросу о том, из того, что я говорил ранее, можно предположить, что дальше я буду говорить о том, что сознание в каком-то виде может быть у любой системы, которая обладает символным мышлением. И, соответственно, здесь возникает предположение, что мы можем количество символов, длину логических цепочек, с которыми можно фигурировать систему, Вот разложить на такой шкале. Шкала будет, грубо говоря, дискретная. То есть здесь мы можем категорировать с цепочкой в один символ, тут можем категорировать с цепочкой в два символа, тут можем категорировать с цепочкой в три символа, тут можем категорировать с цепочкой в семь символов. Или мы можем эту шкалу оцифровать количество цепочек логических, которые можем обрабатывать одновременно. Еще один интересный аспект изменения способностей Но важно то, что многие из моих коллег считают, что измерение возможности сознательного поведения или сознательности, оно не бинарно. То есть в каком-то, как в общем-то интеллекту. То есть если мы возьмем, грубо говоря, птиц, то в каком-то минимальном объеме птицы обладают тем, что мы называем сознанием, может быть, близко к нулю. И в достаточной степени некоторые птицы могут обладать интеллектом. У приматов все еще лучше, у них сознание становится уже отличимым от людевого уровня, а интеллект уже существенно превышает то, что есть у остальных животных. Ну и человек уходит, соответственно, далеко в отрыв. Что будет дальше за человеком, мы попытаемся увидеть на следующем слайде, если что-то будет. Но вот здесь, если кто-то получит доступ к презентации, есть примеры поведения на разных уровнях эволюционной лестники, как себя ведут клеточки, как себя ведут мароккенчатые организмы, как себя ведут приматы. Следующий слайд, пожалуйста. Соответственно, если мы говорим о том, что у нас в какой-то степени как интеллектом, так и осознанием могут обладать разные живые существа, мы можем, и, очевидно, системный искусственный интеллект достаточно сложно построенный, мы можем говорить о том, что социум, сама по себе совокупность агентов, обладающих интеллектом в той или иной степени, может быть способна к осознанному поведению. Например, возьмем Можем ли мы говорить о том, что у муравейника, колонии муравьев есть интеллектуальное поведение? В какой-то степени да. Можем ли мы говорить, и об этом говорят специалисты в ботологии. Можем ли мы говорить о том, что у муравейника есть сознание? Скорее всего нет. По крайней мере, вроде как неизвестно о том, что бы были какие-то символы, с которыми мог работать муравейник. Вот, может быть, просто не знаю. Жанну Резникову можно спросить при случае, кто с ней знаком. Можем ли мы говорить о том, что возможность коллективной работы с символами, с логическими выводами и с принятием осознанного принятия решений есть у человеческого сознания? Очевидно, да. То есть, очевидно, конференции, воркшопы, стратегические сессии, дорожные карты, планы пятилеток, контроль за исполнением планов пятилеток, дорожных карт, этапности по выполнению научно-исследовательских отчетов. Очевидно, это все элементы осознанного поведения в том смысле, в котором я его обозначил в начале этого доклада. Есть определенные языки, есть определенные процедуры, есть определенный регламент, это все, которое принято к исполнению всем участникам сообщества. Следующий слайд, пожалуйста. Значит, что нас может ждать и к чему мы можем готовиться, и о чем мы можем говорить в будущем. Ну вот первое, сейчас любят строить всякие сингулярные шпилевые, как мы ведем технологические сингулярности. Вот одна иллюстрация, типики могут быть немножко устаревшие. пару лет назад эти циферки были, сейчас все быстро меняется, но смысл понятен. То есть если мы говорим о том объеме памяти, который обладает некоторой системой, либо биологическая система, либо физическая система, то вот у нас сначала идет по ходу эволюции рост в битах объемов генетической памяти, потом у нас перестает генетическая память расти на уровне Вот шимпанзе, оно как мышь в количестве нейронов, а человек уже резкий скачок. Дальше у нас память начинает накапливаться и расти количество памяти в компьютерах. Если самый большой суперкомпьютер в количестве параметров сопоставим с человеческим мозгом, тут есть нюансы, то ли мы считаем синапсы, то ли мы должны считать дендритное предразветвление. На самом деле, если мы будем считать, если мы ведем пульс человеческой памяти не по количеству синапсов, а по количеству, значит, разветвлений на дендритах, а еще и умножим это на количество медиаторов, значит, где каждый синапс может работать с разными медиаторами, то на самом деле человек сильно вырывается то картиф примерно так получается, что компьютеры в последние годы начинают человека обгонять, особенно если мы берем учредительные классики, вроде тех, которые сейчас строят штаты в Китае. с которым он может работать, то человек начинает постепенно оставаться на месте этого соревнования. Интереснее еще оказывается с логическим мышлением, что, опять-таки, сетка определений, в которой работают, предполагает непосредственно связанное с сознательным мышлением. Это способность оперирования с логическими цепочками с одной стороны, а с другой стороны с несколькими сущностями одновременно, потому что для того, чтобы построить некоторую логическую цепочку и принять на основе ее какое-то решение, нам нужно все вот эти вот сущности где-то иметь в некотором текущем операционном контексте в своей виртуальной модели мира, которая, как мы знаем из множества психологических экспериментов, у людей варьирует от 5 до 9, то есть в среднем в контексте В текущей рабочей памяти человека имеется 7 символов. Эффективное количество членов команды, которые человек может управлять, около 7. В каких-то условиях до 10, если жесткая дисциплина. А если дисциплина в семье, то даже с двумя-тремя людьми трудно справиться. Это число существенно сокращается, то есть обезьяну можно научить говорить какими-то предложениями, если дать возможность формировать фразы, но в лучшем случае три члена предложения у обезьяны получится. Соответственно, у мышей больше или у других животных сложнее, чем дают бери, не получается. Так, что важно, я у кого-то из нейропсихологов не спрашивал, а вот почему этому? Какие структуры мозга есть, какие нейрофилософические структуры, ограничения, какие принципы конкретного человека обеспечивают эти 5-9, а у обезьяны 2-3? Ответа никто не дает. Биоэтика одна и та же, структуры одни и те же. Организация разная, то есть в чем-то это отличие есть. Но, наверное, оно чем-то определяется. А вот если мы возьмем суперкомпьютеры, которые мы сами строим, для которых мы сами пишем программное обеспечение по тем правилам, которые мы сами придумываем, а уже сейчас компьютеры придумывают новые правила и сами начинают писать. Вот сейчас это плохо получается без надзора человека, но тем не менее прогресс идет. то возникает предположение, что системы искусственного интеллекта смогут строить, осуществлять принятие решений на логических цепочках любой длины, во-первых, и во-вторых, делать это одновременно для большого числа логических цепочек. Если человек не может одновременно говорить по-русски и писать по-английски предложение из семи членов предложения, По системе искусственного теоретика, очевидно, сможет одновременно, ну, некоторая гипотетическая система сможет одновременно, она уже может, да, то есть, если мы возьмем какую-нибудь часть ЖПТ, она одновременно работает с миллионами пользователей на разных языках, вот, вроде как логические циклончики строить не могут логические выводы, хотя, опять-таки, эксперименты типа Trail of Thought, Chain of Thought, системы типа RAP, про которые я сейчас говорил уже, даже в области осознанного мышления в системах искусственного интеллекта. Следующий слайд, пожалуйста. Значит, вопрос о том, нужно ли это нам. Ну вот, основной этот вопрос, с моей точки зрения, в сегодняшний день, связан с... Основная острота вопроса определяется проблемой так называемого Lethal Autonomous Vehicle Systems, то есть это применение интеллектуального, искусственного интеллекта в боевой сфере, когда принимаются решения о том, что данная система искусственного интеллекта может сама выбирать цель и принимать решение на их поражение, потому что принятие решения на поражение цели дроном, например, или ракетой, это очень хороший пример осознанного поведения. Убивать или не убивать, если убивать, то кого? Успеха в регулировании и попытках запрета на развитие автономных систем убийства на основе искусственного интеллекта нет. Можно следующий слайд, пожалуйста. Потому что существующее развитие международной политики, к сожалению, приводит к гонке вооружений, в первую очередь в области именно автономизации систем нанесения ущерба живой силе техники противника. Мы знаем, какой успех появился в результате того, что вместо дронов на радиосигнале появились дроны на автоволокне, поскольку они могут преодолевать систему радиоэлектронной борьбы. А если появляется возможность дать дронам полностью автономно действовать в отсутствие сигналов GPS, в отсутствие полного демонтирования средств радиоэлектронной борьбы, при отсутствии вот этого окна, которое тянется от оператора, если оно может самостоятельно проходить по рельефу, пережидать светлое время суток, перемещаться ночью, днем сидеть где-то там на веточке, подзаряжаться от солнечной батареи и дальше лететь к назначенной цели, то мы попадаем в чудный новый мир. Следующий, пожалуйста. Соответственно, в краткосрочной перспективе, наверное, мы скорее не хотим, чем хотим, чтобы вот это вот развитие осознанного, целенаправленного поведения появлялось как минимум в боевых системах. Хотя как этому противостоять, не очень понятно. В долгосрочной перспективе я отношусь к тем людям, которые смотрят в постсингулярное будущее, что называется. когда кончается ресурс Солнца, когда кончается ресурс планеты Земля, когда человеческая цивилизация оказывается перед неизбежным выбором либо прекратить свое существование, либо отправиться в космос, мы должны думать о том, что звездами или человеками, как сказал Артур Хопларт. И, наверное, в очень долгосрочной перспективе, единственный способ передать код, интеллектуальный, культурный, какой угодно код человеческой цивилизации, не генетический код, но генетический код, если угодно, человеческой цивилизации, о передаче его через вот те системы, которые мы создадим. То есть можно говорить о том, что система искусственного интеллекта это наши дети на эволюционной перспективе масштабного существования Вселенной. Следующий слайд, пожалуйста. Ну и вот примеры того, какие ответы были даны на вопросы в том сообществе, про которое я говорил, соответственно, если есть желание поучаствовать в этом голосовании, посмотрите сегодня можно по этим ссылочкам пройти. Что мы видим? Вопрос, кто обладает сознанием в вашем определении, в вашей понятильной сетке, хотя бы в самом минимальном объеме? Мы с удивлением видим, что людям, только 82% корреспондента оказали доверие в наличие сознания, это голосование с множественным выбором, возможно, выбором выбирать любое количество опций. Соответственно, оказалось 13% участников считали, что человек не обладает сознанием, но, может быть, они не справились с голосованием. Обратим внимание, что многоглеточные сюда вписались в первую очередь благодаря семеновым. Ну и дальше насекомые, видимо, за счет муравьев как-то попали в социальное поведение муравьев. не только человек, но и приматы, препятающие птице, а также сообщество людей, государства, компаний и даже лучшие большинства языковых моделей, существенной частью аудитории доверены к обладанию вот этим вот самым минимальным количеством сознания. И самый главный вопрос, возможно ли, нужно ли нам создание, возникновение сознания в вашем определении на уровне человека. То есть здесь на правом голосовании мы говорим про уровень человека. И выше его в системе искусственного интеллекта. Ну и вот, значит, здесь гораздо более четкие результаты. Значит, три частных сиденья, часть считает, что это невозможно, очевидно это вот сторонника антропоморфного определения сознания. Часть считает, что это неизбежно, и никогда мы от этого не тянемся, и необходимо прямо сейчас сюда в том числе попадают те участники, которые считают, что оно просто уже есть. Зачем об этом говорить? Оно уже есть в большинстве законных моделей. Ну и вот мой голос в этом пункте, что в будущем это неизбежно и необходимо по обозначенному причину, но сейчас лучше бы не надо, хотя непонятно, как с этим бороться. Следующий слайд, пожалуйста. Да, вот если эта тема интересна и продолжать ее обсуждение, то за рамками нашей встречи можно это делать у нас в сообществе. 

S02 [00:46:05]  : у меня, наверное, два вопроса, может быть они не самое сердце вашей задачи будут направлены, но то, что меня беспокоило Несколько раз вы говорили в связи с сознанием о муравьях. Ты вопрос ставился, есть ли у муравьев сознание, факты и вопрос совокупного сознания. Меня стыдило, почему вы говорите о муравьях, а не о пчелах. Если мы примем ключевым маркером сознания оперирование символами, то, на мой взгляд, пчела здесь годится больше, потому что пчела-разведчица, которая прилетает в Улии и общается с пчелами-сборщицами, она, пусть не очевидна, но с некоторой степенью вероятности демонстрирует символ сознания, потому что она четко задает пчелам-сборщицам угол, на который они должны повернуть, длину перелета, что-то еще. То есть это все кодируется определенным образом, это все истанцы пчел, где кодируются, все эти записи есть, все это есть, дальше огромная куча этих танец. Запомнить, у вас были вот эти вот запоминалки, два-три слова в книжке, еще что-то. Какое количество символов способна вот эта пчела, которая собирает, запомнить? углы поворота, солнца над горизонтом, там очень много заходированных всего. Вот вопрос, да, почему, допустим, муравьи, а не пчелы? И второе, годятся ли пчелы в таком случае на носителей сознания? 

S03 [00:48:17]  : Да, спасибо, прекрасный вопрос. Значит, вопрос совершенно справедливый. Муравьи здесь оказались, когда речь идет о коллективном интеллекте, всегда упоминают муравьев. редко упоминают пчел, но просто в дискуссии общественной. Поэтому вот оказались муравьи, а чтобы мурашки больше и пчел, то просто мест на слайд не хватило. С точки зрения работы с символами, безусловно, да, то есть если мы говорим про работу с символами, то в работе пчел использование символов более очевидно, чем в случае с муравьев, хотя вроде как у муравьев тоже какие-то символы Здесь имеет смысл посмотреть последнее выступление Жанны Резника, в том числе по муравьям, она много рассказывает. И там тоже есть, на самом деле, синие. При этом, опять-таки, в тех дискуссиях, которые у нас в сообществе проходят, есть очень много голосов, что нет, это все рефлексы. То есть это просто сложная система рефлексов. В результате которой пчела прилетела эллифлекторно, в процессе эволюции она выучилась того, что прилетая из такого-то азимута, нужно ползать по такому-то азимуту. Что это не поведение, это предмет неосознанного мышления, а естественного отбора на генетическом уровне. Это не моя позиция, я не знаю, я не этолог, я не генетик. Мне лично более близка ваша позиция, что да, это работа с символами, это осознанное поведение на некотором рудиментарном, скажем так, около нулевом, но тем не менее не нулевом уровне. И в этом плане, да, мы можем сказать, что и пчелы, и муравьи, они в каком-то минимальном уровне, могут быть номинированы на обладателей минимального количества сознания. Но многие не согласятся. 

S02 [00:50:15]  : Второй вопрос в продолжение. Там был график, где показывалось соотношение сознания и интеллекта, зелененький и синенький, если я сейчас правильно помню. Как-то прям заптиц было очень обидно, потому что вы показали как минимальный носитель сознания и в каком-то смысле тоже такой Тоже минимальный носитель, вот он, зелененький, вот там показали, некоторые птицы, выглядели ли птиц. Но, грубо говоря, любая, даже самая бестолковая кукушка способна так картировать мир, строить такую модель мира, что она из года в год, мы оставим пока вот этот разговор о рефлексах, из года в год она улетает в Африку, возвращается в Эскитим. Влетает в Африку, возвращается в Азербайджан. Сказать, что она действует на рефлексах. И для рефлексов нужно учесть температуру, магнитное поле, поток ветра и кучу всего еще, да, закаты и восходы, массу всего. Старая позиция, что мозг размером с пельмень, но она не работает, потому что уже доказано, что организация нейронов в мозге птицы более компактная, более емкая и способна по некоторым параметрам превосходить этот гипертрофированный, не очень удобно скомпонованный человеческий мозг. 

S03 [00:51:40]  : Схема ориентирована на людей, стоящих на более антропоморфических позициях. Поэтому, так сказать, ну и потом я опять-таки не специалист в экологии, то есть моя задача была показать, что это не бинарно, да, то есть окей, я легко могу двигать птицу сюда, а тут нарисовать в чёрном объёме. 

S01 [00:52:05]  : Вот такая критическая реплика, я буду говорить не о предмете вашего разговора, а о вашей речи. Получается опять классическое смешение понятий. Вы символ одного порядка сравниваете с символом другого. Сначала вы показали нам антологическую сеть и язык запросов к антологии, такую цифровую концептуализацию, которые ведут в темноте в искусственную систему внешнего феноменального сознания, они в общем-то качественное состояние не переживают. Даже если мы говорим о компьютерном зрении, мы переводим это все потом в гамбитинги, ну и так далее. Сами говорили, что в любом случае будут какие-то символы численные, не феноменальные. Слово феноменальные надо пояснять? Качественное состояние, которое вы переживаете здесь и сейчас, на уровне тела. визуальные, тактильные, обонятельные, не просто перцепция, а все, что происходит внутри, именно в вашем состоянии данности. Вот у искусственных агентов в состоянии данности нет. 

S03 [00:53:11]  : Вы будете с этим подходить или не будете? Я не понимаю, откуда это утверждение взялось. Это выглядит как Xeom. 

S01 [00:53:17]  : Ну, вроде бы, мы говорим сейчас о технологиях же, да? Нет, о каких искусственных агентах? 

S03 [00:53:25]  : Искусственных агентов очень много. Есть два искусственных агента, которые сейчас видео снимают, а есть GPT. Мы о каких агентах говорим? 

S01 [00:53:35]  : Давайте возьмем любую технологическую сторону на физическом уровне. Берем физическую организацию. Но так вопрос не получится. 

S03 [00:53:44]  : Нет, нет, нет, я даже просто скажу, что если на уровне, так сказать, спора в интернете, в чад интернет-чад, вы неправы. Потому что у чад-GPT есть, условно говоря, вот эта статическая модель, которую он включил, а у него есть еще контекст. Причем, на самом деле, у него есть двухуровный контекст. Есть минутный контекст, есть долгосрочный контекст. Так вот, то, что к нему попадает, оно хранится и варится вот в этом вот контексте, и вот как раз вот это вот перцептивное поле, феноменальный опыт, который используется для принятия, для атлета, пользователя, начинающего вот этой всей большой языковой модели, оно, можно сказать, находится вот в этом контексте. 

S01 [00:54:27]  : У меня понятны излишне концептуальные ошибки, потому что вы концептуальное поле машинного интеллекта приравните к феноменальному. А это даже на уровне компьютерного зрения не так. Там темнота. Я боюсь, что это вопрос определится. Ну да. Вопрос в том, что вы вычислили телесность, а телесность это основной источник концептуализации. А у вас вопрос в этом квадратике, где интеллект, сознание, коммуникация, язык. Очень схема понятная. 

S03 [00:54:56]  : Я специально сказал, что телесность, она находится за рамками. То есть телесность, это у нас то, на что мы воздействуем. 

S01 [00:55:04]  : Просто система наград, которую вы хотите обучать, она вне феноменального поля лежит. Даже светочувствительный белок, похоже, имеет какие-то минимальные состояния. А кремнии, вот концептуальная система вычислительных процессов, она лишена этого. Поэтому и символ будет иного порядка. Но это ладно, здесь мировоззрение. И очень короткий вопрос. 

S00 [00:55:35]  : Альдон Германович, разрешите любую из писательно-этических приложений разговоров об искусственном интеллекте, например, о военном деле. ли он обладать, наденять ли его понятием сознания, которое связалось плотно с антропоморфными представлениями, или без наделения этой сознательностью можно также разрешить эти вопросы этические, связанные с агентностью и воздействием на… Да, спасибо, очень хороший вопрос. 

S03 [00:56:14]  : Смотрите, два момента я подчеркнул. Первое моё понимание, в той терминологической сетке, в которой я нахожусь, сознание – это просто более эффективный способ решения текстуальных задач. То есть, если мы берём и превращаем, перевозим этот феноменологический опыт или поток рецептивных ощущений в некоторые модели, символьные модели, компактные, с которыми мы можем обсуществлять сложные, Если нам необходимо у системы искусственного интеллекта повышать производительность и качество принятия ее решений, то да, это важно, необходимо. С точки зрения этических норм, очевидно, если мы действительно хотим повышать их производительность, то мы должны очень четко думать о том, как нам правильно задавать вот эти вот базовые системы ценностей, потребностей и ценностей, чтобы система не пришла в противоречие тем, что от нее ожидает человеческое общество. Тут можно вспомнить законы Азимова, которые, черт, не колятся, если очень коротко, но это тема отдельной дискуссии. Спасибо. 

S01 [00:57:27]  : Спасибо большое, Антон Германович. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
