# 21 августа 2025 - Непрерывное обучение и проблема катастрофического забывания в импульсных нейронных сетях с колоночной организацией - Денис Ларионов
[![Watch the video](https://img.youtube.com/vi/ERNu240umQg/hqdefault.jpg)](https://www.youtube.com/watch?v=ERNu240umQg)
- [видео в RUTUBE](https://rutube.ru/video/4d0de669aab490222d5a8c517fddbb77/)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239224)
- [презентация и код](https://gitflic.ru/project/dlarionov/cl)
- https://arxiv.org/abs/2506.17169

# Краткое содержание:

## Обзор семинара: Непрерывное обучение и "катастрофическое забывание" в нейронных сетях

В ходе семинара была рассмотрена проблема **"катастрофического забывания"** в нейронных сетях, возникающая при последовательном обучении на разных задачах. Было отмечено, что классические системы искусственного интеллекта, в отличие от биологических организмов, не способны эффективно накапливать знания в непрерывном режиме.

Основной причиной этой проблемы в традиционных сетях глубинного обучения (Deep Learning) был назван метод обратного распространения ошибки (**Backpropagation**), который при обучении на новой задаче изменяет все параметры сети, повреждая знания, полученные на предыдущих этапах.

### Альтернативный подход: Локальное обучение и архитектура Colonet

В качестве альтернативы был предложен фреймворк локального обучения, реализованный в импульсных нейронных сетях с колоночной организацией (архитектура **Colonet**).

**Ключевые особенности этого подхода включают:**

*   **Локальные правила обучения:** Вместо глобального обновления весов используются локальные механизмы пластичности, такие как Spike-Timing-Dependent Plasticity (STDP), которые изменяют синаптические связи на основе локальной активности нейронов.
*   **Колоночная организация:** Сеть состоит из "колонок", каждая из которых отвечает за свой класс. Внутри колонок существуют "микроколонки", позволяющие нейронам специализироваться на различных подклассах или вариантах одного и того же класса.
*   **Конкурентность:** Применяется механизм "победитель забирает всё" (Winner-Take-All), который обеспечивает специализацию нейронов.
*   **Адаптивный порог срабатывания:** Нейроны, которые уже обучились распознавать определенные паттерны, повышают свой порог активации, что делает их более "стабильными" и менее подверженными изменениям при обучении на новых задачах.

### Результаты экспериментов и выводы

Были представлены результаты экспериментов на датасетах Permuted MNIST и MNIST/E-MNIST.

*   В задачах, где **отсутствовали общие признаки** (Permuted MNIST), архитектура Colonet продемонстрировала высокую устойчивость к забыванию, превзойдя стандартные подходы.
*   Однако при обучении на задачах с **похожими признаками** (цифры и буквы) эффективность снижалась.

В заключение была выдвинута гипотеза, что для решения проблемы на задачах с общими признаками необходимо введение **иерархической структуры**. Такая структура могла бы выделять общие низкоуровневые признаки, позволяя колоночной архитектуре работать с более абстрактными и уникальными представлениями на высоких уровнях.


## Расшифровка доклада:


S01 [00:00:01]  : Коллеги, всем добрый вечер. Мы неожиданно, не дожидаясь первого сентября, начинаем семинаров русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта. И начинаем ее на новой электронной площадке. Это КИТОК, предоставленный Линейной лабораторией аналитики больших данных и искусственного интеллекта Новосибирского государственного университета. Вот, и сегодня у нас в гостях Денис Лавионов, и он нам расскажет про непрерывное обучение в импульсных и нейронных сетях с колоночной организацией, продолжая опять-таки серию семинаров его и его коллеги Михаила Киселева, которые у нас раз в год или даже несколько раз в год рассказывают о прогрессе в области импульсных нейронных сетей. Денис, пожалуйста. 

S00 [00:00:48]  : Добрый день, коллеги. Я видео для скорости отключу. Сегодня я представляю научную группу Чувашского государственного университета под руководством Михаила Киселева. В рамках этой группы мы занимаемся исследованиями в области импульсных сетей. Сегодня я расскажу об одной из наших работ. Доклад будет структурирован следующим образом. Сначала сделаю обзор в целом области непрерывного обучения в Deep Learning. расскажу о метриках, о методах, о подходах и самое главное о проблемах. Подведу к тому, что виноват Backprop. Дальше перейду в плоскость локального обучения и соберу фреймворк локального обучения. Поговорим про конкурентность, модулируемую пластичность. и колоночную организацию. Далее мне придется, насколько это возможно, рассказать о колонет. Я так подозреваю, что не все коллеги подробно с этой архитектурой знакомы. И это позволит мне перейти к самому интересному, к экспериментам. Как мы в экспериментах с непрерывным обучением демонстрируем, что колонет может достаточно эффективно Так, ну, собственно, перехожу. К сути, да, показывать я собираюсь в... ну, у меня есть презентация и немножко кода будет, поэтому я сразу показываю в среде разработки. Сейчас пойму, как листать. Поехали. Первый тезис следующий. Животные, люди, вообще говоря, биологический организм, они имеют способность в непрерывном режиме накапливать и использовать знания. Чем, в общем-то, не могут похвастаться классические системы искусственного интеллекта. Собственно, эта проблематика применительно к системам искусственного интеллекта изучается в области непрерывного обучения или Continual Learning. Справа мы видим иллюстрацию, которая показывает основные, с чем мы работаем. Предположим, что у нас есть несколько задач. И мы обучаемся. Наша задача обучаться сначала на одной задаче, потом она становится нам недоступна. Дальше мы продолжаем обучаться на второй задаче, потом на третьей и так далее. И смотрим, как у нас падает метрика качества на первую задачу. В данном случае приведена иллюстрация, которая показывает, что когда мы начинаем обучение на следующей задаче, Мы наблюдаем очень сильную деградацию в какой-то метрике, например, в эффективности на прошлой задаче. Эта проблема имеет даже название специальное «катастрофическое забывание». И чем дальше мы учимся, тем больше мы наблюдаем деградацию в качестве решения первой задачи. Связано это с тем, что мы обучившись на одном распределении данных, обучаясь на другом, обновляем за счет обратного распространения ошибки все параметры, повреждая таким образом полезные знания для первых задач. Эта картинка показывает еще один эффект, связанный с непрерывным обучением, так называемый прямой перенос. Часто задачи, которые мы встречаем в реальном мире, они обладают некой общностью, и поэтому можно ожидать, что если мы обучили какую-то сеть на одной задаче, то на другой задаче она уже будет работать лучше, чем случайно инициализированная сеть, ну или какая-нибудь с нулевой инициализацией, поскольку какие-то паттерны между задачами все-таки должны сыграть роль и являться полезными. И это явление называется прямой перенос. Итого, когда мы говорим о В дизайне эксперимента в области непрерывного обучения обычно на него смотрят трех срезов. Во-первых, насколько качественно каждая задача решается. Во-вторых, насколько сильно мы деградировали в первой задаче по отношению к обучению в последней, это называется мерой забывания. И насколько обучение на первых задачах позволяет нам лучше решать следующие задачи. Это называется мера прямого переноса. Ну и еще маленькая заметка, что вообще говоря о непрерывном обучении, говорят не только о метриках. В целом есть такая проблематика, как баланс пластичности обучения и стабильности памяти. Имея в виду, что первое мешает второму, и наоборот, если мы очень хорошо приобретаем новые знания, значит нам их сложнее запоминать. И наоборот, если мы очень хорошо запоминаем, значит нам сложнее учиться. Далее есть отдельное направление, связанное с тем, как различать отличия не только внутри распределений каждой из задач, а еще и различать задачи между собой, если в нашем дизайне не заданы границы задач явным образом, точнее идентификаторы задач. Ну и, наконец, еще важно всегда отмечать, что говоря о непрерывном обучении, мы должны говорить о ресурсах вычислительных, которые мы тратим на эту задачу, потому что существует очень много разных инженерных подходов, которые, в принципе, решают эту проблематику. Такой самой явной мы можем просто запомнить все обучающие примеры первой задачи и использовать их в обучении на второй. таким образом получив вычислительные издержки, но в целом решив нашу проблему. Далее давайте поговорим о типовых сценариях в непрерывном обучении. Принято различать сценарии по следующим категориям. Во-первых, task-based и task-free. Заданы ли границы между задачами. Я приведу пример. Например, мы делаем какого-то робота, который на гусеницах ездит по разным поверхностям. И мы его учим. В task-based постановке, когда у нас границы четкие, мы этого робота в каждой итерации скидываем с вертолета, моментально помещаем в локацию. А в task-free он может плавно переезжать из одной локации в другую, из песка на травку, из травки в снег. И это гораздо более сложная постановка. Далее различают Task, Domain и Class Incremental Learning, имея в виду доступны ли идентификаторы задач как в обучении, так и в тестировании. В Task Incremental Learning мы выбираем У нас, собственно, заданы... ну вот смотрите, давайте на примере картинки снизу. Это сплит MNIST, сделанный из всем известного датасета MNIST. Мы разбили его на 5 задач, и дальше мы можем в этом разбиении по-разному спланировать наш эксперимент. Мы можем сказать, что наша задача выбрать одну из двух цифр в известной задаче. То есть нам в инференсе на вход поступает идентификатор задач, которую мы решаем. Тогда мы можем сделать инженерное решение, которое будет обычным ифом. задействовать нужную нейронку, которая будет классифицировать нужную задачу. Это опять же инженерный обход. Далее мы можем поставить задачу в терминах domain incremental learning. когда нам неизвестен идентификатор задачи в инференсе, но у нас пространство классифицируемых объектов, пространство меток одинаковое, в данном случае равно 2. То есть по сути мы должны определить четная задача или нечетная. Вот мы обучились последовательно на 5 задачах и какую бы нам задачу ни дали, мы либо 0 говорим, если это число Это постановка Domain Incremental Learning. У нас одинаковое пространство меток и отличается пространство входных данных. И есть еще постановка Класс Incremental Learning, когда мы в каждой из задач, опять же идентификатор задач неизвестен в инференсе, и мы должны предсказывать, что это конкретно за цифра. Наиболее естественной постановкой, возможно, это покажется странным, является domain incremental learning, когда у нас одинаковое пространство меток. В случае с нашим роботом на гусеницах это бы означало, что у него одинаковые контролы управления. То есть, когда он двигается вправо, вперед и влево, эти кнопочки у него одинаковые, независимо от задачи или от локации. а меняется только сенсорный или сенсорный вход. Ну и дальше еще различают постановки стриминг, когда в один момент времени предъявляется только один пример. Имеется ввиду противопоставление батчингу, что мы не используем батчей при обучении. И еще онлайн, когда один пример предъявляется только один раз. Имеется ввиду, что мы используем только одну эпоху, а не повторяем примеры множества эпох. И те эксперименты, которые дальше будут демонстрированы, они сделаны в постановке онлайн, стриминг, домейн, таск-бейс, инкрементал-лернинг. Пару слов о метриках. Как я уже сказал, мы в наших экспериментах будем измерять общую производительность. Это то, как качественно решается каждая из последовательностей задач. по сути, меру забывания или стабильность памяти, то, как сильно мы забываем, обучаясь новым задачам, старые задачи, и так называемую обобщающую способность в виде меры прямого переноса. Я не буду подробно останавливаться на метриках. Дальше, поскольку я постараюсь вкратце буквально пройтись по подходам к решению проблематики непрерывного обучения в дипленинге, мы выделили Их пять групп. Снизу представлены две работы, которые являются очень хорошими обзорами этой области. Первая стратегия решения проблематики непрерывного обучения – это методы воспроизведения. Когда мы пытаемся аппроксимировать и восстанавливать распределение данных прошлых задач при обучении на новых задач. И тут есть две центральные идеи. Одна, как бы я уже чуть раньше сказал, это реплей буфер. Мы можем предусмотреть небольшой буфер памяти, в который сохранять или все, или не все какую-то часть обучающих примеров с прошлых задач и эффективно использовать это в обучении. В Rally у нас сектор Critic, DQN, по умолчанию включают replay buffer, решая эту проблематику. Так что это довольно стандартный подход. И тут есть важный тезис. Есть целое направление исследований о том, какие примеры из прошлых задач выбрать эффективно. С точки зрения непрерывного обучения оказывается, что наиболее эффективно выбирать те, Экземпляры, которые похожи, обладают высокой степенью похожести на экземпляры, присутствующие в новых задачах. Этот тезис про общность и похожесть сегодня будет несколько раз возникать. Вот здесь он первый раз возник. Другое направление в решении методов воспроизведения – это обучить генеративную модель, которая умеет воспроизводить данные задач, и опять же, когда мы учимся новым задачам, просто генерить старые данные, генерить данные из распределения старых задач и подмешивать их в обучающую выборку для новых задач. Следующее направление – это методы регуляризации. Тут есть два центральных подхода. Регуляризация – это то, что мы ограничиваем изменения каких-то весов, исходя из каких-то правил. Во-первых, мы можем сказать, что разные веса имеют разную важность для разных задач и как-то начать эту важность измерять. И тогда мы можем препятствовать обновлению важных с точки зрения одной задачи параметров. при обучении на другой задаче. И это тоже целое направление исследований о том, как понятие важности можно определить и как можно эту регализационную поправку вносить. Второе направление в стратегии регулизации – это, по сути, предотвращение отклонений в отображении вход-выход сети. Обычно имеется в виду дистилляция знаний, когда мы между задачами сохраняем модель-учитель, и дальше встает вопрос, какие данные через нее прогонять для того, чтобы потом на них учиться. И можно вообще на новых данных, можно сохранить старые данные и так далее. Это тоже целое отдельное направление исследований. Я подробно по всей области проходить настолько не имею возможности, поэтому это достаточно верхнеуровневый обзор. Третья стратегия – явное манипулирование процессами оптимизации. Здесь есть много интересного. Есть работы, которые просто исследуют разные варианты чего угодно. Количество нейронов в слоях, количество слоев, ленинрейты и так далее. В целом есть такой тезис, что лучшими с точки зрения непрерывного обучения оказываются те подходы оптимизации, которые стремятся находить более широкие и плоские минимумы. Есть, соответственно, такое направление, очень похоже на идею регуляризации, когда мы Скорость обучения или Learning Rate выставляем не одинаковым для всех параметров, а варьируем его в зависимости от разных параметров. Это Adaptive Learning Rate. В принципе, это похоже на идею ограничения параметров за счет регуляризации. Дальше есть очень красивая идея, с которой обычно начинают рассказ о непрерывном обучении. Это про проекцию градиента. Когда мы учимся с помощью градиентных методов, то шаг градиентного спуска на новой задаче мы можем осуществлять в направлении, безопасным для прошлой задачи, например, ортогональным. И, в принципе, если у нас пространство высокой размерности, то мы таким образом можем довольно безопасно обучаться на каждой новой задаче. не повреждая, не выходя из минимума для предыдущей задачи. Есть еще интересный подход, основанный на идее химтоновских быстрых весов. когда мы на уровне одного синапса имеем несколько параметров, которые меняются в разной временной шкале, с разным временным масштабом. И таким образом это тоже позволяет отвечать на проблематику непрерывного обучения. Четвертый подход — это явное манипулирование архитектурой. Мы можем использовать многоголовые архитектуры. Например, у нас мог бы быть такой подход. Мы учим какую-то сетку, пусть даже большую, а потом на каждой новой задаче накидываем ей сверху еще один слой, который обучается только под эту задачу. Ну и, в общем, надеемся на то, что, собственно, у нас первая часть сети выделяет какие-то общие признаки для всех задач и последняя сеть классификаторов. Дальше есть идея маскирования параметров. Это опять похоже на adaptive learning rate и на регуляризацию. мы можем выучить так называемые маски, ну или просто их задать, и замораживать одни веса при обучении. То есть на одних задачах иметь одни пластичные веса, на других задачах другие. И еще и делать это умно. Ну и, конечно, очевидная идея, давайте мы просто на каждой новой задаче в сеть доливать новых нейронов или новых синапсов, таким образом обеспечивая новую пластичность. И последняя стратегия в Deep Learning, которую мы выделили, это шаблонизация. Мы можем создать прототип класса. и получая новый объект измерять близость к этому прототипу, таким образом выполняя задачу классификации. Есть еще одна красивая идея. Мы можем построить для каждой задачи генеративную модель и когда мы получаем на вход классифицируемый экземпляр, мы можем прогонять через каждую модель вероятность того, что этот объект получен именно этой генеративной модели, и таким образом выбирать класс. Соответственно, что мы по итогу видим. Подавляющее большинство методов и подходов к решению проблемы катастрофического забывания и вообще проблематики непрерывного обучения, они все используют градиентные методы обучения. Хотя вот уже даже первый наш слайд намекал на то, что именно это является фундаментальной причиной забывания. На наш взгляд, решение проблемы катастрофического забывания по существу лежит не в плоскости, я это называю, инженерных трюков, таких как маскирование, адаптивные веса, какие-то архитектурные гейтинги и так далее. а в области альтернативных методов обучения, а именно локальных методов, таких, которые бы позволяли организовать пластичность сети таким образом, чтобы при обучении на новых задачах не повреждать знания, которые содержатся в параметрах сети, имея в виду возможность обновлять не все параметры, а лишь какие-то конкретные, определяемые механикой обучения. Здесь мне бы хотелось выделить еще один концепт. Мы его назвали «локальность вычислений». Это подход к реализации эффективных распределительных вычислительных систем, имею ввиду аппаратную реализацию, основанных только на локальных сигналах от физических узлов сети. С помощью метод обратного системы, построенной на Backprop, принципиально невозможно из них получить системы, обладающие свойством локальности вычислений. А вот системы, которые используют локальное обучение, нам не гарантируют локальности вычислений, но дают возможность строить такие аппаратные реализации, которые обладают этим очень полезным в прикладном смысле свойствами. Дальше я перехожу к фреймворку локального обучения. Мы выяснили, что основная проблема катастрофического забывания — это обратное распространение, и вот какие же у нас есть альтернативы. Один из популярных методов локального обучения это Хэббовская пластичность. Справа мы видим цитату переведенную Хэбба. в 1949 году постулировал, что изменение веса зависит от активности. Мы рассматриваем синапс. У нас есть пресинаптический сигнал и постсинаптический сигнал. И есть членинрейт. И вот изменение веса зависит от просто одновременной активности пресинаптического и постсинаптических сигналов. И еще важный тезис, он мне дальше понадобится. Такое вообще представление пластичности. Как и вообще говоря, весь Deep Learning существующий использует так называемый firing rate. формализм, а именно допущение о том, что спайки, которые наблюдаются в биологических системах или импульсы, превращаются в среднюю частоту, и это выражается непрерывными числами. Ну ладно, возвращаемся к Хэббовской пластичности. В таком виде определенное правило пластичности неприменимо, поскольку мы получаем проблему неограниченного роста весов. Когда у нас есть какие-то положительные вход и выход, мы постоянно увеличиваем вес, и это нам не позволяет получить полезного обучения. Поэтому придумано большое множество способов, как решить эту проблему ограничения весов. Есть правила ООИ, регуляризация, нормализация и другие подходы, которые в целом вводят какие-то ограничения, которые позволяют весам где-то стабилизироваться и не расти. Но нам все эти подходы не нравятся. Не нравятся они по следующей причине. И опять же, я к этому чуть-чуть издалека попробую подойти. Вот после уже хэба, совсем недавно, видите, би и мингпу. продемонстрировали, что величина изменения веса при приходе пресинаптического и генерации постсинаптических спайков она критически зависит от относительного времени. Вот это несимметричное временное окно, которое они зафиксировали в эксперименте, оно принципиально важно, потому что позволяет нейронам формировать причинно-следственные связи. То есть нам теперь становится не просто важно, что что-то произошло одновременно или не одновременно, а важно до или после друг друга. Вот это то, чего не хватает в классических подходах, это учет вот этой принципиально важной на наш взгляд временной динамики. И, соответственно, существует правило Spike Timing Dependent Plasticity, которое учитывает эту временную динамику. Правда, тут тоже возникает проблема ограничения роста весов. В случае наших экспериментов, это подход Михаила Киселева, решается с помощью следующего небольшого дополнения. Параметром, который обновляется при актах пластичности является не непосредственно вес, а так называемый синоптический ресурс. Это связанное с весом величина вот по такой вот формуле. И вот мы видим здесь график этого синоптического ресурса. Видно, что он ограничен двумя асинтетами и что, в общем-то, ограничивает нам значение веса, хотя значение ресурса может принимать любые значения. Такой подход используется в той архитектуре сети, в колонетах, о которой дальше пойдет речь. Ну и, соответственно, продолжая собирать фреймворк локального обучения, значит, еще один компонент, который нам показывает, понадобится — это конкурентность. Массом в 2000 году был описан такой паттерн winner-take-all, Он описывает наблюдаемый в биологии принцип латерального торможения. И бывает двух видов. Бывает Hard VTA, где это торможение безусловное, и Soft VTA, где торможение или подавление зависит от конкретной динамики. И вот в сочетании есть ряд работ. Самая известная из них – это вот эта вот работа «Unsupervised Learning with Digit Recognition». Из нее как раз картинка, которая демонстрирует, что использование STDP в сочетании с WTA, с конкуренцией, уже позволяет решать целый класс задач в области unsupervised learning. При некоторых допущениях здесь даже решается задача... Обучение здесь в unsupervised, но потом происходит ручная разметка, и поэтому получается, что в Inference решается задача классификации, которая вообще-то supervised. Последний компонент, который нам нужно добавить во фреймворк локального обучения, это модуляция обучения. Экспериментальные данные свидетельствуют о том, что пластичность может зависеть не только от пре- и постсинаптических спайков, а от некого третьего сигнала, его назвали модулируемым, В 1965 году Эрик Эндл и Владислав Таук изучали нервную систему улитки и предложили принцип ассоциативного обучения или модулируемой пластичности. В их эксперименте было замечено, что существует прессиноптический спайк, существует некий модулируемый сигнал, а вот постсиноптического спайка нет, а пластичность уже происходит. И она как раз зависит от наличия этого третьего модулирующего сигнала. Это было названо модулирующей пластичностью. Зачем нам это все нужно? Потому что это позволяет вставить нам задачи в терминах Supervised Learning или даже Reinforcement Learning, вводя полезную награду в наш фреймворк обучения. И тут хотелось бы назвать термины. Мы различаем однофакторную пластичность, когда изменение веса зависит только от активности пресинаптического нейрона. Хэббовскую пластичность, бывает еще антихэббовскую, когда изменение веса зависит от активности пресинаптического и посинаптического нейрона. Двухфакторную модулируемую пластичность, Пластичность, когда изменение веса зависит от активности пресинаптического нейрона и модулирующего сигнала, как в экспериментах, которые я описал. И, наконец, трехфакторную модулируемую пластичность, когда изменение веса зависит от трех факторов. Это пресинаптический сигнал, постсинаптический и модулируемый. В наших дальнейших экспериментах с Colonet будет использоваться трехфакторная модулируемая пластичность. Поэтому я об этом подробно рассказываю. Ну и, наконец, обобщение. Все, о чем я сейчас рассказал, это CTP, конкуренция, модуляция обучения, учет времени. Все это нам предлагает фреймворк импульсных нейронных сетей, на базе которого мы собираемся искать решения проблемы катастрофического забывания и непрерывного обучения. И здесь стоит сказать о том, что импульсные сети уже исследовались в контексте этой проблемы. Антоновым и другими, и в их работе не было показано эффективности просто применения импульсных сетей даже с локальным обучением к проблематике катастрофического обучения. И на наш взгляд это от того, что в их экспериментах не хватало некого еще одного важного компонента, а именно мы его назвали колоночная организация. Основная идея в том, что Для того, чтобы реализовать разграничение знаний между задачами, недостаточно функциональности одного нейрона. Для этого должны использоваться структуры более функциональные. Мы дальше это увидим, они будут названы микроколонками, которые содержат в себе и ВТА, и другие вспомогательные, всякие гейтовые штуки. И наша идея в том, что как раз выделив еще дополнительно в сети структуры, которые можно назвать микроколонками, мы получаем некий достаточный фреймворк для того, чтобы адресовать проблематику непрерывного обучения. импульсной нейронной сети, архитектуры колонет, которую придумал Михаил Киселев, мы как раз используем как объект наших исследований. Я постараюсь о ней кратко рассказать и, в принципе, мы имеем возможность задать вопросы ее автору. На данном слайде показана эта сеть в режиме инференса. Она состоит из десяти так называемых колонок. Эти штуки — это колонки. Колонок у нас столько же, сколько классов в задаче классификации, которую мы решаем. В нашей сети есть в каждой колонке 15 так называемых L нейронов. L потому что они learning, потому что они обучаются. И предположим, что их веса... Это полносвязанная сеть. Они связаны со входом размерностью 28 на 28, потому что это амнист. И вот мы имеем в каждой колонке 15 пластичных лиф нейронов. Кстати, все нейроны лиф, там с небольшим дополнением о нем попозже. С каждым нейроном ассоциирован WTA нейрон. И если нейрон L срабатывает, это приводит к тому, что срабатывает VTA нейрон, подавляя тем самым все остальные VTA нейроны в колонке и пропуская спайк на нейрон out. Подавленные другие L-нейроны, даже если они срабатывают, не пропускают спайки каут. И, собственно, каждая колонка накапливает за время предъявления картинки какое-то количество И мы смотрим argmax, какая колонка победила, тот класс и есть. В картинке у нас представляются сети на 10 вычислительных шагов или тактов. за которыми следует 10 шагов молчания. Молчание нужно для того, чтобы сеть расслабилась, чтобы все мембранные потенциалы лифнеронов утекли к своим нормальным значениям, хотя в данном эксперименте можно было бы, наверное, изменить этот протокол. Важный момент. Как мы превращаем картинки в спайки? На каждом вычислительном шаге вероятность генерировать спайк зависит от интенсивности пикселя. Условно, если у нас максимальная интенсивность, мы точно сгенерируем спайк со стопроцентной вероятностью. Если минимальная, то не сгенерируем. А если она, например, 128, то мы его сгенерируем с вероятностью 0.5. И будем это делать 10 шагов подряд. Таким образом, мы имеем возможность каждый вычислительный такт в реальном времени принимать решение о том, есть у нас спайк на входе или нет. Вот так картинки подаются в сети. Далее я уже сказал, как принимаются решения о классе. Переходим к обучению. Буквально пару слов, потому что это важно в контексте дальнейшего изложения, как колонет учится. Помимо входа в виде картинки, подаем на вход метку класса. У нас 10 меток, 10 колонок. Каждая метка ассоциирована со своей колонкой. Вот мы сейчас видим колонку для цифры 9, это десятая колонка. Метка стимулирует специальным образом некоторые дополнительные нейроны. Это BIAS gate и REF gate. Как у нас происходит обучение? В начале, и это принципиально важно, все нейроны L инициализированы нулевыми значениями. То есть их веса нули. Поэтому если им предъявлять какой-то вход, они сами не вносят никакого вклада в мембранный потенциал, и такие нейроны не могут сработать. Однако, такие нейроны начинают потенциироваться с помощью вот этого связи. У нас есть специальный нейрон Bias Gate, который, если получает сигнал отметки, он потенциирует все L-нейроны. Какой-то из этих L-нейронов спайкует, срабатывает механизм, через VTA он подавляет остальные нейроны. И через дополнительный механизм, через вот этот нейрон REFGATE, я о нем еще не успел сказать, он тоже стимулируется отдельной меткой. Вот если этот REFGATE получает активацию от VTA нейрона, он пропускает спайк получаемой отметки к нейрону L, Таким образом нейрон L увеличивает веса синапсов, на которые пришли спайки в определенное временное окно. То есть если какой-то паттерн привел, который сейчас был активен, его пытается нейрон запомнить. Вообще наша цель обучения специфицировать каждый из L-нейронов на разных представлениях одного класса. Мы предполагаем, что девятка может писаться разными способами, и мы хотим в процессе обучения получить такие нейроны, что каждый из них будет максимально возбуждаться на свой конкретный подкласс девятки. Мы предполагаем, что 15 подклассов нам хватит на нашу задачу, поэтому у нас 15 нейронов. Итого, когда мы начали обучение, у нас веса были 0, метко потенциировала bias gate какой-то из нейронов с работы, он получил подкрепление, и в следующий раз, если мы будем предъявлять похожий паттерн, именно этот нейрон при условии, что его также стимулирует bias gate, будет иметь большую вероятность сработать, и когда-нибудь этот нейрон так сильно обучится, что ему уже будет не нужна стимуляция Bias Gate, и он будет отвечать буквально сразу. Да, я еще забыл сказать, что эта стимуляция Bias Gate, она отложена на 10 вычислительных шагов, И наступает момент, когда у нас сайленс в сети, когда мы предъявляем пустую картинку. Таким образом, если нейрон успел ответить до наступления сайленса, то есть за время полезного предъявления картинки, то как бы VoiceGate уже не нужен и, собственно, дальше этот механизм не включается. Итого, вот это первый фактор, который нам обеспечивает обучение. Это увеличение от нуля в большую сторону весов тех синопсов, которые были активны во временном окне. при предъявлении картинки. Далее, у нас бывают такие случаи, когда у нас L-нейрон сработал и произошел спайк, зафиксирован нейрон имаут, но в этот момент вообще-то другая метка предъявлялась. и тогда синапсы, на которые пришел сигнал долго, их надо наказать, ослабить, и это второй фактор нашего обучения, антихэбовского обучения. Если у нас наблюдается сценарий, что L-нейрон сработал неправильно, то он наказывается, его веса ослабляются. И есть еще третий фактор, определяющий пластичность, это так называемая ренормализация синаптического ресурса. Это случающееся довольно редко по отношению к актам пластичности события. Если у одного нейрона есть сколько-то синапсов, тысяча, например, если мы 10 из этих синапсов увеличили на какую-то величину, то для того, чтобы этот нейрон не стал откликаться вообще теперь на все паттерны подряд, потому что раньше был ноль, а теперь как бы больше нуля, то мы на такую же величину пытаемся пропорционально уменьшить все остальные синапсы. То есть если какая-то группа синапсов у нейрона подросла, то все остальные синапсы из нуля станут отрицательными, что позволит этому нейрону менее часто отвлекаться по сравнению с нулевым нейроном на какие-то входные случайные паттерны. И вот эти три фактора у нас балансируют пластичность, увеличение весов через трехфакторную пластичность, уменьшение весов через антихэбовскую пластичность и синаптическая реанормализация. 

S01 [00:43:42]  : Извините, вопрос, Денис. У меня почему-то выскочило сообщение, что наша встреча через 10 минут заканчивается. Я не знаю, как поведет себя платформа. Если вдруг через 9 минут наша встреча закончится... Прервемся еще раз. Прервемся, перейдем и подсоединимся. 

S00 [00:44:02]  : Хорошо, предупредите тогда вовремя. 

S01 [00:44:04]  : Пока работаем. 

S00 [00:44:05]  : Да, ну и, собственно, я вот... заключительный слайд про колонет во всей этой архитектуре. Разумеется, я ее не описал полно. Я попытался сформировать интуицию о том, как это все работает. И вот мне важно теперь выделить весьма конкретные вещи в этой архитектуре, которые будут нам дальше важны с точки зрения непрерывного обучения. В Covonet используются несколько механизмов, с помощью которых можно управлять балансом пластичности в памяти и стабильности обучения. И в первую очередь это так называемый адаптивный порог срабатывания пластичных нейронов. Давайте чуть-чуть потратим внимание, чтобы в этом разобраться. У нас в классическом варианте есть значение порога, и когда это значение достигается за счет стимуляции этого нейрона, нейрон генерирует спайк. В нашей модели пластичные нейроны обладают адаптивным порогом, величина которого складывается из двух частей. Во-первых, это константная часть, пусть она равна единице. Но есть вторая часть, которая зависит от суммы положительных весов. Мы помним, что у нас веса в начале обучения нули, и поэтому вот этот вот это слагаемое, оно в начале обучения вообще не играет никакой роли, и у нас как будто бы константный порог срабатывания. Но если наш нейрон начинает специфицироваться, если его веса растут, то ему все сложнее начинает быть... его порог повышается, и ему начинает быть еще сложнее и сложнее отвечать на новые там случайные или не случайные импульсы. Вот это такая механика, достаточно примитивная, но она является ключевым элементом в том, чтобы закреплять нейроны на конкретных знаниях, конкретных задач и не давать им быть пластичными при обучении следующих задач. Есть еще два фактора, которые в целом эксперименты показали, что они не так важны, но тем не менее. Количество виртуальных синапсов. Я чуть ранее сказал об эффекте ренормализации синоптического ресурса, когда мы раз в какое-то время или по какому-то событию хотим накопленную величину изменений разбросать по всем другим синапсам с другим знаком. И вот тут мы можем сказать, что мы разбрасываем не только по реальным физическим синапсам, которые у нас есть, а еще сказать, что у нас есть любое количество виртуальных синапсов, и размазать эту величину по ним, снизив таким образом величину этого изменения. Ну и, конечно же, мы можем еще регулировать количество L-нейронов в микроколонках. Очевидно, что если мы много-много задач, 100 задач начнем решать, то нам 15 нейронов не хватит, чтобы их все выучить. Это некий третий фактор, однако понятно, что он приводит к высокой вычислительной сложности. И теперь, соответственно, мне бы хотелось буквально кратко... Я вот нажимаю кнопочку. Мы, оказывается, находимся внутри репозитория. Я потом все ссылки дам. Он доступен публично. Вот весь этот код включает в презентацию. Она там лежит. В общем, первое, что я показываю. Я хочу сейчас продемонстрировать, что те эксперименты, которые мы делаем, во-первых, они реальны, а во-вторых, их можно воспроизвести при каких-то допущениях. Либо при наличии фреймворка Arnyx, либо можно вообще любой другой фреймворк взять, и здесь все равно много всего полезного. Я только что рассказал об архитектуре колонет и теперь пару слов, как мы с ней работаем. Есть такой проприетарный фреймворк Arnix, в данном случае он представлен тремя файлами. Вот этот, вот этот и вот этот. Это собственно Arnie GPU-X, это его Core Form File, это модуль, который позволяет читать картинки удобным образом, а стоит Classifier, это модуль, который Accuracy считает в конце. Дальше у нас есть XML. Вот я сейчас открыл некий конфиг 2, в котором как раз описана сеть колонет, которую мы только что видели в виде презентации. Собственно, пока опускаю две секции ресепторс, вот, собственно, Секция. Надо сразу сказать, что колонет — это ансамбль сетей. То, что я сейчас показывал, — это один экземпляр. В колонет используется ансамбль из 15 таких экземпляров, и это один отдельный трек. Почему так? Сейчас, если будет вопрос, ответим. Итого, колонет состоит из секций. Вот у нас секция L нейронов, их 150 штук. 150 — это потому, что у нас 10 колонок по 15, получается 150. И вот есть какие-то настройки. И вот самое важное для нас будет тот самый адаптивный порог, про который я сейчас говорил. Это коэффициент альфа. Да, вот этот коэффициент альфа. Вот его значение. Вот оно. И в принципе мы можем им играть. Дальше у нас секция ВТА нейронов и так далее. И потом у нас также описываются связи между разными секциями. Самые важные связи у нас вот. Они единственные пластичные во всей этой архитектуре. Это связи между рецепторами и обучающимися нейронами. У них начальное значение ресурса, я напомню, что не вес, а ресурс таков, что вес 0. То есть на самом деле здесь написано, что вес 0. Ну и так далее. У меня сейчас нет цели подробно разобрать архитектуру, я лишь демонстрирую, как это все устроено. Дальше у нас есть exe-шник, которым мы, собственно, запускаем через консоль обучения результатам. В данном случае это занимает минут 15 и будет дополнительный шум, хотя я это воспроизвел недавно, не буду запускать сейчас. Результатом обучения являются лог-файлы, в которых есть Тоже accuracy в каком-то виде выведены, которые дальше можно обрабатывать. Вот так мы работаем с нашим экспериментом. Дальше теперь какие же эксперименты мы ставим. Перехожу к первому эксперименту. Он использует протокол Permuted MNIST. Мне нужно пару слов про этот протокол сказать. Его предложил Гаттфеллоу в 2013 году. Сначала про протокол, а потом, почему Гаттфеллоу им занимался. Идея следующая. Мы хотим создать много задач. для того, чтобы сначала поучиться на одной, потом на другой, потом на третьей и каждый раз замерять качество на прошлой задаче. Вообще-то у нас довольно сложно подобрать одинаковые датасеты и вообще сделать эти задачи удобными, одинаковыми. Godfellow предложил такой трюк. Мы можем сгенерировать так называемую случайную перестановку. И вот здесь как раз показано, что такое случайная перестановка. Это просто вектор чисел случайно перемешанных. Это сначала упорядоченный набор чисел от нуля до размерности картинки. И такая перестановка нам задает преобразование, которое мы можем применить к каждой картинке и получить, ну вот, что мы видим. Видите, мы к пятерке применяем одну случайную перестановку, потом другую, получаем картинки, в которых потеряны пространственные паттерны. Конечно, это не дает их теперь классифицировать человеческим глазом, сверточными сетями. Однако, если мы работаем с такими картинками полносвязанными сетями, то вообще-то для них информативность не изменяется. Если мы такую перестановку одинаковым образом применим ко всем картинкам датасета Manista, то мы получим новый датасет, которые мы можем использовать для новой задачи. Мы можем взять таких перестановок сколько угодно и нагенерить таких задач сколько угодно. В данном случае мы генерируем 10 штук. Ну и, в общем, вот, собственно, здесь демонстрация того, как это делается. Ну давайте глянем. В общем, все это можно воспроизвести. Я сейчас В общем, если будет вопрос, я это все перезапущу. Но что здесь происходит? Мы берем из кероса обычный MNIST, stack and train test, и в бинарном виде каждую картинку вытягиваем и по байтово пишем в бинарный файл. Вот ровно этот бинарный файл используется в нашей конфигурации. Я ее чуть раньше скрыл. Вот здесь мы прямо на него ссылаемся, когда говорим, откуда колонет читать данные. Так, возвращаясь к генерации. Дальше у нас есть некий код, который генерирует эти перемутации и 10 датасетов. Вот у нас есть бинарник с оригинальным датасетом и 10 его перемутаций, по сути, датасетов со случайными перестановками. Ну и для всех них еще генерируется файл с меткой ministarget, в котором в каждой строчке метка класса, номер строчки — это номер объектов в датасете. Вот у нас есть такой фреймворк. Теперь с чего начнем? Давайте обучим просто обычную классическую не спайковую сеть, и просто это будет наш бейслайн. Посмотрим, что будет. Тетрадка есть накаговую, она тоже публично доступна, ссылка на нее в рядме. Я кратко по ней пробегусь. Что у нас здесь показано? Мы берем MNIST, берем обычную полносвязанную сеть, в которой один слой на 512 нейронов. Вот он. Вот у нее вход по размеру картинки. И в конце 10 нейронов для классификации Softmax. В общем, элементарная, наиболее простая сеть. И она нам позволяет получить уже 98% при обучении манистер. Тут небольшое отступление. Я чуть-чуть раньше сказал, что этот протокол предложил Goodfellow. И вот он в своем эксперименте использовал двуслойную сеть по 256 нейронов, вместо однослойной, как вот здесь. И его качество классификации было в районе 80 с чем-то, может быть даже 87 или 88, но ему на это было плевать, потому что он пытался найти признаковые представления, которые бы сохранялись между задачами даже в протоколе Permuted NIST, когда эти задачи не имеют между собой общности. Ну и надо сказать, что он их не нашел, и вот он ради этого писал работу. Но потом все стали использовать в экспериментах на Permuted NIST двуслойную сетку на 256 нейронов, хотя это с практической точки зрения На мой взгляд, неоправданно. Лучше использовать сетку попроще, она гораздо качественнее задает бейзлайн. Что мы делаем? Мы можем обучить эту сеть. Отлично. Теперь мы генерируем 10 пермутаций. Я пропускаю этот момент. И хочу чуть подробнее рассказать про то, что получается. В итоге мы проводим такой эксперимент. Мы одну и ту же сеть обучаем сначала на первом наборе данных, потом на втором, потом на третьем. Это одна и та же сеть, которая последовательно обучается на разных наборах данных. И каждый раз мы замеряем качество на всех прошлых тестовых датсетах. Вот эта строчка показывает, что будет, если случайно инициализированную сеть просто прогнать на всех тестовых выборках всех датасетов. Мы видим там 10%, что, в общем-то, случайное значение. Вот эта вторая строчка. Мы обучились на первом датасете, и качество на первом датасете у нас 96, ну почти 97. Кстати, 96, а не 98, это потому что мы используем одну эпоху, а не сколько-то было выше, перейдя уже в парадигму онлайн-обучения. Но все остальные задачи у нас показывают как бы рандом, десятку. Ну и дальше, чем больше учимся, в самом конце мы учимся уже на десятой задаче. Получаем здесь какую-то метрику, но мы видим деградацию качества. Чем дальше мы учимся, тем больше деградация. И вот на 10 задачах мы почти на 50% качестве потеряли. Давайте посчитаем это за наш бейзлайн. Ну и дальше что мы хотим сделать? Мы хотим взять и в таком же эксперименте запустить колонет и посмотреть, что будет. Ну и вот об этом, собственно, папочка test1. Я, опять же, просто пару слов, чтобы это можно было воспроизвести, как все устроено. Есть, по сути, 55 последовательных запусков ArniX, то есть 55 конфигов. Первый конфиг говорит запусти KovaNet на первом датасейте. Во втором конфиге сеть уже берется из обученного, ну из файла, который получен из первого конфига, ну и так далее. Сначала мы девять раз так сеть прогоняем по всем датасетам и потом все остальное это валидация на отложенных выборках, чтобы посмотреть деградацию качества. Мы проводим там большое число экспериментов. В конце мы провели кучу экспериментов с разными гиперпараметрами, такими как значение адаптивного порога, о котором я чуть ранее рассказывал, и так далее. Получаем там кучу логов и у нас есть скриптик, который их умеет агрегировать, показывать их в виде вот такого лога. И мы в принципе для каждого значения гиперпараметров знаем матрицу деградации, которую я только что описывал, и вычисленные значения всех гиперпараметров. Дальше я возвращаюсь в презентацию. В таком формате, наверное, будет удобнее на это смотреть. Вот мы взяли колонет, которая оптимизирована на Манисте специальным образом, генетическим алгоритмом. И она сходу показывает полную устойчивость. Вот мы ее прогнали. Мы видим, что качество на первой задаче после обучения на десятый вообще не упало, а даже выросло. Скорее всего, потому что какие-то нейроны еще дополнительно специфицировались. Но при этом сеть абсолютно не обладает пластичностью обучения. По всей видимости, много нейронов закрепилось на первой задаче, они перестали быть пластичными. Потом какая-то еще часть смогла быть пластичной на второй задаче. И чем дальше, здесь уже качество близкое к случайному, сеть не может обучаться новым задачам. Давайте повысим очевидное действие. позволим нейронам быть более пластичными, более легко отвечать на новые паттерны. Например, мы понизим альфа, то есть уменьшим вклад второго фактора в сумме, который я рассказывал. И вот мы проводим множество экспериментов и рисуем две кривые. Одна из них это качество, общее решение задать. усредненное, а второе – это меры забывания. Вот видно, что начиная с какого-то по шкале x это значение как раз альфа, того самого значения адаптивного порога. В общем, мы видим, что начиная с какого-то значения альфа до оптимального значения у нас сеть просто не забывает. Но при этом качество зависит. Мы отсюда можем выбрать оптимальное значение, при котором у нас и хорошие метрики забывания, и хорошее общее качество сети. Ну и вот условно лучшая метрика, которую мы получили на 15 микроколонках. И так как у нас много задач, очевидно, что если мы добавим больше микроколонок, сделаем их не 15, а побольше, то у нас иметрики должны возрасти. И, собственно, вот результаты колонет. на 45 микроколонках с какими-то оптимальными значениями адаптивного порога. Что мы здесь видим? Что у нас одна сеть способна как минимум 10 задач, а может быть и больше, выучить. Наверное, здесь можно зафиксировать, что уже началась какая-то небольшая деградация. Можно с ней поработать. Но хорошо то, что у нас вот здесь 89% и мы всего на 4% деградировали за 10 задач. Это в принципе довольно хороший результат вообще для... в целом, для всех других подходов. О сравнении я скажу чуть-чуть попозже. И вот здесь итоговая таблица. На ней, наверное, сейчас останавливаться не будем, но мы просто рассчитали все метрики для базовой конфигурации, которую я показывал. других конфигураций. Теперь продолжаем. Это был эксперимент Permuted MNIST. В чем его особенность? В том, что задачи друг на друга вообще не похожи. В задачах нет общности. И вообще-то нам это вырубает возможность использования прямого переноса. То есть никакие паттерны, полученные на одной задаче, не оказываются полезными для другой задачи до обучения. То есть, во-первых, это вырубает нам возможность использования всяких механизмов типа сверток, а во-вторых, это нам еще вырубает возможность использования прямого переноса. Давайте попробуем теперь взять задачи, которые получены более естественным образом. Есть такой датасет E-MNIST, Extended MNIST. Он довольно обширный и в нем содержатся буквы в таком же формате, как MNIST. Их там много в разных вариациях. Есть работа Антонова, на которую я ранее ссылался, в которой как раз был поставлен некий бенчмарк, было выбрано 10 конкретных букв, они здесь на экране. из которых мы можем построить, по сути, вторую задачу в терминах непрерывного обучения. Первая задача у нас — распознать цифры, вторая — распознать буквы. Так как у нас из EMNIST удается получить только 28 тысяч изображений, то мы и Data Set MNIST тоже, я напомню, в нем 70 тысяч, мы его тоже ограничиваем 28 тысячами. Пару слов. Опять же, устроено все примерно так же. У нас есть последовательность конфигов, которые мы запускаем. И на выходе фиксируем для разных значений параметров, разные профили деградации, разные метрики. Вот что мы видим. Мы провели довольно много экспериментов, и как мы ни стараемся, нам не удается получить приемлемых метрик. Забывание даже в эксперименте на двух задачах составляет 30-40%. При этом у нас также есть baseline на MNIST, полученный аналогичным образом. Тоже есть тетрадка, ссылки на нее есть, где мы взяли ровно ту же самую нейронную сеть. И обучили ее сначала на МНИСТе, потом на ЕМНИСТе и померили деградацию. Если в эксперименте Permuted MNIST она составляла 5-7% между задачами, то здесь она 50-60% между задачами. То есть, смотрите, одна и та же, даже не импульсная, обычная сеть на протоколе permuted показывает 7% между задачами деградации. А вот на двух задачах, которые обладают общностью, деградация вообще чудовищная. Третья задача вообще будет нереалистична к решению. Возвращаемся в презентацию. Также у нас импульсные сети как-то себя плохо ведут, и Colonet со всеми своими возможностями по непрерывному обучению показывает достаточно посредственные результаты. Однако, что можно из этого полезного получить? Я напомню, что Colonet – это полносвязная сеть. И таким образом мы имеем возможность визуализировать рецептивные поля обучающихся нейронов. Собственно, они здесь и визуализированы. Каждая строчка соответствует колонке. У нас 10 колонок по числу классов. Каждый столбик соответствует микроколонке или одному из 15 нейронов L. Вот мы сейчас видим рецептивные поля всех обучающихся нейронов одного экземпляра сети колонет из ансамблев 15. И что мы наблюдаем? Мы наблюдаем эффект разделения параметров. Мы видим, что разные нейроны специфицировались на разные способы написания разных цифр. Какие-то цифры обладают большим разнообразием, какие-то меньшим. Для цифры 1 нам понадобилось всего 5 нейронов, чтобы условно учесть все единички, а вот двойки, похоже, не влезли. Ну и это как бы очень здорово. Давайте теперь посмотрим, как выглядят рецептивные поля, если сначала поучиться на МНИСТ, а потом на ЕМНИСТ. И вот это как раз представляет интерес. Смотрите, мы видим, что примерно половина нейронов первой колонки специфицировалась на 0, а другая половина на букву А. Я не знаю, хорошо ли видно, я могу еще увеличить, но в принципе паттерны довольно хорошо узнаются. Можно посмотреть, и мы в принципе здесь наблюдаем как раз то клонет, несмотря на то, что общие метрики не очень хороши, при этом мы, используя визуализацию через рецептивные поля, достаточно Четко наблюдаем явление разделения параметров уже между задачами. Мы видим, что одна колонка в себе сочетает как паттерны одного класса, так и другого. Ну, и там был однажды задан вопрос, а что будет на 45? Вот примерно, сейчас я опять же тоже поувеличиваю, будет вот так. Что будет, если дать настолько большую сеть, что там будет много паттернов? Ну, мы видим, что в ней свободные места таки остаются. Ну, и так далее. Итак, перехожу, собственно, к сути, к ключевому месту доклада. а именно к сравнению результата. Вот что мы только что увидели. Мы увидели два эксперимента. Один на 10 задачах с использованием перемотации, другой на двух задачах, полученных с помощью MNISTA и EMNISTA. Вот хочется теперь сравниться, сказать, а хорошо, а хорошие мы метрики получили или плохие. Во-первых, ну такой дисклеймер, первое же сравнение в области непрерывного обучения это довольно сложно, потому что все используют разные архитектуры сети, разные протоколы обучения, там разное количество слоев, эпох, там кто-то Eulestoping, кто-то еще что-то. кто-то использует допущение по памяти, создает реплей буфер и так далее. Поэтому очень сложно между собой сравнивать подходы. Нам удалось найти в случае с протоколом Permuted NIST очень похожую работу. Там вот ссылка на нее снизу, где была взята сеть, как у Godfellow в эксперименте, ну, собственно, аналогичная нашей, и оценены state-of-the-art подходы с воспроизведения. Они считаются наиболее эффективными с точки зрения непрерывного обучения. И вот мы видим, что колонет как на 15, так особенно на 45 колонках с поправкой на архитектуру превосходит State of the Art на несколько лет назад в подобном бенчмарке. Ну и это хорошо. Но смотрим дальше на эксперимент на двух задачах. Вот работа Антоновов, в которой была взята импульсная сеть, трехслойная сеть, которая весьма специфическим образом обучалась. И вот эта сеть показала забывание 42, что достаточно много. Наша сеть показывает забывание 43, что тоже много. И вот в работе Антонова были проанализированы разные другие подходы, в частности, например, запоминание 10% данных на первом датасейте, дропаут и так далее. Joint training — это объединение данных для обучения, и self-reminder, когда мы 10% данных запомнили, вот эти два подхода позволили получить достаточно низкие метрики забывания, но никак не подход, связанный с оригинальным применением импульсной сети. Ну и, собственно, это, в общем-то, воспроизводит наш результат. Но тут как бы остается последний вишенка на торте, тезис. Почему так происходит? Ну и вообще, чего с этим можно делать? Наш ответ, собственно, я уже это несколько раз озвучивал, в том, что проблема в общности между задачами. Так как у нас однослойная сеть, то признаковые пространства, с которыми мы работаем, они очень сильно похожи друг на друга. Как это можно было бы решить? Тот путь решения, которым хотелось бы двигаться, но который требует дополнительных исследований, это введение иерархии. И тут хочется использовать тезис. Кажется, что если бы мы использовали колонет только на глубоком уровне иерархии, имея какую-то иерархически устроенную сеть, то уровень общности в признаковом пространстве на глубоких уровнях иерархии был бы гораздо меньше, чем на высоких. Но мы это наблюдаем как в биологии, так и в сверточных сетях, когда верхние слои, которые распознают палочки, кружочки, все это очень похоже друг на друга. Чем глубже мы падаем по уровню иерархии, тем уровень общности признаковых представлений снижается. Если применять колонет на высоком уровне иерархии, то там общности не будет, и мы в принципе будем наблюдать ту же ситуацию, как спермьютит вниз. Это некий нейробиологореалистичный подход и на мой взгляд перспективный к решению. Но есть еще один подход, инженерный трюк. А как можно еще убрать общность из задач? Мы только что видели, мы вообще-то можем применить пермутации или случайные перестановки. одну перестановку к МНИСТу, другую к ЕМНИСТу и таким образом убрав перестановку. Если так сделать, то на 10 экспериментах мы получаем метрики забывания, которые даже лучше, чем joint training. Колонет оказывается в таком эксперименте тоже показывает эффективность. Вообще, применение перемутации с точки зрения реализации алгоритмической, да даже в аппаратном обеспечении, никого не пугает. По сути, это ревайринг, сигналы по-другому направить. Но это, конечно, не нейроморфный трюк, но, однако, который может использоваться уже для прикладного применения. Ну и чтобы как бы закрепить этот тезис, типа не случайно ли это получилось, последний маленький эксперимент, он тоже здесь есть, мы взяли уже из Extended MNIST еще одну задачу, сделали из других буквок, ну и показали, что если применить к датасетам предварительную перемутацию, а это, кстати, обратимая процедура, поэтому мы можем восстанавливать назад картинки, то метрики забывания показываются такие же хорошие, как и в эксперименте на Permuted Mist. На этом у меня все. Ссылки я попозже опубликую. Это ссылка на группу, где можно вступить в контакт, пообщаться и на гид, где лежат все материалы. Так, у меня все готов. Что-то прокомментировать, ответить на вопросы. Спасибо. 

S01 [01:15:41]  : Ага, Денис, спасибо. Коллеги, если у кого-то есть вопросы, задавайте в рамках живого микрофона. Тут у нас вроде народу немного. У меня, знаете, сразу несколько вопросов есть. Во-первых, вот то, что вы показывали, я там увидел кусочки кода на питоне. Я правильно понимаю, что то, что вы сейчас показываете, это на самом деле все сделано на том же самом питоне, реализация вот этого кола нета. И идет как бы симуляция вот этой вот асинхронности. 

S00 [01:16:12]  : Нет, смотрите, колонет есть конфиг в XML, вот он. Вот он описывает структуру колонет, вот какие в ней слои, что взять на вход из какого файла, как получить результат. Потом есть волшебный фреймворк ArnieX. Его можно… А он на GPU. Это вот то, что как раз Михаил… Да, вот его в исследовательских целях можно запросить доступ к нему у Михаила, написав ему там на почту. Собственно, есть веб-сайт, с которого можно этот запрос сделать. Вот дальше, если у вас есть этот фреймворк, есть вот этот экзешник, он бывает еще под CPU, то вы можете просто через терминал его запускать и получать… результаты экспериментов. А дальше есть к этому всему фантик в виде питона, всяких CMD-шников. Это просто, как сказать, обработка логов экспериментов. Вот видите тут, ну вот, как их запустить через CMD вот под Linux и все такое. Вот этот код, который читает логи Михаила, ну в целом это Здесь еще есть результаты, если кому-то это будет полезно, запусков с разными гиперпараметрами, если кто-то захочет посравниваться. 

S01 [01:17:32]  : Ага. И следующий вопрос. Вот вы там в какой-то момент упомянули, что у вас число колонок соответствует числу задач. Вот. Ну а вот в реальной жизни, когда у нас задач становится больше, чем колонок, Как эта проблема решается? 

S00 [01:17:50]  : Тут не задача. Я поправлю. Мы число классов внутри задачи. То есть, например, у нас задача управления движением, и мы можем двигаться вверх, вниз, влево, вправо. И вот в каждой задаче у нас только такие контролы. А при этом игры могут быть разные. 

S01 [01:18:08]  : Одна колонка может отвечать за распознавание разного класса в разных средах. одного класса, то есть одна колонка отвечает за класс, но в разных средах и в разных задачах. 

S00 [01:18:26]  : Да, при этом вот видите, мы сейчас специфицируем, вот у нас одна колонка, вот, и вот часть у нее специфицировалась на один, ну на первый класс первой задачи, а вторая на первый класс второй задачи. 

S01 [01:18:43]  : То есть у нас колонки могут совмещать получается, да? 

S00 [01:18:46]  : Если бы мы на 10 датасетах учились, мы бы ожидали увидеть здесь все возможные способы написания всех первых классов во всех задачах. 

S01 [01:18:58]  : Ну, я тогда перейду. А смотрите, а у нас не получается, что вот когда у нас начинается переполнение, когда у нас, если мы, грубо говоря, ограничиваем свою систему там пятью колонками, а задачи классов и сред у нас становятся сотни, то мы на самом деле проваливаемся в те же самые графики с забыванием, которое вы показывали. 

S00 [01:19:22]  : Все верно. То есть это тонкий момент, как правильно выбрать, сколько у нас должно быть микроколонок или сколько у нас L нейронов для того, чтобы на данном количестве задач мы смогли учесть все разнообразие. И тут, конечно, есть такой подход в лоб, а давайте просто увеличим число микроколонок. Но не хочется в эту сторону двигаться, поскольку кажется, что если бы мы ввели иерархию, то иерархия бы могла на себя как раз забрать эту проблему, выделив общность. И тогда бы нам осталось... Да, мы бы, конечно, потеряли возможность смотреть такие красивые рецептивные поля, но нам бы гораздо меньше нужно было бы нейронов, чтобы описать все разнообразие, если бы общие признаки были формализованы на более верхних слоях или нижних, не знаю как. 

S01 [01:20:17]  : Ну, с этим трудно не согласиться, но все-таки я выступлю в качестве адвоката дьявола и спрошу, окей, а если мы тогда просто тоже будем в нейросетях классических увеличивать количество нейронов и количество слоев, за счет количества слоев увеличивать иерархию, А за счет количества нейронов в слое увеличивается пресловутая емкость. Может быть мы там тоже будем? У нас не будет. 

S00 [01:20:43]  : Опыты показывают, что нет. И почему нет? Потому что на новых задачах у нас нет эффекта закрепления знаний от прошлых задач. Условно вот эти нейроны, они видите на разных ноликах специфицировались, и так как у них есть положительные большие веса, теперь их настолько сложно вообще разбудить для пластичности, что на новых задачах они скорее всего не будут меняться. И это и есть ключевая фишка локального обучения. Вот бэкпропом мы бы их просто меняли, ну, независимо от той задачи, которую мы решаем. И чем дальше учимся, чем больше эпох, тем мы вот эти нолики бы больше размывали. 

S01 [01:21:22]  : Ну, понятно. То есть все-таки речь идет о том, что вот эта вот колоночная организация позволяет добиться некоторой локальности обучения. Вот. И за счет... А вот эти самые большие нейросети, они всегда учатся глобально. 

S00 [01:21:37]  : Когда мы бэкпропом учимся, у нас нет возможности оставить какую-то часть сети нетронутой при акте пластичности. 

S01 [01:21:49]  : А можно, вот у меня в какой-то момент возник тезис, наверное, неправильный, но вот как бы вы на него ответили, можем ли мы сказать, что у нас каждая колонка решает задачу бинарной классификации, распознавая тот класс, который она предназначена распознавать? 

S00 [01:22:07]  : Так и есть. И как она это делает? Сейчас я листаю на inference. У нас, по сути, каждая колонка вносит свой вклад количеством спайков, которые сгенерировал некий последний аут нейрон. Какая колонка больше спайков сгенерировала, такой класс у нас и есть. В принципе, не совсем бинарная классификация. Но очень похожий, наверное, принцип. 

S01 [01:22:36]  : А вот еще вопрос от Ивана. Что за виртуальные веса? 

S00 [01:22:40]  : Можно подробнее? Да, смотрите. Центральная идея в том, что мы начинаем с нулевых весов. И когда мы встречаем какой-то случайный новый паттерн, у нас нейроны, в которых нулевые веса, но им нужна какая-то дополнительная стимуляция, чтобы специфицироваться. Допустим, у нас возникнет какой-то нейрон, который какие-то свои веса увеличит, ну просто какую-то маленькую группу. И тогда, если больше ничего не сделать, то этот нейрон теперь всегда будет выигрывать у нулевого нейрона, потому что у него хоть какие-то положительные связи есть и вероятность на случайный паттерн откликнуться будет больше. Как с этим побороться? А давайте мы у этого нейрона, у которого мы увеличили веса, другие веса понизим. И тогда у него уже будет отрицательный вклад, который будет откликаться меньше. Теперь вопрос, а насколько мы понизим? Чтобы варьировать эту величину, как раз вводится число виртуальных синапсов. Представьте, что повысили синапсы, положительные мы, на 10 каких-то единиц. У нас всего там 1000 синапсов. Это значит, что на остальные 990 синапсов мы должны раздать минус 990, точнее 10 поделить на 990, то есть всем по чуть-чуть. Но мы можем еще сделать эту величину меньше, размазав ее по так называемым виртуальным синапсам. Мы можем сказать, что еще у нас есть миллион виртуальных синапсов, и тогда вот этот вот минус будет уже не поделить на 10 тысяч, а поделить на миллион. И величина вот этой вот ренормализации станет меньше, и такой нейрон станет более легко откликаться на новые случайные паттерны. Мы его не так сильно в минус опустим. Не знаю, понятно я объяснил или нет. Возможно, Михаил мог бы уточнить. 

S02 [01:24:53]  : Ну, в общем-то, это примерно так. Я еще по предыдущему вопросу хотел бы добавить вот какую вещь. Вот в этой ступле имеется фактически две размерности. Это число колонок и число микроколонок в колонке. Число колонок, как правило, нам известно, потому что если мы решаем задачу классификации, мы, по крайней мере, эти классы-то знаем. Мы знаем, сколько их, какие они, поэтому число колонок оно фиксировано. А число микроколонок может быть сделано адаптивным. Как было показано на одном из слайдов, в случае единички у нас реально задействованы только три микроколонки. Остальные фактически вообще не играют никакой роли, потому что у них остались нулевые веса. Вот в моей архитектуре предусмотрена, в принципе, динамика, то есть те нейроны, которые вообще подавлены полностью, а получается, что у нас вот в этой ничке у нас есть один большой чемпион, несколько, четыре нейрона, которые как-то более-менее когда-то что-то вякают, и есть куча нейронов, десять, которые вообще молчат-молчат всегда, они полностью подавлены. чтобы их не тратить, можно их оттуда убрать и переместить другие колонки, где, допустим, в двоечку, где нам, возможно, не хватает неровов. Такая адаптивность на предусмотре. Это позволяет нам, не зная... Конечно, мы не знаем априори, сколько будет у данного класса подкласс. Это априори неизвестная вещь. Но за счет такой адаптивности она может быть настроена, то есть мы берем много когда они как-то мигрируют так, чтобы адаптивно приспосабливаться к сложным и простым классам. Дополнение к ответу на предыдущий вопрос. А насчет этих виртуальных синапсов, да, это просто такая техническая мера, которая позволяет механизм резормализации плавно изменять по его действенности. Если у нас нет совсем этих виртуальных синдромах, у нас он полностью действует, то есть у нас общий суммарный эстетический ресурс одного нейрона всегда постоянен, а в случае, если их много, то он не действует. 

S01 [01:26:53]  : История с миграцией нейронов между колонками, это вообще зачет. Это круто. 

S02 [01:27:00]  : Да, технически это в принципе не сложно реализуется, это как бы сделано 

S01 [01:27:06]  : Еще у меня вопрос, спасибо за ответ на предыдущий. Вот смотрите, Сергей Шумский рассказывал на своих семинарах, как минимум на последнем, а может быть и раньше, что тоже подобную архитектуру они делают с многоколоночными делами и вроде как тоже у них там относительно хорошо за тем получается и вопрос тогда а вот в чем выигрыш именно многоколоночности при реализации на импульсных архитектурах за исключением этой численной энергоэффективности за счет принципа WinRTX All. Какие-то еще плюшки есть в форме энергоэффективности WinRTX All? 

S00 [01:27:52]  : Иммиграция нейронов. Последний тезис не понял, но в целом, если вопрос ставится, почему импульсные сети хороши, потому что они позволяют Вот при данных допущениях, при использовании конкретной архитектуры, а именно с колоночной организацией, отвечать на проблематику непрерывного обучения. А другие подходы на нее не отвечают или отвечают с гораздо худшими допущениями. Вот это, помимо энергоэффективности, чем это хорошо, если я правильный вопрос услышал. 

S01 [01:28:28]  : А, кстати, Михаил же, по-моему, в прошлый раз показывали какие-то начальные эксперименты с пинг-понгом. С пинг-понгом там нет прогресса у вас? 

S02 [01:28:41]  : С пинг-понгом пока нет, потому что пинг-понг требует довольно сложные штуки, он в общем-то требует model-based reinforcement. Это я говорил в контексте reinforcement learning. Пинг-понг требует моделирования. То есть, если у меня шарик двигается быстро, а ракетка медленно, то просто стимул реакции здесь не годится, потому что у нас редкие достаточно. Но если мы ставим по честному сдачу, то есть мы получаем, даем на сеть доказание, когда она шарик пропускает, а прощаем, когда отбивает, то эти сигналы редки. И поэтому, если мы не можем планировать, если мы не можем выстраивать длинных лично-следственных связей, что привело к неудаче или к удаче, то, соответственно, бесполезно делать там RL. Но я сейчас работаю над тем, чтобы имплементировать в достаточно полном объеме Model-based RL в импульсных сетях, но пока это большая работа, она пока еще далеко не закончена. 

S01 [01:29:45]  : Спасибо. Вопрос от Ивана еще. Можно ли подробнее про адаптивный порог? 

S00 [01:29:52]  : Да, попробую еще раз. Вот тут целый слайд. Смотрите, у нас есть модель LIF нейрона. Она о том, что у нас есть динамически меняющийся мембранный потенциал. и он, если ничего не происходит, утекает к нормальному значению, а если нейрон потенциируется положительными импульсами, то этот мембранный потенциал растет, растет, растет, и когда-нибудь он достигает порогового значения, которое здесь обозначено U-threshold, при котором нейрон генерирует спайк, и этот мембранный потенциал падает опять к своему нормальному значению. Это обычная модель. Обычно в этой модели само значение порога является константной, пусть единичкой для простоты. Тогда получается, что для того, чтобы нейрон спайканул, его нужно с какой-то силой потенцировать. Но мы можем нейроны, которые уже чему-то научились, Закрепить. Сделать так, чтобы они гораздо сложнее спайковали на входной стимул. И как мы это можем сделать? Мы можем к величине срабатывания, к величине этого порога добавлять еще одно слагаемое. которая зависит от суммы только положительных весов. У нас синапсы есть и положительные, и отрицательные. Мы берем только положительные, их все складываем и получаем какое-то большое положительное число или не очень большое. Умножаем его на наш коэффициент, который в тысячных измеряется, и складываем с порогом. Таким образом, если у нас нейрон нулевый, то у него порог срабатывания маленький. А если он уже имеет большие веса, то порог срабатывания увеличивается на это слагаемое, и этот нейрон считается закрепленным. 

S01 [01:32:01]  : Спасибо. Коллеги, есть еще вопросы? Если вопросов нет, тогда, наверное, хотелось бы поблагодарить Дениса и Михаила за историю интересную, полезную, нужную, важную. Будем тогда ждать, когда можно будет с помощью этой технологии управлять роботами, пинг-понгами, 

S02 [01:32:37]  : Я хотел бы добавить, что колонет является базовой структурной единицей для более сложных сетей, которые уже решают не только задачи классификации, но и задачи reinforcement learning, потому что это некая типовая структурная единица. Как эти структурные единицы объединять, что-то более хитрое. Собственно, на это мы сейчас и работаем. И это как раз будет ответом на IRL и на все остальные типы задач, которые выносится. 

S01 [01:33:10]  : То есть, решение задачи пинг-понгов и всего остального, оно сводится к построению когнитивных архитектур на основе вот этих базовых многоколоночных матриц с элементами иерархии. Правильно я понимаю? Да, примерно так. И, очевидно, иерархии тоже будут самоорганизующиеся, и колонки смогут бродить между сегментами колонок. Да. Отлично. Ладно, тогда будем ждать продолжения и надеюсь, что с кем-то здесь присутствующих увидимся в Москве в обозримой перспективе. Ну и на наших семинарах. 

S02 [01:33:49]  : Да, ну на нейроинформатике, я думаю, тут многие будут. 

S01 [01:33:53]  : Хорошо, ну и приглашаем в ближайшие четверги. У нас сейчас планируется активная работа в ближайшие несколько месяцев по четвергам. Денис, спасибо огромное. Михаил, спасибо огромное. Спасибо всем участникам. До свидания и до новых встреч. 

S00 [01:34:09]  : Спасибо. 

S01 [01:34:09]  : До свидания. Всем всего доброго. Спасибо. 

S00 [01:34:15]  : Спасибо. Всего доброго. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html


