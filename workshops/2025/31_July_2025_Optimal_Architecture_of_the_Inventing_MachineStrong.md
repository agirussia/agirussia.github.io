# 31 июля 2025 - Оптимальная архитектура Изобретающей машины (Сильного ИИ — делающего научные открытия) — Евгений Гарин (Директор центра долгосрочного прогнозирования НТР и СЭР ИНЭС РАН)
[![Watch the video](https://img.youtube.com/vi/yP9OdhRlGQY/hqdefault.jpg)](https://youtu.be/yP9OdhRlGQY)
- [видео в RUTUBE](https://rutube.ru/video/03f5b3d7dafc7a6d74e4405c54f38a32/)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239223)
- [расшифровка](https://github.com/agirussia/agirussia.github.io/blob/main/workshops/2025/31_July_2025_Optimal_Architecture_of_the_Inventing_MachineStrong.md)
- [слайды](https://github.com/agirussia/agirussia.github.io/blob/main/presentations/2025/2025-07-31-Garin-Invention-Machine-ASI.pdf)

# Краткое содержание:

## Изобретающая машина: Прорыв к сильному искусственному интеллекту через "лакуны" в научных знаниях

На летнем семинаре русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта Евгений Гарин представил доклад о создании **"изобретающей машины"**. Эта система, основанная на концепции сильного искусственного интеллекта, способна совершать научные открытия и изобретения без блока целеполагания, работая как в гибридном режиме "человек-машина", так и полностью автономно.

В основе концепции лежит анализ **"лакун"** — пробелов в научных знаниях, которые выявляются с помощью статистического анализа больших корпусов научных текстов. По словам Гарина, изначально эта работа была связана с исследованиями профессора Громова из Высшей школы экономики, который изучал семантическую близость языков и обнаружил так называемые "языковые дыры".

### Ключевые моменты доклада:

*   **От языковых "дыр" к научным "лакунам":** Исследователи перешли от анализа отдельных слов и n-грамм к анализу **"концептов"** — осмысленных фрагментов текста, таких как определения, свойства и закономерности. Анализ семантической близости между этими концептами позволил выявить **"лакуны"** в научных знаниях. По прогнозам, в центральной, наиболее плотной области науки, существует около 2200 таких лакун, а на периферии — до 900 тысяч.

*   **Метод графов для выявления "лакун":** Для визуализации и анализа этих пробелов используется теория графов. Свойства и концепты представляются в виде графа, и отсутствие связи между узлами указывает на **"лакуну"**. Примером послужила задача математического моделирования строения социума, над которой работали многие выдающиеся математики с 1965 года. Анализ показал, что два из восьми ключевых свойств модели никогда не пересекались в исследованиях, что и являлось "лакуной".

*   **"Лакуны" как следствие ложных знаний:** Важным выводом стало предположение, что **"лакуны"** возникают не из-за нехватки информации, а из-за наличия ложных знаний или ошибочных интерпретаций. Устранение ложного свойства приводит к **"схлопыванию"** лакуны и созданию более полной и непротиворечивой модели.

*   **Практическое применение и результаты:** Этот подход был проверен на наборах данных Росатома и Роскосмоса. Были получены потенциальные открытия, которые сейчас проходят проверку профильными учеными. Одно из них — новое корпускулярное свойство света, применимое в лазерных технологиях.

*   **Сравнение с большими языковыми моделями:** Гарин утверждает, что популярные большие языковые модели (такие как GPT и GROK) являются тупиковым путем для генерации новых знаний. Они работают с наиболее вероятными путями в семантическом пространстве, в то время как научные открытия лежат в **"лакунах"** — областях с низкой вероятностью.

*   **Рекурсивная модель речевой деятельности:** Для автоматического заполнения **"лакун"** предлагается использовать рекурсивную модель речевой деятельности, основанную на работах Остина, Поршнева и Арутюновой. Эта модель позволяет анализировать сложные контекстуальные связи в текстах и выявлять замкнутые циклы, которые, как правило, указывают на абсурд или ошибку.

*   **Технологический стек и аппаратные решения:** Для реализации этого подхода необходимы графовые процессоры и тензорные базы данных. Гарин отметил, что в России есть наработки в этой области (МЦСТ, "Элвис", МГТУ, "Байкал"), и переход на аппаратные решения позволит многократно ускорить процесс поиска "лакун" и генерации открытий.

*   **Гонка за сильным ИИ:** Докладчик подчеркнул высокую конкуренцию в этой области. По его словам, после презентации их работы в марте, Илон Маск приобрел научное издательство Elsevier, а к российским разработчикам поступали щедрые предложения о покупке их баз данных. Гарин также упомянул три основных направления развития сильного ИИ в мире: подход Маска (обучение на научных текстах), гибридный элитарный подход Трампа и открытый гибридный подход Цукерберга.

В заключение Евгений Гарин выразил уверенность, что создание полностью автоматизированного сильного искусственного интеллекта, способного делать научные открытия, — это вопрос ближайших месяцев, а не лет. Он также анонсировал, что некоторые из первых открытий, сделанных с помощью **"изобретающей машины"**, могут быть обнародованы на Всемирном математическом конгрессе в декабре, если они не будут связаны с разработкой новых вооружений.

# Расшифровка доклада:

S01 [00:00:02] : Коллеги, всем добрый вечер. У нас сегодня неожиданно по предложению Евгения Гарина случился летний семинар русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта. Евгений Гарин расскажет по своей с коллегами работе по созданию изобретающей машины, как сильного ИИ способного делать научные открытия без блока целеполагания. Евгений, пожалуйста.

S03 [00:00:27] : Коллеги, нас немного сегодня. Так что я предлагаю, наверное, прерывать мне, если нужно, вопрос. Потому что тема достаточно серьезная и сложная, поэтому пояснение вполне понадобится. Презентуя материал, о чем мы будем сегодня говорить, во-первых, мы будем говорить про концепт изобретающей машины. Фактически это сильный искусственный интеллект, как в парадигме человек-машин, то есть гибридный вариант, так и полностью автономным. Какие шаги нам нужны, чтобы от гибридной схемы, которую мы презентовали в марте этого года на конференции в Сириусе, перейти все-таки к автономной абсолютно системе, которая бы без участия человека делала научные открытия, изобретения, полезные модели. Понятно. какие у нас технологические есть ограничения в решении этой задачи, по каком пути тем же самым американцы и китайцы идут, вот вкратце об этом. Ну и понятно, немножечко я в конце расскажу про аппаратные решения, но как бы об этом мы, наверное, уже в сентябре-октябре, когда будет уже уже рабочие модели будут, программа работ по этому направлению будет оформлена у нас, тогда, я думаю, вот мы целым коллективом, который сейчас собрался, кто решает задачу именно аппаратного сильного искусственного интеллекта, тогда мы вот презентуем это более подробно. Так, пока я вкратце должен. Начну с чего? Мы презентовали нашу работу еще в марте, в конце марта. Ну, в принципе, что говорилось в этой работе. Презентовали работу тех же наших разработчиков искусственного интеллекта с высшей школы экономики. Вот их фундаментальные исследования компортивистике, скажем так, сравнение языков по семантической близости. Профессор Громов, Выше школы экономики. Достаточно интересные слайды, сравнение языков. Это некая интерпретация, конечно, двухмерной модель языков. Хочу просто отметить, о чём они не говорили. Вот у нас, например, русский и сербский язык, вот они имеют гало такое, в отличие от того же китайского. Долго не могли понять, в чём это связано, но предполагали, что русский и сербский языки имеют очень много заимствований из иностранных языков. В реальности сейчас уже новая гипотеза у нас родилась, что вот это гало, это зона забывания. То есть это часть языка, часть слога русского языка, который уже очень редко используют. То есть мы предполагаем, что, это еще нужно проверять, эту гипотезу, что языки, которые вот такой головой имеют, часть, получается, словарного запаса очень отдалена от центра слога по семантической призвище. Это как раз таки признак того, что язык очень старый и уже имеет голову забываем. Вот заметьте, вот у нас даже на слайде китайский язык, он не имеет головы. Удивительно, учитывая, что китайский язык, это китайская история, там насчитывает 6000 лет. Это вот удивительный факт, что мы под сомнение ставим древность, языковую древность китайского языка. Что еще важно? У нас часто очень специфические задачи декодировки и кодировки данных. И если мы берем тексты, близкие к кодировке фенетической, проверяем их, то можем по сравнению примерно понимать, Какой язык закодирует? Вот в этом я вижу очень серьезное направление, в которое старт данной Высшей Школе Экономики профессором Громовым, вот в этом направлении двигается. То есть это понятно для задачи ассимпта-разведки и кодировки данных. Но даже не об этом. Вот интересный слайд. Обнаружили. Понятно, что языки имеют определенную плотность. Какие-то разделы у нас плотные в языках, какие-то там не плотные. И понятно, что чем ближе к краю, тем менее плотные. Больше к центру, более плотные. Но вот обнаружены вот такие вот зоны, где семантическая близость маленькая. Профессор Громов назвал их дырками языковыми. Этот график, это вот по одному слову. Он делал эксперименты с N-граммами, где разбивал языки на 2-3 слова, 4. Вот возникают вот такие дырки. Что обнаружено было? Если мы в центральной части возьмем вот эти дырки и посмотрим, а когда слово по границе вот этого неплотного образования Когда оно возникло в языке, то окажется, что такие бирки существуют по 60, 80, 120 лет. Возникла вот интересная очень деталь. Откуда вообще, почему они не закрываются? Ко мне Громов обратился года 4, наверное, уже назад. Он знал о моих работах с эзоматизмом и графой и предложил попытаться эти дырки закрывать методами изомаркизмограммы. Вот мы пытались в лоб эту задачу решить методом перебора, очень много потратили времени и ресурсов на это, в лоб не решили, пока не перешли к другой концепции. То есть мы стали брать не слова, отдельные языки, встречающиеся в текстах, не какие-то эндграммы, хотя вот, например, тот же самый у нас антиплагиатру, работает с n-граммами по 7 слов, мы обратились к понятию концепта. В данном случае концептом мы называем какую-то n-грамму. Это такое у нас... такое предложение, абзац, которое имеет смысл отдельный, так как мы работаем с научными текстами, то в данном случае концептом является какой-то высказок. Как правило, это какое-то определение, свойства, закономерность, явления. Причем у этих концептов являются инварианты языковые, особенно не просто между языками эти инварианты, даже внутри русского языка, там какое-то понятие имеет несколько, а иногда несколько десятков определений, особенно если мы берем экономические какие-то явления, там вообще множество определений. Вот они все составляют такую вот библиотеку с ними. И мы просто берем и смотрим, а составляем семантическую близость уже между концепциями. То есть переходим на более большой такой масштаб, И там ищем вот эти зоны на меньшей полосе. Но в данном случае, когда мы переходим от N-грамм к концептам, мы уже называем лакуны. И фактически это лакуны, если мы берем научные тексты, это пробелы в наших знаниях. Чисто статистически, это прогнозная модель, что у нас в науке в центре, где плотность наиболее высокая концептов, порядка 2200 вот этих лохун. Это исключительно статистическое исследование, связанное с ростом закрытых лохун, динамика. Ну понятно, что мы разделяем эти лакуны на те, которые в центральной части, которые очень давно существуют, вот те, которые на периферии. На периферии их там десятки тысяч прогнозируется. Ну вот тоже специфическое модель абсолютно прогнозное, что около 900 тысяч. Вот на границе науки, на границе стыков различных наук у нас до 900 тысяч вот таких лакун. Сейчас покажу, как мы методом теории графов пытаемся закрывать.

S01 [00:09:21] : Евгений, можно здесь вопрос? У меня звука не было, я не успел звук включить. Вы сказали, что можно перебивать, поэтому вопрос у меня и у Алекса Шпотина возник. Вот когда мы говорим о лакунах на двумерной карте, или когда мы говорим о структуре вот этих вот распределений, которые были на предыдущих картинках, русские от китайского, там отличаем и так далее, в каких координатах это происходит? То есть там нет ли того эффекта, что в зависимости от того, в каких координатах мы смотрим, мы получаем разные картинки?

S03 [00:09:58] : Я скажу, что на самом деле это только визуальное представление. В реальности тензоры у нас 11-мерные, мы их визуализировать нормально не можем. Это очень приближенные визуальные модели. Поэтому я, переходя к нахождению этих лакон, перейду уже к матричным формам записи графа. Там уже вот эти вот более наглядные видны латуны, вот как раз пример. Это задача у нас фактически с 65-го года. Задача математического моделирования строения сообществ. В ЛОП ее тоже не решили. То есть это вот с моментов, можно сказать, 63-65-го года, с моментов экспериментов Милгрима, с формулировки его концепции мир-тесен, а еще дальше по времени, если мы смотрим на закономерности цифра, то что мы в принципе привыкли там в просторечии называть расстрелением, золотым расстрелением Паретта, вот эти свойства пытаются в модели какие-то более понятные, ёмкие, для решения специфических задач. Например, маршализация интернета, прогнозирование выдуха. Практические задачи. На данном слайде это тепловая карта. Всего эмпирически обнаружено 8 свойств солнца. Ассортативность, степенное распределение вершины, Концепция вертисина, то, что нам известно как теория шестируковой параллели, это восемь свойств. И разные авторы пытаются эти все свойства использовать как свойства ограничения модели. Используют свой мотоаппарат. Причем тут несколько подходов. Основной в лоб, когда решали, это был теоретико-вероятностный подход. Где-то годов 70-х, начало 80-х другой подход, теоретикой игровой. Последние 10 лет смешанные модели теоретикой игровой и вероятностной. Причем подходы менялись сперва просто, даже миграфные структуры, неориентированный миграф, сейчас точно ориентированный, строго ориентированный миграф, подходы менялись. Это тепловая карта. Какие свойства ограничения моделирования используется в каждой мафии? Заметьте, что в этой фабричке два автора номинировались на логическую премию своей. Это настолько серьезная задача, что она в научном сообществе непросто замечена. А задача не тривиальная. Берется шар. Случайным образом на нем он выступит 9-7 миллиардов точек. Нужно их так соединить случайным образом, чтобы Вот эти свойства все у нас не противоречивы. И задача в лоб не решать. То, что я здесь показываю, тепловая карта, ее применяет методика потеплых ландшафтов ВАИНС. Фактически, визуализация этой методики. Мы получили вот эту тепловую карту. И как специалист, в этой области, в которой много уже работ по этой теме, скажу, что эта тепловая карта вообще ничего не показывает. Что мы можем сказать? Что какое-то свойство используется больше, чем другие. Первое, по-моему, свойство. Это у нас свойство связанности графа. Ну, что граф имеет компонентную связанность. Ну, такое достаточно очевидное свойство. Ну, там во всех матах. И видим, что постепенно у нас количество свойств, которые в моделировании используются, оно увеличивается. И все. Это, кстати, фактически пример того, что тепловые карты непоказательны. Как методика для прогнозирования развития науки, так или иначе. Технологии, текстом патентов. Она имеет очень узкое специфическое применение. Мы перешли к другому варианту. Те же самые, те же самые модели, те же самые 14 моделей мы показали в Грабовне. Это взаимное пересечение, количество тех же в каждой модели. Фактически эти графики показывают связность в каждой модели различных сводов. Берем тепловые карты и в графы видят. Это матрицы смерти. После этого мы берем и складываем вместе. И вот получаем взвешенный граф. Вот он цветной, маленький. И мы видим, Понятно, что у нас веса образуются, мы видим какие свойства, пересечение свойств, пары свойств. У нас прям пересекается очень серьезно. И видим удивительную вещь. Вот у нас второе и третье свойства ни в одной модели не пересеклись. Вот это и есть то, что мы называем лакунами. То есть вот эта область, где она отсутствует. Представляете, с 65-го года по 2022 год столько выдающихся, возможно, самых выдающихся математиков за эти годы пытались решить эту задачу, и два свойства нигде не пересеклись. Вот это вот как раз таки лакун. В марте мы показали, как мы ее решали. Машина показала вот эту лохунку. Дальше мы провели ряд экспериментов. Проверяли второе свойство, проверяли третье. Заново проводили эксперименты. Мы рассылали письма и определили ошибочность. Нашли, что второе... Третье свойство, как мир песен, оказалось возможным. И тогда возникла интересная идея. Первая. Что вот эти вот дырки семантической близости речи, если мы говорим, или лакуны, когда мы говорим про научные концепты, возникают Не потому что у нас не хватает какой-то информации, а потому что одно из свойств пограница вот этой лакуны ложная. И если мы его заменим на неложную, то лакуна стягивается. То есть плотность увеличивается. То есть получается не добавление каких-то знаний, а наоборот мы убираем какое-то ложное знание, Какая-то ошибка, какая-то ложная интерпретация наших экспериментов. И у нас лохумы схлопываются. Совсем другое. Изначально, еще три с половиной года назад, мы думали, что мы из-за марктизмового графа очень сложно будем мастить вот эту вот область, которая у нас неплотная, кто-то там придумает. А потом оказалось, что, может быть, что-то там ложно. Если мы это уберем, то окажется, ну, действительно, проверочный эксперимент. Большой покладатель. Добавились три новых свойства. Понятно, что они там нищие, потому что у трех авторов он встречается, и фактически они с авторами статья ходят. Получается более обширная модель, где не против... Вот убираем третье вот это свойство, и у нас получается плотный граф, полный, где свойства не противоречат друг другу. На самом деле, сейчас это пока самый, наиболее полный математический модель строения социума. Возникает вопрос, понятно, что первое, можно ли применять для других вещей, для других областей науки, где у нас, в принципе, накопленность знаний, можно построить такие модели, где много свойств ограничений моделируют. Там, где их мало, там это практически бессмысленно. И проверяли на разных сетах, на разных, соответственно, наборах данных. Понятно, так как плотно работаем с Росатомом и Эрдкосмосом, брали их сет. На этом слайде определили некоторые достижения. Мы их сейчас плотно проверяем с профильными учетами. подготовили для Ручатского института, отдельный доклад для CineMash Роскосмоса. То есть это еще на стадии проекта. Некоторые вещи подтвердили. По некоторым вещам, наверное, может быть и дополнительная у нас будет информация, потому что новое корпускулярное свойство света, как оказалось теоретическое, оно применимо в лазерном в том числе для задач, когда мы несколько лазерных лучей между собой скрещем и получим более мощный импульс. То есть понятно, что эти вещи могут иметь двойное применение. А с другой стороны, это говорит, что это подход универсальный. То есть он пока позволяет нам находить вот эти лакуны. Ошибок нет, которые мешают нам дальше продвинуться в науке. Это вот парадигма изобретающих машин или сильного искусственного интеллекта в гибридной форме человек плюс машины. Покажу. Сверху у нас мы в марте показали оптимальную модель изобретающих машин, которая состоит из нескольких блоков. Первый блок – корпус текстов, Научный деловый стиль. Мы показали, что это возможно для тех же датасетов, которые у нас инвенторы собрали. На тот момент 550 миллионов файлов научных были, машиночитаемых. Сейчас больше 650 файлов уже. Там и отчеты о них, и патенты, и статьи, и припринты, там эссе, там все. Причем на разных языках. Так как мы переходим к пониманию концепта, нам вообще уже не важен язык. Вот если на уровень положим N грамм, язык важен, то когда мы переходим к анализу концептов научных, нам уже неважно, на каком языке написана статья. Мы ее сильно, статью, уже упрощаем до графовой формы, до таблички смежности, где вот концепты работают. В общем, концепты у нас, естественно, по миллиметрике синонимии, они в разных языках. То есть мы можем полностью, не какой-то брать обильный корпус языковой русского языка или английского, а уже этот метод применять для обширного языкового корпуса общей мировой. У инвентарусов на двадцати, по-моему, двух языков. Понятно, что большинство научных текстов у нас не те основные языки. Тензорная база данных. Это семантической близости N-грамм. До некоторой степени в этой схеме это избыточное направление, потому что некоторые задачи для сильного искусственного интеллекта нам как бы нужны были терзеры. Но в принципе оно избыточное, мы его поставили, потому что вот по этому направлению наши работы были проведены, особенно работа, касающаяся мироспособного баланса. И в принципе там для решения некоторых задач очень сложно, потому что вот я вам показал эту тематическую близость концептов двухмерных, там, где мы на пары разбиваем. Вот у нас в матрице есть парное сочетание концептов. А если нам нужно перейти к задачам, например, сочетания концептов по три, по четыре, то это уже в матрице невозможно, это уже нужны темпы. Поэтому темпы мы указываем. Соответственно, сами протоколы выявления лапун в графе семантической близости концептов Дальше нам, соответственно, протокол смыкания краев на основе кабинетовой замены и протокол заполнения лакомств. Это вот пока еще мировская задача, мы в кокровской задаче только-только переходим к последнему. Это вот в парадигме полностью автономного искусственного билета, который без человека закрывает вот эти вот и плюс еще работает кроме Тех лохун, где у нас действительно много информации, где действительно края центра плотно можно найти. Тех местах, где у нас край науки, где у нас неплотные еще... Только-только заделки у нас в этой области. Какая у нас была реакция? Посмотрите, я в среду докладываю в Англии на конференции, прилетаю в пятницу в Москву, мне докладывают, что Маск купил Эльсавер. Какая-то баснословная миллиарда сделка. То есть, как американцы работают плотно с нашей информацией в режиме реального времени. Мы показали, что мы обучали и на научных дата-сетах, не полностью весь языковой брали, а только научный тех, и тут же Маск покупает МСМ. К нашим разработчикам тестовым базам тоже приходят люди, дают очень щедрые предложения, начиная со 100 миллионов рублей. Это все происходит уже в понедельник. Смотрите, какая скорость работы наших зарубежных конкурентов. Удивительная вещь. Понятно, что высшей школы не обратились, потому что сама в себе концепция векторного пистолета слов в языке, визуализации плотности, выявления дырок, она не нова, ее разрабатывают больше 10 лет, в принципе мы в этом плане даже не пионеры, то есть они считают, что сами будут делать, предложением мы не откисели. Понятно, с тягой не крают ног. Достаточно понятная концепция, которую вот они пытаются сами делать. Дальше происходит удивительный событий. У нас Дуров в Париже заявляет, что будет делать искусственный интеллект вместе с Бронсом, который прям будет настоящим. Потом видно связка с Иваном Москвичем. В телеграмм появляется Громов. Дальше удивительная вещь. Маск делает заявление, что Грок может делать научное открытие. При том, что ни одного научного открытия не показал. Видимо, как раз понимая, что Грок надо обучать и только на научных текстах, тогда он может делать научное открытие. Покажу, в чем. Понятно, дальше мета, скупает специалистов и громкие заявления Трампа, Говорю, что переходит к экономике данных. И вот буквально на прошлой неделе вышла концепция развития сперва от РАН, а потом от Цукерберг. Что хочу отметить. Там четко говорится, что сильный искусственный интеллект, вот этот вот АДЖИН, в принципе нужен для научных акций. Это вот через весь документ проходит красной нитью. Но он, если мы там вчитываемся, он говорит, что он модель общего назначения показывает многообещающие результаты при формулировке гипотез. Ему точно доложили, что это марковская наша презентация, мы еще научное открытие с искусственным интеллектом не делаем, просто это в связке ученые люди очень хорошо работают. Причем там ускорение, там просто колоссальная, если положим, какая-то задача, среднестатистические решаемые внуки открыли какой-то вопрос, требуют, в конце концов, к научному открытию, на это уходит от 60 до 120 лет зависимости от науки. Ну, понятно, гуманитарная кнопка очень медленная, 120 лет техническая, естественно, внуки быстрее решают задачи. В математике тоже есть примеры, когда очень долго что-то делается и так до сих пор не сделано. В экономике есть ряд задач, на решение которых потребовалось 500 лет. Это вот особенно теоретично образование, 500 лет. А тут у нас от нескольких недель до нескольких дней. Но опять же, при формировании определенной команды, которую просто показали магистральное направление, в котором нужно работать, там уже буквально более-менее понятно, что делать. Не нужно какие-то распыляться на проверку сотен гипотез. Скорую гипотезу ее проверяют, и результат просто удивительный. Уже прорыв. Но тут понятно, что американцы хотят полностью авторитаризировать, потому что не хватает компетенции для проверки гипотезы. Вот у них от прогноза с поддержкой искусственного интеллекта мало толку, если ученые не могут также увеличить масштаб экспериментов. Это проблематика. Получают они это магистральное направление, прогноз, в определенном направлении, а проверить не могу, компетенции не хватает. Это вот проблема американцев на самом деле. До некоторой степени скоро будет и наша тоже пробная проблема в связи с такими достижениями в образовании и науке Второго Союза. Понятно. Инвестируйте в автоматизированный облачный лабораторий. Что это значит? Это значит вот этот Этап человеческой проверки гипотез максимально упростить и ускорить. Вот в этом направлении мы и страиваемся. Стимулятивность исследования и публикации больших высококачественных наборов данных. О чем мы говорим? О том, что, положим, если в России есть Инвентарус, в Европе есть Эль-Север, то у самих американцев таких баз данных научных маловато. То есть по объему. этих немцев как бы нет. Сейчас Маск купил, но от того, что Маск купил Эль-Север, это не значит, что он стал американцем. И тут же Трамп говорит, что другие страны, включая наших противников, опередили нас в накопление огромных массивов научных данных. Но тут не поступишь. Какие данные у нас обладает там Роскосмос, там Росатом, там Боэкспериментальный Банк, которые, естественно, закрыты. Ни у кого нет и в ближайшие 50 лет не появится. А он просто у нас вот лежит, ждет своего часа. Ну, я думаю, что вот с этими новыми методами автоматизированных проектов, анализа текстов, вот этот час, ближайшие 6-8 месяцев он как раз по проблематике сейчас пройдет. Постоянно показывает вот такую картинку. Это дерево различных методов. Это я уже перехожу как раз-таки к авторитизированным методам схлопывания краев у акул и авторегенерации текста для того, чтобы генерировать гипотезы там, где у нас неплотные края. Эта картика показывает операции авторитизации разметок. Ну, или операции над ценными данными. То есть вот это дерево вообще не говорит, как мы размечаем данные, какой подход у нас к разметке данных. Вот у нас... Иногда вообще разметка... Это у некоторых, например, поиска скрытых корреляций. Не пользуются разметками. Я постарался изобразить эволюцию подхода к семантической разметке данных. А! Сперва вот... К чему я вернусь? К нашим трансформерам. Вообще даже не к трансформерам, а более широко. Теоретика вероятностного подхода, который используется для генерации текста. То, что генеративным искусственным интеллектом бречь. То есть, фактически, берется большой корпус текста, Исследуется. Соответственно, какие-то используются методы векторного представления слов. Опять же, составляют те же самые тензы, потому что у нас в эндмерном векторном пространстве все это происходит. И, соответственно, смотрится вот эта плотность этого векторного пространства. И что у нас происходит? Как у нас генерируется текст теми же чат-ботами? У нас чат-бот идёт по максимально плотным краям, по максимально плотным областям вот этого семантического пространства. Так работает поисковый, как поисковик он работает, как генератор текста. Он проверяет всё, что написано человеком, большие языковые модели, но они выбирают наиболее вероятный путь. Парадокс. Вот в чём заключается. у нас научные открытия лежат не в наиболее вероятных вот этих областях, то есть будущие научные открытия, а лежат они как раз-таки вот в этих вакуумах. То есть получается, что там, где мы уже все досконально знаем, вот эти генераторы текста нам очень серьезно помогают. Те же задачи обобщения. А там, где у нас какие-то ошибки в семантическом графике, Они их принципиально не находят, не видят. В общем, парадокс. То есть, все направления, даже D-Py, D-Psyc, R-1, GT, GROT, CGPT, с точки зрения генерации новых знаний, это абсолютно ложное направление, тупиковое, по которому идут как в России, так в США и в Китае. многомиллиардные инвестиции именно в этом направлении, которое принципиально не может привести к созданию сильного искусственного интеллекта умнее человека. Теперь я перейду к автозаполнению. К подходу. Понятно, что мы не будем уже к Тюрингу уходить. Можно и дальше уйти к тем же там столоверчению, как раз-таки теоретика вероятности у Паркетса, генерации текста. Оттуда еще идет уже больше ста лет. Принципиально ничего не меняется, кроме Паркетса. Там интуитивная модель у Паркетса, а у нас теоретика вероятности. Но исход примерно одинаковый, генерации текста. Очень близкая к Грамматики, правильно построенные грамматические приложения, иногда вообще не имеющие смысла. Что понимал под собой... Какое серьезнейшее, на мой взгляд, открытие, вот это понимание, что у нас текст любой определяется контекстом по смыслу. То есть смысл текста определяется текстом, если у нас фактически Контекстом в английском языке являются слова, которые идут дальше по тексту. Контекстом предложений являются другие предложения в абзаце. Контекстом абзации являются другие абзацы в тексте. И, соответственно, контекстом самого текста является последующие предшествующие тексты автора конкретно. То есть у нас такой гиперграмм. Но вот это определение сразу не родилось у Остина, к сожалению, молодым. Вообще, эта крайняя смерть разработчиков, она очень сильно на нас тормозит в науку. Я думаю, что если бы у Остина или у Поршнева не умерли, Скоро постижно, достаточно молодым был, в 50-х лет, то, я думаю, у нас сильный искусственный интеллект появился бы не в 25-х, а в 70-х годах. Просто вот, как только умирает автор основной, целое направление разрушается, и в нем не наблюдаются какие-то движения, напряжения 15-20, может, 30 лет. Синонимы у Остина – это объекты, у которых совпадают текст и контекст. Если текст и контекст совпадают, это у Остина синонимы. И, соответственно, дальше идет у него классификация концептов, которые заблудились. Если Остин 6 классификаторов концептов предложил, то современные авторы, буквально последние пять лет, уже дошло до 37 классификаторов. В классификаторах у нас лингвисты запутались. И вот эта вот избыточная классификация, наоборот, тормозит, она не развивает лингвистику. То же самое конкретно. Вот теория гластей и теплостей Поршнера. Ее, понятно, такой очень редкочастотный по упоминанию текст. Его в основном используют у нас политтехнологы, потому что он фактически помогает на выборах в большей степени. Потому что вот если я вам кратко объясню, что такое у Гошниов пластинки. Он говорит, что у нас любой объект определяется матрицей. Пластинки он называет матрицей. который состоит из текста А и контекста Б. А – это множество определений, чем объект является. А Б – это множество определений, чем объект не является. Удивительный подход. Он сравнивал человеческую речь с языковыми системами, первичными птиц, животных. Есть сильные отличия, даже не в определении власти, а сильное определение в синоним. Чем отличается речь у собак и у человека. Это единственное минус чего. Разрознены были работы поршневых. в отдельных списках ходили. Некоторые его работы были политическими. Связаны с исследованиями революции в России, революции во Франции. И они противоречили политэкономическим принципам. Опровергали информационный подход. Поэтому сильно в России не опубликовался. Его вместе все работы сложили в единую только в 2007 году. Вот это откровенный момент. Там у него есть интересная вещь, касающаяся генерации новых знаний. Вот он считал, что если мы вот этот вот контекст и текст переставим местами, вот эта операция перестановки у него называется дипластия. И она ведет к возникновению какого-то предложения, где текст и контекст местами переведут. И он считал, что в этот момент рождается абсурд. И он считал, что в языковых системах людей это возможно, а в языковых системах животных это просто принципиально невозможно. Чем отличается вторая стагнария системы человека? первой сигнальной системы живут. Вот его, наконец-таки, более-менее объяснение. Единственное, что я в нашем понимании, в привязке уже к Костину модели, все это описываю. Словом, 900 страниц, через которых нужно пробираться. Он использует, понятно, не математические термины, он выдумывает термины, не ссылаясь в никого. То есть вот прям тяжело пробираться. Дальше мы идем, да? Язык декларативно-программируемых правил. Это сильное упрощение правил между фактами. То есть это продолжение концепции Поршнера в определении каких-то объектов. Это прямо в языке правил программируемых правил. Там сильное упрощение синонимии правил. И очень сильное упрощение операции de plastique. Она как операция обратного вывода в провод. Но уже это несомненный прорыв в декларативном языке программирования. Чем они хороши? Потому что этот провод родился изначально не как язык программирования, а как переводчик с французского языка на английский. Естественно, на гранты НАТО он делался, чтобы упростить передачу даток внутри многоязычного НАТО. Все переводчики, фактически, они из пролога вышли. И дальше почти до 84 года ничего не происходит. Вот эти парадигмы работают, постепенно уходит пролог. Из-за обращения, потому что он тяжеловат, и в нем изначально заложены ошибки определения пластей, где пластеи очень сильно упрощены. Операция обратного вывода сильно отличается. Пролог, когда родился, изначально вообще предполагал, что вот все, пять лет и сильный искусственный интеллект. Но ничего не родилось. Из-за термологических особенностей, ошибки, раковки, работа в поршнях. Интенциональный брифзит, 84-й год. Работы там с 75-го года, почему-то 84-й, там уже основные статьи о брифзите идут. Брифзит замечательный социолингвист российский. Один из основоположников СОУ, вместе с Левадой они сделали. И у него удивительные вещи. Она по-другому подходит к пониманию контекста. Она впервые, возможно, и завтра, говорит, что контекстом может являться интенсия. Интенсия — это направленность, это цель речевого акта, цель коммуникации. При этом для неё вот эта направленность — это всего лишь точное определение, кто говорит и кому говорит. Вот для неё вообще почему-то никто к этому не подходит. Если мы не знаем, кто говорит и кому говорит, мы не знаем контекста. И, значит, мы точно не можем распознать эффект. Удивительно. Дальше вот эта концепция, она к крогативам в классификации просторечия, к вопросам, подходит по-другому. И она экспериментально показывает, что человек практически не имеет возможности сопротивляться вопросу. Если мы берем какое-то утверждение в вопросительной форме, то люди его воспринимают гораздо проще, чем просто утверждение. И вот это она положила в так называемую технологию формирующих опросов, которые используют на социал. Вот они с Левада еще и для Горбачевых это делают. Я показываю, как вот эти технологии вроде бы они тупиковую для нас с точки зрения компьютерной лингвистики, но они сразу-то меняются властью в политических инструментах. Есть во всех этих моделях один минус. Они не воспроизводят репульс речи. Вообще, для выгонюли репульс, они не горят. Это уже мёртва. Понятно, я тоже В ИСРАМ учился в аспирантуре, как раз в центре, который до этого возглавлял Адридзе, потом Книхонов, и я уже учился ее у учеников, поэтому был с концепцией Адридзе достаточно серьезно знаменит. Мне нужно было ее развить и до некоторой степени вернуть в Корстенской модели. И вот буквально в прошлом году вышла статья моя, рекурсивная модель чего? Я все-таки смог ввести вместе все эти достижения предшественников, да, и модель, которая может воспроизвести рекурсию. Она, если уж упрощать сильно, то она очень простая. Она о чем говорит? То у нас текст определяется контекстом, А смысл контекста приведется к другим контекстам. И так у нас контексты выстраиваются в гиперграмме. А теперь вот что удивительно. Возвращаясь к понятию гиблости и пошли. Вот у нас какой-то там есть текст А, у него контекст В. Потом есть там, положим, у контекста В контекст С. И дальше. У нас нередко в науке Какой-то определенный контекст в конце вот этой цепочки имеет своим следующим контекстом первоначальный текст А. То есть это та же самая теплостия, где у нас контекст и текст меняются местами, но мы ее не замечаем, потому что эти цепочки очень-очень большие. В этих цепочках 15-12, может быть, вершин. Вот это и есть лакуна. Вот если вот мы по контексту, по связности. Это уже нам упрощает очень серьезно поиск этих лакун в сложных текстах. Где у нас киперссылки авторов, где у нас там... Мы выявляем вот эти вот... Не просто уже там косметическую близость каких-то там моделей... к свойство ограничивающих моделирования, а мы уже идем к выстраиванию сложных граффут-фактур, контекстов. И если мы находим вот эти вот замкнутые циклы, мы понимаем, что это гвоздки. И по определению Поршнева, как правило, она является абсурдом. Кроме некоторых... некоторых... отдельных примеров. Вот эти отдельные примеры — это у нас не научные открытия, это, как правило, у нас какие-то полезные модели. У нас нередко смена контекста с текстом в именно полезных моделях, в изобретениях приводит к новому какому-то видению открытий, изобретений. То есть там вот этот кризис — это использование. Когда мы переходим на более простой уровень научных открытий к изобретениям и еще больше к полезной модели, там смена текста и контекста могут частенько работать. Они, как правило, связаны с координатурной перестановкой локоперегатов, как правило. Там это еще дает какой-то смысл. Чем выше мы поднимаемся к изобретениям и к научным открытиям, тем меньше вот эта перестановка текста и контекста у нас дает каких-то результатов. Как правило, это дает ложный какой-то результат, какую-то аберрацию, какой-то то, что я называл, там, абсурда. Как раз то, что я сказал. Переходя, фактически, к выводу. Вот на этой табличке я расписал, без излишней детализации, степь технологические, которые нам нужны для работы с видео в искусственной таблице. Понятная связь, протоколы. Я показал, у каких крупных игроков. Когда я вот здесь пишу ES, на самом деле не должно никого обманывать, что это прям Европейский Союз занимается искусственным проектом. Это исключительно Барселона и исключительно Microsoft. И некоторые отделения транснациональных компаний, которые в США перевезли свой неопыт в Европу. И программы EOM, которые у нас работают. Понятно, тендерная СУБЭД, решение оптимизационных задач в Международном балансе, решение французского логистических задач, это, как правило, соцсети. Или, например, платформы типа Sberbank Online, протокол оптимизации сборки, анталогии, чтобы автоматизировать неурочные процессы. У нас, как правило, языковые модели, конечно, в Китае, на мой взгляд, GCP, R1 собрали вручную, Странно, что в обработке языковой модели участвовало больше миллиона человек. Волонтеры помогали с разметкой текстов. Поэтому они смогли не обойтись американцам. Выявление ненормальной корреляции. Выявление преступления – это отдельная вещь. Это связано с безопасностью. прогнозируемые результаты выборов. И вот если мы переходим к появлению прогнозируемых научных открытий. Вот на этом уровне мы сто процентов. Американцы, судя по заявлениям Трампа, они к этому уровню подошли последние несколько лет. Они уже о нем знают. Дальше есть арт-генерация научных открытий. Здесь, понятно, ни у кого нет Здесь мы настали мир. Мы поняли, как выстраивать в научных текстах вот это вот сложные деревья с гипертекстовыми контекстами. Теперь, снова обращаясь к этому графику. Практическое решение задач выявления вокруг показало, что, как правило, нам приходится работать не с большим гигантским графом, а с множеством маленьких графов. Для большинства задач у нас Количество вершин в графе не превосходит 50. Но зато этих графов очень много. И, соответственно, нам нужно складывать графы, выявлять изоморфные подграфы, изоморфные графы. То есть такие достаточно интересные операции с перестановкой делать. Достаточно простые операции с графами. Но этих графов у нас много. Как правильно. Тут до нескольких команд. Ну, скажем так, 10 в пятности. Эти задачи мы классифицировали как задачи, которые мы можем решать распределенными методами. Они требуют у нас, ну, как бы граммового процессора фактически, в котором у нас было бы маленькое количество решений. Но таких граф-процессоров у нас, естественно, должно быть очень много. Есть задачи, где нам нужно работать с большими графами, где порядка 10 в 9, 10 в 10 вершин. И они, как правило, еще у нас разрежутся, получается. Но как-то в лоб эту задачу мы пока не решили, думаем над ней, как аппаратными методами это сделать. в виде процессоров. Но есть в этом направлении наработки. Я думаю, в октябре уже будет примерно ясна концепция, как мы ее будем строить. Тут это уже, соответственно, у нас компания МЦСТ, это у нас Элвис. Я думаю, там большая работа в этом направлении УМГТУ, очень хорошая заделка. У них рабочая модель графа процессора Леонард Эверс. есть наработки у Байкал. В этом направлении мы до некоторой степени опережаем американцев, хотя у нас, ну, с самими, с самой фотолитографией очень серьезный право, которое нужно, наверное... Для чего это делается? Если мы от программных решений перейдем на аппаратный, мы многократно ускорим работу титлинга. Сейчас, Мы эти задачи решаем либо гибридными схемами, человек-машина, либо программными методами решаем. Это все равно растягивается на нередко недели. Вот задачи с изотопами, задачи с иммельницами, несколько недель у нас ушло. Если мы перейдем к аппаратным ускорителям, В данном случае, там, недобрейшая машина там ценилась 200 лет, где графовых процессоров. Эти задачи решаются практически моментально. Просто колоссальное время мы сможем экономить. Такие задачи, если мы перейдем уже к большим процессорам, где у нас графы большие, девятый, двенадцатый, то мы сможем очень просто решать в режиме реального времени тяжелые задачи, как задачи международного балла. Ну и ряд задач, которые у нас в информационной безопасности, сейчас видите их проблематику, должны быть решены. Там у нас как раз-таки задачи решаются на программном аппаратном или даже аппаратном Проблематика отсутствия ультрафиолета в фотофотографии. Отставание архитектур, микропроцессоров. У нас мы не от американцев отстаём. У нас отставание от математики. У нас математика сильно далеко убежала, информатика от технологического оснащения. В этом направлении, я думаю, сработает, потому что есть понимание проблемы у нас у ВВР, есть понимание у основных авторов, кто этим занимается, кто на стратегических документах либо уже отражено, либо сейчас на стадии обсуждения дальнейшего предпринятия, как по праву определенной законодательной базы. Все это уже делается. И видно, что американцы, имея хорошую разведку, разведку по аспектам данных, они прямо за нами идут. Может быть, даже это неплохо. Потому что это говорит о том, что сильный искусственный интеллект, вот прям не в гибридной форме, как у нас уже есть, а вот прям полностью автоматизированный, Он уже неизбежен. Это вопрос даже не лет, это не 2050 год, это вопрос уже пошел на месяц. Но решение какое? Понятно, как не понять решение. Суверенное, без международного участия, разработка и производство УРФ, графу процессоров и, соответственно, процессоров на новой архитектуре, которые решают проблему, если у нас раньше процессоры решали мало данных, много команд. Сейчас срок баз данных нам нужно Достаточно очень простыми математическими действиями, графами, решать большие задачи, где много. И сборка реестров концептов в ручном режиме, по этому пути фактически пошли китайцы. Либо в автоматическом режиме. Вот в этом автоматическом режиме у нас тоже завелы есть. Первая по разборке Слава речи, сними мне несколько работ, в том числе там пару грамот фонда Бортника, в этом фронте тоже можно будет заделывать. Ну, в принципе, все, что хотел бы доложить, готов ответить на ваши вопросы. 

S01 [00:55:49] : Евгений, спасибо. Коллеги, пожалуйста, у кого есть вопросы, можно прям голосом, у нас народу немного, пока народ собирается. Евгений, а можете, во-первых, уточнить, вы сказали, что Илон Маск купил Элсивер. Да. Я вот сейчас что-то поглядел, я не вижу этой новости. Ну, знаете, интересная вещь. 

S03 [00:56:11] : Как только вот эти новости вышли, они сразу стали затираться. Я больше скажу, что еще полгода назад в интернете вы могли почитать про разработки графовых процессоров. Сейчас, если начнете смотреть, у нас ни Google, ни Яндекс вообще ничего не показывают. Это все признано перспективным, можно даже так сказать, главным направлением, поэтому все затирает. 

S01 [00:56:38] : То есть, вы хотите сказать, что и покупка с Юрой Ланн Маском тоже затерта назад? 

S03 [00:56:42] : Затерта. Мы ее нашли, буквально через 6-7 дней ее уже затерли. А дальше мы уже видели, что почему-то начались проблемы между Трампом и Маском. В принципе, она видна. Я понимаю, в чем суть. Это вовсе там не какая-то Тесла, не за Теслой там ругают все. Четко видно, что каждый хочет идти по своем направлении сильного искусственного телека. Все понимают, что у кого сильный искусственный телек, тот, ну, фактически, там, главальному. Поэтому тот же там Цукерверк идет по направлению открытого доступа к сильному искусственному телеку в гибридной форме. Трамп, видно сразу, тоже выбирает гибридную форму, но элитарную. У него закрытые научные сообщества, он имеет доступ к искусственному интеллекту сильному, и в таком направлении. Еще, получается, вот три направления. Маск, где у него практически те же сайты, но обучаются только на научном тексте. Первое направление. Гибридный искусственный интеллект, по которому идет Трамп. студия по его стратегии развития искусственного интеллекта. И максимально открытая, это вот у Фукерберга, позиция, где у нас не элитарное сообщество работает, а вообще все население привлечено к этому. Вот три направления, они между собой, видимо, не сговорились, они спорят, кто фактически по какому направлению идет. Я считаю, что направление Трампа, оно самое безрисковое. Это реально стопроцентно реализуется, но для этого нужно поднять квалификацию ученых, особенно в таких факторах, как ядерная энергетика, где провал, понятно, гиперзвук. Я думаю, сейчас они начнут привлекать ученых. Более длинная дорога, соответственно, у Циттриберга, потому что нужно нарастить вычислительные мощности, чтобы каждому человеку дать доступ к таким системам, они достаточно тяжелые. Особенно вот, я говорю, что на программных решениях они очень тяжелые, мы рассчитываем, наша энергетика просто не потянет. Наша, если не российская, то великанская, наша человеческая энергетика не потянет. Дать доступ каждому человеку для обработки сильных структур интеллекта просто не выводит. Говорит, что у каждого человека должен быть доступ к такому помощнику, он должен в гибридной схеме работать, и это не сильно повлияет на рынок. И абсолютно, на мой взгляд, как раз тупиковое направление Маска просто обучать на научных текстах трансформеры, которые бы каким-то честным образом делали научную критику. Это тупиковое. При этом, как бы, Маск делает правильные шаги, направленные на сбор вот этих масс данных, на которых мы обучаемся. Ну, я вижу, что, как бы, об этом говорит Трамп, соответственно, как бы, и что сделал Цукерберг? Да, он привлек из Apple одного из ведущих сервисов, который занимался анализом и организацией почты Apple. о чём говорит, что они рассматривают в качестве текстов для обучения не только научной статьи, но и, скорее всего, переписку между учёными. Ну, это моя гипотеза, для чего таких специалистов Пакерберг нанимает. Это вполне правильное, очень правильное направление, потому что как у нас рождается статья? У нас несколько авторов, как правило, перед статьёй у нас какой-то рецензивный припринт, А при принтах же идет многомесячный диалог, они же общаются, переписываются. Вот это обучение искусственной телектрики, польз переписки, это вообще совершенно новое направление, которое вообще коней не валялось. В этом направлении суперпереписка идет, она правильная. Другое дело, как она относится с концепцией неприкасаемой. С другой стороны, мы, пользуясь поисковиками, пользуясь бесплатными почтовыми сервисами, мы практически отдаем почту. Мы не являемся владельцами, мы даем ее таким образом. Тут вопрос такой юридический. А с точки зрения науки, да, это прям целое направление обучать искусственных человек, на переписке ученых. Это же насколько быстрее это происходит. То есть пока там до статьи доходит, это же годы, Вот у меня 24 статья, мы же это создали полтора года, тем как она прошла рецензирование многовечное и вышла, а тут переписка. По ней очень перспективное направление, которое выбрал Кукерберг, за ним может быть будущее. Диалоговая система Человека-скоростной телек. Но, на мой взгляд, избыточники требуют очень больших мощностей, которых у цивилизации нет, у американской экономики нет. Поэтому они сейчас будут развивать ту же самую ядерную энергетику, гидроэнергетику, чтобы ластол прожил экстенсивно, идти по экстенсивным трубам. Наше направление, на мой взгляд, более правильное, когда мы выбираем аппаратные решения. Уже то, что американцы убрали из печати из открытого доступа все статьи, поисковики, у них не индексируют, касающиеся графа процессора, говорят, что они тоже считают это направление перспективным, поэтому открывают. 

S01 [01:02:21] : Вот так. Спасибо. Коллеги, есть еще вопросы? 

S02 [01:02:26] : Можно вопрос? 

S01 [01:02:27] : Да, конечно. 

S02 [01:02:29] : Он немножко в стороне будет, но он касается сравнительного анализа вашего подхода и другим подходам. Скажем, вы уже упоминали, в ТРИЗе тоже шла речь о бретающей машине. Вы занимались анализом? 

S03 [01:02:42] : Да, конечно, проанализировали подходы сами. Во-первых, ТРИЗ вообще не предназначен для научного поиска, научной шкатки вообще. из хороших, конечно, для полезных моделей. Действительно, там перестановка текста и контекста, комбинаторная перестановка каких-то составляющих, она приводит к практическим результатам. Когда мы вверх уходим к изобретениям, это уже очень тяжело работает. А когда мы на верхний уровень выходим, где научные открытия, где явления, свойства, закономерности, это не работает вообще. Это парадокс. А у нас научные открытия являются средствами производства изобретений, а изобретения – это средства производства полезных моделей. И редко у нас полезные модели и изобретения являются средствами производства достаточных научных открытий. Есть просто несколько исключений из этого. Например, оптика, открытие в оптике привели к созданию оптических приборов, которые привели уже к другим научным открытиям, в микромире и в макромире. Но там это связано с тем, что какое-то изобретение расширяет границы исследований многократно. Там нет прямой семантической связи. В расширении нет границ, которые для экспериментальной банки. Я считаю, что когда мы переходим к такому пониманию, контекстов сложным, гиперграфам, мы можем перенести его на ТРИС и фактически дать новое понимание и новый толчок ТРИС. Вот мое мнение, что ТРИС в ближайшее время может быть серьезным. ТРИС более простой, чем работа с графами, он более понятен, он может быть понятен даже школьникам. Это может дать очень серьезный толчок нашему молодежному движению техническому, моделированному тому, что на Советском Союзе было и загуглили по куче. 

S02 [01:04:54] : Я с удовольствием с вами соглашусь, потому что я тоже немножко увлекаюсь тризом. И хочу сказать, что у Триса есть один очень мощный позитивный эффект. Он обращает внимание на необходимость формализации понятия задач. И задача у него формулируется как преодоление неких противоречий. Но там же говорится о том, что для того, чтобы преодолевать противоречия и убедиться в том, что вы его предъявили, вы должны предъявить обязательно критерий преодоления. Вот это вот, к сожалению, никто не может заметить. 

S03 [01:05:28] : Да, это фактически вот эти дырки семантические в эмбирам или лакуны. Это вот этот правильный подход. Просто сам Аль-Шури не определил, как вот он говорил, ищите противоречия или Я соглашусь. Как бы он этого инструментария не дал. А мы этот инструментарий эмпирическим путем нашли. Сейчас я вам рассказал эти годы работы. Не только мы. В высшей школе экономики билось об этом. Мы в Тусуре бились об этом. И СРАМ бился. С разных направлений шли. И это фактически кульминация работы многих поколений. 

S02 [01:06:06] : Хорошо. Спасибо большое. 

S01 [01:06:10] : Евгений, еще вопрос по поводу N-Gram, который вы часто упоминаете. Вот у меня тут небольшое такое дежавю. Мы тут недавно направили работу на конференцию международную топовую. И тоже у нас там N-Gram используются. В ответ получили рецензию, что вот тут всякое допотопное старье. N-Gram это 50-е годы прошлого века. С чем вы к нам пришли? Соответственно, почему N-граммы, почему не имбединги? Как бы вы прокомментировали, почему вы не используете... Дело очень просто. 

S03 [01:06:51] : Распределенность дистрибутивности. Там же компрессивисты сравнивают языки. Есть удивительный феномен языковой. Какое-то есть явление. Оно в одном языке описано, а в другом языке не описано. МБИ позволяет, не элитически, а заниматься сравнительной лингвистикой. Понимать, почему в этом языке это слово есть или определение, а в другом нет. Но там возникает путаница. Например, простое понятие перколяция. Его используют социологи. Его используют, соответственно, газодинамики. Слово-то одно, а обозначения у него огромные. И вот это вот, когда возникает определить даже антонимы. Мы используем объектное представление слов и понимаем, что это разные понятия, хотя слово-то одно и то же. Вот это нам сильно помогает в переводе. И там, например, то же самое, то, что у нас векторное представление языков в сравнении высшей школы экономики. Это шедевр на самом деле. Сравнение языков между собой. Я как специалист, у меня профдеформация, связанная с разработкой протоколов кодирования и декодирования. активации, в работе с архивами, где есть этапы декодировки, разактивации. То есть я вот в этом вижу, что мы какой-то текст имеем на непонятном языке. Мы хотя бы можем определить, естественный это язык или неестественный. Определить какой-то человеческий язык или может быть вообще нечеловеческий. И до такого можно доходить. Наука вот на границе вот этих вещей будет скрывать. Но я вижу в этом даже большую заслугу. Мы идем в направлении психоистории или даже легвинистической истории, чтобы понимать, как развиваются языки. Вот мы сейчас видим язык в современном состоянии. Вот мы собрали корпус языковой, построили какую-то модель, вектор семантической близости. Она нам говорит о современном состоянии языка. Мы должны разметить, когда слово в каком тексте у нас появилось, когда текст опубликован, когда появлялись слова. Если мы перейдем на этот уровень, мы по-другому увидим вообще язык. Мы поймем, как он развивался. Построим тензор во времени. Это серьезно. Эти говорят, что русский – это очень древний язык. Все постоянно у нас Вот историки там спорят о древности народа, а мы говорим сейчас о древности языка. Я не говорю, что, например, русский язык, это сразу мы видим, что он древний, то, что у него там есть зона забывания, что свидетельствует об этом, что сразу свидетельствует о том, что русская культура, русская нация древна. Мы множество знаем примеров, когда нация заинствовала, Другой язык. Сразу не говорю, но когда мы говорим про языки, мы сразу имеем такую картину. Или, говорю, китайский язык. Он нам не говорит, что у китайцев не древняя культура. Вообще, они говорят, что китайский язык, на котором они сейчас разговаривают, молодой. сильно молодой. У него нет зоны забывания. Это еще не значит, что китайская культура не древняя. Вполне возможно, что китайская культура прежней династии уйгурская. На уйгурском языке говорили, но уйгурская письменность, если мы сейчас посмотрим, уйгурский, он сильно к тюркским языкам относится, а у них тоже галлотов есть. Но это уже другой уровень, это новый инструмент для историков. Если мы говорим про Носовского и Фоменко, мне очень нравятся их методы привлечения математики в историю. Здесь это математические методы в лингвистике. Они на многие вопросы нам позволят ответить, если мы серьезно. Другое то, что, на мой взгляд, эндограммы там имбединги у нас, ну их анализ там, какой-то визуальный, там работа там с этим тензорным, как бы их тензорной записью, они не приводят к генерации новых знаков. Но с точки зрения анализа в компактивистике это прям серьезнейший прорыв, который говорит, что у нас Разрыв между естественными и гуманитарными науками сильно в последние 10 лет сократился. У нас лингвистика становится естественной наукой. Представляете, мы являемся современником парадигмальной сдвига наук. Когда у нас изначально науки Разошлись, раскустились, как определились статистические направления, естественные, гуманитарные, социальные науки. Сейчас мы наблюдаем обратный процесс, где все науки снова связываются и связывают их, развитая математика. И математика у нас перестает быть просто наукой. Математика становится языком науки. которая все руки связала. Вот это очень удивительная вещь. Ее можно использовать в том числе для анализа. Но с точки зрения генеративных способностей, генерационного знания, это, на мой взгляд, избыточно сильное направление, потому что требует больших мощностей, суперкомпьютеров, очень дорогостоящие. То, что мы простыми методами, анализируя концепты делаем, мы же даже не пользуемся суперкомпьютерами. Мы все делаем на персональных компьютерах. Вот что самое удивительное. Не требуется где-то там суперкомпьютер, то, который с белаярской АЭС запитывается. 

S03 [01:13:07] : Вот сеть из персональных компьютеров, либо даже один, ну просто медленно, один компьютер из эдаких решает, когда сразу будет матрица смешанности. Ну, в принципе, результат даже на том, что это другое совершенно направление. То есть, если мы говорим про СОДЫ, это направление, которое выбрал Трамп и тот же, там, Фикер Гэнн. Это элитаризация, это контроль доступа к технологиям искусственного интеллекта, а когда у нас что-то работает на мобильных устройствах, не требует больших мощностей. Это другое совершенно направление. Это направление массового применения технологий искусственного интеллекта. Это направление, которое позволяет дать максимальный доступ к этим технологиям в максимально большом количестве. Вот в чем различие между этими подходами концепции, 
S01 [01:14:02] : Спасибо. Коллеги, есть еще вопросы? 

S06 [01:14:07] : Я там в чат написал вопрос. 

S02 [01:14:11] : Могу озвучить. 

S01 [01:14:12] : Озвучьте, пожалуйста. Будут ли первые открытия обнародованы в конце года? 

S03 [01:14:20] : У нас будет Всемирный математический конгресс в декабре. И если у нас там научные эти открытия не найдут применения в вооружениях, респективных новых вооружениях, то мы их обнаружим. Это уже будет принимать высокий руководство наше научное. Красникову доложили, я думаю Красников сам принял решение, что можно, нельзя. Но я думаю то, что у нас в экономике, в социологии мы естественно опубликуем, это частично уже опубликовано, Что касается новых физических законов, наверняка ничего не будет опубликовано, потому что остальное, что связано с холодным и термийным синтезом, наверняка не будет опубликовано. А вот то, что связано с объединительной моделью магнитных полей планет, что-то связанное с эволюцией атмосферы, солнечной системы. Это очень серьезные вещи, где у нас действительно какой-то есть диалог между народами. Несмотря на санкции, несмотря на СВО, у нас все-таки НАСА и Роскосмос пытаются найти какой-то диалог, потому что войны, войны, а человечество, оно должно все-таки строить свой статический путь развития, статический план. на космической экспансии, я думаю, это все будет опубликовано. Это очень сильно влияет на то, какая у нас цель внутри Солнечной системы, какие планеты нам проще всего терраформировать. И, соответственно, от этого уже сильно идет средическое планирование, связывающее с долгосрочной экспедицией. посылать, важен ли нам Марс или все-таки нам важнее Луна или День Мира. Это прям сильно влияет на долгосрочные проекты программы Роскосмоса, наше взаимодействие международное с китайскими товарищами. Поэтому это все будет, я уверен, по-любому. 

S01 [01:16:33] : Спасибо. Евгений, еще у меня вопрос по поводу, вот вы говорили про большие языковые модели, которые ходят по анатопторным тропинкам в тензорном пространстве. Но смотрите, они ходят по анатопторным тропинкам, если им задаешь маленькую температуру. А если им задаёшь высокую террампературу, они вырываются на свободу и генерят так называемые галлюцинации. И, по моему пониманию, на самом деле хорошая галлюцинация вполне может, если повезёт, оказаться открытием. Я полностью согласен с вашим тезисом, что как бы есть экстенсивный путь и есть интенсивный путь. И что они со своими содами и раскупориванием нефтяных запасов и строительством атомных электростанций на уране, который они будут покупать в обход собственных станций. Что это экстенсивный путь. Но, тем не менее, почему нельзя с помощью больших языковых моделей, повышая температуру, заглядывать в лакуны? 

S03 [01:17:44] : Тут вопрос просто вероятности. Вот если мы случайным образом их ищем, то вероятность найти такую лакуну в тёмных генераторах крайне малая. Эта вероятность настолько крайне мала. А на самом деле, почему важен в языковых моделях промп? Промп сильно ограничивает языковую модель в зоне поиска. Именно это ограничение и дает какой-то результат. Когда мы промп не прописываем, там действительно генерируется бред. Пошлин называл абсурдом. Я думаю, применим в развлекательной индустрии, в игровой очень серьезной. Уже видны у нас... Мы же смеемся над абсурдом. Поэтому у нас, на мой взгляд, методом Comedy Club мог бы легко воспользоваться. Ухахатывали бы все. Но с научной точки зрения, избыточная направленность. очень дорогостоящие. Понимаете, запускать языковую модель на ЦОДе для того, чтобы она, может быть, нам что-то ценила, а может быть нет, это настолько расточительное. Что касается урана, 50% урана в Британии, в Канаде и в Австралии. Они действительно пытаются это направление реанимировать, что у них с ураном проблем нет. Уран проблемы в России 5-8-10% мирового уровня. Поэтому у нас РОСАТОМ прям серьезные делают подвижки, реактор на быстрых нейтронах, замкнутый цикл, потому что у нас как раз-таки вот эта проблема с ресницами. Я уверен, что ничего нам не продадут. в чем парадокс. Будут себе во вред нас тормозить. Да, может быть, что-то и сгенерируют случайным образом. Но, опять же, сгенерируют, а это не занимает. Потому что тут должна быть два фактора. Совершенно случайных, которых там 10 в N степени вероятно. что машины действительно сгенерируют открытие. И что это научное открытие увидит человек, который способен его разглядеть. На мой взгляд, людей, способных разглядеть научное открытие, вероятно, крайне мало. Если мы берем список научных открытий, реестр научных открытий, 600 человек. Большинство из них уже умерло. Наши современники, которые сделали научное открытие, десятки, шестьдесят человек. Они, может быть, глядя на случайным образом сгенерированные трансформеры, какие-то решения, может, что-то и увидят. Скорее всего, в своей области, а может и так не делают, потому что они теплом пишут. Это действительно такой инструмент, он не помогает. Он не способен полностью автоматизировать этот процесс. Мы же идем по направлению полной автоматизации этого процесса. Это для человечества достаточно безопасный вариант развития, который компенсирует упадок в науке и образовании. за некоторых суток. 

S01 [01:21:28] : Спасибо. Коллеги, есть вопросы? 

S02 [01:21:33] : Скажите, пожалуйста, я так понял, что ваша оптосистема позволяет находить лакуны и обращать внимание на то, что их заполняемость и есть фактически новые научные открытия. Вот такой способ, скажем, как усиление некоторых параметров существующих технологий. Вот вы там привели пример проблемы о том, что мы отстаем в ультрафиолетовой фотолитографии. А можно эти усилия уйти на рентгеновский уровень и обосновать, что за этим переходом кроется огромное преимущество. Это же ведь тоже в неком смысле аналог, ну микро, но все-таки открытие тоже. 

S03 [01:22:15] : Вот такими лаконами вы тоже... На графике я показываю, что у нас все модели, которые публикованы, используют 8 свойств. И мы, соответственно, их складываем и получаем надвижные графы. Находя лаконы, мы можем прийти к моделям, где большее количество у нас свойств, более полные графы. То же самое здесь с утилением. Смотрите, мы подошли к чему. с точки зрения генерации гипотез. Вот мы взяли наши БПЛА и БАСы, посмотрели компоновку и сочетание компоновок, какие есть, тоже составили вот такую же примерно модель, но только она больше, потому что там компоновок, там сотни изделий, потому что там списки вооружений и наоборот. там просто графов больше и сочетаний больше, потому что компоновка там деталей. И мы посмотрели, как они по-разному. Потом еще подключили некоторые сопряженные узлы. Ну, то есть, например, некоторые контроллеры и некоторые там узлы, как двигатель, у нас есть не только в басах, но и в других агрегатах. Мы составили вот такую как бы взвешенную графику в конце концов. и увидели, во-первых, лакуны, где у нас вот казалось такая компоновка невозможна, а реально она комбинаторна, возможно, ее можно проверить на практике. Это связано у нас с запитыванием бутылок газа. Это у нас научили запитывать там по проволоку, ретранслятор, 70-90 метров на проволоку, он попитывает аккумулятор, он бусит в воздухе, мы подумали, а зачем, у нас же есть двигатель бензиновый, попробовали запитать его бензином. Давайте запитывать газ, у нас же есть газовый двигатель, всё работает, там и бобинка имеет положительные, получится. легче будет. То есть там другое совершенно направление. Это говорит о том, что мы вот прям какие-то технические решения прям комбинаторным методом можем еще проще решать. У нас там добавляются возможности. Мы можем эти узлы комбинировать, переставлять местами. Все это вот просто сложением графа. Получим там завершенный граф. Такое направление, ну я же говорю, что это прям новое направление кризисов. Совершенно если мы раньше вручную кризисом, комбинаторикой занимались, здесь у нас появляется инструмент, который нам позволяет автоматически все возможные комбинации проверить, посмотреть, какие максимально используются, какие несочетаемые вообще, посмотреть, какие просто не сочетаются. Возможно, но мы вообще их просто не используем. И так не только с БАСами, с БПЛА. Я думаю, так во всём. Поэтому я и говорю, что у нас, на мой взгляд, в течение ближайших 10-15 лет примерно 2200 научных открытий сделать, а потом перейти ещё к границам наук, где у нас неплотные графы, методы нанофизмографов, методы генерации гипофиз там уже делают открытие. А на уровне изобретений полезных моделей там вообще открываются огромные возможности для комбинаторики, причем сильно ускоряет этот процесс, потому что сейчас у нас каждый изобретатель вынужден этот гипофиз проверять на практике, не имея инструментария прогнозного, то появляются прогнозные инструментарии, очень серьезные, математические. Поэтому там, я уверен, у нас будут прорывы, которых мы даже не подозревали. Уже количество изобретений экспоненциально зашло. Вот у нас в ковид только замедлился динамика патентования изобретений. У нас почти экспоненциально. Из-за ковида замедлился. Много очень разработчиков помогут. Вот эти инструменты, они позволят нам прям еще больше, крифтологически перейти процессом генерации новых знаний и изобретений. 

S01 [01:26:42] : Спасибо. 

S06 [01:26:42] : Алекс. Да, я хотел спросить, я там в чате спросил, насколько вашу систему тиражируют? То есть, во-первых, можно ли ее раздать, так сказать, людям? Я имею в виду теоретически, да? То есть технологически. И сколько нужно обучать людей в работе с ним? 

S03 [01:27:07] : Вот если мы в лоб не лишим задачу графку процессора, а все будем делать программно, то Это решение не тиражевое на большой качестве будет. Вот у нас будет под какую-то группу научную положен в Геневе госзадание, им будут выделяться мощности, по-одиному СОДы определенные, и они будут с этим СОДом работать. Вот как сейчас это, на каком уровне сейчас происходит. Мы так отдельно собирали команды, Роскосмосовскую, отдельно Росатомовскую команду, отдельно Ростеховскую команду и под них, соответственно, выделяли мощность программистов. Это вот на каком уровне сейчас. И уже как только мы, положим, сделаем первые прототипы графовых процессоров, которые мы, в принципе, называем аппаратными ускорительными искусствами. Задача уже сильно проще решать. То есть, например, задача плагиата научного, какие-то простые задачи, связанные с разработкой полезных моделей, они уже станут доступны просто людям. Мы просто на уровне мобильных устройств можем все процессы вставлять в архитектуру. Я думаю, решаемый вполне вопрос, потому что мы, например, матрицу 10 тысяч на 10 тысяч вершин уже можем в виде процессора сделать. Вопрос только в реальной... Перехода от научной парадигмы, какой-то подхода к выполнению. Не хочется этот процессор делать на Тайване и таким образом передавать наши технологии тайваньцам. Это надо делать здесь. Надо еще решить ряд технологических задач. Может, мы просто даже на 350 нанометров будем делать, не будем париться. Небольшая у нас матрица, фактически. И серьёзный у нас порог. Я сейчас даже не возьмусь, как сказать, мы его преодолеем и как скоро мы его преодолеем. Ну, предполагаю, что преодолеем, что при нашей жизни. Вопрос только, когда. Когда мы сможем делать графовые процессоры, там, положим, 10, там, 9, 10, 12 степени вершины. А может быть как гибридные будут решения у нас, программно-аппаратные. Это реалистично, а вот действительно эти процессоры я не уверен. Но тут есть нюанс. Вот таких вот процессоров, графовых, где нам большое количество вершин нужно, нам их не нужно много. Нужна их порядка четырех, пяти на всю страну, потому что нам нужно решать на их специфические задачи и как расчет нежественности его баланса. Они нам, в принципе, нужны для государственного плана управления экономикой. В общем-то, как было там применимо и экономические цели сообразны. Поэтому, может быть, вот как раз-таки мы вообще не будем делать их в виде микропроцессоров. У нас, может быть, процессор там на то же высотное здание или просто на площади где-то. Ну как бы свернуть его в трехмерном пространстве, ну реально там это у нас матрица смежности будет в гектаре на гектаре. Нам их не много нужно, поэтому это тоже вполне решаем. Не решим ее в виде мегапроцессора, ну тогда сделаем ее вот как вот Да, подделала на несколько гектаров высокочастотную антенну. Вот такое же у нас было решение. Энергозатратная, большая, с безопасностью подверженная, атака была. Может, где-то под землей. Совсем не раздавать. разведку космической технологии. Но оно решает. И я считаю, что мы в таком технологическом укладе уже живем, где это вполне реализуется в ближайшее время. В этом я вижу направление. Так что у меня вполне позитивный прогноз по этому вопросу. 

S01 [01:31:57] : Спасибо. Коллеги, если других вопросов нет, наверное, давайте поблагодарим Евгения за доклад. Евгений, у меня единственная к вам просьба. Мне слайд ваш заинтересовал, где-то ближе к концу, где вы показывали стэк технологии сильного ИИ, но этого слайда нет в презентации, которую вы посылали. Вы можете... Да, я вот пришел. Да, скиньте, пожалуйста, последнюю версию презентации с этим слайдом. Я там потом, может быть, еще отдельно вопросы в чате по нему задам. Хорошо. 

S02 [01:32:37] : Да, это очень интересно, Антон. 

S01 [01:32:40] : А может быть, если есть буквально несколько минут, я вот здесь вот просто уточню. Космическая связь. У нас нет космической связи по сравнению со Штатами? Нет. Широкополосные нету, а у них есть, да? Это старлинк имеется? А, это имеется в виду старлинк, окей. Так, значит, еще я хотел спросить, так, медицинские данные. Вот, тензорная СУБД, а что имеется в виду по тензорной СУБД, которая есть у них и у нас? 

S03 [01:33:15] : Ну, вот смотрите. У нас, как правило, сложные задачи многоприметничеств. Каждый боец на поле боя – это несколько параметров. Здоровье, амуниция, психологическое состояние. Соответственно, он в трехмерном пространстве. Это долгота, широта, высота. Цели какие-то у нас положены. под водой или в небе. Это как бы точка, которая сразу множеством параметров. Соответственно, динамика – это как бы их изменение, эволюция, расположение, изменение параметров. То же самое с задачами прогнозирования погоды. Каждая точка пространства – это какой-то тенз. широкая высота, температура, освещенность, владность, количество, состав атмосферы, давление. То есть это тензор. Вот так вот с этими тензорами у нас математика, ну как пытается, решает задачи на говорительном числе, путем снижения мерности тензора. В задачах, положим, прогнозируем погоды. Вот этот тензор, 11-мерный я считал, мы прям уменьшаем его до трехмерного тензора. Это широта-долгота и давление. Вот эти тригонометрические поля. Вот мы взяли этот многопериметрический тензор, уменьшили. получили трехмерную какую-то модель, и вот она якобы обладает какой-то предсказательной силой. Но эту предсказательную силу вы все видите на примере прогнозирования погоды, когда мы практически не знаем, будет дождь или нет. Мы решаем ее уменьшением. Чтобы не уменьшать тензор, пытаются визуализировать его. У нас есть примеры таких визуализаций тензора. У американцев на этом балантир весь построен. Поэтому я считаю его направлением гибридного искусственного интеллекта, когда они решения политические задачи решают за счет высокой квалификации сотрудников, которые работают с тензорами. Вот они научились визуализировать эти многомерные тензоры. и оператор ищет какие-то закономерности в этом тензоре. Там у них есть разные инструменты для визуализации этих тензоров. Сами тензоры могут вертеть. У нас тоже есть примеры решения. Визуализация этих тензоров вполне удачная. В основном у астрономов наших, российских. Они пытались, вплоть до Матвиенко, дошли, показывали примеры визуализации тензоров, что их можно и в экономике использовать, но не нашли понимания, потому что это очень специфический язык, чтобы понять, что это как-то применять, нужно обладать своими знаниями математическими, не находят эти пока премьеры удачные. Мы вообще удивились, что вообще он есть. Мы думали, что с нуля это так же сделано, как в Палантине. Оказалось, он уже с 2016 года в России существует, но просто используется у нас для визуализации многопериметричных карт звездных. Каждый объект звездного неба. Естественно, там сами разработки всегда говорили, что власть принадлежащим что это в экономике можно использовать, в образовании, в ритиговании вузов. Каждый вуз у нас тоже точка какая-то, многоградничка, либо тензор, который в инвертном пространстве. Вот оттуда теперь тензор. И есть задачи, особенно связанные с экономикой, которые мы решаем тензором. Поэтому у развитых стран и развитая тензорная математика, и, соответственно, технологический стэк в виде тендерных баз данных. У тех, у которых это отсутствует, и математики, и технологический стэк, мы показываем, что они в этом направлении. Значит, они принципиально уже не могут решать эту задачу. Поэтому, положим, Сбербанк онлайн у нас есть, а у Голландии нет. И там немцы до сих пор наличными рассчитываются в четвертом или третьем техноклассе. Нет технологического стека. Они не могут обрабатывать. Поставить терминал-то они не могут. А как обрабатывать сеть транзакций? Это же очень серьезная математика, именно тендерная. 

S01 [01:38:08] : Есть у нас, да? Да, я все-таки за слово СУБД цепляюсь. Что подразумевается подтензорное СУБД? 

S03 [01:38:18] : Пример вы можете загуглить, это ГОПИН. Палантир ГОПИН. Можете посмотреть. Пример, когда реализация тензорной СУБД. Это палантир ГОПИН. Функционал. Они не показывают, что там под капотом, но показывают, как они могут эти тендеры визуализировать, как оператор может с ними работать. 

S01 [01:38:40] : А у нас это, вы говорите, некоторые… У нас они закрыты. 

S03 [01:38:44] : У нас они не публичные. У нас они как бы вот у Госкорпорации. 

S01 [01:38:50] : У астрономов, да, есть? У астрономов есть. 

S03 [01:38:53] : Я просто проводил мониторинг всех заделов и обнаружил. Ну то есть принималось решение, да, нам надо такое же, как Фаланти, вот им сделать, надо привлечь математиков, особенно зверей хорошей математики в этой области, давайте как бы привлечем. Ну а мы же сделаем, если им не пользуются. Ну то есть его предлагали не тем, не в нужное время, не в нужное место. 

S01 [01:39:22] : Понятно, хорошо, спасибо. Евгений, спасибо огромное. Вот, соответственно, на выходных, наверное, будем выкладывать всё это дело на наши каналы. Вот, спасибо. 

S00 [01:39:34] : Можно ответить на вопрос от опоздавших? 

S01 [01:39:36] : Да, пожалуйста. 

S00 [01:39:38] : Да, добрый вечер. Вот хотелось бы всё-таки узнать, действительно, как это тензорное СУБД называется и протокол автоматизированной сборки антологии. Что имеется в виду? 

S03 [01:39:51] : Ну вот, я сказал, что тензорная СУБД, например, это линейка Аполлонтировская. 

S01 [01:39:59] : А как вы сказали слово второе, Аполлонтир, что там потом? Готэм. Готэм? Готэм. А, Готхэм, Готхэм. 

S03 [01:40:06] : Готхэм, да. 

S01 [01:40:09] : Самый яркий пример тензорной СУБД. Да, я вижу, я нашел. Ага, спасибо. 

S03 [01:40:14] : Что такое продвинутая сборка амплологии? Как у нас решается задача синонимить? Вот крупные компании. Технология семантика, Google, Yandex, у них есть штаб лингвистов. Это, как правило, люди с знанием нескольких языков. Для того же портала госзакупки у нас, например, собирали людей, которые знают одновременно английский, испанский и русский. И вот они собирают синонимы, как правило, связывают языковые пары разных языков. либо внутри языка, собирает эту библиотеку, делает это вручную. Так как язык постоянно у нас развивается, так как сленги различные у нас там появляются, новые слова, то этот процесс нужно постоянно обновлять эти бассейны. Это прям серьезная вещь, особенно когда касается товаров, товарных групп, Сколько только наименований разных лекарств. Когда открываешь перечень лекарств, огромную ищешь. И там реально люди сидят и вручную все это списывают. Поэтому когда мы говорим, что в Гугле 25 тысяч разработчиков. 25 тысяч программистов? Что смеяться. Трудовенкая задача – это сборка вот этого словаря-символии. Она вручную делается. Разметка текстов для обучения искусственного интеллекта тоже вручную делается. Мы подумали, может, ее автоматизируют или как-то упростить хотя бы. А мы обнаружили интересную вещь, что если мы анализируем текст, то есть различаем на текст и контекст, автоматизируем. По простому правилу, текст вначале, контекст следующий. Как можно больше текста берем и тоже получаем такие взвешенные графы, то мы обнаружили, что если мы обнаруживаем клику вот в этой семантической близости, то, как правило, это синоним. Либо слова очень близкие, очень близкие по значению, очень близкие. Графики семантической близости и клики, они, как правило, синонимы. И, соответственно, Обучение с учителем, максимально автоматизировать этот рутинный процесс. Он что нам дает в первый день? Мы до конца, конечно, не избавляемся от людей в поиске этих синонимов, Нам не нужен для этой работы квалифицированный лингвист, тем более, знающий несколько языков. С школьной можно такую работу выполнить. С точки зрения требований, квалификации людей, которые эти заполняют библиотеки с синонимами. Первое. Второе. Там иногда бывает, что прям, ну, стопроцентно это синоним. Это как бы, там, без человека, там, есть синоним. Глика тоже может иметь разный размер. Если у нее 9 элементов в клинке, то по 2 полосы. Если у нее 50-60 элементов, то 100% это синоним. Это связано с товарными группами, с товарными субститутами, с наименованиями многочисленными лекарств, которых внутри Формула, на самом деле, вещества лечебного, одно и то же, в разных странах называется. То есть вот для этих задач автоматизированная сборка, она сильно очень прощает. Это же все почему делается? От недофинансированности. У нас задача положена в заработке больших языков моделей. Ну, нам никогда не дают финансирование на разработку реально больших физиковых моделей. 15 миллионов в 100 тысяч человек волонтеров помогают собирать большие физиковые модели. Нужно какие-то задачи, которые там люди применяются, сильно автоматизировать. Вот оттуда вот эта технология автоматизированной сборки и словорисования. Пока, насколько я знаю, по патентам, Такие технологии только у нас в России. Нигде в мире. Китайцы выучили это делать, гипотетика это показала. И камеры СМИ на разведках была. 

S00 [01:45:33] : Получается то, что у нас называются тезаурусы. 

S03 [01:45:37] : Да, это сирония. Тезаурус и онтология это сирония. 

S00 [01:45:43] : Ну вот, просто я когда работал еще вне искусственного интеллекта, у нас академик на Риньяне, он как раз различал все-таки тезаурус и онтологию, у него была отдельная статья на эту тему «Тезаурус плюс онтология». А сейчас я, когда последний раз мониторил эту тему, стали делить еще больше, то есть есть глоссарий, тезаурус… Глоссарий классификации. 

S03 [01:46:08] : Но мы здесь говорим о чем? Антология – это какой-то граф. Нам нужно исключить в составлении этого графа рутинные операции. Рутинные операции – это синоним, как правило. Субституты, если мы про товарную группу говорим. Если мы их в клике собираем, мы понимаем, что это одно рабочее существо. Мы сильно потом упрощаем. Это реально очень серьезная задача. Составлять тезаус, автоматологию для каких-то промоколонических препаратов. Если мы сразу в эти группы синонимов лекарственные препараты близкие не соберем, там непочатый край работы, не обезвуемые никогда. Слишком много наименовал. А вот для этого мы используем такой лепесток. 

S00 [01:47:13] : Понял. Спасибо. 

S01 [01:47:16] : Хорошо, коллеги. У нас уже почти два часа мы в эфире. Большое спасибо Евгению. Спасибо всем, кто поучаствовал, кто задавал вопросы. Евгению ещё раз за то, что давал ответы. Увидимся уже осенью. До осени приглашаю всех. 10 числа у нас будет семинар на английском языке. в реке Явике и удаленно по интерпретируемой обработке естественного языка, где будем разговаривать в частности на те темы технологические, которые рассказывала сегодня Евгения. Всем большое спасибо и до новых встреч. До свидания. 

S05 [01:47:56] : Спасибо. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html



