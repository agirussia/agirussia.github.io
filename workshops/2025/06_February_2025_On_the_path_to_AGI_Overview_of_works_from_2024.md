## 07 февраля 2025 - На пути к AGI: Обзор работ 2024-2025 года - Татьяна Шаврина — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/s2stfH7Zji8/hqdefault.jpg)](https://youtu.be/s2stfH7Zji8)
- [расшифровка](https://github.com/agirussia/agirussia.github.io/blob/main/workshops/2025/06_February_2025_On_the_path_to_AGI_Overview_of_works_from_2024.md)
- [видео в RUTUBE](https://rutube.ru/video/4681e7d70e94ba01798a96446e82df06/)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239213)
- https://t.me/rybolos_channel
- https://www.linkedin.com/in/tatiana-shavrina/
- https://www.llama.com/
- https://iling-ran.ru/

_ВНИМАНИЕ: СЛЕДУЮЩИЙ ТЕКСТ СГЕНЕРИРОВАН ИИ, РАЗРАБОТАННЫМ УЧАСТНИКАМИ НАШЕГО СООБЩЕСТВА!_

**Суммаризация семинара:**

Основные тезисы семинара

1. Определения и подходы к AGI:
- Критика определения AGI от OpenAI/Microsoft, основанного на экономических показателях ($100B прибыли)
- Академическое определение: система, превосходящая человека в причинно-следственных связях, обучении, планировании и коммуникации

2. Проблемы оценки моделей:
- Контаминация бенчмарков (утечка тестовых данных в обучающие выборки)
- Быстрая сатурация новых бенчмарков
- Проблемы с воспроизводимостью результатов
- Коммерциализация бенчмарков (пример FrontierMath и OpenAI)

3. Новые тренды в оценке AGI:
- Акцент на агентских системах с возможностью исполнения кода
- Фокус на научных задачах как метрике прогресса
- Бенчмарки: MLE-bench, Science Agent Bench, Discovery World
- Важность объективных метрик оценки

4. Проблемы автоматизации науки:
- Риски автоматической генерации научных публикаций
- Необходимость валидации источников и результатов
- Важность сохранения качества рецензирования
- Потенциал в автоматизации ablation studies и кросс-дисциплинарных исследований

5. Технические тренды:
- Развитие моделей для работы на устройствах (on-device)
- Увеличение контекстного окна (до 10M токенов)
- Важность энергоэффективности
- Проблемы интерпретируемости моделей

6. Перспективы развития:
- Ожидание появления инкрементального обучения
- Необходимость развития систем безопасности для автономных агентов
- Важность баланса между автоматизацией и качеством в науке
- Потребность в новых методах оценки новизны и валидации результатов

Семинар подчеркнул необходимость более строгого и системного подхода к развитию AGI, с акцентом на научную методологию и объективные метрики оценки прогресса.

**Расшифровка**

S00 [00:00:09]  : Коллеги, всем добрый вечер. У нас сегодня очередной семинар русскоязычного сообщества разработчиков сильного и общего искусственного интеллекта. И сегодня у нас, можно сказать, несколько дней назад был Татьянин день по старому стилю. И в соответствии с доброй традицией у нас в гостях Татьяна Шаврина, которая расскажет о том, где мы сейчас находимся по пути к AGI вообще и с точки зрения больших языковых моделей в частности, или может быть, что это еще, Татьяна, вы нам захотите рассказать, пожалуйста, вам слово. 

S01 [00:00:49]  : Да, добрый вечер, добрый вечер, друзья. Всем здравствуйте. Уже ежегодная традиция у нас практически. Мне кажется, это четвертый раз или, может быть, пятый уже, когда мы устраиваем какой-то такой обзорный доклад. Обычно в конце января, но вот сейчас в начале февраля, как Антон элегантно сказал, значит, по старому стилю дотянем день. Ну, то есть будет так. Я постараюсь сегодня сделать обзор работ, которые, мне кажется, наиболее интересными, наиболее важными, а также, безусловно, подсветить какие-то общие тенденции, которые, мне кажется, ну не то что прям наметились, а уже были очень проминентные весь 24-й год и которые с нами будут везде. поэтому мой доклад сегодня так и называется на пути к AGI, ну и вот такая маленькая приписочка или как делать AGI аккуратно, потому что как неаккуратно делать мы тоже увидим сегодня. Меня зовут Татьяна Шаглина, я энтузиаст open source, сильного искусственного интеллекта, ну и оригинально компьютерный лингвист и большой сторонник того, что языковые модели и язык являются существенной частью того, к чему мы стремимся, к моделированию интеллекта и сверхинтеллекта. Я также сейчас работаю в команде Lama. Lama после релиза 3.3 — это, в общем-то, всё то, к чему я сейчас прикладываю руку. Вот, сегодня хотелось бы немножко начать опять с пересмотра определений, а затем поговорить о том, какие сейчас есть вообще критерии AGI, сильного искусственного интеллекта, и что с ними не так, что вообще происходит в мире оценки моделей сейчас. И существенную часть на самом деле посвятить задаче, которая, мне кажется, одна из самых главных в контексте построения сверхинтеллекта и вообще его измерения — это акселерация науки. И начнем мы с определений. Как вы знаете, один из самых явных игроков, который регулярно эксплуатирует термин AGI, а также оси сверхсильный искусственный интеллект, сверхчеловеческий искусственный интеллект и так далее и так далее. И все термины, которые вот где-то в семантическом пространстве там рядом с ИЖА лежат, используют другое определение сильного искусственного интеллекта, не такое, как принято в академическом сообществе. И руководствуются тоже не им, соответственно. общественности, и оно даже на сайте у них теперь висит, но изначально оно было из судебных документов, публикованное, что они используют внутреннее определение совершенно другое. Их цель тоже построение AGI, но это вот какая-то высокоавтоматная интеллектуальная система, которая превосходит людей в наиболее экономически выгодных областях. Вот такое как бы экономическое определение. И мне кажется, что мы с вами вольны совершенно его не придерживаться, потому что это совершенно не то определение, к которому мы привыкли, как бы академическое, к которому, в принципе, тоже есть вопросы. ставить своей целью акселерацию экономики, а не интеллекта, мы не будем. Это другая задача. Это их какая-то корпоративная вещь. Это было дальше еще больше усугублено, я бы так сказала, потому что дальше еще В новых документах они пошли дальше, и теперь мы видим, что в совместных документах OpenAI и Microsoft, там, где они договариваются, и там у них есть соответствующие пункты в договоре, когда OpenAI достигает то тогда наступают определенные условия, там в частности Майкрософт теряет доступ к эксклюзивному праву на некоторые технологии, в том числе AGI, и там определение вообще экономическое, то есть там определение даже, оно не привязано к интеллектуальным задачам или к превосхождению интеллекта людей, оно привязано исключительно к прибыли компании. Значит, сверхинтеллект — это такая интеллектуальная система, которая может нам сгенерировать 100 миллиардов долларов прибыли. Замечательное определение. Мы не будем его придерживаться и не поддерживаем. Ну, я, по крайней мере, не поддерживаю его. Академическое определение, которое я продолжаю использовать, на основании которого Мои коллеги в том числе строят свою работу. Это все еще такой тип искусственного интеллекта, который превосходит человеческие, но обладает некоторыми соответствующими чертами, которые мы бы хотели видеть. В частности, может хорошо выстраивать причинно-следственные связи, цепочки рассуждений, справляться с неопределенностью в принятии решений, может демонстрировать способность к самообучению, к планированию, к использованию знаний из различных источников, ну а также всё это объяснять и коммуницировать с человеком на естественном языке. Да, оно, по крайней мере, к последнему пункту меньше всего вопросов, всё остальное как бы развивается, так скажем. И помимо всего прочего, да, вот в контексте вот этих каких-то смещений в определениях постоянно, да, мы постоянно видим о том, что Наше внимание смещается с работ, которые на самом деле могли бы быть прорывными или являются прорывными к чему-то, что проще всего превратить в какой-то громкий заголовок. И преподнести, что вот высокоавтономные интеллектуальные системы, они на самом деле очень опасные в текущем виде, и они нас всех заменят, вот к этому прибавилось, я агент и нас всех заменят, и так далее, и так далее. И эта вещь подогревается опять же вот этими всеми экономическими определениями. Мы занимаемся совершенно не этим. Мы занимаемся построением с вами сверхинтеллекта. Одна из больших вех в оценке того, где мы вообще находимся с вами на пути к сильному интеллекту, это, конечно, бенчмарк ARCA-HI. Он достаточно неновый, я уверена, что все про него слышали. Он, по-моему, к концу 2019 года аж по текущим меркам бенчмарк сторожил. бенчмарк от Франсуа Шале, автора библиотеки для нейронных сетей Keras. Идея основная такая. Мы с вами оперируем действительно большими языковыми моделями и, казалось бы, Благодаря такой удачной архитектуре, благодаря тому, что они так хорошо моделируют язык, из них можно много чего квазичеловеческого получить. Давайте попробуем мерить интеллект в задачах, где язык вообще не нужен. Давайте попробуем отделить логические способности этих моделей от языка и посмотрим, что получится. И для этого предлагается вот такой интересный подход, как что давайте различные типы абстракции, различные задачи на вобщение паттернов на причину следственной связи. мы выведем не в текстовый формат, а вот какие-то пиксельные матрицы с координатами. Вот, например, пример такой задачи из ArcGIS, например, восстановить кусочек пропущенный в паттерне. Да, мы с вами беглым взглядом на картинку очень легко понимаем, как его надо восстановить. Такого цвета должны быть пиксели пропущенные. Ну вот, некоторый набор вот такого рода решений, да, вот здесь надо условно понять, что произошло, и также сделать по аналогии с другими картами. Очистить от голубеньких пикселей и так далее. Или здесь вот игра, и там Змейка, по-моему, ест этот голубенький пиксель и так далее, достраивает. Ну, в общем, разные совершенно паттерны. И бенчмарк этот решался, в общем-то, очень плохо. языковыми моделями, что в принципе достаточно ожидаемо, потому что вообще языковые модели плохо работают с пиксельными матрицами. Почему они вообще должны? В целом, задача, мне кажется, совершенно адекватная, потому что изначальное желание сделать этот тест очищенным от языка — это, в общем-то, очень хорошая постановка. экспериментально чистая. И помимо этого еще предлагаются такие критерии идеального теста на AGI. Тест должен иметь четкие границы применимости, оценку достоверности, и как у ARC AGI она есть. Он должен быть воспроизводимым, тоже все воспроизводимо хорошо. Он должен перед собой ставить задачу измерения широких способностей и обобщения у моделей. не должно в его тестовый набор не входить никаких задач, известных заранее, т.е. тест должен быть сюрприз, может быть, какие-то типы вообще не могут повторяться, но в целом задания в train части и в тест части разные. И при этом даже там соотношение другое. В тренировочном наборе 400 задач, а в тестовом 600 задач. Не очень много, но в целом соотношение такое, что в тесте больше. И нельзя так хорошо научиться на трене, чтобы потом на тесте иметь очень высокий результат. И очень хорошо контролируется действительно объем опыта и объем знаний, которые используются системами во время обучения. таким образом. И он еще хорошо подходит и для людей, и для машин, соответственно. для языковых моделей конкретно не очень, но это был вопрос времени, потому что вот сейчас мы видим, что некоторые языковые модели научились хорошо работать с этими пиксельными координатами и релиз вот новой модели от ReopenAI, он очень сильно поднял план по решению задачи в этом году конкретно вот в конце двадцать четвертого года. Весь двадцать четвертый год шло очередное соревнование, ARK Challenge, и можно было разработчикам, инструкторам разных систем попробовать свои силы, и лучшие системы, они были в районе 53% правильных ответов на ARK AGI. А теперь лучшее решение, которое предложено, это аж 87,5%. Вот, видите, справа. И это, конечно, очень большой прирост. И он несравним по качеству с теми решениями, которые предлагались раньше. Алгоритмические преимущества, которые были продемонстрированы, мы, конечно, их не знаем, потому что они не описаны, это закрытая модель, тем не менее они выглядят достаточно существенными. Ну, тем не менее, на состоянии вот теперь уже пяти лет прошедших с начала существования бенчмарка, конечно, он не обладает заявленными изначальными свойствами. Его обучающая и тестовая выборка уже давно опубликованы, так что, в принципе, утечка могла бы быть. И раньше действительно входной формат, эти координаты пикселей очень плохо подходили для языковых моделей. Ну а сейчас представить, что мультимодальная языковая модель или просто языковая модель с достаточно большим контекстом, которая очень хорошо работает с кодом, JSON, что она может переварить эти координаты, ну в принципе вполне можно представить. Но тем не менее, вот опять же, я упомянула контоминацию, и контоминация это некоторая большая проблема для существующих бенчмарков. Я хочу, наверное, вам показать несколько основных работ, которые действительно показывают, что бенчмаркам прям слепо доверять нельзя, и это происходит даже не из-за какой-то такой вот нережливости, что ли, или это не происходит из-за какого-то злого умысла. Часто это происходит просто даже случайно, и разработчики сами, которые обучают языковые модели, они всегда знают, что они уже на самом деле положили в обучение тестовые выборки некоторых матчмарков, то, что они случайно попали, там, скачались Потом оказывается, что на них очень высокие результаты, но это неправильным образом полученные результаты, которые не могут считаться. Один из методов проверки, предложенный в самом начале 24 года, он как бы был про то, что давайте попробуем проверить, если мы в тестовых сетах известных бенчмарках поменяем ответы и вопросы местами, изменится ли перформанс у моделей. Смогут ли они продемонстрировать такое же уровень качества, или он станет хуже, или он упадет. Если он упадет, то будем считать, что модели помнят порядок вопросов наизусть, и ответы на них, соответственно, тоже проверяли, стали различным образом перемешивать. Ответы оказалось, что действительно качество существенно падает. Потом попробовали воспроизвести на маленьких моделях, обученных с нуля на Википедии. Там тоже подкладывать соответствующие бенчмарки внутрь Википедии и смотреть, как они обучаются. И вот полностью воспроизвели этот же самый эксперимент. То есть для многих языковых моделей, в том числе Lama2, Mistral, QPT2, оказалось, что большое количество бенчмарков, включая тестовый сет, уже скомпрометировано и положено в бучейн. То же самое можно увидеть и с некоторыми отдельными способностями, не обязательно даже с бенчмарками, например, с машинным переводом. Очень часто так бывает, что то, насколько хорошо решается тот или иной бенчмарк, связано не только еще с тем, как утек тестового обучения или нет, но и Ситуация с некоторой долей нюанса — это что какие-то очень похожие данные на тест все равно лежали в улучшении. Ну, как бы не тест совсем, но что-то очень похоже, поэтому тест решается хорошо. И многие языковые модели, и там некоторые двухсоревнования всегда присутствуют по поводу бенчмарков, да, часто бывает, что ну а давайте мы поставим одного студента на каждый бенчмарк и там студент будет набирать с помощью кнн или какого-то еще метрики близости, просто фильтрует нам выборку и мы хорошо покроем зону задач, которая связана с определенным бенчмарком. И можно сделать и обратную задачу, можно попробовать почистить обучающую выборку от всех примеров, которые похожи на тесты, которые похожи на примеры с машинным переводом, например. Если это сделать, оказывается то, что у языковых моделей способность к машинному переводу даже у многоязычных пропадает совершенно, ее больше нет. Ну и мой любимый способ, самый простой, мне кажется, проверить утёк бенчмарка или нет у конкретной языковой модели в обучении, подходит для бенчмарков, у которых есть выбор ответа. Таких бенчмарков достаточно много, тот же MMLU, например, основной бенчмарк, который показывает нам различные профессии. Профессиональные экзамены на разные темы, выпускные уровни, выпускной квалификационный экзамен по юриспруденции, по английской литературе, по дискретной математике и так далее. И там есть варианты ответов. Так вопросы все составлены, что там четыре варианта ответа есть. И один из них правильный, и три неправильных. Когда модель выбирает правильный ответ, мы знаем, что она хорошо обучена и выбрала правильный ответ. А что если мы попросим эти задачи из теста ММОЮ? завершить, мы дадим саму формулировку задания, а варианты ответа модель должна сгенерировать. И вот если она неправильные ответы дословно сгенерирует нам, то получится, что она их откуда-то запомнила, потому что они неправильные, они могут быть любыми. а правильный он там один. И вот оказывается, что у многих языковых моделей, в том числе даже у GPT-4, на MMLU прекрасно, на 52% GPT-4 генерирует варианты ответа из оригинального тестсета MMLU. это очень большой рейт, это никак нельзя объяснить случайностью, а только тем, что бенчмарк утек, и смотреть на него нельзя. При этом MMLU — это один из тех бенчмарков, на котором нам показывали превосходство GPT-4 в момент ее выхода, и о том, что она гораздо лучше, и по всем профессиональным навыкам она превосходит и GPT-3, и превосходит человека. Ну и как бы часто авторы, когда выпускают новые модели, они безусловно сами про это рассказывают, что вот мы проверили и нашли, что вот у нас вот такие бенчмарки случайно утекли, поэтому на них, на наши модели не смотрите. Но и часто бывает, что и сообщество что-то находит, и оказывается, что и у Mistral много бенчмарков утекло, и у GKE4, и у многих-многих других. Это, в общем-то, постоянный процесс, и он менее заметный, чем новости, которые мы читаем, яркие заголовки о том, что в очередной раз где-то мы превзошли человека или там мы превзошли вообще во всех профессиях мы можем выполнить 1% всех экономически выгодных работ на планете Земля и так далее. Но помимо этого есть еще и другие проблемы, даже те, которые тоже совершенно относятся к методологическим, но которых раньше не было. Оказывается, что если можно, ну по крайней мере есть такая мотивация, посадить свежего выпускника технического вуза, чтобы он нам набирал, фильтровал датасет, фильтровал автоматические примеры и клал для обучения, чтобы мы на конкретном бенчмарке подняли свой результат, да, ну и как бы оказывается, что действительно это часто работает. Да, если мы разрабатываем языковую модель с нуля, мы хотим, чтобы она была получена на MLU, на каких-нибудь бенчмарках математических и так далее, ну, на каждый бенчмарк посадим там студента условный и пусть набирает датасет. И попутно еще можем заказать там разметку данных и все это до сыпи. Да, вот это был бы такой очень экстенсивный путь, ненаучный, но часто к нему тоже все прибегали. Разметка эта оказывается достаточно выгодным бизнесом, и люди с этой стороны, в том числе стартаперы, они начинают думать, ну вот они сажают студентов, а мы чем хуже, мы тоже посадим студентов, и пусть студенты нам пишут и набирают задания для закрытого бенчмарка, которым мы никому не покажем. И будем продавать, и будем говорить, что вот мы Очень-очень строгий, мы здесь являемся мерилом качества, воспроизводимости и так далее, но просто никому не покажем этот тест-сет, и пусть все к нам приходят. Ну вот, в конце концов, оказывается, и у Epoch AI, и у ScaleAI, у них примерно похожая была модель, у ScaleAI много бенчмарков, в том числе на function calling, и так далее, и они, в принципе, активно ходят. Мне кажется, у любой компании крупной, у Google, и у OpenAI, и Atropik, все они пользуются так или иначе с KLI-бенчмарками, их разметкой. Ну вот, а скандал произошел с бенчмарком FrontierMath. Это такой бенчмарк, как это говорится сейчас на reasoning у языковых моделей, но в математике в различных областях. И там было достаточно большое обсилие сообщества, там были связи с университетами, и чуть ли не филдсовские лауреаты сидели и писали сложные задачи, там цепочки рассуждений, правильные ответы для этих математических задач. И это действительно очень сложный бенчмарк, то есть он был совершенно не стурированный, как сейчас говорят, то есть на нем был большой разброс результатов, у систем было совершенно неровное качество, для многих систем это была задача слишком сложная. Результаты были очень низкие, но вот мы смотрели и видели, что до сверхчеловеческого интеллекта доказать теорему в определенных областях нам еще очень далеко. условно. А OpenAI рапортовала, что у них там все очень хорошо, как обычно, очень высокие результаты, и потом оказалось, что IPOC-EI этот бенчмарк делал, в общем-то, по заданию на деньги OpenAI. И об этом не было объявлено заранее, и даже люди, которые непосредственно участвовали в составлении этого бенчмарка, математики, не знали, что только у OpenAI будут данных. Ну вот, таких проблем раньше не было. Раньше все-таки, когда денег в бенчмарках не было, можно было им доверять чуть больше. Теперь стоит еще смотреть и на это. Ну и в такой ситуации могла бы не только OpenAI оказаться. В принципе, любые бенчмарки, которые напрямую спонсируются какой-то пробной компанией, надо смотреть на них аккуратно. Другая проблема, которая со всеми же бенчмарками тоже существует, это безусловно то, что их становится очень много, они очень быстро саккурируются, и большое количество усилий тратится на то, чтобы как можно быстрее показать state of the art на этих бенчмарках. Есть такое выражение state of the art or perish. публикации не показали, что вы стали самыми лучшими хотя бы на одном батчмарке, то, возможно, ваша публикация не заслуживает принятия на конференцию. К сожалению, вот такая парадигма, вне зависимости от новизны метода, который вы предлагаете, она очень часто мешает хорошим работам пройти и приводит, безусловно, к тому, что во многих задачах мы получаем совершенно сатурированную картину, когда разброс между системами очень-очень маленький, после того, как вот сразу выходит новый бенчмарк, и потом раз-раз-раз-раз, и все очень кучно идут, и за годик, условно, доходим до 99%, и дальше можно выбросить. Но можно ли сказать, что эту задачу мы успешно решили? Да, в общем-то, нельзя, потому что Опять же, что-то из этого утепло, что-то из этого купили какие-то очень похожие данные, пофильтровали. То есть это все далеко не всегда достигается именно благодаря алгоритмическим достижениям. Это конкретно график текущего состояния бенчмарка BigCodeBench. Это такой бенчмарк по способности моделей генерировать выполнимый и исполнимый код. И вы видите здесь, вот когда я говорю, что он сатурирован, вот я примерно вот это имею в виду. Здесь еще не самый плохой вариант, потому что здесь суммарно вы видите не 99% верхняя планка, а всего лишь 57. Но он еще недолго существует, еще более где-то, чуть меньше, так что возможно дальше мы увидим через год, что уже здесь будет 90+, и тоже вот такая же будет кучность примерно. Вот. Ну и точно также новые бенчмарки, которые выходят, они в последние годы, конечно, несколько теряют продолжительность своей жизни и своей применимости. Если раньше мы говорили всегда, что Всегда датасет живет дольше, чем модель, поэтому лучше отдельно всегда писать публикацию про отдельный датасет и отдельную публикацию про метод, потому что на метод будут ссылаться один-два года, и потом он устареет, а датасет еще 10 лет будет жить, как какой-нибудь цифр 10. Но сейчас уже все не так, и многие бенчмарки тоже живут полгодика и все. И новые хорошие бенчмарки, даже очень сложные, которые появились в 2024 году, даже раньше, чем год назад, они уже потихоньку тоже начинают устаревать. Вот есть Frontier Math — это ризнинг на математике. Есть бенчмарк TauBench, на котором тоже репортуют успехи и антропик, и многие другие работы. Это симуляция таких бизнес-ориентированных диалогов, суппорт технический относительно поддержки заказов, отмены, поменять даты билетов и так далее. Есть software engineering бенчмарки, где надо показывать, что модель умеет генерировать исполнимый код, который при этом действительно решает заданную проблему, которая может быть достаточно сложная. И Life Code Bench тот же, например, который тоже похож на SVE Bench, но вот они решили бороться с контаминацией таким образом, чтобы смотреть только конкретные задачи, привязанные к датам, и там можно очень аккуратно пофильтровать задачи. были, например, задачи только за последнюю неделю, за последний месяц. Если, например, мы видим, что у одной из моделей, которая занимает очень высокое место в лидерборде, планомерно снижается качество, если смотреть более новые задачи, это значит, что старые были решены за счет контаминации, по сути. Ну и MLE Bench, про него сегодня еще подробнее тоже поговорим. Это бенчмарк тоже, который нам позволяет оценить способность не просто модели писать код, но и решать очень конкретные сложные задачи в заданных условиях, где конкретно нам выданы технические условия для обучения какой-то модели машинного обучения. Задан датасет, задана метрика целевая, и мы должны, вот языковая модель или агент на ее основе, он должен научиться через несколько итераций аккуратно приходить к решению, которое затем сопоставляется по объективным метрикам, по метрикам кросс-антропии, например, или по метрикам точности полученной модели с моделями, которые уже исторически предлагали люди-участники. С ними совсем что-то не так, на самом деле. LiveCodeBench, при том, что даже он борется с контаминацией, но при этом на нем уже тоже все сатурировано и плотненько идут все модели с очень маленьким разбросом. FrontierMap, мы уже говорили, что он скомпрометирован, непонятно, можно ли на него серьезно опираться, ну или как минимум только на него, может быть. в совокупности с другими независимыми бенчмарками. SwayBench, кодовый бенчмарк, потихонечку тоже сатурируется, на нем очень активно пробуют модели. И TauBench, несатурированный бенчмарк, на нем разгрос пока что очень большой, очень высоких метрик нет ни у кого на нем. Но, тем не менее, он просто очень маленький, что для меня удивительно. Там две части в одной 119 задач, у другой 50. Это очень мало. Очень мало точек наблюдения, чтобы, в принципе, иметь достоверный результат. Потому что вы одну и ту же модель можете на таком батчмарке запустить пять раз, и у вас будет разброс 10%. MLE-бенч пока что единственный, который не сатурированный, и мы еще поговорим почему. Все эти бенчмарки так или иначе, они в некотором роде агентские. Агентские в том смысле, что часто системы, которые там сопоставляются, это не только языковые модели, а это некоторые аугментированные языковые модели, у которых есть также доступ к внешним инструментам, будь то браузер или среда, в которой можно исполнять код на определенном языке, какой-нибудь контейнер, там обычно есть еще способ проверить, сделать обратную связь, код исполнился, не исполнился, какие были ошибки, если ошибки нет, какой результат, что нужно делать дальше, там часто бывает какой-то модуль планирования и так далее. Да, это всё аугментированные языковые модели, которые, в общем-то, инструментами, которые вместе с ними работают, да, это всё, что связано с памятью, с доступом к информации, с внешними инструментами и так далее. Все это надо как-то оценивать. Все это надо как-то оценивать, возможно, даже строже и сложнее, чем мы делали для языковых моделей, потому что все эти внешние инструменты нам помогают, по сути, налепить закладку на затладку на недостатки фундаментальных языковых моделей, о которых мы уже давно знаем. Да, это все, что связано с невозможностью часто отличить фактологическую информацию от галлюцинаций. Это все, что связано с непосредственно знанием последних событий, которые были неделю назад, а не во время обучения модели. и так далее. Таких бенчмарков сейчас в целом много, часто они, это тоже статурировано достаточно, в бенчмарке веб-арена и визуал-веб-арена, где уже мультимодальные системы соревнуются, там есть некоторый набор заданий, что характеризует агентские бенчмарки, это то, что там всегда есть некоторый набор заданий, в которых можно очень четко объективно определить правильный результат. То есть это могут быть задачи, которые не то чтобы прям очень интеллектуальные для нас с вами. Например, где-то пойти в браузер, что-то найти, найти где что-то купить на маркетплейсе, положить это в корзину, потом кому-нибудь написать, там сопоставить цены и так далее. ориентированные задачи, но тем не менее там можно оценить, был достигнут правильный результат или нет. Конкретное действие в данном случае было получить имейл на почту о том, что вот такой артикул товара куплен. Было это достигнуто или нет, да или нет. В этом смысле действительно эти бенчмарки не сатурированы и при этом достаточно сложны. Но мне бы хотелось сегодня поговорить на самом деле про еще один ряд совершенно новых бенчмарков, которые на их основе возникают, потому что у нас с вами есть уже системы с исполнением кода, у нас есть с вами системы, которые получают обратную связь от исполнения кода, какой-то очень качественный ризнинг. Соответственно, когда мы говорим, что мы строим AGI, сверхинтеллект, возникает вопрос, ну на чем же мерить, не на браузинге же интернета, а мерить наш сверхинтеллект. Давайте попробуем науковемкие задачи, давайте попробуем что-то, где действительно, в принципе, мы знаем, что Сверхинтеллект может быть очень полезен, потому что в некотором роде, я всегда говорю, что сверхинтеллектуальные системы уже давно существуют, просто они не искусственные. Любой НИИ или хорошо выстроенная коммерческая организация, если там правильно организованы профессионалы, отделы и так далее, это некоторые сверхинтеллектуальные системы, потому что Она в целом обладает совокупностью знаний и навыков, и целеориентированна гораздо больше, чем один конкретно взятый человек. Ну вот давайте попробуем, возможно, применить агенты к акселерации науки. Для начала небольшое отступление, потому что с тем, что науку надо акселерировать, вообще не все далеко согласны. Есть большое опасение в сообществе, что наука в целом сейчас переживает тяжелые времена уже даже без акселерации с помощью искусственного интеллекта. И у этого есть действительно некоторые основания. Во-первых, у нас с вами не хватает рецензентов. На всех крупных конференциях, в том числе и в журналах, рецензирование — это неоплачиваемый труд сообщества, некоторая повинность. Часто, если вы засылаете статью, вы обязаны отрецензировать часть статей. Ну а представьте, таким образом, если мы расширяем пул рецензирования, в общем-то, что происходит с качеством рецензирования. Качество рецензирования последние годы тоже упало, это отмечают все. Рецензентов не хватает, и при этом рецензии, которые мы получаем на свои работы, они стали хуже качества. При этом сместился фокус, по крайней мере в публикациях области компьютерных наук, с публикацией в журналах, потому что публикация в журналах, опять же, там часто гораздо более качественное рецензирование и более долгое, сместился фокус на открытые площадки, где вообще никакого рецензирования нет, в частности архивы. ну или там open review, где в общем-то можно получить рецензию от любого желающего, ну и вот работа ваша будет висеть в открытом доступе. Почему это происходит? Понятно, почему? Ну потому что работы очень быстро устаревают. Да, соответственно, ждать пока целый год журнал будет рецензировать вашу работу никто не будет, потому что она к этому моменту уже устареет. Но при этом что же происходит? с научной ценностью работы и с целеполаганием. индустрия и все усилия тратятся на краткоиграющие публикации, которые очень много, очень сильно устаревают, пусть даже они открытые, что тоже хорошо, но вот некоторые, в частности, вот Эмили Бендер, это бывший президент организации, ассоциации компьютерных лингвистов, организаторов всех крупнейших конференций по языковым моделям, считает, что архив — это рак на науке. Это её мнение, безусловно, но многие в сообществе, безусловно, опасаются, что науку лучше бы замедлить, лучше бы как бы инспирировать людей, публиковать поменьше и пореже, зато более качественно, отправлять всё так же в журналы, развивать инфраструктуру, чтобы рецензирование было более качественным. будет ли так, мне сказать сложно, мне лично кажется, что с тем, что происходит сейчас, это все-таки мало вяжется, и при том, что проблемы действительно есть, мне кажется, что ситуация так и усугубится в следующие годы. И усугубится она, к сожалению, в том числе из-за искусственного интеллекта. Одна из работ, которые я включаю Как критический пример, это статья EI-Scientist от стартапа SakanaEI. Достаточно большая публикация, советую ее почитать более подробно. Основная ценность данной работы состоит в том, что они предлагают на текущих языковых моделях создать готовый пайплайн, который полностью повторяет, в принципе, вполне человеческий, наукообразный подход к написанию публикаций, без малейшего вовлечения человека, и в результате такого пайплайна мы должны получать не какую-то научную новизну, или верифицируемое открытие, или какой-то новый метод, А просто большое количество уже сгенерированных PDF-файлов, которые можно смело класть на архив и говорить, что всё, у нас новая публикация, замечательно. И моделируются, собственно, по очереди совершенно все ступени, начиная от генерации идей, проверки новизны относительной, очень плохо прописанной, генерация возможных экспериментов в методологии, генерация кода и операция с этим кодом. Итерирование по экспериментам совершенно нормально, но затем происходит написание манускрипта по результатам без какой-либо проверки и затем моделируется даже рецензирование статьи. Рецензирование статьи работает автоматически как некоторый фильтр, чтобы отфильтровать совсем неудачные работы, но в принципе можно представить, что Без малейшего вовлечения ученых и вообще хоть какой-то валидации на многих этапах этого плана мы можем получить совершеннейший мусор. И так и происходит. Но тем не менее, интересное достижение, мне кажется, статьи, что все-таки они попробовали смоделировать всю ситуацию до конца, в том числе смоделировать и автоматические рецензирования, посмотреть, будет ли оно действительно совпадать с рецензиями на OpenReview. И на самом деле, во многих случаях, может быть, даже и будет. Может быть даже и будет. И это иллюстрирует действительно проблему, о которой и Эмили Бендер пишет, и о которой пишут сторонники движения замедленной науки, потому что инфраструктура, лицензирование, даёт трещину, рецензирование у нас становится всё менее и менее качественное, и поэтому всё легче и легче получить эмулирование этого рецензирования и, сгенерировав 100 статей, автоматически, не читая их, выбрать ту, которая, скорее всего, получит наивысший балл. Конечно, ничего общего к науке это не имеет. Ну а что же может быть на самом деле полезно науке, если подходить к автоматизации науки аккуратно? С чего бы нам начать? Тут, наверное, надо сказать, что В целом, не ко всей науке вообще, наверное, можно модели сверхинтеллекта, в том числе какой-то, в будущем применить. Наверное, можно как минимум применить к тем областям науки, где уже хотя бы есть хоть какой-то формализм, и в этом формализме можно выделить хоть какие-то модели и симуляции. Моделирующих науку у нас все равно достаточно много. Это и физика, и лингвистика, и нейронауки, и много-много всего. И ученые в этих областях уже давно работают с моделями, просто это не модели искусственного интеллекта, а какие-то их другие формализмы, совершенно часто не связанные между собой, а иногда и связанные через некоторые математические конструкции. Мы как бы не стремимся ничего объяснить или проинтерпретировать, но мы стремимся отдельно в этих науках построить такие модели, которые бы были приближены к реальности. Научная школа исторически распадается, возникает новая, предлагается новый формализм, новые модели, они чуть-чуть лучше, мы переходим на них, и вот итерируясь, итерируясь какие-то есть постоянно конкурирующие подходы к моделям в разных науках. Соответственно, искусственный интеллект во многих из них уже и был таким формализмом, таким способом смоделировать что-то. Мы все с вами прекрасно видели, что прекрасно применяются такие модели таких областях, как моделирование ДНК, или генерация молекул лекарств, или автоматическое доказательство теориям. И спокойно это нормально работает, если это делать аккуратно, и даже Нобелевскую премию за это дают. Соответственно, аккуратно можем начать с того, чтобы, например, автоматизировать ablation status. Например, если предлагается новый метод, улучшенная модель в какой-то науке, можно попробовать автоматически, просмотрев больше статей, чем физически может человек, автор статьи или научный коллектив посмотреть, предложить более полный обзор всех методов, на которых ее надо проверить, всех возможных модификаций, которые являются в данном случае применимыми, чтобы проверить, будет ли это еще лучше работать, или если хуже, то почему. И это все действительно необходимо, потому что во многих работах сейчас ablations недостаточно представлены, и мы получаем в недостаточной степени полные работы очень часто, какой-то результат получен, а почему и за счет чего конкретно, мы точно не знаем. Часто за счет утечки информации, но часто из-за каких-то еще причин, и может быть даже мы теряем некоторые алгоритмические достижения по ходу, потому что мы не успеваем посмотреть, а почему собственно метод, который мы предлагаем, лучше. Точно так же автоматически, если человек формулирует какие-то гипотезы, можно автоматизировать большое количество итераций над этими гипотезами, посмотреть, что будет лучше работать. Ну и моё любимое в том числе это автоматизировать проверку идей в кросс-дисциплинарных между разными областями и посмотреть, которые, например, были проверены в одной области и хорошо работают, но могли бы быть переносимы и на другую. Например, отдельные направления языковых моделей рекуррентных, архитектуры типа Mamba. Мы их давно видим, и какая-то работа по ним ведется, и вроде как это здорово, что есть альтернативные архитектуры, они развиваются. Ну вот, а когда же мы увидим некоторые их обобщение в других областях, в той же моделировании ДНК, или в химии просто, или в нейронауках. Почему есть ДНК-верт, а ДНК-мамбы нет? Ну просто ни у кого не доходит руки это сделать. И когда в модели еще очень много разных выходит, и выходит очень много их различных вариаций, ну правда Есть существенные пробелы, до которых ни у кого руки не доходят, но это можно сделать автоматически. Совершенно можно сделать и можно, в принципе, даже предоставляя новые модели и новые архитектурные достижения, сразу показывать, что они хорошо работают, например, не только для языка. И в данном случае мы сразу улучшаем воспроизводимость наших экспериментов, и мы очень хорошо улучшаем верифицируемость и фальсифицируемость, потому что мы сразу показываем, где работает и где не работает. И это могло бы быть существенным скачком вперед, на самом деле. И поскольку область машинного обучения сама по себе работает и с моделями, и с симуляциями, она сама тоже становится в некотором роде объектом моделирования. И есть достаточно много работ, которые стремятся именно автоматизировать исследования в области только машинного обучения и вокруг. В частности, уже упомянутый MLE-бенч. которые являются по сути автоматизацией бенчмарков, автоматизацией исследований в области машинного обучения, но в очень заданных условиях конкретно. Авторы берут то, что в принципе уже было готово, кегл-соревнования. Кегл-соревнования — это системы, в которых Все желающие могут поучаствовать и предоставить свое решение, заданные задачи машинного обучения. Там зафиксированный обычно всегда датасет, зафиксированная метрика, по которой все оцениваются, открытый и закрытый тест-сет. Главное — предоставить свое решение в заданном формате. система автоматически его провалидирует, скажет, какая у вас там точность кросс-энтропии или что-то еще, и вы увидите, где вы, какое место занимаете в общем лидерборде в решении этих задач. И удобно, в принципе, потому что мы можем, имея систему, пусть даже агентскую какую-то, которая итерируется по коду, может взять фиксированный датасет, взять какой-нибудь baseline с него начать и начать итерироваться, улучшать, улучшать, улучшать модель. Мы, в принципе, действительно можем увидеть результат и сразу его место в общем лидерборде и, условно сказать, вот мы стремимся попасть в золотые медалисты в соревнованиях. Практически как олимпиадные соревнования, только в мире машинного обучения. И можно еще протестировать заодно сразу разные альгентские фреймворки, разные логики построения такой системы. Где-то это будет напрямую просто задача где-то это будет более сложная система с итерацией относительно кода, где-то это будет очень специализированная система относительно дерева решений, чтобы помнить все параметры переборы гиперпараметров и так далее. Ну и действительно оказывается, что такой подход часто работает, и текущее состояние вот таких агентских системных языковых моделей нам показывает, что мы даже в текущем сетапе с вот заданным датасетом, заданной метрикой, заданным базовым решением, мы можем попадать в золотые медалисты автоматически. Вот, например, модель У1, она попадает в золотые медалисты в 9% случаев, почти в 10. Золотые медалисты — это топ 10% всех решений. Ну, достаточно серьезно. Ну и можно и другие языковые модели тоже попробовать. Вот мы видим, что там лама в 2% случаев топ попадает. То есть есть, в принципе, существенный разрыв в том, отдельный вклад языковых моделей, которые существуют, насколько хорошо они работают в различных логиках. Что в самой лучшей логике лама все равно не дотягивает и только в двух процентах выдает топовый результат. Помимо прочего, есть еще и подходы, которые пытаются справедливо оценить, что же происходит с новизной. Да, мы уже говорили о том, что оценка новизны, и в целом вот рецензирование – это некоторое слабое место, которое очень трудно преодолеть. Да, это некоторое бутылочное горлышко. Ну, может быть, все-таки мы можем построить какую-то систему, которая будет более надежной, подсказывать, что же там происходит. Ну, оказывается, что на самом деле нет. Вот, авторы данной статьи, они попробовали такой подход, они попробовали посмотреть, можем ли мы с различными фреймворками, с различным доступом к статьям заставить языковые модели, агенты на их основе, сгенерировать идеи и сгенерировать очень короткий одностраничник к этой идее, чтобы При этом рецензенты не смогли это отличить от человеческих идей и сказали, что это действительно более новая, более интересная идея. На самом деле, конечно, такой эксперимент можно провести, и можно даже провести настоящее рецензирование, не говоря, на что авторы смотрят на самом деле. Они смотрят на исследовательские предложения по абстракту, которые написаны были настоящими исследовательскими группами или языковыми моделями. Ну и оказывается, в общем, что если смотреть по текущей системе, вполне такой же, как и на OpenReview, смотреть на новизну, на то, как хорошо звучит, на то, как это вообще можно выполнять, на то, как это там... в целом, это осмысленная задача или нет, Но в целом оказывается, что разница существенная. Вот здесь вот желтеньким показан человек, голубеньким чисто идеи языковой модели, а темно-синим показаны идеи, которые искусственный интеллект, условно, сгенерировал, но другие посмотрели и выбрали то, что на глазок им кажется получше. Вот мы видим то, что на глазок человек выбирает, оно в целом не сильно лучше, чем то, что было уже и раньше просто сгенерировано. Но в целом результаты такие, что результаты языковых моделей по научной новизне как будто бы выделяются, статистически значимо они получают более высокие оценки, оцениваются как более новые. С точки зрения вот интереса рецензиена, тоже часто оцениваются как более интересные. При этом выполнимости общая оценка значимости никакой нет, то есть примерно все-таки одинаково, но при этом, когда мы непосредственно анализируем, а что же там было сгенерировано, то у всех из генерированных предложение, у них есть шесть типичных паттернов, ошибок, которые, в общем-то, приводят к тому, что идеи эти либо невозможные, либо очень ограничены на самом деле. Звучат хорошо, но не совсем являются исполнимыми. Например, очень часто расплывчатое описание деталей реализации, неправильное использование датасетов, Отсутствующие или совершенно неподходящие baseline предлагаются, базовые решения. В целом слишком большая требовательность к ресурсам, которые невозможно обеспечить. Отсутствие правильной методологической мотивации. опора на предыдущие работы и так далее. Сейчас объективно оценивать, что достаточно тяжело автоматизировать полный пайплайн от генерации идеи до эксперимента самого. Именно бенчмарки, которые не сатурированы и которые тяжелые все еще в решении для большинства систем сейчас, это как раз научные бенчмарки, которые пытаются покрыть именно эту область проблем. Вот, например, работа Science Agent Bench. Это как раз такой бенчмарк, который основывается на уже существующих научных статьях. Там выбраны экспертно 44 статьи из хороших журналов, у которых есть хороший, прилагается к ним датасет, к которому прилагается базовое решение и очень хорошо описаны метрики. Опять же, даже похоже на MLP-бенч, на Kaggle-соревнования, только из разных областей науки. И там есть задача среди этих 44 на самые разные области применения. на биоинформатику, на химию, на нейронауке, но везде там есть какая-то языковая модель или там надо обучить какую-то ML-модель, у которой есть тоже объективная метрика. И на их основе сделано 102 разных задания, у которых есть объективное измерение результата. И в частности задачи самые очень разные, там есть и обработка данных, и моделирование, и визуализация. Ну и в целом оказывается, что если сравнивать различные бейслайны, авторы заключают, что у них вот по результатам получается, что системы, у которых есть возможность исполнять код и итерироваться относительно кода, они гораздо лучше справляются сейчас с этими задачами. И еще они очень много сами проводят ablation, то есть различных экспериментов, где какие-то части систем выключены. Например, они разные языковые модели с разными агентскими системами внутри сравнивают перебором. И они еще делают доступ к научным статьям, доступ к знаниям и без доступа к знаниям, то есть только опираясь на то, что языковая модель знает сама. И вот у них в текущих их формулировках получается, в общем-то, что совершенно не всегда доступ к научным статьям сильно дает какое-то преимущество относительно того, чтобы использовать знания, которые уже есть в модели. Вот. Еще похожий бенчмарк — это Discovery World. Он тоже, в общем-то, очень похож на Science Agent Bench. Там тоже научные агенты или там агенты для науки, но они... И они тоже, на самом деле, с различными, разными наборами данных из разных областей науки специально. и тоже химии, даже есть археология, физика и даже лингвистические задачи там есть. Но оно в некотором более кукольном формате, если хотите. Там 120 задач, но они все очень неразнообразны. Там есть всего 14 действий, которые может любой агент предпринимать. Там что-то посмотреть, поставить какой-то конкретный эксперимент. что-то погуглить, там что-то проанализировать и так далее. И, соответственно, как бы разнообразие действий, оно там очень сильно контролируется, и можно лучше прослеживать отдельные паттерны, но при этом как бы нельзя сказать, что этот бенчмарк нам полностью дает свободу и хорошую вариативность задач. Но зато там действительно надо делать полный пайплайн тоже в этой ограниченной симуляции, надо придумывать гипотезы, почему что-то случилось, надо выбирать объекты для экспериментов, надо выбирать данные для экспериментов и так далее. Ну и есть работы, которые вот без бенчмарка, тоже вышли примерно в то же самое время, но вот пытаются сделать, собственно, акселерацию науки с помощью агента и пытаются как-то его оценить. В частности, вот Research Agent, он в Open Source доступен, кстати, все эти работы доступны в Open Source, они совершенно открыты. Вот у них концептуальный подход, что давайте будем опираться более качественно на литературу, давайте попробуем все научные статьи и хорошие источники связать в граф знаний некоторый по кросс-ссылкам, и давайте давать агенту доступ именно к этому графу знаний, чтобы он ходил, собирал факты, а не просто рандомно использовал какие-то непонятные вещи, которые нашел в интернете. И затем это все оценивается людьми, либо ЛЛМкой, насколько хорошо получилось сгенерировать эксперимент и результат, то есть оценка там как бы не совсем использует какой-то объективный результат исполнения экспериментов, то есть в принципе можно придумать что угодно, но вот они очень хорошо сравнивают по различным областям, тоже как на OpenReview, в общем-то по важности, по явности результата, по релевантности, по оригинальности, насколько хорошо получилось написать план эксперимента и результаты И мы видим, что автоматическая оценка, которая справа три кружка, и человеческая оценка, это слева три кружка, она, в общем-то, очень не похожа друг на друга. То есть мы видим, что автоматическая оценка часто достаточно сильно смещена статистически, и она часто даже более строгая, чем оценка, которую дают люди. Работа очень большая, я вам советую тоже ее почитать более подробно. В частности, там есть тоже хорошие облейшины относительно использования знаний и неиспользования знаний. Там как раз показывается, что граф знаний очень полезен для таких агентов. Все эти статьи я оставляю здесь. Тоже можете потом ознакомиться, я думаю, презентацию тоже мы пришлем. И в завершение хочется, наверное, вот что сказать. Кажется, что все доступные, по крайней мере те, которые находятся в открытом доступе задачи, связанные с текстом, уже очень скоро будут сатурированы. Поэтому новые бенчмарки, они так или иначе должны быть более сложными, они будут, скорее всего, агентские, многоступенчатые, вот с какой-то частью исполнимого кода итерации на нем. достаточно мало, практически нет бенчмарков агентских, которые были бы на какие-то более прикладные задачи профессиональные, чтобы был как бы MMLU, но агентский. Зато сама область email и все науки вокруг, у которых есть хоть какое-то моделирование, становится объектом этого самого моделирования, потому что там есть очень четкие цели и очень можно аккуратно задать среду, в которой надо итерироваться, чтобы Loss уменьшался, точность росла и так далее. Тем не менее остаются очень актуальными такие бутылочные горлышки, как что же делать нам с автоматической оценкой новизны. Если эксперименты мы быстро научимся делать очень хорошо, непонятно как все равно оценивать новизну. Новизну мы умеем оценивать плохо. Хорошего решения нет. И валидировать весь pipeline целиком end-to-end тоже умеем плохо. Помимо того, что существует ML-задачи в очень четко заданных условиях, есть еще очень много задач, у которых условия заданы нечетко, и надо придумывать и опираться на некоторые собственные решения методологические, которых у агентов нет, и тоже непонятно, Если мы делаем шаг в сторону какого-то более открытого научного исследования, то здесь мы можем пока что генерировать любой бред, к сожалению. И сильным искусственным интеллектом это пока не назвать. Но это явно следующий шаг, куда все будет двигаться. Спасибо. Вопрос, пожалуйста. 

S00 [01:04:22]  : Татьяна, спасибо. Один из участников уже задал тот же самый вопрос, который я задал в конце. Настолько ли круг дипсик как его молюют? Стоит ли оно того хайпа? 

S01 [01:04:41]  : вот или это как бы моё сегодняшнее выступление часто я думаю что я специально не упоминала особо дипсик но я не смогу от него убежать я понимаю это ну что ж ну дипсик на конкретных пенчмарках вполне себе мы видим объективно что показывают очень хороший результат и это замечательно у нас есть контент и конкуренция open-source с closed-source замечательная. Насколько хорошо, насколько показательны эти бенчмарки, которые мы видели, к ним всегда могут быть вопросы. То есть отдельный взятый набор бенчмарков — это всегда тоже результат контаминации, результат подтягивания каких-то данных, разметки в обучающий выбор, чтобы это было получше. Но если дальше мы увидим, этим действительно можно пользоваться каждый день на том же уровне, что и привычными моделями, то это уже более показательно. DeepSeek пока еще не применили ко всем вот этим научным агентским бенчмаркам, про которые я сегодня рассказывала, и я думаю, что это будет очень хороший показатель, потому что как раз эти задачи сложные, несатурированные и очень объективные. и новых достаточно. То есть как бы у них еще несколько лет жизни точно есть. И часто у-1, у-3 там занимает с большим отрывом первые места. Вот если дипсик тоже будет с небольшим отрывом тоже занимать высокие места, это будет показательным. 

S00 [01:06:16]  : Спасибо. Следующий вопрос от Кима более серьезный. Татьяна, сегодня в ИИ-исследованиях много говорят о ризнинг, цепочках рассуждений, формальной логике, выстраивании аргументации. Но у этого ризнинга есть и человеческая сторона. Сторона согласованности, связанности, понятности рассуждений для реальных людей. То, что мы видим в концептуальном моделировании DSL, согласовании требований и т.д. Как вы думаете, стоит ли нам отделять технический аспект ризнинга, алгоритмы, логика от гуманитарного, когнитивный и лингвистический, и рассматривать этот абстрактный уровень согласованности рассуждений как самостоятельное направление лингвистики или смежных гуманитарных дисциплинах? 

S01 [01:07:00]  : Интересный вопрос. На самом деле, на практике, конечно, разные виды ризнинга отделяют друг от друга. и можно составить прикладную антологию ризнингов разных, отдельно разные области математики, отдельно какие-нибудь научные рассуждения, отдельно что-то гуманитарное, потому что, в принципе, скорее оно все вместе друг другу мешает, и надо как-то подробно отдельно подходить к каждому из этих типов. С точки зрения лингвистики у меня был такой вопрос, может ли это являться каким-то объектом исследования, потому что такого типа данных вообще говоря лингвистика практически не видела, мы видели их мало. Как правило, может быть у человека есть поток сознания и мы его не особо очень терморизируем, не всегда, не весь, не сто процентов, умеем мегам или чем-то еще так что дословно прям записать да и оказывается что этот внутренний диалог это вещь такая относительно недоступная относительно вот текстов в интернете И возможно то, что мы видим сейчас, это некоторый вспомогательный материал, который не имеет на самом деле прямого отношения к тому, как логические цепочки происходят у человека. Просто их удобно читать или удобно на них учить модели. И удобно отслеживать, а что они там учат и куда Идёт само это рассуждение. Совершенно оно на данном этапе как будто оно не привязано к тому, как идёт рассуждение у человека. Просто это удобно. 

S00 [01:08:44]  : Спасибо. Коллеги, если у кого-то есть еще вопросы, вы можете задавать в чат, а я пока пойду, потому что есть. Вопрос. Как вы видите перспективу появления у больших языковых моделей или систем на них основанных? инкрементального обучения, переобучения. Потому что сейчас, как я понимаю, если мы модель долго и упорно тренировали на каких-то наборах данных, включая результаты экспериментов, собранных по обратной связи, по предыдущей версии модели, то Мы с ней работаем какое-то время и можем только загружать в контекст дополнительную информацию, уточняющую наши запросы. И для того, чтобы получить новую версию этой модели с учетом того, что мы и наговорили в контекст, мы ее должны снова перетренировать с учетом всех собранных логов коммуникационных. Вот как вы видите проблему, если уж мы про AGI говорим, то есть возможность не только решать широкий круг задач, но и постепенно самосовершенствоваться. 

S01 [01:09:56]  : Да, мне кажется, что это, скорее всего, вот что-то, что мы увидим в следующем году, в текущем году, возможно, тоже. То есть мы уже видели успех оффлайн обучения с подкреплением языковых моделей, а онлайн обучение с подкреплением еще не очень, но вот отдельные работы выходят, и как будто хочется нам иметь возможность обновлять какую-то который мы получаем. Может быть, даже не обязательно это фидбэк от пользователя, это может быть фидбэк от самой среды, когда мы что-то неправильно написали, код какой-то неправильного-неправильного привел нас к результату, мы терируемся. Возможно, сама разница в том, насколько хорошо мы решаем и будем дальше решать задачи с элементами автоматизации, она вот именно здесь лежит. 

S00 [01:10:51]  : А за счет чего вы это видите? То есть это в рамках существующих архитектур или их доработок? Или какие-то вы видите принципиально новые, перспективные? 

S01 [01:11:03]  : Нельзя с точной долей уверенности сказать, что OpenAI это уже есть. Но допустим, если мы считаем, что O3 это что-то в таком роде, и мы видим разницу непосредственно Lama405B и O3 на конкретные задачи, вот как раз такого рода, там, MLE bench, допустим, то мы увидим, что, ну, действительно, разница достигается за счет того, что просто pre-train качественной модели не хватает. Вот. И, ну, никаким, там, просто fine-tuning ее так просто сделать не очень удобно. В какой-то момент уже мы достигаем лимита того, что можно сделать с помощью фронта. 

S00 [01:11:51]  : Спасибо. А как вы видите перспективы повышения энергоэффективности ЛЕЛЕМ? Или это будет достигаться за счет просто увеличения производительности и снижения стоимости и снижения энергозатратности железа? то есть как, чтобы можно было, если не в каждый дом, то в каждую компанию. 

S01 [01:12:17]  : Сейчас очень большой тренд это модели для он-девайс, то есть возможно мы увидим и действительно вот даже новые чипы, которые Nvidia выпускает, растет. Они, конечно, для работотехники и всего, что на устройстве, оно должно быть маленькое, объективно. Оно должно быть очень эффективное, потому что ждать, пока оно отправится на сервер по интернету и придет ответ сервера, это очень долго. Решение надо прямо здесь сейчас принимать. Поэтому это просто отдельная ниша, которая развивается. Отдельно Еще, наверное, тоже часть мотивации — это увеличение контекста, вот, контекстного окна языковых моделей. Сейчас, опять же, у нас есть RAC, да, и у нас есть окно контекста, да, вот как нам лучше положить длинный документ. Если нам нужно делать вывод по всему документу, то скорее REC нам не подходит, нам надо все положить в длинное контекстное окно, там длины миллионов, десять миллионов токенов. Это очень долго, если просто в пронт положить войну и мир и ждать, пока произойдет префил. даже со всеми кэшированиями, это будет, я не знаю, 5-10 минут. И, соответственно, очень большие усилия направлены на то, чтобы именно сделать эффективной работу с длинным контекстным окном. И кажется, Google даже в этом преуспевает, потому что у них за счет того, что у них тоже свои чипы на TPU, все работает, Gemini, У Gemini очень длинный контекст, они 10 миллионов сделали первым, и это единственное решение среди коммерческих моделей, которые предлагают такой объем контекста. И это в принципе просто возможно за счет того, что оно очень сильно оптимизировано. Ну и дальше тоже будет больше оптимизироваться. 

S00 [01:14:19]  : То есть, всё-таки речь идёт о том, что в рамках существующих архитектур мы просто повышаем энергоэффективность, повышаем миниатюризацию, делаем устройства новые типа того, что Nvidia демонстрировала на ладонную карточку. Понятно. Следующий вопрос. Конкретно у меня на одном из проектов ситуация, что мы делаем рак на основе моделек. Сейчас, допустим, мы поняли из того набора моделек, который был в каком-то моменте, на чем у нас работает лучше всего. На нем настроились, что-то делаем, а тут выходят новые модельки. Новые модельки оказываются лучше, чем старые. Нужно на них переезжать. А там все работает по-другому. Промпты другие нужны. Нужно все перенастраивать. Поскольку модельки будут меняться сейчас, очевидно, если не каждую неделю, то не реже раза в месяц. Как бы вы их рекомендовали? выстраивать пайплайн разработки и тестирования, чтобы можно было верифицировать, что фреймворк в целом, вся система, включая RAC, не деградирует или как минимум работает в рамках обратной совместимости. с предыдущей версии. Я это вижу только в создании каких-то собственных фреймворков под свои доменные специализации. Можете прокомментировать? 

S01 [01:15:53]  : Сейчас фреймворков очень много, в которых можно просто подменять самую языковую модель. Если вы написали что-то, что подходит именно под ваш случай, то скорее надо иметь набор тестов, чтобы контролировать обратную совместимость. И в тестах в данном случае можно взять парочку уже существующих бенчмарков на рак и длинный контекст. например, Needle in the Haystack на качество извлечения, или Loft, например, тоже длинный бенчмарк, на еще reasoning на длинном контексте, там разные задачи есть. Соответственно, там есть много, там большой набор метрик, и вы можете увидеть, что условно, не знаю, у вас был мистраль, вы подменили на свежий гипсик, который вроде бы похожего размера с такими же характеристиками, и вы увидели, что вот на этом же бенчмарке у вас там качество выросло на 5%, ну вроде, значит, должно работать. А потом подменили на какую-нибудь еще новую мистраль или там решили оптимизировать опять же учлительной мощности взяли маленькую модельку, раз у вас там уже минус 30 процентов. Ну как бы это надо просто контролировать. Иногда эти минус 30 процентов, если это гораздо дешевле, то это все равно имеет смысл. 

S00 [01:17:18]  : Спасибо. А как Вы видите существование и решение проблемы интерпретируемости с применением ЛЛМ и решение на их основе? Есть ли эта проблема или ее нет? Или если она есть, то решается ли она просто в процессе интерактивного взаимодействия на естественном языке? 

S01 [01:17:39]  : Да, ну вот конкретно для агентских систем, как будто бы мы остаемся на том же уровне, на этой проблеме, как мы были раньше. То есть у нас остается открытым вопрос механической интерпретируемости части языковой модели. А все, что вокруг, это некоторая программистская абстракция, чуть ли не EFL, правиловая система, как в 80-е. Если это, то посмотри в поиск документов. Если там что-то еще, то посмотри, сходи в интернет. И вот эти части совершенно интерпретируют. Тут как бы проблемы никакой нет. Главное, чтобы это лагировалось. Относительно языковых моделей, Полтора года назад, мне кажется, была хорошая работа, где антропик предложили прямо отслеживать цепочки активации конкретных нейронов в разных задачах, и оказалось у них в частности, что на самом деле работает даже в большой нейросети нейронов очень мало. А все остальные как бы тоже есть, но активизируются совершенно не всегда. И если что-то работает неправильно, то обычно именно на уровне цепочек активации это часто видно. что куда-то в сторону отходит. Да, но дальше что с этим делать? Например, мы нашли конкретный случай, и мы даже с помощью вот таких методов интерпретируемости мы установили конкретные условия, при которых это начинает работать неправильно. Почему активизируется не та цепочка, которая нужна. Дальше все равно встает вопрос о том, что с этим делать, как это лечить. Это надо менять, искать какую-то причину в обучающих данных, это надо переучивать модель, это надо сверху лепить какую-то заплату. Пока что хорошего решения нет. Не то чтобы как будто есть даже какой-то индустриальный стандарт относительно этого. Есть просто выверенные наборы данных. Возьмите вот это, обучитесь на этом, и у вас не будет сильных смущений. Будет как датасет безвредных, полезных примеров. От антропик, например. Просто какие-то морально-этические задачи, в которых учат правильно принимать решения. чтобы не наносить вред человеку. Они подобраны специально. Но является ли это исчерпывающим или является ли это достаточным? Точно ли при обучении на китайских корпусах гипсика это не приведет к тому, что вот эти данные слишком недостаточные, слишком далеки от того, что было в предобучении? Открытый вопрос. 

S00 [01:20:30]  : Спасибо. Вопрос от Андрея Пихтина. Большое спасибо за рассказ. Скажите, пожалуйста, насколько качественно получается работать с такими большими окнами внимания, как у G-Mini? Кажется, по крайней мере для Гигачата, что количество ответа падает на меньшем количестве токенов, чем заявлено. 

S01 [01:20:49]  : Да, это хороший вопрос. Про Gemini я уже говорила, что у них в некоторых версиях этой модели доступных там даже 10 миллионов токенов в окне контекста есть. Конечно, они не совсем равномерно используются. я не знаю, война имеет 10 миллионов токенов, наверное, меньше, но будем считать, что примерно так, то разные части ее, конечно, будут там представлены с разным качеством. И оптимизация, всякие усилия по тому, чтобы оптимизировать работу именно механизма внимания на этом контекстном окне, они часто приводят к тому, что качество-то ухудшается еще больше, то есть работает быстрее, но что-то теряется явно. Метрики, которые вводятся дальше, чтобы это контролировать, они часто строятся не только на слепом извлечении фактов из разных мест войны и мира, что мы знаем, что с каждой страницы мы можем извлечь факт правильно, но еще и построение выводов на некоторых извлеченных фактах с разных страниц. И вот это уже является таким более качественным обобщением того, что длинное контекстное окно работает. Они работают 100% не идеально сейчас, то есть вот еще часть извлечения отдельных фактов может работать неплохо, там 90% допустим точности, но если факты между собой, то совершенно не гарантировано, что оно будет прям очень точным. 

S00 [01:22:32]  : Спасибо. Вопрос от Артемия Адановского. Татьяна, как думаете, столкнёмся ли мы или уже сталкиваемся с кэшированием генераций? Очевидно, что в каждую модель поступают тысячи одинаковых или почти одинаковых запросов и должен быть соблазн в целях экономии отдавать на один и тот же вопрос один и тот же закэшированный ответ. С точки зрения пользователя это не совсем то, что он хотел. С другой стороны, если ответ устраивает, то почему бы и нет? 

S01 [01:23:02]  : Это такое продуктовое решение, если оно и принимается часто, то действительно из-за некоторой продуктовой экономии в принципе сделать это возможно, потому что есть некоторые параметры, вроде как случайный сид, который можно зафиксировать и при одинаковых запросах подставлять этот фиксированный сид и использовать то, что уже было сканировано, и в принципе это будет даже воспроизводимо. Но обычно все-таки так не делают, потому что тогда репутация падает. Если это какая-то технологическая компания, обычно все-таки нет. Обычно так не делается. Но можно это делать на некоторых… Не обязательно на последнем уровне уже картинку выдавать готовую. Это же можно кэшировать некоторые внутренние представления. я не знаю, конкретно у диффузионных моделей, они же делают много шагов, условно у вас 100 шагов итерации, прежде чем диффузионка выдаст вам финальную картинку, вы можете кэшировать на 20-30 шаге, это уже будет существенная экономия, и сверху доделывать, и картинка во время этих шагов существенно меняется, 30% шагов вы сэкономите при этом. Я думаю, что так и делают на самом деле. 

S00 [01:24:19]  : Спасибо. Вопрос от Александра Харитонова. Куда будет развиваться направление AI safety в ближайшие пару лет? 

S01 [01:24:30]  : Я не то чтобы очень много занимаюсь AI safety, я понимаю, что я сегодня как специалист широкого профиля выступаю, постараюсь. Есть очень много направлений, которые еще не покрыты никак с точки зрения AI-сейфти, а прототипы при этом уже делаются. Или вот когда тот же OpenAI заявляет нам, что Deep Research или их новый режим работы с нейросетями может очень сильно помочь в таких ежедневных интеллектуальных задачах, да, и что он может за вас ходить в интернет, и он может оперировать вашим логиновым паролем, там где-то регистрироваться, где-то что-то смотреть, составлять документы, да, но вот каждая часть из этого, она в целом как бы может быть, несет в себе существенный риск, а если это все целиком, вместе одна цепочка, то риски могут быть очень большие. Также интернет сам засорен уже достаточно сильно этими языковыми моделями. И качество источников, которые без вашего ведома нейросеть собирает, они тоже могут быть очень спорными. Мне кажется, что существенная часть сейфити будет безусловно работать с валидируемостью и качеством источников. потому что без этого никуда, иначе мы просто будем по сгенерированным страницам ходить, и никакой валидированной научной и качественной информации у нас не будет. Ну а вторая часть — это, безусловно, safety, вот безопасность для агентов, потому что если мы уже даем системе какую-то следующую степень автономности, там, от моего лица, как пользователя, сделай что-то, Сходи в интернет, поищи что-то. Здесь огромное количество, которые можно придумать. И с точки зрения дискредитации пользователя, и с точки зрения безопасности его компьютера, и даже просто с точки зрения того, насколько будет безопасным результат. 

S00 [01:26:42]  : Спасибо. Вопрос. Как связаны агенты, которые двигают мышкой и кликают в интернете с языковыми моделями? 

S01 [01:26:54]  : Они очень сильно связаны, потому что у каждого агента есть как минимум модуль планирования, который придумывает, ага, мне надо сделать первое, второе, пятое, десятое, чтобы выполнить эту задачу, прям пишет, на какие сайты пойти. Дальше, да, это делает часто мультимодальная система, то есть там как обязательно есть хорошее распознавание изображений, там скриншоты, модель распознаёт какие-то объекты на скриншотах, принимается решение вот кликнуть, симулировать клик мышки вот по таким координатам. И часто ещё эти скриншоты получают текстовое описание, опять же, что вот здесь явно на скриншоте там это интерфейс поиска, а это реклама, а это спам. Это как бы очень прямо связано. 

S00 [01:27:43]  : Спасибо. Еще у меня был вопрос про Канемана. Не знаю, готовы вы ответить или нет. Как вы вообще относитесь к этой его дихотомии? Система 1, система 2. Имеет ли эта дихотомия смысл вообще и в частности в больших языковых моделях? И если имеет, то какое? 

S01 [01:28:04]  : Я напомню, что Бенжи в 1919 году популяризировал подход, вдохновленный прочтением книги Дэниела Каннемана. мыслить медленно и быстро, кажется, так оно по-русски называется, thinking fast and slow, и там приводится вот такая некоторая онтология интеллектуальных способностей, что есть вот система 1, древняя и медленная, за которую как бы отвечает мозжечок, но это сильное упрощение древнего мозга, и есть вот thinking slow, это вот система номер 2, за которую отвечает кора. И, соответственно, к системе 1 относится вождение машины, относится всё, что связано с машинным зрением, относится действия, которые мы делаем на автомате, относится система контроля дыхания, хождения и так далее у человека. И задачки в ML тоже есть такие же, то есть всё, что то, что связано с какой-то простой классификацией, это как бы система 1. А система 2 — это какие-то высокоинтеллектуальные системы, это как раз ризнинг, цепочки рассуждений, математика и так далее. Это просто одна из антологий. Мне кажется, что в тот момент она как будто была достаточно удобна. Ну вот я не берусь оценивать здесь, насколько сила метафоры нам действительно помогает. К метафорам когнитивистским стоит относиться, наверное, достаточно аккуратно. Иногда они действительно могут помогать нам организовать систему лучше, ту же самую агентскую, но здесь солью всего является практическая применимость. Если мы на основе системы Канемана сможем сделать два типа модулей агента, и они вместе так хорошо будут работать, ну, наверное, да, наверное, это является некоторым подтверждением того, что это полезно. Ну, или там кого-нибудь еще, там, любых там когнитивистов восьмидесятых, да, там, кого угодно можно взять, тогда да, тогда да. Но, как бы, это Лекун еще рыбачит, Хлубер тоже, вот, тоже. Нарисовать какую-нибудь систему, значит, мозга еще приклеить, и вот очень выглядит убедительно как бы. Но вопрос опять же здесь всему глава – это верифицируемость, фальсифицируемость. Можно ли действительно это сравнить в равных условиях с другими системами, будет ли это давать преимущество и за счет чего? Относительно того, что есть ли у этого какое-то будущее сейчас у агентов, я давно не слышала, что прям использовали. Хотя конкретно метафора с Канеманом, ее недавно как раз использовали сторонники медленной науки. которые предлагают нам думать медленно. И они как раз использовали эту метафору, чтобы сказать, что «Ребята, вы генерируете много каких-то не очень качественных публикаций, давайте вы будете как «Система-2». Потому что мы научное сообщество, мы должны очень отработать как кора, а не как мужичок». 

S00 [01:31:43]  : понятно спасибо коллеги есть у кого-то еще вопросы татьяне устно задать потому что в чате у нас вопросы кончились можно подать руку так вот появился вопрос как агенты могут сейчас значит как агенты могут быть автономны если они обращаются копии Я не совсем понял вопрос. 

S01 [01:32:11]  : Да, они обращаются к ОПИИ. Они автономны в том смысле, что они не требуют промежуточного подтверждения человека очень часто. Они так спроектированы часто, что для достижения цели в конкретных условиях агент может придумать себе план, в котором будут действия из 10 опишек состоящие, из веб-поиска, еще из чего-нибудь, из цепочек рассуждений, исполнения кода с учетом полученной информации. В промежутке там нигде человек рубильник не выключили, в этом смысле автономно. 

S00 [01:32:44]  : А я правильно понял, что в какой-то момент вы сказали, что те агенты, которые для решения каких-то задач, имеется ввиду, как я понимаю, вычислительных задач, могут писать код и запускать его, типа пандас-эйджента в ланчейне, очевидно, то они, в общем, достаточно хорошо с этим справляются, даже в том случае, если у них нет доступа к дополнительной информации. 

S01 [01:33:14]  : Да, ну, в принципе, поиск не нужен. То есть, если вы возьмете, там, дипсик, или мистра, или ламу, неважно, да, и вы просто напишите сами даже. питоновскую небольшую обертку, что вот придумай кусочек кода, который должен, я не знаю, строить линейную регрессию на датасете iris классической, и надо задачу уменьшить какие-то метрики. В принципе, допустим, напишет он один какой-то выполнить, получает результат, анализирует логи и такой «ага, все, теперь можно предложить вот такие исправления». Либо получили ошибку, значит, надо еще что-то поменять. В принципе, для этого больше ничего не нужно. Среда исполнения и системы, в которые можно итерироваться на основе языковой модели. 

S00 [01:34:11]  : Понятно, спасибо. 

S01 [01:34:12]  : Ну и, естественно, это должен быть ограниченный контейнер. 

S00 [01:34:16]  : Да, да, да, про это надо не забывать. Вопрос ещё от Семёна Бойко появился, даже три вопроса. Что думаете по поводу сетей Колмогорова-Арнольда, Колмогоров-Арнольд Нетворкс, есть ли у них перспективное будущее? 

S01 [01:34:32]  : Ну, мне вообще всегда нравятся альтернативные архитектуры, мне хочется, чтобы всегда какой-то процент времени исследователей он уходил на какие-то не самые хайповые вещи условно, какие-то, которые как бы не очень предсказуемы, альтернативные методы. Поэтому в этом смысле, конечно, это очень интересный подход. Ему не было предложено никакого практического применения, мы пока что не можем сравнить никакие КАНы на тех же самых метриках, на которых мы сравниваем трансформерные модели, поэтому здесь как будто, ну потому что это не в том состоянии зрелости еще это исследование, да, там просто предложена сама эта архитектура и вот некоторые минимальные совершенно эксперименты. Это в таком состоянии, это часто такие работы, их 50 штук в год как минимум проходят на NeurIPS. А потом из них остается в практике одна или ноль. То, насколько это приживется. Мне хочется автоматизировать исследование таких вещей. Допустим, у нас есть рекуррентные разные архитектуры, которые возникают. RKVW, там была вот Mamba, вот KAN, ну хорошо бы, чтобы агент в заданных условиях, с заданным вычислительным бюджетом, например, мог аккуратно их все сравнить в одинаковых условиях на одних и тех же датасетах, и нам моделирование каких-то типов данных, к которым только трансформеры добрались. ДНК, например. А может и нет. Мне хотелось бы автоматизировать эти вещи, эти исследования, потому что очень много вариантов, как это может сыграть, и внимание сообщества распределено неравномерно очень. Все равно все читают одни и те же какие-то популярные статьи, ссылаются на них же, очень много работ проходит незамеченно, совершенно несправедливо. 

S00 [01:36:48]  : Спасибо. Следующий вопрос от Бойко Семёна. Считаете ли вы, что Возможен без физического воплощения, например, в виде робота? 

S01 [01:36:59]  : Да, конечно, возможен. Без физического воплощения языковые модели работают. Да, ну как бы там, в принципе, у человека, когда человек учится, учит язык, у него же есть обратная связь от среды, да, у языковой модели нет никакой обратной связи от среды, она учивает язык совершенно по-другому на других принципах. Если мы хотим какие-то данные среды передать в какую-то мультимодальную модель, там, пространство, какие-то карты глубины, там, и так далее, это все совершенно спокойно, без физического воплощения можно сделать. 

S00 [01:37:38]  : Спасибо. И последний вопрос от Семёна. Что думаете по поводу квантового машинного обучения в контексте AGI? 

S01 [01:37:46]  : Я ничего не знаю про квантовое машинное обучение, если честно. 

S00 [01:37:51]  : Спасибо. 

S01 [01:37:53]  : Я рада, если оно есть. Давайте посмотрим, что там будет. 

S00 [01:37:58]  : Спасибо. Коллеги, есть ещё к Татьяне вопросы? Если вопросов нет, тогда, Татьяна, благодарю Вас за участие и от имени всех участников нашей сегодняшней встречи. Большое спасибо и будем Вас ждать в следующий раз. 

S01 [01:38:21]  : В следующем году. 

S00 [01:38:22]  : Да, в следующем году. Благодарю, благодарю. Если вдруг появится что-то новое, что рассказать, то приходите раньше. думаю все-таки что нет ну вдруг придете расскажете хорошо всем большое спасибо спасибо татьяне до новых встреч до свидания спасибо до свидания до свидания 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
