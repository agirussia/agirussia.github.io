# 19 сентября 2025 - За пределами глубокого обучения: новая парадигма в машинном обучении - Николай Токарев - семинар AGI
[![Watch the video](https://img.youtube.com/vi/mAuOKhsS4K0/hqdefault.jpg)](https://www.youtube.com/watch?v=mAuOKhsS4K0)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239227)
- [видео в RUTUBE](https://rutube.ru/video/e9781516d47cda62a42db2e804e14c79/)
- [КОРА (алгоритм) Бонгарда](https://ru.wikipedia.org/wiki/%D0%9A%D0%9E%D0%A0%D0%90_(%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC))

## Краткое содержание:

Николай Токарев представил на семинаре русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта новую парадигму в машинном обучении, названную "машина Т". Эта архитектура призвана решить ряд проблем, присущих современным нейронным сетям, таких как непрозрачность принятия решений, высокие вычислительные требования и уязвимость к атакам.

### Основные проблемы глубокого обучения, которые призвана решить "машина Т":

*   **Непрозрачность ("черный ящик"):** Сложность в понимании того, как нейронные сети принимают решения, что ограничивает их применение в критически важных областях, таких как медицина и военная промышленность.
*   **Высокие вычислительные требования:** Обучение крупных моделей требует огромных ресурсов, что делает их разработку доступной только крупным компаниям.
*   **Уязвимость к состязательным атакам:** Модели, такие как GPT, могут генерировать нежелательный контент при незначительных изменениях во входных данных.
*   **Экологический след:** Обучение больших моделей потребляет значительное количество электроэнергии и оставляет большой углеродный след.

### Архитектура "машина Т":

Вдохновленная символическим подходом в искусственном интеллекте, в частности, архитектурой "Кора Бонгарда", "машина Т" основана на наборе логических правил (клауз), которые обучаются на основе обратной связи. Ключевым элементом является "порог принятия решения" (Т), который определяет, будет ли правило считаться истинным или ложным.

**Принцип работы:**

1.  **Инициализация:** В начале работы все параметры устанавливаются на уровне "порога памяти".
2.  **Обучение:** На вход подаются обучающие данные (например, признаки кошки). Правила (клаузы) обновляются с определенной вероятностью: признаки, соответствующие классу, усиливаются (их значение повышается), а несоответствующие — ослабляются (значение понижается).
3.  **Формирование итогового правила:** Признаки, значение которых превысило "порог памяти", формируют итоговое правило для классификации.
4.  **Классификация:** Новые данные сравниваются с итоговым правилом. Если большинство признаков соответствует правилу, объект классифицируется как принадлежащий данному классу.

### Глубокая "машина Т":

Для решения более сложных задач, таких как XOR, была разработана многослойная версия — "глубокая машина Т". Эта архитектура строит иерархию правил, что позволяет создавать ассоциативную память (например, на более высоком уровне абстракции "кошка" и "собака" могут быть объединены в класс "животные").

### Результаты и сравнение:

*   На задаче распознавания рукописных цифр MNIST "глубокая машина Т" достигла точности 98% уже после первой эпохи обучения.
*   В сравнении с глубокими нейронными сетями, "машина Т" показала более высокую скорость обучения на первых 50 эпохах.
*   **Преимущества:** прозрачность процесса рассуждения, устойчивость к шуму, более низкие требования к объему данных и использование простых вычислительных операций (сложение и вычитание).

### Планы на будущее:

*   **Создание прозрачных рассуждающих систем:** Систем, способных делать выводы на основе логики и объяснять их.
*   **Разработка автономных агентов:** Архитектура уже была протестирована в игре "пинг-понг".
*   **Морфогенетические системы:** Разработка систем, способных самостоятельно организовывать свою структуру (количество слоев), что приведет к созданию более энергоэффективных архитектур.

### Дискуссия и вопросы:

В ходе обсуждения были подняты важные вопросы, касающиеся новизны подхода, его ограничений и потенциала. В частности, обсуждались проблемы добавления новых признаков (требуется полное переобучение), масштабируемости интерпретируемости для очень больших систем и возможности применения для обработки естественного языка. Николай Токарев отметил, что некоторые из этих ограничений планируется преодолеть в будущих версиях, например, с помощью "морфогенетической" структуры, которая будет обладать свойством нейропластичности.


## Расшифровка доклада:

S00 [00:00:00] : Всем добрый вечер. Мы начинаем немножко в сложной научно-технической обстановке заседание очередного семинара русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта. И у нас сегодня в гостях Николай Токарев, который нам расскажет свое видение того, что нас ждет, может быть, за пределами парадигмы глубокого обучения. И хочет рассказать про новую парадигму в машинном обучении. Правда, здесь у нас уже была небольшая дискуссия по его презентации в чате EJI Russia, где некоторые участники чата предположили, что эта парадигма не столько новая, сколько хорошо забытая старая. Но я думаю, по ходу мы разберемся. Николай, пожалуйста. 

S04 [00:00:41] : Да, всем привет, коллеги. Я хочу сразу же оставить какие-то философские вопросы за порогом. Так, начнём. Собственно, план семинара такой. Сначала мы разберём, какие существуют проблемы машинного обучения. также какие существовали подходы до, и разберем, соответственно, новую архитектуру, которую я предлагаю на основе предыдущих подходов. Также мы разберем перспективы этой архитектуры. Собственно, начнем с того, что современная машинное обучение довольно хорошо справляется с задачами. То есть мы решили задачу игр AlphaGo, где получается очень много перебора нужно для того, чтобы решить эту задачу. Но эта задача была решена с помощью обучения с подкреплением. Вот. Также мы разработаны GBT-модели и генеративные языковые модели, GBT-модели и генеративные модели для генерации изображений. Но за всем этим стоит колоссальное количество вычислений и не особо оптимальное расходование ресурсов. Проблема номер один. Проблема номер один — это то, что в критически важных системах мы не понимаем то, как, соответственно, глубокая нейронная сеть либо любая другая нейронная сеть принимает решения. Но при этом она эти решения принимает хорошо. Но мы не можем просто допустить такие архитектуры, каким-то критически важным решением, допустим, в отрасли медицины, там, в какой-то военной отрасли, ну и так далее. Это проблема номер один. Проблема номер два. Проблема номер два — это высокие вычислительные требования, что не позволяет современным исследователям разрабатывать какие-то свои архитектуры, на собственном железе. То есть нужно арендовывать большие серверные за большие деньги и соответственно это только предоставляется для больших компаний. Также проблема современных нейронных сетей глубокого обучения в том, что они очень уязвимы к состязательным атакам. Собственно, такой пример есть, такая проблема есть у GBT, то есть можно чуть-чуть переделать промпт и GBT-модель тебе получается начать генерировать какие-то очень токсичные ответы. Хотя и изначально обучали этого не делать. Также проблема следующая, которая наблюдается в машинном обучении, это экологический след от обучения языковых моделей и, собственно, вообще крупных моделей машинного обучения. То есть тут приводится пример то что обучение языковой модели может съедать, точнее генерировать столько же тонн CO2 сколько соответственно генерирует пять автомобилей за весь срок службы. Также обучение этих языковых моделей и вообще моделей нейронных сетей потребляет очень много электричества. Исходя из этих всех проблем, я решил посмотреть на предыдущие архитектуры, которые были до, и я увидел такую архитектуру как Карабонгора. То есть изначально эта архитектура основывалась на символическом искусственном интеллекте, где знания представлены в виде фактов и решения принимаются путем логического вывода. Соответственно, кора Бонгарда Эта архитектура изначально создавалась для распознавания нефтяных пластов. Собственно, кору Бонгарда сделан Михаил Моисеевич Бонгард в 1967 году. И одна из задач этого алгоритма была поиском закономерности с помощью вывода логических правил на каком-то уже подготовленном наборе данных. Но проблема этого алгоритма в том, что этот алгоритм использовал конъюнкцию логической И, и он не умел обобщать. дабы решить эту проблему я создал архитектуру под названием машина t собственно почему именно t в конце потому что есть такой эксперимент обучение в t-образном лабиринте где соответственно помещают туда грызуна он должен выбрать направление, куда ему идти, либо влево, где, допустим, разряд электрического тока, либо вправо, где, собственно, находится какая-то награда. Если грызун принимает все время неоптимальные решения, это, соответственно, глупый грызун, и получается так оценивают его интеллект. Т в конце этой архитектуры это порог принятия решения. Теперь пройдемся по самой архитектуре. Сама архитектура состоит из набора логических правил, которые называются клаузами. Каждая клауза вводит какое-то свое логическое правило на основании того, на основании входных данных. Собственно, эти клаузы обучаются на основе обратной связи. Для примера я продемонстрирую, как машина на такой простой архитектуре может классифицировать кошек и собак. Мы возьмем пять признаков. Это наличие хвоста, мяукает или не мяукает объект, лает или не лает, наличие шерсти и наличие белого цвета. Наша задача будет классифицировать кошек и собак. В самом начале машина инициализируется на границе порога памяти. Порог памяти устанавливается самим разработчиком. Все, что выше этого порога памяти, это по логике единица. Все, что ниже или находится на пороге памяти, это нолик. То есть это логическое отрицание. Все, что выше порога памяти, это логическое соответствие. ниже порога памяти или равно порогу памяти. Это логическое отрицание. Собственно так у нас инициализируется наша клауза. То есть изначально наша клауза инициализируется полностью и все наши параметры инициализируются на самом пороге памяти. То есть изначально машина вообще ничего не знает. собственно далее у нас поступают наши обучающие данные то есть вот у нас есть некое правило для обучения это наличие хвоста мы собственно пытаемся мы собственно пытаемся сейчас классифицировать кошку то есть первое правило для обучения по признаку кошку у нас Есть хвост, оно не мяукает, не лает, есть шерсть и не белое. Для того, чтобы ввести... Для того, чтобы... Собственно, архитектура не каждый раз все забывала и не каждый раз все запоминала. Для того, чтобы ввести какую-то вариабельность. мы добавим, собственно, сюда некую вероятность обновления. Соответственно, с помощью вероятности обновления у нас получается первое правило то, что есть хвост и есть шерсть. собственно признак мяукает у нас остался там же где и был и из-за того что признак light не соответствует из-за того что признак light это у нас соответственно нолик то есть он соответствует значению не light мы смещаем вниз И далее у нас еще есть признак не белый, соответственно он тоже смещается вниз, так как это отрицание. Идем дальше. Та же самая итерация повторяется на втором наборе данных. то есть все что соответствует признаку у нас идет наверх все что не соответствует признаку идет вниз мы получаем итоговое правило для классификации класса кошка это то что у нас есть наличие хвоста то что кошка мяукает и то что есть шерсть то есть все, что вышло от порога памяти, то есть Border Memory, как это тут обозначено красной линией, это наше итоговое правило, которое получилось. Соответственно, по этому итоговому правилу мы будем в будущем классифицировать новые данные. Теперь примеры с новыми данными. У нас поступает правило для классификации. Нет хвоста, не мяукает, лает, есть шерсть и наличие белого цвета. Собственно, четыре из этих признаков не соответствуют нашему правилу, которое выявила машина. Соответственно, они тут вымечены красным. Один признак соответствует. Так как четыре признака несоответствия это больше, чем собственно один положительный признак, машина у нас классифицирует свой ответ как то, что она не знает. Что это такое? Теперь дальше. Следующие правила для классификации. Наличие хвоста не мяукает, не лает из шерсти и белый цвет. Собственно четыре признака соответствуют нашему правилу классификации и один признак мяукает не соответствует нашему правилу классификации. Получается 4 признака соответствия больше чем 1 признак несоответствия и машина знает то что это кошка. Соответственно она с большей уверенностью ответит то что это кошка. Вот так в своей базовой логике работает этот логеритм. Далее этот алгоритм был реализован в коде на Python и C++ и было проведено сравнение с перцептроном. Собственно алгоритм дал примерно похожие результаты. Ну собственно сам алгоритм тут оказался чуть похуже перцептрона. и для того чтобы решить эту проблему была создана следующая архитектура это глубокая машина T собственно фишка глубокой машины T в том что это многослойная система которая строит иерархию правил то есть условно вначале у нас выводятся какие-то правила, которые обозначают какой-то объект. Допустим, у нас в начале есть объекты кошка и собака. Соответственно, объекты кошка и собака на следующем уровне могут классифицироваться как животные. И вот дальше они идут по уровням и классифицируются. В этом суть многослойной архитектуры. То есть она позволяет строить ассоциативную память. Собственно, пример того, как работает эта многослойная архитектура на задаче XOR. То есть с логического исключения. Мы вводим 1.1, у нас соответственно признак 1.1 соответствует второй клаузе. У нас эта клауза активируется, то бишь отвечает и подавляет другие остальные клаузы. Соответственно на выходе мы получаем активность второй клаузы, так как у нас Машина работает только с бинарными данными. Мы преобразуем вторую клаузу в бинарный вид, то бишь 0 0 2 0 0 1 0. Соответственно 0 0 1 0 соответствует у нас во втором слое первой клаузе. Мы выбираем опять же максимальное значение по соответствию. и итоговый у нас вывод это единица. То есть тем самым с помощью обучения с подкреплением эта архитектура способна создавать многослойные правила. Далее Далее я решил сравнить эту архитектуру с глубокой нейронной сетью. Она показала довольно внушительные результаты. То есть на первых 50 эпохах у нас уже эта глубокая машина отрывается от глубокой нейронной сети. ну и ну и далее тут точность почти что не повышается после 50 эпох у глубокой машины T вот то есть это доказывает то что соответственно эта глубокая машина T она лавливает правила быстрее чем глубокая нейронная сеть Далее, эта архитектура была протестирована на DTS-IT MINIST. Собственно, система показала точность 98% после первой эпохи. Выборка была такая, что 50 тысяч изображений сначала помещались в обучающую выборку, и 10000 изображений в конце помещались в тестовую выборку. По итогу в тестовой выборке мы получили точно 98%. Собственно, тут показан пример то, как на первых слоях, то есть вот на этих слоях заполнила машина то, как выглядит девятка. То есть разные формы девятки. Далее я решил сравнить глубокую машину T с глубокими нейронными сетями. Собственно, почти по всем параметрам глубокая машина T выигрывает у глубоких нейронных сетей. то есть она выигрывает потому что здесь решена проблема прозрачного процесса рассуждения то есть можно посмотреть что модель усваивает внутри своих слоев также тут нету проблемы зависимости от данных то есть Машина может обучиться за одну эпоху, распознавать изображения с точностью 98%. Также есть устойчивость к соответственно шуму, потому что это все-таки машина основана на логическом выводе, а не на статистике. и она пытается подобрать все под правило, которое у нее находится внутри. Также я решил сравнить глубокие нейронные сети, биологические нейроны и глубокую машину T по разным параметрам. собственно по механизму обучения локальный хэбовский он совпадает и у биологических нейронов и у этой машины потому что соответственно принцип хэбовского обучения хэбовского обучения в том что соответственно нейроны которые активируются вместе связываются вместе. Собственно, тут получаются паттерны, которые активируются вместе, то бишь находятся... то бишь находятся как бы... в одном обучающем наборе, они связываются вместе. Интерпретируемость. Соответственно, интерпретируемость у этой машины очень высокая, потому что, опять же, она основана на булевой логике, которая довольно понятна человеку. набулевые символьные линки, которые довольно понятны человеку. Также эта машина использует довольно простейшие вычислительные операции, то бишь она использует логические операции и только операции сложения и вычитания. Там не используется ни одной операции ни деления, ни умножения. Конкуренция. Также по конкуренции глубокие нейронные сети в основном распространяют свой сигнал во все нейроны, в биологических нейронных сетях нейронные сети подавляют, биологические нейроны подавляют активность соседей, собственно, выигрывает та нейронная группа, которая быстрее всего откликнулась. И та же самая лампка реализована в глубокой машине Т. Тобишь победитель получает все через голосование. Ну и собственно самое последнее, что я хотел сказать про эту архитектуру. Это планы развития, это ее дальнейшие планы развития. Собственно дальнейшие планы развития этой архитектуры таковы. То бишь с помощью этой архитектуры можно строить прозрачные рассуждающие системы потому что, опять же, она основана на символьной логике, которая довольно прозрачна. Также планируется создание автономных агентов с помощью этой архитектуры. Ну, я уже эту архитектуру тестировал в игре ping-pong. Агент довольно быстро научился играть в эту игру, но это уже наверное, можно будет обсудить потом. Также планируется разработка морфогенетической системы, то бишь, когда нам не нужно настраивать количество слевов, которое будет в системе, а когда система самостоятельно будет образовывать какие-то слои и самоорганизовываться. Тем самым она будет строить энергоэффективную архитектуру самостоятельно. Вот. Ну и в принципе... Вроде как по этой архитектуре я все разобрал. Спасибо за внимание. 

S00 [00:26:06] : Николай, спасибо. Тут у нас есть вопросы и в чате, и у меня есть ряд вопросов. Давайте будем через один. Один от меня, один из чата. У меня первый вопрос, продолжение той дискуссии, которая у нас была в чате сегодня. Смотрите, когда общая практика научных исследований, у нас семинар претендует, конечно, не на полную научность, Но когда готовится научная статья или научная публикация, обычно все начинается с исследования предшественников, чтобы убедиться в том, что не изобретается велосипед и не воспроизводится какой-то предыдущий результат. вот и поэтому вот вопрос вот кроме того что вы сказали в начале вот машина ван гарда вот кроме этого вы еще на что-то смотрели вы видели или смотрели что или тискали и находили что-то похожее чтобы не получилось так что вы сделали что-то то что уже делали несколько раз других проектах 

S04 [00:27:22] : Ну такую архитектуру я видел только у машины Бонгарда. 

S00 [00:27:28] : Хорошо. Тогда следующий вопрос от Виктора Казаринова. В клаузах 0 означает только отсутствие входного параметра, а единица наличия, нет значения, неизвестна. То есть действует только в замкнутом мире? 

S04 [00:27:44] : Да, в клаузах значение 0 означает отсутствие параметра, а значение 1 означает присутствие параметра, но значение неизвестно. Можно вычислить так, что вот мы, получается, берем параметры которые не соответствуют нашему итоговому правилу которое получилось в машине собственно у нас вот в данном правиле классификации не соответствует 4 параметра и вычитаем параметры которые соответствуют в итоге мы получаем точнее из соответствующих параметров мы вычитаем параметры которые не соответствуют в итоге мы получаем отрицательное значение либо значение равное нулю если это значение либо в итоге отрицательное либо оно равное нулю то это означает то что машина не знает что-то такое вот принципе такой ответ на этот вопрос хорошо 

S00 [00:28:56] : Вопрос доклада тоже от Виктора Казариного в догонку к предыдущему вопросу. Как ваша система справляется с появившимися в процессе эксплуатации новыми признаками? Например, в мире арбузов стало известно о треугольных арбузах. 

S04 [00:29:18] : Ну, изначально признаки в этой системе фиксированы. То есть, если получается, в мире арбузов стало известно о мире треугольных арбузов, то надо будет полностью заново переобучать всю систему по новым признакам. 

S00 [00:29:43] : А не является ли это тем же самым недостатком, одним из недостатков, за которые многие ругают глубокие нейронные сети? что если выяснилось, что у нас датасет не описывает существующую реальность, то мы не можем дообучить систему, а мы вынуждены по новой обучаться. 

S04 [00:30:06] : Да, в этой машине есть такой недостаток, но как раз таки я планирую в будущем разработать морфогенетическую структуру, которой этот недостаток будет решать. 

S00 [00:30:16] : А за счет чего он может быть решен? Просто интересно, куда здесь можно копать? 

S04 [00:30:26] : Вообще я сейчас не приступал к разработке морфогенетической структуры, но в принципе в биологических нейронных сетях есть такая особенность, как нейропластичность. То есть они способны адаптироваться под новые паттерны. Я планирую использовать такую же особенность в этой морфогенетической структуре. То есть будет некое количество клауз, которые будут как-то по-разному распределены. И каждая клауза, соответственно, может быть как и промежуточным слоем так она может быть и каким-то обрабатывать какие-то сенсорные сенсорные данные и обрабатывать какие-то выходные данные окей так у меня еще давайте парочку вопросов 

S00 [00:31:36] : Вот вы сказали в какой-то момент, то есть вы, значит, описывали, что у вас бинарная логика, вот, а потом в какой-то момент вы сказали, что система учит ассоциативные правила. То есть вот мне тут немножечко реже слух, значит, некоторая противоречия, потому что у нас логика либо ассоциативная или нечеткая, либо она символьная или логическая. Вот вы Нет, вы не видите здесь противоречия? Что вы подразумеваете под ассоциативностью, короче? 

S04 [00:32:07] : Тут используется символьная логика. Что я подразумеваю под ассоциативностью? У нас есть некоторые признаки, которые, соответственно, формируются на первом слое. Это какие-то сенсорные признаки. который в дальнейшем система может преобразовывать самостоятельно в процессе обучения в какие-то промежуточные данные. Я это называю ассоциативностью. 

S00 [00:32:43] : Могу ли я со своей колокольней сказать так, что мы принимаем решение о том, что если нам покажут кошку, которая будет допустим, без хвоста, но по всем остальным признакам она будет напоминать кошку, то все равно система примет решение, что это кошка, потому что она по большему числу признаков напоминает кошку. То есть это не точно кошка, но она напоминает кошку, и поскольку ничего больше, чем кошку она не напоминает, мы можем считать, что это кошка. Это оно? Это корректно будет сказать или нет? 

S04 [00:33:23] : Да, так, корректно. 

S00 [00:33:25] : Окей. Хорошо. И второй тоже давайте тогда вдогоночку еще вопрос от меня. Смотрите, значит, вот вы сказали, что у вас есть по сравнению с большими языковыми моделями прозрачность. Но если мы будем строить систему интерпретации, допустим, изображений или из обработки естественного языка, у вас система будет достаточно... у вас сеть вот этого перцептрона будет достаточно сложная и многослойная, правильно? Да. Вот. Не получится ли у вас, что сложность, даже вот так скажу, не получится ли так, что грубо говоря, чтобы получить примерно одну и ту же точность, Для одного и того же набора тестов вашей системой и глубокой нейронной сетью, вам получится иметь одну и ту же топологию сети, только лишь с одной разницей, что у вас эти связи будут логические, а у нейронной сети они будут с плавающей точкой. Ну и механизм обучения будет разным. У вас будет формирование клаус. а у нейронной сети будет backpropagation. Но топология, я предположу, что будет примерно одна и та же. И тогда вопрос, если у нас одна и та же топология, только коэффициенты либо логические, либо с плавающей точкой, понятно, что логи, бинарные коэффициенты, они более эффективны вычислительно, место меньше занимает, все хорошо, но с точки зрения интерпретируемости, насколько это будет проще, потому что это все равно будет каша, которую мы не сможем там явно идентифицировать логические правила. 

S04 [00:35:17] : ну если это будет Соответственно, большая, глубокая такая машина, то, скорее всего, да, там будет очень много правил. Но все-таки тут их можно как-то интерпретировать, взвлечь от глубоких нейронных сетей. 

S00 [00:35:40] : А вопрос на понимание, а если мы возьмем, грубо говоря, обучим нейронную сеть, Да, значит, потом пройдемся по всем весам и их, соответственно, откруним. Все веса, которые выше какого-то порога, запишем в единичку, а все, которые ниже какого-то порога, запишем в нолик. И потом вот эти вот веса, значит, загрузим в ваш перцептрон. не получится ли, что мы просто таким образом для инференса получили более эффективную систему, то есть не можем, я просто как бы эти рассуждаю, не можем ли мы backpropagation обучить нейронную сеть, значит, а потом просто использовать инференс с помощью вашей системы как более эффективную, более ресурсосберегающую. 

S04 [00:36:31] : Наверное, все-таки так не получится. 

S00 [00:36:34] : Не получится. Ну ладно. Хорошо, тогда следующий вопрос от Виктора Казариного. Не проще ли вместо иерархии правил сразу строить иерархию знаний в виде онтологии, а уже по ней можно выполнять различные операции, включая работу по правилам? 

S04 [00:36:53] : Ну, в принципе, тут... Но в принципе тут строится по сути иерархия правил и иерархия знаний. 

S00 [00:37:14] : Мы не можем их разделить. То есть у вас получается некоторое черно-белое дерево. У нас получается черно-белый направленный граф, где связи либо черное, либо белое. И там перемешиваем и правила, и знания. Правильно? Да. вопрос у меня вопрос встречный к виктору значит а как может быть проще строить иерархию то есть иерархию же кто-то кто-то должен построить значит как вы будете строить вот по моему николай здесь и строят эту иерархию и про и знание правил автоматически значит потому что не автоматически их разделить нельзя Я бы мог интерпретировать этот вопрос так. Можем ли мы как-то разделить иерархию правил от иерархии знаний? Но у меня нет ответа на этот вопрос. Вы можете разделить каким-то образом или подумать, как разделить иерархию правил и иерархию знаний? 

S04 [00:38:24] : Нет, тут в принципе разделить нельзя в этой архитектуре. 

S00 [00:38:30] : Виктор, если вы нас слушаете, а за счет чего простота будет достигнута? Вы можете подсказать Николаю, как сделать проще автоматическое формирование иерархии правил? Могу говорить? Да-да-да, слышим, ага. 

S02 [00:38:50] : Ну, тут немножко не так. Действительно, эта машина больше ваша машина Т похожа на Персептрон. А иерархия онтологии, она немножко другая. Ну, я как раз работаю над такой системой, поэтому и говорю. Правила на самом деле могут образовываться, вычленяться на основе графа вот этого онтологического. Ну допустим набор нескольких элементов, когда приходят новые факты, они активируют некоторые узлы онтологии. И соответственно от них можно фактически переходя по графу, мы можем те же самые правила Допустим, если у нас активировался сигнал А и Б, то что мы будем делать? Фактически, это, как правило, могут срабатывать переходы по элементам графа. Это самый простой вариант, когда близкие данные находятся. Но когда мы скрытые, со скрытыми знаниями работаем, которые далеко отстоят, соответственно нужно многоходовые сделать обработки, в том числе и работу с правилами. Вот сейчас вот я просто так экспромтом не смогу объяснить это дело. Но на самом деле Если есть автоматически созданная антология, то по ней можно накладывать правила. 

S00 [00:40:20] : Главная проблема с антологиями это то, что пока никто не придумал, как их строить автоматически. И как раз то, что Николай предъявляет, мне кажется, это как раз попытка построить энтологию автоматически, хотя бы в перемешку с правилами. 

S02 [00:40:37] : Вот именно, понимаете, две вещи взяты и подсмотрены у нейросетей, в которых соединены две вещи, и движок на каждом нейроне сидит. которые обрабатывают входные данные, и структуру знаний, которые образуются внутри, понимаете, в нейросетях. А в продукционных правилах разделены эти вещи, да, есть движок в продукционных правилах, сами правила имеются в виду, отделены, и факты отделены. И вот они, ну, плюс сам еще движок в продукционных правилах, там как бы больше разделено, вот. И поэтому здесь, ну, у него как бы Комбинация этих двух штук. Двух подходов получается. Но мне кажется, это не очень гибко. Вот смотрите, допустим, в ходной потоке идут сплошные данные. А у вас все это разбивается на правила. Если то, то, то, если то, то, то. Если же у нас идет поток, как в тексте, то в каждом внутри текста со сдвигом на любой символ, токен, мы можем уже получать продукционные правила. Допустим, какая-то фраза бьется, внутри нее мы можем уже выделять эти продукционные правила автоматически. Их таких станет очень много, понимаете? во входном потоке неразмеченных данных, неразмеченных, а здесь вот у него скорее всего размечены данные. То есть это вообще другая система. Ну ладно. Короче, я запутал вас, да? 

S00 [00:42:05] : Но меня не запутали, я просто не знаю, как вы собираетесь. На основании чего вы говорите, что проще будет сначала строить иерархию знаний? 

S02 [00:42:14] : Ну, смотрите. Во-первых, у него уровень сейчас вручную делается. Он берет произвольно, так же, как в этих 96 слоев сделаем. А почему 96, 95 или 301 слой в этих иерархиях? 

S00 [00:42:28] : Давайте у Николая спросим. Николай, вот вы как количество слоев задаете? 

S04 [00:42:32] : Ну и сейчас они задаются вручную, чисто на подбор. Но в дальнейшем при обучении можно использовать импринтинг, то бишь удаление ненужных весов, то есть которые близки, получается, то есть которые, соответственно, никакие правила почти не делают. Вот. И, соответственно, мы получаем гораздо меньшее количество слевов. 

S00 [00:43:05] : А что значит, вот тут я бы поспорил. Вот смотрите, вот у вас есть огромный слой, в котором есть часть узлов, являются содержателями и связаны с предыдущим и последующим слоем по делу. А часть весов являются пустыми, потому что допустим через них там все напрямую пролетает. Они просто один в один соединяют n-1 слой и n-1 слой. И вот как вы этот слой уберете? Понимаете, о чем я говорю? 

S04 [00:43:51] : Да. ну в принципе можно как-то сделать можно просто взять ну вот условно к примеру нам получается тут во втором слое не нужен условно какой-то первый параметр вот 1100 что мы можем сделать мы его можем убрать и соответственно убрать все числа которые отвечают за этот параметр внутри предыдущего слоя вот ну и в принципе так решить ту проблему вот 

S00 [00:44:41] : То есть, как бы мы можем понижать, получается, размерность связанных тензоров в этом тензорном пространстве, удаляя эти немые, так сказать, участки или незначимые участки. 

S04 [00:44:56] : Да. 

S00 [00:44:58] : Окей, хорошо. Следующий вопрос к докладчику тоже от Виктора. Какие именно нейросети Вы подразумеваете под глубокими нейронными сетями? 

S04 [00:45:10] : Под глубокими нейронными сетями стандартные нейронные сети, которые обучаются с помощью обратного распространения ошибки. 

S00 [00:45:23] : Окей, вот еще вопрос докладчику от Лины Бессоновой. Планируете ли вы специализацию сегрегацию ролей для агентов на базе машин Т, чтобы они могли глубоко погружаться в предметную область и соответственно снижались риски непрозрачности в чувствительных областях? 

S04 [00:45:46] : Я сейчас вообще не задумывался о барон-агентах пока что. Вот на таком уровне. 

S00 [00:45:53] : Окей. Ну, мне кажется, это логичное развитие вашего проекта. Если бы я отвечал на этот вопрос, ваш проект закрытый или open-source? 

S04 [00:46:04] : Проект пока что закрытый, но скоро он станет open-source. 

S00 [00:46:11] : Вот, кстати, я просто продолжаю наш разговор, Николай, с вами, который начался раньше, что вот то, что вы делаете, оно пересекается со многими вещами, которые я делаю, поэтому если будет желание, то можно будет делать некоторую совместную работу, а если делать совместную работу, какие-то высокорейтинговые журналы, то нам предполагается open-source реализация кодов. Но это как бы за рамками данного семинара, просто пользуюсь случаем сказать. Значит, вопрос еще от Виктора. Я услышал от вас, что количество слоев в вашей системе задается разработчикам, а количество правил внутри каждого слоя лимитируется. Я так понимаю, это вы же тоже задаете, да? То есть вы задаете количество слоев и количество правил в каждом слое, это типа гиперпараметры такие получаются? 

S04 [00:47:00] : Да, да, да. 

S00 [00:47:01] : То есть здесь как все у нейросетей, вы говорите сколько у вас в системе параметров и сколько у вас параметров на каждом слое и сколько у вас слоев? 

S04 [00:47:10] : Да, именно так. 

S00 [00:47:11] : И это, по сути, архитектура вашей сети. Очевидно, для разных агентов, специализируемых на разных задачах, в соответствии с тем, о чем Ильина Бессонова спрашивает, оно может быть разное. И задача подбора этих наборов гиперпараметров для конкретных задач – это отдельная проблема, которую тоже нужно решать. Правильно? Да. Спасибо. Так, еще вопрос от Лены Бессоновой. Возможно ли, по-вашему, формирование таких агентов на базе DEEP машин T, которые смогут сохранять и накапливать внутреннюю динамику целей? То есть не просто адаптироваться, а развивать агентную непрерывность, сдвигая акцент от реактивной к проактивной деятельности. 

S04 [00:47:59] : Сложный вопрос. ну я пока что вообще не тестировал эту систему почти в RAO агентах, вот, кроме Заттарча Пингфонга, поэтому я сказать ничего не могу. 

S00 [00:48:34] : Окей, но я могу сказать, что в моем понимании ответ на этот вопрос, он ровно такой же, как Он может быть для любой системы основанной на нейронных сетях, то есть чем более сложная система, чем больше у нее подсетей, чем больше у нее различных модулей, которые работают в различной модальности и взаимодействуют друг с другом, тем больше возможности там возникновения разных целей у разных модулей и у разных компонентов. в их взаимодействии. И соответственно, чем больше иерархия вот этих разных модулей, где более высокие модули, находящиеся на более высокой управленческой иерархии, получают информацию с одной стороны, а с другой стороны дают данные на вход модулями на на более низких уровнях управленческой иерархии, тем больше возможность формировать внутреннюю динамику целей, появляться конкурирующим целям, организовывать соревновательность целей. По этому поводу как раз у нас с Владимиром Крюковым про множество целей и сложные цели был доклад на конференции Красновидова на прошлой неделе, запись скоро будет, вот, а перед этим, по-моему, пару недель назад у нас как раз с Владимиром Курюковым был семинар на эту тему и, в принципе, значит, вот то, что Николай рассказывает, мне кажется, это, может быть, хорошая реализация. хороший возможный вариант реализации вот этой вот многоцелевой и много параметрической системы, основанной на так называемом пространстве состоянии, про которое мы с Владимиром рассказывали. Хорошо, следующий вопрос от режиссера Тарипова. В зависимости от контекстов и потребностей для разных агентов одни и те же объекты и ситуации могут иметь разные и даже противоположные значения и смыслы. Как это реализовано у вас? Возможно ли перечислить все множество таких контекстов и смыслов? Вот я даже сейчас пример приведу. Вот смотрите. У нас есть символы в разных алфавитах. Да, вот я оттолкнусь от проблемы этой самой МНИСТа, да? Вот у нас есть символы в разных алфавитах, которые в разных языках имеют разное значение, разную значимость. Ну, допустим, О в русском она О, а в английском ОУ. А А в русском языке она А, а в английском ЭЙ. Ну и дальше можно по списку. Если мы греческий возьмем, то там можем обнаружить, что гласное и согласное. То, что мы видим как гласное, в одном языке может оказаться согласным, в другом и наоборот. Соответственно, у нас появляется многозначность. Как у вас может достигаться эта многозначность? вы видите решение проблемы многозначности вашей системе? Понятен вопрос? 

S04 [00:51:55] : Проблема многозначности может решаться с помощью с помощью... либо сюда надо добавлять какие-то дополнительные параметры контекста, которые могут указывать явно на то, что контекст как-то изменяется. Ну, в принципе, больше В принципе, это один вариант решения этой проблемы. 

S00 [00:52:40] : Что значит добавлять параметров контекста? Имеете ли вы в виду, что у нас, грубо говоря, должен быть некоторое... Если для примера МНИСТа. То есть что, нам на вход нужно каждому квадратику еще язык добавлять в качестве дополнительного правила, добавлять битик, то есть, грубо говоря, сделать еще, положить рядом с картинкой битовую маску, где каждый битик этой битовой маски будет отвечать за определенный язык. И предъявлять, значит, для обучения уже две битовые маски. Уже две картинки. Одна картинка с битовой маской языков, а другая с изображением. Или как? Практически, как вы это видите? 

S04 [00:53:23] : Ну да, по сути, это битовая маска языка. 

S00 [00:53:33] : Окей. Спасибо. Вопрос от Дмитрия Балашова. Как решается проблема разметки обучающих данных? 

S04 [00:53:49] : Проблема разметки обучающих данных. В смысле, как обучающие данные преобразовываются в бинарный вид? 

S03 [00:53:57] : Я тоже не понял вопроса, Дмитрий, если вот здесь... Можно я голосом поясню свой вопрос? Вот смотрите, вы свои эксперименты обучали уже на размеченных данных, да? А, допустим, я хочу обучить вашу машину T на нескольких миллионов статей из Википедии. Как я их буду размечать, чтобы уже были готовые наборы объектов и их параметров, по которым будут строиться правила? 

S04 [00:54:28] : Ну, вам, соответственно, это скорее всего будет преобразовывать. эти все статьи в on вход вектора и, собственно, потом уже обучать машину. 

S03 [00:54:43] : Ну вот сам проблемой преобразования будет, по сути дела, нужна другая машина, чтобы из естественного языка как-то отформатировать входные данные, на которых можно будет потом вашу машину обучать. Да, так. Хорошо, спасибо. 

S00 [00:55:01] : А я, значит, со своей стороны тогда вот тоже здесь вопрос задам, значит, раз про Википедию было сказано. Вот смотрите, значит, МНИСТ – это задача классификации, значит, там с пинг-понгом – это задача, значит, генерации, там, правильного воздействия, там, вправо-влево стоять, значит, на некоторую, некоторый, так сказать, визуальный вход. Википедия, о Википедии, мы на что будем обучаться? То есть что мы будем, если мы берем Википедию, то мы, как я понимаю, решаем задачу NLP, мы решаем задачу unsupervised learning, вот, то есть мы решаем задачу например, генерации последующего токена, да, как это все делают большие языковые модели. Соответственно, вопрос, как ваша система, вот на примере ваших клаус, будет обеспечивать генерацию, вероятностную модель языка и вообще, может ли она обеспечить вероятность модели языка или это будет какая-то другая модель языка, вот как языка естественного в терминах вашей модели. То есть понятно, что мы каждое слово, видимо, каждое слово мы можем, каждый символ в последовательности мы можем закодировать как one-hot-vector, наверное. А дальше что? 

S04 [00:56:29] : можно закодировать каждые символы последовательности опять же как one-hot vector соответственно построить опять же некоторую слоистую модель которая будет выделять некоторые паттерны то есть она сможет выделять некоторые слова которые часто встречаются и тем самым обучаться 

S00 [00:56:56] : Но как вы пока не представляете, то есть вы пока не пробовали вашу систему использовать для задачи на УП, правильно? 

S04 [00:57:03] : Я пока что не пробовал. 

S00 [00:57:05] : Ну вот это как бы вот отдельная, наверное, будет история. Вот в вашем списке это, наверное, будет история, может быть, самая важная, поскольку как основное торжество больших языковых моделей, как я понимаю, сейчас оно в области на УП. имеет место быть. Еще знаете у меня какой вопрос, значит вот вы в какой-то момент сказали что у вас победитель забирает все и поэтому ваша система она примерно такая же эффективная как человеческий мозг, но насколько я понимаю в человеческом мозге там все гораздо интереснее в том плане что там вычисления происходят параллельно, то есть мы берем грубо говоря пытаемся распознать что-то значит, по большому числу, значит, этих вот колонок, вот, и если какая-то колонка что-то распознала, она кричит «я распознала», а остальные могут еще там, значит, колупаться и, значит, не иметь свой вывод к законченным, вот, тем не менее мы уже знаем результат. Вот, и в этом плане мы можем принимать решение быстрее, чем сделаем полный перебор. А у вас все-таки, получается, нужно для того, чтобы найти правильный вариант, перебрать все возможные варианты, пусть даже быстро, на бинарном уровне. Правильно? Вот этот у нас. Да. Или вам нужна какое-то специальное железо, или вам нужно это все загонять в карточки графические, чтобы это параллелизовать. 

S04 [00:58:31] : Ну, скорее всего, для данной архитектуры, да, нужно специальное железо. Ну, либо на графической карте, все правильно. Понятно. 

S00 [00:58:40] : Вот. Ну и еще тоже комментарий про пинг-понг. Насколько я понимаю, то что вы сделали в пинг-понге, это сделано для подкрепления в момент отбивания ракетки, правильно? Да. Отбивания мяча. А в настоящем понге, где ты не сам правила задаешь, а там, где ты правила получаешь от движка Atari, виртуального в OpenAI Gym, там все несколько сложнее, там отложено подкрепление, поэтому я бы настоятельно рекомендовал вам, как вы с Мнистом разобрались, пытаться получить результат на пинг-понге или брейкауте. Вот как я вам уже рекомендовал. Вот я как раз в Красновидово на конференции мы общались с Игорем Пивоваровым. Вот он сейчас развивает тоже свою альтернативную нейросетевой архитектуре, тоже иерархического обучения, основанную на имитации колонок человеческого мозга. И будет, кстати, доклад у него, по-моему, через несколько недель у нас на семинаре будет, по-моему, в начале октября. Приглашаю в нем поучаствовать, послушать, что Игорь расскажет. Но вот у него пока что такая ситуация, что он энергетически, у него там тоже все эффективно. Но скорости обучения и качество обучения, сопоставимого с Deep Cullioning, он пока не добился. Поэтому, чтобы говорить о том, что предлагаемое решение действительно выигрывает, для этого нужно занять призовое место в лидерборде Breakout и Ping-Pong, например. Будет очень интересно, если вам удастся обогнать, например, Игоря Пьеварова. Вот, собственно, у меня все. Какие еще есть вопросы? А, вот еще вопрос от Гизара Талипова. Вся реальность, правильно ли он понимает, что вся реальность описывается единым множеством правил? 

S04 [01:01:07] : Да, в принципе, тут формируется уникальное правило под каждый признак. 

S00 [01:01:24] : Так, Виктор Казаринов хочет еще что-то спросить. Виктор, пожалуйста. 

S02 [01:01:33] : Вот вопрос разработчику. Не считаете ли вы, что каждое продукционное правило это фактически формальный нейрон, имеющий бинарные входы, которые вы настраиваете вручную, фактически нейросеть собрана вручную со всеми коэффициентами во всех слоях? Потому что вы размечены данные, но у вас нет обратного распространения ошибки, только специфическая сеть. Это попытка сделать очередной вариант нейросети. Спасибо. 

S04 [01:02:12] : Ну да, в принципе это очень похоже на нейронную сеть. Тут есть обратное распространение ошибки. Это обратное распространение ошибки. Это называется мыслительная память. Вот. То есть в эту память закладываются клаузы, которые были активны, соответственно, в момент того, когда делался вывод. Вот. И потом, если фидбэк, допустим, положительный, то эти клаузы закрепляются. То есть они берутся из памяти и закрепляются. Если фидбэк отрицательный, то эти клаузы ослабляются. 

S00 [01:03:05] : Ослабляются? Да. А ослабление происходит каким образом? То есть есть какой-то... Коэффициент, который тоже является другим гиперпараметром, коэффициент ослабления или как? 

S04 [01:03:23] : Ну там скорее всего не коэффициент ослабления, просто у нас есть либо понижение клаус, либо ослабление клаус, то бишь это понижение их памяти. 

S00 [01:03:39] : А на сколько? Увеличена понижение? 

S04 [01:03:44] : На минус единицу. 

S00 [01:03:45] : На единичку. 

S04 [01:03:46] : Либо увеличение тоже на единичку. 

S00 [01:03:52] : А уровень он относительно чего? То есть у нас получается так, что со временем значения клауз вырастают до каких-то умопомрачительных размеров, но мы работаем все равно на некотором среднем уровне? 

S04 [01:04:09] : Нет. Есть определенная граница памяти, которая устанавливается разработчиком. 

S00 [01:04:18] : Но смотрите, там не получится так, что вот у нас, ну вот я приведу пример. Допустим разработчик заложил верхнюю границу 10, да? Вот и у нас вот Клауза 10 раз выстрелила, вот, хорошо, вот, и потом мы ее больше не увеличиваем, да? Вот, так сказать, вес этой Клаузы, а потом она, значит, хотя она могла бы дорасти до 100, да? Вот, и вот ее счет 100 раз она подкрепилась, а мы не увеличиваем. а потом вот 5 раз значит она не сработала из 10 вычли 5 и она оказалась на 5 хотя на самом деле если бы мы считали до 100 она бы все равно осталась достаточно высокой понимаете о чем я говорю 

S04 [01:05:05] : Проблема ограничения памяти в том, что чем больше памяти у этой машины, тем она крепче запоминает какой-то паттерн. Чем меньше память, собственно, она будет забывать быстрее. 

S00 [01:05:33] : Но у нас... Так, Виктор снова спрашивает. Виктор, пожалуйста. 

S02 [01:05:39] : А что такое память? Я все-таки не понимаю. То есть... И уровни. Это приоритет правил внутри каждого слоя или что? Вот вы говорили сейчас только об этом. 

S04 [01:05:49] : Память? Ну, смотрите. Вот у нас, соответственно, тут... Это можно представить как память размером... 5. 5 единиц. 

S02 [01:06:03] : То есть количество фактов или признаков, которые на вход могут поступать, да? 

S04 [01:06:09] : Нет, это не количество признаков, а собственно то, насколько признаки могут глубоко храниться в памяти. 

S00 [01:06:19] : А что значит глубоко храниться в памяти? Вот можно я вот здесь, мне кажется, важный момент могу ли я сказать? Я тоже не пойму это. Сейчас, секундочку, можно я гипотезу выскажу? Можно ли сказать, что вот это число, это сколько раз мы видели объект с удовлетворением вот этого клауза? Грубо говоря, что вот сейчас мы видим, что мы видели 4 кошки с хвостом, 3 кошки с мяукающих, 1 кошку лающую, 4 кошек с шерстью и 1 кошку белую. можно так сказать? 

S04 [01:06:56] : можно так сказать, но тут все-таки есть природа вероятности логики, поэтому это будет неправильно. 

S00 [01:07:02] : а как природа вероятности логики тогда работает? 

S04 [01:07:06] : ну вот в простой архитектуре машины t природа вероятности логики работает так, что мы запоминаем все входные паттерны и забываем где-то 50%, с вероятностью 50% паттернов, в которых у нас не было входных данных. 

S00 [01:07:31] : Ну а в reinforcement learning у нас же паттерны поступают постоянно на протяжении всей жизни. Откуда мы знаем, 50% или не 50? Вот нам сыплется под паттерн первый, второй, третий, четвертый, пятый, шестой, у них нету там 50% из 100. 

S04 [01:07:49] : Ну, рефорсмент, рефорс, вот тут вот машина, это задача классификации тут решается, тут не решается рефорсмент лернинг. В рефорсмент лернинг там чуть по-другому все устроено. Там нету такого забывания грубого. 

S00 [01:08:11] : То есть там, соответственно... А как устроена память вот в пинг-понге? Вот эта вот картинка там не применима? 

S04 [01:08:22] : Нет, там устроена память также, но вероятность обновления там устроена чуть по-другому. Собственно, там опять же выбирается параметр глубины памяти, то бишь насколько агент будет, либо насколько он будет запоминать долго, хранить какие-то знания долго, либо насколько он быстро будет забывать. Вот. То есть чем меньше память, тем, соответственно, агент быстрее забывает. Чем больше память, тем агент дольше хранит знания. 

S00 [01:09:07] : А как это определяется? Чем определяется эта глубина физически? То есть это массив какой-то? Это какой-то стек состояний или что? 

S04 [01:09:19] : Нет. Физически это просто переменная, которая задает ограничения. 

S00 [01:09:26] : Ограничения на что? 

S04 [01:09:29] : ограничения на количество состояний. 

S00 [01:09:35] : В пинг-понге вы храните в памяти все состояния? Да. И длина вот этого стека состояния определяет емкость памяти? Да. И вы, получается, при принятии решения все равно сканируете все эти состояния в поиске подходящего, правильно? Ну понятно. Ну понятно, да. Но здесь сразу в полный рост возникает проблема выселительной эффективности. То есть понятно, что она у вас бинарная. И считать проще. Но окей. Коллеги, есть еще вопросы? Если вопросов нету, то я предлагаю на сегодня нам завершиться. Николай, спасибо вам большое за доклад. Было интересно. Желаю вам успехов в борьбе с пинг-понгом, а также с естественным языком и более сложными вещами. Особенно про рассуждающие системы. Давайте последний вопрос, который я забыл спросить. Про рассуждающие системы. Про рассуждающие системы вы имеете в виду работу с естественным языком или вы под рассуждающими системами что-то другое имеете в виду? 

S04 [01:10:59] : Под рассуждающими системами я имею в виду системы, которые могут хранить в себе То есть вот эта вот многослойная система по сути это рассуждающая система. То есть эта система может делать абстракции из более низших абстракций. Она может делать более высшие абстракции. То есть из низших фактов она делает более высокие факты. То есть допустим у нас тут хренится опять же факт допустим собака и кот, а более высокая абстракция будет то, что это животные. Вот я подразумеваю этот процесс. 

S00 [01:11:52] : Но это рассуждение будет, то есть это все-таки будет не на уровне естественного языка, как рассуждают большие языковые модели, а рассуждение именно на уровне логики, правильно? Да. То есть под рассуждением вы здесь имеете в виду некоторый внутренний невербализованный процесс, который будет позволять делать что? То есть какова тогда задача машинорассуждения? То есть какие сценарии, какие задачи решает вот эта вот машинорассуждающая система? 

S04 [01:12:21] : Задача тут рассуждения в том, чтобы переобразовывать, собственно, факты более высоких уровней, точнее, факты более низких уровней, факты более высоких уровней. 

S00 [01:12:39] : Ну и если я правильно понимаю, это и будет ответом на вопрос Виктора, как разделить синтологии от правил, то есть мы, грубо говоря, анализируя некоторые сырые объекты, сырые структуры сырые паттерны, которые предъявляются нам как объекты некоторых онтологий, проявляющиеся во временной последовательности, и преобразовывать их в некоторые правила, которые описывают законы физического мира. Как-то так, да, можно предположить? 

S04 [01:13:12] : Да, в принципе, это верно. 

S00 [01:13:16] : Хорошо, вот еще регистратор спрашивает, может ли система сама генерировать правила логического вывода, как? Ну это я так понимаю, что вот когда будет рассуждающая система, будет сделана, тогда она сможет генерировать правила логического вывода, правильно? Да. Хорошо. Николай, большое спасибо. Спасибо всем участникам. Кто не является членом сообщества, приглашаю присоединяться в AGI Russia. канал и группы AGI Russia на сайте agirussia.org, там все ресурсы есть и в группе в Telegram можно найти контакты всех участников. Все, всем спасибо, до свидания и до новых встреч. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html

