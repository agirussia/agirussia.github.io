## 26 сентября 2025 - RSE with AI or RSE vs AI: ИИ для исследовательской программной инженерии? - Алексей Незнанов
[![Watch the video](https://img.youtube.com/vi/p8eqDYYSCRU/hqdefault.jpg)](https://www.youtube.com/watch?v=p8eqDYYSCRU)

**Краткое содержание**:

### Искусственный интеллект и программная инженерия: взаимное обогащение и будущее сотрудничества

Алексей Незнанов представил доклад о взаимосвязи между искусственным интеллектом (ИИ) и исследовательской программной инженерией (Research Software Engineering, RSE). Он осветил три ключевых аспекта: что такое RSE, как ИИ может способствовать развитию программной инженерии, и какой вклад программная инженерия вносит в развитие ИИ.

**Исследовательская программная инженерия (RSE): история и ключевые принципы**

Исследовательская программная инженерия, история которой насчитывает около 60 лет, окончательно оформилась в 2017 году. Толчком к её развитию послужил семинар 2012 года, где были заложены её основы. Ключевой идеей RSE является применение инженерных подходов к разработке исследовательского программного обеспечения, что обеспечивает его надёжность и воспроизводимость.

Один из фундаментальных принципов RSE — **воспроизводимость (reproducibility)**. Этот принцип включает в себя семь аспектов, обозначаемых как "7R":
*   **Reusable** (переиспользование)
*   **Repurposable** (переиспользование для другой цели)
*   **Repeatable** (повторяемость)
*   **Reproducible** (воспроизводимость)
*   **Replayable** (воспроизводимость с возможностью просмотра предыдущих вычислений)
*   **Referenceable** (возможность сослаться на предыдущие результаты)
*   **Respectful** (уважительное отношение к результатам)

Кроме того, важными составляющими являются **интерпретируемость (interpretability)** и **объяснимость (explainability)**, особенно в контексте ИИ. Для обеспечения воспроизводимости используются специализированные инструменты и методологии, такие как FAIR4RS (Findable, Accessible, Interoperable, Reusable for Research Software) и цитирование данных и кода.

**Влияние искусственного интеллекта на программную инженерию**

Современное развитие ИИ, особенно больших языковых моделей (LLM), оказывает значительное влияние на программную инженерию. ИИ-инструменты способны автоматизировать множество задач, от написания кода до его тестирования и документирования. Это особенно заметно в области "программирования в малом" (programming in the small), где ИИ уже может успешно решать алгоритмические задачи на уровне лучших программистов, что было продемонстрировано на соревнованиях ICPC.

Однако в "программировании в большом" (programming in the large) и "программировании многими" (programming in the many), где важны архитектура, управление гетерогенными ресурсами и коллаборация, возможности современных ИИ-систем пока ограничены. Тем не менее, ИИ уже активно используется в коллаборативных платформах для улучшения взаимодействия в больших командах.

**Роль программной инженерии в развитии искусственного интеллекта**

С другой стороны, принципы RSE критически важны для создания надёжных и воспроизводимых ИИ-систем. Разработка сложных моделей ИИ, таких как AlphaFold, стала возможной благодаря применению строгих инженерных практик.

Особое внимание в докладе было уделено **проблеме двух языков**, когда для прототипирования используется один язык (например, Python), а для высокопроизводительных вычислений — другой (например, C++ или Rust). Современные языки программирования, такие как Julia, и экосистемы, как Marimo для Python, стремятся решить эту проблему, обеспечивая интерактивность, реактивность и воспроизводимость в единой среде.

**Будущее взаимодействия**

Будущее сотрудничества ИИ и программной инженерии видится в создании гибридных систем, объединяющих сильные стороны обоих подходов. Это включает интеграцию явных знаний (онтологий) с генеративными моделями для повышения их точности и снижения "галлюцинаций". Примером такого подхода является интеграция Wolfram|Alpha с ChatGPT.

Также ожидается дальнейшее развитие инструментов для **литературного программирования**, где код, данные и текст объединены в едином интерактивном документе, что способствует воспроизводимости и коллаборативной работе. Платформы, такие как Hugging Face, эволюционируют в сторону комплексных экосистем для совместной работы, включая бенчмаркинг и публикацию научных артефактов в виде интерактивных ноутбуков.

В заключение, Алексей Незнанов подчеркнул, что отказ от "вайт-кодинга" (слепого следования указаниям ИИ) и переход к осознанному использованию "ИИ для RSE" (AI for RSE) станет ключевым фактором для дальнейшего прогресса как в области программной инженерии, так и в области искусственного интеллекта.

**Расшифровка доклада:**


S00 [00:00:00] : Коллеги всем добрый вечер у нас снова происходит очередное заседание русскоязычного сообщества разработчиков общего и сильного искусственного интеллекта и сегодня на гостях алексей незнанов и он расскажет нам что искусственный интеллект может дать до для программной инженерии а что программная инженерия может дать для искусственного интеллекта вот ну или может быть он поправит если Название и содержание сегодняшней темы будет отличаться от того, как я его воспринял. Алексей, пожалуйста. 

S02 [00:00:30] : Добрый вечер, коллеги. Да, именно так. Более того, мы как раз сделаем аж три разных акцента. Почему? Потому что мы говорим не в целом о программной инженерии, делаем акцент на исследовательской программной инженерии и поэтому мы немножко расскажем в целом о том что это такое а дальше с каждым кусочком раскрытия тематики по именно программной инженерии мы будем к ней или к этому кусочку до пристыковать кусочек по текущему развитию искусственного интеллекта что интересно нам придется да с вами пройти через очень разные вещи потому что исследовательская программа инженерия, она с одной стороны про исследования, а с другой стороны про инженерию. Ну и понеслось. Значит, у нас на самом деле есть несколько базовых акцентов, которые мы обычно делали. Сейчас мы на них останавливаться серьезно не будем. Они будут раскрыться в процессе. Но важно, что это еще раз подчеркивает междисциплинарность. И вначале здесь у меня, видите, есть Scientific Epistemology and Entology. То есть мы в любом случае говорим о нормальном научном подходе. И эпистемологические экзорцизы нам придется сделать, но чуть-чуть. При этом, с точки зрения того, что такое исследовательская программная инженерия, которая как раз очень нужна нам всем, и последние, например, дискуссии в чате, да, они показали, что хорошо бы, чтобы все были в этой области хотя бы чуть-чуть подкованы, потому что с точки зрения реализации того же самого искусственного интеллекта, да, это главное, что нужно из исследовательской программной инженерии, собственно, знать, да. Мы говорим, что ее история насчитывает примерно 60 лет, но на самом деле оформилась она с очень интересными дополнительными приключениями. В 2017 году британцы с коллегами некоторыми написали очень интересную статью. Нешен, естественно, британский. Что интересно, там они подчеркнули несколько важнейших вещей, в том числе как раз сказали, к чему сейчас пришла история, как раз кончающаяся там в 17-м годом, то есть прошло уже почти 8 лет. И главное, что без исследовательской программы инженерии нам не жить. В том смысле, что дальше заниматься исследованиями, с одной стороны, без программной инженерии нормально нельзя, а с другой стороны, что программной инженерией без соответствующих исследований заниматься нельзя. Что здесь интересно, историю рассчитываю с 2012 года. Почему? Потому что тогда собрался очень важный семинар, на котором, как мы сейчас примерно, люди обсудили базовые вещи и предыдущую историю. Поэтому дальше мы как раз будем следовать с одной стороны результатам этого семинара, с другой стороны отойдем в прошлое, где-то до 70-х годов прошлого века, естественно, а с третьей мы как раз сошлемся на свеженькие, по сути, постулаты, которые специалисты в этой области поделились с нами в прошлом и в этом году. Но в этом году мы сошлемся в самом конце. Итак, Товарищ Рампи, да, в прошлом году у нас сделал очень интересный whitepaper и соответствующее выступление конференции, где он указал, что на самом деле у нас есть набор тезисов, дальше набор как раз условий, набор рекомендаций. Рекомендации в этом смысле наиболее интересны, потому что они как раз четко стыкуются с тем, что происходит при каждодневных обсуждениях. Как раз. Домайн-специфик тулинг. Ну, естественно, без домайн-специфик нечего делать. Wizard-like smart tools. Да, мы хотели бы, чтобы были кнопки, которые проводили нас по какому-то сценарию для того, чтобы мы сделали что-то полезное. Да, скиллы нам нужны. Да, сами software-инженеры нужны, которые знают research software engineering. И, соответственно, нужны теперь исследователи этой подобности. Ну, и так далее, и так далее. Что интересно, если мы посмотрим, а что до этого народ пытался сделать с точки зрения именно не формализации области, а понимания и рефлексии над этим, то в 2022 году вышла замечательнейшая просто статья Research Software Science, Expanding the Impact of Research Software Engineering, где говорится, что инжинирингом сыт не будешь, нам нужна наука. Ну и, соответственно, я здесь привел очень красивые картинки, которые говорят о том, где, собственно, там наука. Она, с одной стороны, в исследовании самой софты инжиниринга, своего самого, если он инжиниринг, и, с другой стороны, это как раз появление с точки зрения того, как мы правильно делаем программные продукты, собственно, дополнительной науки. Ну и как раз понеслось. Коллеги, недавно выступая, сказали тут, что надо смотреть в будущее. И, например, есть очень хороший прогноз до 2030 года. Ну и прогноз очень веселый с учетом того, сколько процентов людей организации должны заниматься РСЕ в отличие или в дополнение к обычному СЕ. В этом смысле дальше мы как раз поговорим в том числе об организациях и зачем они участвуют в развитии искусственного интеллекта. Понятно, что сами эти организации достаточно известны с одной стороны, с другой стороны не на слуху, потому что вообще исследователей не так много, а исследователей, которые одновременно что-то хорошее пишут лапками, еще меньше. Но, тем не менее, у нас есть международные ассоциации, есть национальные ассоциации, и причем они потихоньку объединяются. Что еще интересно, у нас есть некоторые уже базовые туториалы, которые обобщают некий опыт за прошедшие десятилетия, в том числе есть полностью открытые. В этом смысле, если вас кто-то спросит, а какой источник порекомендовать как первый-единственный, то на GitHub лежит замечательный гайд Open Source Ecosystem for Research and Engineering. Он чуть-чуть устарел, но зато замечательен в плане охвата. Что важно? Мы говорим, что с точки зрения именно открытости материалов RSE очень хороша. Почему? Потому что с одной стороны требует, чтобы была наука, а соответственно нужны открытые научные результаты. И Open Science они очень хорошо поддерживают. А с другой стороны, они в Paradigm работают воспроизводимости, о чем дальше. И соответственно нам нужны открытые программные коды, которые становятся научными артефактами. Понятно, что здесь я привел просто несколько самых популярных вещей, связанных с лицензированием открытых разработок. С одной стороны кода, с другой стороны других артефактов. Я сослался на Creative Commons. Что еще интересно, когда мы говорим о том, кто такие ресурс-энженеры в больших командах, например, в правом энтерпрайзе, то оказывается, что это как раз проработано наиболее круто и даже вошло во многие стандарты. И мы говорим, что да, в любой современной команде, которая работает над серьезными проектами, есть выделенный отдел, и причем это теперь как раз ресерч-отдел, который занимается не столько общим ресерчем, сколько ресерчем в социальной инженеринге, а он примыкает к общересерческому отделу. И дальше как раз мы говорим, что все великие вендоры, они про это хорошо пишут. Погружаться туда не будем, поскольку они про это пишут как бы вне искусственного интеллекта, как нам сейчас интересно. При этом, что интересно еще более, очень многие увязывают развитие РСЕ со сменой парадигмы на дата-центрическую. Почему? Потому что когда мы начинали писать простенькие алгоритмы в где-то там 40-х годах еще прошлого века, тогда мы на данные обращали внимание настолько, насколько был объем данных в каких-то массивах и списках интересен нам. А теперь, особенно как мы дальше узнаем с искусственным интеллектом, у нас уже автоматизация, автоматизация, автоматизация, которая работает адаптивно на объемах данных больших. Отсюда требования, в первую очередь, реагировать на артефакты данных, качество данных, смотрим восьмитысячные стандарты, на соответственно SQUARE и все остальное. Это огромная отдельная область, здесь я привел только что, что непосредственно касается развития именно методологии ресурсо-инженеринга. Во-первых, это Fair4S. то есть специальный вариант использования методологии FAIR, Findable, Accessible, Interoperable, Reusable, кстати, везде полезно, для именно Research and Engineering. И дальше, конечно же, про цитаты данных, то есть цитирование данных. Дальше мы еще обратимся к цитированию кода. Что важно отметить, что как только мы получили FAIR-FRS, то мы получили нормальный формализованный профайл того, на какие вопросы надо ответить и как потом в чек-лист их загнать, чтобы проверить соответствие и уровень готовности Readiness Level. Вот Антон в свое время инициировал дискуссию по тому, как определить, а что можно сделать лапками, если кто-то что-то говорит про некую реализацию искусственного интеллекта, да, и имплементейшн. И в результате здесь очень красивый список вопросов, причем к каждому есть куча подвопросов. Здесь все кликабельное, потом даунда, и можно кликнуть, посмотреть, как это у них описывается на сайте. Это вообще жутко полезная вещь в целом. Если говорить о современном этапе развития, то где-то порядка 10 лет назад, а может чуть больше, мы начали обсуждать, как Data Science в целом, который тогда уже формализовался, связан с RSI. Оказалось, что напрямую, потому что RSI не может существовать вообще никак. И как раз в 2009 году появилась очень хорошая идея сделать как раз что? Некую четвертую парадигму. То есть мы говорим, что у нас есть теперь не просто науки о данных, а Data Intensive, то есть очень-очень мощные по данным науки о данных. И мы говорим дальше, а что делать с этими данными с точки зрения Discovery. Ну и коллеги, включая коллег из Microsoft, они сделали как раз несколько очень интересных, так сказать, главных подпорочек этого дела. туда не будем сейчас углубляться, но именно с этого момента у нас очень интересно пошло в том числе видение того, как данные для обучения искусственных нейронных сетей начинают играть с точки зрения их качества, их как раз возможности переиспользования и так далее. Почему? Потому что теперь это все развивается в рамках Data Science, в который RSE включился как составная часть. При этом, что интересно, если смотреть на как раз упомянутые мной же стандарты, которые еще не рассказал, то есть, например, несколько работ, которые четко говорят о том, как именно в индустрии устроено не просто RSE, а RSE, которая увязывает все возможные варианты создания программных продуктов организации, и как раз там выделяются шесть базовых областей именно функциональности, которые увязываются через создание сообщества RSE. И понятно, что есть практика, обучение, инфраструктура, карьерные всевозможные пути или траектории, как раз то, как мы описываем преимущество RSE, и, наконец, исследование области RSE как такового. Ну и понятно, что с этой позиции, если рассматривать, то у нас уже, у меня в обзоре было где-то там больше ста публикаций, буквально за последние всего пять лет. Ну и, наконец, примеры. Да, почти у каждого вендора, опять-таки, есть очень крутая какая-то исследовательская группа по этой области. Просто в качестве примера я многие стер. Да, это, например, макрософтский Rise, да, Research and Software Engineering, который очень много всего публикует, блог большой и так далее. Ну и наконец, чем мы пользуемся для того, чтобы делать что-то интересное в RSI? Понятно, что у нас на самом деле есть специальные языки. Но специальные языки развивались очень серьезно. С одной стороны, где-то в 80-х годах прошлого века, потом был второй всплеск, начал 2000-х, и сейчас все совсем по-другому. Можно считать, что некий третий всплеск. Почему? В первую очередь это связано с тем, что в рамках Data Science как такового у нас выиграл один из языков. Вот он тут приведен. При этом приведена и минимальная версия, с которой имеет смысл работать, с точки зрения особенно, как раз того, что современный Python это во многом Rust. Вообще лучшее, что случилось с Python за последнее время, это Rust. Ну и, наконец, дальше мы говорим, что многие экосистемы, которые специально развивались в контексте RSI, в первую очередь это как раз надежные воспроизводимые системы, как сам Rust, как R, С точки зрения работы над статистическими данными Инакайджулия, которые еще будут несколько упоминаний очень интересных с точки зрения решения проблемы двух языков, мы к ней перейдем. Конечно же, очень интересно состыковались с результатами, которые были достигнуты людьми непосредственно либо из Академии, которые, например, делали рэкет, из индустрии с точки зрения, в первую очередь, анимационного моделирования, MATLAB тот самый, его все вокруг, в том числе бесплатные, типа Octave и так далее. И, наконец, теми, кто занимался специальными видами явного знания, как, например, вольфрамовцы со своим вольфрам-блендвич, которому не стали давать специальное название. Что интересно, это имеет много отдельных изначальных корней, То есть, что интересно, здесь корней много, а ствол один. А иногда бывает наоборот, корень один, а стволов много. И как раз мне очень нравится, например, обзор многих языков и последующие обсуждения их рейтинга, которые говорят, а давайте мы не просто все языки программирования обсудим, а те, которые продуктивные, хорошо спроектированы и вообще клевенькие. И вот как раз можно посмотреть, какие самые интересные. Что еще важно? Как только мы все это начали серьезно делать, уже как раз в конце 2010-х годов, то оказалось, что на это начал накладываться, как супердрайвер, вариант развития искусственного интеллекта как источника неких инструментов для программной инженерии. Ну и как раз в этом году вышла шикарнейшая просто статья очень крутых товарищей, причем из очень разных организаций, которая называется Challenges and Paths Towards AI for Software Engineering. И в нем приведена шикарнейшая картинка. С одной стороны, да, у нас есть то, с чем мы сталкиваемся, с другой стороны, то, как AI на это отвечает. Ну и, например, да, понимание данных и кодового база. Да, Data Curation. Ура, ура. Да, значит, бенчмарки и как раз оценивание, да, Human-Centric Data Curation. Ну, логично, да, сейчас без человека никуда. И так далее. И, в принципе, здесь перечислены почти все области, которые реально воздействуют с одной стороны на SE как таковой, а с другой стороны драйвятся именно искусственным интеллектом. В этом смысле, что интересно, они это все последовательно описывают. Здесь, видите, есть номера разделов. Поэтому очень рекомендую потом именно в эту статью зайти и посмотреть, как четко увязываются инструменты, которые дает текущий искусственный интеллект, с именно методологией SE в целом и RSE в частности. Мы к этому чуть-чуть попозже вернемся. Почему? Надо понять, а что это, что здесь обозначает. Поэтому. мы акцентируемся на том, что составляет корень всех, с одной стороны, проблем, а с другой стороны, что приносит наибольшую пользу от хотя бы наивного внедрения RSI. Это воспроизводимость, reproducibility. Что интересно, с точки зрения reproducibility у нас, на самом деле, внутри очень много разных R. В этом смысле, да, у меня сначала было, когда я в свое время общался на эту тему с коллегами, два R, Там была повторяемость, да? Потом было 3R, потом 4R, потом, наконец, 5R. Это была очень известная статья, сейчас приведу. И, наконец, дошли до 7R. То есть reusable — переиспользование просто так, repurposable — переиспользование для другой цели, repeatable — повторяемость, reproducible — воспроизводимость, replayable — воспроизводимость с точки зрения просмотра того, что считалось раньше. referenceable, да, возможность сослаться на предыдущие результаты, которые уже посчитаны, и наконец, respectful. Это очень тяжело однозначно перевести на русский, но вообще говоря, да, это значит, что мы должны относиться к этому с уважением, да. Помните, ты подошел ко мне, но сделал это без уважения. Что еще интересно, да, к этим именно R, которые четко указывают на некие свойства продукта, И, кстати, напомню, мы когда делаем искусственный интеллект, он у нас в любом случае сейчас программный продукт, ну или программно-аппаратный комплекс, и в результате все эти R играют. Наконец, некоторые из них в качестве четырех R по-другому сфокусированы на как раз все записывай, все автоматизируй, все сохраняй и все предоставляй или экспонируй. И, наконец, отдельно выписано, что как раз журналирование, аудит и бенчмаркинг. На самом деле, без чего-то этого говорить, в принципе, о reproducibility тяжело. Но еще сейчас, именно с точки зрения искусственного интеллекта, особую роль играет что? Interpretability и explainability, то есть интерпретируемость и объяснимость. Мы уже неоднократно ломали копию по этому делу. Я вообще очень уважаю именно объяснение искусственного интеллекта. и поэтому поставил это на первое место. Быстренько прокручиваемся. Значит, первое, да, семинар, который был посвящен именно Reproducibility. Он ссылается как раз на тот самый семинар по RSE 2012 года. Он как раз еще на старом стеке, мы от него потом уйдем. Он про классику жанра, да, про Гиты, Питера и так далее. Сейчас уже все изменилось, да, 10 лет все-таки почти прошло. Но там были заложены основы. Поэтому до сих пор многие именно его первым цитируют с точки зрения этой области. Дальше. 5R. Знаменитая статья 2018 года. RERUN, REPEAT, REPRODUCE, REUSE, REPLICATE. Причем статья в нейроинформатике. Как раз как интересно все увязано. Там был очень интересный пример маленького кода на питоне. Жалко, что он именно программинтинзисмол, как мы дальше поймем. Но уже в начале обычный человек напишет что-то вот такое, что слева, потом он его преобразует, преобразует, преобразует, чтобы выполнили цепиотер, и получается что-то очень красивое, но, к сожалению, с неким налетом привнесенной сложности, которая с точки зрения РСИ не считается привнесенной, она считается имманентной. То есть если вспомнить семифически человека месяц, то это имманентная сложность процессов как раз воспроизводимости. И от нее уже идут привнесенные сложности с точки зрения инструментов программной инженерии. В том числе это сейчас очень сильно играет, когда мы пытаемся воспроизвести какой-то эксперимент с точки зрения искусственного интеллекта. Почему? Потому что даже пришлось с точки зрения операций, которые мы там делаем, сделать отдельную область MLOps, кроме DevOps, DataOps и всего остального. Далее знаменитый манифест код EaseScience. Что важно? Science-то понятно в целом, а что является артефактами этой науки? Ну, код, собственно, и является артефактом, но тогда возникает вопрос, а как его оформлять? Мы уже с вами до этого упоминали, например, цитирование данных и артефакты данных, а теперь нам надо, чтобы код вел себя примерно так же. Понятно, что как раз мы имеем несколько стандартных чек-листов на эту тему. Более того, в любых областях, где нужна была сертификация, например, клинической информатики, это все есть где-то примерно с 2008-2011 годов, когда принимались основные стандарты в этой области. И вот в 2013 году, как некое подведение итогов, у нас появилось 10 Simple Rules for Reproducible Computational Research. Публиковано в PLOS Computational Biology, как одном из плосовских журналов. Отмечу, что PLOS — это один из вообще главных журналов в медицине и смежных областях. И здесь очень четкие классические рекомендации в виде чеп-листа с очень хорошим раскрытием и примерами. Обращаюсь к источнику. Что интересно, здесь все классическое для просто воспроизводимости кончается Provide Public Access to Script Transient Results. Тоже открытость. Ну и как раз дальше. Очень много есть людей, которые подобные чек-листы, базовые принципы и свойства, то есть те самые 5 R6, R7 R8 и так далее, обсуждают, выводят некие следствия и делают современные обзоры. из последних, 2025 года, я еще не видел, есть 2024, то есть Overview of Reproducible Research with a Focus on High-Performance Computing. Шикарнейший обзор, именно когда нам нужны мощные вычисления каких-то суперкомпьютеров, это абсолютно однозначно переносится на современные, например, обучение ллм-ок. Да, сотни миллионов долларов, да, суперкомпьютеры, все дела. При этом Именно с точки зрения последующего оформления, да, нам один из R не сильно нужен с точки зрения базового реюза, нам нужно как артефакт это представить. И в 23-м году вышла статья, которая теперь становится той, на которую все ссылаются. Repetibility, Replicability, извиняюсь, Repetibility, Replicability, Reusability, да, как раз в Journal Policy, Science Software, да, это Management Scientific Publications. Тоже хороший очень обзор. И в итоге, что можно сказать? Народ пишет, сотни уже пишут, обзоры есть, но очень мало кто этого знает. Более того, сейчас очень большая нужда в соответствующих RSE, в смысле, инженерах, в мультидисциплинарных командах, занимающихся искусственным интеллектом. Собственно, после обсуждения в июне этого вопроса у Антона и возникла идея это все к этому привязать. Что еще важно, у нас за период где-то с 2015 по 2020 год сложилась некая система идентификации того, какие свойства все-таки выполнены у артефактов уже теперь кода. И как раз в 2020 году у нас появилась уже версия 1.1 осиемовских бейджиков, который выглядит вот так. Никто не встречал, я уже достаточно часто встречаю в области, И здесь, видите какая прелесть, что артефакты оценены и соответствуют неким базовым уровням. Они функциональны и переиспользуемы. Ура, красненькие. Дальше. Эти артефакты доступны, но понятно, что с какой-то лицензией, но доступны. Ура, зелененькие. И, наконец, они валидированы с точки зрения как раз воспроизводимости как таковой и репликации с точки зрения именно воспроизведения научных результатов. Синенькие. Вот так бы сейчас, если бы помечались соответствующие варианты яй, было бы все намного проще. Ну и дальше, как раз, ой, вот сюда то, что хотел, главное забыл сделать. Да, у нас PayPay VS Code переехал на Hugging Face. Наверняка все уже это отследили, да? И у Hugging Face теперь зато вместе с просто ссылками на GitHub появляется нормальный битчмаркинг. Посмотрим. Они обещают в октябре выкатить уже нормальную версию этого дела. Мне очень интересно. 1000 Research, да, он как был, так и остается. Более того, у него крутые планы на развитие. Именно от них я очень нежно люблю Tidur. Tidur — шикарнейшая вещь. Citation, Dissemination, Use, Research — как раз И дальше мы говорим, что все это вместе позволяет как раз собрать некоторое пространство, в котором можно оценивать эти артефакты. Собственно, они так и оценивают, и поэтому у них очень крутой репозиторий. Дальше, откуда взялись CMR? Мы говорим, что если мы получаем объекты, и они становятся как раз в данном случае зелененькими по CM, какими они должны быть, чтобы дальше можно было на следующий уровень выйти. И вот чтобы как раз у нас Replication появился с точки зрения ученых, и чтобы появилась возможность использовать Research Objects, нам нужно как раз в CCMR. И как раз вплоть до Respectful. Почему? Потому что мы, как правило, не произведем огромную цепочку преобразования артефактов, которые начались Аристотелем, извиняюсь за выражение, и закончились в 2025 году. Мы, скорее всего, каким-то из промежуточных артефактов будем верить. Ну и самое веселое, что Research Objects полностью основаны на Linking Data идеях, и, соответственно, тут у нас есть антология. Более того, она вполне себе используется. При этом отмечу, что сама статья 60-го года, но потом в 20-м году и в 23-м году были прям к ней серьезные дополнения с точки зрения того, как Research Object реализовывает современных степеней. Ну и наконец, да, цитирование данных просто как повторение. И как раз как они сейчас выглядят. И цитирование кода. Дело в том, что сейчас, да, мы уже живем в мире, в котором есть соответствующие стандарты библиотеки, включая CFF на как раз метаданные для цитирования кода. Отмечу, что серьезные все GitHub-пропозитории, да, CFF-файлики имеют. Ну и плюс как раз есть для всех языков, которые более-менее используются в RSI, в том числе, естественно, для Python, библиотека, которая умеет все это генерить, лазить по вашему коду оттуда, выбирать описание и так далее, и так далее. Что важно? Если мы посмотрим на примеры попыток воспроизведения, то есть проверки reproducibility, то мне, например, очень понравилось в предыдущем году, коллег, которые взяли знаменитую статью Лекуна 89 года, Лекуна, наверное, все знают, и попробовали воспроизвести. В общем-то, двумя серьезными вопросами воспроизвели, но вопросы серьезные, именно с точки зрения лего-инструментов. Это вообще очень больная проблема, и дальше мы о ней поговорим. Что еще очень важно, мы говорим, значит, что Карпатый, когда в свое время это делал, Он очень четко это увязал со своими же исследованиями по минималистичным реализациям, качество которых легко доказать, и в том числе со своей реализацией очень простой LLM на языке C, может кто видел. Ну и как раз что важно, как только мы теперь смотрим, как к этому сейчас относятся коллеги, которые сразу начинают использовать LLM, даже не переходя к проблеме двуязычности, мы можем что наблюдать? Что у нас с одной стороны очень серьезные усилия снова идут в явное знание. Вспоминаем доклад Зимний про как раз то, как в интерпрайзе работают онтологии. Дальше мы говорим, что у нас появляются специализированные AI-инструменты по как раз областям, доменам, которые решают конкретные задачи. И там с воспроизводимостью относительно хорошо. Почему? Они относительно узкие, и на эти вопросы тратятся очень большие деньги. Тоже сотни миллионов долларов. Почему? Потому что иначе никто просто из серьезных людей не воспользуется этим результатом. и, соответственно, не продолжит как раз нормальную уже промышленную разработку решений. Я здесь не зря привел альфа-фолт. Почему? Потому что наверняка все вспомнят, что случилось в прошлом году на какой премии. Антон, наверное, знает. Нобелевская имеется в виду? Да, замечательно. Поэтому это сейчас очень хороший пример именно потому, что даже Нобелевский комитет сказал, что да, это настоящее исследование. Ура, ура. При этом, что важно, я здесь по-английски сформулировал, да, white-coding is anti-7r warfare, то есть на самом деле white-coding в том смысле, в котором его многие понимают, это просто разрушительная вещь для как минимум воспроизводимости, как максимум, в принципе, для РСИК. Но дальше мы увидим, что нормальные люди, которые говорят, что вайкодинг – это не наше все, а есть другие способы AI-кодинга, нормально вполне это сочетают. В первую очередь здесь стоит отметить усилия команды от Сакана, наверняка тоже слышали такую, да? Которые в том числе сделали первую официальную публикацию, которая официально признана публикацией инструментов искусственного интеллекта. Но правда она курировалась людьми, то есть она human-curated. Ну и самое интересное, что недавно от коллег вышла очень крутая вещь с точки зрения обзора тех инструментов, которые саккановцы использовали. То есть вылейтин, сакканос и айсантис. Шикарно, да? Вот, сейчас они следующую, кстати, пишут, потому что это весенняя. Ну и теперь как раз я несколько раз упоминал проблему двуязычности. Она на самом деле сложнее, чем просто маленький язык, большой язык. И давайте по ней пройдемся. Она тоже нас сведет к некоторому выводу об искусственном интеллекте относительно РСИ. Напоминаю, что в 1976 году у нас вышла замечательная статья, коротенькая очень. «Programment in the large vs. Programment in the small». Ура! Мы оттуда узнали, что, оказывается, есть совершенно два разных уровня понимания того, что такое программирование. Снизу это алгоритмизация каких-то структур данных, а сверху это архитектура сколь угодно больших программных продуктов, которые входят в то, что сначала мы сказали, как компоненты, совсем обычно маленькие. Дальше что понеслось? Понеслось очень интересное обсуждение этого программного интересного, которое, в принципе, закончилось через 10 лет статьей Programming in the Lodge. И там как раз подвели итоги десятилетнего развития. Дальше что интересно? Народ сказал, ну, мы-то уже в 90-х годах начали большими, большими командами разрабатывать программные продукты. Какая сейчас команда разрабатывает OpenAI? ChatGPT, по количеству народа, кто знает. Можно пока пытаться угадать. И дальше, в 1993 году, была статья, где противоставляли программинг Latch и программинг Queen's Menu. То есть, когда мы программный продукт не только большой делаем, но еще и огромными командами. Огромная команда — это много-много ролей. Соответственно, какие могут быть дополнительные проблемы, кроме того, что просто большой программный продукт? Это то, что нужно разделять с точки зрения управления персоналом метод и безопасность, очень важно. А дальше, с точки зрения ресурсов, у нас ресурсы получаются очень гетерогенными, то есть разнородными и распределенными. Отсюда, кстати, будет вывод про коллаборативные инструменты чуть дальше. Ну и наконец, дальше мы что видим? Что у нас появляются всевозможные специальные архитектуры, специальные их описания, специальные языки именно для программ NLH и NLMN. И в конце Рот сказал, а давайте вообще использовать доказательное программирование. Аналогично доказательному медицине, доказательному чему угодно. То есть это связь полноценной науки replicability с EvidentBase 7. Что важно, что в 2004 году была замечательная статья EvidentBase Software Engineering. Дальше она очень интересно обсуждалась на двух последующих конференциях Software Engineering в 2006 году. Но самое-то веселое, что к ней возвращаются сейчас постоянно. Я сейчас ссылаюсь на 2014 год в программе Language Wars о том, какие языки как бы больше для программирования в малом, какие для программирования в большом, какие для программирования большими толпами народу и так далее. И потом как раз все это в том числе привело к появлению языка Джулия. И что важно, Мы говорим, что у нас появляются дополнительные контексты, когда мы теперь это пытаемся переиспользовать. Давайте так скажем, очень по-простому. И кроме малого, большого и гигантского, который пришлось ввести, чтобы определить следующий уровень, который уже относится не к архитектуре отдельных программных продуктов, а к архитектуре каких-то распределенных, как сейчас часто говорят, киберфизических систем. И к этому всему добавляется сложное окружение. Причем это окружение тоже гетерогенное, с кучей ролей и всего остального. Отмечу, что сейчас это развивается исключительно с точки зрения инструментов в системной инженерии. Ну и наконец, к чему все это пришло? С точки зрения программирования в малом это пришло к тому, что можно и, в общем-то, нужно заменять программиста, который делает конкретный алгоритм с четко определенными небольшими условиями и как раз каким-то небольшим входом, импутом и, например, там, задачей распознавания свойств, чем искусственным интеллектом, причем даже современными ЛЛМ-ками. Почему? Потому что, если посмотреть на последнее CPC, которое недавно тут прошел, то OpenAI, ну и, кстати, это подтверждено оргкомитетом ICPC, выполнила все 12 проблем. Правда, не очень понятно, какой именно моделью. А Google, который вполне себе обычный Gemini DeepThink как раз использовал, выполнил 10 проблем. Отмечу, что золотые финалисты реально начинали с 10 проблем. Более того, да, самая крутая команда отмощников наших сделала только 11 проблем. То есть, программирование в малом, с точки зрения РСИ, уже не столь интересно. Почему? Потому что можно, с точки зрения формализации и соблюдения всех пяти семьер, сделать современный искусственный интеллект, который в этом смысле заменяет человека. Это дальше можно обсуждать, но факт налицо. Но в чем вопрос? Как раз в программе In The Many, Large, Huge, Отсюда. Важная вещь это то, что современное программирование, оно все платформоориентировано. Сюда мы специально не будем углубляться, просто скажем, что без платформ нам не жить. И более того, у нас платформы даже инфраструктурные, просто неимоверные по размерам. Платформы развертывания разнообразные и тоже огромные. И в этом смысле конкретное приложение, это на самом деле маленькая нашлепка к огромным, как говорят сейчас, фреймворкам. которые используют, да, инфраструктурные платформы, платформы рассвертывания и какие-то бизнес-платформы, в которых это не единственное приложение. И вот тут, кстати, да, любые ЛЛМки современные, они просто уходят в минуса, да, так сказать, ничего не могут сделать и так далее. Скорее всего, некоторые скажут, что не хватает контекста, другие скажут, что нужно с Attention как-то поработать, а я скажу, что нет. Дело в том, что там возникают совершенно другие проблемы, не увязываемые в формализацию простого входа, простого выхода и конкретного алгоритма их связывающего. В этом смысле, да, хорошо бы поговорить про инфраструктуру, которая реально огромна, но мы не будем. Дальше посмотреть на вопрос оркестрации. и указать, что как только искусственный интеллект хоть какой-то научится хотя бы чуть-чуть в оркестрацию динамических процессов над большими данными, вот тогда будет следующий мегапрорыв. При этом Там пока прорыва не намечается, но намечается прорыв в самих методах и инструментах оркестрации. У нас в конце 2010-х годов был реально супер-мега прорыв, очень часто говорят о втором поколении средств оркестрации. И как раз, если мы на современные посмотрим, то они уже разделились по кускам не просто на оркестрацию кода или не только на оркестрацию ETL, на очень разные вещи. И как раз дальше очень круто развиваются. А вот искусственным интеллектом, с точки зрения самих инструментов оркестрации и соответствующих алгоритмов, они пахнут вообще. Дальше про безопасность. Тоже очень важный акцент делают сейчас. И, например, я ни одного случая в индустрии не знаю, когда бы разрешили более-менее современную даже ЛЛМ-ку использовать как раз вне самого-самого страшного контура безопасности, что опять-таки полностью лишает это смысла. Ну и дальше лаборативка, программинг in the menu, на что сейчас упирается и что здесь делает искусственный интеллект. Ну, во-первых, сама коллаборация — это изобретение середины прошлого века. В 60-х годах первичная формализация. Во первую очередь, конечно, связана с именем Дугласа Энгельбарка, того самого, который и родитель мышки, и родитель всех демок, и много чего еще. И дальше как раз мы говорим о том, как она выглядит. Не будем останавливаться, поскольку это достаточно общие вещи. Главное, что сейчас это взаимоувязывает обычно с цифровыми двойниками и метаверсом, когда говорят, что ИИ-агенты, то есть агенты, представляющие не нас с вами, а какие-то как раз искусственные интеллекты, должны в именно нормальных средах коллаборативной деятельности вместе с нами работать, а не только видя, да, ты написал строку, он тебе выдал строку. Как известно, в начале этого года у нас была замечательная статья, большая, о том, как коллеги на современных LLM'ках именно полноценно воспроизводили классический ограниченный тест Тьюринга и перешли к тестам Тьюринга в высокоиммерсивных средах. Мы же здесь что говорим? Что у нас, да, именно в программе на In The Main с точки зрения коллаборативных технологий очень круто развивается. Более того, Отсюда точка роста была именно в Software Engineering. Дальше мы во многих других областях это переиспользовали и очень крутые эффекты получили. Ну и, наконец, мы это очень хорошо оцениваем с точки зрения текущего уровня инструментов. И вот тут-то инструменты, особенно с точки зрения социологических опросов и затем как раз чек-листов и том, как правильно внедрять, точки зрения особенно всевозможных современных body of knowledge, нам обеспечили что? Литературный программинг на новом уровне. Ура! Программинг на Индземейне очень круто развивается с точки зрения в том числе искусственного интеллекта. Почему? Все современные среды для программинг на Индземейне, они работают на куске того, что мы связываем с как раз частью достижений. Так, можно я чуть-чуть прервусь? Буквально, коллеги. У меня маленькая люка. 

S00 [00:38:45] : Да, давайте воспользуемся перерывом, дадим возможность Киму с поднятой рукой сказать, что он хотел сказать. Передохнем и двинемся дальше. 

S02 [00:38:56] : Таким, говорится, печально. Так, я с вами, извиняюсь. 

S00 [00:39:07] : Да, Ким. Вопросов у Кима нет, значит давайте вопрос от Виктора Казариного здесь возник. Не упрощаете ли вы ситуацию, когда в качестве ИИ подразумевается только ЛЛМ и нейросети в целом? Ведь идут разработки, хотя с отставанием альтернативных подходов к ИИ. 

S02 [00:39:25] : Я как раз пока нигде в принципе не сказал, что ИИ это исключительно ЛЛМ. Я просто, когда говорю об инструментах, говорю о том, что реально можно потрогать. И потрогать можно сейчас три в основном вещи. Это, во-первых, что-то, связанное с явным знанием, эксплицитным. То есть, возможно, это логически инженеринг, и я же с ним. А во-вторых, это как раз всевозможные не только, кстати, LLM-ки как таковые, то есть не только языковые, но и мультимодальные модели, то есть генеративные. Мы к этому, кстати, в конце сведем. И как раз можно потрогать всевозможные частные инструменты машинного обучения. И здесь понятно, что сейчас была революция в глубоком машинном обучении, но не только оно. То есть я нигде напрямую это не свожу и не буду. Так, продолжаем. Извиняюсь, мы прервались на том, что развитие инструментов программинт Инзэмэни, с точки зрения удобной коллаборативной работы больших трансдисциплинарных команд над не только кодом, но и всеми остальными артефактами, привело во многом к чему? К появлению тех самых ноутбуков кодовых. И здесь я показал некоторый кусочек истории, который на самом деле до сих пор вполне развивается, потому что и обероны, фары и готовки, они вполне доступны, свежие версии недавно вышли, они веселые, при этом обероны это еще виртуозская разработка и так далее. Но дальше что интересно, у нас появляются результаты Literature Programming, именно в смысле кнута, которые используют коллаборативную разработку и, в кавычках, коллаборативное чтение последующее, то есть коллаборативное использование артефактов. В качестве примера мне очень нравится суперкнига Physical Based Rendering, где как раз в тексте есть не только гиперссылки и всякие стили, в том числе кодовые, но есть реальные вычисления, которые автоматически порождают и код, и формула, и все остальное. Замечательный пример литературного программирования, как он должен быть. На самом деле, такого сейчас все больше и больше. Более того, знаменитая, например, оптимизация и как раз Optimizing Algorithms, которые уже даже книгу по валидации результатов написали, можно отдельно потом это обсудить, это поддерживают и хотят сейчас это все переписывать, потому что они это писали еще как раз в 2019 году, первую книгу, точнее, писали еще раньше. Поэтому они сейчас хотят это все переделать. Что важно теперь с точки зрения I, что никакие современных лабораторийных инструментов без I не работают. То есть они, конечно, могут работать, но эффективность их снижается во много раз. И сейчас, если вы посмотрите на любые, как раз, коллаборативные платформы серьезные, типа Microsoft, да, это встроенность разных совершенно видов ИИ, и как раз антологии, да, и как раз разных отдельных ML'ек, и распознавателей генераторов, да. Почему? Потому что есть теперь общие ассистенты. Их очень сейчас любят, начиная с позапрошлого года примерно, ну, с появления ChatGPT, да, и как раз у Microsoft это купай вот. и как раз дизайн презентации, да, генеративка в чистом виде, и обработка текста от как раз там проверки грамматики и орфографии до суммаризации, да, и как раз переводы, и транскрибирование, и чтение, и чего только нет. При этом понятно, что это все делается ради того, чтобы человек наряду с компьютерными агентами чувствовал себя удобно в больших коллективах. И здесь мне очень нравится приводить пример современной платформы Clarity, которая развивалась от достаточно маленького движочка от совместного деятельности и после именно включения инструментов перешла на другой уровень. Если кто не видел, с удовольствием могу порекомендовать посмотреть как референсный или иллюстративный пример. Почему? Потому что там как раз, казалось бы, все стандартные вещи чем дополнены? Автоматическим учетом и генерацией контекста, который берется по тому, что сейчас динамики происходят на как раз там имейлах, там звонках, сообщениях, там и прочим прочим. И тут же к нему можно либо автоматически, либо небольшими доп. запросами притянуть все что угодно. От персон и тем обсуждаемых, до артефактов и как раз какой-нибудь динамики развития отношений, трендов и прочего. На самом деле именно так это по сути и должно выглядеть. К сожалению, у них некоторые области не проработаны, особенно редакторы крутых артефактов. То есть, по-хорошему, это должны заняться как раз Microsoft, Autodesk и прочие массоманные компании, в смысле Adobe, и это делать. Микропример, мы говорим, что уже даже если смотрим через Word на коллаборативную деятельность и говорим, что у нас даун 3.65 и мы редактируем документы кучей народа, то на самом деле там и агенты уже вполне себе действуют рядом с нами. В этом смысле именно программа In the Mania получила самую крутую инструментальную поддержку. Почему? Потому что там всегда у тебя есть человек, который будет хуманкурировать какой-то результат автоматом, расколлаборативно. А вот дальше становится очень интересно. Если мы теперь это объединяем, то есть появившиеся интерактивные ноутбуки, как кодовые ноутбуки, с как раз возможностью интерактивной коллаборативной деятельности, То дальше вопрос. Почему не хватает классического Юпитера? Да, на самом деле, даже в виде Юпитер-хаба Юпитер очень неудобен для коллаборативной работы, то есть программинт ин зе мене и очень плохо для просто даже программинт ин зе смол с точки зрения именно РСИ. Он не поддерживает полноценную производимость. Почему? Потому что он не код. Более того, он даже никакая не программа скомпилированная. Он JSON-файл, у которого одновременно лежат тексты, данные, код, которые причем не имеют никакой нормальной связи с какими-то версиями пакетов и другими RSE-артефактами, которые сделаны до конкретного ноутбука. В результате, с некоторого момента, когда это все было отрефлексировано, примерно 10 лет назад, стало развиваться сразу несколько проектов, которые пытаются решить краеугольную проблему невозможности использовать нормальный Юпитер даже в виде хабов или лэбов в как раз RSA полноценно. И самым крутым вариантом, который сейчас является иллюстративным примером, является плута на джули. Может кто уже юзал. При этом сейчас по его стопам идет Marima для питона и как раз они бесплатные в общем-то эквиваленты для крутых промышленных решений. Почему? Потому что Microsoft уже до этого делал подобные решения. Сейчас они не очень развивают Wage, но оно там есть. Valfram делал, да, Valfram Notebooks. Они крутые, развиваются очень круто, но дорогие. И как раз дальше мы говорим, что сам Diplo еще очень тяжелый. Особенно с точки зрения как раз поддержки коллаборативки, когда надо в облако это разворачивать. И как раз Марима это учитывает. И сейчас Марима это во многом символ того, как это должно быть сделано, почему это должно быть сделано и дальше, как туда встраивать в том числе напрямую искусственный интеллект. Вот это базовый примерчик того, как используется реактивка. В этом смысле Юпитер очень плохо, он нереактивный. И как используется интерактивка. Но дальше мы говорим. Мало того, мы прямо в свойствах видим, что есть настройки. В настройках есть AI и VA. Есть аж три пункта дополнения кода. То есть пишешь код, и я тебе советую редактирование кода. То есть ты выделяешь какой-то кусок и говоришь, переделывай мне так-то, так-то. И, наконец, есть рядышком чат. в котором есть кнопочка «Добавить результаты в виде кода из этого чата в ноутбук». Примерно так это выглядит. И отмечу, что, пожалуй, на текущий момент из открытых решений это не просто лучшее, а единственное, в котором одновременно все это есть. Есть несколько других решений, в которых есть по кускам, но зачем нам это смотреть. Плюс понятно, что это все можно внедрить в какой-нибудь VSCode и спокойненько использовать локально. Более того, eMarimo локально прекрасно работает, хотя, конечно, сейчас они очень много усилий тратят на то, чтобы ее перевести в полноценный коллаборативный режим и как раз обеспечить, чтобы были кнопочки еще и с другим участником-человеком общаться. Вот, кстати, те самые кнопочки от ноутбука, да, и я здесь специально привел маленький примерчик, типа, расскажи мне, как подключиться к OpenAI. Все работает. При этом дальше в самом ноутбуке у тебя всегда есть Generate with AI, И можно просто продолжать код, можно как раз делать compilation, можно делать редактирование. Он понимает ошибки, то есть то, что выводится в качестве ошибок, втыкается автоматом в контекст. И это, казалось бы, да, просто LLM. Но если использовать серьезные инстракт-ЛЛМки, как бы предназначенные в том числе для программистов, то есть которые обучены на языках программирования, то мы уже помним, к чему приходит как раз отдельно даже досуждающая ЛЛМка на ICPC. Все видели, все задачи OpenIT пришила. И вот здесь получается, что отдельные алгоритмы, либо отдельное обращение к какому-то API, либо как раз тесты для них, Прекрасно делаются. И даже не приходится говорить о вайподинге. А вот дальше вопрос. Можно ли как раз сделать это все на одном языке, чтобы не было переходов между разными языками. Да, много на самом деле проблем. Они потихоньку решаются. Вот сейчас в 14 версии очень хорошо решилась некоторая проблема с точки зрения декораторов. В 15-м наконец-то решатся проблемы с точки зрения как раз параллельного выполнения, кроме стандартного SICA и ODE. И в итоге это круто. Но та же Julia, конечно, круче, потому что она изначально об этом задумалась. Дальше, что важно, если мы посмотрим на Pluto как сам иллюстративный пример, то к нему есть еще и не просто яичные какие-то инструменты, а специализированные инструменты визуализации, специализированные инструменты в смысле решателей физических задач и прочее, которые позволяют получить максимум отдачи от подобного ноутбучного стиля и как раз все, что касается воспроизводимости и других свойств RSE, сделать. Круто, круто. Это как раз примерчики из Julia. Реактивность. Это на самом деле первый нормальный реактивный ноутбук. Дальше как раз примеры визуализации через маке, причем на любые рендереры. И, наконец, использование в обучении. Когда мы говорим, что интерактивность и реактивность вместе с базовой коллаборативностью, это очень круто. И отмечу, что уже несколько ведущих университетов мира многие длинные курсы перестраивают на сквозное использование того же самого плута. Вот, кстати, сейчас некоторые перестраивают на тот самый Марима с точки зрения питома, но отдельно. Более того, именно иммунитетонщикам и физикам плута нравится намного больше. Ну и, наконец, объединение двух миров Python Call и Julia Call, проникновение друг в друга, возможность обмениваться структурами данных и как раз некоторые общие требования, которые потихоньку закрываются. Поскольку они напрямую не связаны с искусственным интеллектом, а связаны именно со всяким девопсом, туда отвлекаться не будем. В этом смысле, да, примеры нас даже не так волнуют. Нас особо волнуют, да, что будет дальше. И вот здесь как раз будет ответ на ранее произвучающий вопрос. А именно, мы говорим, что новое рождение, третья весна, да, это метод работы с явным знанием, антологическим инжинирингом и всем остальным. Здесь, опять-таки, ультрафрам является иллюстративным примером, потому что обычный человек бесплатно может воспользоваться альфой, Дальше, заплатив буквально 5 долларов, подключить ее, допустим, в ChatGPT и воспользоваться уже гибридной системой, которая будет крутейшей LLM-кой плюс крутейшими антологиями. Из присутствующих наверняка кто-то уже пробовал? Нет? Тишина. Ну ладно. На самом деле, изумительно. Более того, это дает настолько крутое возрастание качества, то есть даже не в разы, а именно просто бесконечно крутое, что это обязательно надо хотя бы попробовать, чтобы оценить. В этом смысле, когда мне кто-то начинает рассказывать про галлюцинации, я, во-первых, ему говорю, что это не совсем галлюцинации, не будем туда погружаться, потому что в чате это было неделю-две назад, а дальше мы говорим, что У нас как только есть возможность какой-то оценки и хотя бы просмотра в виде запроса антологии, то дальше начинаются веселые вещи. А именно, мы говорим, что современные как раз большие языковые модельки, а еще лучше мультимодальные модельки, они получили возможность не просто уже ризнинга, который на IRL основан, они еще получили возможность чего? Пробовать сделать формально описанный какой-то алгоритм, но высокоуровневый с точки зрения описания процессов. Например, вот эта статья свеженькая, используется PDDL, Planning Domain Definition Language, очень веселая вещь, кстати. Но на самом деле подобных много, различных языков описания работ в разных предметных областях. И оказалось, что если заставлять модель учиться на подобных языках и действовать с подобными языками с точки зрения агентности, то все намного круче. Причем реально в разы тоже сразу. Более того, если мы как раз сужаем область и урезаем осетра, Даже простые ллмхо можно обучить работать с математическими формулами. В ней останутся ошибки с точки зрения того, что она может говорить что-то совсем не то. Но если у нас есть с точки зрения учительной сложности какой-то валидатор, То есть понятно, что это не для всех задач подходит. То есть для многих антиполных задач это не подойдет в смысле сложности валидации. Но если есть валидатор, то очень хорошо, например, сейчас начинает работать математика. Многие уже наверняка видели, как доказывается сумасшедшая сложность ремая на линии. Я даже несколько символов приводил. И вот уже два года назад была, например, лемма. Наверное, кто-то узнает, почему двоял. И они уже два года назад делали очень неплохой вариант математического сольвера. За два года эта область разрослась и специализировалась. Я знаю специальный сольвер в дискретной математике, на алгебре и где только ни по пути, а вплоть до топологии. Ну и наконец, когда это сейчас было осознано, то начиная с осени прошлого года на нескольких конференциях именно по программному обеспечению в разных видах, Кстати, по конференции по базам данных, конференции по большим данным и так далее. Что сказали? Надо это формализовать как инструменты именно Software Engineering в целом и тем самым обогатить Research Software Engineering. И в этом смысле долго не было никакой серьезной статьи, но потом появилась статья Generative AI and Empirical Software Engineering. Парадинг-шифт. Но парадинг-шифт и так понятен. А что такое Empirical Software Engineering? А это когда мы говорим, что включаем артефакты, которые нам создают всевозможные ML-ки разных типов, вплоть до как раз мультимодальных интерактивных диалоговых LLM. И как раз говорим, что мы включаем состав данных на входах, выходах, тренинг, промпты и аутпуты. включая некие алгоритмы и артефакты, которые нужны для того, чтобы поддержать агентность. И, соответственно, здесь проблема в том, что, например, MCP, который сейчас развивается, он откровенно убогий. То есть он приятный, но очень простой, недостаточно оксимиотизирован, можно так сказать. И поэтому, на самом деле, он должен на границе пары лет замениться на что-то серьезное. К тому же MCP очень неудобен для корпоратов. Ну и как раз вывод. Какой вывод? Вывод такой, что сейчас вы наверняка все слышали, во-первых, что-то о вайб-кодинге, во-вторых, сейчас вы услышали от меня про RSI, а плюс еще очень сильно развивается, и поэтому можно делать отдельное выступление, эксплоратор и кодинг, то есть попытки, да, алгоритмически исследовать какую-то предметную область с получением как раз артефактов кода. И понятно, что можно сказать, что если систематическое создание ПО нас интересует и одновременно интересует использование AI, то волей-неволей возникает часть, которая называется у коллег AI for RSI. И да, это теперь хот-топик в точке зрения объединения того, что мы говорили о свойствах, в смысле Reproducibility и всех прочих R, то, что мы говорили о междуспланных командах и программинг In The Main и коллаборативке, то, что мы не говорили про программинт ин зе хьюдж с точки зрения многоуровневых архитектур, многомасштабного моделирования всего остального страшного из системной инженерии, и как раз того, что реально делает кодер, который пишет конкретный код и хочет, чтобы ему помогло AI. И всем рекомендую почитать как раз статью. Она сейчас на ревью в Automated Software Engineering, но мне базовая понравилась. Я, конечно, кое-что поменял и кое с чем поспорил, Но все равно приятное. Базовое название Jensen Research Software Engineering VZI. На самом деле после ее как раз просмотра мне окончательно и пришла в голову идея не просто это рассказать, но еще и увязать с базовыми источниками по областям. Заканчиваем. Что у нас получается в сухом остатке? Возвращаемся. Гестемология, онтология. Это как раз то, о чем я рассказывал в зимние выступления, и то, что до этого год назад рассказывал, точнее, даже больше года назад, когда мы говорили о том, где корни пистемологии и онтологии, объекта признаковых данных, и как раз работы над измерениями со всеми реальными данными, будь то робот, будь то какая-нибудь система анализа телеметрии или еще что-нибудь. Дальше у нас как раз обновляются достаточно серьезно своды знаний по системной инженерии, по программной инженерии, да, по как раз управлению данными, ДМБОК и все прочее. И отсюда очень большой акцент на опциях всех типов. В этом смысле в череде DevOps'ов и DataOps'ов появляется и AIOps. Его причем сейчас отдельно рассматривают от MLOps. Туда сейчас лезть не будем. Дальше понятно, что произошло по новой. Во-первых, формализация интереса к вычислительным экспериментам, к методологии. Во-вторых, к инструментам поддержки учрежденных экспериментов и как раз тому, чтобы это было не просто данные, которые становятся артефактами данных как результаты эксперимента, а чтобы это было одновременно и как раз артефакты кода, и чтобы можно было их публиковать. В этом смысле, да, Pluto, там, Джулевский, Марима, как раз Питоновский и прочие, это шаги в очень правильном направлении. И как раз уже сейчас появились новые сайты припринтов, где припринт — это реально ноутбук. И я прямо это просто поддерживаю всеми лапками. Дальше обязательно рассматриваем программирование не только с точки зрения спортивного программирования. Это как раз и закроет, скорее всего, через пару лет окончательное и бесповоротное. Рассматриваем создание серьезных программных продуктов. И здесь очень большой акцент должен делаться на тестирование, причем включая human curation, и развертывание, особенно с учетом и пройденных сред развертывания. Ну и дальше науки о данных. Науки о данных все возможные варианты управления этими самыми данными, визуализации данных, объяснимости, интерпретируемости и всего остального. Ну и IAI здесь как раз напрямую втыкается сюда. Мы отрицаем вайп-кодинг и приветствуем IAI for RSI. Спасибо за внимание. Вопросы? 

S00 [00:59:34] : Да, Алексей, спасибо, что называется, за очередное расширение сознания. на космических масштабах. Некоторые, как я понимаю, улетели в космос. Вопрос докладчику из чата. Как вы оцениваете динамику развития языков программирования и в целом программной инфраструктуры Библиотек, Платформы ТД в Горизонте 5-10 лет? Я понимаю, что даже на год заглядывать трудно, но все же будут ли существовать языки программирования или эти артефакты исчезнут, как принаписано в длинных табличках? 

S02 [01:00:07] : Как раз на год-три очень хорошо все видно, а вот дальше как раз может быть какой-нибудь подрыв, то бишь destruction. Почему? Потому что сейчас будут всеми силами развивать среды, в которых можно нормально, а не вайпкодить, программировать. И в первую очередь это все видно по тому же Маримы Плута и всех прочим. Почему? Потому что там огромное количество небольших, но нерешенных технологических задач, которые надо решить. И поэтому на примерно три года повестка абсолютно ясна. Более того, вместе с этими решениями развиваются как текущие языки, так и появляются новые. Здесь наверняка кто-то может вспомнить ZIK, кто-то вспомнить NIM, кто-то вспомнить еще что-нибудь интересное, типа развития EFILE. Но на самом деле сейчас языки конвергируются. То есть я не зря говорил, что Python во многом сейчас раст. У меня из 40 основных библиотек питоновских используемых 19 — это растовские библиотеки. То есть почти половина. Еще бы одна, и была бы точно половина всех библиотек растовских. Плюс огромное количество возникает сейчас библиотек на языках типа Rust или даже C++, которые сделаны так, что интерфейс для программиста прикладного — это Python. Отмечу, что, например, сейчас выходит Unreal Engine 6. В него включили новый язык программирования, потому что поняли, что, с одной стороны, блюпринты развивать неинтересно для чего-то серьезного, а на C++ программировать ужасно, особенно с точки зрения искусственного интеллекта. Искусственный интеллект, с точки зрения C++, это как раз какой-то даже не джун, а вредитель. На питоне искусственный интеллект пишет на порядок лучше. Ну и в результате, видите, Unreal Engine, то бишь Epic Games, пришлось сделать новый язык. Обязательно посмотрите. А с точки зрения 10 и далее лет, как раз непонятно. Скорее всего будет какой-то disruption. 

S00 [01:02:03] : Спасибо. Алексей, у меня такой вопрос, я хотел его задать Вам безотносительно к докладу. Оказалось, что очень даже относительно. Я поясню чуть вопрос. Мы тут недавно обсуждали следующую проблему, что есть некоторый научный работник, Который когда что-нибудь написал, он с одной стороны может свою статью отправить в нормальный высокорейтинговый журнал, точнее отправлять на протяжении пары лет разные высокорейтинговые журналы до тех пор, пока статью наконец куда-нибудь примут после полугода мурыжения. И он, наконец, получит заветную запись в этом самом скопусе и вклад в свой хирш на скопусе. Это как бы одна альтернатива. А другая альтернатива, что как только он что-то сделает, он выводит это в архив и, как показала моя практика недавно, что буквально через сутки на статью уже начинают ссылаться после того, как она попадает в архив. 

S02 [01:03:08] : Архайв это одно, а можно, например, в Ресечскую. 

S00 [01:03:15] : Я сейчас поясню в чем вопрос. То есть получается, что если я кладу статью в архайв, то она попадает в цитирование не спустя год-два, а спустя сутки. И с тем же самым Хиршем на Google Scholar все нормально, потому что Google Scholar считает, в том числе, по архиву. А здесь я хотел бы задать вопрос, как вы видите вообще развитие современной науки? Умрет ли скопус и рейтингование рецензируемых журналов? Или нет? А если умрет, то что? У нас все будет индексироваться, все будет по архивам и ноутбукам? Да, и вы как бы заострили этот вопрос, потому что я так понял, что заливается модно уже сейчас не в архив, а вот всякие коллаборативные среды, где можно все заливать с работающими примерами кода. Как вы видите эту перспективу? Куда, так сказать, наука идет с точки зрения наукометрии? 

S02 [01:04:25] : На самом деле, как раз давайте с конца начнем. Никакие крутые журналы, скорее всего, просто так не умрут. Они, скорее всего, мимикрируют под что-то и всячески будут извиваться и выживать. Но они, собственно, сейчас это и делают. Наверняка же вы в курсе, сколько они денег берут за публикацию открытую. Дальше как раз у нас что? В самих guidelines, во всех основных серьезных, имеется ввиду, журналах, У нас есть не только как раз, что мы делаем с текстом, но есть еще, что мы делаем с данными. И как раз дальше, когда мы говорим про данные, там уже все требования, которые я сейчас перечислял, все есть. Более того, если мы посмотрим, что вот мы описали саму статью, и у нас дальше есть специфик Study Types, то у нас теперь не только клинические исследования, например. У нас теперь очень много всего, что связано как раз с данными. И это все нужно. Вот, например, personal data и так далее. И все это во всех крутых журналах прописано. Более того, почти все они, как только ты что-то вычисляешь на каких-то данных, требуют, чтобы были цитирования данных. Если не можешь процитировать, то чтобы ты их приложил. они могут обязательно их не показывать, а показывают только если кто-то засомневается в результатах, и значит, они должны будут к тебе обратиться, получить результаты, ой, получить разрешение, а журнал предоставят. Почему? Потому что журнал обязан как раз не краснеть, если окажется, что ты предоставил не те данные, на основе которых ты на самом деле в статье что-то считал. А вот как раз дальше все сложнее. Почему? Потому что современные как раз ресурсы для обмена научной информации, они, конечно, переросли журналы, причем уже лет 10 назад переросли, просто сопротивляются. И как раз у нас есть до 2020 года конвенция европейская об открытом доступе к науке, много чего еще есть, но это в основном всякие декларации типа ОНОВСКИХ. А вот что настоящее, да? Ресерч-гейт, ой, извиняюсь, ресерч-гейт хорошая вещь, во что превратился P2S-код, да? У нас теперь есть Хаггинг-фейс, Hacking Face у нас теперь что имеет? Он имеет бенчи. И если просто на него зайти, то как раз в поиске у нас есть естественно модели набора данных и пространство. И вот пространство это ноутбуки. Причем они сейчас очень хотят перейти на Марима. Более того, они в себя как бы втянули несколько проектов по воспроизводимому управлению пакетами. А дальше есть организации. А дальше, что самое веселое, здесь они еще не вывели, но очень обещают, да? Метчмарки. И вот здесь, видите, у них теперь написано Collaborating Platform, да? Дальше написано, какая активность. Дальше, как раз, что у них много модальностей для всего на свете. Есть Compute, да, Teams и Open Source. Все, о чем я говорил, в одном месте. А самое веселое, да, это то, что появился Hacking Chat. Вот он. А, они еще нет. Я его просто уже тестировал. Шикарнейшая вещь. С внедренным E-агентом. Ну, как же без него? И теперь что осталось? Сделать отдельное место, которое будет прямым наследником Research. То есть если мы вот так вот делаем, то Они уже вот такую себе штучку сделали, но, к сожалению, еще ее не превратили в новый интерфейс, который уже даже нарисовали. Они его показывали на конференции, где как раз бенчи со ссылками на Spaces и все остальное. И где можно, по сути, тоже уже начинать делать публикации. Более того, они организовали дополнительный кусок для публикаций. И так, но туда это нам далеко сейчас зайдет разговор. Короче, платформа Hacking Face публикации тоже сейчас будет. Вот такая вещь. Отметим, что пока это, видите, в зародыше, но, скорее всего, они это сделают, как обещали, как раз в середине октября, а потом будут всячески дорабатывать несколько лет. А что важно? Важно, что если мы посмотрим на то же самое F1000, то там уже давно все доработано, а они сейчас наоборот технологии меняют. В этом смысле, видите, у них есть Submissions, о чем вы спрашивали, да? Как раз браузер результатов очень веселый. И они изначально нормально придерживались политики M5R, и поэтому у них все хорошо. При этом они готовы и статьи рассматривать, и обзоры, и любые произвольные документы, постеры с точки зрения результатов постерных сессий, и просто слайды. Молодцы, молодцы. Ну и, наконец, как раз Research Square. Давайте первую страничку. ShareEarly, ImproveEarly, Manuscript, MakingPack. Прям ответ на ваш вопрос. Отмечу, что старые коллаборативные пространства для написания именно статей тоже активно пытаются играть в код. Например, у нас есть tutorial. Надо в Google, конечно, искать. Вот. Discover, Publish, Cutting Edge, Open Research. Это один из лучших коллаборативных редакторов LaTeX, который я знаю. Он лучше, чем Overleaf, но Overleaf тоже крутой, конечно. И как раз они одновременно предоставляют площадку для публикации. Где физика? 4465 статей. Пожалуйста, открываем. Это нормальный, совершенно рендерный LaTeX. который, к тому же, может тут же подгружать как раз источники данных и автоматическую визуализацию. Может, естественно, тут же делать PDF-ку, .docx-ку там и все остальное. Такая вот большая, хорошая прелесть. Народ просто не в теме, да, и плюс очень долго переобуваются, а потом им придется даже не просто в прыжке, да, а уже в приземлении переобуваться, классические институции типа школ, университетов, там, лабораторий и всего прочего. Спасибо. 

S00 [01:10:54] : Да, спасибо. А еще, да, коллеги, у нас не очень много народу, поэтому если какие-то есть вопросы, то просто голосом можно включаться. Пока народ включается, у меня еще вопрос, пара вопросов есть. Во-первых, уточните, значит, а что, скажите, с вашей точки зрения, особенного в Питоне-3.12? Я вот на 3.11 сижу, пора переобуваться. 

S02 [01:11:17] : Разница почему? Ну, во-первых, сам Python 3 это вообще ни второй ни разу. А дальше, начиная с версии 3.4, он совсем уже и не базовый 3, а с 3.10 это очень другое с точки зрения базовой алгоритмизации, потому что появилась что появился матч в первую очередь, а дальше у него развивается типизация. Более того, скорее всего, с версии 15 он уже частично станет нормальным типизированным языком программирования. И, например, уже сейчас, если вы работаете с датфреймами в Polaris, у них с 51 версии что появилось, возможность для лэзи-запросов обрабатывать исключительно те запросы, для которых точно и изначально известны точные, то есть конкретные типы их столбцов, ну и так далее. То есть Python становится языком, который нормально является интерфейсом удобным для сколь угодно эффективных библиотек. В качестве примера могу привести Taichi, могу привести тот же Polar с расширениями и много чего еще. В этом смысле Python проще воспринимать свежий как как раз некий надстройку над, допустим, тем же Rust. Поэтому просто старые версии питона до 12-й во многом это не будут уметь. И вы себе либо откатываетесь на старые версии библиотек нужных, либо говорите, что да, у меня нет соответствующих возможностей для создания хороших программ с нормальными типами. 

S00 [01:12:40] : То есть 3.12 появилась поддержка RAS, как я понял, вот основной? 

S02 [01:12:43] : Нет, RAS с точки зрения поддержки это на самом деле по сути библиотека PIO3. вот такая RAST-биндинг и она развивается уже достаточно давно. RAST вошел железно, так сказать, в базу питона начиная где-то с 21 года, то есть уже 4 года назад, а начиналось в 2018 году. 

S00 [01:13:08] : Еще вы упомянули неудобства MCP, а вы можете конкретно обозначить, что MCP не устраивает? и чего нужно ждать, и к чему стремиться. 

S02 [01:13:21] : Нужно по сути такую же экосистему, как любая нормальная экосистема развертывания программной инженерии. То есть нужно, чтобы у тебя не просто был MCP, как протокол, Он же не только формат как раз обмен данными, но еще и протокол. Надо, чтобы он был безопасный, надо было, чтобы он нормально встраивался поверх любых других протоколов, использованных при развертывании ООО. Нужно, чтобы у него были нормальные вещи, связанные с версионированием, с аудитом, комплайенсом и всем остальным. В этом смысле он простой, но недоверченный. 

S00 [01:14:03] : Окей. Ну и, собственно, главный вопрос с моей стороны. Вы сказали про свою и мою тоже любимую интерпретировость. Но как Вы относитесь к следующему тезису, что на самом деле интерпретируемость в конечном итоге невозможна, недостижима по той простой причине, что основная проблема неинтерпретируемости не в том, что моделька описывается каким-то неинтерпретируемым видом. Если маленькую модель описать неинтерпретируемым видом, то если она маленькая, то всегда ее можно проинтерпретировать, и она станет интерпретируемой. Но истинная проблема неинтерпретируемой модели заключается в том, что модели становятся настолько сложными, Что на нормальную, хорошую модель не то, что времени, жизни человеческой не хватит, чтобы все ярлыки развесить для интерпретируемости, а просто ярлыков не хватит. И поэтому нельзя ли сказать, что на самом деле по мере увеличения сложности моделей и развития систем и приложений искусственного интеллекта решаются уровни простых программ, а будут решаться сложные уровни, что в какой-то момент интерпретируемость станет физически нереализуемой, по крайней мере в перспективе интерпретации этих моделей и поведения человека. 

S02 [01:15:37] : На самом деле интерпретируемость я использую уже как рамочный термин, и мы с вами об этом, помните, год назад договаривались, да? И в этом смысле нас больше волнует объяснимость, то есть explainability. И на самом деле, да, если мы посмотрим даже на классическую вот эту картинку, он нормально, интересно, сможет? 

S00 [01:15:55] : Пока вы открываете, можно я сразу так поясню? У нас же вот есть интерпретируемость локальная и есть глобальная. С моей точки зрения, как раз локальная интерпретируемость это фигня, потому что нам важно обеспечить в первую очередь глобальную интерпретированность, особенно для, что называется, mission critical system. А тут вот как раз возникают проблемы. 

S02 [01:16:15] : Проблемы в любом случае возникают. Мы, в принципе, собираемся, чтобы решать некие проблемы. Они всегда будут и без них нельзя. Интерпретируемые же не об этом, то есть не о том, что любой человек, подошедший к какой-то мельке, сразу поймет, что она ему выдала. Это абсолютно бессмысленная постановка. У нас есть, как здесь правильно написано, есть инженерная интерпретируемость, дальше есть каузальная интерпретируемость и как раз интерпретируемость, которая индуцируется доверием. И с точки зрения человека, который хочет получить от как раз каких-то инструментов искусственного интеллекта пользу, вот это членение намного интереснее. Почему? Она дает как бы классификацию плодов. Почему? Потому что здесь у нас возникает знаменитый Trust Paradox. И Trust Paradox, да, он заключается в том, что у нас, да, как раз невозможно, да, никак сказать человеку, который не знает, как оно работает, что оно работает правильно. Если человек знает, как оно работает, ему достаточно просто некого объяснения текущих результатов. Но вопрос, как вы правильно задали, в том, что очень серьезные становятся модели, очень многомасштабные, и человек просто объема внимания никакого не хватит, вообще никакого человека не хватит объема внимания для того, чтобы как раз понять то объяснение, которое даже выдаст машина. И в результате мы к чему приходим? К классическому парадоксу, который описал еще Тот человек, который ответственный за фальсифицируемость. Кто это был, коллеги? Кто придумал фальсифицируемость и формализовал ее с точки зрения научных теорий? Так, что-то я переключился в какой-то режим работы со студентами, простите, пожалуйста. Нет, нет, ничего. Очень правильно. Когда сказал, да, что есть фальсифицируемость, да, он дальше не смог выяснить, а как эту фальсифицируемость, да, конструктивно устроить, чтобы как раз получать от нее плоды. И пришлось Локатышу, он с ним долго переписывался, чтобы объяснить, что такое научные программы и что такое результат деятельности научной программы. В этом смысле, да, философия науки, она сейчас неразрывно связана с развитием искусственного интеллекта. Почему? Потому что вот здесь вот у нас, да, FI, FI-RSI, да, как раз эти вопросы обсуждаются. У нас систематично есть некий процесс, да, производящий некий систематичный результат. Да, с использованием ИАИ. И этот ИАИ должен объяснять все на том же уровне, на котором мы требуем от обычного ученого. Потому что если мы от обычного ученого не требуем, чтобы он нас доводил все до 2х24, то почему мы этого требуем от ИАИ? А если мы этого все-таки требуем от ИАИ, то как вообще это конструктивно поставить как задачу? Вы же правильно сказали, что невозможно конструктивно поставить как задачу. 

S00 [01:19:24] : Окей, спасибо. Следующий вопрос у нас от человека с ником Starchy. Уже сейчас есть четкое понимание, что полноценная разработка с использованием кодин-агентов, преимущественно Cloud Opus, постепенно сводится к методологии с использованием SDD, Specification Driven Development, плюс TDD, Test Driven Development. Например, kiro.dev. Я сделаю ремарку, я буквально послезавтра выложу как раз свой доклад по этой теме. Он уже записан, можно кстати на ВК пойти, у меня как раз на эту тему есть доклад, который я завтра на микроэлектронике буду рассказывать. Паблик выложу чуть позже. Дальше вопрос. Спасибо за эту ссылочку, Кирадев. Дальше вопрос. И это уже демонстрирует большой прирост эффективности и качества разработки больших кодовых баз, где человек участвует в качестве оператора и фактически не занимается кодингом до 5%. Следующий шаг – это роевое программирование с использованием нескольких узкоспециализированных LLM-агентов. которые тоже уже демонстрируют неплохой прирост в работе над многоуровневыми задачами. Как вы считаете, чего не хватает в этой связке и в каком направлении это будет развиваться? Аплодирую вопросу. 

S02 [01:20:46] : Замечательный вопрос. На самом деле их тут аж четыре. То есть первый вопрос это о том, что такое СДД и ТДД с точки зрения EI. Современный EI на самом деле СДД и ТДД полноценно не знает совсем. То есть даже последние модельки, о которых я говорил, с улучшенным резингом, а не просто как раз ERL с точки зрения поддержки человека, они все равно этого не знают и не умеют. Я и многие коллеги, которых я знаю, пользуются искусственным интеллектом в тех или иных пределах, и в этом смысле TDD у искусственного интеллекта не получается. Почему? Потому что TDD основан на очень важной идее bounding-контекстов и как раз некого BTP-сленгвича. И сначала искусственный интеллект нужно обучить этому языку. Вот если ты его вдруг каким-то образом обучил этому языку и задал как раз границы доменов, то бишь контекстов, то тогда уже как раз, как я и говорил, обращение к API или как раз реализацию алгоритмов преобразования достаточно маленьких структур данных в другие структуры данных он делает. Проблема в чем? Он это обычно делает так, как учили. И вот сейчас я пробовал GPT-5. Ее учили, во-первых, старому, во-вторых, плохо. То есть ее учили как джуна. То есть как только ему нужно принимать решения больше, чем о спортивном программировании, начинается ужас-ужас. То есть он мне совершенно неправильно отвечает, например, на вопросы о базовых вещах, связанных с архитектурой данных. И всячески их пытается пропагандировать. Я как раз через неделю... А, когда? В понедельник, да? Следующий. Шестого числа буду рассказывать на постгресс-конференции, да? ПГ-шной, да? Про то, какие лакуны, значит, в моделировании данных. Вот. И искусственный интеллект, включая GPT-5 последний, да? Не знаю, насколько крутой. По-моему, я спрашивал у среднего, который про. Вот. Он откровенно врет. Вот. Алгоритмы маленькие, хорошо делают, но на старых версиях, например, недавно как раз спрашивал Девстраля летнего этого 2025 года, как мне сделать там на Polars одну штучку. Так он мне приводит пример Polars версии до 0.9, а сейчас 1.33, то есть трехлетней давности. И вот это постоянно происходит. И в результате нужно что делать? Нужно выходить на какие-то стабильные версии обучающих выборок, дальше ни в коем случае не позволять в контекст попадать каким-то противоречащим вещам, связанным с версионированием. В версионировании модельки тоже работают очень плохо. Посмотрите, например, как сейчас мучается Анатолий Лебенчук. не разговаривали с ним в последнее время по поводу его фпв Нет. А зря. Очень интересно. Значит, здесь проблема в том, что как раз модельку надо как раз, во-первых, ограждать от противоречий, выраженных в том числе в версионировании. Во-вторых, делать ей настолько четкие задачки, чтобы она тем резингом, которые сейчас есть, могла с ними в принципе справиться. И, в-третьих, откуда-то брать архитектурные решения. У него не получается. В этом смысле, какой бы ни был SDD, и какие бы ни были, например, входные данные на email диаграммах плюс языках описания процессов любых, начиная с VSDL, заканчивая чем угодно, как только мы перешагиваем границу программин In The Small, ничего из мною виденного сейчас не работает. То есть оно дает отрицательный прирост, как сейчас любят говорить. То есть это не плюс проценты времени человека, а как раз минус. Если кто-то покажет мне пример обратный, я буду просто мега счастлив в первом же. Поэтому если коллега старче покажет подобный пример, я ему буду просто сумасшедший благодарен и готов с ним как раз эти примеры потом рассмотреть в любых позициях, если ему будет интересно. В этом смысле KiraDev ничем не отличается от вайб-кодинга и всех остальных курсоров. 

S00 [01:25:07] : Окей, спасибо. Коллеги, есть еще вопросы? 

S02 [01:25:11] : Я не отрицаю развитие. То есть мы просто смотрим с низкой базы. То есть мы сорвали черепикингом некоторые плоды низковисящие, и сейчас говорим, что ох, как круто. На самом деле, дисраптив будет, ему никуда не деться. Вопрос, когда и какой. Поэтому я сейчас описывал чисто текущее состояние. Так, дисклеймер дал. 

S00 [01:25:32] : Окей, спасибо. Так, коллеги, есть еще вопросы, комментарии? 

S02 [01:25:38] : Дмитрий, спасибо, да, вы написали текстом. Но я с задержкой смотрю. 

S00 [01:25:44] : Так, а что Дмитрий написал? Так, я не вижу. 

S01 [01:25:50] : Меня слышно? Да-да-да, Егор. Да, Алексей, слушай, а что для тебя было бы этим самым программами? То есть, доказательство того, что этот вот программный InDesmol уже повержен, скажем так. Вышли куда-то, не знаю, программные InDesmol Great, Big, там что? 

S02 [01:26:13] : Как раз по нормально выданному заданию, например, на архитектуру данных в виде концептуальной диаграммы. И как раз задание в виде сценариев в, например, кейс 3.0, он сделал нормальную распределенную систему под заданный уровень масштабирования. 

S00 [01:26:36] : Ну хорошо, а как быть в реальной жизни? Есть, я не помню, это анекдот был или нет, что задачка в жире, которая написана, спросить у Олега. Поскольку большинство задач в современных компаниях выглядит примерно так. Сделать такую херню в правом верхнем углу экрана. Вот как быть с тем, когда спецификации не позволяют использовать, делать SDD, не говоря вообще, не говоря уже о том, чтобы делать это с помощью LLM? 

S02 [01:27:15] : Тогда нужен просто такой искусственной интеллекции, да, диалоговой, да, который как раз не будет в углобу угла ставить в кавычках субъективное удовлетворение пользователя, а будет ставить именно в кавычках истину. Понятно, что истины никого нет, есть модели, но тем не менее. И будет говорить мне, что он проверил такое-то решение, сейчас мы обсуждаем его изменения, и проверенное решение в такой-то версии лежит в таком-то гитхабе-гитлабе, и, соответственно, каждый следующий коммит, он будет понимать, что означает с точки зрения изменения, например, каких-то пререквизитов, пост реквизитов, инвариантов и тому подобного исходного кода. Вот это тоже будет супер прорыв. 

S00 [01:27:57] : То есть мы перейдем в режим, когда мы работаем по схеме Agile, где разработчик выступает в роли Product Owner, а искусственный интеллект выступает в роли джуна или синьора? 

S02 [01:28:11] : Нет, джуна как раз бессмысленно, потому что нужен тот искусственный интеллект, который может заменить медла. то есть, ну, исключая медлов постановщиков задачи на как раз отдельные компоненты, имеется ввиду. Всех остальных медлов кодеров. То есть, пока что, да, мы не можем обойтись без высококвалифицированных кодеров. 

S01 [01:28:32] : Так, на мой взгляд, это и очень хорошо. Конечно, очень хорошо. Вот когда мои эксперименты, так скажем, последние полгода, Они показали, что как раз таки наибольшую пользу получают люди с горизонтом, инженерным горизонтом, архитектурным горизонтом, которые могут как раз таки организовывать пайплайны и понимать, как это работает. То есть медлы и, тем более, джуниоры, они могут легко войти, но здесь вход рубль, выход пять. Сюда можно быстро нагенерить всякой ерунды, а дебажить совершенно невозможно. Если неправильно делаешь. Я сейчас тоже пытаюсь такой pipeline выстроить. У меня было несколько прорывов таких, которые удивили. Например, когда правильно формируешь контекст. из логов я нашел несколько достаточно таких злобных багов, связанных с OpenID диктом. Несколько сервисов с друг другом общаются через редиректы. Очень сложно трассируемая штука. Когда у тебя там много логов, которые нужно обобщить, вот он это может делать. 

S02 [01:29:49] : Более того, если язык позволяет контракты минимум, да, а максимум полноценное поведение динамики в тот же раз, да, то ИИ начинает лучше намного работать даже в статистическом смысле. Другое дело, что ему нужна хорошая база решений. Вот, к сожалению, сейчас база решений для питона, она есть либо для программок для ICPC, Либо как раз совершенно непредсказуемого качества программок для доступа к различным играм. Причем старых версий в основном. А еще хуже, что разных версий. То есть у тебя на Tegla, например, главная проблема какая, да? Если ты хочешь использовать примеры с Tegla, то там примеры есть на все версии, например, пандаса, да, начиная там с 1.1, да, заканчивая там 2.2, вот, но уже больше. Значит, и в результате это полный маразм. Поэтому, если, например, на Rasty, да, обучат искусственный интеллект, и он будет использовать достаточно хорошие решения, в том числе по всевозможным вариантам, там, анализы гонок и всего прочего, что на расте очень круто делается, вот тогда может быть даже в текущем состоянии прорыв без специальных дополнительных механизмов объяснения и рассуждения. Потому что у него, в принципе, уже же контексты большие, да, attention там многоголовочный, в принципе, должен уже даже на частотности срабатывать. Но пока мешают очень плохие данные. То есть как только его специализируют, все становится намного лучше. 

S01 [01:31:22] : Ну, а вот этот вопрос с деградацией производительности, с увеличением, то есть контекст-то есть, контекст на основе большой, но если оно забивается, то продавительность сильно падает. Вот этот момент, как ты его замечал? 

S02 [01:31:38] : Ужасно все. На самом деле здесь единственный путь, который я сейчас вижу без смены как технологической парадигмы, это как раз преобразовывать потихоньку те данные, которые у него в контексте, в явные знания, то есть в те же самые антологии предметные. Более того, сейчас, если вы видели, как сделали Fusion Rack, то это же тоже прорыв технологический очень крутой, кстати. 

S01 [01:32:06] : У меня вот сейчас один из вопросов. Я пытаюсь тоже накачивать контекст антологии продукта, строить антологическое утверждение, которое можно и высказывать контекст за контекстом, нарезая на субагентов. Есть Flodo, хорошая такая штука, чтобы еще контекст сужать. Вопрос, как оценивать оценить, насколько все это отработало. 

S02 [01:32:41] : У коллег, например, есть большой платный продукт, очень-очень сильно платный, который автоматически делает слияние онтологии и как раз ищет парадоксы. И в одной онтологии, и при слиянии онтологии. И дальше, главное, что самое крутое, он после нахождения этих парадоксов вокруг пытается найти причины ошибок. для того, чтобы понять, откуда берется этот парадокс. Потому что этот парадокс мог вылезти каким-то запросом, который не является первопричиной. Такие штуки, оказывается, есть, но дорогие. Открытых я таких не знаю. По крайней мере, так сказать, плагина к протеже такого нет. Что делать? Ждать. Ну или пока Microsoft не встроит Office 365. В общем-то, если Microsoft над Common Data Model сделает как раз нормальный антилогический слой, закупит его Cambridge Semantics и Oxford Analytics, ой, наоборот, извиняюсь, и Semantic Web Company, и как раз все это утрясет и сделает как раз сеть запросчатки внутри, а мы с ними, чтобы общались через LLM, это, конечно, будет супер-мега-прорыв. Я его больше всего, на самом деле, жду, чем все остальное. То есть мне нужна система, которая позволит без очень длительного написания ручками кучи запросов, неважно там на Spark или просто еще на чем-то менее сложном, главное, что самому и ручками, чтобы это кто-то за тебя делал и просто говорил, какие у тебя есть парадоксы, в чем проблемы, и дальше ты его просто направлял голосом. Я готов достаточно долго посидеть и повтыкать, и, так сказать, пообщаться с ЛЛМкой, если она как раз будет меня проводить по соответствующим Sparkle-запросам хотя бы. Ну, потихоньку, я говорю, уже это есть вопрос стоимости и внедряемости. В этом смысле на RSI особая надежда, потому что как только мы говорим, что какой-то продукт становится артефактом RSI, он должен как бы все это в себя включать. И потихоньку к этому идет. Более того, если вспомнить ACMR и ResearchObject, то как раз ResearchObject без соответствующей антологии и ссылок на какие-то другие антологии бессмысленен. То есть даже если это крутая cognition ML, то все равно ты ее просто так никуда не интегрируешь, если она не ссылается именно антологически на другие компоненты. Так, это у меня такие хотелки, да. Или, естественно, хочется, чтобы это было open source, но тут это вряд ли пока такое будет, особенно при текущей ситуации с США, Китаем, Россией и всем прочим. 

S00 [01:35:24] : Да. 

S02 [01:35:25] : Коллеги, есть еще вопросы? 

S00 [01:35:38] : Или у всех уже мозг расплавился? 

S02 [01:35:42] : Про крутой обзор написали, да, спасибо. На самом деле эта часть, она очень хорошо объединяется с предыдущим обзором по как раз Data Management и Knowledge Management. И я хочу на самом деле ее объединить со следующим куском по именно эксплицитным технологиям. Я надеюсь, я сейчас там студентам в течение этого полугодия порассказываю и как раз объединю как раз на зимних праздниках. 

S00 [01:36:05] : Да, вы тогда просигнальте, мы соберемся. 

S02 [01:36:08] : Да, о чем мы с вами так говорили в июле еще. Но это через полгода, да. 

S00 [01:36:14] : Хорошо, будем ждать. Хорошо, коллеги, большое спасибо Алексею за огромное количество информации. 

S02 [01:36:22] : А ей будет возможность поделиться, потому что... Я сейчас это самое, просто проверил, нашел две мелкие глюка, пока зачитывал, но я вам не говорил. 

S00 [01:36:29] : Сейчас поправлю все и подаю, кто там... Я особо важные ссылки три запомнил, сбросил в чат. Вот, одну, две от вас и одну вот от Старчи. Но вот было бы интересно еще посмотреть кое-какие ссылочки. Алексей, огромное спасибо. Спасибо всем участникам и тем, кто посмотрит эту запись. И до новых встреч. В следующий четверг поговорим об управлении с точки зрения специалиста по экономике и управлению. Неожиданный будет немножечко семинар, поэтому всем приглашаю. Спасибо за платформу, всего наилучшего, успехов. Спасибо, Алексей. Всем всего доброго, до свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
