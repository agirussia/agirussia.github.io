## 13 января 2025 - Полностью спайковая реализация обучения с подкреплением - Михаил Киселев — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/Xb67MhTsfEg/hqdefault.jpg)](https://youtu.be/Xb67MhTsfEg)
- [видео в ВК](https://vkvideo.ru/video-210968399_456239208)
- [видео в RUTUBE](https://rutube.ru/video/deff16cc1bd6fb372ca84e83694a80f7/)
- [расшифровка](https://github.com/agirussia/agirussia.github.io/blob/main/workshops/2025/13_january_2025_Fully_Spiking_Implementation_of_Reinforcement_Learning.md)
- https://www.researchgate.net/profile/Mikhail-Kiselev-5

**Суммаризация семинара:**

Семинар посвящен обсуждению и анализу методов обучения с подкреплением на импульсных нейронных сетях. В центре внимания находятся вопросы реализации обучения с подкреплением в спайковых нейронных сетях, а также проблемы затухания и лавинообразного распространения активации в каскадных структурах.

Основные тематические блоки


1. Каскадная структура и проблемы затухания

- В схеме B показана каскадная структура.
- Обсуждается проблема затухания активации и лавинообразного распространения.
- Михаил Киселев подчеркивает, что в начале обучения веса афферентных синапсов нулевые, и активация происходит только при внешней стимуляции.
- Временная синхронизация между слоями и премасштабирование системы предлагаются как решения проблемы затухания.

2. Механизм стабилизации при обучении

- Михаил Киселев утверждает, что в начале обучения система неактивна, и только после того, как предыдущий слой обучился, следующий слой начинает стимулировать.
- Не видится положительных связей, которые могли бы привести к катастрофическому лавинообразному распространению.
- Михаил Киселев также говорит о стабилизации системы, но в контексте ограниченного количества микроколонок, которые не могут быть миллионными, как в случае с МНИСТ.

3. Обучение с подкреплением и спайковые нейронные сети

- Михаил Киселев представляет доклад на тему "Помощь спайковой реализации общения с подкреплением".
- Обучение с подкреплением рассматривается как наиболее адекватная схема для адаптивного обучения.
- В спайковых нейронных сетях изменение внешнего мира оценивается, и при получении награды или наказания происходит усиление или ослабление соответствующих синапсов.

4. Использование положительного и отрицательного подкрепления

- Михаил Киселев сравнивает эффективность обучения с использованием только положительного подкрепления и с использованием и положительного, и отрицательного.
- Оптимальное соотношение между положительным и отрицательным подкреплением может быть найдено с помощью генетического алгоритма.
- В случае с Model Free Rail и шариком, вес отрицательного подкрепления должен быть в 20 раз больше положительного для оптимальной работы.

5. Отложенное подкрепление и его влияние на обучение

- Михаил Киселев обсуждает проблему отложенного подкрепления, когда действие сейчас, но его полезность известна только позже.
- Для решения этой проблемы требуется элемент планирования, что является сложной задачей.

6. Model-Free и Model-Based подходы

- Михаил Киселев выделяет Model-Free подходы, такие как прямая задача, задача сдачи и задача ожидания вознаграждения.
- Model-Based подходы включают в себя планирование и использование моделей для оценки ценностей состояний.
- В спайковом варианте Model-Based подходы еще не реализованы, в отличие от Model-Free.

7. Иерархическая классификация и планирование

- Архитектуры для классификации колонок могут быть иерархическими.
- Проблемы в данном случае только с экстенсивным планом и необходимостью иметь много технических процессов для моделирования.
- Михаил Киселев подчеркивает, что для планирования необходима полная динамика мира, включая действия агента.

8. Прогнозирование и планирование в спайковых сетях

- Михаил Киселев говорит о том, что для планирования необходимо выучить модель динамики внешнего мира.
- Проблема в том, что пока непонятно, как применить эту модель для планирования.

**Итог**

Семинар показал, что обучение с подкреплением в спайковых нейронных сетях является сложной, но интересной задачей. Михаил Киселев и его коллеги обсудили различные подходы к решению этой задачи, включая Model-Free и Model-Based методы. Они также затронули темы стабилизации и планирования в контексте обучения с подкреплением. Однако, несмотря на значительные успехи, многие проблемы остаются нерешенными, и требуется дальнейшее исследование для разработки полноценных решений.

**Расшифровка**

S00 [00:00:13]  : Коллеги, сегодня всем добрый вечер. И у нас в гостях снова Михаил Киселев, который весной прошлого года уже рассказывал про экспериментах с обучением с подкреплением на импульсных нейронных сетях. Ну и сегодня, как я понимаю, будет продолжение этой темы. Михаил, вам слово. 

S01 [00:00:36]  : Да, здравствуйте. Сейчас я покажу экран. Ну, надеюсь, что... Я уже, честно говоря, не помню, о чем я говорил весной, но с тех пор много нового появилось, поэтому я думаю, что я не повторю сильно. Вот, а это, собственно говоря, по мотивам работы, которую мы недавно напечатали в журнале Cognitive System Research, ну, и некие продолжения этого всего. Сейчас я демонстрирую экран. Так, так. Угу. Экран виден сейчас? Да, да. Виден, да? А, ну, хорошо. Ну, давай начнем. Что, собственно говоря, мой доклад называется «Помощь спайкового реализации общения с подкреплением». Сразу скажу, что он поддержан, что эта работа поддержана Российским научным фондом. Вот номер гранта такой-то. Меня зовут Михаил Киселев, я руководитель лаборатории нейронных вычислений в Чуварском государственном университете. Ну и вот, собственно, мы этими вещами тут занимаемся, я и мои аспиранты. Сначала на том, почему мы этим занимаемся. Ну, тут в этой теме слилось всё, и актуальности, и новизна, и всё на свете. Потому что, ну, в первых, действительно, это пока ещё нерешённая проблема, как реализовывать обучение с поступлением им в нейронных сетях. С другой стороны, очевидно, что она практически значима, потому что если мы хотим, чтобы всякие институтальные штуки были адаптивнее, обучались, то обучение с подкреплением – это наиболее адекватная схема для этого. К тому же, все же мы полагаем, не только я, но и другие исследователи, что на подходе достаточно разнообразный и дешевый, общедоступный специализированные нейропроцессоры, которые как раз специально сделаны для эмуляции между нейронных сетей. Соответственно, вот надо их чем-то будет занимать, вот как раз это будет то, что они будут делать. Ну и эта проблема сложная, потому что, в чем она будет сложной, я чуть дальше расскажу. То есть, собственно говоря, если суммировать, то обучение с подкреплением – это наиболее адекватная модель обучения львых агентов, работающих и формирующихся в поведении во внешнем мире сложном. А нейроморфные системы – это, вероятно, технологические платформы для технологического прорыва в будущем. что мы верим. Ну и все это в целом еще пока не решено, так как не имеет нормального научного решения. Но сначала как бы общеизвестные истины, азбучные, о том, что такое обучение с подкреплением в его классическом варианте. Ну вот, собственно говоря, представим, что есть агент, который взаимодействует с внешним миром, и это все, так сказать, и агент, и внешний мир, он имеет некое состояние из множества S. Он, этот агент, действует на внешний мир и на себя с помощью действий из некоего множества A. Это все динамично, это все меняется во времени, но агенту известна только некая часть информации о состоянии S, то есть полное состояние он, как правило, не знает. Разумеется, действия у него, так сказать, тоже функции времени. Как правило, когда мы работаем с компьютером, моделирование этого процесса, у нас время понеболее делается дискретным. Какие-то кванты времени у моделирования. И как все это происходит? Агент действует, он меняет тем самым состояние своего мира, причем менять он может не детерминированно, то есть есть некая функция переходов, что вот было состояние такое-то, действие такое-то, и какая-то вероятность, что следующие состояния будут такие-то. Это либо потому, что мир, в принципе, стокхастичен, либо потому, что просто мы знаем только часть состояния, часть компонентов состояния, а остальные нам неизвестны, поэтому она проявляется как некий детерминизм. И самое главное, что, собственно говоря, о чем мы хотим. Вот это все оценивается в нашей деятельности с термином награды, которая есть в функции времени, и, как правило, эта функция является функцией перехода. Вот у нас было состояние одно, мы пришли в состояние другое. Ну и вот это хорошо или плохо. Соответственно, мы вознаграждены или мы, значит, наказаны, потому что это могла быть функция не только положительная, но и отрицательная. Есть варианты, что мы еще включаем в эту функцию награды само действие. Есть варианты, когда он зависит только от текущего состояния, неважно, как мы к нему пришли. Возможно, различные постановки, но сама эта функция, собственно говоря, агенту неизвестна, поэтому он должен отчасти понимать, как она выглядит. Ну и агент выбирает некое действие. Каждый раз относится, что у него есть какое-то текущее состояние, у него имеется спектр действий, и у него формируется этим агентом, так называемая, политика. Это вероятность того, что при данном состоянии будет выбрано такое-то действие. Это как раз то, что нам неизвестно. У политики есть какие-то параметры, которые мы должны оптимизировать. И задача оптимизации – это нахождение такой политики, которая бы максимизировала суммарное вознаграждение. Она обычно считается в терминах дисконтированного вознаграждения. То есть мы говорим, что нам важно не только текущее вознаграждение, но и вознаграждение, которое мы хотим получить в будущем, но с каким-то дисконтом. Потому что будущее – оно как бы не так. более или менее неважно. Поэтому максимизируется ценность текущего состояния, вернее, оценивается ценность текущего состояния, это фактически сумма последовательных ревордов в каждый момент времени, умноженных на некие, значит, времяэкспоненциально уменьшающиеся множества. Вот, собственно говоря, в чем заключается лучшение с потреблением. Но это классический вариант, огромное число людей им занимается, построено множество теорий, целый огромный область математики. Все это здорово, но только если мы переходим из числового домена в спайковый домен, то мы теряем почти все это накопленное человечеством ценностей. Потому что, если мы рассмотрим специфику даемственных сетей, там нет никаких-никаких чисел, А там единственные объекты, с которыми мы работаем, это спайки, так называемые, это некие сигналы бескачественные, как правило, которые нейрон передает друг другу, ну и потоки этих спайков. То есть чисел нет, и поэтому вся эта наработанная огромная математика, и всем понятно, как ее к этому делу применить, если мы хотим это все принести в спайковый домен. Мы хотим, чтобы всё это... лежало внутри импульсной сети. Почему? Потому что если мы собираем все это имплементировать на каких-то нейропроцессорах, а на самом деле по большому счету только в этом случае все это и стоит этим заниматься, если для этого у нас будет специальное железо, то крайне желательно, чтобы все было внутри этого нейропроцессора, потому что любые интерфейсы нейропроцессоров с внешним миром, обычными числами, с аналоговыми какими-то сигналами. Это сразу то, на чем мы теряем резко и по энергетике, и по времени, и по всему остальному эффективность. Поэтому мы хотим, чтобы все было внутри. Ну и при этом все должно быть максимально просто. Нейрочипы, но они состоят из очень большого количества очень маленьких простых процессоров. У каждого процессора крайне ограниченные ресурсы и в терминах памяти, и в терминах, если это цифровая штука, и возможные операции математические, то все должно быть абсолютно минимальным. Ну и к тому же все это должно оперировать асинхронно, наращиваться как угодно. И вот это, собственно говоря, из этих требований и вытекает все дальнейшее. Ну, собственно, вот что я его называю нейропроцессоры, нейроморфные системы. Чуть-чуть буквально тезис на том, что это такое, чтобы было понятно, чем они отличаются от других систем вычислительных. Ну, во-первых, это большое количество простых асинхронно работающих Процесс этиков, который эмулирует нейроны. И они между собой взаимодействуют только с помощью посылки друг другу сообщений. Причем эти сообщения, они как правило просто, ну сам факт сообщения. И все. В современных реализациях еще можно к этому сообщению приделать некое число, а спайки это аналоги нейронных импульсов, которые обычно калиброваны, но можно сделать их разной амплитуды. Не очень понятно, зачем это надо до сих пор, но в принципе можно. Причём существенно, что процесс передачи от нейрона к нейрону спайка — это не мгновенный процесс, а процесс, занимающий определённое время. Это не плохо, это хорошо, потому что это позволяет внедрить во всё это некую динамику. Кроме всего прочего, в отличие от обычных нейросетей, у нейрона есть некое состояние. То есть это простая сама всединамическая система. Он не вычисляет, что там подали, он вычислил выход, ну и все, как бы забыл. А он длится во времени, это некая там, в общем, имеется собственную динамику. Собственно говоря, его функционирование — это прием спайков и генерация спайков по некоторым законам. И что важно, что мы рассмотрим, и что имеет принципиальное значение, что основная функция такого взаимодействительного нейрона – это детектирование совпадений в широком смысле этого слова. То есть в узком смысле этого слова – это нейрон генерирует спайк, когда одновременно получает несколько спайков входных, пришедших на его синапсис большими весами. Собственно говоря, фичи основных нейроморфных систем и импульсных нейронных сетей они здесь как бы сформулированы. В этих терминах что мы теперь имеем, если мы обратимся к проблеме обучения с потреблением? Мы имеем следующую картину. Все спайковое. То есть вот у нас описание внешнего мира, ну и самого агента, самого себя, да и его собственное состояние. Это некие потоки спайков, как тут написано, нарисовано слепо. Тут у нас событийная камера, которая как раз вполне реальное существующее устройство. много применяемых жидкостей, которые реально генерируют потоки спайков. Сама нейросеть что-то такое там делает в ответ на эти спайки и тоже генерирует спайки команды. Как вот, в общем-то, целодействия, которые к нам, к мышцам направлены по нашим нервам периферическим, да, это фактически на токе спайков, которые нам наши актуаторы, значит, приводят к их действию. Так же и здесь. Это такие команды, которые, значит, интерпретируются эффекторами, которые что-то делают. Те самые вот из множества А. Ну и в ответ на это всё иногда на систему поступают некие специальные спайки, имеющие особую семантику. В отличие от описания внешнего мира, это спайки прощения, спайки наказания. Ну, можно сказать, что в нашем человеческом понимании это какие-то сигналы боли и удовольствия. Ну и наша задача, в ответ на описание внешнего мира, отвечать настолько хорошими командами, настолько хорошие действия делать, чтобы минимизировать поток наказаний и максимизировать поток поощрений. Как мы все это будем делать? То есть, как должна выглядеть нейросеть, которая предположительно это будет делать? Ну, как выглядят традиционные нейросети, там всякие сверточные, глубокого обучения, все на свете автоинкодеров, понятно. Это такие слоистые системы. Почему они слоистые? Это большей степенью определяется тем, как они обучаются. Разумеется, и обычные нейросети, и плюсные нейросети. Вначале это некий хаотичный набор весов, который ничего не умеет, его надо как-то обучить. Причем обучение и в том и другом случае сводится к изменению весов, связей, синаптических весов. Хотя бывают с лупчей импульсной сетей еще другие подходы, там мучат и задержки синаптические, и там другие всякие свойства нейронов, но в основном это изменение весов. Но здесь аналогия кончается, потому что обычные традиционные нейросети, их можно рассматривать как очень-очень многомерные и гладкие функции и весов, и входных параметров. В сущности говоря, это так. Поэтому мы можем, пользуясь этим, применить градиентный спуск, который, как давно еще доказали всяческие классики этой науки, особенно эффективно реализуется. Если сеть имеет слоистую структуру, тогда можно это сделать как такой итеративный процесс, распространяющийся от выходов ко входу. В случае с импульсными сетями ничего этого, к сожалению, нет. Потому что у нас нет ни градиентов, вообще ничего нет. Он не может быть чуть-чуть, а он только как бы 0,1. Поэтому никаких градиентов там, в общем-то, нет. Ну, люди, конечно, придумывают некие алхимические способы туда ввести градиенты. Называется метод суррогатных градиентов. Но все же это такой скорее палеотиф, некая такая полумера. Вообще говоря, обучение там должно основываться на совершенно других принципах. И это вот как раз то, о чем я говорил, что нейроны — это корреляции. На этих корреляциях, собственно говоря, построено обучение нейронных сетей на их фиксации. Но поскольку у нас нет обратного состояния ошибки, то и слоистая структура тут не является необходимой, и поэтому, в отличие от более-менее однородно выглядящих обычных сетей, импульсные нейронные сети которые сейчас изучаются, имеют очень-очень разнообразные архитектуры, в том числе и, например, полностью хаотические, в случае машин в таком состоянии. В чем проблема вообще? Почему RL, почему Reflexive Learning – это сложная проблема? Какие бывают то, что осложняет этот RL? Ну, во-первых, мы не всегда знаем состояние реальное. Мы можем узнать только немалые части этого состояния. Состояние, на самом деле, может включать очень большое количество переменных, из которых мы знаем только чуть-чуть. Это, кроме всего прочего, еще и переходы могут быть сами все недоторминированы. Просто, ну, какая-то случайность. Очень большая проблема – это то, что мы не всегда, очень редко знаем реальный Мы очень редко получаем награды и наказания. В основном, мы действуем, действуем, ничего не происходит, а бац, выясняется, что мы, оказывается, сделали все очень плохо. Это выяснилось только через тысячу шагов, после того, как мы начали это плохо делать. То есть, очень малая вариабельность функциональной награды нам не дает возможности определить, куда нам двигаться. К тому же, это все еще может приходить с запаздыванием. То есть вот эти факторы, они как бы определяют то, что это сложная задача, а эти факторы, они совершенно реальные, и в реальных задачах обучения с подкреплением они наверняка встретятся. Но тут мы еще имеем дополнительные, так сказать, проблемы, связанные с именно спайковым характером всего. Ну вот, в обычном понимании, пусть мы знаем не все о состоянии, но мы, по крайней мере, то, что мы знаем, у нас формализуется в нечисто понятном, ну, каких-то векторах, каких-то признаков, например, какие-то числа. Понятно, что мы можем только 10 чисел из 100, но все равно эти числа, с ними как-то можно работать. Здесь этого ничего нет, у нас есть только потоки спайков. И информация вся только у них и заключена. Поэтому определить на основе этих потоков, в каком состоянии сейчас находится мир, это целая отдельная задача. Ну и, соответственно, вторая проблема, то, что у нас редкая оценка, это означает, что эти вот самые спайки, наказания и поощрения, они редки. и могут запаздывать. И это все выбивает у нас несколько раз из-под ног нашу опору теоретическую. Например, понятие ценности текущего состояния в таком спайковом понимании, в общем-то, становится довольно бессмысленным. Вообще, подходы к решению задач ученического укрепления их можно разбить на две категории. Одни более простые и более эффективные, так называемые Model-Free подходы. которые, в случае классического варианта, это несколько разных типов моделей. Например, можно поставить прямую задачу, вот у нас такое состояние, мы хотим обучиться наилучшему действию для данного состояния. Просто прямая задача такая. Можно, допустим, поставить сдачу, вот мы долго-долго функционировали, мы знаем эмпирически ценность каждого состояния. Мы можем ввести сдачу, которая отобразит, построит модель управления из описания состояния в его кумулятивное вознаграждение, его ценность. можем, допустим, поставить задачу, вот у нас есть состояние, есть действие, какое ожидать кумулятивное вознаграждение. Тоже прямая сдача, так сказать, машин-драйвинга. Потом мы эту модель используем в механизме Actor-critic, которая выбирает наившее действие. В принципе, такая же механика может быть реализована и в спайковом варианте, но с некоторой поправкой на спайковость. То есть, в случае, допустим, корреляции. Состояние у вас реализуется такими-то спайками, мы сделали такое-то действие, получили спайк-оценки. То есть, в сущности говоря, нахождение корреляций между этими разными видами спайков. Но даже этот подход, он тоже не очень прост, потому что требует долговременной памяти. Например, чтобы оценить кумулятивное вознаграждение, нам надо помнить, какое состояние мы оцениваем. Вот мы какое состояние хотим оценить, мы дошли до вознаграждения, но мы должны запомнить, что мы в этом состоянии были. То есть нужно, чтобы где-то в сети была механика запоминания этих предыдущих состояний. Ну и механизм After Critic тоже может быть вполне реализован за счет разного рода структур типа Winner Takes All. Это у нас фактически роль критика. Здесь такая структура выполняет самый сильно стимулированный нейрон, он всех подавляет и является выбирающим. Это хорошие все методы, но они не очень применимы, потому что требуют, чтобы, во-первых, мы часто получали оценку, чтобы она не запаздывала, и чтобы мы примерно представляли состояние внешнего мира. Если же всего этого нет, или хотя бы одного из этого нет, то нам придется применять более сложные методы, которые уже основаны на планировании, на построении моделей внешнего мира, то есть то, что называется Model Based Array. Тут мы уже выучиваем модели. Например, модель динамики внешнего мира, которая нам в первом варианте была не нужна, потому что мы там все напрямую строили. А тут нам нужна, чтобы догадываться о динамике состояния, даже когда они частично наблюдаемы. Мы можем эту модель использовать для оценки ценностей текущего состояния. Если мы знаем, как мир развивается, мы можем понять, дойдет она до целевых состояний этой системы или не дойдет. Ну, разумеется, самым замечательным было бы, если мы вообще каким-то образом научились полной динамики мира, включая и действия агента. Тогда мы могли бы применить планирование, если мы выучили такую модель, и просто, так сказать, планировать действия, максимизирующие кумулятивное вознаграждение. Такой подход возможен и в спайковом варианте, но вот в отличие от первого подхода, который Model Free, который уже реализован, я об этом скажу дальше, этот подход вообще еще никем не реализован. Хотя, в общем, ну, примерно понятно, как он мог бы выглядеть. Потому что, допустим, если мы знаем, целевые состояния, если мы их обучили, то мы примерно можем знать от каждого состояния, ну, вот у нас есть целевое состояние, мы можем видеть, из каких состояний эти состояния достижимы за короткое время. То есть тут тоже классационная сдача. В первую очередь у нас получаются как бы вторичные цели, ну и так далее. Мы можем, допустим, смотреть, из каких состояний достигаются эти вторичные цели. То есть мы можем строить такую иерархию, иерархию классификации, иерархию оценок состояний, которые нам позволят такую модель ценности делать. В общем-то, с помощью такого кузуального подхода, кузуального, извиняюсь, мы сможем смотреть, какие действия вызывают какую реакцию внешнего мира, то есть вот с помощью таких вот каузальных моделей мы можем отчасти строить динамику внешнего мира, правда, открытый вопрос, как мы будем ее использовать для планирования. Это пока еще механика планирования на основе этого всего, то есть как модель вы учите, уже примерно понятно, а вот как ее использовать для планирования, это пока не очень ясно. То есть вот, как бы это все находится пока в процессе, и вот, собственно, дальше мы чуть-чуть рассмотрим эти эту механику и как мы собираемся это все реализовывать. Сначала просто пару слов о том, на чем мы все это делаем. Что за сети мы исследуем, какие у нас нейроны. Мы используем очень простую, ну как, достаточно простую модель нейрона импульсного, так называемый нейрон-пороговый интегратор с утечкой адаптивным порогом. Его динамика характеризуется уравнениями, которые написаны вот тут вот в левом верхнем углу. Нейрон характеризуется двумя переменами. Это его мембранный потенциал и его пороговый потенциал, у и у. Которые ведут себя очень просто. Мембранный потенциал изменяется при приходе каждого спайка. на величину веса синапса, по которому получен спайк. А коробовый потенциал увеличивается при каждой генерации нервного спайка и потом линейно стремится к его базовому значению. Ну, такая вот очень простая модель. Тем не менее, даже она показывает достаточно неплохие некоторые свойства, функционалы, например, гомеостаз. Такой нейрон сложно перевозбудить, потому что если он сильно возбужден, то, соответственно, у него очень высокий порог, и дальше возбуждаться ему уже сложнее. Он, что ценно, гораздо более выраженно реагирует на начало стимуляции, на динамический стимул. Как мы видим на этом графике. Когда мы начинаем какую-то константную стимуляцию, сначала он на неё реагирует часто, а потом гораздо более редко. Мы еще дополняем эту простую модель дополнительными элементами, позволяющими частотехнически сделать сложные логические вещи. Например, мы можем вообразить, что этот нейрон имеет возбуждающую связь сам с собой. которые могут циркулировать спайки, это фактически можно использовать для создания механизма памяти. Причем контролируемого длины, потому что у нас каждый раз толк меняется, он увеличивается. И рано или поздно эта штука прервется. То есть мы начинаем генерировать, генерируем только какое-то определенное время. Причем это управляемо. И второе, это мы говорим, что у нас нейрон может быть в состоянии пассивном и активном. В состоянии пассивном он вообще ни на что не реагирует, просто он как бы вырублен на какое-то время. А активный, ну это его нормальное состояние. И причем есть специальные синапсы, которые переключают его из активного в пассивный и назад. Это позволяет очень просто реализовывать всякого рода логику, которая нам как бы избытно понадобится. Теперь об этом самом важном качестве импульсного нейрона, о том, почему мы называем его детектором совпадений. На самом деле это понятно. Даже если не брать обучение, а брать просто его работу, инференс такой системы, то мы видим, что чтобы нейрон сработал, надо, чтобы близко по времени пришли несколько разных спайков. Он срабатывает именно когда приходит несколько спайков на него, делают совпадение. Более того, если мы рассматриваем непрерывные потоки спайков, скажем, у нас два по-соновски процесса, они частично коррелированы. Если мы подадим спайки этих процессоров на нейрон, то мы увидим, что частота генерации им спайков растет в пропорциональной степени коррелированности двух этих потоков. Поскольку мы еще помним, что у нас время тут играет роль, да, у нас распространение спайков в сети – это не мгновенный процесс, а процесс, занимающий какое-то время, то мы таким образом можем детектировать какие-то кузырные связи, но если рассматривать кузырные как различие во времени. То есть, допустим, у нас есть фактор A, который, так сказать, и фактор B, который вот мы знаем, что, вернее, не мы знаем, а фактор A вызывает фактор B. Тогда регистрация этого факта, что вот фактор A Сначала фактор B, потом… Он как раз тоже производится таким нейроном, учитывая то, что, допустим, от нейрона А, нейронов, составляющих фактор А, более долгие по времени связи к этому регистрирующему нейрону. Получится, что у вас эти четыре спайка, они придут одновременно на нейрон, и он сгенерирует спайк, тем самым зафиксируя эту самую каузальную связь. Это еще больше проявляется, если мы рассматриваем обучение импульсного нейрона. Классический механизм обучения импульсного нейрона, многим известный, называется ДП, или Хебберская пластичность. Она говорит, что если нейрон часто, его срабатывание часто вызывается приходом спайков на какие-то определенные синапсы, то эти синапсы усиливаются. Мы часто видим его роль как детектор совпадений. Как раз этот момент показан здесь на правой верхней картинке. Точно так же и в терминах потоков спайков. Вот если мы подадим, опять же, две, два потока спайков просолнцевских процессов разной степени корреляции, то в зависимости от степени этой корреляции синапсы, связанные с этими потоками, они будут либо усиливаться, либо ослабляться. Вот как это показано на графике слева, где степень корреляции выражается цветом. а динамика веса – это как раз эти линии. Ну и еще один вариант фиксации именно каузы альных связей – это так называемая дофаминовая пластичность, мы чуть позже ее рассмотрим. Она работает так, что у нас есть специальный рецептор, И он обладает теми свойствами, что приход на него спайка вызывает усиление тех силопсов, которые получили спайки незадолго до него. То есть, в сущности говоря, это как раз прямая фиксация кузонности. То есть, если мы видим, что сначала что-то происходит, а потом происходит другое, другой допаминовый спайк. то мы этот факт фиксируем и усиливаем веса именно тех синапсов, которые эту причину собой формализуют. Ну вот поэтому, кроме уже всем известной хемовской пластичности СТДП, нами используется еще так называемая допаминовая пластичность, причем в двух видах. Двухфакторный и трехфакторный. Вот у нас есть нейрон. У него есть пластичные синапсы, называемые сигнальными синапсами. То есть они как раз получают информацию о состоянии. И есть синапсы специальные, которые интерпретируются как синапсы награды и наказания. Условно, опять же, не без претензий на какой-то физиологизм, назовем их допоминами. И работает все это крайне просто. Вот пришел оценочный спайк. Это раз. Два. Значит, если синус получил спайк за какой-то период у него, то он усиливается. Крайне просто. Вот как это показано на рисунке. Тут сверху допоминовые спайки, а снизу пресно-оптические спайки сигнальные. Но важно, что если у нас пришел целый паровоз спайков на один синапс, то этот акт происходит только один раз. То есть, скажем, первый будет, переведет поселение и спайки, которые внизу, а второй уже нет. Хотя он тут тоже как бы часто допоминал о спайке. Третий нет, потому что он пришел уже после, он как бы нарушил грузовую связь. Остальные два не изменились, потому что они далеко находятся. Понятно, в общем, вот такая вот простая механика. И второй вариант, он чуть более сложный. Это трехфакторная модель RSTDP. R от смысла reward. Тут все зависит еще от того, сгенерировал ли сам нейрон спайк. Соответственно, три фактора здесь играют роль. Чтобы изменился вес синапса. Во-первых, синапс должен получить спайк. Во-вторых, какое-то время, рядом по времени, сам нейрон должен сработать спайк. И после этого, еще в течение какого-то времени, он должен получить либо подкрепление, либо наказание. Вот только при трех этих факторах у нас изменится вес от этого отлично входного синапса. Это более подробно изложено на картинке внизу. Наверное, примерно понятно, почему синапсы 3 ослаблены. Потому что они пришли по времени около генерации спайка самим нейроном, а через какое-то время еще после этого нам пришел черный спайк наказания. Поэтому они будут ослаблены. Похожая механика. с награждением. То есть, вот это три наших базовых механизма пластичности, с помощью которых мы задачи REL в комбинации решаем. Теперь, как мы это делаем? Какие для этого используются архитектуры? Ну вот, вопрос с Model-Free-REL в какой-то степени уже решен, потому что он продемонстрирован, что можно так сделать. Вот очень простой такой вот архитектурой, которая здесь сейчас нарисована. Вот оранжевые квадратики – это популяции нейронов, соединенные со входами. Вот то, что внизу – это как раз источники спайков, характеризующих внешний мир, спайки внешнего мира, которые характеризуют состояние внешнего мира. Но пока бокс с этим шумом, который у нас тут справа, приходят эти спайки из внешнего мира, они вызывают срабатывание каких-то нейронов. Вот в этих коричнево-оранжевых прямоугольниках. Но при этом, поскольку у нас действия могут быть взаимоисключающие, то если мы хотим повернуть что-то влево, то мы уже не будем делать этого вправо. Если сработал первый нейрон, который отвечает за движение влево, он подавит нейрон, который справа. Это реализуется этими красными толстыми стрелочками. Это взаимное подавление. Ну и вот у нас нейрон простимулирован какой-то входной информацией, он генерирует спайк. Это спайк на самом деле из команды, какого-то актуатора. Актуатор что-то сделал, как-то изменил внешний мир. Мы полагаем, что у нас каждое изменение как-то оценивается. У нас нет первой проблемы, что у нас редкость оценки. У нас оценка частая. Вот мы что-то сделали, мы сделали плохо либо хорошо. Нам пришла либо награда, либо наказание. Пришла нам награда. Замечательно. Это фактически означает приход допоминанного спайка на те нейроны, которые сгенерировали эту команду. Соответственно, по нашему простому правилу, который мы только что изучили, у нас веса соответствующих синапсов входных будут усилены. Значит, они с большей вероятностью на такое же описание внешнего мира сгенерируют это действие, которое оказалось правильным. Ну и наоборот. Если у нас мы сделали плохо, у нас пришло наказание, соответственно, нам надо сделать так, чтобы больше на такое описание внешнего мира нейрон больше не реагировал. Соответственно, те синопсы, которые у нас получили спайки из внешнего мира до этого, они будут подавлены, чтобы в следующий раз он такого не делал больше. Ну, к этому ещё добавляется некая простая механика. Сначала мы ничего не умеем, ничего не знаем, на что не реагируем. Нам надо сначала веса, там, все там, маленькие, любые. Нам надо заставить как-то сначала систему работать, чтобы она получала какую-то experience, какую-то статистику, что-то плохое такое, хорошо. Поэтому мы в ответ, дополнение к этому, дополнение не к внешнему, случайную стимуляцию, некий шум, который заставляет срабатывать всю эту систему и заставляет делать её какие-то действия, которые потом будут оценены. Но когда, значит, либо у вас большая стимуляция внешнего мира, либо когда мы научаемся, мы должны это дело прекратить, чтобы шум нам не мешал. Тут не показан еще один вентиль. Когда система у нас начинает сама принимать решение, то она фактически блокирует этот прослоновский шум. Поскольку он больше не нужен, это как бы некое первоначальное исследовательское поведение. Когда мы уже знаем, что делать, оно нам будет только мешать. Вот такая очень простая механика. позволяет уже как-то более-менее решать сдачу URL, оставаясь в терминах наших требований, то есть чисто спайковая схема. Несколько добавлений, чтобы сделать это всё более точно. Во-первых, мы не совсем вес меняем. То есть у нас в нашем подходе меняется не вес, а другой параметр syntax, который называется ресурсом, и который связан с весом вот по такой формуле. То есть ресурс, он бывает от минус бесконечности до плюс бесконечности. Но вес, он бывает, согласно этой формуле, только от W-min до W-max. То есть он ограничен. Это очень хорошо. У нас нельзя делать веса, равные миллиону чего-то. Не бывает такого. То есть, это позволяет ограничить наши веса, и с другой стороны, оно позволяет вести веса в режиме насыщения, что позволяет сделать их устойчивыми. То есть, если мы, допустим, чему-то научились, какие-то веса сделали сильными, но они не сильные по значению, значение у них все равно не больше, чем у WMAX, а они сильные своим ресурсом. Даже если мы теперь много-много сделаем неправильно, какой-то шум, какая-то неточность, мы не разрушим наше состояние, потому что, чтобы его разрушить, нам надо сильно изменить ресурс. Вес у нас не меняется, он насыщен. Для этого надо стабилизировать обучение. Ну и еще одна важная компонент нашей модели пластичности это постоянство суммарного синаптического ресурса. То есть на самом деле синапсы конкурируют внутри нейрона за этот самый ресурс. То есть если мы усилили оставляются в равной степени. Таким образом, ресурс перетекает из менее нужных синапсов в более нужный. На самом деле, этот эффект очень полезен. Мы теорически это выяснили. Ну и вот пример этого всего. Это вот, значит, простая задачка, такая вот в стиле именно Model-Free-RL. Мы хотим, чтобы сеть у нас держала в центре этот перемещающийся шарик. Сеть, у нее четыре команды, вправо, влево, вверх, вниз, и сеть получает, значит, информацию о, значит, это как бы камера, Причем это камера в стиле DVS камеры. Это камера 20 на 20 пикселей, которая бегает. Причем у нас три канала. Один канал – это просто текущая яркость пикселя. Чем ярче у нас пиксель, тем он чаще посылает спайк. Два остальных канала, это какие-то девесовские каналы, они измеряют изменение яркости. То есть, если шарик движется влево и вверх, как показано, то первый канал просто это дает его текущую ситуацию. Кружочек. Один канал на увеличение, он только в этом полумесяце дает спайки. А канал уменьшения, он в другом полумесяце дает спайки. мы можем, так сказать, видеть, ну и явно измерять скорости шарика. Ну и вот мы видим, что сначала сеть не знала, что ей делать, а потом вот с помощью наказания, разумеется, мы ей об этом не говорим, мы просто говорим, плохо она или хорошо делает. И вот она понимает, что ей надо делать, и она вот уже сейчас достаточно неплохо удерживает этот самый шарик. Ну, это крайне простая сдача, но как в прошлых концептах вполне годится. Ну, кое-что о том, как мы это делаем. Я даже думаю, что на самом деле это не очень интересно. Да, единственное, вот наша методология еще, вот как мы это все делаем, да. Разумеется, эти сети, они имеют много параметров. Сколько нейронов, какие там постоянные времени мембранного потенциала, какой инкремент подъема этого порога, какая скорость его падения к базовому уровню и так далее. То есть их там довольно много. Для данной сети их было столько, дюжин примерно. Откуда их брать непонятно сначала, то есть потом уже это понятно, но сначала кому-то только что занялось, мы видим первый раз шарик, это сеть, мы вообще не знаем, что делать. Мы используем генетический алгоритм для оптимизации гиперпараметров, и это очень эффективный метод, он быстро сходится, как правило, то есть сначала мы генетическим алгоритмом, а потом Поскольку довольно-таки всё стокастические вещи, более тонкими методами градиентный спуск и так далее действовать тут не приходится. Вообще градиентный спуск плохо дружит с любыми аспектами импульсных нейронных сетей. Ну вот мы так вот оптимизируем, и за 23 поколения мы дошли до такой сети, которая хорошо обучается. Но, разумеется, это надо делать только один раз. Это для класса задач, а не для данной задачи. Дальше уже эти параметры достаточно или дефолтными используются, диапазон. Ну вот мы видим там вот такие места у него сформировались. Да, займемся остатками нашего доклада более интересной вещью, а именно ну такая, можно сказать, масштабная и С большой претензией программа направлена на реализацию в полном объеме спайкового Model-B из TRL. Что здесь сделано и что еще надо сделать с общим планом? Разумеется, МНС, которая реализует Model Based TRL, это должна быть довольно сложная система, гетерогенная, потому что она должна включать несколько функциональных разных компонентов. Это не одна какая-то однородная штука, а это такой целый агрегат в сущности разных сетей, решающих разные подзадачи. Что это за подзадачи, если мы говорим о model-based array? Ну, во-первых, нам надо понять, что от нас хотят. Мы должны иметь классификационный модуль, который нам идентифицировал бы целевые состояния, то есть те состояния, которые индицируются получением реворда. Ну, или, соответственно, наоборот, которые надо избегать, которые нам наказываются. Затем один из вариантов – это хорошо бы иметь какую-то оценку, насколько мы сейчас близки к этому состоянию целевому. В частности, это для того, чтобы, если у нас совсем редки наши оценочные спайки, то мы хотя бы можем генерировать какой-то суррогат, внутреннюю стимуляцию. Если мы видим, что сейчас мы были далеки от целевого состояния, а сейчас мы стали ближе, то действие, которое привело к этому приближению, мы его вознаграждаем. Это внутренняя генерация. помимо нового спайка. Для этого нам надо иметь модуль, который бы оценивал близость текущего состояния к целевому. Затем, конечно, если мы хотим планировать, а мы хотим планировать, без этого не обойтись, нам надо иметь модуль, который бы устроил динамику внешнего мира. То есть фактически каузальные связи между разными компонентами описания внешнего мира. Причем это все уже построено, но я дальше чуть-чуть расскажу каким образом. А вот то, что совсем еще не построено, обозначено здесь знакомым вопросом. Дальше мы должны сделать модель действия агента на внешний мир. И причем, более того, нам надо предусмотреть, что сначала мы ничего не умеем, надо сначала делать, ну вот как и в том простеньком примере, сначала делать какое-то исследовательское поведение, причем это должно быть не случайное, а какое-то более хитрое, чтобы это было достаточно, ну вот как сейчас в современных моделях RL, в обычных сетях это целая тоже история. Затем модуль планирования. То есть совсем пока не понятно, вот мы выучили модель внешнего мира, замечательно, вот мы выучили модель воздействия агента на внешний мир, и это мы должны как-то применить для планирования. В каких структурах это выразить? Вернее, есть, но очень-очень слабая. Ну и, наконец, нам нужен некий мета-уровень. Нам нужна некая управляющая система, которая нам бы отменяла или вводила бы исследовательское поведение, это планирование бы запускала. Некий супервизор, который бы управлял работой других модулей. Разумеется, это пока некие поджимки. Но первые три компонента лишены большой степени. Сейчас мы рассмотрим вкратце как. Во-первых, классификация, которая в контексте ERL нам должна отличить целевые состояния. Ну, на самом деле, у нас есть общий подход к классификации любой, в том числе к классификации в терминах обычного машин-леарнинга. У нас есть табличные данные, ирисы отличать, но ирисы всем стыдно, там, не знаю, что-нибудь отличать. Рак молочной железы, висконсинский дататель. Замечательно, мы тоже можем это все формулировать в виде спайковых описаний. И вот есть система, есть универсальная архитектура, она называется Colonnet. Colonnet расшифровывается как Columnar Layered Network, поскольку она такая колонечно-слоистая. Как она работает? Ну, во-первых, действительно такая вот колонечно-слоистая структура. Причем, если мы говорим о классификации на несколько классов, то каждая колонка соответствует одному классу. Если мы на 7 классов классифицируем, значит у нас будет 7 колонок. Каждая колонка устроена следующим образом. Вот это одна колонка. У нас 5 слоев нейронов, которые здесь были показаны, они растут разным цветом данные. Какая механика всего этого? Обучающиеся нейронам, которые L, только их связи являются пластичными. Они получают спайки, характеризующие внешний мир. Входные спайки. Они на них как-то реагируют. Сначала мы рассмотрим инференс. Допустим, мы уже научились всему. Откуда-то мы с неба получили эти веса нужные. Они реагируют как-то. Они вызывают срабатывание нейрона ВТА, вызывают срабатывание нейрона АУТ, который, собственно говоря, является решением. Действие какое-то, либо это, что мы там сейчас, если у нас это как молочные железы, мы там говорим, что это там такой-то тип рака, да? А input это у нас спайковое представление для секвадных данных. А как мы это все, как у нас все это обучается? Обучается это вот как, значит, на этапе обучения у нас не только описание входное, описание внешнего выхода подается на входы этих элинейронов, но и правильные нетки. поскольку мы обучаемся, мы знаем правильный ответ. Эти самые метки имеют тоже вид спайков. То есть, если у нас, допустим, семь разных вариантов целевой и переменной, у нас имеется семь входных узлов, и на момент предъявления соответствующего описания этого примера активен только один из них, который соответствует правильному классу этого примера. Вот класс Label, он как раз у нас тут слева сверху. Этот самый класс Label, он приводит к стимуляции BS9 нейрона, который является постоянным источником спайков. Сначала у нас нейроны ничего не обучены и сами они ничего не генерируют. У них какие-то небольшие, если у нас есть разброс начальных весов, у них есть какие-то разные наборы, разные значения мембранных потенциалов, у нас такая стимуляция есть. Вот этот Bias Gate, он начинает работать на секвенцию спайков, которые распространяются на все нейроны L. постепенно повышая их потенциал. Когда этот процесс у нас в первом сработает, тот нейрон, который уже имеет наиболее близкий набор весов, адекватный входному сигнал, тогда он в первом сработает, Он, во-первых, подавит остальные нейроны, из-за него сработает нейрон ВТА, который подавит остальные нейроны ВТА. Черные связи – это взаимоблокирующие связи. Остальные точно не сработают, хотя на них подается стимуляция. Этот нейрон ВТА он откроет, простимулирует. Я говорил про вентильные симпонсы, которые переводят нейроны из активного в пассивное состояние. Нейрон ревгейд обычно пассивен. Чтобы он стал активен, он должен получить по этому вентильному симпонсу спайк. Он откроется и станет активным. а на него тоже подается стимуляция от метки класса. А вот сам он является источником допамина, допаминового спайка. Тогда, когда он откроется, он, соответственно, под влиянием внешней стимуляции от ClassLabel испустит допаминовый спайк на нейрон L, и нейрон L подкрепит те синапсы, которые приняли участие в генерации им спайка, пусть и с их помощью, но все-таки. Но когда таких актов будет несколько, у него уже настолько вырастут его собственные веса, что он уже без внешней помощи сам ответит нужным образом, срабатывая на узнаваемый им эмпатер. тогда он будет просто подкреплен этим временем RefGate, но если он сработает сам, то тут такая механика, что он заблокирует BiasGate, поскольку дальше эта стимуляция внешне уже не будет нужна, он начнет работать. Таким образом, мы получим, что у нас сформируются нейроны L, которые специфически реагируют на распознаваемые им паттерны, сдаваемые меткой их класс. И более того, не просто на свои, но еще и на разные варианты. То есть, допустим, если мы решаем какой-нибудь МНИСТ, то там четверка может быть написана кучей разных способов. И нам бы хотелось, чтобы каждый нейрон Это одна колонка, то есть в одной колонке может быть несколько нейронов fail, назовем это микроколонкой, этой триплетой, чтобы каждый из них реагировал только на свой вид написания четверки. А так оно и получится, потому что когда мы проявили какую-то четверку, написанную одним способом, то она сработает, но остальные нейроны не сработают, они будут заблокированы, они не получат вознаграждение за эту четверку. Зато они получат возрождение на другие четверки, потому что на другие четверки этот нейрон уже не сработает, а сработает другой нейрон L. Теперь у вас сформируется столько простимулированных нейронов L с повышенными весами, сколько разных начертаний этой четверки есть. То есть это некая архитектура, которая позволяет решать любые задачи классификации общего образа сетей. Это только колонет. На чем мы это все тестируем? Разумеется, пока что у нас игрушечные задачи. но уже требующие вполне применение Model-based. Например, задача с пинг-понгом. Задача с пинг-понгом охраняется тем, что мы знаем информацию о координате шарика, о его скорости по х и по у, координате ракетки, но мы не знаем, пока что мы хотим, потому что мы получаем вознаграждение и наказание только тогда, когда ракетка либо отбивает шарик, либо его пропускает. То есть у нас, пока шарик не достиг левой и левой стенки, мы ничего не знаем. У нас нет ни плохого, ни хорошего. Поэтому у нас редкие сигналы наказания и вознаграждения, нам надо догадаться, чего от нас хотят. Ну вот, это хорошая тестовая площадка для реализации проекта таких всяких. Антон, а сколько у меня еще времени? Еще минут 15 есть или сколько? 

S00 [00:52:43]  : Ну, у нас час-полтора, поэтому вот уже еще... А, ну, хорошо, час-полтора, да? 

S01 [00:52:48]  : Тогда я минут 15-20 еще. Теперь, как вы, собственно говоря, остальные, по классификации, под номером 1 с галочкой, под номером 2, оценка текущего состояния? Вот тут нарисована похожая такая колончатая архитектура, которая позволит делать оценку текущего состояния вот такую вот градуальную. Вот самая левая часть – это фактически сеть, которая классифицирует те состояния, которые являются целевыми, которые отмечены получением, собственно, самого настоящего реворда из внешнего мира. Это классификационная сеть, которая действует по принципу, близкому к тому, что я уже изложил. Но когда она научена, она сама начинает реагировать на приход системы в целевое состояние и является источником для обучения следующего, более правого сегмента, То есть, фактически, правый сегмент, второй, более правый сегмент, он начинает классифицировать те состояния, которые предшествуют целевому состоянию. И так далее. Такой ряд может продолжаться вправо. Таким образом мы получаем классификационные модели, которые нам отличают все более и более далекие от целевого состояния состояния. Соответственно, по изменению активности этих популяций, мы можем судить, хорошо мы делаем или плохо. Если у нас была активно третья, слева, популяция, а ты стала активно вторая, Значит, мы что-то хорошее сделали, мы приблизились к текущему состоянию. То есть это уже переключение активности с третьего на второй уже может быть источником собственного внутреннего сигнала реворда, который мы можем использовать для понимания, что нам здесь делать, если мы в состоянии номер 3. Ну и наоборот, если мы были в состоянии номер 2, а стали номер 3, то, значит, что-то плохо сделалось, нам такого делать не надо. То есть, ну, я не буду рассматривать, как эта архитектура работает, она работает на том же, в общем, примерно, принципе, на том, который я изложил, когда говорил про колонны. Хотя тут небольшое отличие связано с тем, что у нас не имеется запаздывания. То есть там мы одновременно получали и сигнал метки, и сигнал описания, а тут они запаздывают. То есть у нас сначала формируется описание, а потом мы через какое-то время узнаем, что это, оказывается, целевое состояние, то есть тут имеется некая рассинхронизация. Это учитывается в этой архитектуре, я сейчас не буду ее анализировать, но в общем принцип тот же самый. То есть с помощью нейронов-гейтов мы отбираем только тот нейрон, который должен быть простимулирован. Отчасти решена задача и нахождение динамики внешнего мира, ну, по крайней мере, если ее можно как-то представить в виде какого-то гонечного автомата, пусть даже с большим количеством состояний. То есть у нас эти вот отдельные колонки — это теперь у нас сети, фиксирующие какое-то состояние внешнего мира. И нам надо найти переходы, то есть нам надо найти, после связи между этими колонками, их сила формализует вероятность того, что после состояния такого-то будет состояние такое-то. То есть нам надо эти переходы фиксировать. Опять же используется очень близкий принцип. То есть тут сеть должна угадать, вот мы сейчас находимся в таком состоянии, что будет следующее. То есть, соответственно, те веса, которые соответствуют связям более частым, они будут более часто подкрепляться, и это будет фактически восстановлением этой матрицы вероятности переходов между этими состояниями. Это, ну, тут это в таком простом варианте, да, когда у нас одна колонка одно состояние, но, в общем-то, это можно, это может быть применено и в более сложных случаях, когда у нас это не конечная автомата, а когда, допустим, У нас какая-то есть линейка взаимоотношающих состояний. Это у нас один параметр, второй параметр, еще одна линейка других состояний. Понятно, что у нас декоративное произведение было бы очень большим. А тут мы просто это все формализуем, и у нас каждый такой ансамбль формализует только какое-то одно измерение, одну размерность этого состояния. То есть это делает такую систему вполне обозримой по объему. Ну и вот, в принципе, таким образом можно выучить модель динамики внешнего мира. Другое дело, что пока непонятно, как мы эту модель применим для планирования. Как я сказал, эта проблема пока не решается, и есть только некие наметки. То есть да, мы матрицу получили, но теперь нам надо еще сделать некий прогноз. Как это сделать, не очень-не очень понятно. Вот. То есть, по крайней мере, более подробно вещи не будут останавливаться. То есть, чего мы сейчас хотим? Чем мы сейчас занимаемся? Вот как раз этими нерешенными компонентами, которые нам нужны для того, чтобы воплотить Model Based TRL в полном объеме. Вот они здесь перечислены. Они уже могут быть перечислены. Я пока не буду говорить, ну, потому что это сыро. У нас, в принципе, есть ответы некие предварительные на том, как это делать, но это все-таки, наверное, лучше оставить, когда мы хотя бы на уровне профилюмконцента это продемонстрируем. Это как бы как раз тема занятий нашей научной группы на ближайшие пару лет. Ну и немного о технике процесса. Чем мы, собственно говоря, пользуемся в нашем исследовании? Поскольку, разумеется, тут теория, тут, конечно, дело хорошее, но ее тут очень мало, потому что эти системы очень сложно исследовать эмпирически. Хотя мы сейчас ведем такую работу, у нас, возможно, будет проект, связанный отдельно с этим, с теоретическим анализом всего этого дела. Но все равно одним из главных средств исследования у нас остается вычислительный эксперимент. А для этого нам надо на чем-то эмулировать импульсные нейронные сети. Ну, физически, если мы говорим о нашей платформе, то сейчас, разумеется, импульсные нейронные сети – это максимально не фон Неймановские штуки. Нам надо не один большой процессор, который умеет все, а нам надо миллион мелких процессоров, которые умеют только одно – генерировать спайки, грубо говоря. Сейчас такого нету, к сожалению. Из того, что есть у всех, и то, что к этому наиболее близко, это GPU. Ну, тут мы как бы, так сказать, похожи на обычные нейронные сети, от которых тоже используются сломаны. Поэтому первым инструментом, которым мы пользуемся, это эмулятор нейронных сетей на GPU. Ну, есть такой эмулятор, он называется ArnieX. Это моя собственная разработка. Но вообще таких эмуляторов в мире довольно много. Их там дюжина или даже две дюжины больше. Мой Arnex имеет некую особенность. В отличие от всех остальных, я решил, что нам надо описывать нейросети не формируя их с помощью питоновских вызовов, как делают большинство из эмуляторов, а мы их будем описывать декларативно, на языке XML. что гораздо проще и, более того, даёт возможность делать с сетями некие формальные операции. Если мы хотим как-то сеть преобразовать, а сеть у нас формализуется питоновскими вызовами, то это даже сложно сделать, потому что надо менять программу, это автоматически сделать сложно. А если сеть формализуется некоторым описанием на XML, то можно формальными способами её преобразовывать, что хочешь с ней делать, поэтому это очень удобно. Ну и, кроме всего прочего, это гораздо проще, не требует программирования. Ну, в общем, вот такая вот механика, я сейчас не буду о ней говорить, просто это я вкратце о том, что мы ее пользуемся. Ну, хотя, разумеется, оно дополняется для гибкости всяческими API, которые позволяют ее применять и в потенциальных всяких промышленных применениях, системах реального времени, просто, скажем, доступ, получение сигналов, там их... Наоборот, их интерпретация и всякие вещи, связанные с реконфигурированием динамическим сети, даже такое возможно. Все это делается с помощью API. Но основная структура описывается на XML. Вот, допустим, это какая-нибудь простая сеть, которую там какой-нибудь мист классифицирует, он вот так выглядит. Ну и она описывается вот такими вот XML-овскими конструкциями, то есть чисто декларативное описание. Это вот как бы основная фишка моего подхода, и пока что мне она очень нравится и позволяет делать следование очень быстро. Но это GPU. А вот на самом-то деле мы хотим не GPU, на самом-то деле мы хотим настоящие нейропроцессоры, И очень надеемся, что такие появятся. Мы очень надеемся на проект Altai, который делается мотивом. Но в этом случае наша группа будет пользоваться другой системой, тоже очень мощной, но она более традиционного подхода, потому что там тоже питоновский интерфейс. Это то, что сейчас разрабатывает лаборатория Касперского. платформа КНП, Касперский нейромаркет-платформ, которая как раз позволит, ее главное достоинство, то, что она позволит использовать Altai нейропроцессор, причем не только тот, который сейчас есть, Altai-2, который очень хороший, конечно, чип, но он не умеет обучаться, жесткая только для инференса, но и Altai 3. Вот Kaspersky Network Platform это очень мощная штука, которая к тому же является опенсорсовской. И вот, как мы надеемся, она позволит в полном объеме использовать всю мощь Altair 3 и делать это просто. И наши исследования в дальнейшем, когда будут доступны эти уже совсем правильные нейрочипы, они будут вестись на этой платформе, которую мы сейчас активно развиваем, поскольку я являюсь сотрудником лаборатории Касперского. Ну, опять же, не буду говорить о механике этой штуки. Это довольно-таки прогрессивная вещь, которая сделана с учетом ошибок и слабых мест других эмуляторов. Это просто слайд, который просто не знаю для чего. Это очень крутая внутренняя вещь. Вот. Ну, наверное, все. То есть, пока это вот сейчас вот на ArmyX, а впоследствии это будет, когда это будет на Altai, то это будет KNP. Это главное, значит, следство разработки всего этого дела. Тогда, наверное, на этом я в целом закончу. Как раз минут 15 можно подискутировать. Ну и вот всяческие там лейблы, ссылки и все прочее. Да, то есть я вот и из Чегу, но и одновременно из Касперского. Вот еще есть наш группа в Telegram, в которой мы все это обсуждаем. Ну и вот проект Ornex доступен. Правда, не стоит на телефоне там сайт не оптимизирован. Если кого интересно, то обращайтесь по удовольствию ко мне. Все, спасибо. Ну, надеюсь, что не очень сбивчиво, да, как-то более-менее логично. Очень надеюсь, что это выстроил, но если кому-что непонятно, давайте обсудим, поговорим об этом. 

S00 [01:04:58]  : Ага, Михаил, спасибо. У меня тут много вопросов. Давайте начнем с вопросов из Google. 

S01 [01:05:07]  : Отключу доступ к экрану. 

S00 [01:05:10]  : У меня сразу только вопрос по поводу Altai. То, что вы показывали, это все-таки вы на эмуляторе пока делали, правильно? 

S01 [01:05:19]  : Это сейчас делается, вот то, что я показывал, сейчас делается на GPU, но на Altai, вот то, что касается RA, на Altai уже продемонстрированы некоторые другие вещи, но они связаны, скорее, с классификацией. Ну, вот как мы на нашей конференции в Касперском показывали, там всякие распознавания скорости вращения вентиляторов, ну, такие более типичные задачи измерительно-классификационного такого свойства. РЛ пока что мы и демонстрировали на Алтае, ну и все-таки тут хотелось бы демонстрировать не инференс, а обучение, потому что РЛ — это обучение. Обученную РЛ как-то не особо прикольно. А это надо ждать третьего Алтая. Поэтому мы с нетерпением его ждем и, надеюсь, как только мы его получим, мы сразу на нем РЛ будем как-то имплементировать. 

S00 [01:06:09]  : На третьем Алтае можно будет уже с эмуляции на ГПУ переходить на реальное железо, да? Да. 

S01 [01:06:17]  : Насчет ГПУ, кстати, сейчас я одну маленькую вещь добавлю. Пока еще мне непонятна очень простая речь, которую я никак не удосужусь выяснить. Насколько все это имеет смысл на каких-нибудь промышленных ГПУшках типа Джетсона. Возможно, уже там это будет из-за спайковости, из-за внутренней экономичности, связанной даже не с железом, а с идеологией, уже может дать какой-то выигрыш. Так почему-то я ни разу не попробовал, хотя, может быть, там это тоже имеет смысл. Даже до Алтая. 

S00 [01:06:46]  : Да, если я правильно понял, то... А, я хотел вот что спросить. Вот этот Алтай, он по габаритам какой? То есть, грубо говоря, если мы задаемся вопросом, насколько... У меня другой вопрос. Насколько то, что вы рассказываете, далеко от того, чтобы это все встало на борт чего-нибудь там движущего, ездящего, летающего? Насколько это все габаритно, энергозатратно? Уже недалеко. 

S01 [01:07:17]  : Вот у меня где-то была фотка, где я держу платку небольшую 16 Alltime на руке, она маленькая такая штучка. Ну, в общем, разумеется, очень низкоэнергопотребляющая, не буду сейчас говорить цифры, я их просто не помню. Но это уже можно ставить на... Всем нам понятны устройства ледающие. 

S00 [01:07:39]  : Понятно. Хорошо. Так, вот здесь вопросы. Коллеги, просьба, вопросы пишите не мне лично, а пишите в общий чат. Я сейчас несколько вопросов переслал. из лички. Первый вопрос Александра Тетеркина. Зачем нужны импульсные нейронные сети? МНС – это продукт эволюции, а мы сейчас имеем более эффективные протоколы. Приведите примеры пользы эмуляции именно спайков нервной системы живых организмов. 

S01 [01:08:20]  : Да, это, конечно, первый вопрос, который у всех возникает. Спасибо большое, но совершенно логично. Зачем что-то лучшее, когда это все хорошо, да? Ну, во-первых, собственно, Главная причина первоначальности этой деятельности – это, конечно, энергоэкономичность. Она не самая главная в моих, так сказать, прямым мнениям, но это как бы исторически самое главное. То есть, ну, понятное дело, что эти самые интенсивные нейросети, они отнюдь не только для микро-девайсов, не только для микротронов, они в том числе и для большого интеллекта тоже. В общем-то, это, по крайней мере, моя цель – это движение в ту сторону. Всем известны планы отдельно атомной электростанции под ВПТ-5, ВПТ-6. Ну, это я так обобщенно говорю. Дальше это безобразие, конечно, не может так просто увеличиваться, это понятно. И это один из прямых путей энергономичности. Но не только это. На самом деле то, что в индустриализированных сетях участвует время, они во времени живут, это динамические системы. Поэтому если мы хотим взаимодействовать с чем-то, что развивается во времени, учитывая пространственные временные паттерны, задержки, запаздывания, временное планирование, то это наиболее естественно делать на импульсных нейросетях, потому что в них время – это один из факторов вычислений. Если мы хотим использовать… большое количество никак не связанных, явно никак не синхронизированных агентов, маленькие нейрончики, они друг друга не знают, они только импульсы получают, они не имеют никакой команды, что все обновитесь, ничего такого. То, опять же, это наиболее естественным путём, кажется. Какие есть проблемы? Проблема в том, что, во-первых, это всё имеет смысл только на специальном железе. Разумеется, если мы будем делать импульсные нейросети на обычных, хотя вот под Jetson, я, кстати, сказал, это действительно так, может быть, уже стоит попробовать и на этой или на этой базе, то это всё не будет иметь больших преимуществ ни в энергии, ни в чём. скорее всего. То есть мы ждем пришествия большого количества новой микроэлектроники, которая отчасти уже есть. У нас там есть всякие обзоры в интернете, какие сейчас уже нейрочипы имеются. Акида, и там очень много-много-много основательных тянечек. Но вырезаться здесь самое главное. Тогда это будет. Это заиграет по новинке. Пока что это вопрос фенологичный. Да, действительно, пока мы на ГПУшках, ну, в общем-то, преимущества не вполне ясны. 

S00 [01:11:11]  : Вот так. Вопрос от Романа. Как вы планируете реализовать взаимодействие между модулями прогнозирования и исследовательского поведения в условиях спайковой природы сигналов? Особенно интересуют моменты с relay-in, relay-out нейронами и их связью с памятью МЕМ и управляющими гейт-элементами. Ведь в классическом подходе Model Based TRL мы обычно работаем с непрерывными значениями, а тут нужно как-то совместить дискретную природу спайков с необходимостью строить предсказательные модели внешнего мира. Плюс, как будет работать мета-обучение в контексте супервизорного модуля? Будет ли он также спайковым или вы планируете использовать гибридную архитектуру? 

S01 [01:12:01]  : Ну, мы, конечно, хотели бы использовать чисто спайковый подход, потому что, в общем, как я сказал, на самом деле интерфейсы здесь, ну, все портят. То есть хотелось бы, чтобы все было спайковым, но не знаю, насколько это максимум, насколько оно реально. Это вопрос исследований. Тут даже проблема не в том, что они спайковые или не спайковые, а проблема более логического плана. Например, планирование. Мы должны запланировать, вот мы научились каким-то переходы, но когда мы планируем, мы должны те же самые нейроны активировать, которые у нас обучались, но при этом мы должны понимать, что это сейчас не реальное состояние А, а это мы думаем о том состоянии А для планирования. А нейроны те же самые, то есть мы должны либо каким-то образом переносить веса обученные. Вот у нас есть первичная сетка этих нейронов, которая на реальных данных обучилась. Но на планировании нам нужны не идеальные данные, нам нужна цепочка активации, чтобы она не приводила к тому, что мы думаем, что мы сейчас реально... То есть, грубо говоря, мы должны подумать, что к чайнику нельзя прикасаться, потому что он горячий, но это не значит, что мы сейчас подумали, мы должны отдернуть чью-то руку, у нас нет чаяния. Как разделить логику планирования от логики обучения, потому что мы должны еще в то же время обучаться, то есть процессы должны быть совмещены, у нас инкрементальное обучение. Скорее, вот это главная проблема, потому что в остальном Если мы такую механику будем иметь, ну да, вот у нас вероятность активации, это будут вероятности переходов, в сущности говоря. Если у нас большие ансамблии нейронов, то, в общем-то, эти вероятности, они как раз будут выражаться этими весами статистически. Это большие темы статистически, поэтому это как бы нормально. Но вот вопрос логического плана, который я сказал, пока нам не вполне ясно, как их решить. Вот это та же проблема, допустим, как со сверточными сетями. Да, разумеется, можно сделать импульсную сверточную сеть, но только непонятно, как их обучать. Это я немножко о другом проекте. Импульсная нейронная сеть может быть сделана, но поскольку нет бейдшаринга, то мы должны ее обучить где-то вне, а эти веса уже железно встроить в систему. То есть мы не можем сделать обучение, потому что у вас веса локальные. 

S00 [01:14:34]  : Но вот тут такая же немножко проблема. Понятно. Спасибо. Здесь еще Александр Тетеркин спрашивает, вышлите ли вы презентацию. И вопрос от Романа. В планах на Алтай-3 заявлено обучение на чипе. Как вы планируете реализовать сложные механизмы пластичности, особенно дофаминовую модуляцию СТДП, непосредственно на аппаратном уровне? И какие компромиссы между точностью энергопотребления и скоростью обучения предполагаются? 

S01 [01:15:07]  : Спасибо. Вот на этот вопрос у нас есть как раз очень чёткий ответ. Потому что всё, что мы делаем, мы делаем именно с тем, чтобы это всё умещалось на крайне ограниченные ресурсы RTI 3. Поэтому вот те механизмы обучения, те законы пластические, которые я показывал, они содержат практически ничего. У них даже нет экспонентов. Там изменение весов, они на фиксированную величину. Это даже не как СТДП, если вы помните, в СТДП там две экспоненты, которые... Изменение веса в зависимости от разности прихода спайков, и там это разность надо экспонировать с сложными числами. Здесь никаких экспонентов нет и практически нет даже мультипликативных операций. Изначально делается все, чтобы умещать это в очень простую логику, ограничиваясь в основном только аддитивными операциями и простой логикой. Пришел до, пришел после в течение какого-то времени, это какие-то счетчики времени, ну и все. То есть, как раз это не проблема. Это мы все умещаем. Причем все результаты, которые мы показываем, показываем уже на тех же самых, на той самой механике классической, которая будет имплементирована на Altai. Только я ее априори не могу представить. 

S00 [01:16:26]  : Тогда вопрос уж про Altai разговорили. А как он смотрится по сравнению с мировыми аналогами? 

S01 [01:16:37]  : Ну, это вы про Алтай-2, который сейчас есть, или про Алтай-3, который в будущем? 

S00 [01:16:41]  : Можно и про тот, и про другой. Как мы смотримся на фоне, значит, на этом фронте? 

S01 [01:16:48]  : Ну, Алтай-2 – это, в общем-то, скорее аналог Трунос, потому что он не поддерживает обучение. То есть, главного плюса, который есть в логике, у него нет, потому что он не пластичный. Поэтому тут как бы сравнение. не может произойти. В сравнении с Tronors, он, в общем-то, более мощный, потому что, например, у Tronors совсем беда с весами, у него фактически вес только, ну, там 2 бита на вес, да, и той использует, может, только 3 значения из этих. То есть там практически веса они мега-дискретная. Здесь ситуация гораздо лучше, там навес, насколько я помню, существенно большее количество бит, там, по-моему, на один нейрон мог быть 16, что ли, разных значений весов, то есть уже, ну, какое-то нормальное значение. То есть в плане функциональности это более богатая функциональность, чем у TrueNorth. то у нас более старый чип. По сравнению с другими, точно так же, допустим, он подходит для подхода INN и SNN. Есть подход, в котором мы просто не обучаем ничего импульсного, а просто мы берем обычную нейронную сеть и делаем эквивалентную ей спайковую сеть, а это можно сделать, там есть формальный результат, говорит, что импульсная сеть может приблизить обычную сеть большого количества нейронов. Поскольку там есть такая вещь как graded spikes, то есть там в спайке не обязательно бит, а это может быть к ним привешено еще действительное число, то этот подход, который сейчас часто используется в других процессорах, в этом смысле он такой же, как, допустим, Akida. То есть, ну, нормально смотрится. Если говорить об Altai 3, ну, во-первых, это, конечно, скоро не убитого медведя, пока еще его нет, но то, что планируется, учитывая то, что он будет микропрограммный, то есть он будет довольно гибкий, ну, Пока что я вижу, что это будет круче, чем логики, но в любой стороне это зависит от имплементации. То есть как это будет напечатано, как это будет работать, это надо смотреть. Замысел очень крутой, но как это будет реализовано, неизвестно пока. 

S00 [01:19:07]  : В схеме B показана каскадная структура. Как вы планируете бороться с проблемой затухания или наоборот лавинообразного распространения активации по такой цепочке? Особенно интересует механизм стабилизации при обучении. 

S01 [01:19:25]  : Ну, если это речь, слава богу, о второй структуре, которая иерархию состояния, которая позволяет оценивать непосредственно целевое состояние, предшествующее, близкое, ну, об этом, наверное, идет речь. Да нет, там, собственно, я не вижу, почему там будет какое-то лавинообразное чего-то. Наоборот, у нас сначала вот эти более далекие, более левые компоненты, более левые популяции, они вообще будут неактивны, поскольку изначально там веса, афферентные веса, они нулевые, то есть без внешненаправленной стимуляции они сами ничего не будут делить. Только когда обучится предыдущий слой, тогда он будет стимулировать следующий, И, ну там опять же, ну даже, то есть я не вижу, там нет никаких положительных связей, я не вижу откуда там может быть что-то там катастрофическое. Это если вот об этом, да. Поэтому временная синхронизация между ними и премасштабирование системы. Я тоже тут не очень понимаю, что здесь имеется в виду. Ну, хорошо, масштабируем систему, но... Если говорить об этих микроколонках, их не может быть много, потому что, в частном случае, если вернуться к МНИСТу, пусть не МНИСТ, пусть мы собачек рассматриваем каких-нибудь, все равно этих сильно отличающихся архетипов собачек, их не миллион, а десятки. Мы стабилизируем здесь, в этом смысле, не будет. Опять же, я говорю, что если мы говорим о классификации состояния внешнего мира, их может быть, конечно, миллиард, но мы не будем классифицировать каждое состояние. Мы разложим их на компоненты с тем же шариком. Шарик может находиться там, но если у нас дискретность 10 на 10, то он может находиться в 100 разных точках. Но мы не будем делать как 100 состояний. то есть мы будем декомпозировать состояние на компоненты. А в этом случае тоже их не может быть миллион. Может, я не понимаю вопрос про масштабируемость, но если он про это, то тут и такой проблемы нет. 

S00 [01:21:46]  : Спасибо. Роман, если требуется, вы можете голосом пояснить ваш вопрос. А я тут дальше иду по вопросам. По поводу Алтая. Понятно, что Алтай – это альтернатива ГПУ, учитывая, что сейчас активно развиваются и другие подобные проекты. Тунос, Лойхи, китайский Тианник. Как вы видите развитие этого направления? То есть оставаться на GPU. Я так понимаю, вы ответили на этот вопрос? 

S01 [01:22:15]  : Ну да, нет. Если будут доступны эти нейропроцессоры, то вся моя деятельность направлена на то, чтобы перенестись на них. GPU это как некий палеотип, некое временное решение. 

S00 [01:22:28]  : Понятно. И проблема градиентов. Планируете ли вы использовать подход SLIER или двухэтапную стратегию для обучения? и как это будет реализовано на уровне аппаратного обучения в Altai 3? 

S01 [01:22:40]  : Нет, не планирую. Я думаю, что вполне можно обойтись в принципе без градиентного обучения на основе тех принципов обучения через фиксацию корреляции, о которой я говорил. 

S00 [01:22:57]  : У меня еще вопрос по поводу забывания. Вы говорили, что у вас, я не помню какими словами это произносилось, но я так понял, что у вас система, если сигнал какое-то время не подкрепляется, то он забывается постепенно. Правильно? 

S01 [01:23:20]  : Да, вот одна из очень важных проблем в любом обучении, если мы говорим про реальный мир, и тем более в обучении с подкреплением, это проблема катастрофического забывания версус переучивания. То есть, если мы чему-то долго учились, то нельзя допустить, что мы это быстро разрушили. Это, так сказать, номер раз, да? Каким образом это решается? У нас есть две разных механики, направленных на борьбу с этим явлением. Ну, отчасти они немножко в разных контекстах применимы. Первая из них применима скорее в контексте unsupervised learning, вторая – supervised learning. В случае вот с unsupervised learning, где, на самом деле, не требуется, как правило, точная настойка весов. Там достаточно, чтобы во многих таких сдачах, достаточно, чтобы веса были как в воздействии на насыщение. То там работает механика, связанная с ресурсом и весом. Соответственно, у нас меняется быстро и сильно в больших диапазонах ресурс, но вес по седьмой. Если у нас большой ресурс по абсолютной величине, то он застывает на минимуме или на максимуме. Мы обучаем ресурс, он гуляет по оси, но вес при этом мало меняется. Если мы загнали ресурс в большие величины, чтобы изменился вес, нам надо много отрицательных, плохих примеров. Мы не можем просто с умом его разрушить, мы заданы в режим насыщения. А для случаев супервайзливания, где нам важна именно точная настройка весов, нам используется другая механика, связанная со стабильностью так называемой. То есть у нейрона имеется дополнительный элемент состояния, он называется стабильностью. Он определяет меру пластичности нейрона. То есть, если нейрон, у него высокая стабильность, то у него нету пластичности, его веса меняются. Вот эти дельты, на которые меняются веса, на тех графиках, которые я показывал, они не константы. Они зависят от пластичности. И в процессе научения мы не только меняем веса, но мы еще и меняем пластичность. То есть, когда у нас нейрон научен, он высокостабильный, у него стабильность высокая, у него нет пластичества, он дальше не учится. Чтобы его переучить, нам надо много-много-много раз его наказать, грубо говоря. У него сначала уменьшится пластичность, вернее, стабильность, а только потом начнут меняться веса. То есть, у нас обучение – это процесс второго порядка в своей сути. То есть мы не только веса учим, но мы еще учим и изменение весов, меру изменения. Опыты показывают, что это позволяет бороться с статическим забыванием. Он делает обучение стабильным, но в то же время не оставляет у нас приучивания. Во-первых, за счет того, что у нас имеется ресурс нейронов, который не используется в этих ВТА. в ВТА-популяциях, там активно бывают 3-4 нейрона. Если у нас появляется какой-то новый паттерн, которого раньше не было, у нас из этих 3-4 нейронов ничего не активируется, потому что это новый паттерн, он не соответствует их весам. У нас тогда имеется шанс для активации других новых нейронов, которые раньше молчали. То есть у нас имеется некое депо еще необычных нейронов. Более того, у нас еще имеется миграция нейронов. То есть если у нас нейрон с вами подавлен, он начинает мигрировать, он пытается подсоединяться к другим входам, чтобы найти, нащупать свой паттерн, где он еще в какое-то место, где еще нет подавления, где он не конкурирует ни с кем другим нейроном. Вот за счет этого мы реформируем проблему и катастрофического обучения, и доучивания чего-то нового. 

S00 [01:27:05]  : Спасибо. Еще вопрос у меня был по поводу архитектуры. Когда вы говорили, что у вас нет структуры, нет связей, означает ли это, что у вас полная connectivity? 

S01 [01:27:20]  : между нейронами? Нет-нет-нет, наоборот, как раз у нас где-то, ну, там, фулл-коннективить, если мы говорим о связях нейронов со входами, которые пластичные, неизвестно, какие из них должны быть сильные, какие слабые, но вся более служебная часть сети, она, наоборот, совершенно четко фиксирована там они очень четко упорядочены, структурированы, как раз они реализуют логику обучения. И там как бы нет никакого хаоса, там, наоборот, очень регулярные такие системы. А вот афферентные компоненты, где высокий элемент самообучения, unsupervised learning, Самоорганизации там, да, там более хаотично, то есть там мы не знаем априори какие у нас должны быть структуры, какие связи должны быть реально, какая должна быть технология. 

S00 [01:28:16]  : Спасибо. По поводу РЛ, по-моему, этот вопрос задавал весной, когда вы спрашивали по поводу положительного и отрицательного подкрепления. Вы реально используете и положительное, и отрицательное подкрепление? Если да, то вы сравнивали эффективность обучения, когда используется только положительное, или когда используется и положительное, и отрицательное? 

S01 [01:28:41]  : Да. Да, причем более того, мы можем сделать это с гиперпараметром. У нас есть реакция на положительный спайк и реакция на отрицательный спайк. И мы можем с помощью генетического алгоритма посмотреть, чему равна оптимальное соотношение между этими двумя вещами. Вот для задачи с камерой, с этим простым Model Free Rail выяснилось, что там наоборот очень велика роль Роль наказания. Он не столько учится находить пятно, сколько учится от него не уходить. Но я думаю, что это на самом деле сильно зависит от задачи. На самом деле задачи очень разнообразные. Где-то нам важно достигать, где-то нам важно не упустить достигнутую и относительную роль этих двух процессов, она разная. А они как раз контролируются, в сущности говоря, двумя ветками обучения положительного и отрицательного. В случае с этим самым шариком оказалось, что вес, помимо отрицательного, должен быть раз в 20 больше, чем положительного. Тогда будет оптимально. 

S00 [01:30:06]  : Получается, что в этой ситуации кнут полезен. Да. 

S01 [01:30:13]  : Во всех моих моделях используется и то, и другое, и наказание, и прощение. 

S00 [01:30:20]  : Их комбинации работают лучше, чем только одно из них? Однозначно. Понятно. Интересно. Спасибо. И второй еще метод. Вы как-то исследовали, как отложенность подкрепления, насколько она ухудшает обучение или делает его вообще невозможным? Или у вас отложенного подкрепления не было? 

S01 [01:30:46]  : ну, как, вот, в сущности говоря, отложенная просто редко, то есть для того, чтобы ракетка движется медленно, поэтому, чтобы она отразила шарик второй сдачи в пинг-понге, надо заранее позаботиться об этом деле, значит, а не сразу. То есть тут мы должны сделать сейчас действие, а то, что оно будет полезным, окажется только известным через какое-то количество, через какое-то время. Разумеется, да. Это вот в случае с Model 3 такие вещи, ну, трудно, да, сделать. То есть для этого нужно элементы планирования. То есть, это то, на что мы сейчас как раз направлены. 

S00 [01:31:24]  : Я даже обострю ситуацию. То есть, отразить ракетку – это еще ерунда. А в классическом ПОНГе из Open AI Gym, там же плюшка-то идет не за отражение ракетки, там плюшка идет за выигрыш. То есть, отразить мало. Она должна еще куда-то там попасть. 

S01 [01:31:45]  : Ну, попасть... Я... Насчет классического пинг-понга от Алиска, он такой нет, он только отразить, по-моему. 

S00 [01:31:53]  : Я про Эппо-Найджину говорю. 

S01 [01:31:55]  : Мы пока, даже чтобы сотразить, тоже целая история. Тут все зависит от скорости ракетки, на самом деле. Если ракетка у вас быстрая, то мы можем действовать в принципе в режиме Model Free Rail и все будет хорошо. Если у вас ракетка медленная, То есть, чем медленнее ракетка, тем надо более сложный рэль делать. Понятно, да? То есть, у нас всё параметризуется очень простым одним фактором. Ну, пока с более быстрой ракеткой мы хорошо, а с медленной ракеткой мы плохо. Она требует отражения от стен, там начинаются всякие вещи, которые пока мы не можем. 

S00 [01:32:35]  : И ещё тогда есть у нас ещё время на пару вопросов, да? У меня, да, я... универсальности, применимости замены, спасения глобуса от атомных электростанций для ЖПТ-6. Насколько применимо то, что вы делаете, допустим, для unsupervised learning на последовательных данных, в том плане, что мы же можем последовательным данным тем же самым текстом относиться, решать задачу предсказания следующего токена как будто в RL. То есть мы просто бежим по последовательности, все время предсказываем следующий токен и по ходу дела учимся. Потому что каждый следующий токен оказывается либо угаданным, либо нет. Мы любую задачу обучения на последовательных данных, в том числе текстовых, можем реформулировать через задачу URL. И то, что вы рассказываете, можно использовать для построения моделей, которые будут работать с текстами. Или каким-то, может быть, другим способом. Вы вообще видите, как то, что вы делаете, может быть отмасштабировано для того, чтобы строить языковые модели? 

S01 [01:33:59]  : Да. Тут дело только в одном. Это очень высокий порог вхождения. Чтобы языковая модель не совсем не вызывала гомерического смеха, она должна быть очень большой. В отличие от… пинг-понг понятен и даже он требует каких-то тысяч нейронов. Тут все определяется тем, что на GPU я не очень большие сети могу моделировать, частотехнически. Это, скажем, мой пакет Ornix, он позволяет где-то до 100 тысяч нейронов. Боюсь, что хоть сколько-нибудь, хоть даже в концепт логистические задачи требуют существенно больших сетей, ну и просто пока это нереально. Это будет реально, когда это будут реальные нейрочипы, потому что там все будет на порядке быстрее, чем на GPU. На GPU это все-таки трудно делать, большие сети на GPU. А там они должны быть большие, иначе смысла ни у кого не будет. 

S00 [01:34:59]  : Насколько вы видите, возможно, при выходе на соответствующее железо, воспроизвести большие языковые модели на импульсных сетях? Или это как бы задача... Я думаю, что это возможно. 

S01 [01:35:16]  : Вот те же самые наши архитектуры, связанные с классификацией колонет, они могут быть сделаны иерархически. Очевидно, что такие штуки должны быть иерархичны, в первую очередь. Понятно, как делать их иерархичными. То есть принципиальных проблем я здесь не вижу. Проблемы в данном случае только с экстенсивным планом. Нам надо иметь много технических процессов, чтобы в какое-то реальное время моделироваться. 

S00 [01:35:45]  : Технических я не вижу. От меня последний вопрос, если, конечно, ответ на него не является секретом. Насколько мы далеки от практической реализации? решений, которые товарищ на видео показывал, пугающим пару лет назад про применение этих микродронов роевых. Или то, что Ольга Ускова описывает под названием «Джимми» в романе «Раша», если кто-то читал. Насколько автономный роевой дроновый интеллект нас ждёт с применением этих технологий? 

S01 [01:36:28]  : Если он и будет, то он и на этих технологиях, потому что там энергоэкономичество будет принципиальным моментом совершенно. И поскольку именно в эту точку мы бьём, то если он и будет, то будет именно на такой элементной базе, скорее всего. 

S00 [01:36:45]  : Понятно. Коллеги, есть ещё вопросы? Хорошо. Михаил, огромное вам спасибо. Спасибо большое. Спасибо вам также за внимание. Было бы любопытно услышать ваши новые результаты через полгода-год. 

S01 [01:37:09]  : Я постараюсь, чтобы они были. Мы работаем. Не я один, а еще мои аспиранты. Нас пять человек. 

S00 [01:37:15]  : Успехов вам и вашим аспирантам и коллегам. Коллеги, всем спасибо за участие. Спасибо вам. 

S01 [01:37:20]  : До свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
