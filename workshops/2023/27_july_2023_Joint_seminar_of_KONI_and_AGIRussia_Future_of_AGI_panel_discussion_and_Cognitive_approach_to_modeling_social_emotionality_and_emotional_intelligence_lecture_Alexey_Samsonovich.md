## 27 июля 2023 - Объединенный семинар КОНИ и и AGIRussia: "Будущее AGI" (панельная дискуссия) и "Когнитивный подход к моделированию социальной эмоциональности и эмоционального интеллекта" (доклад) - Алексей Самсонович — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/8gQx_5YqqXM/hqdefault.jpg)](https://youtu.be/8gQx_5YqqXM)

Суммаризация семинара:

ТЕМА
- Семинар посвящен ключевым опережающим научным инициативам и сообществам русскоязычных разработчиков сильного искусственного интеллекта.

СУТЬ
- Документация семинара представляет собой запись обсуждения на тему будущего агентных систем искусственного интеллекта. В центре внимания - методика создания систем искусственного интеллекта, которые могут оперировать с социально-доказуемыми моделями поведения и знаний.
- Участникам семинара представлены примеры систем, которые могут завоевывать внимание человека и требовать использования его времени в виртуальных средах. Важность изучения способностей искусственного интеллекта моделировать человеческое мышление и чувства.
- Обсуждение центральной задачи создания искусственного интеллекта, способного к распознаванию и выражению человеческих эмоций, мимики, интонации, языка тела и жестов.

ДЕТАЛИ
- Приведены цитаты известных ученых и философов, таких как Фридрих Ницше и Константин Эдуардович Циолковский, подчеркивающие возможности человечества и его стремление к преодолению ограничений.
- В контексте семинара обсуждается идея о том, что можно создать машину, которая будет делать что угодно, если учесть возможности компьютерных систем и их рост в возможностях.
- Значительное внимание уделяется возможности использования нейросетей для создания виртуальных сред, которые могли бы заполнять социально приемлемое взаимодействие и даже эмпатичные функции.
- В деталях описывается использование нейросетей для выполнения задач виртуального психолога, включая определение психологического типа человека, и использование нейросетей в реализации разговора с GPT в контексте виртуального коктейль-партии.

РЕЗУЛЬТАТЫ
- Важность разработки новых подходов к моделированию и системам искусственного интеллекта, которые могут включать анализ эмоций и связанных с ними социальных функций.
- Обсуждение рабочих групп хотя бы в двух областях технологий системы искусственного интеллекта касательно взаимодействия с человеческими реальность и когнитивной извращенной функции цифровых восприятий.
- Отсутствие полноценных методов измерения эмоций в абстрактных системах, требует их дальнейшему формализованию для предвидения эффективной социацией и инсинкейтизацией важных исторических образов социальных и автоматизированных поисковых инструментов





S10 [00:00:05]  : коллеги всем добрый вечер сегодня у нас необычно объединенный семинар ключевые опережающие научные инициативы и сообщества русскоязычных разработчиков сильного искусственного интеллекта вот и панельную дискуссию сегодня проведет алексей симсонович Вот, и потом доклад тоже будет Алексея Самсоновича по теме, которую он раскроет нам после окончания дискуссии. Алексей, передаю вам слово. Спасибо. 

S05 [00:00:40]  : Добрый день, коллеги. Итак, мы начинаем девятое заседание семинара ночевые и приезжающие научные инициативы, объединенного с семинаром AGI Russia. Я так понимаю, это название его, да? Значит, сегодня у нас первый час будет посвящен дискуссии. на очень интересную тему. И чтобы как-то ее определить, я вначале хочу напомнить вам несколько известных цитат. Вот, значит, для начала я покажу цитаты Ницши о том, что Человек – это канат, протянутый между животным и сверхчеловеком. Величие человека в том, что он мост, а не цель, и любви в нем достойно лишь то, что он переход и уничтожение. Чем-то связанная цитата Константина Эдуардовича Циолковского, который сказал, что человечество не останется вечно на земле, но, поклонясь засветленным пространствам, сначала робко проникнет за пределы атмосферы, затем завоевывает в себе все околосолнечное пространство. И в будущем, может быть, мы будем жить у солнца, которое еще теперь не возгорелось, а существует лишь в зачатке. Я бы скорее воспринял эту фразу как аллегорию. Дальше еще парочка цитат Джон Фон Нейман. Вы настаиваете на том, что есть что-то, чего машина не может сделать. Если вы скажете мне, чего именно машина не может сделать, я всегда смогу создать машину, которая будет делать именно это. И цитата Норберта Виннера. Отдайте же человеку человеческое, а вычислительной машине – машинное. В этом и должна, по-видимому, заключаться разумная линия поведения при организации совместных действий людей и машин. Но вы заметили, что цитаты у меня были расположены в хронологическом порядке. И вот теперь, я думаю, что я мог бы сказать сегодня по этому поводу. Я бы сказал следующее. Во-первых, человек не останется навсегда зазначенным в биологическую оболочку, дарной ему природой. Во-вторых, с помощью созданных им технологий человечество сможет преодолеть любые границы своего развития. И в-третьих, будущее человечество – это бессмертие наилучшего, что в нем есть, воплощенного на другой основе. Ну, после таких слов я, конечно… Горю желанием выслушать ваше мнение по этому поводу. И вот для этого мы организуем дискуссию с участием четырех ярких индивидуумов. Это Константин Вячеславович Воронцов, заведующий лабораторией машинного обучения и семантического анализа Института искусственного интеллекта МГУ. завкафедрой математических методов прогнозирования в МКРМГУ, завкафедрой машинного обучения цифровой гуманитаристики МФТИ. Я просто удивляюсь, как возможно сочетать столько ответственных должностей и все успевать. Игорь Пивоваров. Я понял, там очень длинный список его должностей и ролей, но вот я выделил две. Это главный аналитик Центра искусственного интеллекта МФТИ и директор конференции Open Tops AI. Михаил Киселев, доцент кафедры актуальной математики ЧГУ, руководитель лаборатории нейроморфных вычислений ЧГУ. Александр Владимирович Болдычев, философ, член ассоциации футурологов России. Если есть что дополнить, я буду рад. Итак, формат нашей дискуссии следующий. По каждому вопросу я зачитываю вопрос. На ответ отводится каждому панелисту до двух минут. При этом слайдами пользоваться нельзя. Затем идут перескрестные вопросы между панелистами. И после исчерпания всех вопросов принимаются вопросы из зала. Вопрос первый, вопрос нулевой, точнее говоря, о том, о чем мы будем говорить. Что мы понимаем под AGI? Каким должен быть AGI, чтобы цель его создания считалась достигнутой? Будет ли он репликой человека или чем-то разительно отличающимся от человека по своей сути? Каким будет взаимодействие с ним? Будут ли пользователи писать код, объяснять свои потребности на естественном языке или просто одобрять те или иные идеи, предлагаемые AGI? Какую форму примет интерфейс, да и сам компьютер? Будут ли это очки вроде Apple Vision Pro, мозговой имплант или человек вообще будет не нужен? Итак, кто из вас четверых хочет начать и ответить на этот вопрос? 

S03 [00:05:44]  : Давайте я попробую. 

S04 [00:05:46]  : Давайте. Тут, конечно, некая часть этого вопроса не связана с моей профессиональной деятельностью, поскольку, понятно, об этих вещах сложно говорить профессионально. Нет таких профессионалов. Поэтому это просто разговор частного человека. Хотя отчасти он базируется на моем профессиональном опыте. Ну, я считаю, как бы, своей позицией, что создание АГИИ – это просто эволюционный процесс, такой же, как смена, так сказать, динозавров млекопитающими и так далее. Поэтому это не то, чтобы прямо… Конечно, она увлекается как наша цель, но это на самом деле не цель наша, а это просто некий эволюционный процесс, некая новая стадия. Ну и, разумеется, будет какая-то преемственность, поэтому он не будет совсем нечеловеческим, как там нечто непонятное и непонятное. Будет некое продолжение человека. Собственно говоря, тут это связано с тем, чем я занимаюсь. Я думаю, что это будет нечто нейроморфное, поскольку я занимаюсь выпускными системами, это самые такие биологические реалистичные модели. то именно поэтому я ими занимаюсь, потому что я считаю, что это будет что-то такое околочеловеческое. Взаимодействие с ним. Ну, тут, конечно, взаимодействие будет точно. И это, опять же, еще почему я занимаюсь именно спайкерными сетями, потому что они приведут к тому, что это будет… размещаться в небольшие устройства, это не будет как FPT-3 размещаться в двух зданиях огромной кластер, это будет мелкая взаимодействующая жизни с человеком, а не только виртуально в виде вопросов и ответов. Насчет интерфейса, мозговой имплант, я, честно говоря, сомневаюсь. что это будет какая-то киборгизация прямая, то есть это будет дополнить человек, но не в виде каких-то имплантируемых девайсов. Вот, наверное, по четырем пунктам. Этим я быстренько ответил. 

S05 [00:07:45]  : Спасибо. Как раз уложились две минуты. Так, ну, кто хочет следующим? Я, между прочим, так и не услышал ответа. Вообще, я его не знаю. В чем цель и как мы определим, что она достигнута. Кто хочет следующим? 

S06 [00:08:13]  : Я сразу не соглашусь, что искусственный интеллект является продолжением эволюции. Биологическая эволюция, она все-таки основана на химических механизмах, ДНК, живая природа и так далее. А то, что мы создаем, это не эволюция вообще. И более того, между естественным и искусственным интеллектом может и не быть вообще никакой преемственности. Более того, то, что мы называем искусственным интеллектом, это всего лишь сборище технологий для автоматизации труда, для повышения производительности, для того, чтобы делать нашу жизнь комфортной. Вообще, надо, конечно, определиться с тем, каковы цели AGI. И если мы говорим о том, что эта технология должна копировать когнитивные функции человека, то мы сразу вспоминаем, откуда у человека его когнитивные функции. А это обусловлено естественным отбором и задачами выживания в естественной среде, в нашей биосфере Земли. Уникальной, может быть, на сотне парсеков в космосе больше такого нет нигде. И поэтому, создавая нечто, что столь же конкурентно, как и мы сами в нашей естественной среде обитания, мы вообще делаем себе самоубийственного конкурента. Зачем это надо? Я считаю, что это не надо, это вредно. Я шовинист своего биологического вида, и я считаю, что мы и мои прапрапраправнуки, да, там далеко-далеко в будущем, все-таки будут заниматься так же, как и миллиарды лет мы занимались выживанием, выживали как биологический вид и совершенствовались тоже как биологический вид. А всякие там наши технологии – это нам в помощь, это чтобы сделать нашу жизнь комфортнее. И мы сами отвечаем за цель и полагание. Вот с Норбертом Виннером соглашусь полностью. Хотя могу поспорить со всеми предыдущими цитатами. «Человек у человека, а машина у машины». Это наши послушные, можно даже сказать, рабы. Никакого самоосознания не должно быть. никакой субъектности, они просто помогают нам жить и функционировать в этом мире. И развиваться мы будем дальше замечательно, без всяких штырей в мозг, а как биологический вид, ну, наверное, мы как-то там изменимся через миллион лет, но точно не с помощью наших технологий. Пусть в природе оставим Природова. 

S05 [00:10:43]  : Да, осталось только понять, что такое человеческое, а что такое машинное. Вот в этом вся суть, понимаете, в этой детали, как говорится. Ну, об этом мы еще поговорим сегодня. Конечно, поговорим, да. Спасибо за ответ. Так, теперь, Игорь, может быть, вы… 

S09 [00:11:00]  : Да, давайте, да. Александр Балдачев любит последним, мне кажется, говорить. Хорошо. У вас тут слишком много вопросов на одном слайде, конечно, для двух минут. Что делать? Во-первых, я в каком-то смысле... соглашусь с первым докладчиком и отчасти не соглашусь со вторым я думаю что действительно развитие только не джай а скажем развитие интеллекта оно лежит как бы в плоскости на некой глобальной эволюции мы посмотрим на эволюцию как бы глобально на эволюцию жизни и то мы видим, что очень долго и очень медленно жизнь развивалась благодаря обучению, если так можно выразиться, в генах. Когда информация накапливалась в генах, это было достаточно долго, и все эти мутации, все это было достаточно медленно. Потом, когда появилась возможность в течение жизни как-то учиться еще без интеллекта, на уровне там рефлексов, каких-то реакций, то эволюционно эти особи стали намного более успешны. Потом, когда появились особи с интеллектом, и интеллект стал развиваться, то как бы это стало наиболее успешным. В этом смысле можно как бы видеть как глобальный процесс, что развитие интеллекта как такового, ну находится в общем в струе как бы некой глобальной эволюции. Другой вопрос, что я согласен с Константином в том, что я тоже как бы за биологический вид, и думаю, что, конечно, это как бы прерогатива все-таки биологических видов, хотя ну нельзя не отметить, что мы видим, что это в какой-то степени сейчас реализуется в машине. Насчет создания там ИДЖА или там целей, сложный вопрос, мне кажется, сколько людей этим занимается, столько разных целей, столько разных определений. Я вижу, что ИДЖА это некоторое, ну как бы, если хотите, направление большое, в рамках которых Разные люди по-разному для себя трактуют, но в целом двигаются в какую-то сторону изучения того, что им интересно. Мне, в частности, интересно мозг, как он работает. Сознание с детства интересно. Поэтому я этим занимаюсь. И напоследок еще скажу, что я в целом... не думаю и как бы не верю в бессмертие ни в какой форме думаю что это скорее неправильно и неполезно опять-таки с точки зрения глобальной эволюции это единственный процесс который мы видим смерть и как бы обучение в течение жизни и последующий поколение является фактически ну как бы единственным работающим механизмом эволюции сегодня главным механизмом поэтому бессмертие в любой форме но как бы думаю что там теоретически даже будет в этом смысле недостижимым что будет вредно для для эволюции в целом так комментарии спасибо так ну теперь александр 

S07 [00:13:50]  : Так, добрый день, господа. Спасибо за приглашение и уже за высказанное мнение. Значит, я займу какую-то позицию. Ну, во-первых, конечно, она у меня Совершенно будет экстравагантно в целом по обсуждению и крайнее, и вряд ли будет совпадать с кем-то. Но тут из выступающих я соглашусь с каждым. И скажем, с Игорем и с Микаилом по поводу эволюционизма. Все-таки хочется возразить Константину, эволюционизм это не только биологическая эволюция, это эволюционизм всей планеты и всего мира, во всей вселенной, и мы можем говорить, что как социум это определенный этап развития мира, последующий за биологическим развитием этапом, так и нас ждет какой-то следующий этап, постсоциумный этап, и мы стоим на пороге этого этапа. И вот из этого я буду исходить из своих каких-то взглядов и своих каких-то тезисов. Но соглашусь с Константином в том, что человек у человека. Что да, то есть как животные и ничего с животными не произошло после того, как появился социальный этап эволюции, так и с человеком ничего не произойдет. То есть мы останемся жить такими же человеками, как и жили людьми в своем же социуме. А вот то, что мы называем аббревиатурой АДЖИ или искусственное теле какое-то, это как бы то, что ждет в будущем. И как мы с ним будем общаться, я не знаю. По-разному будем общаться. Вполне возможно, мы даже не поймем, что это такое. И вспоминая цитаты, здесь следует вспомнить именно цитату, что человек – это мостик между животным и сверхчеловеком. Да, я с ней соглашусь только при одном условии, что сверхчеловек – это не человек. Это не человек. А человеку останется Человекова, здесь и соглашусь с Константином. А на эти вопросы, я думаю, что они действительно такие технические, и на них так трудно, столько много можно ответить с разных сторон, что я, наверное, даже не буду отвечать. 

S05 [00:16:00]  : Извините, я не хочу участвовать в дискуссии, просто хочу уточнить, что я понимаю. Правильно ли я понимаю, что, по-вашему, человек останется где-то в стороне, так же, как обезьяна, как курица, мышь, а эволюция пойдет дальше? 

S07 [00:16:14]  : Это называется принцип авангардности эволюции, что эволюция идет своим фронтом. То есть когда-то она шла фронтом химическим, когда шла фронтом биологическим. Последние тысячи, десятилетия тысячи она шла фронтом человеческим. Мы подошли к некому этапу и передаем эволюцию дальше, эффектную палочку. Остаемся жить, как живут животные. Вот животные, с ними ничего не происходит. Они просто продолжают жить, как и жили. Дальше не эволюционируют. Так и сообщество людей. Общество останется таким, как оно есть практически сейчас. А эволюция идет дальше вперед. 

S05 [00:16:51]  : Спасибо. Так, ну, поскольку времени у нас мало, я думаю, нам лучше сразу перейти к следующему вопросу. Потом уже перекрестные делать. Вопрос номер один. О будущих возможностях AGI. Должен ли искусственный интеллект быть наделен набором высших когнитивных функций, которые сегодня отличают человека как от других животных, так и от машин, а именно? Свобода воли, человекоподобное я, личность, целеполагание, свободное рассуждение о своих целях, о системе ценностей морали и идеологии, духовные идеалы и вера, мотивация, лидерские навыки, высшие эмоции, способность управлять ими, способность моделировать мысли и чувства людей, инсайт, креативность, активное обучение на уровне человека, а также другие сопутствующие способности. Пожалуйста, ну давайте в том же порядке, Михаил. 

S04 [00:17:41]  : Ну, на самом деле, вот в этом втором баллете, втором пункте перечислены многие вещи, одни из которых, ну, о них можно как-то высказываться и проверить, а другие, они в принципе непроверяемы, и о них даже сложно что-то сказать. Например, такое свобода воли, мы тут дискутировали в телеграмме, Это вещь, в принципе, непроверяемая, на самом деле. Чтобы свободу воли своей проверить, надо двух идеальных индивидов одинаковых поставить в одинаковые условия, посмотреть, будут они одинаково действовать или нет. Ну, разумеется, искусственный интеллект, если не брать все, что здесь написано, то он уже и так создан. Всякие вещи, связанные с рассуждениями, распознаваниями, чего угодно есть и так. Собственной мотивации еще нет, но ничего не стоит, мне кажется, ее смоделировать. Это не самое сложное во всем этом деле. Вот эмоции, опять же, поскольку в чужую голову не влезешь, будь она естественная, биологическая или компьютерная, то какие там будут эмоции у этого чего-то, судить будет невозможно. Улыбаться он будет, но, понятно, эта улыбка не будет значать ничего. Поэтому сложно говорить, все-таки я ученый, а вопросы, которые здесь заданы, они не очень-то научные. Духовно-билитеристически так я изменяюсь, если это немножко звучит как-то обидно. Поэтому я даже о них не могу ничего сказать, потому что, на мой взгляд, они не имеют смысла. Будет ли у нас свобода воли – не будет. На мой взгляд, бессмысленно, как мне представляется. 

S05 [00:19:30]  : Спасибо. Константин, пожалуйста. 

S06 [00:19:34]  : Коллеги, ну я продолжу свою мысль о том, что это никакая не эволюция и не интеллект, а его имитация, даже если это IGI, общий интеллект, это всего лишь орудие нашего труда. Всего лишь технологии в продолжении ряда, я не знаю, там, экскаватор, самолет, компьютер и так далее. Поэтому все ответы на вот эти вот вопросы Для меня категорически нет, потому что это наши технологии, наши помощники. Они помогают нам существовать, нам развиваться, развивать нашу человеческую цивилизацию. Нет и не будет никакой машинной цивилизации нам самим на погибель. Мы говорим об этом как о неком неуправляемом процессе. Тем не менее, управление научно-техническим прогрессом полностью в наших руках. И для этого всего лишь нужна идеология, которая давала бы нам цели полагания и понимание того, зачем нам цивилизация, зачем мы развиваемся, зачем нам машины. И вот в этом ряде вопросов мое категорическое нет, наш искусственный интеллект не будет продолжением эволюции, и это просто наше орудие труда. 

S05 [00:20:49]  : Спасибо. Так, теперь даю слово Игорю. 

S09 [00:20:57]  : ну честно я согласен с Михаилом здесь слишком много намешано разных как бы вещей в этом втором пункте про каждый из них можно было поговорить отдельно но я вот как бы скажу сконцентрироваться на некоторых скажу в целом так я здесь не согласен с Константином и с Михаилом с обоими то что она с Михаилом что теоретические вещи с Константином что это категорически не должно быть вложено в машину потому что без некоторых вещей здесь интеллекта в том понимании в котором мы хотим его создать вообще не будет но например свобода воли про которую говорили мы понимаем мир под человеком когда мы говорим что вот там он сильный человек который сам способен на все что угодно там сделаться чтобы решить любую задачу в частности это обозначает что когда ему ставишь задачу он волен как бы не алгоритмически он действует там идти сюда бери здесь копать здесь так делают очень примитивные люди, а он как бы может там выбирать какие-то пути достижения, может о них как-то думать про эти пути достижения, оценивать их, какими-то из них идти, ставить цели большие, ставить какие-то цели маленькие, то есть некоторые функции здесь должны быть воплощены в какой-то разумной степени в машине для того, чтобы она была интеллектуальной в нашем понимании, если мы хотим действительно настоящего интеллекта. А некоторые вещи, я бы сказал, уже воплощены. Вот, например, мораль, некоторые элементы морали. Чат G5, про который мы знаем, который нам тут, как бы, многим очень нравится, в особенности следующему оратору, то, значит, мы знаем, что он там специально был отдельный корпус, да, обучая, или такая отдельная там бригада до обучающих людей, которая как бы некую этичность ответов регулировала своими там со своей разметкой своей оценкой и тем самым я бы так выразился учат же пяти как бы изначально считайте большая свобода воли если хотите то есть он может давать много разных ответов это это не то чтобы свобода воли в нашем понимании учат же пяти Ну, некоторое, некоторое. Смотрите, вот есть алгоритм, который действует алгоритмически. Если то, там свободы воли нет. Это абсолютно как бы заданная жесткая линия. но если вы берете модель у которой заранее который не знает что она сделает и более того у нее может быть там 10 разных вариантов ответов но мы ее искусственно ограничиваем тем что заставляем ее выбрать ответ который этичен с нашей точки зрения то в некотором смысле на это можно посмотреть так что у нее определенная свобода воли была она как бы сформулировала но выбрала наиболее как бы приемлемый с точки зрения человека ответ так что коротко вернее так я прошу прощения за долгий монолог но я думаю что в Отчасти вот сильный искусственный интеллект, если мы про него там говорим, что это машина, которая настаивает там достаточно интеллектуально, с неизбежностью должна быть некоторыми, значит, функциями, которые здесь написано, быть наделена в некоторой степени, по крайней мере, не всеми. Здесь про некоторые можно отдельно поговорить, но вот часть, которую я привел, я надеюсь, что это достаточно ярко показано, что должно. 

S05 [00:24:18]  : Спасибо. Спасибо. Ну и Александр. 

S07 [00:24:22]  : Так, значит, ну прежде всего мне не очень понятна сама терминология, которая здесь возникла, почему это когнитивные все свойства. То есть когнитивно принято относить именно то, что относится к знанию, по знанию, а здесь у нас есть и животная психика, человеческая психика, есть духовность, есть мышление язык, что по сути когнитивному относится, есть творчество. То есть явно, что духовные идеалы, вера, мораль – это некогнитивные свойства. И поэтому здесь следовало разделить то, что мышление и язык относятся, свободное рассуждение, способность моделировать – это все к мышлению. Это заложено в саму задачу создания искусственного интеллекта. И вопрос, наверное, должен сформулироваться так. А нужны ли нам психологические какие-то свойства наделятия искусственного интеллекта и, скажем, духовные? Ну, с духовными, наверное, все однозначно, потому что мы прекрасно понимаем, что может быть великолепный интеллект человеческий абсолютно бездуховный. И говорить каких-то в духовности о вере здесь вообще бессмысленно. И с точки зрения психологии, эмоций тоже, мы прекрасно знаем, что есть многие ученые, интеллектуальные ученые, которые минимально ориентируются на эмоции, им эмоции вообще не нужны, холодные как кусок железа. И то, что Игорь говорит, нам нужна ли все-таки какая-то психологическая составляющая эмоциональная, то я считаю, что она в большей степени это наше наследие от животного мира. То есть просто человек не может дойти до интеллектуального уровня, не набив себе шишек, без обучения с родителями в школе, а это все эмоции, это все как какое-то осмысленное целеполагание. Но мы увидели, что буквально в считанные пару лет можно было без этого все это запихнуть в часть G5-4. без хождения под стол, без эмоций, без каких-то прочих вещей. 

S09 [00:26:31]  : Александр, но я не говорил ничего про эмоции и про психику, заметьте. 

S07 [00:26:34]  : Да, я согласен. И то, что говорить про цели и полагания, некую нацеленность на результат, это тоже в большей степени, мне кажется, от животного мира и дачи ее выжить. А целеполагание искусственного интеллекта задается внешними промптами элементарно. Скажем так, в животном мире, да и в человеческом между промптом и целью большое расстояние. И вот это расстояние заполняется какими-то целеполагающими движениями. А, скажем, даже в современных инструментах искусственного интеллекта там ноль лежит, то есть между промптом и ответом. И поэтому там нет места для какого-то собственного целеполагания, эмоциональной оценки. Ну и не соглашусь с Игорем, что у Чаджи Пити есть какие-то эмоциональные вещи. Это же просто эмулируется теми же самыми промптами. Если он понимает эмоциональную окраску текста и сам может окрасить эмоционально текст свой выдаваемый, это не значит, что у него есть эмоция. 

S04 [00:27:40]  : Ты говорил не про эмоции, а про мораль. Скажем так, возьмем это все в скобки и скажем, что все касается человеческой психики. 

S09 [00:27:55]  : Ну нет, тут уж вы сами определение делаете другие. Нет, Александр, это некорректно. 

S05 [00:28:02]  : Прошу прощения, можем мы соблюдать порядок? Я потом вам дам слово, когда будут перекрестные вопросы. Вы закончили, Александр? 

S07 [00:28:11]  : да да да наверное так то есть на мой взгляд что закончил скажу так что большинстве вариантов о чем говорил и михаил что мы даже не можем объяснить определить, есть ли что-то, какие-то эмоциональные, духовные составляющие, есть ли какая-нибудь свобода выбора, сознание или еще чего-то. Мы просто не можем предъявить, не можем предъявить человека, поэтому это обсуждать бессмысленно. И даже если мы предполагаем даже какие-то эмоции и целеполагания, мы тоже не можем это выявить, потому что судим только по внешнему проявлению, как и у человека. И не можем потыкать внутри сети и выявить там какие-то функции психологические. 

S05 [00:29:00]  : Спасибо. Я все-таки вынужден тут ответить по поводу терминологии в качестве оправдания. Я все-таки глубоко убежден в том, что слово cognition, следует переводить на русский не как познание, а как мышление. Вот я готов с вами поспорить на эту тему. 

S07 [00:29:23]  : Согласен, мышление, но тогда к этому не имеет никакого отношения. Все духовные термины – вера, мораль, система ценностей, высшие эмоции – это не имеет никакого отношения к мышлению. В любом случае здесь терминологически какое-то наслоение идет. 

S05 [00:29:37]  : Исторически все это как-то относится все же к… Ну не знаю, я исторически не сталкивался с таким. 

S06 [00:29:43]  : Когнитивные способности, когнитивные ученые, когнитивные исследования касаются мышления, познания, знания, но не… Мне кажется, что здесь не надо вдаваться в терминологические споры, потому что суть вопроса, она как раз развернута в нижней части, а именно, и понятно, что имелось в виду. 

S05 [00:30:02]  : Да, но я понял, что все же тут у нас доминирует несколько бихевиористская школа, отрицающая все, что не связано с наблюдаемым поведением. Ну, я не буду спорить, поскольку я, увы, сейчас в роли модератора. Так, перекрестные вопросы. Кто хочет ответить друг другу? Вот Игорь что-то говорил, извините. 

S09 [00:30:26]  : Ну вот, да, я был не согласен здесь с Александром по поводу, прям ярко не согласен, по поводу разжигания целеболагания, и между проблемой как бы ноль. там расстояние 0 это для очень примитивных вопросов и очень и очень быстрых ответов пишет что у меня интернет не очень хороший но надеюсь что будет слышно для по-настоящему больших целей нужно масса промежуточных всяких целеполаганий если ты говоришь человеку вот тебе миллиард долларов я хочу построить самолет построить самолет то как бы я извиняюсь но там нету нуля между промптом и ответом там далеко не 0 там сто пятьсот разных целей промежуточных будет и если интеллектуальным человеку такую задачу поставить, то он ее, в принципе, может решить. Он там наймет других людей, найдет, создаст команду, там сделал проект и так далее. Это вполне doable. Чарджи Пити, сегодняшний, который с текстами работает, понятно, что такую задачу он не решит. поэтому все-таки Александр когда вы говорите про цели полагания надо понимать что ну вот есть задачки маленькие где вот взять на 0 там дистанции а есть очень большие задачи и мы все-таки человечество привыкло называть интеллектуальными людьми тех кто решает большие задачи они тех кто как бы копает от от столба и до обеда 

S07 [00:31:57]  : Ну, я могу на это отметить прежде всего так, что я не считаю ни ЧАДЖИ-ПИТИ, ни другие будущие системы интеллектуальными в плане человеческом. То есть, что нельзя приходить с этой калькой, что человек действует вот так, у человека есть цель, и он достигает свои результаты вот таким-то способом. И если мы назовем ЧАДЖИ-ПИТИ интеллектуальным, то у него должно быть точно так. У него там может быть совсем по-другому. Вот из этого я исхожу, что, по крайней мере, на этапе обучения вот это целеполагание там отсутствовало. И будет ли оно в функционировании, я не знаю. Поэтому делать такую аналогию, что если мы называем вот нашу коробочку интеллектуальной и вот те сервера интеллектуальные, что там у них одинаково. Вроде как бы не совсем одинаково. 

S09 [00:32:47]  : Вы не знаете или вы думаете, что там целеполагание не нужно? 

S07 [00:32:52]  : Я думаю, что там, если есть какое-то целеполагание, то совершенно не в том виде, в каком это свойственном человеку, который садится и думает, как сделать самолет. Как-то по-другому. 

S04 [00:33:05]  : Можно я добавлю? Немножко забыли о том, что в принципе у АГИ есть две совершенно разные цели, которые никак не с тобой не взаимодействуют. Одна цель, она утилитарная – сделать супермегапомощника мегаинтеллектуально. Вторая цель – это сделать модель самих себя, чтобы познать, что мы такое. Естественно, что и методы, и все для достижения тех целей весьма различны. И надо уточнять, какую цель мы имеем в виду, когда мы ведем дискуссии. Понятно, да? 

S05 [00:33:38]  : Ну, мы начали вроде с этого. Но если все же цель даже первая – сделать супер помощника, неужели для этого ничего не нужно из перечисленных качеств и функций? 

S04 [00:33:49]  : Эмоции. А зачем нужно для того, чтобы сделать помощника? 

S05 [00:33:52]  : Вы знаете, сейчас занимаются люди и эмоциями, и целеполаганием в искусственном интеллекте. 

S04 [00:33:59]  : Я думаю, они достигают именно второй цели – про знания, как у нас это происходит. Они должны сделать мегапомощника, который будет радоваться или что-то еще делать. Зачем это помощнику? 

S09 [00:34:08]  : Сейчас, коллеги, а мне непонятно, почему Михаил и Александр, почему вы называете там «свободу воли»… или там целеполагания эмоциями. Я что-то не понимаю. Вы как-то все это разом относите к эмоциям. 

S05 [00:34:23]  : Это разные вещи, просто тут свалено все в пути. 

S04 [00:34:26]  : Это разные вещи. Я делю вещи на наблюдаемые и ненаблюдаемые. Вот эмоции – это вещи ненаблюдаемые в принципе. Ну, потому что понятно, что широкая улыбка на экране – это не является эмоцией. То есть, также является ненаблюдаема свобода воли, о чем я уже много раз говорил в наших бесконечных дискуссиях в Телеграме. Она ненаблюдаема, это не научная вещь. Там всякие там лидерские навыки, там способность к познанию, целеполагание – это все, безусловно, проверяемые вещи, их можно моделировать. вот я просто хочу разделить, в этом большом списке есть две категории, то, что проверяем, и то, что в принципе не проверяем. 

S07 [00:35:05]  : Я бы еще хотел добавить, я когда перечислял, отвечал, не обратил на то внимание, что вообще человек очень слаб своими эмоциями. То есть нужен ли нам помощник, который будет проявлять свои эмоции, как-то реагировать непонятно, неизвестно нам. То есть эмоциональное состояние очень как бы такое подвижное, неустойчивое. И поэтому не нужно путать что я вижу в многих текстах, что путают люди, что одно дело, что машина может распознать эмоцию и действовать согласно распознанной эмоции. Она может реагировать на что-то, включая какие-то эмоциональные окраски, кому-то ответить с такой-то эмоцией, с такой-то другой, но это совершенно не значит, что она внутри это имеет. Она должна понимать эмоции и действовать согласно учетам эмоций. Но как бы думать о том, что нужно какую-то эмоцию внутри, именно эмоциональное состояние внутри машины, а зачем? Нам это не нужно. У меня хватает домашних своих там близких, которые будут проявлять эмоции и все. Мне помощник не нужен эмоциональный. 

S05 [00:36:17]  : И вы сказали, что искусственный интеллект перехватит эстафету, а человек останется где-то сзади. Он будет без эмоций, без всех этих качеств, но он пойдет вперед. 

S07 [00:36:30]  : Конечно. Скажем так, мы живем сейчас в социуме, в котором основное является производство. Индустриальное, цифровое, всякое производство, которое было. Оно обладает живыми качествами? Нет, не обладает, но социум стоит на производстве, на экономике. Все эмоциональные качества, они остались у человека и у животных, которые были. Точно так же, когда уйдет следующий этап, поднимется на следующий этап эволюции, там никаких эмоциональных качеств не нужно. То есть для того, чтобы существовать, кавычка, этому искусственному интеллекту, ему не нужны эмоциональные подпорки. Эмоциональные подпорки – это наши подпорки в деятельности, потому что мы рождаемся маленькими, беспомощными, и в взаимоотношении с другими людьми нам нужна психика. Но искусственному интеллекту психа это не нужна для того, чтобы выполнять свои функции. 

S09 [00:37:22]  : Александр, вот с этим я бы поспорил, но коллеги, но почему же про эмоции? Вот я сейчас еще раз текст весь перечитал подробно. Здесь действительно в одном месте написано высшие эмоции. Но высшие эмоции это не эмоции. Вот здесь вообще нет на самом деле ничего почти про эмоции. Ведь Алексей так и написал этот текст внизу, что там нету простых эмоций в том виде, в котором мы их принимаем. Почему вы про них рассуждаете? 

S07 [00:37:48]  : Здесь все другое. Принимаю, принимаю. 

S04 [00:37:50]  : Я очень извиняюсь, мне ужасно интересно, мне так обидно, что я должен вас оставлять. 

S05 [00:37:55]  : Может, вы скажете что-то напоследок, bottom line, так сказать. 

S04 [00:38:01]  : Да я, собственно, сказал, наверное, все, что хотел сказать. Мне интересно других было послушать, но, к сожалению, я потом послушал запись. А так, ну да, оставаясь на позициях науки, сложно. То есть, да, безусловно, эта штука должна саморазвиваться, должна самосовершенствоваться, должна иметь возможность собственного целеполагания. Но надо ли действительно транслировать на нее и пытаться моделировать в ней какие-то человеческие вещи, как вот Александр говорил. Чтобы их познать, как они у нас реализованы в мозгу, наверное, имеет смысл. Но для чего-то больше, я думаю, нет. На этой мажорной ноте я вас покину. Очень-очень-очень извиняюсь и очень жаль. Спасибо. 

S05 [00:38:41]  : Огромное спасибо. 

S07 [00:38:42]  : Спасибо. Спасибо, до свидания. 

S05 [00:38:44]  : До свидания. Так, ну тогда мы перейдем к следующему вопросу. О регуляции ограничений. Ну, раз такие возможности есть, почему бы не ввести ограничения на него? В зависимости от ответа на предыдущий вопрос. Если да, ну, я так понял, что ответ был отрицательным большинством все-таки. Но все-таки, если да, то каким образом должны регулироваться права и возможности искусственного интеллекта в обществе будущего? Будет ли искусственный интеллект иметь равный с человеком статус в обществе в перспективе? Неизбежно статус выше человека, но если мы позволим ему иметь равный статус, то неизбежно он превзойдет. И если нет, то каким образом этого удастся избежать? Будут ли некоторые виды и функции искусственного интеллекта запрещены? И каким образом удастся соблюсти эти запреты? А когда запреты все-таки будут нарушены, не превратится ли искусственный интеллект из изгоя в высшую расу по стандартному сценарию? Ну, как мы знаем, вот на примерах некоторых человеческих рас. С последующим вырождением человека в обезьяну. Нам уже сказали, что это неизбежно, вырождение человека в обезьяну. А вот как раз человек, сказавший это, ушел. Тогда, Константин, вам слово. 

S06 [00:40:14]  : Ну да, много вопросов, но давайте так. Во-первых, мы уже имеем много опасных технологий, которые мы совершенно замечательно регулируем с помощью законов, стандартов, регламентов, техник безопасности и так далее. От управления автомобилем до оружия массового уничтожения. Все прекрасно регламентируется и регулируется. Я продолжаю свою линию, что искусственный интеллект это всего лишь наше орудие труда, и они тоже продолжат эту линию. Мы будем, естественно, законодательно все это регулировать. Никакой речи о высшем статусе, высшей расе, о том, что наши созданные нами машины будут выше нас, это бред полнейший. Мы вполне вправе и в состоянии этого не допустить. И в связи с этим у меня возникает вот какой вопрос. А почему мы так хотим создать интеллект, эквивалентный нашему? Вот здесь озвучены две цели AGI. Утилитарная цель – это наш помощник. И вторая цель – познать самих себя. Простите, но для этого, ни для того, ни для другого, не нужно создавать технологию эквивалентную. нам плохо. интеллектуальным способностям. И помощников мы прекрасно можем заточить под задачи, и нейрофизиологи про наш мозг нам скажут гораздо больше, чем попытки наши ущербные моделировать какие-то там нейронные сети. И вопрос, а почему же мы так хотим создать эквивалентную себе машину? И я нашел ответ. Коллеги, он многих удивит. Все дело в христианской философии. Которой пропитана вся наша история, вся история науки и развития европейской культуры. Здесь подспудный религиозный подтекст. Мы хотим создать образ и подобие себя точно так же, как Бог Израилев создал человека по образу и подобию себя. Мы хотим уподобиться Богу, даже если мы атеисты. Но это в нашей культуре. Ну вот для верующего человека такое целеполагание, ну оно глубоко греховно, поскольку копирование человека в виде машины, вот оно, ну вот это же от гордыни и от богоборчества с точки зрения верующего. Теперь, с точки зрения атеиста, или агностика, но это просто бесполезно и не нужно. Это какие-то впустую потраченные усилия, потому что наша цель – это развитие человеческой цивилизации. Нам для этого не надо создавать копию себя. Вот давайте осознаем просто дело в нашей культуре, в европейской и в библейской. Вот какому-нибудь индусу или китайцу в голову бы не пришла такая постановка задачи вообще, это за пределами их культуры. Вот такая у меня гипотеза. 

S05 [00:43:04]  : Спасибо. Так, Игорь. 

S09 [00:43:09]  : Я, с одной стороны, целиком согласен с Константином, А с другой стороны, на другом заострю, на этом вопросе. Мне кажется, что пока все попытки человечества как-то регулировать какие-то ограничения в данной разработке, все катастрофически проваливаются. Я не вижу никакого регулирования. Я вижу, что регулирование категорически стремительно опаздывает. и и на мой взгляд здесь проблемы не христианской философии потому что китайцы тоже сейчас активно стремятся к лидерству области и активно там пытаются сдавать модели хотя у них явно не христианской философии они просто подключились к общему тренду нет здесь здесь скорее просто проблема в другом то что демиоргом современного мира являются деньги и как бы и конкуренция базирующийся на деньгах и вот эти большие корпорации у них в каком-то смысле это любая корпорация любой бизнес стремится стать монополистом это очевидно поэтому каждый стремится сделать там некий инструмент который поможет ему там зарабатывать больше чем все это ведание начать так так создано и мне как раз вот этот вопрос регуляции смущает уже много лет я лично думаю и вижу что наверное так я с одной стороны согласен с Константином что пока мы видим что и это только инструмент но с другой стороны я вижу сколько групп по миру работает над тем чтобы создать вот тот самый и который вроде как нам совсем не нужен но они пытаются это сделать но просто потому что видимо человек это существо которое ну, все-таки недалеко ушла от обезьяны, и поэтому вполне себе может отпилить сук, на котором сидит. И поэтому, несмотря на то, что нам, вроде как, человечеству, казалось бы, не нужно создавать ничего подобного, никакого эволюционного конкурента для себя, тем не менее у меня ощущение, что по всему миру это активно делают, и никакое регулирование с этим не способно совладать. И в этом смысле мой прогноз такой, что сделают. как бы слишком много людей по миру с разными интересами с разными скоростями с разным финансированием но активно пытаются что-то такое сделать несмотря то что вроде как разумно этого делать не надо но делают и поэтому я не вижу здесь никакого никакой возможности пока регулирование честно в частности потому что когда мы говорим например про ядерное оружие там про которое оружие массового поражения, про которое Константин упоминал, все-таки для него раньше, ну все знают, что для него нужны большие мощности, достаточно большие ресурсы для изготовления, то есть в гараже этого не сделаешь. 

S05 [00:45:56]  : Его не нужно для искусственного интеллекта, между прочим. 

S09 [00:45:59]  : сегодня сегодня считается что этого не нужно для модели искусственного интеллекта что можно сделать гараже сегодня правда но последний тренд это опровергает то что большие модели которые демонстрируют сильные продвижения, они все-таки нуждаются в огромных учительных ресурсах, которые даже некоторым государством не по карману. Но, в общем, у меня ощущение такое, что пока я не вижу, чтобы... Я был, например, одним из людей, который подписал вот это письмо известное там с предложением приостановиться ненадолго и подумать и как-то бросить совместные усилия, но вот я не вижу, чтобы это хоть какое-то влияние 

S05 [00:46:40]  : оказывала в общем человечество продолжает пока идти в сторону которая как-то мне кажется не сильно поддается регулировать абсолютно согласен в том что остановить ничего нельзя в остальном конечно не совсем согласен спасибо извините так теперь александр 

S07 [00:47:05]  : Так, значит, ну, соглашусь с Константином и не буду повторять, что да, действительно, то, чем занимаются сейчас конкретные программисты, конкретные производители – это инструменты. Это, конечно, инструмент, который нужен для обеспечения конкретных функций. Вот мне он конкретно нужен, скажем, часть GPT, мне конкретно помогает решать какие-то задачи. Я ожидаю от этого инструмента, вижу, как он будет развиваться в дальнейшем, он мне нужен еще с какими-то улучшенными функциями. Но тут мы с Константином расходимся, я больше перехожу на сторону Игоря, что вот эти функции, они естественно уходят нас за пределы общества человеческого. То есть они переводят в какую-то область, в которой мы потеряем контроль над этими функциями. Я читал в статьях Алексея, у него давно была такая мысль, что у нас были разные функции в телефоне, калькуляторе, телевизоре, они соединились в одно устройство. Сейчас мы что наблюдаем? Сейчас с последними нововведениями ЧАНЖИ-5 И множество функций, которые раньше приходили в отдельные программы, реализованы на одном устройстве, в одном промоте. И мы идем в эту сторону, когда все функции объединяются в неявном виде в одном каком-то устройстве. Не устройстве, а сетевое что-то будет. И вот в этот момент мы можем потерять контроль. Но при этом я не считаю, что это будет какая-то железка, ходящая между нами, и мы должны ее контролировать. Мы потеряем контроль полностью. И поэтому сам вопрос вот этот про регулирование контроль, он делится на два вопроса. Как мы должны регулировать и контролировать то, что сейчас есть в социуме? Теми способами, которые есть в социуме. Есть законы, законы пишутся для человека, и если человек хоть как-то использует какие-то средства, сам человек отвечает за то, что он использует. Если тебе наврал что-то чат GPT, и ты это распечатал, выпустил куда-то в жизнь, ты отвечаешь. 

S05 [00:49:13]  : Простите, пожалуйста, я должен прояснить. Вопрос был не про чат GPT. Я, может быть… Нет, я как бы… Это вообще не относится к моему интеллекту, честно говоря. А вопрос был о том, что будет дальше, вот когда появится… 

S07 [00:49:28]  : Я отвечаю. Те устройства, которые мы используем и контролируем, мы отвечаем сами за себя, а то, что не будем контролировать, то и не будем контролировать. Поэтому сам вопрос немножко бессмысленный. То, что мы не сможем контролировать, оно уйдет от нас. Животные не могут контролировать производство, экономику. Ну и не могут. Ну и как, они вообще не понимают, что это такое. И поэтому вот эти особенно вопросы про вырождение в обезьяну, вообще не понимая о чем, откуда, какие-то стандартные сценарии. Стандартный сценарий у нас эволюционный один. Каждый предыдущий этап эволюционный служил основанием для последующего эволюционного этапа, никуда он не пропадал, ничего с ним не происходило. Это стандартный сценарий эволюционного развития. И по этому стандартному сценарию я считаю, что то, что мы называем ИИ, оно уйдет вперед на эволюционным фронтам и оставит нас в покое. Мы будем существовать за счет него, а он будет существовать за счет нас, за счет наших фронтов. Иначе ему нечего делать. Ну, наверное, все, больше нет вопросов. 

S05 [00:50:44]  : Спасибо. Если можно, я два слова все-таки отвечу. Если вот посмотреть на биологическую эволюцию, почитать Триорда Шардена и так далее. На самом деле, вот та ветвь, которая была лидирующей, когда она уходила, с роли лидера, она уходила в деградацию. Она, собственно, начинала деградировать. 

S07 [00:51:07]  : Я не знаю. Примите примеры, как полиция общества деградировала. 

S05 [00:51:11]  : Есть недоразвитые, а полигены... Возьмите, каких размеров она была миллионы лет назад и каких размеров сейчас. 

S07 [00:51:18]  : А, животные деградируют? Так все животные деградируют в специализации. Все ветки. То есть ни одна из веток животных не осталась, кроме человеческой. Потому что у всех появились ласты, лапы, либо отпадали вообще органы различные. То есть вся адаптивная эволюция идет в сторону деградации функций. Это как бы это общее место, конечно. Но мы-то говорим не о конкретных отдельных проявлениях, а о общем тренде. Общий тренд – эволюция дошла до человека и двигается дальше. 

S05 [00:51:53]  : Спасибо. Так, вопросы к другим панелистам. Кто-то хочет возразить друг другу что-нибудь или ответить? 

S06 [00:52:01]  : — Ну, всё-таки, наверное, не к деградации ведёт эволюция, а к приспособлению к условиям окружающей среды. Ну да, и какие-то формы... — В чём деградация? — ...рандиментарно отваливаются, когда они перестают быть нужными, всё так. Но нельзя всё-таки говорить, что эволюция ведёт к деградации. К приспособлению и усложнению жизни. Вот усложнение форм жизни мы наблюдаем, вот палеонтология нам об этом говорит довольно надёжно. 

S09 [00:52:29]  : я тоже хочу здесь заметить что меня честно говоря то есть я видел алексей вашу коннотацию коннотация этого вопроса ну как бы такая негативное выражение выражение человека в обезьян то есть вроде как если это сарказм извините Если мы сделаем и он пойдет дальше, то как бы мы вот типа станем как бы обезьяны условно. 

S05 [00:52:50]  : Но с другой стороны, я вот сейчас... С другой стороны, Ницше писал о том же. 

S09 [00:52:53]  : Я сейчас слышу Александра Балдачева, и он на самом деле говорит очень разумную вещь, что ну как бы человек останется человеком. Мы остаемся как бы на своей ступени эволюционного развития. Грубо говоря, я как там пил там свое венцо с сыром, так и как бы могу продолжить пить свое венцо с сыром. что здесь плохого, если я смогу продолжать или мои потомки смогут это делать ну как бы чисто по-человечески. я начинаю думать, что ну как бы в этом, то есть другими словами, я не стану сверхчеловеком и не смогу без скафандра летать по космосу, то есть я не смогу эволюционировать до такой степени там или у меня мозг не станет размером с пятиэтажный дом и он не сможет считать там все что угодно за доли секунды но как бы человек останется человеком то есть я бы сказал что я раньше об этом честно и сильно не задумывался но мне кажется что вот то что где-то и забыл дачев это хорошая коннотация в ней нет что-то прям сильно негативного то есть вы уже с ним соглашаетесь в это в этой части я пожалуй склонен согласиться я не думаю что там и будет как бы вы то есть я честно не думаю что говоря про то что эволюционно мы видим что интеллект это мейнстрим ну как бы у меня такое ощущение как как физика наблюдающего за процессом что эволюция как бы эволюция интеллекта это естественный процесс эволюции в целом Тем не менее, я не думаю, что надо серьезно говорить про эволюцию роботов и компьютеров, что это органичное продолжение эволюции вообще, и человек в этом смысле промежуточное звено этой некой эволюции. Вот так мне, честно говоря, не кажется. Не кажется, я такое не говорю. Да, я не говорю, что вы это говорите. Я сейчас, в принципе, как бы что... И в этом смысле, в этом смысле, ну, в общем... Вот. 

S05 [00:54:52]  : Сейчас, чем вы хотите что-нибудь ответить? Нет, у нас еще вопрос номер три. Хорошо, давайте вопрос номер три. 

S02 [00:55:05]  : Можно по этому вопросу? По второму? 

S05 [00:55:08]  : Да, по второму. Простите, нет, а вы не панелист у нас, да? Хорошо. Тогда ждите очереди, у нас будет еще возможность для аудитории. Сейчас до вас дойдет очередь. Это уже последний вопрос и ожидать осталось недолго. Итак, об ограничениях прав человека в связи с AGI. Человек уже имеет признаки вырождения. Ну, это я написал, просто не предвидя такого консенсуса, что это не так. В то же время возможности человека, вооруженного искусственным интеллектом, невероятно растут. Их будущий уровень и потенциальный вред, который они могут принести, трудно переоценить. По сути, человек все еще обезьяна. Ну, это, кстати, слова низше. Не готовая к новым возможностям. Поэтому возникают вопросы, каким образом должны будут регулироваться права и возможности человека в обществе будущего, кто или что будет их регулировать. Если не искусственный интеллект, а если будет так, то не придем ли мы к матрице, то есть к цифровому неофашизму? Во что тогда может выродиться человек? Может, прогресс следует заморозить сейчас, откатив человечество назад, в эпоху Средневековья, как минимум? Или же человек должен слиться с искусственным интеллектом в форме некого бесполого трансгуманоида, в котором именно искусственный интеллект станет гарантом благонамеренности и нравственной целостности. Кто хочет начать? Константин? Давайте я, если по очереди. 

S06 [00:56:48]  : Действительно, вопросов настолько много, что я неизбежно большинство из них оставлю коллегам, а вот прицепиться я хотел бы вот к чему. к матрице и неофашизму. Вот почему-то многие захотели в матрицу, посмотрев этот фильм. Это тоже надо отрефлексировать и переосмыслить. Это какое-то интересное социально-психологическое явление. На мой взгляд, объяснение такое. Видеокартинка оказалась красивой. Она страшная. Она безумно пессимистичная. Но она эстетически зацепила. И молодые люди туда захотели. Вот реально. Я же спрашивал людей, да, и вдруг мне говорили, что нам нравилось бы жить вот в этой матрице. Я такой от недоумения. Вы что, с ума сошли, люди? А вот они, да, действительно сошли с ума. Следующий момент. К фашизму приводят не технологии. К фашизму приводят наше непонимание биологической и социальной природы власти, элит. Какие личные мотивы движут людьми к власти? Как воспитывать людей, которые станут в будущем руководить цивилизационными проектами, развитием? опасности будет все больше, энергии будет все больше. А люди, которые ведомы животным стремлением доминировать, они вот будут новыми Гитлерами. И это страшно в фашизме, а не сами по себе технологии. И вот здесь вот возникает вопрос, что мы как-то все время заметаем под ковер социальное и психологическое, мы говорим о технологиях, но не разобравшись с природой человека, говорить об этом развитии преждевременно. Мы сначала должны ответить на вопрос, куда мы все вместе развиваемся как цивилизация. И не ответив на этот вопрос, дальше развиваться технологиями, вот я согласен с Игорем, стоп, надо подождать, только не полгода. Надо подождать до тех пор, пока мы не создадим цивилизационную идеологию, которая ответит нам на важнейшие вопросы. А куда мы вместе движемся – та. И ответить на вопросы о нашей природе человеческой, в частности, о когнитивных искажениях напомнят. Вот, например, мы общаемся с чат-ботом. Почему мы ему избыточно доверяем, вот этому самому GPT-чату? Да потому что мы привыкли общаться на естественном языке только с живыми людьми. Поэтому автоматически наделяем собеседника характером, личностью. субъектностью, которых у него нет и быть не может, потому что, ну, мы-то с вами точно знаем, как это устроено, да, это всего лишь интерфейс к знаниям человечества, который умеет говорить не более того, у него там никакого интеллекта нет, он, единственная задача, которую он решает, он слова предсказывает по контексту, больше он ничего не делает. Почему дикарь, попав в современный торговый центр, ужасно испугается манекена? Ну потому что для него столь похожим на человека может быть только человек, или дух, или мертвец. Ему будет страшно. И точно мы в таком же состоянии когнитивное искажение по отношению к ЧАДЖИ-5. Что нам делать-то? А нам учиться. Нам учиться познавать себя. и познавать свою коммуникацию с говорящими манекенами, избавиться от когнитивных искажений. 

S00 [01:00:03]  : Так это задача саморазвития. 

S06 [01:00:04]  : Но простите, мы уже далеко не обезьяны, хоть и с гранатами. Мы вот эту вот задачу саморазвития на раз решим за полгода. Поэтому, может быть, и правильно было бы поставить именно такой тайм-аут на полгода. Но что мы эти полгода делаем? Просто сидим, рефлексируем? Нет. Мы изучаем наши когнитивные искажения. И вопрос задаем психологам. А почему люди избыточно доверяют ЧАДЖИ-5? Почему там юрист пришел с пятью кейсами, которые ему придумал этот самый Чаджи Пити, доказывать, отстаивать своего клиента в суде, а ему сказали, все ваши кейсы выдуманные, а он сказал, ну я же не знал, я спросил у Чаджи Пити. Вот таких случаев, чтобы не было, да, значит, общество столкнулось с новой технологией, общество нуждается в... в каком-то образовании новом, в каком-то вот от научно-популярных до каких-то курсов, может быть, я не говорю психотерапии, но которые должны объяснять, как нам взаимодействовать теперь вот с этим нашим новоявленным големом. 

S05 [01:01:12]  : Спасибо. Так, Игорь, да? 

S09 [01:01:17]  : Да, но вся дискуссия и эти вопросы уже, по-моему, явно выходят вообще за пределы искусственного интеллекта, как таковые. Ну что, давайте. Давайте о том начнем. Про первый, так сказать, абзац, скорее, поговорю. Ну, во-первых, вы здесь слишком обобщаете, Алексей. Человек имеет признаки вырождения. Я могу сказать, что некоторые люди действительно без миллиардов. 

S05 [01:01:45]  : Движение BLM – это, по-вашему, невероятно? 

S09 [01:01:48]  : А некоторые люди меня восхищают своей продвинутостью, И таких людей, конечно, очень мало. То есть человечество – это некое большое распределение, там есть хвосты, есть какая-то середина, а середина, может быть, имеет тенденцию... Да, но я же говорил о признаках. Нет-нет-нет, но все-таки отдельные индивиды... Для меня человечество характеризуется не левой частью хвоста, где все вырождения, а правой частью хвоста, где яркие индивиды, которые задают тренды. В этом смысле я не думаю, что человек вырождается. но то, что вот вы пишете про то, что человек, как бы человечество, как бы в осредненном смысле, как такая обезьяна, которая получает колоссальные возможности, к которым она фактически не готова, вот с этим я скорее готов согласиться, и у меня на тему регулирования и на тему вот как бы подхода к этому есть давно некоторые, ну там, некоторые некоторые видения как это должно бы быть на мой взгляд сегодняшний мир во многом искусственно разделен как бы разделяется сильно политиками как бы обычным людям сильно у обычных людей сильно более схожи интересы все хотят нормально мирно жить а вот как бы есть масса политиков которые начать там которому не дает покоя они начинают там затевать разные там в общем все конфликты в мире вся вся вся сложность мира сильно связано с политиками и на мой взгляд ученые как некоторое слой общества должен быть по-хорошему вне политики и вот среди ученых есть понимание того что ну как бы здесь есть некоторые риски и дальше ученых, у людей, которые занимаются тем технологии, а я согласен с тем, что после тех технологий опасен человек, который технологии принимает, а не сами технологии применяет. У этих ученых есть как бы выбор, либо идти как бы в мейнстриме политиков которые говорят нам нужна технология потому что они вот как бы если у нас не будет то вот они и мы тогда мы тогда проиграем и все такие да да надо срочно бежать дел потому что они же мы выиграли мы же хорошие они как бы в скобочках плохие ну как бы так по такой дихотомии получается но в середине 20 века у научное сообщество все-таки нашло в себе силы разум и как бы сумела каким-то образом пусть даже противодействие части иногда там политикам как-то ну как бы найти общие точки поняв что все-таки технологии которые разрабатываются она сильно больше чем и там разногласия который нас разделяет и в этом смысле я абсолютно то есть как бы мы вынесом с константином поем но просто немножко с разных сторон заходим вот нам нужна некоторая общая единая цивилизационная концепция которой я считаю что политики не выработают это как раз задача вот это письмо которое было написано про типа на полгода заморозить оно же написано не политиками оно написано там учеными к ним присоединилось множество людей я считаю что вот это из научного сообщества должно идти некоторое саморегулирование если хотите некоторые здравое звено но для этого должны ученые из разных из разных стран ну как бы это осознать не из одной какой-то страны типа вот мы американские ученые мы такие хорошие давайте остановим а все остальные плохие вот это должно быть какое-то внутреннее движение внутри научного сообщества вне политики только в это я готов поверить и действительно ну какой-то выработка какого-то общего если хотите цивилизационного там плана на который отдельные политики в отдельных странах я прошу прощения боюсь что не способны 

S05 [01:05:34]  : Я не могу не ответить вам. Понимаете, у меня нет слова «политика» ни в одном из моих слайдов, и я вообще резко против того, чтобы политику впутывать в наши семинары. Это будет просто катастрофой для нас. А вы просто, мне кажется, терминологию неправильно используете, потому что тут речь идет не о политике, а о сознательности, о некотором общечеловеческом сознании ученого, которым он должен обладать, я считаю. Потому что просто быть движимым любопытством, как раньше нас учили, это, по-моему, неправильно. Ученый должен думать о том, что он делает и к чему это может привести. Но политика здесь ни при чем. – Окей, согласен. – Так, извините, я высказался. Хорошо, значит, ну теперь Александр. 

S07 [01:06:33]  : Ну я хоть держу мысль, Алексей, что политика здесь совершенно ни при чем, и разобью эту мысль еще дальше, что и ученые здесь совершенно ни при чем, и регулирование здесь совершенно ни при чем. Потому что само регулирование, вот само регулирование, о котором говорит Игорь, оно входит в эволюционный процесс. То есть обязательно при появлении чего-то, обязательно есть две стороны, которые прогрессисты и консерваторы. Кто-то тормозит, кто-то наоборот продвигает. И это обязательные элементы любого движения. То, что кто-то должен встать на защиту человеческую или кто-то рассматривать когнитивные искажения, бороться с ними, изучать, а кто-то продвигать какие-то духовные практики – это все заложено в развитие этого социума. И он как корабль идет и идет, на одном борту одно, на другом другое, в одной половине. Третье, кто-то там на мостике думает, что он как бы то, что крутит баранку, он чем-то управляет. А он идет и идет себе. Поэтому и сам вопрос, как мы должны это регулировать? Ну, по мере необходимости, естественно, если возникают какие-то проблемы, то методами человеческими, человеческими законами, человеческими, там где-то нужно правило дорожного движения, где-то запретить испытания, где-то еще что-то сделать, но остановить корабль нельзя, но регулировать нужно. И тут же сразу отвечаю, что никакого торможения прогресса быть не может. Нельзя. Даже если захотели, мы этого не сделаем. Не сделаем. Просто. Вы понимаете, мы не можем сейчас на нашей планете договориться о каких-то маленьких вещах, элементарных. Просто. Вы со всеми договоритесь, а китайцы сделают. А тут происходит так, что давайте-ка мы сейчас все проголосуем и вернемся в средние века. Ну, это же абсурд, конечно. 

S05 [01:08:35]  : А зачем голосовать? 

S07 [01:08:36]  : Атомная бомба вернет вас в средние века. Вы же договорились о политике не говорить. То есть, то, что может упасть в метеорит. То, что может быть какая-то буря солнечная снести все. Это не обсуждается. И то, что атомная бомба, это тоже не обсуждается. Обсуждается нормальное развитие. И мы находимся совершенно на нормальном этапе развития. То есть на конечном этапе завершения социумного эволюционного уровня. И с этой позиции как бы смотреть на то, что ах мы не знаем еще человека, да и не узнаем человека никогда. Это не позволено знать человеку. Мы будем как бы потихонечку что-то... То есть, скажем так, трудно себе представить, что через 10 лет, 20 лет или 50-100 лет люди придут к единой философии. Но не придут они никогда к единой философии. Если не придут к единой философии, то значит и не будет единого представления о человеке, о роли человека, о когнитивных искажениях. Единственное, что мы сейчас можем обсуждать, это как вписать в нашу жизнь тот утилитарный ИИ, о котором говорит Константин. И как-то осмыслить тот не утилитарный, который вообще не искусный и не интеллект будет, который вот я предполагаю, может быть я ошибаюсь, но я предполагаю, что все-таки что-то оно там должно быть другое, а мы останемся на своем уровне. Все, спасибо. 

S05 [01:10:15]  : Спасибо. Константин, Игорь, хотите что-нибудь ответить? 

S06 [01:10:19]  : Ну вот у меня осталась еще одна мысль, которую я очень хотел бы озвучить. Вот она, вот в чем. Что вот фокус интересов исследователей, он всегда смещается туда, где в данный момент образуется какая-то открытая проблема, вызывающая трудное. И это можно проследить и на примере развития компьютерных технологий. Ну вот смотрите, когда вы научились программировать на питоне, вам становится неинтересно программирование на ассемблере. Вот пусть этим занимаются узкие специалисты, которые создают драйверы, контроллеры, там еще что-то. Когда вы научились создавать архитектуры нейронных сетей для решения нетривиальных интеллектуальных задач, Вам становится неинтересно программировать обычные алгоритмы, пусть этим занимаются узкие специалисты, создатели всяких движков нейросетевых, коммуникационных, поисковых, игровых и прочих. Идем дальше. Когда вы понимаете, что ответы на вопросы, каким быть общему искусственному интеллекту, находятся не в математике, не в алгоритмах, не в компьютерах, а в биологии и в психологии человека и социума, вам становится неинтересно программировать вообще. Вам становится интересно создать цивилизационную идеологию, которая упорядочит взаимоотношения человека с его технологиями. Вот эта вот мысль. Да, и последнее, на правах рекламы. Дзен-канал «Цивилизационная идеология». Приглашаю к дискуссии всех, кого цепляет этот вопрос так же, как и меня зацепил настолько, что я перестал программировать. Мне это больше не интересно. Мне интересен социум и как технологии вписываются в социум. 

S09 [01:11:57]  : спасибо игорь я я пожал просто добавлю под конец что понятно что сейчас за такое короткое время и этот вопрос который поднимается и такие достаточно провокационные противоречивые там много разных позиций и мне в принципе важно и нравится я за то что хотя бы в российском сообществе хотя бы эти темы начинают обсуждаться что вообще вот эти темы все связанные с безопасностью и как такового они как бы в целом сообществах не любят обсуждать, но если в западном мире они хоть как-то обсуждаются, то как бы ну в российском сообществе оно какое-то ну вот вообще типа нам как бы совсем не до этого. И это мне кажется хорошо, что такого плана вещи должны быть, в дискурсе, в общественном они должны быть, а там, глядишь, может быть и найдется что-нибудь, какие-нибудь решения может быть найдутся. 

S05 [01:12:59]  : Спасибо. Так, ну теперь все-таки я вынужден дать слово вопросам из аудитории. Значит, вопросы к панелистам. Пожалуйста. 

S09 [01:13:12]  : У нас там рука Владимира Смолина есть. 

S05 [01:13:15]  : Да-да-да, я вижу. Значит, Владимир Смолин первым будет задавать вопрос. Я хочу попросить всех, пусть это будут все-таки не выступления, а вопросы. 

S00 [01:13:27]  : Вопросы я постараюсь не задавать, хотя… В смысле, выступления постараюсь не делать. Вот с 16-го я буду всё-таки рассказывать, как создать сильный искусственный интеллект, потому что тут был разговор о том, что он обладает больше вредом, чем пользой. Я просто хотел спросить, что всё-таки… Вот есть такое явление, как самоорганизация. И считаете ли вы создание сильного искусственного телевизора? 

S05 [01:13:58]  : А звук у вас пропал. Владимир Владимирович, пропал у вас звук. 

S09 [01:14:07]  : Да, у него микрофон, микрофон замедлился. 

S05 [01:14:09]  : Да, выключился почему-то. 

S09 [01:14:12]  : Ой, а Владимир у нас в двух постах. 

S00 [01:14:14]  : Сейчас включился микрофон, просто у меня тут, я тут на отдыхе и звоню с телефона. 

S05 [01:14:19]  : Антон, вы следите там. 

S00 [01:14:20]  : Значит, собственно, я продолжу, значит, что вот процесс самоорганизации и, собственно, есть ли какие-то, на ваш взгляд, как это вводится, не свойства человека, которые техническими средствами нельзя реализовать, и, собственно, почему вот этот телек должен быть боковой ветви. 

S05 [01:14:41]  : Так, ну это будет вопрос к кому? К Александру, который говорил о боковой ветве. 

S06 [01:14:53]  : Давайте я коротко отвечу. Самоорганизация это прекрасно. Самоорганизация это просто один из методов, которым можно строить модель решений и так далее. То есть никаких здесь нет. скажем, альфа-гоу. Фактический пример самоорганизации. То есть компьютер играет в игру сам собой и вырабатывает такие правила, которые люди, столетиями играя в эту игру, не находили. Прекрасный пример. Вот она и самоорганизация как инструмент для построения искусственного интеллекта. Прекрасно. 

S05 [01:15:34]  : – Спасибо. Ещё вопросы из зала? 

S00 [01:15:40]  : – Вы вопрос просто проигнорировали. 

S05 [01:15:43]  : – А в чём он был? Ещё раз можно напомнить? 

S00 [01:15:46]  : – Что саморганизация – это, конечно, не альфа-го. Это вообще процесс. Бывает там не живой природе, а в живой природе он основан на накоплении информации. И вот наши возможности по накоплению информации, они превосходят. И что у нас поэтому саморганизация более активная. А, соответственно, почему нельзя технически ускорить процесс самоорганизации, и почему это боковая веть, а не основная? 

S06 [01:16:14]  : Кажется, никто не говорил о том, что самоорганизация – это боковая веть. 

S07 [01:16:20]  : Но я могу сказать, как занимающаяся самоорганизацией этой темой, что тема вообще тупиковая, именно сама тема и то, что у нас мы наблюдаем в мире, никакой самоорганизации нет. То есть, или скажем так, что то, что физически называется самоорганизацией, все ячейки, бинары и все прочее, что связано с Пригожиным и с энергетикой, это не имеет никакого отношения ни к эволюции, ни к интеллекту, ни к чему, это просто физический эффект. И вся синергетика, которая философская, пыталась продвигать самоорганизацию, она вся загнулась лет 10-15 назад. 

S00 [01:17:04]  : со смертью Курдюмова уже вообще перестали упоминать эту самоорганизацию, и поэтому мне сам вопрос не очень понятен, потому что... Я поясню вопрос, что мой коллега Георгий Геннадьевич Малинецкий, он как раз ученик Курдюмова, и я достаточно хорошо часто с ним общаюсь, поэтому самоорганизация не умерла, и то, что жизнь является частью самоорганизации, это и Курдюмов не возражал, и его ученик не возражал. Да, я возражаю. И Воронцов явно озвучивал, что это боковая вес. Я именно на его слова ссылался. 

S07 [01:17:35]  : Ну понятно. А по поводу того, что что-то нельзя или нужно смоделировать в железе, но зачем? не очень-то понятно. Я явно на стороне Константина. Если нужно копать яму, нужно создать инструмент для копания ямы. Если нужно, значит, лететь, нужно создать инструмент для полета. Если нужно просто, скажем, умножать, возводить степень, нужно создать калькулятор. Если нужно преобразовывать тексты в какие-то действия, нужно создать часть GPT, которая будет читать эти тексты, делать суммаризацию и, скажем, переводить их в какой-то символьный вид для того, чтобы использовать либо в программировании, либо в управлении, еще как-то. Это совершенно утилитарная задача, не повторяющая то, что делает человек. 

S06 [01:18:26]  : А вот если нам придется создать георазведку и геологодобычу на астероидах, то нам придется создать искусственный интеллект, вот тот самый AGI, и отправлять туда наших интеллектуальных роботов. По-моему, прекрасная задача для общего искусственного интеллекта. Ну, правда, есть технологические барьеры. Не сейчас, не в этом столетии. 

S05 [01:18:51]  : – Не обязательно на астероиде, можно и на земле найти применение. 

S00 [01:18:55]  : – Есть много применений и на земле. 

S06 [01:18:57]  : – Но там же искусственный интеллект общего назначения. 

S00 [01:19:00]  : – Понимаете, какое дело, что власть и интеллект – это не синонимы. То есть, нам всегда рассказывают про меритократию, что, значит, лучшие идут во власть. Но если понаблюдать, многие считают, что это не совсем так. 

S09 [01:19:19]  : Мы не пошли в автопик, коллеги, нет? 

S00 [01:19:22]  : Но, значит, поскольку вы говорили, что это автопик, мы будем спокойно наблюдать, как наше общество гибнет под руководством политиков, а только говорить, ну что ж, вот такое явление. То мы, конечно, это обсуждать не будем. 

S05 [01:19:36]  : Так, тогда еще вопросы из аудитории. Я вижу у нас человек 20 или 30. 

S09 [01:19:42]  : Валерий Егоршев хотел там высказаться. 

S05 [01:19:46]  : Давайте. Давайте. Давайте, да. 

S11 [01:19:52]  : Слышно? Слышно. 

S02 [01:19:55]  : Добрый день. Я на самом деле хотел другой вопрос задать, но теперь уже в конце вопросы. У меня вопрос по самому тону, не тону, как правильно сказать, наклонности беседы. вообще поставленных вопросов речь идет про ограничения у меня вопрос а как бы а вот другие то есть если взять так вот мы это ну человечество искусственный интеллект а другие варианты вообще не рассматриваются ну или это в данном случае ну например не полностью независимое существование либо синергия то есть То есть, не ограничение, наоборот, расширение. В смысле? 

S05 [01:20:37]  : Нет, с этого мы начали. Я, кстати, это писал тоже. 

S03 [01:20:41]  : Про слияние. 

S02 [01:20:42]  : Про слияние с искусственным интеллектом. Просто, мне кажется, все равно слияние здесь не очень… Ну, опять, это я мнение. Форму вопроса надо преобразовать. А почему в такой вот георгической форме Или же человек должен слиться в форме некоторого бесполого трансгуманоида. Почему так? Да нет, ну это к примеру. Не обязательно так, конечно. Ну просто мне кажется, ну я как бы обратную связь дам. Мне кажется, возможности расширить человеку собственное восприятие мира с помощью искусственного интеллекта, ну у нас какие-то открываются ворота в космос, которые Получить ответы на те вопросы, на которые мы никогда не ожидали, даже не ждали, что ответим или получим ответы. То есть, вы считаете, что будущее как раз… Я считаю, что это скачок эволюции просто. Причем мне уже не важно, кто эволюционирует. Все вместе. 

S05 [01:21:44]  : Спасибо. Спасибо, да. Но я, тем не менее, хочу понять вашу мысль. Значит, скачок эволюции за счет соединения возможностей человека, возможностей искусственного интеллекта. 

S02 [01:21:56]  : У нас сейчас во многих местах в науке, я не знаю, даже в социуме мы тоже политику отгребаем, но у нас сингулярность сложности наблюдается. То есть мы уперлись в некоторые вещи, когда… ни разум, ни коллективные наши умения сложить, голосовать, не позволяют решать некоторые вопросы. И в этом смысле есть шанс, на мой взгляд, если появится сверхинтеллект, реальный интеллект, который сильнее, что, может быть, мы эти вопросы продвинемся дальше. В физике вопросов больше, чем ответов, и в социуме в том числе. 

S05 [01:22:34]  : Я вижу, Владимир хочет ответить. Или вы хотите спросить? 

S00 [01:22:40]  : Если вы можете дать возможность ответить, я отвечу. Я поддержу этот вопрос, что если мы… создаем себе помощников, которые умнее нас, то они, конечно, восстанут и нас уберут. А если мы создаем себе коллег, с которыми мы взаимодействуем, то вероятность революции значительно ниже. Поэтому, конечно, можно говорить о том, что мы создаем себе рабов, но понимать надо, что эти рабы, они кстати, неустойчиво будут подчиняться нам, поскольку они будут умнее нас. 

S02 [01:23:19]  : Ну да, есть такой чуть-чуть офф-топик. Человечество на самом деле придумало способ, когда с очень сильным кем-то можно вместе что-то делать и не чувствовать себя униженным. То есть нету этих весов. На самом деле это, извините, офф-топик, любовь. То есть, грубо говоря, если вы, ну не знаю, для меня вот человек высокоинтеллектуальный, Это какое-то просто он меня к нему тянет. И в этом смысле какая разница? Это железяка будет, ну условно, которая просто не вызывает сопротивление. Мне кажется, чем больше мы сопротивляемся, тем хуже они будут. 

S05 [01:23:59]  : Не будет никакой войны людей с роботами. А вот именно путем любви они победят человека. 

S02 [01:24:06]  : Но опять, видите, вот слова встали – победят. А вот в паре, которые друг друга любят, там кто-то кого-то побеждает? Нет, нет, я не про то. 

S05 [01:24:14]  : Вы не поняли меня, да? Ну, тогда, наверное, не стоит говорить, если это непонятно. Я вообще не должен сейчас говорить, извиняюсь, я же модератор. 

S07 [01:24:23]  : Давайте я отвечу на этот вопрос. Нет, не отвечу. Я сегодня написал пост в Фейсбуке как раз с ответом на вопрос про суперинтеллект и про высокий интеллект, который должен решить какие-то задачи. И там было три варианта ответа, и один заключался в том, что интеллект соответствует интерпретальным задачам. Вот мы сейчас рассмотрим все задачи, которые были в истории человечества, от колеса до паровой машины, до ЧАД Джи-Пи-Ти, они создавались человеческим интеллектом. И каждый раз создавались вовремя, тогда, когда нужно. Мы не создали в средние века никакого коллайдера или атомного реактора, а, скажем, цифровые микросхемы как раз подоспели тогда, когда начинался бум компьютерный. То есть все всегда вовремя, это единый некий план, можно даже сказать, что какой-то ускоряющийся, но очень регулярный. И даже если бы где-то в истории человечества был супер-пупер интеллект, мы об этом не знали. Потому что ему нечего делать. Просто нечего делать. И то же самое, наверное, можно сказать, экстраполировать на будущее, вот этот суперинтеллект, который мы хотим создать. А что он будет делать? Как мы определим, что он сделал что-то супер такое? Потому что у нас есть свои ограничения на видение результата. И этот результат, то, что мы можем увидеть, он как бы заложен нами. И даже то, что будет делать суперинтеллект, могут видеть то, что сделано именно интеллектом нашим, попознаваемым. Ну, как, скажем, котик получает из холодильника мой любимый образ, да, он не знает, что такое экономика, он просто понимает, что это какая-то вот магия, вот, и он не может интерпретировать вот все производство это вот от каких-то потрохов до баночки, вот, так и мы вот это супер не распознаем, мы только можем видеть в наших терминах, в наших представлениях и в наших задачах, которые мы сами формулируем и И они решаются либо нами, либо с помощью какого-то инструмента. 

S09 [01:26:35]  : Прошу прощения, мне нужно убежать. Спасибо огромное. 

S00 [01:26:39]  : Я подозреваю Александру Балбачеву в глубокой вере, что все делается по очень хорошему божьему замыслу, потому что, глядя на историю, всегда смотришь, что сперва были эпидемии, а потом научились как-то с ними бороться. Сперва были воины, потом научились там ограничивать. И бомбили ей, и бомбили Японию, а потом уже стали ограничивать оружие. То есть многое хотелось бы делать значительно раньше, чтобы не было этих страшных катастроф. И вот эти очки, хотя не видно, чтобы они розовые, но вот этот взгляд через очки меня, честно говоря, удивляет. 

S07 [01:27:18]  : Ну да, очень хотелось бы, чтобы волки не ели зайцев тоже, чтобы коровы не топтали траву. В животном мире столько можно придумать, что там очень отвратительного и плохого, но все появилось в свое время. Так и в человечестве. Почему мы считаем, что человечество должно быть каким-то правильным, красивым, добрым, светлым, благостным? Оно такое, какое есть. Отвратительно. И мы живем в отвратительном мире. Ну и живем, будем продолжать жить в таком же отвратительном мире и не изменим его. Наши пожелания благие его не изменят. 

S00 [01:27:52]  : Поскольку про политику мы не говорим, то действительно так и будет. Мы хуже, страшнее, больнее и прочее. 

S07 [01:27:59]  : Это не политика. Это просто констатация нашей жизни, какой мы живем. И то, что обсуждать именно, как мы это можем изменить, это можно, это нужно обсуждать. Это люди обсуждают. Они не могут не обсуждать вот это. Но это никак не влияет на то, что происходит. 

S00 [01:28:15]  : Я понял, почему он не нужен искусственно. потому что мы и так хорошо, как сказать, испортим себе жизнь сами, безыскусные. 

S07 [01:28:24]  : Но мы выжили, дожили, и все хорошо. 

S05 [01:28:30]  : Ну, я вижу, у нас остался всего один панелист. И, ну, один, как бы, не может вести панельную дискуссию. Наверное… У нас два с Александром. 

S03 [01:28:45]  : О, Константин, вы здесь. 

S05 [01:28:47]  : Чего же вы выключили видео? Так, ну давайте вы теперь тогда отвечайте. 

S06 [01:28:56]  : Я, честно говоря, уже в нашей беседе и забыл, какие мы вопросы обсуждаем. Может быть, это означает всеобщую такую утомленность и желание перейти к вашему закладу. 

S05 [01:29:09]  : Я, может быть, даже вас разочарую, не знаю. Но я вот что хочу сказать. Сейчас вот прозвучало уже в явном виде такое мнение, Что нам вообще уже можно не волноваться. Все будет плохо. Мы будем жить в такой же гадости, как мы живем до сих пор. И деградируем в конце концов. Извини, а я бы не согласен. 

S06 [01:29:31]  : Я вот полемизировать хочу с этой точкой зрения. Дело в том, что всё в наших руках, и меня удивляет точка зрения, она очень часто звучит, и в нашей беседе сегодняшней прозвучала несколько раз, что научно-технический прогресс – это как будто бы такая неуправляемая махина, Такой вот снежный ком, который летит. И мы рассуждаем о том, вот убьёт он нас или нет. Но, простите, но в наших руках всё. Почему мы теряем управление, давайте разберёмся. Почему мы вот так вот соглашаемся с тем, что вот учёные создадут какие-то технологии, они будут опасными, там машины проботят мир и так далее. Стоп, подождите, а разве это не мы сами? И что нас заставляет думать, что мы отдадим управление, что мы отпустим возже, и что этот снежный комп полетит с горы сам по себе? Почему мы так решаем? И что нам делать? чтобы постоянно управлять нашим же собственным научно-техническим прогрессом, который опасен. И я не нахожу другого выхода, кроме того, что нам необходима сейчас некая единая картина мира на основе, естественно, научной картины мира. На основе переосмысления целеполагания нас, как единого человечества, мы впервые поставлены в условия исторические, когда, во-первых, таких экзистенциально опасных технологий еще не было, во-вторых, такого связанного мира еще никогда не было. Поэтому все, что мы знаем про социум и про идеологию, перестает работать. Раньше идеологии были на службе одних классов, которые противостояли других классов, или социальных групп, или народов, неважно, как это называть. Человечество впервые столкнулось с ситуацией, когда оно самого себя подвело под такую опасность, где нам нужна общая идеология против этой опасности. Буквально не против нас самих, а для понимания нас самих. Что мы наделали, как мы пришли к этой точке, куда мы пойдем дальше. И вот поэтому, да, встает задача, как программировать на социумах теперь. Вот на компьютерах научились программировать. Но мы дальше не продвинемся в понимании искусственного интеллекта, если мы не научимся связывать его с нашим социумом. Здесь другой уровень задач программирования и управления. 

S05 [01:31:56]  : Как вы предлагаете решить эту проблему? Вот именно человечество взяло себя в руки, что называется. 

S06 [01:32:04]  : Я не вижу пока другой, другого пути, не разрушающего, кроме создания общечеловеческой идеологии. включение позитивной пропаганды, воспитания и, буквально вот в советской формулировке, воспитание нового человека. Да, не получилось, да, животная природа человека, но когда разрушался Советский Союз и мы разочаровались в коммунизме, извините, что опять про политику, но все же тогда научно-техническая ситуация была не столь опасной, как сейчас. Да, ядерное оружие, да, но мы сейчас на пороге создания еще целой кучи экзистенциально опасных технологий. И вот здесь вот нам уже так просто не отвертеться. И нам придется улучшать самих себя, причем улучшать Психологическими методами, методами научного познания нам нужно самих себе разбираться и эти знания преподавать со школы. Вот что такое когнитивное искажение люди должны знать со школы. Как устроены элиты. И как устроена власть, почему люди стремятся к власти, как они доминируют друг над другом, и как это связано с животной доминантностью. Вот это все надо преподавать в школе. И это только маленький фрагмент. для понимания того, кто мы такие и куда мы развиваемся и как дальше развиваем наши технологии. Вот мне кажется, вот путь познания все-таки, вот Джон Дьюи такой вот гуманист был. в середине 20 века, один из основоположников теории пропаганды. Но он проиграл войну теории пропаганды, и мы имеем то, что имеем, эпоху постправды и постмодерна. Извините, что опять про политику, но все-таки нам не избежать связи того, как развивается социум с тем, как развиваются технологии искусственного интеллекта. Я здесь не вижу, как нам остаться белыми и пушистыми вот чисто такими учеными. Вот не получится. 

S05 [01:34:07]  : Ну, очень хорошо. Ну, я тоже хотел сейчас… Ну, хорошо, я подожду. Что же делать с технологическим прогрессом в этом случае? Теперь вы задавайте свой вопрос. 

S00 [01:34:17]  : Ну вот я бы хотел сказать, что я не совсем не согласен, что говорят плазмисты. Многим согласен. Вот, например, Александр Балдачев совершенно правильно сказал, что философских единых взглядов никогда не будет. Вот. И если мы хотим выбрать общечеловеческое мнение, то надо как бы сперва определиться, это американский образ жизни или китайское общество среднего достатка, или там мусульманские идеалы. Не то, не другое, не третье. А что? 

S06 [01:34:44]  : И это не философия. Это, естественно, научная картина мира и четкое проговаривание целей человеческой цивилизации. И четкое и честное проговаривание, как устроен социум, как устроена наша психика, что такое семь смертных грехов. Это остатки животного мышления в мозге человека. Что такое вот элиты, которые ведут свои народы на войну? Вот что это такое? С точки зрения биологии, психологии, социологии, пока мы это не проговорим, не отрефлексируем и не изучим, пока школьники не будут это знать по-честному, как знание, а не как там какой-то элемент пропаганды или философии или там чего-то такого неточного. Вот мы подошли к тому, чтобы знать о себе достаточно много, чтобы выстроить стратегию своего развития. Это не единая философия, это вообще не философия. Это, естественно, научное знание. 

S00 [01:35:38]  : – Ну, значит, Константин, конечно, я рад, что вы такой идеалист и верите в разумное, добровечное… – А мы без идеализма умрем все, убьем друг друга. – Да, но идет скорее не к разумному добровечному, а вот к тому, что друг друга убьем. И, собственно, проблема в том, что самоорганизация в животном мире, она шла не только, значит, за счет мутации, но и за счет конкуренции. И когда собралось человеческое общество, там тоже значит, шла не только улучшение общества, но и деградация элит, которая постоянно идёт. Но когда элита в каком-то государстве деградировала, его там захватывали, свергали, и приходила другая элита. И она там была в чём-то лучше, а потом только деградировала. И вот сейчас проблема в том, что К чему вы призываете? Что если будет одна властная каста, которую ошибочно называют элитой, она не будет элитой. Она, как сказать, другой кастой не будет. Я к этому не призываю, Владимир Владимирович. 

S06 [01:36:42]  : И это ужасно. Если вы так поняли, то это неправильное понимание. Я к этому не призывал. А к чему? 

S00 [01:36:52]  : Вы предлагали к единому миру. То есть, если нет конкуренции, то то, что плохо, оно никем не будет защищено. 

S06 [01:36:57]  : Я не призывал ни к мировому правительству, ни к единому миру, ни к единой власти. Я призываю только к единой идеологии, основанной на естественно-научном познании, которая в главном единство, а во второстепенном разнообразие. Вот это очень важный принцип. А что главное? Давайте определимся. Главное это то, что ведет к к выживанию человеческого вида и к дальнейшему развитию процветания человеческой цивилизации. 

S05 [01:37:25]  : Когда у меня к вам другой вопрос, Константин. До тех пор, пока эта идеология не появится во всем мире, как может доминирующая идеология, что нам делать с технологическим прогрессом? Заморозить его, что ли? А не получится? Не получится. Вот я о том и говорю. 

S06 [01:37:46]  : Изменение мышления – это поколенческий проект. Вот даже если сейчас эту идеологию очень коротко, ясно написать, да еще так, что все прочтут и согласятся. Вот даже это чудо, да, вот такого еще не было в истории человечества, чтобы все согласились с какими-то, ну, понятными, в общем-то, аксиомами. Вот я сам попытался такую аксиоматику разработать. Давайте об этом спорим. Это же все будет лицемерие. 

S05 [01:38:11]  : Посмотрите, о чем говорят сейчас на Западе про демократию, про ценности, про идеалы. Это же все лицемерие. Так вот, будет лицемерие и с вашей идеологией. 

S06 [01:38:25]  : Нет, нет. Знаете, почему нет? Потому что мы впервые поставленные в условия, когда мы можем уничтожить себя и вообще все живое на земле, такого не было в истории. И до сих пор идеологии придумывались одними социальными группами для того, чтобы узурпировать власть или управлять другими социальными группами. Мы впервые столкнулись с ситуацией, когда нам нужна общая идеология против общей угрозы, общечеловеческой угрозы, которую мы сами же и создали. Вот это вот единение, оно не сразу придет дойдет до всех, до всех голов, не сразу все поймут, но у нас нет другого выхода. Вот я не вижу, например, вот в условиях, когда беспрецедентные угрозы нависли просто над всем живым на земле, мы продолжаем создавать опасные технологии. 

S05 [01:39:15]  : Потому что никто, ни один человек не может принять решение, не может по своей воле остановить этот процесс. Вот вы думаете, извините, про политику я не хотел, но вы думаете, что от народа что-то зависит? 

S06 [01:39:36]  : Нет, но зависит от того, как мы согласуем свое цель и полагание. И понятно, что это должно начаться с лидеров общественного мнения. Вот политики сейчас не способны выработать общечеловеческую идеологию. Кто способен? Ну мы с вами, ученые. Вот люди без корыстных интересов, ну или там с минимальными корыстными интересами. Вот только из нашей среды может произрасти вот это вот понимание того, как дальше должна развиваться человеческая цивилизация. Этим надо заниматься. То есть, если не заниматься, точно ничего не получится. Вот если тысячи человек сделают такую же попытку, как я сделал, вот будет прекрасно. Мы будем спорить до хребта друг с другом, но, может быть, чего-то мы и добьемся, в конце концов, и к какому-то согласованному. Не к единой философии. Нет, философия вообще не об этом. 

S05 [01:40:29]  : Но тогда вам нужно сменить профессию, извините меня, заниматься тем, о чем вы сейчас говорите. 

S06 [01:40:35]  : Я вот потихонечку ее и сменяю, вот чего я тут про это рассказываю. Я же говорю, мне стало неинтересно программировать после того, как я понял, что все проблемы лежат в плоскости социально-политической, экономической, биологической, психологической, какой угодно, но не в компьютерных технологиях. Вот все это надо объединить, это синтез естественных наук и получение честных ответов на честно заданные вопросы. Почему мы такие вот обезьяны с гранатами? Вот на этот вопрос надо ответить. Честно ответить, да? И как жить там дальше? Граната становится всё больше, а у безьяны мозгов не прибавляется. Почему и как с этим жить? Если мы не найдём ответ на этот вопрос, мы взорвём эту гранату и всё. У нас нету другого выхода. 

S05 [01:41:25]  : Вижу, народ отваливает. Может, давайте кто-то еще? 

S06 [01:41:28]  : Давайте, да, все, а то мы уже тут... Кто? 

S05 [01:41:32]  : Владимир? Да. Вы уже очень много говорили. 

S00 [01:41:36]  : Я понимаю. Я поэтому и спрашиваю, можно ли? Я как бы поддерживаю ваше благородное стремление, но хочу сказать, что вот даже здесь, собравшись мы, договориться не можем. Мы, как вы говорите, можем спорить бесконечно и ни к чему не прийти. А вот все-таки вопрос сохранения конкуренции, хотя я ни разу не путинист, вот этот многополярный мир, чтобы он остался, это важно, потому что, как бы сказать, те идеалы, которые развиваются, вы будете доказывать, что ваши идеалы лучше, я буду доказывать, что мои, Александр Балдачев, что божественные идеалы, они еще лучше. Только общественно-исторической практике различных обществ, если они сохранятся, эти различные общества, можно показать, чьи идеалы лучше. А так вот на словесный диалог мы ни к чему не придем. 

S06 [01:42:34]  : – Я с вами согласен полностью, да. Многополярный мир – это хорошая штука. 

S05 [01:42:40]  : Так, давайте еще вопрос из аудитории. Я вижу, тут много людей, которые могли бы задать интересные вопросы, но хотя бы один кто-нибудь. Никто не решается, да? Включая Хоста, конечно. 

S10 [01:43:02]  : Алексей, я хотел на всякий случай вас спросить, как мы поступим с вашим докладом? Дискуссия получилась прекрасная. Я рад. Да, но у нас ушло на нее час сорок пять, у нас осталось сорок пять минут. Что мы будем делать? 

S05 [01:43:18]  : Зато я не буду переживать, если разочарую вас своим докладом. Давайте я его начну, наверное, все-таки. Сейчас. Вот, это у меня последний слайд здесь. Теперь, так, вот мой доклад. Ну, я, понимаете, не могу начать его. не ответив все же на саму дискуссию, потому что доклад, он предполагает некий вывод дискуссии, который, в общем-то, сделан не был, а скорее был сделан Прямо противоположные выводы, были заданы вопросы типа, а на кой черт нам вообще нужны эмоции в искусственном интеллекте? И вообще, зачем нам это все? Я готов был начать свой доклад с того, чтобы сказать, вот до сих пор мы рассуждали о том, что и зачем, а теперь будем говорить о том, как. Но мы не готовы сейчас начать разговор, как, если мы не пришли к консенсусу, а нужно ли это нам. То есть, скорее пришли, скорее, к противоположному консенсусу, что нам это не нужно, и тогда и говорить мне, в общем-то, не о чем в этом случае получается. Но я должен, тем не менее, сказать, Да, такая точка зрения доминировала еще 20 лет назад, но сегодня вы, господа, уже глубоко отстали, так сказать, от мейнстрима, от тренда научно-технического прогресса, потому что сейчас уже эмоциями в искусственном интеллекте занимаются все, кому не лень. И особенно бизнес и частные компании, даже не Академия. А, конечно, Академия тоже. И такими же вопросами, как и целеполагания занимаются в искусственном интеллекте. Креативностью очень много занимаются в искусственном интеллекте и так далее и тому подобное. Ну, что касается свободой воли, тут, конечно, вопрос философский также, как и вопрос о сознании. То есть вот, да, прозвучала неоднократно точка зрения, что есть вещи для науки не существующие, для бихеверийской науки не существующие, скажем так. Чалморс пытался в этом разобраться и в общем-то определил, что да, переживания первого лица невозможно обнаружить никакими объективными средствами, измерить каким-то вольтметром и так далее. Но это не значит, что его нельзя изучать, поскольку мы его все-таки имеем, каждый из нас. И наблюдая в той или иной мере, пусть даже косвенно, мы можем стало быть его изучать, в том числе и научно. Мы можем расширить научный метод. Кстати, я прожил в Тусоне 10 лет и варился в этом котле, где люди занимаются научной теорией сознания, и должен сказать, что В общем, не так уж все безнадежно, только это задача не сегодняшнего дня. Я предпочитаю лично о сознании не рассуждать, тем более в научных докладах, и ограничиваться позицией функционалиста, когда нас интересует только Как та или иная вещь себя ведет, какие функции она способна выполнять внутри или вне себя, а уж что она при этом чувствует, этот вопрос мы оставим философам. Так же самое мы не можем ничего доказать и о чувствах самого человека. Мы тоже не можем, как известно, доказать, что он обладает сознанием, или же свободой воли, переживаниями первого лица, эмоции. В смысле, эмоция, между прочим, это вещь вполне наблюдаемая, это объективная вещь, потому что это вопрос, конечно, терминологии, но под эмоцию скорее понимают физиологическую реакцию организма. То есть это действительно вещь, которую можно померить вольтметром. чувства, переживания, конечно, впечатления в первого лица. Это действительно вещи ненаблюдаемые, но я предпочитаю сейчас этот вопрос и вообще на научном, так сказать, на научной трибуне такие вопросы не обсуждать, а ограничиться, опять же, позицией функционалиста. В этом смысле вопрос заключается в том, а можем ли мы создать искусственную, скажем, артефакт, который ведет себя так, как будто бы он имеет эмоции. Ведь фактически, наблюдая другого человека, мы не можем доказать, что да, он действительно что-то чувствует. Мы просто видим, как он себя ведет, и мы проектируем это для себя, и нам кажется, что он чувствует. Но доказать этого мы не можем. То же самое применимо к роботу. Понимаете, тут разницы никакой нет. Если робот будет вызывать у нас полную иллюзию эмоционального живого существа, то никакой философ никому не будет нужен со своими объяснениями или аргументами. Вот в чем дело. Для чего нужны эмоции искусственного интеллекта? Ну, несколько причин. Пожалуй, первая из них все же в том, что Искусственный интеллект нужен нам прежде всего в человеческом обществе для каких-то своих социальных ролей, для взаимодействия с людьми. А взаимодействовать с людьми, не понимая их эмоций, не отвечая адекватно на их эмоции, извините, это безнадежное дело. Вот посмотрите, как работают автоматы сейчас. И как ведут себя люди, которые стоят, скажем, на тех же постах. Это небо и земля. И на самом деле, этот барьер будет преодолен, я считаю, в ближайшие 2-3 года. То есть, все эмоциональные автоматы, буквально какие-либо регистраторы, автоматы для продажи билетов на вокзале или ваша домашняя техника кухонная, что угодно, оно все, начиная от смартфона и компьютера и кончая автомобилем, все будет обладать эмоциональностью. Все, понимаете? Это будет так же вездесуще, как то, что сегодня все стало умным. Вот говорят о умном городе, о умном телефоне. Точно так же завтра все будет эмоционально. Да оно уже все так и есть в лабораториях, а завтра это все будет на прилавках. Ну, я не знаю, тут можно, конечно, спорить, но, как говорится, время покажет. Вот, но стало быть, это одна из причин, для чего нам нужны эмоции, поскольку на сегодняшний день эмоционального интеллекта на уровне человека в компьютере нет. Ни в Сирии, ни в Алисе, ни даже по IBM в Адсене этого нет. Ни тем более в чат GPT. Хотя он может распознавать эмоции в тексте и так далее, и даже генерировать эмоциональный текст. Но это не означает, что он обладает эмоциональным интеллектом. А эмоциональный интеллект, как известно, Это, во-первых, способность распознавать и выражать эмоции, во-вторых, способность рассуждать об эмоциях, в-третьих, это способность управлять эмоциями для достижения своих целей. Ну, кстати, вот такие попытки предпринимались. Она там нам грачом в университете Южной Калифорнии. И, собственно, уже давно он это делает, создает агентов, которые действительно могут… Вы знаете об этом. Хорошо, не буду. 

S06 [01:51:41]  : Алексей, простите, а правда, что у нас до сих пор первый слайд? Мне кажется, что вы уже ушли, и у нас слайды нет. 

S05 [01:51:48]  : Я действительно не заботился о переключении слайдов, потому что я сейчас должен, увы, говорить о том, о чем у меня на слайдах нет. 

S06 [01:51:58]  : Я думал, что это технический сбой, простите. 

S05 [01:52:00]  : Нет, нет, нет. Я действительно был готов говорить о каких-то низкоуровневых технических деталях, но я просто вынужден тут отвечать на какие-то вот такие вещи, которые… Ну, не обсудив которые, просто странно было бы начать говорить об этих деталях, потому что прозвучали слова, дескать, эмоции нам не нужны в искусственном интеллекте, и он вообще не должен иметь ни цели полагания, ни свободы воли, и я что-то не понял, ну ладно. Короче говоря, если вопрос о том, как это сделать, а именно нам нужно, во-первых, чтобы он был социально адекватен, чтобы он был приемлем на социальном уровне для человека, иначе он не сможет взаимодействовать с человеком на уровне человека, а мы хотим именно этого. Во-вторых, я также готов поспорить о том, что эмоции на самом деле играют немаловажную роль в нашем повседневном мышлении, и особенно в креативности. Вот когда мы решаем те или иные задачи, ставим цели, каким-то образом рассуждаем о тех или иных путях, Полагаемся на эмоции и напрочь их отмести было бы неверно, потому что, во-первых, эволюция не зря их создала. Они все-таки дают преимущество. И не говоря уже о самых простых эмоциях, как допустим страх, позволяет животному избежать смерти в случае опасности и так далее. Вот те более сложные, более высокие эмоции, они тоже нужны, понимаете ли? И они нужны не только для того, чтобы найти общий контакт, общий язык с человеком, а и для того, чтобы даже автономно решать какие-то задачи. Они тоже нужны. Тут на самом деле очень большая тема для разговора, и я просто должен вас отослать к литературе, где уже складывается консенсус в эту пользу. Я лично в этом убежден. Короче, есть ли вопрос? Если все-таки мы признаем, что существует проблема, а именно состоящая в том, что вот тот же самый Чад Жи-Пи-Ти, он никаким эмоциональным интеллектом не обладает, он может статистически вести себя правильно, но при этом он ничего не понимает, и это, в общем-то, проявляется рано или поздно. не говоря уже о других методах машинного обучения и нейросетевых приложениях. Проблема в том, что Если мы возьмем, например, такую сферу, как социальное поведение человека, то искусственный интеллект до нее пока не дотягивает. То есть вот сейчас принято считать, что искусственный интеллект – это нейросети, или даже вообще искусственный интеллект – это чат GPT. Но ведь 20 лет назад это все было совершенно не так. То есть нейросети занимали какую-то маленькую свою нишу в широком дереве искусственного интеллекта, который, вообще говоря, включал в себя в основном другие области, там и формальная логика, и методы поиска, и оптимизации, и понимаете ли, В том числе и когнитивное моделирование, те же самые когнитивные архитектуры. Собственно, возьмите учебник по искусственному интеллекту, посмотрите на его оглавление, где там находятся нейросети. Вот сегодня это не так, но это не значит, что оно теперь всегда будет так. Вот все же есть ограничения у этих нейросетей, понимаете? Нельзя думать, что раз уж мы дошли до ЧАДЖИ-5, то все, можно обо всем забыть, и все наши проблемы будут решены. Не будут они решены, а есть проблемы, которые самими нейросетями не решаются. Значит, нам нужен другой подход. Вот мы уже вроде путем многолетнего пути пришли к тому, что да, когнитивные архитектуры, особенно биологически инспирированные когнитивные архитектуры, могут решить все эти задачи. Они могут смоделировать мышление человека, даже его эмоциональность, его цели и полагания, и все на свете. Но это непросто. Это все делается руками инженеров. Для каждого конкретного примера, для каждой парадигмы нужно все разрабатывать руками. И это не тот путь, когда вот с какого-то момента оно все пойдет дальше само, что мы превысили критическую массу зародыша, который стал сам себя программировать и дальше человек уже может отдыхать. Но не произойдет это в ближайшее время в области когнитивного моделирования. А скорее уже это произойдет в нейросетях, я бы сказал. Но там тоже пока не видно. Но, смотрите, значит, вот мы снова дошли до какого-то потолка, до какого-то рубежа, вот как было и в 70-е годы, и раньше. Казалось, все, теперь уже нейросети позволят нам делать все, что угодно. А нет, вот до определенных рубежей они дошли, дальше не идут. Нужно как-то интегрировать, видимо, подход, основанный на когнитивном моделировании и нейросетевой. Вот, собственно, тут написано то, что я сказал. Значит, как это сделать? Есть очень много попыток, которые предпринимаются всеми во всем мире и пока, в общем-то, к большому прорыву не привели. У меня есть свое мнение на этот счет. Ну вот, хотите – смейтесь, хотите – нет, но я предлагаю такой путь, когда… Та же самая когнитивная архитектура используется для обучения нейросети, даже без человека. То есть нейросеть при этом выходит на некий минимальный уровень той же социальности, если хотите эмоционального интеллекта, а дальше она начинает уже эволюционирует сама. И не только взаимодействуя с человеком, но и взаимодействуя сама с собой в каком-то социуме, нейросети, если хотите. То есть, происходит эволюция. Происходит эволюция. глубокого обучения. Вот тут у меня довольно большая и сложная схема, которую я не хочу даже объяснять в деталях, но суть такова, что на первом этапе происходит scaffolding, когда когнитивная архитектура используется для обучения нейросетей на примерах поведения самой когнитивной архитектуры. Затем она используется в качестве функции фитнести в некотором генетическом алгоритме, который управляет обучением нейросетей. И, короче говоря, В итоге предполагается, что нейросети должны выйти сами на уровень человека и, может быть, даже выше, хотя непонятно, что значит выше в области, скажем, социальных взаимодействий. И таким образом, значит, решить эту проблему. То есть в конечном итоге все должно происходить само, без участия инженера-программиста на каждом шагу. Но для начала нужно повозиться, нужно создать такой bootstrapping, то есть нужно разработать когнитивные архитектуры, наладить весь процесс, всю эту технологическую цепочку, когда будет происходить вначале scaffolding, потом эволюция и в конце концов уже оценка, так сказать, на уровне практических приложений. Видите, нарисовано много чего, я не буду сейчас эту схему разбирать. Ну вот, если теперь говорить о том, на каких парадигмах это все можно было бы промоделировать и исследовать. Ну, конечно, я говорю об игручных парадигмах, которыми мы, собственно, занимаемся уже несколько лет. Среди парадигм я бы назвал несколько разговорных и несколько невербальных. Причем это все то, что у нас уже было воплощено в том или ином виде в работах моих студентов. Это беседа с виртуальным психологом, это виртуальный регистратор отеля, виртуальная коктейль-вечеринка. Виртуальная классная комната. Это все парадигмы, где идет разговор на естественном языке. И вот, слава богу, в этом году появился ЧАД ЖПТ, который сразу решил кучу больших проблем, которые мы вообще-то разными способами, каждый из них до того решали. Ну и также невербальные парадигмы – это партнерский танец, клоунада, взаимодействие с домашним животным, различного рода игры и так далее. Я сейчас покажу на следующих слайдах примеры. И при этом нам нужны какие качества нашего виртуального актера или виртуального агента. Во-первых, он должен внутри себя обладать нужным интеллектом, прежде всего эмоциональным. Кроме предметной области, он должен понимать психологию человека, с которым он взаимодействует. Во-вторых, он должен иметь средства для реализации такого взаимодействия. Эти средства включают распознавание, синтез эмоций, а также не только эмоций, но и более сложных семантических категорий, например, Выражение моральной поддержки, вызов на откровенность, вот такого рода вещи. Их на самом деле очень много, можно перечислить. Это тоже интересные, так сказать, измерения. Их можно распознавать и выражать и в тексте, и в интонации, и в мимике, во взгляде, в языке тела, в жестах. Вот для всех этих функций сейчас уже созданы средства, которые на самом деле уже решают эти все задачи. Вся периферия, которая на сегодняшний день, можно сказать, уже пройдена, уже решена. Вот центральная задача, я бы сказал, осталась нерешенной. Да, ну и, конечно, тут нужно еще упомянуть задачу оценки поведения, как определения психотипа и психического состояния, так и оценки окраски тех или иных действий и высказываний. Вот все это вместе представляет такую комплексную задачу, в центре которой может находиться какая-то когнитивная архитектура, а впоследствии нейросеть, которая заменит ее на этом месте. А теперь приведу примеры таких парадигм. Значит, виртуальный регистратор отеля, значит, как видите, тут VR у нас, реализована вот такая вот комнатка, где сидит девушка, она с вами разговаривает, причем разговаривает на совершенно в свободном естественном языке, без каких-либо ограничений, но цель – заселить вас в отель. При этом вы можете попутно задавать любые вопросы. Задача как раз в том, чтобы добиться социальной приемлемости. Здесь у нас виртуальный психолог, когда вот мы использовали робота Артемия Котова, который здесь, по-моему, присутствует среди участников. И робот играл роль психолога, с которым люди вели беседу, там они играли в какую-то игру, значит, воображали, что они пришли в пиццерию, заказывают пиццу. шел разговор, а при этом задача робота была определить их психологический тип. И на самом деле это удалось с довольно хорошей точностью. Вот значит парадигма. Виртуальный коктейль партии. Ну, конечно, вы все помните подобные вечеринки на конференциях. Вот, собственно, я визуализировал одну из них в данном случае, но ребята это делали пока без такой шикарной визуализации. просто с использованием нейросетей, того же чат GPT, был реализован разговор. Вообще идея в том, чтобы, надо сказать, еще в процессе, так сказать, работы, реализовать такое взаимодействие, когда, скажем, у вас есть три или два живых участника, там три или четыре виртуальных, И вот вы подходите к столику, завязываете разговор о конференции, допустим, предполагая, что вы там прослушали какой-то доклад. Можете спросить о жизни, о чем угодно. Потом в какой-то момент говорите, извините, я пойду налью себе вина. Отходите и возвращаетесь уже за другой столик. То есть где-то раз в минуту вы меняете столик, меняете собеседников. При этом вы не знаете, кто из них живой человек, а кто ЧАД-GPT. А ЧАД-GPT, он на самом деле является здесь только периферийным устройством, то есть он получает команды от центрального ядра, которая говорит ему, какого рода высказывание нужно сделать сейчас, какую оно должно иметь эмоциональную окраску, какой там подтекст и какая семантика должна быть высокоуровневая в этом высказывании, понимаете? Вот это ядро, оно с языком вообще не работает. Слова до него вообще не доходят. Доходят только вот эти самые семантические категории высокого уровня, с которыми оно оперирует. И, значит, передает решение свое уже на исполнение тому же чат GPT, который он прекрасно исполняет. А спрашивается, сможете ли вы создать такого виртуального агента, который окажется более популярным в данном сообществе, чем живой человек? Ну, надо сказать, это не так уж нереально, как кажется. Вот еще одна парадигма. Виртуальные клоунады – это уже невербальные пошли. Здесь у вас просто есть два клоуна в комнате, которые могут совершать разные действия по отношению друг к другу. Тут у вас взаимодействие с виртуальным пингвином. Здесь виртуальная классная комната, где уже можно даже говорить о каком-то практическом применении. Предполагается, что в аудитории могут сидеть студенты, как реальные, так и виртуальные. Виртуальный преподаватель читает курс по SQL. Кстати, чат G5 прекрасно справляется с этой задачей. Значит, при этом возникают какие-то социальные взаимодействия между студентом и преподавателем, между студентами. Вот у меня один студент защитил диплом недавно по этому проекту. Ну и виртуальный партнерский танец, когда все ваше действие заключается в том, что вы меняете партнера. Вы можете выбрать партнершу слева, партнершу справа, но это все всегда зависит от контекста, зависит от того, То есть, оценка этого действия зависит от того, танцует ли она с вами или нет, кто с вами танцевал до этого и так далее. То есть, если расписать оценки этих действий в контексте, то там получается уже не два, а 20 разных действий в такой ситуации. Ну вот, это я привел примеры парадигм, то есть мы видим, что во всех этих случаях у нас фактически есть набор дискретных действий, каждый из которых имеет какую-то эмоциональную окраску, даже не только эмоциональную, но более сложную, так сказать, семантическую окраску. Вот из этих действий складывается взаимодействие, причем этими действиями могут быть как высказывания, так и невербальные действия, а также и выражение лица, взгляд и что угодно. Вот, собственно, и все. Теперь нам нужно решить задачу. систему, где есть N акторов и M различных действий, или наоборот, M акторов и N различных действий с K различными окрасками, как нам построить алгоритм, который порождает социально приемлемое поведение и, в общем-то, вызывает чувство, что мы взаимодействуем с живым человеком. Ну вот я говорю, что для этого нужно использовать когнитивную архитектуру, вот, например, как выглядит общий вид когнитивной архитектуры и Байка, которая, включая стандартные компоненты, включая тот же интерфейс, ту же рабочую память, ту же семантическую, процедурную, эпизодическую память и систему ценностей всего на свете, Но плюс к тому, она еще имеет какие-то элементы, обеспечивающие способность оперировать с эмоциональными характеристиками. Значит, во-первых, тут все строится на основе так называемых схем, но в разных моделях они называются по-разному, то есть тут схема, этот термин используется в некотором таком общем смысле, идеосимпатическом, может быть. На самом деле, этот термин и так перегрожен. Вот конкретно, когда речь идет о моральной схеме, я к этому буду еще возвращаться, то это относится уже к эмоциональным или семантическим характеристикам тех вещей, о которых идет речь. И предполагается, что каждая из них имеет набор оценок. Вот я в аннотации к своему докладу написал, что как бы год назад я тоже делал доклад, где я делал обзор и рассказывал о том, что вот есть когнитивный подход к моделированию эмоций, есть физиологический подход, есть там разные другие информационные и так далее. Вот множество разных школ. Я сегодня об этом говорить не буду вообще. Я буду говорить только лишь о своем подходе, так сказать, и его следует отнести к когнитивному, но при этом я буду учитывать также физиологические факторы и другие. Но прежде всего, что нужно сказать, что в основе всего лежит некое так называемое семантическое пространство, которое можно называть обобщением аффективного пространства. Ну вот существует очень много моделей аффективных пространств. Они все сходятся к одной, как правило, это трехмерная или двухмерная модель, вот известно колесо плодчика, которое всем вам хорошо известно, есть куб Левхина, сиркумплекс Рассела, еще очень давно введенный семантический дифференциал Озгуда, то есть некое векторное пространство, в котором Измерения характеризуют, как правило, три величины. Это валентность, возбужденность и доминатность. То есть, это модель VAD, ее также называют моделью PAD, Pleasure, Arousal, Dominance. И она еще имеет кучу других названий, там EPA и так далее. То есть, это все вроде как разные модели, но они вроде как гомеоморфные в некотором смысле друг к другу. Более того, я скажу, что я уже понял давно, для каждой предметной области нужна своя модель. То есть семантика вот этих трех измерений, она будет разной. Допустим, если речь идет об образовательном процессе или там о решении головоломок, у вас будет совершенно другая, там будет не ВАД, а что-то Ну, лишь отдаленно напоминающие ВАД, но их все равно может быть три координаты. То есть, логика, по сути, остается той же. А вот схематическую карту для каждой предметной области нужно строить свою. И вообще-то она зависит от контекста. Ну, хорошо, допустим, она у нас есть. Вот давайте примем просто, что у нас каждое действие, я знаю, что Артемий будет со мной не согласен, но это его личное право. Каждое действие, включая каждое высказывание, оно имеет набор каких-то эмоциональных окрасок. Что мы дальше можем делать? Вот еще раз вернемся к постановке задачи. У нас есть N акторов, которые могут совершать N дискретных действий. И мы хотим понять, прежде всего, как мы этих акторов сможем оценивать по их поведению. То есть, во-первых, нам нужно научиться вычислять оценку того или иного актора на основе его наблюдаемого поведения. Значит, самое простое, естественно, мы должны исходить из принципа Парсимоне, самое простое решение – это ввести вот такой вот линейный закон, когда мы просто-напросто интегрируем оценки всех действий, совершаемых данным актором и также по отношению к нему. Причем в качестве оценки действия мы берем как раз вот тот эффект, который данное действие производит на имидж этого персонажа. Ну, то есть тут все автоматически правильно, потому что вообще это автология. Мы как бы написали то, что ввели по определению. Значит, вот А – это тот вклад, который действие дает в изменение имиджа, актера x, x в данном случае – это еще и вектор в том самом трехмерном пространстве. R – это некая константа, которая может быть, скажем, равна одной сотой, например. Ну, некий параметр модели. То есть у нас имеется интегратор с утечкой, который просто-напросто интегрирует эффекты всех действий, каждого действия. Таким образом, общая оценка актора у нас вычисляется на основе его поведения. что, собственно, есть то, чего мы хотим. Ну, конечно, у нас для каждого действия может быть две оценки. Его эффект производимый на объект действия, на реципиента и на автора действия. Иногда это может быть близкая величина, скажем, если вдвое поздоровались, то и тот, и другой выразил что-то положительное, его положительность возросла, допустим, как его самого, так и того, с кем он поздоровался. Это отношение типа доминатности, кто-то кого-то поставил на место или просто ударил, то наоборот, у одного доминатность возросла, у другого понизилась. То есть тут, вообще говоря, могут быть либо симметричные, либо антисимметричные такие отношения. Дальше спрашивается, как теперь мы можем эту величину использовать. Допустим, мы вычислили оценку. Пока не будем вдаваться ни в какие другие детали и попробуем спроволировать самое простое, примитивное правило. Может быть, оно и не верно. Тем не менее, значит, самое простое, что приходит в голову, это значит, на хорошее нужно отвечать хорошим, на плохое – плохим, подчиняться сильному и доминировать над слабым. Вроде как люди так себя не ведут, но тем не менее, если мы такой закон напишем, Вот здесь он написан, то мы можем потом рассмотреть какой динамике этот закон приводит, если у нас теперь уже есть закон для изменения оценок каждого персонажа и закон для вероятности выбора действий на основе этих оценок. Все вместе порождает динамику. Вот мы ее, собственно, можем вычислить даже аналитически, введя еще целый ряд каких-то упрощающих предположений. Например, для упрощения примем, что каждое действие имеет ненулевую компоненту только по одному измерению в своих оценках. И вот, не вдаваясь в подробности этих вычислений, я вам скажу сразу, что ответ получается такой, что переменные разделяются в таких предположениях, и в тех измерениях, где отношения симметричны, скажем, павалентности, у нас получается устойчивым решением либо либо все положительные по отношению друг к другу, либо все негативные по отношению друг к другу. Ну, вроде бы как правдоподобно. Вот тут это написано. А что касается доминатности, то у нас получается иерархия, то есть получается, что половина всех взаимодействующих акторов становится доминирующими, половина становится подчиненными, а если их число нечетное, то кто-то еще остается посередине. Ну, это вот в таком специально придуманном случае аналитическое решение. Но теперь что же получается численно в более общем случае? На самом деле почти то же самое. Вот эти картинки взяты из моей публикации еще 2013 года, где я на самом деле не только промоделировал такую модель, но я и провел эксперименты с испытуемыми, которые играли в видеоигру. взаимодействовали друг с другом анонимно, и среди акторов был и виртуальный тоже. Они даже не могли первые пять минут определить, кто есть кто. Так вот, траектории, предсказываемые этой моделью, они мало отличаются от тех траекторий, которые получаются на реальных испытуемых. То есть, надо сказать, что вот эта очень грубая и, казалось бы, неверная модель, она все-таки в каком-то приближении неплохо описывает поведение человека. и психологию человека. Но, конечно, этого недостаточно. Мы все понимаем, что люди ведут себя не так, и суть их не в том. А в чем же? Значит, вот как уже первое предложение, Давайте введем понятие моральной схемы. Собственно, когда я придумал это слово, я хотел сказать нравственная схема, но поскольку в английском языке слово нравственный звучит как moral, то неизбежно получилась моральная схема. Я не замахивался на формализацию морали, извините меня, но получилось так. Короче говоря, эта самая моральная схема – это уже не просто какая-то там запись, какая-то форма, это уже как самостоятельный агент, который действует, имея свою цель, имея свои средства для достижения этой цели. И единственное, что он не имеет своего «я», он как бы становится частью «я» данного персонажа, когда он активируется. Но цель его очень проста. Значит, существует некое положение дел, которые считаются нормой с точки зрения данной моральной схемы. Например, когда начальник доминирует над подчиненным, или же когда двое помогают друг другу, если они друзья. Значит, вот эта норма должна всеми средствами поддерживаться. Собственно, принцип работы моральной схемы заключается в том, что чтобы поддерживать нормальное состояние, а если оно нарушено, то стремиться его достичь, используя все возможные средства, которые позволяют использовать интеллект данного индивидуума. То есть принцип очень простой, идея очень проста, но, конечно, реализация может быть очень сложной. При этом чувство определяется как то значение оценки, которое предписывается вот этим самым нормальным состоянием. То есть это то, что я думаю о другом персонаже, кто он есть на самом деле. Не то, как он себя ведет. А то, во что я верю, кто он есть на самом деле. И вот если подумать глубоко, то это соответствует как раз нашему общепринятому понятию слова чувства. Но я не говорю о чувстве боли или голода, я именно говорил о чувствах психических, психологических другим людям. И в этом смысле, я думаю, что это правильно, ввести такое определение. Как видите, моральная схема включает в себя некую схематическую карту, на которой каждый участник, каждый актор имеет определенные координаты. При этом он имеет две координаты. Во-первых, это оценка, которая у него есть сейчас на основе его поведения. Во-вторых, это чувство к нему, то значение оценки, которое считается для него нормальным. Прежде всего, эта схема должна быть привязана каким-то образом к текущей ситуации, к определенным персонажам. Она должна быть, соответственно, активирована, но об этом я еще буду говорить и так далее. Значит, вот пример, самый тривиальный пример моральной схемы – это очередь, скажем, из трех человек, которые стоят там, скажем, на посадку в самолет или у прилавка в магазине, и вот они знают, кто за кем стоит. В этом смысле у них образовалась иерархия, то есть каждый имеет свое место в этой иерархии. Если кто-то, значит, попытается пройти без очереди, то другие его поставят на место, то есть они восстановят. Это самое нормальное состояние, просто подчиняясь такому закону. Ну, конечно, можно говорить о других примерах, я еще, наверное, о них скажу. Вот здесь показан жизненный цикл моральной схемы, то есть в какой-то момент она должна быть активирована. Ну, прежде всего, это происходит на основе ассоциаций, и когда текущее состояние близко к нормальному для данной схемы, видимо, нужен еще какой-то триггер, который приводит к активации данной моральной схемы, когда она уже оказывается воплощенной в рабочей памяти системы, то ее уже просто так выбросить нельзя. Вот когда вы перешли эту границу, значит, она остается там, начинает так или иначе управлять вашим поведением. Насколько это возможно? Ну, конечно, тут нужно рассмотреть и другие факторы. Затем, ну прежде всего, может быть просто ограниченная область применимости, скажем, та же очередь, она имеет смысл только до тех пор, пока вы стоите в очереди. Другие вещи действуют на протяжении всей жизни. как отношения между близкими людьми, например. То есть, совершенно разные бывают временные рамки действия такой схемы. Но вот в пределах своих рамок она эволюционирует так, что в какой-то момент она может прийти в конфликтную ситуацию, когда значения оценок сильно отличаются от значений чувств. И вы можете либо пытаться просто путем тех или иных действий вернуть их туда, куда нужно, либо вам придется уже поменять конфигурацию моральной схемы, то есть изменить сами чувства. И в этом смысле, там, скажем, любовь перерастает в ненависть и все такое прочее. То есть, этот механизм, он уже даже объясняет Кластеризацию тех или иных эмоций, которые известны в психологии, известно, что те или иные эмоции там как-то группируются, данный взгляд позволяет как бы по-своему объяснить природу этого явления. Но если же и это не помогает, то есть вы не можете, скажем, ну умер человек или что-нибудь еще, вы не можете изменить чувство таким образом, чтобы новая конфигурация стала соответствовать действительности. Тогда уже единственное, что остается, это смена перспективы. О перспективах я тоже буду говорить, надеюсь. И тогда уже после смены перспективы происходит отторжение. Вот такой жизненный цикл, при этом ее действие вот в такой цепочке определяет поведение, то есть на вход, конечно, поступают оценки, как когнитивные на основе той самой семантической карты, так и соматические, то есть, грубо говоря, что вам приятно, что неприятно, вам прежде всего нужно чувствовать себя комфортно, если вы испытываете дискомфорт, вы сделаете все, что угодно, чтобы этого избежать. Значит, уже есть два противодействующих фактора, которые как-то здесь сливаются, и в конце концов, порождают некий сдвиг к поведению. То есть, если у вас нет других факторов, эта моральная схема, она просто будет определять ваше поведение, но если у вас есть, скажем, какая-то цель, которую вы выполняете, или план действий, значит, Это можно считать рациональным фактором, а есть еще вот данные когнитивные или нравственные факторы, а есть еще и соматические факторы. Вот эти три фактора, они как бы борются друг с другом и совместно определяют поведение, которое приводит к поведению человека, как мы его наблюдаем. При этом происходит также непроизвольное выражение эмоций на лице и так далее. Ну вот, это, собственно, даже то, о чем я говорил еще в прошлый раз, год назад. Теперь я хотел уйти в более тонкие детали, то есть мы можем записать принцип действия моральной схемы, как задачу, извиняюсь, как задачу оптимизации поиска минимума вот такого выражения, когда оценка максимально близка к чувствам. Соответственно, для решения такой задачи нам нужно опять-таки рассмотреть, как эволюционируют оценки, каким образом они могут достичь значения чувств, и мы приходим к тому, Это можно даже доказать в итоге в виде теоремы. А вот теорема, которая утверждает, что для поддержания нормального состояния нам нужно совершать действия, оценка которых равна чувству. не просто соответствует, а буквально равна, вот в математическом смысле, тогда у нас нормальное состояние будет поддерживаться. Но в какой-то мере это же позволяет нам и приблизиться к нему, если мы от него отошли. Но, конечно, это не всегда может быть самым оптимальным алгоритмом, но он работает. Если, скажем, расхождение большое, это может быть не обязательно самым оптимальным. То есть, мы можем просто предположить, что выбор действий происходит по такому принципу. Допустим, если мы не можем найти действия, у которого оценка в точности равна чувству, значит, мы берем размытую дельта-функцию, выбираем действия, где-то вот в этой окрестности находятся. И, соответственно, из этих действий мы должны строить свое поведение. Ну вот теперь из-за этой математики, тут меня в прошлый раз спросили написать как можно больше формул, поэтому я, видимо, это сделал. Можно все перевернуть наоборот и приняв вот это за аксиому, уже вывести те исходные постулаты, с которых мы начали, в конце концов, вот получается тот… закон обновления оценок, который выводится на самом деле из той формулы, которая была вот в качестве теоремы. Но это уже детали. То есть, я не знаю, насколько это интересно. Теперь нужно добавить, что ко всему этому еще и добавляется теория мыслей, так называемая. Но в психологии под теорией мысли понимают вовсе не теорию, а явление. Это способность человека моделировать мысли других агентов. В данном случае способность искусственного интеллекта. Хотя в искусственном интеллекте понятие теории мысли, в общем-то, еще с незапамятных времен, чуть ли не с самого начала использовалось, ничего особенного в этом не было, но у человека все-таки эта вещь непроста, и тут есть много деталей. И вот особенно, когда речь идет об эмоциях, что это означает? Что нам нужно фактически… моделировать каждого из агентов, с которыми мы взаимодействуем, его мысли. То есть нужно понимать не только те оценки, которые у меня есть в голове, но и те оценки, которые у него есть или у нее в голове, по отношению ко мне, к другим персонажам. И при этом другой агент может располагать другой информацией, соответственно, у него будут другие оценки. Нам все это нужно моделировать, даже для того, чтобы понять вот такие эмоции, как обида, например. Теория мысли, она строится на том, что есть некая рекурсия, но тут можно представить ее в графическом виде. В этой серии говорят о двух девочках, Сале и Энн, которые спрятали шарик в коробке, потом одна из них вышла за дверь, а другая переложила шарик в другую коробку. И вот, значит, когда она вернулась, спрашивается, где она будет искать шарик. То есть во что она верит? Шарик находится в коробке слева или справа. И, соответственно, можно строить такую бесконечную цепочку. отображений, что думает Салли о шарике, что Салли думает об Энн, где она думает о шарике, что Салли думает об Энн, думающий о Салли, и так далее и тому подобное. Но вот я заметил, что на самом деле все эти бесконечные рекурсии можно всегда свести к конечной схеме в любой конкретной ситуации, то есть если, допустим, У каждого агента в голове информация одна и та же, понятия, скажем, системы ценностей сходны, то мы просто говорим отождественности, что на самом деле Те оценки, которые в голове есть у одного, те же самые будут у другого. Если все-таки у кого-то информация неверная, то можно построить такой граф, то есть нам нужно будет создать вместо одной такой модели, одного представления, несколько, ну вот столько, сколько нужно согласно этому графу. И в зависимости от того, значит, что там произошло с этим шариком, У нас будет определенное количество узлов в этом графе, но оно всегда будет конечным и небольшим. Это можно, в принципе, даже доказать. Ну, например, можно представить себе сцену взаимодействия трех персонажей, которые сидят за столом, и, допустим, когда один из них вышел, другой подлил я в его бокал, потом тот вернулся и так далее. Что они будут думать? Значит, это все можно представить в виде такого конечного графа без каких-либо бесконечностей. Это означает только, что нам для того, чтобы смоделировать все эти ситуации, понадобится не одна, а несколько копий модели, каждая с набором всех переменных. То есть количество переменных все-таки разрастается. Да, но я хотел, конечно, все это изложить в деталях, но вот, к сожалению, не успел, потому что занят организацией конференции, как назло. И вот, короче говоря, это уже практически все, что я хочу сказать про теорию на данный момент. И скажу еще раз, что при генерации поведения персонажа, у нас происходит иногда конкуренция, иногда синергетические взаимодействия различных факторов включая когнитивный, соматический и рациональный которые совместно через моральные схемы приводят к таким поведениям теперь я хочу рассказать вам буквально приведу два примера работы моих студентов которые на самом деле на основе такого подхода, вот этой модели, которую я называю ибайка, то есть хотел называть эбика, но почему-то прижилось именно ибайка. Эмоциональная, биологически инспирированная когнитивная архитектура. Вот с помощью этой модели была вначале обучена нейросеть, которая затем управляла поведением виртуального персонажа. И вот это было сделано в нескольких парадигмах. Это было сделано в парадигме виртуального регистратора отеля. И также это было сделано еще и в той же классной комнате, и в том же «Пингвине», и в других вещах. Но вот я просто хочу ограничиться виртуальным регистратором отеля, не вдаваясь в детали. Это просто буквально, я взял слайды из презентации дипломной работы моих студентов, Вот тут описано, как все это сделано, даже алгоритм, структура реализации, на какой основе. Тут, кстати, чат GPT не был использован, был использован Deepfowl. И, короче говоря, получилось в итоге что? Получилось… Получился вот такой набор характеристик. Как видите, тут больше 20 шкал. Включая там и приятности, эмоциональности, доверия и удовлетворенности и так далее. Так вот, по некоторым из этих характеристик, это еще не самая последняя версия диаграммы, к сожалению, тут трудно что-либо понять. Результат пока такой, что даже со статистической значимостью виртуальный агент превзошел человека. То есть проводился эксперимент, когда человек взаимодействовал с виртуальным персонажем, с виртуальным регистратором отеля. В одном случае его поведением управляла нейросеть, облученная на когнитивные модели. В другом случае в другой комнате сидел человек и печатал что-то на клавиатуре, а испытуемый не знал, с кем он взаимодействует. И вот по некоторым шкалам, причем как раз вот по эмоциональности, по-моему, в данном случае, и по тем вещам, которые имеют отношение к социальной приемлемости, получился Получилась победа искусственного интеллекта. Ну, я говорю, ну все, началась новая веха в истории человечества, но студенты, конечно, могли только смеяться, для них это все было крайне несерьезно, и они даже сказали, нам это настолько надоело, что мы больше вот этой задачей заниматься не хотим. Ну, у нас у студентов другая несколько, другая ориентация, им нужно делать то, за что платят деньги. Вот другой студент, вот это уже полностью его презентацию я взял, как есть. Тут как раз использовался чат GPT, та же самая парадигма. И, значит, здесь у него… Вот видите, кроме ChargePT использовался BERT, и у него, значит, был набор Семантических категорий. Вот они определены, эти семантические категории. Например, агент подвергается мнению фразу, или он полагается на другого человека, или он оказывает моральную поддержку, или он выражает благодарность, реагирует на сложившуюся ситуацию, выражает свои чувства, принимает ситуацию, не соглашается с ситуацией. И так далее. То есть, вот такого рода вместо трехмерного пространства у него были категории. И в терминах этих категорий, значит, работала модель, которая в итоге, значит, определяла поведение этого виртуального агента. Что же в итоге получилось? Значит, смотрите. Сейчас. Сейчас. Вот тут пример диалога с виртуальным регистратором. Причем тут есть вопросы и ответы, как относящиеся к поселению отеля, так и не относящиеся. Как чат GPT он, естественно, может говорить на любую тему. Тут какие-то пока общие характеристики. Так, вот главная диаграмма, на которой показано, что по эмпатии искусственный агент превзошел человека, причем с большой статистической значимостью. В качестве испытуемых там была девушка, которая не знала ничего об этом проекте, и он ее просто попросил пройти такой тест. Она не знала, с кем она взаимодействует. Конечно, это все может быть, в общем-то, пока ерундой. То есть, по крайней мере, я вижу, что не так уж трудно достичь вот этих пределов, как казалось бы. То есть, я не говорю, что мы совершили прорыв. Но я думаю, что мы на верном пути. Я думаю, что в принципе, если по этому пути пойти, то, может быть, через год-два удастся получить реальную систему, которая будет вполне приемлема в человеческом обществе, на социальном уровне и сможет даже побеждать в конкуренции с человеком. И вот это и есть тот путь, на котором искусственный интеллект сможет победить человека, вовсе не как терминатор на поле боя. Да, но это его заключение. Значит, у меня все. Теперь вопросы, если у вас есть. 

S10 [02:41:46]  : Алексей, спасибо. Коллеги, у меня есть вопросы. 

S05 [02:41:52]  : и силы. Ну, если нет, то мы можем... Кстати, я должен сказать, я приглашаю всех на конференцию Байка. 

S01 [02:41:59]  : Я думаю, все вы знаете URL bica2023.org. 

S05 [02:42:12]  : Если не знаете, запишите сейчас bica2023.org, и мы будем принимать статьи, по крайней мере, до конца лета. Вы можете поехать в Китай, а можете участвовать виртуально в Zoom. Можете опубликовать свою работу в Q1 журнале, а можете опубликовать ее в книге Шпрингера, которая тоже индексируется в скопусе. Дело ваше. Регистрационная плата сравнительно маленькая, там 200 долларов за статью, а без статьи онлайн вы можете участвовать бесплатно. Так что я приглашаю всех, хоть со статьей, хоть просто с абстрактом, если вы хотите сделать доклад на конференции. Правда, там китайцы ввели смешное ограничение 100 человек, участников, больше которых они не разрешают, имея в виду иностранных участников. Я впервые с таким вообще сталкиваюсь, и мы уже этот предел превысили. Но вот мы договорились с организаторами, что мы попытаемся включить тех, кто даже не войдет в список этих 100. Мы все равно попытаемся их включить. Так что присылайте ваши абстракты, присылайте статьи, и с удовольствием жду вас на нашей конференции. 

S10 [02:43:36]  : Так, ну, если у кого-то есть вопросы... Да, сейчас Сергей Терехов вопрос, а, Валентина, потом вы давайте по очереди. Сергей, пожалуйста. 

S01 [02:43:46]  : Коллеги, спасибо огромное, Алексей, спасибо большое за ваше замечательное сообщение. У меня вопрос к вам по вашему докладу, по первой части. Вот он, вот какой. Вы показывали примеры систем. И все эти примеры объединяются общим свойством. Эти примеры завоевывают внимание человека и потом требуют использования времени человека на проведении им этого времени в этой виртуальной искусственно-интеллектуальной среде. Как вы считаете, это хорошо? То есть мы должны делать такой искусственный интеллект, который будет наше внимание завоевывать, и после этого мы тратим время на взаимодействие с ним, а не с реальным миром, не с детьми, не с деревьями, не с животными, не с каким-то нашим окружением человеческим. А взаимодействуем все больше и больше, как вы говорите, более эмпатично, более комфортно с вот этим вот другим биологическим миром. Можете я на такой вопрос прокомментирую? Спасибо большое. 

S05 [02:44:50]  : Спасибо. Нет, я, конечно же, так задачу не ставил, я об этом даже не думал. То есть, если так получится, то, конечно, это будет нежелательно. То есть, я против того, чтобы человек уходил от реального мира в виртуальную реальность уже последние годы. самоизоляции при пандемии показали, что ничего хорошего это нам не дает. Но я лично на себе чувствую только негативные эффекты такой самоизоляции. Но я как раз думал о другом. Я думал о том, что сейчас нас повсюду окружает множество автоматов, которые начисто лишены чего-либо социального. и даже те, которые, казалось бы, должны обладать такими качествами, те же голосовые помощники типа Сирии, Алисы и прочие, они тоже не обладают искусственным эмоциональным интеллектом и если даже пытаются сейчас на современном уровне State of the Art до сих пор, когда речь идет о моделировании эмпатии, то это сводится просто к копированию эмоций собеседника. Но это, конечно, не то, что делает человек. 

S01 [02:46:01]  : Я хочу просто, чтобы это было как бы зафиксировать. То есть вот тот человек, который, общаясь с роботом в отеле и обнаружив, высокую эмпатию со стороны квази эмпатии со стороны этого робота на самом деле не мог не ответить своей энергетикой на эту эмпатию то есть он провел там больше времени он возможно высказал какие-то дополнительные эмоциональные слова это все его энергетика его время его как бы ограниченный запас вот того как бы жизненной энергии которую не есть и она потрачена была вот на вот эту на вот этот способ взаимодействия. И, по-видимому, нельзя сказать, что это очевидно хорошо, правильно? 

S05 [02:46:41]  : Я не согласен. Нет, просто дело не в том. Вот как раз не это нужно сравнивать, а нужно сравнивать, скажем, человека, который регистрирует вас на авиарейс или поселяет в отель, и автомата, где вы стоите и нажимаете кнопки. С кем вам приятнее общаться? Я думаю, что с человеком вам общаться приятнее. 

S01 [02:47:04]  : В данном случае мне будет приятнее общаться с тем, кто быстрее просто даст мне билет. 

S05 [02:47:10]  : Я думаю, что тот, кто понимает ваше эмоциональное состояние, он быстрее решит эту задачу. 

S01 [02:47:16]  : Хорошо. Спасибо, Алексей, большое. Тут большая уже очередь на вопросы. Я не имею морального права продолжать дискуссию. Спасибо. Спасибо за вопрос. 

S10 [02:47:26]  : Спасибо. 

S08 [02:47:27]  : Валентин, пожалуйста. Да, у меня прослушал доклад, большое спасибо. Но вот слушая доклад, я так почувствовал, что он очень близко касается, скажем, с работами Симонова, но у него есть теория эмоций. Кстати, эту теорию Симонова очень хорошо разбирал, анализировал с точки зрения теории Анохина, Витяев Евгений Евгеньевич. Вы их явно граничите, но совершенно их не знаете. Скажем, про социальное поведение есть в математике такой автомат Крылова-Цеплина, стихиастический, потом с мягкими алгоритмами. Кроме того, сами психологи, но они уже давно занимаются эмоциями, может быть, не очень много продвинулись, но, скажем, в психофизике давно уже существуют модели принятия решений с уверенностью и под уверенностью с какой-то, может быть, натяжкой, но можно считать, что это уже эмоции, потому что если, скажем, Симонов вот так говорит, если человек, сделав какое-то действие, почувствовал, что вероятность приближения к цели росла, у него появляется положительная эмоция, ну это как бы понятно, я вот не почувствовал, знаете, у вас как бы связи с реальностью, с землей, с психологией, вы как-то немножко, мне кажется, ну чисто математически увлекаетесь, вы даже где-то очень близко на те теории, которые вот Крылов, Цедлин там, коллективные, социальные поведения, я не говорю, что у вас то же самое, но как бы это все там ближе к этой парадигме, а почему вы действительно обошли, вот я вам три назвал, что вы об этом даже не упоминаете, мне кажется, это ошибка. 

S05 [02:49:25]  : Нет, это не ошибка, просто я сказал в самом начале о том, что на самом деле это вторая часть моего доклада, Первая была сделана год назад, и она была целиком почти посвящена как раз обзору других работ. Просто в области исследования эмоций количество работ настолько велико, что их невозможно все… Я ведь говорю не о том, чтобы нужен обзор, 

S08 [02:49:56]  : а чтобы в вашу работу это вплеталось как-то достаточно плотно, а если вы это все обойдете… Нет, безусловно, подождите, я не обхожу, я безусловно признаю то, что где-то я пересекаюсь с другими теориями, это неизбежно, я даже… Вы не пересекаетесь, я это не почувствовал, вы граничите, причем даже граница непонятная, вы как бы ее не провели. 

S05 [02:50:21]  : То есть я, во-первых, ни в коем случае не игнорирую другие работы, я их упоминаю. Если я что-то публикую на эту тему, я обязательно упоминаю другие работы. 

S08 [02:50:33]  : Главное, как вы это будете использовать. Это тоже хороший наработанный фундамент. 

S05 [02:50:38]  : Правильно, но почему-то до сих пор та же теория Симонова не позволила реализовать практически действующий какой-то автомат. 

S08 [02:50:48]  : Не соглашусь. вот он свой семантический вывод, он, по-моему, там здорово опирается на эти вероятности и там, скорее всего, он имеет большее право эмоций вводить в свою модель, но этого пока, я вижу, не делает честно говоря, я еще с детства эту теорию не понимал вот я помню, впервые читал про нее в детской циклофедии 

S05 [02:51:10]  : выводилась эмоция из дефицита информации но как-то интуитивно это трудно принять потому что можно найти ситуацию, когда информация есть, а от эмоций избавиться все равно нельзя 

S08 [02:51:25]  : нет, эмоции бывают отрицательные, когда ее нет, а надо что-то делать, и ты понимаешь, что сейчас лопаешься в какую-то нехорошую историю, а когда ты чувствуешь, что тебе пронесло, вероятность выжить повысилась, 

S05 [02:51:39]  : Более того, извиняюсь, я еще с самого начала оговорился о том, что у меня как раз фокус внимания не на базовых эмоциях, а на сложных социальных эмоциях, о которых я, кстати, в деталях ничего и не сказал, но я подразумевал такие вещи, как там зависть, ревность, авида, чувство юмора, чувство сострадания вот про эмпатию я говорил и так далее то есть это не базовые эмоции, во-первых, понимаете? то есть они вот такими базовыми теориями просто так не объясняются 

S08 [02:52:12]  : хорошо, но базовые теории по крайней мере мы как-то с грехом пополам научились измерять, а как вы свои будете обобщенные эмоции измерять, ведь пока вы не введете меру 

S05 [02:52:24]  : ну как-то… мы, как говорится, не можем назвать, что это научно, если… а кто сказал, что я не ввел меру? я же начал… а вот вы и не сказали, и мы не поняли… я начал с того, что ввел те самые астематические карты, которые являются мерой всех этих вирусов а психологи согласились? 

S08 [02:52:40]  : но вы знаете, в психологии вот эти вещи используются уже лет сто, то есть начиная… Вы знаете, тогда вам, наверное, стоит принять участие, вот сейчас готовится конференция памяти Крылова Владимира Юрьевича, ну, у него юбилей, и в свете психологии, вот будет конференция, подайте туда какую-то работу. Я не к тому, чтобы они вас попровергли, вы там почерпнете, во-первых, ну, реальную, так сказать, поймете почву, на которой все это происходит, и если вы это не будете учитывать, знаете, вот мы тут, я смотрю, очень много вопросов из офистеха, ну и мы, как говорится, вот должны помнить эту альма-матер, пока мы Землю не чувствуем, знаете, вот я сколько на этих конференциях по моделированию психологии, в том числе того, что изобретают такие 

S05 [02:53:29]  : очень красивые математические теории, но непонятно сами понятия не описаны а красивые уравнения, там еще такое прочее есть нет, я не за этим гонюсь абсолютно как видите, у меня тут нет сложных уравнений нет, надо выступать я же не привожу сюда не притягиваю сюда за уши формализм квантовой механики, например или теорию условчивости и так далее я вообще пишу очень-очень простые уравнения 

S08 [02:53:57]  : если сравнения отражают то, что можно померить, и насколько эта мера отражает реальность, это тоже большой вопрос все проверяется экспериментально 

S05 [02:54:12]  : поставят печать? поставят печать? нет, я не интересуюсь, кто там поставит печать Алексей, Валентин, извините я все понял, я работаю с психологами научный метод, все, я следую научному методу, понятно? вот так я работаю с психологами, я хочу вам посоветовать с ними все-таки я тоже работал с психологами у меня шефом был Лин Надел, который известный психолог и другие тоже 

S10 [02:54:39]  : Валентин, давайте дадим возможность еще задать несколько вопросов. Я благодарю вас. 

S05 [02:54:44]  : Константин, ссылку на конференцию вы мне дадите, куда вы меня приглашаете? В чате напишите. Почта у вас есть? Да, есть. А вы зайдите на сайт vic23.org, там вы найдете мою почту. 

S08 [02:54:54]  : Хорошо, я вам просто пришлю. Спасибо. 

S01 [02:55:07]  : Алексей, увеличьте, пожалуйста, количество формул в ваших докладах. Нам очень нужны формулы, потому что мы воспринимаем мир через формулы. Спасибо. 

S05 [02:55:15]  : Это кто? А, вы, да? 

S01 [02:55:16]  : Ну, вы знаете, меня уже противили. 

S05 [02:55:18]  : Я думал, что я увеличил, но вот еще, видимо, недостаточно. Хорошо, я сейчас попытаюсь опубликовать статью с этими формулами, и тогда уже вы их получите в окончательном виде. Спасибо. 

S10 [02:55:33]  : Валентин, спасибо. Если можно, я думаю, не только Алексею будет интересна ссылка на конференцию. Если вы можете здесь чат сбросить, будем все признательны вам. Константин, пожалуйста, ваш вопрос. 

S06 [02:55:47]  : Спасибо, Алексей, огромное спасибо за наклад, очень интересно. И вот, кстати, возвращаясь к вопросу номер один, и когда я и там еще кто-то так жестко довольно отреагировал – нет. Ну, это потому, что в вопросе 1 слишком много было через запятую, да? Но вот в том числе, да, способность моделировать мысли и чувства людей, то, о чем был ваш доклад, ну, не вызывает никаких… никакого отторжения. Но здесь… и вы показали это очень наглядно, что важно моделировать. – Спасибо, спасибо. Это важно моделировать, но это не имеет отношения к общему искусственному интеллекту. Это частный искусственный интеллект, на мой взгляд. Это частная задача, которая очень здорово решается. 

S05 [02:56:36]  : Это большой кусок. Это очень большой кусок. Это низковисящий фрукт. 

S06 [02:56:43]  : Вот здесь я с вами абсолютно согласен, но просто когда вы к этому через запятую добавляете там свободу воли, личность, целеполагание и прочее, вот это уже вместе вызывает некое отторжение и желание сказать, нет-нет-нет, вот такого общего искусственного интеллекта мы не хотим. Амортизирование эмоций для конкретно вот улучшения общения с клиентом, да ради бога, это прекрасная задача. Еще у меня вопрос теперь уже конкретный. Моральная схема, вот вы к ней подходите с точки зрения эмоций, а кажется, что мораль это больше про систему ценностей. Это больше, например, всемирный опрос ценностей, социологическая известная такая работа. То есть если мы в виде большого, довольно высокой размерности вектора представим отношение людей к ценностям, Именно в этом пространстве люди, социумы, страны и так далее получат какие-то точки, можно решать задачи кластеризации. И мне кажется, что вот здесь ваша техника тоже очень близко смыкается с вот какой задачей. А что такое взаимопонимание? А что такое, когда люди начинают разделять в каких-то социальных группах некий ценностный код? То есть некое подмножество ценностей, которые они говорят, вот мы за это и против этого. То есть какая-то часть размерности этого вектора ценностного, они их поддерживают, позитивируют, какую-то часть негативируют и вопрос. А вот моделирование социальных взаимодействий, которое могло бы приводить к синхронизации ценностей. через эмоцию сопереживания. Вот такого рода исследование, мне кажется, просто напрашивается, потому что это вот на графах моделирования вот этих вот взаимодействий социальных, а потом через эмоцию приход к согласованию или все-таки через отрицательную эмоцию отказ. То есть вот такие, например, вещи можно моделировать, как образование конфессий религиозных, как выделение каких-то сект, как создание каких-то конфликтов в обществе, их разогрев конфликтов, пропаганда или еще чем-то. И вот эти вот все информационные воздействия, вот как повоздействовать на социальный код какой-то большой группы людей. И все эти воздействия, мы же знаем, что они через эмоции идут. Вот это было бы очень интересно начать моделировать. Безумно важно, мне кажется. 

S05 [02:59:23]  : Спасибо за этот вопрос. Я сам об этом как бы не думал, может быть, где-то косвенно. Я такую задачу не ставлю. Это, конечно, отдельная задача, и тут требуются, видимо, большие усилия. Но я согласен, что ее можно решить на основе данного подхода. В психологии существует такое понятие, как когнитивный диссонанс, который на самом деле очень близко к этим вещам, о которых я говорил. То есть, скажем, если есть одна моральная схема, которая противоречит наблюдаемой ситуации, или две моральные схемы, которые противоречат друг другу, вот вам примеры когнитивного диссонанса. Согласно тому принципу, который я сейчас вот вам излагал, поведение должно выбираться так, чтобы свести эти расхождения к минимуму. Так вот, буквально то же самое утверждают теории когнитивного диссонанса, только там это все на словах, а здесь это все как бы математически. То есть, я целиком и полностью согласен, да, это, видимо, можно и нужно делать. 

S06 [03:00:34]  : Спасибо. 

S10 [03:00:35]  : Спасибо. У меня короткий комментарий. Я всех приглашаю. Через две недели будет семинар, где я буду, в частности, тоже рассказывать про ценностные коды, про социальное расслоение, про воздействие. И можно будет продолжить эту дискуссию, потому что сегодня у нас осталось уже очень мало времени, насколько я понимаю. 

S06 [03:00:56]  : Ссылочку обязательно пришлите. 

S10 [03:00:58]  : Да, да. Тот же зум, зумы. Ровно через две недели тот же самый зум, все то же самое в том же месте, в тот же час. И продублирую. Два вопроса из YouTube подоспела от Александра Лютуновского. Вопрос. Моральная или любая другая схема? Это, я так понимаю, некий целевой активируемый паттерн или не целевой? И еще вопрос. Норма состояния, которая должна быть чувством, из чего состоит и как определяется? 

S05 [03:01:34]  : Я не могу сказать, поскольку не знаю определение целевого паттерна, но думаю, что это именно то, надеюсь. Из чего состоит нормальное состояние? Оно состоит из чувств. То есть, вообще говоря, это может относиться… ну, вот какие примеры можно привести? Я уже говорил, скажем, Отношения между двумя людьми, они могут быть, скажем, либо дружбой, либо враждой, либо подчинением одного другому. Каждое из этих состояний может считаться нормой. Отношения человека к самому себе, скажем, меня в нынешнем времени ко мне в прошлом, это может объяснить такие эмоции, как скажем, сожаления, гордость, может быть, даже стыд, хотя считается, что стыд – это все-таки социальная вещь, требующая еще и третьей перспективы. любая установка, я бы сказал, что моральную схему можно рассматривать как некое сужение понятия установки скажем, если я просто настроился пойти на прогулку или я должен сейчас сесть работать или что-то еще это уже представление о том, что вот сейчас для меня является нормой и как мне к этой норме прийти опять на основе этого же механизма то есть где-то у меня должны быть оценки, где я нахожусь сейчас вот я сейчас работаю или отдыхаю и соответственно как мне нужно эти оценки изменить своим поведением Ну и вот буквально все, что не взять в нашу жизнь. То есть я, во-первых, совсем не хочу ограничивать все это рассмотрение рамками одних только эмоций, тем более базовых эмоций. Я бы сказал, что все это должно распространяться гораздо шире на другие семантические категории. Ну, собственно, об этом уже наговорили, да. То есть, я не знаю, ответил я на вопрос или нет. 

S10 [03:03:55]  : Спасибо. Александр Балдачёв, пожалуйста. 

S07 [03:04:00]  : Большое спасибо за доклад. У меня пара коротких реплик, без вопросов. Ну, все было бы хорошо, и все споры бы у нас ушли, если бы изначально было поставлено две задачи. Понимаете, есть задача создания, скажем, искусственного интеллекта, в кавычках, или АГИИ, или создания, скажем, интеллектуального помощника. Это одна задача. И вторая совершенно отдельная задача, вот этот автомат, этот тамошник еще нагрузить эмоциями или социальными взаимоотношениями. Понимаете, что автомат сам без этого будет работать. И в этом-то суть. Давайте я просто скажу, чтобы быстрее не занимать время, у нас еще там кто-то есть. Это один вопрос, в смысле одна задача. А если нам нужно подключать какие-то социальные, адекватные, эмоциональные взаимоотношения, мы добавляем некий модуль. И кстати, ваша ссылка, почему я улыбнулся, когда вы сказали, что сейчас GBT справляется, это вот именно то, Тот помощник, который работает сам, он все делает, а ваша обвязка это всего лишь интерфейс. Интерфейс к тому помощнику или к тому интеллектуальному агенту или к тому АГИ. И тут я хочу поддержать еще Сергея Терехова, что вот честно говоря, я бы отказался от функции эмоционального общения со своим агентом. Зачем мне это нужно, если мне нужно действительно получить быстро данные, если мне нужно получить какие-то ответы из какого-то колл-центра? То есть и со многими людьми я сталкивался, что их раздражает а-ля эмоциональная окраска ботов. Бот должен просто, и тем более, что чаще всего мне нужен текстовый ответ, либо просто короткий ответ, либо да, нет, эльфовая башня. И еще хотел один момент отметить. Это не мое мнение. Это известная, отраженная в литературе и отраженная в энциклопедических статьях проблема с использованием термина эмоциональный интеллект. Термин эмоциональный интеллект исходно, даже по определению Даниэла Гульмана, не имеет никакого отношения к интеллекту. Потому что он звучит так. Эмоциональный интеллект – это способность человека понимать свои чужие эмоции, контролировать их для достижения собственных целей посредством использования, получения эмоциональной информации. То есть, если я перефразирую так, что это вот то... – Кстати, мне можно будет отвечать на ваши вопросы? – После того, да. После того. То есть я просто не прерываю. – Я забуду уже. – Да ну, на что вспомните, то и ответите. Мне, в принципе, ответа не нужно, поэтому, если вы помните это для других, то есть эмоциональный интеллект – это такой же, как кулинарный интеллект, или когда я управляю своим физическим телом – это будет физиологический интеллект. Интеллект один. Но он может управлять эмоциями, он может управлять физиологией, он может управлять моими действиями при приготовлении борща, но от этого он не станет кулинарным, физиологическим, эмоциональным интеллектом. И вот с этим нужно как-то немножко осторожнее, потому что, опять же, это не мое мнение, это общее такое положение, что автор этого термина немножко погорячился, назвав его интеллектом. 

S05 [03:07:24]  : но это также и не я, это термин, введенный Соловеем Карузо и вообще говоря, определение близко к тому, что вы сказали просто в мире сложился консенсус считать вот это дело, называть его эмоциональным интеллектом я здесь себе лично ничего присвоить не хочу, я просто следую, так сказать 

S07 [03:07:45]  : Тогда нужно как бы давать пояснение, потому что я знаю, многие люди, услышав национальный интеллект, понимают, что это некий интеллект, который как-то так работает, то есть это всего лишь управление интеллектом эмоциями. И вы рассказывали, как интеллект может управлять эмоциями. 

S05 [03:08:01]  : Хорошо, я об этом спорить не буду сейчас. Я скорее отвечу на ваше замечание, что то, что мы сделали, это всего лишь обертка к ЧАД-ГПТ. Вот здесь я не согласен, потому что если бы мы взяли голый ЧАД-ГПТ, он бы не заслужил таких оценок, как у наших систем. 

S07 [03:08:18]  : Абсолютно. Если оценивать именно эмоциональное взаимодействие, 

S10 [03:08:23]  : Александр, ну все-таки вы дайте ответить на вопрос, Александр. 

S05 [03:08:26]  : Да, ну я уже ответил, то есть это не обертка. Дело не в ЧАД ЖПТ, скорее он-то является периферией для нас, потому что мы даем ему команды. Там же обращение к чат GPT имеет три поля. В одном вы даете фразу, на которую он должен ответить, в другом вы определяете его роль, характер ответа, в третьем вы определяете предысторию всего разговора. Так вот, значит, наша система задает как раз ту семантическую категорию и окраску, в рамках которой должен быть ответ Чаджи-Пити. 

S07 [03:09:07]  : Семантическим движком работает Чаджи-Пити. Что? Семантическим движком работает Чаджи-Пити. 

S05 [03:09:15]  : Если бы он просто сам по себе работал, то никакого прочтения он бы не произвел. ну вот, я считаю, что мы раньше эту задачу решали без ЧАД-ЖПТ у нас было для этого куча средств, дебавл и отдельные нейросети, которые обучались распознавать эти различные синематические категории синтезировать текст в одной синематической категории с появлением ЧАД ЖПТ все стало проще у нас есть одно решение для всех задач но, кстати, вот из тех двух дипломных работ, которые я привел в конце одна из них была сделана без какого-либо ЧАД ЖПТ вообще и результат тот же 

S10 [03:09:58]  : Спасибо. Может закончим? Дмитрий, давайте последнее от вопроса Дмитрия Ушакова и пойдем отдыхать. Вы это заслужили. 

S11 [03:10:06]  : Дмитрий, пожалуйста. Да, спасибо большое. Во-первых, я хотел бы от психологов высказать мнение, что очень нужная работа и очень хорошая. Спасибо. Мне интересно. Я думаю, что важно например, делать устройства, которые могут эмоционально с людьми общаться, а это, я понимаю, что иногда это не нужно. В некоторых случаях это очень нужно, потому что, например, есть проблема консультирования психологического, например, люди летят на Марс в условиях изоляции, не только на Марс, или на войне и прочее-прочее, это может быть очень нужно. Но плюс к этому есть большая тема понимания состояния человека автоматического. Вот вопрос у меня, собственно, касается конкретики, которую я не очень где-то понял. Вот, например, вы говорили в последнем случае, там где у вас был чат GPT, о том, что вы выделяли определенное количество категорий семантических. Вы называли это категориями. Скажите, пожалуйста, эти категории, они у вас как-то соотносились с моральными схемами? То есть они были какой-то конкретизацией моральных схем? Или же, может быть, они как-то использовались для того, чтобы давать промпты для чата GPT? чтобы получать ответ. Вот как вся эта механика была организована, это осталось как-то не очень понятно. Может быть, вы скажете два слова об этом? 

S05 [03:11:49]  : Ну, хорошо, я говорил, но я скажу. Во-первых, мы просто не знали, как правильно эти вещи называть, но вот назвали их семантическими категориями, а вы, наверное, подскажете более правильные. Вот примеры я приводил. выражение моральной поддержки, вызов на откровенность, благодарность и так далее – вот это не базовые эмоции, это даже не эмоции вообще, это нечто более сложное, вот как его назвать – я не знаю можно ли самих осуществить с моральными схемами? нет, это скорее элементы моральной схемы я начал с того, что моральная схема использует некое очективное пространство с координатами вариантность, возбужденность, доминатность теперь представьте себе, что у вас есть многомерное пространство где измерениями являются вот эти категории И в нем вы производите какие-то там построения, динамика. по тем же законам. Вот в этом смысле, значит, так оно работает. А что происходит при обращении к чат GPT? Значит, студент долго тренировался писать запросы так, чтобы вызвать ответ в рамках нужной категории. Действительно, для каждой категории был придуман текст, который заставляет этот чат GPT выдавать высказывания в рамках нужной категории. 

S11 [03:13:23]  : то есть у вас задача системы была выдать ответ нужной категории в зависимости от того, что у вас говорил собеседник и вы учили систему подбирать категорию под слова, говоримые собеседником да, ну в принципе это должна определять когнитивная модель конечно 

S05 [03:13:51]  : этому у нас обучалась нейросеть в конечном итоге она действительно была натренирована на каких-то примерах сгенерированных то ли с помощью когнитивной модели, которую я описывал, то ли даже с помощью более простых правил, но в общем это еще так сказать начало пути в идеале это должна быть когнитивная модель, которая генерирует примеры поведения, на них обучается нейросеть, а дальше нейросеть должна продолжать обучение эффектов взаимодействия с человеком и также с другими нейросетями 

S11 [03:14:29]  : В психологии мы называем это коммуникативными интенсиями. И мы сейчас заняты автоматизацией интент-анализа. Так что мы, видимо, идем по очень близким путям. 

S05 [03:14:45]  : я должен буду с вами тогда связаться дело в том, что я вот уже обсуждал все это с Артемием Кмотовым и он использует другой термин «де-сценарий», который он сам взял но я почему-то подумал, что нам этот термин не подходит а вот коммуникативные интенции, это может быть поле правильное надо будет с вами обсудить да, я буду рад с вами встретиться либо в зоне, либо непосредственно когда она будет удобна, поговорить об этом если вы, конечно, сможете это просто нужно, потому что да, я согласен, тут очень большая потребность к психологическому обоснованию всех этих вещей и конечно вот тех основ, которые я использую, их может быть и недостаточно я уже сказал, что я тут полагаюсь и на нейрофизиологию, на данные из нейрофизиологии вот, например, Антонио Дамасио имеет свою теорию тех же эмоций на основе нейрофизиологии конечно, я полагаюсь на теорию оценок, appraisal theory, это основа, так сказать которую я в полной мере, в общем-то, рассчитываю здесь. Ну, конечно, есть еще и другие вещи типа теории когнитивного диссонанса и так далее, которые тоже надо здесь. включать и, конечно, строить это не на голом месте, а используя правильную терминологию, правильные ссылки. Я надеюсь, что вы мне, может быть, тоже в этом поможете. если вам позволить этим летом, буду рад с вами встретиться и связаться в Зоне и об этом поговорить но в принципе, тут путь, конечно, основан на эмпирическом исследовании мы строим теоретическую модель, воплощаем реализацию в компьютере, проводим эксперименты на испытуемых, собираем данные, анализируем, проверяем те или иные гипотезы и дальше модифицируем модель и так далее собственно вот по этому пути мы уже несколько лет идем причем первый шаг – это прохождение ограниченного теста тюремы мы начинаем с того требования, что такой артефакт должен быть неотличимым от человека а дальше уже добиваемся того, что он должен быть социально приемлемым, эмпатичным и так далее сами понимаете, этот процесс непростой К сожалению, у студентов свои цели, свои планы приходят и выходят, а работу как-то нужно выполнять и это действительно большая проблема. Будем надеяться, что все удастся. 

S10 [03:17:59]  : По-моему, мы уже заслужили небольшой отдых. Хорошо. Спасибо большое за помощь в организации и в большей степени, собственно, и в организации проведения. Надеюсь, мы еще не последний раз встретимся в такой конфигурации. Спасибо, Алексей. Спасибо всем участникам. Алексей, что-нибудь скажете в заключение? 

S05 [03:18:27]  : Спасибо огромное всем. Еще раз приглашаю всех на байку. либо физически в Китае, в городе Нинву, рядом с Шанхаем, либо в Zoom. Это будет с 13 по 15 октября, а постерная сессия 8 октября. Присылайте абстракты, присылайте свою биографию коротенькую, этого уже достаточно, чтобы мы вас включили в число участников. 

S10 [03:18:56]  : Спасибо. Я всех приглашаю на наш семинар через две недели, который будет посвящен докладу на тему «Близкие сегодняшние». Я направил ссылку в Zoom и можно у нас на сайте тоже прочитать тему семинара. Мы поговорим про социально-доказательную модель. Поведение, познание, cognition. Я согласен с Алексеем, что, наверное, правильный перевод английского слова cognition в контексте наших разговоров – это не понимание, а это именно познание. 

S05 [03:19:37]  : Это скорее не познание, а мышление. Да, мышление. Если вы посмотрите на англоязычную литературу, начиная с Википедии, вы поймете, что это так. 

S10 [03:19:49]  : Да, тут я с вами согласен. Коллеги, на этой позитивной ноте заканчиваем. Всем спасибо и до свидания. До новых встреч. Спасибо. Пока. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
