## 12 января 2023 - Коэволюционирующий Гибридный Интеллект и его приложения - Кирилл Кринкин (кандидат технических наук, доцент, заведующий кафедрой математического обеспечения и применения ЭВМ СПбГЭТУ «ЛЭТИ»), Юлия Шичкина (доктор технических наук, профессор кафедры вычислительной техники СПбГЭТУ «ЛЭТИ») — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/IHBn57oAxCs/hqdefault.jpg)](https://youtu.be/IHBn57oAxCs)

Суммаризация семинара:

Семинар касался темы коэволюционирующего гибридного интеллекта и его приложений. Коллеги из Санкт-Петербурга Кирилл и Юлия представили свою работу, в ходе которой были затронуты следующие ключевые моменты:

1. Определение и цели исследования:
   Коллектив обратил внимание на искусственный интеллект в течение более двух лет, сосредоточив свои усилия в области компьютерных наук и анализа данных. Они сформировали определенное видение развития направления, акцентируя внимание на необходимости интеграции человеческого и машинного интеллекта.

2. История и развитие искусственного интеллекта:
   В ходе семинара были рассмотрены изменения в идеях, возникших на Дартмутском семинаре, который положил начало понятию искусственного интеллекта. Обсуждались основные задачи ИИ, такие как автономность компьютеров, использование нейронных сетей, демонстрация творчества и креативности, программирование и общение с компьютером на естественном языке. Было отмечено, что с 1956 года удалось продвинуться в взаимодействии с компьютером на более высокоуровневых языках, хотя и не включая семантику, способную человеком демонстрировать.

3. Новые подходы к гибридному интеллекту:
   В прототипах гибридного интеллекта, таких как система с голограммами, акцент делается на интерфейс человека-компьютер. Рассматривается возможность построения гибридной модели между моделью, построенной на данных, и набором правил. Также обсуждалась важность рефлексии и самоанализа в контексте коэволюционирующего гибридного интеллекта.

4. Критика и новые перспективы:
   Был поднят вопрос о том, что некоторые подходы к машинному обучению с учителем обладают существенным недостатком: inability to identify and formalize certain behaviors. Обсуждалась проблема извлечения невербальных знаний и возможности использования системы для обучения человеку.
   
5. Взаимодействие человека и машины:
   Понятие коэволюции было использовано для описания процессов, в ходе которых происходит взаимодействие и развитие человеческих и машинных интеллектов.

6. Антология знаний и машинное обучение:
   В ответах на вопросы было уточнено, что в текущем прототипе гибридного интеллекта не используется наработка с антологиями знаний. Обсуждалась возможность использования систем машинного обучения для извлечения данных и автоматического построения антологий.

7. Эволюция и коэволюция в технологиях:
   Вопросы о коэволюции были рассмотрены с точки зрения взаимодействия технологий и эволюции общества. Обсуждалась адаптация инструментов искусственного интеллекта для решения конкретных задач в сотрудничестве с человеком.

8. Обсуждение и обратная связь:
   Обсуждение было направлено на получение обратной связи и поиск новых перспектив в развитии гибридного интеллекта, в том числе через обмен мыслями и идеями с собравшейся аудиторией.

В целом, семинар представлял собой платформу для обсуждения современных подходов к развитию гибридного интеллекта, включая вопросы взаимодействия человека и машины, адаптации инструментов ИИ и коэволюционных процессов в технологиях.







S02 [00:00:02]  : Вот, и коллеги, всем здравствуйте. Сегодня у нас в гостях коллеги из прекрасного Санкт-Петербурга. И Кирилл и Юлия нам расскажут про свою работу над коэволюционирующим или коэволюционным гибридным интеллектом и его приложениями, его приложениях. Кирилл, Юлия, пожалуйста. Здравствуйте, коллеги. 

S03 [00:00:31]  : Меня слышно? Да, значит, я сделаю немножко вначале небольшое такое самопредставление. Мы с Юлей действительно работаем в Аэротехническом университете в Санкт-Петербурге. Вот, и какое-то время уже, скажем так, более двух лет обратили внимание на тему искусственного интеллекта, но так, более сфокусированный у нас бэкграунд у обоих такой компьютер-сайенс, вот, анализ данных и, в общем, это в области, вот. И за вот это время, последние там два-два с половиной года, Мы сформировали определенный vision, такое определенное видение, как нам кажется, куда движется и куда должно развиваться направление. Ну, нехорошо говорить искусственного интеллекта, я буду говорить, наверное, просто интеллекта. Потому что будет у меня пара слов о том, почему нельзя, на наш взгляд, совсем разделить, сделать искусственный интеллект и делать его каким-то похожим или другим. Естественный интеллект, нет этого разделения. Я надеюсь, у меня там у нас огромный слот времени. У меня нет столько, конечно, материала на такую прям лекцию. Ну, вернее, это было бы, наверное, неправильно поделать. Поэтому я вижу следующий формат. Я расскажу о том пути, который мы прошли, о тех наработках, которые были сделаны до нас и том, что делаем мы конкретно. А потом, ну, наверное, было бы здорово с собравшимися коллегами в режиме вот такого диалога обратиться к разным частям рассказа, может быть, где-то более детально чего-то обсудить, может быть, выйти за рамки. Тех слайдов, которые я представлю, мне кажется, что это, по крайней мере для нас, главной целью участия, почему мы с радостью приняли предложение Антона. Главной целью является получить такой фидбэк, пообсуждать и потрясти с разных сторон наши мысли и идеи. Начнем. Тут маленькая очень картинка, но тем не менее внизу есть ссылка, можно будет после семинара, я слайд предоставлю, можно будет по ней сходить, походить. Начали мы с того, что попытались представить в виде такой карты изменения идей, которые возникли на Дартмутском семинаре. когда возникло понятие искусственного интеллекта, построить такую карту, как эти идеи трансформировались, во что они сейчас преобразовались. Если обобщить то, к чему мы пришли, то можно сказать, что один из таких взглядов представить, если сначала основными задачами, которые должен решить искусственный интеллект, были автоматизация компьютеров, то есть их автономность, достижение автономности, использование нейронных сетей, демонстрация творчества, случайности, креативности, Программирование или общение с компьютером на естественном языке. Должна была решена задача размера вычислений. И, собственно, самая сложная вещь – способность к абстрактному выводу, абстрактному мышлению. и тому, что с этим связано. Можно сказать, что в некоторых направлениях начальных человечества исследователи-разработчики достигли определенного результата. Мы знаем, что сейчас нейронные сети отлично работают в ряде властей, даже способны проявлять, я не знаю, можно ли это серьезно называть творчеством или нет, но, по крайней мере, случайность в процесс строения каких-то моделей точно могут демонстрировать. Достаточно хорошо с тех пор, я имею в виду, с 1956 года мы продвинулись для того, чтобы взаимодействовать с компьютером на более высокоуровневых языках. Конечно, это не те языки, которые, скажем так, включают в себя семантику, которую способен человек демонстрировать, но, тем не менее, прогресс какой-то есть. Немного продвинулись в сторону автономности, то есть какие-то, скажем так, высшие уровни автономности вряд ли достижимы в ближайшее время, но в каких-то весьма ограниченных условиях такая автономность может быть продемонстрирована. Ну и где мы, на наш взгляд, или на мой взгляд, не продвинулись, совершенно не продвинулись в области размеров вычислений. Известно, что современные нейронные сети, например, существенно зависят от вычислительных ресурсов, хотя решают такие же задачи, которые биологические системы могут решать на несколько порядков, меньше затрачивая энергии, вычислительной какой-то энергии. Совершенно, на мой взгляд, не продвинулись в области абстрактного вывода, абстрактных моделей. Пока кажется, что это все-таки прерогатива человека. Ну и если говорить о том, что сейчас, на наш взгляд, важно, ну это такой не полный список, это вот тот, скажем так, та проекция, которую мы обсуждаем, над которой мы работаем. Значит, первое – это самообучение и способность эффективно действовать в неопределенных открытых окружениях. Вот это интероперабельность интеллектуальных систем, причем не какая-то интероперабельность по данным, а это интероперабельность именно на уровне решения интеллектуальных задач. Как подкласс когнитивная интероперабельность человеком, ну, наверное, очень важно все же говорить о энергоэффективности, но есть работы, мы этим не то чтобы занимаемся, но немножко у нас есть ряд результатов экспериментов в области строения биологической обратной связи, я про это говорить не буду, но если кому-то интересно будет это пообсуждать, мы можем об этом рассказать. Это нейроинтерфейс, или можно говорить, что сигнальная интероперабельность с человеком. Ну и если вот обобщить вот этот вот набор позиций, то кажется, что можно сфокусироваться в развитии интеллекта, искусственного интеллекта на вот таких вот основных позициях. Я прошу прощения, у меня часть слайдов на русском, часть на английском, но я думаю, что, наверное, эта аудитория позволяет такой микс иметь. Значит, первая важная вещь, значит, нельзя рассматривать искусственный интеллект, здесь важность его, искусственный интеллект, просто как какой-то tool, то есть какой-то инструмент, потому что он требует, любой инструмент, вместе с повышением его сложности, он требует определенных изменений в социуме для того, чтобы этот инструмент вообще можно было использовать. То есть сложность инструмента связана со сложностью того, кто его использует. Дальше понятно, что очень важно, чтобы системы интеллектуальные были способны объяснять свои решения, и это очень важно для взаимодействия машин и людей, то есть искусственных и естественных интеллектуальных агентов. Можно декларировать, что Machine Learning не является таким ответом на все, хотя многие так еще по-прежнему считают. Есть достаточное количество областей, где машинное обучение и нейронные сети хорошо работают, но в то же время есть области, в которых они не могут работать по определению. Понятно, что Все еще важно заниматься различными математическими моделями или моделями математических вычислений для построения интеллектуальных систем, то есть математически доказуемыми. На наш взгляд ключевой, ключевым направлением является human-machine integration и их когнитивная коэволюция, я про это буду как раз говорить. И, собственно, понятно, что приложения в разных областях. Мы попытались вместе с коллегами, попытались сформулировать некоторое такое видение, как вообще можно заниматься развитием интеллектуальных систем. Ну и пришли к такой вот картинке. Значит, картинка говорит о следующем, что, во-первых, интеллектуальные системы и вообще развитие интеллекта не может быть сделано без, скажем так, ориентации на какие-то задачи конкретные. То есть невозможно выращивать интеллект просто ради интеллекта. Он всегда предметен. Поэтому его развитие является ответом на какие-то реальные задачи. Это могут быть задачи, не знаю... моделирование экосистемы, могут быть задачи моделирования пандемии, ну и все что угодно, с чем человек сейчас не способен справляться. Или моделирование человеческого тела и организма и так далее. А, собственно, разработка должна быть синхронизована и должна вестись в трех областях одновременно. Первое – это в области концепций, потому что без концепции невозможны какие-то принципиально новые решения. В области технологий, потому что если у нас, даже если есть концепция, но не существует технологизированного способа производства каких-то решений, продуктов, например, или каких-то конкретных вещей, которые может применять человек, то, собственно, никакого применения не получится, не получится мостика к человеку. Ну и третье, понятно, что должны быть продукты, то есть должен существовать рынок, на котором появляются востребованные инструменты, решающие вот те самые задачи или их части, которые, собственно, инициируют такого рода разработку. Понятно, что это все должно быть увязано с исследованиями, образованием, рынкообразованием и системой разделения труда. Я к этому не буду сильно апеллировать, это не предмет нашего разговора, но тем не менее сошлюсь на классика. Значит, еще в 1962 году Энгель Барт, размышляя о построении интеллектуальных систем, практически нарисовал ту же самую схему. То есть он нарисовал ее по-своему, но важным является то, что он отметил, он строил не искусственный интеллект или какой-то интеллект, он строил модели расширения человеческого интеллекта. И отмечал то, что невозможно строить какие-то, создавать какие-то интеллектуальные решения или какие-то машинные реализации интеллектуальных решений, интеллектуальных задач без оглядки на то, как это будет использовано человеком. То есть вплоть до изменения в социальной системе и связанных вещах. Мы когда добрались до понимания этой картинки, которую я показывал на предыдущем слайде, по сути дела, читая Энгельбарта, мы нашли много похожего. немножко с другой стороны и под другим углом зрения было подано в Энгельбарда, но тем не менее. Ну и когда мы говорим о разработке интеллектуальных систем, нам надо иметь какие-то критерии развития, то есть как-то уметь мерить, насколько мы успешны. Ну и здесь я сошлюсь, конечно же, на шале. который в 2019 году дал, на наш взгляд, подходящий способ измерения мощности интеллекта. Он говорит примерно следующее, что, если так очень сильно загрубить, Он говорит о том, что, собственно, интеллект связан со способностью обобщать знания или обобщать какие-то способы действия в реальности, или способы адаптации, и переносить это в другие условия, то есть использовать знания, полученные в одном окружении, в другом окружении, ну и как путь вот этого переноса опыта или переноса знаний, он указывает на способность обобщать. Ну и дальше такой предлагает вывод, чем более система способна обобщать знания и переносить их из одной среды в другую, тем она более интеллектуальна. Ну, собственно, это хорошее, то есть это, конечно, не все инструменты или не все измерители, которые нам нужны для обсуждения интеллекта, его мощности и силы, но вот это кажется хорошей очень такой отправной точкой. Но мы, в свою очередь, если вот вернуться к слайду вот этому, то есть мы начали, вот я сказал, что нам нужно иметь активности в трех, а я не знаю, мой курсор мыши видно или нет? Не видно, наверное. Ну, в общем, нам нужно иметь... Видно курсор. Не видно, да? Да-да, видно все. А, видно, да, отлично. Значит, нам нужно иметь активность во всех трех вот этих вот квадратах, да, и, собственно, вот в этом квадрате наша концепция – это коволюционирующий гибридный интеллект, о котором я чуть позже расскажу, ну и связанные с ними технологии, которые уже, скажем так, прикладной части. Ну, надо сказать, что вообще гибридный интеллект – вещь далеко не новая, если говорить просто про гибридный интеллект. И существует он уже, ну, минимум 20-25 лет, наверное, такой термин. Наиболее, ну, таким, что ли, современным взглядом на то, что содержит гибридный интеллект, какие направления в нем есть, является вот этот вот документ, который был опубликован в 2020 году группой исследователей. Они попытались обобщить, собственно, вот идею гибридизации интеллектуальных систем, а по сути дела обобщить направление развития взаимодействия человека и машины при решении интеллектуальных задач. И они вот определяют, гибридный интеллект как комбинацию человеческого и машинного интеллекта, когда человеческие возможности расширяются возможностями, которые предоставляет машина, и совместно они способны достигать таких целей, которые человек без такой инструментализации достичь не может. То есть, по сути дела, Они говорят примерно следующее, что... Вот наш взгляд на гибридный интеллект, их взгляд на гибридный интеллект – это реализация идеи Унгельбарта, когда кто-то дизайнит, кто-то создает систему, которая подразумевает интеграцию человека, человеческих агентов и каких-то инструментальных средств автоматизированных, искусственного интеллекта, для решения конкретных задач. То есть создатель системы по-прежнему является где-то в стороне решаемой задачи. То есть он должен ее осознать, он должен сконфигурировать способ решения, создать инструменты и запустить какую-то деятельность, решающую эту задачу. Мы же опираемся на это определение и делаем шаг вперед. Мы говорим, что коэволюционирующий гибридный интеллект – это симбиоз естественно-искусственного «интеллекта», которые совместно развиваются, взаимообучают друг друга, ну и, собственно, проявляют некоторую… Мы говорим коэволюцию, хотя, конечно, в биологическом смысле это довольно странно говорить, но давайте говорить когнитивную коэволюцию. общая мощность вот такой развивающейся системы интеллектуальной, она возрастает, в смысле шале, например. И основными, скажем так, ключевыми идеями, на которых базируется кеваляционирующий гибридный интеллект для нас, является когнитивная интероперабельность, то есть способность взаимодействовать с машиной на когнитивном уровне, на уровне когнитивных функций, коэволюция, то есть передача знаний или каких-то ну, скажем так, извлеченных знаний и фактов из деятельности совместной друг к другу, от машины к человеку и человек к машине, и рефлективность, то есть способность, скажем так, анализировать свое предыдущее состояние и модифицироваться. Вот здесь указана работа, где мы такое определение дали. И она будет, наверное, там где-то есть в ссылках, которые Антон рассылал. Для того, чтобы как-то это визуализировать, можно сказать следующее, что если посмотреть на искусственный интеллект, этот взгляд на искусственный интеллект, который есть сейчас, то это выглядит примерно так. Человек развивает инструмент, он делает его все более и более сложным и, собственно, по дороге делает применяет его для создания все более и более сложных инструментов. Если же говорить на гибридный интеллект или гибрид, эволюционирующий гибридный интеллект, то человек развивает не просто инструменты, он развивает себя, использующего инструменты. Модификация системы происходит целиком, всей гибридной системы. посмотреть на историю развития компьютерной техники интерфейсов, по сути дела, человек адаптируется к интерфейсам, и интерфейсы адаптируются к человеку. Даже слова нас задают, потому что, например, 10 или 15 лет назад существовало понятие, или было введено понятие, наверное, больше, пользовательский интерфейс, а теперь уже как бы мейнстрим называть то же самое не UI, а UX, то есть пользовательский опыт, то есть как опыт, как пользователь интегрирован в систему. Вот мы все это делали-делали. Но в 20-м году, то есть в декабре 22-го года, то есть буквально там месяц назад, вот вышел такой меморандум Фристона, который, собственно, очень, скажем так, я думаю, что все присутствующие его уже видели, который, собственно, очень многие вещи, которые мы разрабатывали, описал в таком более системном виде. И, собственно, получается, что можно как бы, встраиваться в том числе и в то, что описывает Фристон. Вот, ну, я вот выделю несколько вещей, которые важны. Фристон определяет интеллигенс очень интересно. Он говорит, что интеллигенс – это способность системы генерировать доказательства своего собственного существования. Ну, такие, как бы, определение встречались и раньше, но тем не менее, по сути, следствие из этого определения такое, что интеллигенс – это свойство активных агентов, каких-то агентов, способных взаимодействовать с миром и находить отражение себя в мире и мира в себе. Я немножко тут абстрактно говорю. Следующий момент. Основное поведение или основной инструмент существования этого агента – это активный вывод, active inference. Говорится примерно следующее, Интеллект существует только с позиции и развивается только с позиции активного, то есть тестирования среды, в которой он находится. То есть извлечение каких-то знаний, использование их дальше. Дальше очень интересная мысль. интеллектуальные агенты должны быть в той или иной мере embodied, то есть как бы представлены в физическом мире. То есть эта мысль кажется симпатичной по той простой причине, что действительно в какой-то, по-моему, в 2020 году, я, к сожалению, здесь не привел эту ссылку, но скажу. В 1920 году в Nature была статья, которая говорит примерно следующее, что сильный искусственный интеллект невозможно понять, и если он будет создан, то его невозможно будет понять по одной простой причине, потому что машины просто не существуют в реальном мире. То есть они способны вычислять, они способны обрабатывать сигналы, но знаний или контакта с реальным миром у них просто нет. В некотором смысле человек является таким контактом, но об этом чуть позже я скажу. И опять же, вот этот вот Фристон и товарищи говорят следующее, что интеллектуальные агенты могут быть биологическими, ну вот в смысле как бы не обязательно человеческими, но можно найти какие-то зачатки или даже незачатки интеллекта и в других животных. Некоторые ищут и в растениях. В общем, это отдельная дискуссия. Вот, интеллектуальные агенты могут быть машинными, ну то есть компьютерными, да, и, собственно, быть комбинацией. И вот в нашем как раз фокусе лежит вот эта вот комбинация и о том, как эта комбинация, на наш взгляд, является, собственно, ключевой для построения интеллекта. Вот, дальше. Инструментом Взаимодействие или развитие агентов является belief propagation, то есть возможно в виде графов или сетей. Это постоянно выстраиваемое с помощью Active Inference модель мира является предметом для взаимодействия интеллектуальных агентов. Ну и коммуникация – это, собственно, ключевой момент здесь. И кажется, что до сих пор мы, как люди, исследователи, недооценивали коммуникацию. То есть, на наш взгляд, вот эта история о том, что можно создать изолированный интеллект, неважно, как его назвать, общий, сильный, еще какой-то, в какой-то отдельной банке, Она довольно странная, потому что даже, я об этом пару слов скажу, даже с точки зрения оценки, анализа или доказательства того, что этот интеллект является интеллектом, с ним нужно уметь коммуницировать. И коммуницировать ровно на том уровне сложности, на котором этот интеллект способен проявлять свои когнитивные способности. Вот теперь, собственно, о некоторых... в проблемах, которые привели нас вот в текущую ситуацию. Проблема номер один – это множество всяких разных определений интеллекта, искусственного интеллекта и связанных вместе с ними каких-то других слов, которые используют обычно для описания построения продуктов или интеллектуальных систем. Можно взять Гарднера. Гарнер много чего определяет. Например, говорит, что artificial intelligence, искусственный интеллект способен предлагать какие-то продвинутые техники интеллектуальные, которые демонстрирует человек. С точки зрения Гартнер, искусственный интеллект – это просто некоторое моделирование того, что человек делает. Если посмотреть на спектр и определение интеллекта, то спектр очень широк. Кто-то определяет интеллект как способность адаптироваться, кто-то определяет интеллект как способность вводить символы и оперировать с этими символами в символном пространстве, кто-то определяет еще как-то, но, наверное, правильно будет привести дискуссию, ну, напомнить просто, что существует дискуссия, которую инициировал Пейванг, не помню, по-моему, в восемнадцатом году, девятнадцатом, Он сказал примерно следующее. Вообще, довольно сложно заниматься развитием искусственного интеллекта и обсуждать разные его черты, поскольку мы до сих пор не определились не только с тем, что такое интеллект, но и с тем, как мы этот интеллект интерпретируем при создании интеллектуальных агентов. Он выделил несколько категорий, обобщающих, в которые более-менее хорошо ложится ложится понимание того, что называют интеллектом или искусственным интеллектом. Первое – структурированный интеллект. Действительно, если говорить о системе, которая устроена точно так же, как мозг, и способна так же, как мозг, обучаться и демонстрировать потом такие скажем, вещи как распознавание, как трансляцию, в общем-то то, что делают нейронные сети в настоящее время, то можно считать это искусственным интеллектом. С другой стороны, можно считать интеллектом некоторые поведенческие AI, то есть способность системы в тех же самых условиях демонстрировать какое же самое поведение, например, адаптационное поведение, что и человек. Тоже хорошая вещь, причем здесь интересно, Значит, что в этом определении совершенно не говорится никак о… никак не говорится о том, каким образом вот эта модель поведения возникает. Она может возникать путем обучения, например, в нейронных сетях, а может возникать другим способом. Дальше. Capability AI – еще более абстрактная вещь. Можно считать искусственным интеллектом такое свойство системы, которое позволяет решать задачи такой же сложности. Здесь, конечно, возникает куча вопросов о том, как определить класс задач, как его измерить. Но, тем не менее, это тоже довольно интересный взгляд на определение искусственного интеллекта. Или вот следующее. Functional или Function AI. То есть, по сути дела, это говорится о том, что искусственный интеллект должен быть способен делать точно такую же функциональную декомпозицию задач или действий, как и реализовывать ее, как и человеческие. например, ну или там principle AI – это самое сложное, да, то есть давайте укажем просто набор принципов, которые определяет интеллект, да, дальше эти принципы позволят сгенерировать систему любой сложности. Вот, то есть, ну, P-bank запустил большую дискуссию на этот счет, которая пока еще ничем не завершилось, то есть было высказано много различных мнений. Ну, в общем, это большой разговор, подводя итог. Поэтому, вообще говоря, когда мы обсуждаем развитие искусственного интеллекта или интеллекта, Надо понимать, что во многом это обсуждение связано с языком и контекстом, в котором мы это обсуждение ведем. Следующий момент. Что-то не на том месте слайд у меня. Ну ладно, я к нему вернусь. Хотя нет. Имея вот это вот большое количество определений, надо сказать следующее. Несмотря на то, что есть вот этот вот хороший подход, который нам предлагает Шале, о том, что интеллект может быть измерен как способность к обобщению и переносу опыта, у нас до сих пор нет никакого теста Тьюринга. То есть Тьюринг высказал идею невозможности распознавания машинного или человеческого агента, но на самом деле это не работает, особенно не работает, когда мы говорим про создание Я не люблю это слово, но буду использовать. Сильного искусственного интеллекта. Получается как? Предположим, с одной стороны, что этот интеллект может быть создан. Окей, мы его создали. Но если этот интеллект сильнее, например, человеческого интеллекта, то каким образом можно в этом убедиться, если способности к обобщению человека меньше. Никак. Получается, здесь тупик. С другой стороны, если этот интеллект там тоже, опять же, предположить, что он существует, то каким образом можно установить с ним взаимодействие? Тоже непонятно, потому что вроде как такой Типичный или общепринятый подход, но не всеми он разделяется. Многие разделяют, что интеллект – это нечто, созданное в дата-центре или в какой-то коробке условно-компьютерной, способное думать. Ну, не так. Поэтому проблема, вообще говоря, построения или отсутствие понимания, как должен быть устроен тест Тьюринга, тест на наличие интеллекта, она остается открытой, и она мешает двигаться вперед, равно как и множество определений, которые у нас есть. Ну вот мы с вами, вернее, я сказал, что Вот здесь я повторюсь, чтобы был плавный переход. Я говорил следующее, что мы говорим, что эволюционный гибридный интеллект, который мы развиваем, это некоторый симбиоз, который базируется на следующих вещах. Когнитивная интероперабельность, коэволюция и рефлективность. я перехожу к объяснению того, что мы понимаем под когнитивной интероперабельностью. если посмотреть на классические учебники по тому, как работает мозг, можно увидеть следующее, что на самом деле одни и те же функции мозга выполняют разные его отделы у разных людей, то есть не существует прямой связи между конструкцией мозга, собственно на нейронном уровне, этими нейронными сетями и функцией. Да, есть корреляция, но тем не менее такой прямой связи нет. Тогда возникает вопрос, а как же мы собираемся устроить когнитивную интероперабельность, то есть интероперабельность на уровне когнитивных функций, если нет такой связи. Об этом чуть дальше. Но если посмотреть на работу такого нейрофизиолога Пол Чисек, Он делает очень хорошую классификацию. Он говорит следующее, что если посмотреть на то, как устроен мозг и как он эволюционировал в процессе появления, развития в природе, то вообще говоря, можно найти некоторую связь. между когнитивными функциями и структурой тех частей мозга, которые эти функции реализуют. Это обозначает следующее, что если мы будем фокусироваться не на мозге целиком, например, да, а на каких-то когнитивных функциях, ну, например, не знаю, способности выделять объекты или способности к трансляции одного языка в другой, или способности например, поиска, то на уровне таких примитивных когнитивных функций мы в принципе можем создать такие взаимозаменяемые интерфейсы, которые можно, ну не для всех когнитивных функций это возможно, но тем не менее, можно заменять ту же самую когнитивную функцию либо человеческой реализацией, либо машинной реализацией. хоть какой-то, хоть какой-то между ними будет протокол условно. Вот, ну вот если так посмотреть, какие есть когнитивные, ну очень много есть классификаций когнитивных функций, даже медики, с которыми мы взаимодействовали, они честно признаются, что вот определения интеллекта у них нет, Но они могут сказать следующее, что вообще принято считать, ну вот те медики, с которыми мы разговаривали, что принято считать, что интеллект – это система когнитивных функций при решении какой-то задачи. То есть выглядит это так, что вот, ну я очень упрощен, конечно, это не так выглядит, что есть некоторая номенклатура когнитивных функций. Есть некоторый набор базовых операций, которые могут быть задействованы совместно, операции, которые способен человеческий мозг выполнять, они могут быть задействованы при решении задачи, то есть при возникновении какого-то стимула, который требует адаптации. И в этом смысле, если мы посмотрим на вот эти когнитивные функции, или здесь написано «сложные ментальные операции», то можно увидеть, что часть из них как-то может быть выполнена машинами, например, память. Мы можем найти какие-то не знаю, похожести, вот, а часть в принципе не может быть выполнена машинами, ну, по крайней мере, сейчас, да, например, вот intelligence, да, способность к абстрактному мышлению, вот, и это наводит нас на мысль, почему мы этим занимаемся, нашим вот коалиционирующим гибридным интеллектом, наводит на мысль, что если на уровне когнитивных функций уметь строить человека машинные системы, то они будут способны решать гораздо более мощные задачи, сложные задачи, чем по отдельности. И, собственно, это некоторое развитие идеи Энгельбарда в том числе, ну и многих других. Значит, что есть еще интересного, что позволяет нам об этом с некоторым оптимизмом думать? Ну вот я сошлюсь всего лишь на две работы. Обе этих работы – это нейрофизиология. Первый – это Танони. который придумал и развивает на протяжении уже 10 лет интегральную теорию информации, которую некоторые считают или называют математической теорией сознания. Но, честно говоря, На мой взгляд, до сознания это довольно далеко, но некоторые вещи, некоторые свойства сознания, которые, на взгляд, Танони приводит как доказательство математические сознания, они интересны с точки зрения моделирования когнитивных процессов на компьютере. Вот вторая книжка, вернее, статья, это Грациана, который говорит о некой attention scheme theory. которая говорит, ну в двух словах сводится к тому, что человек, это вот к сложности вычисления, что человек заменяет сложный мир, который ему доступен через его сенсоры, там глаза, уши и так далее, некоторым набором абстрактных сигналов, некоторым набором абстрактных символов, и внутри вот этих символов он уже может принимать решение, делать некоторый вывод. Для этого нужно две вещи. Первое – это уметь вводить символы и их распознавать. А второе – это уметь синтезировать и впоследствии применять правила, которые могут быть применены к этим символам. и могут быть протестированы обратно в реальности. Собственно, вот этот активный инференс или активная обучение, активный вывод, про который Фристон говорит как ключевым фактор, это, собственно, вот некоторый способ уточнять вот эту символическую модель мира и фильтровать, по сути дела, этот мир, распознавая в нем объекты, связанные с символами. Но это не новая информация, это, в общем, такая довольно известная история. Что же касается Грациана, ой, этого Таноне, он говорит очень интересные вещи. он говорит, первое, вот это свойство сознания, на его, значит, взгляд, он говорит, первое, сознание существует, да, и в этом смысле он даже ссылается на Декарта и говорит, я вот, ну, правда, он его перефразирует, да, он говорит, я имею опыт, то есть я имею опыт получения опыта, я бы так сказал, следовательно, я существую, да, и это не что иное, как то, о чем говорит, опять же, в своем меморандуме Фристон, то есть это, как бы, по сути дела, его определение intelligence, то есть он говорит, интеллект – это, собственно, поиск доказательств своего существования. Смотрите, люди из разных, как бы, со всем областей, А очень похожие вещи говорят. Дальше. Композиция. Оно не говорит, что сознание структурировано. В нем можно различить различные аспекты объектов, различные способы думания о них, способы распознавания, и оперировать отдельно с этими аспектами. Это тоже намекает нам на то, что моделирование среды – это один из активных, используемых инструментов развития интеллектуальных агентов. дальше оно не говорит, что сознание информативно, то есть каждый испытываемый опыт явно отличается от другого. то есть как бы всегда можно найти некоторую дельту, которую либо объяснить, либо обозначить, либо просто ввести, то есть различать. дальше он говорит, что сознание интегральное. что это значит? это значит, что невозможно разные части некоторого распознаваемого объекта воспринимать по отдельности. Он приводит в своей статье несколько примеров, здесь я один вставил. То есть красный треугольник не может действительно восприниматься как сумма чего-то красного и треугольника. Это некоторый цельный объект. И в этом смысле демонстрируется некая связность. Есть некая, скажем так, отсылка к тому, что говорится о том, что belief некоторого агента веры модель может передаваться с помощью каких-то сетей либо графов. то есть вот это отсылка к связности. ну и эксклюзион. эксклюзион очень хорошо демонстрируется психологическими тестами, где нужно распознавать фон и фигуру. то есть агент не может одновременно распознавать два противоречащих друг другу аспекта. Вот это как бы на наш взгляд, на мой взгляд, в том числе является некоторым ориентиром со стороны нейрофизиологов о том, как структурировать создание вот этих и как вообще строить протокол вот этого когнитивного взаимодействия. Итак, мы говорим, что есть новая концепция, которую мы вводим на базе гибридного интеллекта, коэволюционирующий гибридный интеллект. Здесь немножко я пропустил, я не хотел об этом рассказывать. Поскольку мы рассматриваем всегда человеко-машинное взаимодействие, нам важно понимать, что человек – это тоже некая часть системы, которая обладает своими характеристиками. И эти характеристики меняются во времени. То есть человек, действующий с утра, его когнитивные способности, Они отличаются от человека, действующего вечером после 12-часового рабочего дня, хотя он делает то же самое, что не скажешь о машинах. Поэтому, когда мы говорим о гибридной системе, мы должны учитывать параметры человека внутри нее и учитывать его способности реализовывать вот эти когнитивные функции. И может быть, и даже не может быть, а в том числе для того, чтобы оптимизировать общую мощность интеллектуальной, в кавычках, этой системы гибридной, мы должны заменять часть когнитивных функций человека, на те, которые могут быть реализованы машиной, пусть и с каким-то более малым ухудшением качества решения задачи. Дальше нам нужно строить индивидуальную модель человека, уточнять его границы работоспособности, очень выгодно использовать биологическую обратную связь. вот и тренировать человека да ну и вот когнитивная интероперабельность это то о чем я говорил в прошлом на прошлом слайде вот если говорить немножко про коэволюцию то что, на наш взгляд, сильный интеллект здесь зря написан, но тем не менее, к более интеллектуальным системам. Основной процесс, обеспечивающий движение к более интеллектуальным системам. Отчего зависит скорость этой коэволюции? Во-первых, от степени формализации когнитивных функций. Мы говорим, что если когнитивные функции можно как-то формализовать, писать их интерфейс, то тогда можно будет строить какие-то гибридные системы. Дальше. Технологичности переноса опыта, знания от человека машине или наоборот. Я потом пару слов скажу о невербальном опыте и невербальных знаниях, которые человек не способен извлечь, а машина способна. Ну и легкость интеграции продуктов каких-то решений на базе интеллекта в систему разделения труда. Когда интеллект или сложность системы возрастает вместе с людьми, которые ее используют, тогда, собственно, не существует никакого процесса перехода, не существует процесса обучения, не существует проблемы неадекватного использования инструмента. Дальше вот такой немножко иллюзорный пример. Но, на мой взгляд, он важный. процесс сомоделирования и создания совместной онтологии. Здесь онтологию я использую не в смысле способа представления знаний, а в смысле некой системы понятий, в которой осуществляется деятельность какая-то. Как я уже сказал, интеллектуальный агент, и не только на наш взгляд, Это некая действующая сущность, может быть, стадичная штука. По сути дела, создание вот этой общей системы понятий, в которой можно взаимно обучаться и действовать, это процесс согласования антологии, ну или символов, которые представляют вот этот мир. Я отсылаюсь опять на Горциана, к его attention scheme theory. Значит, и дополняю, вот смотрите, если есть два агента, по сути дела, когда они могут взаимодействовать друг с другом, когда у них есть общее распознавание какой-то ситуации или каких-то объектов в реальном мире, то есть у них есть своя символическая модель этого мира, и они способны также сопоставить, то есть провести процесс сопоставления этой модели некоторому такому же понятию в модели другого агента. Причем если на Фрисмана сослаться, он как раз говорит, что у каждого агента своя персональная belief model, то есть модель мира абсолютно своя какая-то, но именно способность находить общие символы является основой для коэволюции. То есть что это такое? Но есть у философов такой такое высказывание, что университетский профессор может о чем-то договориться или может понять дикаря только тогда, когда горячий песок обоим жгет пятки. То есть у них появляется некоторая общая ситуация, символ внутри их модели мира. И если об этом поговорить в смысле человека и машины, на примере, например, машинного обучения, то можно сделать следующее. Машина может извлекать какие-то особенности, например, это я очень ограниченный пример говорю, из данных. Человек способен их распознавать и именовать, потому что машина не имеет более широкого контекста. Да, и таким образом как бы человек может передавать дополнительные знания машине. И вот в процессе вот этого согласования антологий, опять же антологии в смысле системы понятий, вот со-развитие, это и есть вот как бы или со-моделирование и коэволюция, это и есть вот этот вот процесс согласования антологий внутри какой-то решаемой задачи, совместно решаемой задачи. Вот. Наверное, буду закругляться с докладом, лучше прийти к обсуждению. Последняя вещь, которую мы оформили в виде небольшой работы, это некая когнитивная архитектура конволюционирующего гибридного интеллекта. Значит, ну вообще к слову, когнитивная архитектура относится, ну как бы сначала относилась только к человеку, его способности, вот реализовывать вот этот вот цикл восприятия, осознавания, адаптации. Вот. И, собственно, потом она, значит, уже стала применяться и в машинных системах, и в человекомашинных системах. Ну вот одна из интересных Статей на этот счет, там была представлена некая комитивная архитектура. компьютерной системы. И здесь, собственно, есть все блоки, которые связывают входные сенсоры. Первое – это какое-то распознавание, сенсорика, perception, распознавание первичной модели. Там же находится механизм внимания, который позволяет обращать внимание на какие-то важные для задачи решения. Есть уровень извлечения знаний и их накопление, то есть, по сути дела, реализация поведения человека, специалистов предметной области. Дальше есть какие-то более-менее инструментальные вещи, связанные с построением модели мира, планированием действий и исполнением. Ну, собственно, мы как бы попытались вот в рамках той концепции, которую я рассказывал, встроить сюда человека. И, собственно, что у нас получилось? Получилось следующее. Сразу пункт номер один. Никакие существующие вещи, связанные с искусственным интеллектом, никуда не пропали. Они нашли свое место. Второе. в этой когнитивной архитектуре рассматривается с двух позиций. первое – это человек как субъект, то есть человек, способный реализовывать какие-то когнитивные функции, то есть что-то делать, какую-то работу производить интеллектуальную, и человек как объект, то есть человек как нечто, демонстрирующие эти функции. Я уже сказал, что каждый человек делает по-своему. Один и тот же человек делает это в зависимости от каких-то обстоятельств, хуже или лучше. И, собственно, получилось так, что все на предыдущем слайде представленные блоки, они в этой архитектуре присутствуют и, более того, ложатся на собственно, архитектуру коэволюционирующего гибридного интеллекта, то есть есть область человека субъекта, есть область человека как объекта. Ну, пару слов о некоторых блоках. Я не буду здесь останавливаться на всех. Есть статья, ее можно прочитать, значит, по поводу моделей активности и неявных знаний. Дело в том, что вот такой straightforward подход, который часто применяется в машинном обучении с учителем, то есть когда у нас есть какие-то данные, значит человек их размечает, ну или там полуавтоматически они размечаются, или они обогащаются с помощью симуляции, вот он обладает одним существенным недостатком. Дело в том, что человек сам по себе способен проявлять какое-то поведение, способен проявлять какие-то поведенческие паттерны при том, что не способен их идентифицировать и формализовать. То есть, например, если мы будем говорить про обучение, в школьное обучение или обучение каким-то видом спорта или еще чего-то невозможно зафиксировать знания таким образом, чтобы можно было их каким-то волшебным способом передать другому человеку его обучить. например, опытный водитель, гонщик, он может что-то сформулировать, но гораздо лучше это за него сделает наблюдающая за ним интеллектуальная система, построенная на примитивных каких-то методах машинного обучения. Поэтому извлечение вот этих неявных невербальных знаний является одним из таких очень обещающих, что ли, свойств таких гибридных систем, про которые мы вот сегодня говорим. И, наверное, это самое важное. Я забыл об этом сказать. Есть дополнительный процесс, который мы ввели в эту когнитивную архитектуру, в pipeline вот этого perception. и так далее. Мы ввели некоторый процесс, который называется рефлексия, reflection. Значит, если вовлечь активно человека и саму вот, не знаю, его инструментализацию вокруг него в процесс как бы Самоописание или самоанализа, насколько хорошо решается задача, если машина может предъявить ему, где ошибки. Например, обучение какому-то виду спорта. Можно посмотреть, понаблюдать за человеком, который учится, а потом ему предъявить. Вот здесь это не так. И таким образом можно поднастроить разные части системы, как человеческую обучить, так и машинную. И примеры таких приложений. У нас много всяких разных проектов, в которых мы пытаемся разные части технологии отрабатывать. устоявшаяся и еще пока только на уровне концепции, я поэтому не стал там приводить много слайдов. я вот так расскажу. во-первых, новый-старый взгляд на автоматизированную систему. что это такое? я на следующем слайде покажу. значит, например, Хорошее применение – это такой knowledge management или knowledge extraction, когда гибридный агент, то есть человек, оснащенный пусть даже системой машинного обучения, способен все больше и больше извлекать знаний. Как это работает? Например, возьмем врача. Врач анализирует какие-то снимки. он способен их размечать, он способен создавать датасет, который обучает, на котором можно обучить систему, построенную на машинленинге, потом эта система начинает обучаться, вернее, начинает применяться, начинает сшибаться, систематизируя и называя, например, типы ошибок и, может быть, даже приводя какие-то правила, которые их описывают, можно вот эту систему обучать и передавать знания человека к машине больше, то есть такое инкрементное обучение. С другой стороны, Например, если это какой-то врач, делающий МРТ, например. Но если таких пользователей, допустим, много, сотни или тысячи, можно посмотреть и выявить паттерны их поведения, их классифицировать, связать с ошибками. И тогда получится, что мы можем извлечь знания из поведения пользователей невербальные, предъявить их, собственно, человеку, где он их как-то квалифицирует, и, собственно, получится передача знаний в обратную сторону. Как я уже сказал, можно, это такое мелкое приложение, заниматься оценкой функциональной готовности человека, его функционального состояния. Очень обещающая вещь – это персонифицированная медицина, персонализированная медицина. Дело в том, что текущий подход, по крайней мере о том, который я видел и слышал на конференциях, на мой взгляд, на наш взгляд, немножко наивный. Ну, давайте, как бы, соберем кучу данных о человеке, давайте их разметим, обучим, значит, какую-то машину, и она будет там классифицировать и ставить диагноз. А врачи говорят, ну, умные, да, они говорят так, что подождите, каждый человек индивидуален, границы нормы для каждого свои, да, и мы не можем А если составить действительно какой-то аватар человека цифровой, мы должны этого конкретного человека наблюдать долго за его процессом функционирования. И то, что мы построим к концу его жизни, будет являться собственно его моделью. Но тогда получается парадокс. Тогда получается, что мы должны к каждому человеку добавить еще одного человека, который будет размечать его данные. А потом, значит, ну то есть какой-то странный получается такой буст трэп. Вот поэтому наша идея какая? Вот если человеку дать инструменты предоставления обратной связи, там допустим наблюдающая система за ним говорит, вот у тебя изменились вот такие параметры, давай анализировать. он получается сам, как бы такой конструктор своего цифрового двойника. здесь вопрос в правильных интерфейсах. а когда человек сам начинает замечать свои данные, сам пытается разобраться, может быть с помощью врача, но когда это его забота о построении своего такого цифрового аватара, и он ей занимается каждый день, тогда возможно построение какой-то модели, которая показывает рамки адекватности или адекватно идентифицирует проблему. Как я сказал, это тоже самое касается и построения различных смарт-окружений вокруг людей, и поведенческий анализ, и обучение. Я приводил пару примеров. Ну, есть куча всяких вещей. Это слайд такой больше не для такой, наверное, аудитории. Понятно, что нейросетевые решения сильно ограничены. Да, вот теперь про взгляд на автоматизированные системы. Еще 20-30 лет назад считалось, что автоматизированная система – это система, состоящая из персонала и комплекса средств автоматизации в деятельности человека. Так сложилось, что в области искусственного интеллекта человек как-то забылся, и все стали строить интеллект без человека. Ну, не все, но многие. Ну и, собственно, если посмотреть на то, как цифровой двойник строится для того, чтобы управлять чем-то, почти всегда в контуре есть человек. Не всегда, это не так. То есть, если приложить вот эту архитектуру на реальную какую-нибудь задачу, например, задачу управления фабрикой чем-то еще, то, в общем-то, мы получаем такую уже вполне себе практичную архитектуру, информационные системы, которые подразумевают человека бесшовно интегрированного во все процессы. Ну, я, наверное, в силу, так сказать, уже большого количества времени, которое использовал, пропущу всякие мысли, которые больших компаний на этот счет есть. Вот сошлюсь на тот проект, который мы делаем с рядом партнеров, Это система оценки функциональной готовности. Она такая прикладная, она не очень связана с эволюционирующим гибридным интеллектом, но, тем не менее, это часть, которая позволяет оценивать состояние человека и его способность решать задачи. Есть как подчасть, опять же, очень интересная разработка, которую мы сейчас доводим до ума, это неинвазивное детектирование состояния человека по пульсу, то есть это детекция, это просто висит там камера или несколько камер, и они способны усиливать сигнал, который связан с притоком крови, кожи, извлекать оттуда пульсовую волну. По пульсовой волне можно очень много чего о человеке сказать, о его состоянии, о смене состояний. Но опять же, это все работает, если мы в течение какого-то довольно длительного времени этого человека наблюдаем, извлекаем как бы его какие-то характеристики реальные. Еще один проект, который мы тоже делаем, это связано с эпилепсией. Здесь история такая. Врачи хорошо умеют размечать данные, но не то что размечать, они очень хорошо умеют идентифицировать ситуации какие-то в данных, но они не могут свести этот опыт к разметке этим данным. То есть они могут сказать, ага, вот это вот связано с этим, Но размечать данные – это слишком трудоемкая задача, и она часто содержит очень много шума. Потому что это другой уровень просто работы с этими данными. И вот мы пытаемся как раз выйти, но пока на начальном этапе, на такую вот систему гибридную управления данными, когда сначала примитивные сигналы размечаются, потом идентифицируется, собственно, врачебный опыт по выделению каких-то важных вещей уже в размеченных сигналах, в обработанных сигналах, извлечение его опыта. Вот. Ну и, собственно, да. На этом я, наверное, закончу. Я бы предложил какие-то вопросы задавать. Наверное, я всех уже утомил. 

S02 [01:07:55]  : Да нет. У меня все. Хорошо. Спасибо. Сейчас давайте мы перейдем к вопросам. Там есть часть вопросов из YouTube. Значит, отчасти у нас прямо в группе. Значит, первый вопрос от Бориса Новикова. ИИ – это у вас агент или это свойство агента? 

S03 [01:08:20]  : И это что? В каком контексте? ИИ. ИИ. Ну, смотрите, я как-то не очень четко, может быть, это произнес. Я говорю следующее, что вообще мы говорим не про искусственный интеллект, мы говорим про интеллект и про то, как он проявляется или может быть измерен в каком-то интеллектуальном агенте. Я иногда мешаю терминологию, но это в силу тех же самых причин, о которых я говорил. У нас нет единства в определениях. Поэтому можно говорить, что это свойство. Интеллект – это свойство. 

S02 [01:09:00]  : Спасибо. Я думаю, Борис именно это уточнял. Следующий вопрос, который, как я понимаю, многих комментаторов и слушателей интересует в той или иной форме. Первый этот вопрос задал Владимир Смолин. Кто определил те области, в которых машинное обучение не может работать в принципе? Вы говорили, что машинное обучение там-то, там-то не работает в принципе, насколько я понял. Было услышано. На основании чего эти решения принимаются? 

S03 [01:09:38]  : давайте так. это, скажем так, не некоторые номенклатуры областей. я могу привести пару примеров просто. вот один из них я приводил. ну вот есть человек и функционирование его. если говорить про машинное обучение, то классическая задача, ну если мы не говорим там о reinforcement learning, я не знаю, как его можно здесь применить, но обычное обучение на данных с учителем или без учителя, то невозможно создать такой датасет, который бы адекватно аппроксимировал человека. То есть невозможно создание такого датасета относительно конкретного человека, который бы мог использоваться для того, чтобы обучить систему машинного обучения, для того, чтобы она выдавала с большой точностью его состояние или прогнозы в отношении его состояния, просто потому что некому этим заниматься. Я приводил пример, что тогда мы должны на каждого человека поставить дата-сайентиста, который будет этим заниматься. То есть некоторые данные невозможно просто достичь. Некоторые процессы очень большие. То есть, например, если мы зададимся целью создать на базе машинного обучения модель функционирования, ну, не знаю, биосферы, ну, довольно сложно себе это представить. Ну, это мое мнение. Можно с ним как бы... Спасибо. 

S02 [01:11:09]  : ...дискутировать, да. Спасибо, Кирилл. Владимир, вы хотите уточнить свой вопрос? 

S04 [01:11:15]  : Ну, типа того, что если вы никогда не сможете смоделировать мое поведение, считаете ли вы, что у вас нет интеллекта? 

S03 [01:11:22]  : Нет, не считаю. 

S04 [01:11:23]  : Вы считаете, что если машина не может смоделировать мое поведение, почему у машины нет интеллекта? 

S03 [01:11:31]  : Смотрите, я обопрусь на медиков, на определение интеллекта, которое дают нам медики. Они говорят, что это система когнитивных функций. Но церковники, наверное, тоже могут нам дать? Да, конечно. Или у нас как бы некоторые огороды, тут медики, а там все остальные. Я с этой позиции не согласен. Значит, смотрите, как система когнитивных функций для решения какой-то задачи. Вот среди тех когнитивных функций, которые есть и которые некоторые реализации интеллекта складывают, есть те, которые реализуются только человек. Например, абстрактное мышление, выделение символов и вывод. 

S04 [01:12:24]  : То есть вы считаете, что ничего такого никогда невозможно. 

S02 [01:12:27]  : Владимир, спасибо за ваш вопрос. Вот здесь вот как раз на эту тему следующий вопрос из Ютьюба, когда он пришел от Сергея Новикова. Смотрите, Сергей Новиков утверждает, что в области как раз абстрактных моделей будущее уже наступило. Чад ГПТ даже в нынешней тестовой версии способен поддерживать научный диалог на уровне идеи и концепций. А к самостоятельным обращениям и выводам ЖПТ пока не готов, но это дело уже техники и нескольких месяцев года обучения и настроек. Следующее утверждение. И третье заявление, которое я могу сформулировать. Следующим образом, что вот у нас, к примеру, есть Миджорни, знаменитый, с недавнего времени. Вот мы ему говорим некоторые абстрактные слова, а он, опираясь на эти абстрактные слова, на символы, которые мы говорим, он рисует какие-то варианты чего-то связано с этим, ну то есть мы ему говорим там нарисуй котика и он нам рисует разных котиков вот исходя из видимо какого-то образа котика который у него где-то там есть который является на самом деле достаточно абстрактным потому что тех котиков которые он в итоге рисует они разные соответственно вот отталкиваясь от того что люди наблюдают общаясь с жпт или с миджорни не можем ли мы сказать что на самом деле Он обладает абстрактным мышлением по факту? 

S03 [01:13:58]  : Смотрите, что я об этом думаю. Я с чат ГПТ начну. Что это такое? Это некоторая аппроксимация. Это поисковая машина, по сути дела, с продвинутым интерфейсом. То есть, да, понятно, что есть некоторая внутренняя модель того, что написано в интернете, в документации еще где-то. И, собственно, может быть, меня покидают помидорами, но я тем не менее скажу. Это продвинутый интерфейс к поисковой машине. Вот. И это первое. Второе. А кто является источником тех данных, тех абстрактных символов, на основе которых вот эти модели учатся? Не человек ли? То есть это и есть примитивная реализация, ну как бы какая-то реализация некоторой гибридной системы. И если мы продлим, так сказать, вот в будущее такое размышление, если люди начнут с помощью чат ГБТ, ГПТ или чего-то еще, дообучать эту модель или генерировать новые символы, которые связаны с новыми предметными областями или с какими-то вещами, которые раньше не были символизированы. Фиксировать эти знания – это и есть не что иное, когнитивная интероперабельность на уровне языка, которого мы говорим. То есть символы это генерирует человек. Понятно, что механическое генерирование символов возможно, но привязка этих символов к реальному миру – это вопрос. Можно ли машина такое делать? То есть попробуйте извлечь человека из этого процесса. Будет ли чат ГБТ существовать? 

S02 [01:15:57]  : Спасибо за ответ. Есть три вопроса от Бориса Новикова. Борис, я не очень понимаю контекст, в котором эти вопросы заданы. Может быть, вы их сами озвучите и привяжете к конкретному контексту, чтобы было понятно? 

S05 [01:16:13]  : Да, я попробую. Так, меня слышно, да? 

S02 [01:16:17]  : Да-да, слышно, пожалуйста. 

S05 [01:16:19]  : Значит, если интеллект – это свойство агента, а не агент, то гибридный интеллект – это гибридная система, состоящая из естественного и искусственного агента, а не их интеллекта. Агенты, кроме интеллекта, имеют массу других свойств. 

S03 [01:16:44]  : Как звучит вопрос? 

S05 [01:16:46]  : Значит, вопрос в том, что Нужно различать интеллекты агента и различать интеллект сознания и психику агента. И на прошлом семинаре я представлял свое видение философской этих вопросов, что нужно различать реальность и модели. И что вы говорили, что человек такой, как... субъект или как объект, не человек как субъект или как объект, а модель человека как субъект или как объект. И при этом модели можно делать самых сложных систем. Ну, например, солнечные системы, если брать нас как элемент солнечной системы, людей и всех животных, это очень сложная система. А если брать только движение планет, то это очень простая система, и есть ее модель Кеплера-Ньютона, вполне очень хорошая для определенного круга задач. Поэтому сложность модели определяется не столько объектом моделирования, сколько кругом задач, для которых эта модель делается. 

S03 [01:18:04]  : Ну, я понял, это, в общем, не вопрос, это тезис. Спасибо, что вы его говорите. Я вот что скажу по этому поводу. Я с вами согласен, ну, согласен в целом. Детально, не знаю, надо подумать, посмотреть ваш семинар. Но ведь помните, я говорил вот о чем, что интеллект всегда, ну, как свойство, он всегда проявляется в некоторой деятельности и всегда соответствует какой-то конкретной задачи, конкретному контексту. Потому что ничего абстрактного, как бы висящего в воздухе, невозможно продемонстрировать свойства интеллекта, если оно как бы не связано с каким-то решением задачи, какой-то существующей задачи. 

S05 [01:18:52]  : Да, конечно, но нужно различать, с моей точки зрения, решение задачи и постановку задачи. Постановку задачи может делать только агент, у которого есть свои интересы и цели. 

S03 [01:19:06]  : Это правильно, я с этим абсолютно согласен. 

S05 [01:19:09]  : Значит, поэтому, собственно, на мой взгляд, и нужна гибридная система, потому что искусственному интеллекту не надо давать свои интересы и цели. А надо ему ставить задачи, когда интересах и целях людей. 

S03 [01:19:26]  : Давайте я прокомментирую. Мне это симпатично, но у меня есть такая персональная мысль, что поскольку цели биологических систем вытекают из ограниченности к жизни, Чего не наблюдается внутри компьютерной системы. Мы можем замоделировать это, но это не будут цели этой системы. Это будут ограничения. Поэтому, возможно, так и не будет. что у компьютерной системы будет какая-то там цель, мотивация и так далее. Но не знаю, это вопрос уже такой философский. А вообще, почему бы и нет? 

S02 [01:20:13]  : Борис, Борис, Борис, давайте все-таки не превращать диалог на все-таки много народу. Вас, наверное, еще будет возможность задать вопросы. Мне хотелось бы вот еще, Кирилл, вас что уточнить. По-моему, у самого Бориса был такой вопрос, я бы хотел сейчас на нем акцентировать. Согласно определению и Герцеля, и Паиванга, и, по-моему, еще ряда товарищей, интеллект или общий интеллект – это про достижение целей. Есть разные варианты. Ограниченные ресурсы, ограниченные возможности. Сложные цели, сложные среды, но в конечном итоге про достижение целей. Понятно, что человеческий интеллект достигает каких-то целей. Искусственному интеллекту тоже цели можно поставить. В вашей картине гибридного интеллекта все-таки у него есть, могут быть какие-то цели или это просто, когда мы говорим про гибридный интеллект, это вот просто некоторая, как это, человеко-машинная инфраструктура, где есть вычислительный агрегат и есть человек с целями и он ставит цели этому агрегату агрегат этим помогает ему эти цели достигнуть вот где в вашей конструкции давайте давайте я вот так отвечу и сразу как бы убегу значит но в смысле из дискуссии значит я считаю что 

S03 [01:21:42]  : цели должны быть у этой гибридной системы. А вот разговор о том, кто является их источником, я бы в него не ввязывался. 

S02 [01:21:54]  : Спасибо. И тогда еще сразу тоже простой вопрос-ответ без дискуссии. Вы в какой-то момент сказали, что вам не нравится определение сильный искусственный интеллект. Вы можете прокомментировать по поводу вот почему оно вам не нравится, во-первых. Во-вторых, Как вы соотносите сильный искусственный интеллект и общий искусственный интеллект? Какое отношение между ними? 

S03 [01:22:23]  : Смотрите, ответ будет парадоксальным. Мне не нравятся общий искусственный интеллект и сильный искусственный интеллект. Почему? Потому что мы не до конца все разобрались, что такое и пытаемся его классифицировать. Мне кажется, что это упражнение может быть полезное, но не фундаментальное. Можно говорить, что сильный интеллект – это, не знаю, Как бы даже сложно сформулировать корректно, что такое задачи, например, которые превосходят возможности человека. Какого человека, в какой конфигурации, чем оснащенного, группы людей. То есть это настолько, скажем так, для меня персонально. Я знаю, что это, может, сильно не популярно будет звучать, но тем не менее, мне кажется, что эта классификация, она как бы вредна. вот я бы говорил просто про интеллект я бы говорил про способности его там или способы его оценки разных может быть даже аспектов ну вот шале один предлагает вот но не говорил бы про там сильный общий в общем это на мой взгляд я до конца не понимаю что за ним стоит 

S02 [01:23:46]  : Спасибо. И еще пара вопросов на понимание. Вы в какой-то момент сказали, что у агента должен быть имбодимент. Причем вы, как мне показалось, сфокусировали на том, что у него должен быть эмбодимент в реальном мире. А вот возникает вопрос, причем я этого неспроста задаю, мы эту тему тут на наших семинарах неоднократно поднимали. А разве не может быть или может быть эмбодимент, но в виртуальном мире? Я вот даже приведу один пример, что вот возьмем ситуацию, что есть некоторый агент, который в виртуальном мире взаимодействует с некоторыми агентами, которые являются, грубо говоря, представителями реальных агентов из реального мира. И этот виртуальный агент, допустим, там есть какой-нибудь персонаж в компьютерной игре. И он пользователем этой игры, которые в этой игре участвуют, заходя в нее с терминалов компьютерных, он им дает некоторые указания, что им нужно сделать в реальном мире. А они ему рассказывают, что они сделали, что происходит в реальном мире, а он на основе этого дает им следующее указание. То есть вот такое вот. 

S03 [01:25:00]  : Но смотрите, это техническое рассуждение. Технически это Виртуальный агент, получается, имеет свой embodiment в виде реального человека. То есть опыт присутствия в реальном мире передается через интерфейс игры Аватару. Но попробуйте отрезать вообще в принципе это взаимодействие. 

S02 [01:25:26]  : Окей. А тогда предположим, что вот у нас есть некоторая игра, где некоторые агенты в ней взаимодействуют с друг с другом. Кто-то у кого-то отбирает какие-то артефакты, кто-то кому-то дарит какие-то артефакты. И все это происходит в виртуальном мире. Это все не настоящее. даже два игрока играют в виртуальном мире в шахматы и кто-то из них расстроился кто-то обрадовался кто-то из них выиграл кто-то проиграл и они не могут за счет это то есть это не будет проявлением их интеллекта я немножко по-другому может быть сейчас на другой вопрос отвечу вот 

S03 [01:26:08]  : Что дает… Сейчас я сформулирую. Это вот Борис Новиков на это намекал. Может, он на другое намекал, но я это услышал. Значит, смотрите, присутствие человека в реальном мире с ограниченностью его жизненного ресурса, заставляет его извлекать из этого мира все больше знаний или какого-то опыта, чтобы обеспечивать себе такие модели, которые позволяют ему адаптироваться лучше. Никакое извлечение дополнительной информации из environment, созданного человеком, как бы в среде вот этих виртуальных агентов, играющих друг с другом в шахматы, не существует. то есть они живут в рамках детерминированной системы, они могут ее соптимизировать, ну как-то свое поведение, кто-то кого-то поглотит или там будет какой-то баланс, какой-то вычислительный процесс оптимальный с какой-то точки зрения организуется, но никакой информации о конструкции этого мира, о том, что еще оттуда можно будет извлечь, там, не знаю, гипотезу по МКР, никто из них доказывать не будет. Вот в этом смысле я считаю, что целеполагание внутри как бы виртуальных миров, сложившихся случайно, ну, человек создал среду, а там что-то сложилось, какие-то процессы, ну, это некоторое Ну, это такой самообман, который, ну, простите, я буду резок, который как бы говорит, ну, вот эти, как бы, это, наверное, интеллект. Нет. На мой взгляд, это просто некий вычислительный процесс, который, ну, зашел в какую-то фазу. 

S02 [01:28:00]  : Спасибо. Следующий вопрос у Бориса Новик от Бориса Новикова, который еще и руку поднял. Но мы все-таки будем идти по порядку вопросов, Борис. Предыдущий вопрос от Бориса. У биологических видов есть очень разные мозги и с разным поведением. Как это учесть? 

S03 [01:28:20]  : Учесть для чего? 

S02 [01:28:22]  : Борис, тогда уж поясните, пожалуйста. 

S05 [01:28:25]  : Ну, говорилось, что нужно строить искусственный интеллект, ориентируясь на мозги человека. Интеллект есть не только у людей как способность решать задачи и приспосабливаться к внешней среде с помощью интеллекта. Ну, приспособление шире, чем интеллект, но если он у вас немного, например, или у ворона, которые решают разные задачи, но мозг устроен совершенно не так, как у человека. 

S03 [01:28:58]  : Смотрите, во-первых, я все-таки не говорил, что надо строить интеллект по образу и подобию человеческого мозга. Я говорил, что пей Ванг, вводит структурный интеллект, который как бы… А я говорю… Да, и все такое. То, что я говорил про систему когнитивных функций, я имел в виду следующее, что можно говорить, что эти функции существуют как бы реально, потому что они… Ну, я свое мнение… Можно говорить, что существует модель. Хорошо, давайте в этом языке говорить. Существует модель, которая позволяет эти функции различать, которая позволяет эти функции описывать. И хороший фильм «Мой учитель-осьминог», на который, наверное, вы тоже ссылаетесь, говорит о том, что между человеком и какими-то другими биологическими объектами возможны коммуникации. Возможно, коммуникация при решении задачи. Там собака помогает человеку охотиться. Они коммуницируют не на уровне структуры мозга, которым они устроены. Они функционируют на уровне как бы общей цели. Правильно? И если им удается организовать интерфейс друг с другом, например, вот если мы вместе загоняем слона, то тебе достается кусок мяса. то это проявление некой гибридной системы. 

S05 [01:30:30]  : Антологии у них совсем разные. Собака видит одни цвета, человек другие и так далее. Антологии у них совсем разные. Не нужны одинаковые антологии. Нужны именно возможности коммуникации в рамках определенной модели для определенной задачи. Ни больше, ни меньше. 

S03 [01:30:50]  : У них, смотрите, у них должна быть общая онтология в части цели. 

S05 [01:30:57]  : Нет. Окей. У собаки цель получить кусок мяса от хозяина, а у хозяина убить медведя или оленя. У них разные цели. 

S03 [01:31:11]  : Я услышал. Спасибо. У меня нет дополнительных аргументов. 

S02 [01:31:16]  : Хорошо. Спасибо, Борис. Спасибо, Кирилл. Есть еще вопрос от Ольги Заречной, которая всех поздравляет, что, оказывается, мы параллельно с Пивангом решаем одни и те же задачи. И от нее есть вопрос. Получается, что согласование онтологии – это написание правил системами искусственного интеллекта? 

S03 [01:31:44]  : Нет. 

S02 [01:31:48]  : То есть вы не согласны с этим утверждением? Хорошо. 

S03 [01:31:51]  : Не согласен. 

S02 [01:31:52]  : Хорошо. Дальше вопрос от Сергея Новикова. Ключевым для понимания интеллекта и сознания является понимание, что человеческое сознание – планетарный феномен, а не результат работы мозга отдельного человека. Но это комментарий. Может быть вы прокомментируете второй вопрос от Сергея. Когда говорится о сложности, есть ли у вас понимание, как можно формально оценивать сложность? 

S03 [01:32:24]  : Смотрите, что я на этот счет думаю. Сложность – это нелинейное понятие. Мы не можем сказать, что это сложное, а это простое. Потому что есть структурная сложность, функциональная сложность, там еще какая-то сложность. И вообще говоря, я небольшой специалист в этом, но есть подходы, которые позволяют ортогонализировать аспекты сложности и оценивать общую сложность вообще, ну, по крайней мере, для какого-то ограниченного типа объекта. Что касается задач, ну, опять же, вопрос без контекста. Отвечать на такой вопрос в общем виде довольно тяжело, потому что Критерии сложности зависят и от задачи, и от контекста, и от типа агентов, и от типа ресурсов. Это просто некоторая характеристика, описывающая количество необходимой энергии, которую нужно затратить для того, чтобы добиться какого-то реворса. какого-то решения. Вот я так смотрю, потому что все связано с тратами энергии. И вот, кстати, вот этот вот товарищ с группой коллег, он тоже ставит, я с физикой плохо знаком, но вот он как бы принцип свободной энергии ставит тоже во главу угла как фришман, как основополагающую некую идею для, собственно, возникновения интеллекта. 

S02 [01:34:18]  : Спасибо. Потом вот здесь вот есть практически вопрос по вашим собственным работам. Вы где пульс по видео определяли, это правда не по теме нашего семинара, но тем не менее, у вас это проэкспериментальная работа или это у вас уже на промышленный уровень где-то выходит на решение? 

S03 [01:34:38]  : Это на уровне прототипа сейчас существует. Эта работа, скажем так, не не пионерская, то есть есть публикации на этот счет, мы просто в своем контексте имеем некоторый прототип программный, который сейчас дорабатываем для того, чтобы начать его вставлять в продукт. 

S02 [01:35:05]  : Спасибо. Вопрос снова от Бориса Новикова. Знакома ли вам книга А.П. Рыжков «Гибридный интеллект. Сценарий использования в бизнесе». 

S03 [01:35:16]  : Вы знаете, я ее видел и, по-моему, даже смотрел по диагонали, но не могу сказать, что я детально знаком с ее содержанием. 

S02 [01:35:25]  : Спасибо. Следующий вопрос от Ольги Заречной. Можно ли считать гибридным интеллектом человека с калькулятором? 

S03 [01:35:35]  : Ну, в принципе, любой, как бы, любой инструментализированный человек может в некотором смысле пониматься гибридным интеллектом, но не коэволюционирующим. 

S02 [01:35:48]  : Спасибо. Так, ну и дальше есть Борис Новиков, который поднимал руку. Борис, пожалуйста, дошло дело до вашей руки. 

S05 [01:35:59]  : Спасибо. Ну, во-первых, я хочу поблагодарить за интересный доклад, сказать, что мне очень нравится идея коэволюции естественного и искусственного интеллекта. На мой взгляд, если взглянуть на историю развития науки и техники, то прослеживается аналогия развития человека и машин без интеллекта. Ну, например, землекопы и землеройных машин. Они тоже коэволюционировали. Землекоп превратился в мужчиниста-эскаватор, и это совсем другая квалификация, и другие требуются физические и умственные способности. В итоге мощность этой системы многократно возросла. И мне кажется, что эволюция интеллектов искусственных и естественных, она как раз может рассматриваться как аналог по эволюции людей и интеллектуальных машин. И последнее, что я хотел бы сказать насчет сильного и универсального интеллекта. С моей стороны, точки зрения система такая уже существует именно при взгляде на кое-какую эволюцию, что это человечество со всей вычислительной техникой, с интернетом и со всеми средствами обработки информации. Вот у этой гибридной системы существует сильный универсальный и искусственный интеллект, потому что очень значительная роль в этом интеллекте принадлежит машинам. Вот такая система, вот как раз коэволюционная. Она дальше может успешно коэволюционировать, если не приведет к самоуничтожению этого успешного гибрида. 

S03 [01:38:09]  : Я согласен. В основном согласен. 

S02 [01:38:13]  : Хорошо. Спасибо. Ольга Заречная подняла руку и просит пояснить ваш ответ по тому, что согласование онтологии не является правилом для искусственного интеллекта. Можете это пояснить? Или, Ольга, может быть, вы уточните свой вопрос тогда? 

S01 [01:38:35]  : Нет вопроса именно об этом, просто прошу видение автора пояснить, как он понимает согласование антологий, потому что я как-то немного здесь разницу пока не могу для себя дифференцировать, потому что, на мой взгляд, когда мы даем некий набор определений системе, чтобы она понимала конкретные понятия так, а не иначе, но для меня это по сути равно какие-то правила понимания, это и есть согласование антологий. Если у вас другое мнение, тогда поясните, в чем разница и как вы видите этот процесс. 

S03 [01:39:11]  : Давайте так, значит, хорошо, спасибо. Во-первых, я напомню, что я сказал, что я не рассматриваю онтологию как способ представления знаний. Я имею в виду некую систему понятий внутри действия. Если говорить более точно, я попробую. По сути дела, смотрите, гибридная система решает какую-то задачу. И она как бы адаптируется к решению этой задачи. Ну, по сути дела, извлекает, например, информацию из данных и как-то по-другому, значит, действует. Но, по сути дела, это изменение, ну, немножко загрубим, это изменение, ну, как бы опыта действия. Вот возьмем человека. Его знания могут быть, его опыт может быть невербальным. Я тоже приводил этот пример. Это значит, что невозможно описать правилом, как он действует. Он как-то действует, потому что у него есть мозг рептилии, он в сознание не попадает, сердце начинает быстрее стучать, но это не правило. С другой стороны, возьмем машинную часть. Допустим, эта машинная часть построена на каких-нибудь обучающих алгоритмах. Это тоже не правило, это тоже вывод по какому-то набору данных. Но этот набор данных все время меняется и, по сути дела, машина может находиться в состоянии reinforcement learning того человеческого агента или тех человеческих агентов, которые вместе с ней решают эту задачу. Она может, например, адаптировать интерфейс, не исходя из правил, а исходя из того, на какой цвет человек быстрее, условно говоря, эффективнее работает, меньше ошибок делает. Это не система правил. То есть в очень рафинированном виде можно сказать, что это система правил, но в этом определении есть один, на мой взгляд, изъян. Для того, чтобы иметь систему правил, нужен тот арбитр, который извлекает правила, его формулирует и передает обеим сторонам – машине и человеку. Вот в этом разница. 

S01 [01:41:42]  : А в гибридном интеллекте человек не может быть таким арбитром? Потому что у машины же у нас система целеполагания как таковая в принципе пока отсутствует. То есть мы не можем об этом сказать? Может быть человек может быть таким арбитром? Ведь если упростить, допустим, структурировать процесс действия гибридного интеллекта как такового, представим, вот система информационных ресурсов, вот человек. Они соединены. Даже когда мы пользуемся компьютером, поисковой системой, можно сказать, что у нас есть некое восполнение дефицита и совершенствование определенной функции. Соответственно, но мы в любом случае даже в поисковую систему отправляем запрос, а дальше так или иначе принимаем решение, как арбитр устраивает нас результат поиска, продолжать поисковую активность или нет. Соответственно, в гибридном интеллекте ведь человек, получается, реально может быть неким арбитром, который все равно так или иначе будет оставлять за собой функцию принятия решения, соответственно корректировать или не корректировать правила или все-таки искусственная вот эта надстройка должна сама так или иначе где-то рекомендовать эту корректировку вот смотрите я с вами согласен значит вот в том что человек может являться арбитром а может и не являться В зависимости от того, каковы его собственные мощности интеллектуальные, видимо. 

S03 [01:43:08]  : Ну, конечно. Вы очень хорошее слово сказали – дефицит. Мы, когда проектировали систему оценки функциональной готовности, мы ее проектировали вместе с коллегами, которые в институте мозга в Питере работают. И мы выработали такое понятие, Зачем вообще эта система нужна? Она нужна для того, чтобы дополнять когнитивный дефицит, возникающий у человека, который подвержен работе, стрессу или какому-то интенсивной деятельности. И в этом смысле человек не может сам про себя адекватно сказать, я устал, правило такое. Вот машина может его вывести, условно, на основании наблюдений. Человек начал ошибаться. Окей, значит, ему нужно упростить интерфейс, например, с которым он работает. Нужно меньше задач давать, ну каких-то, которые требуют его внимания. То есть я совершенно согласен с тем, что человек является арбитром, может быть арбитром и должен быть арбитром и должен предоставлять обратную связь насчет адекватности принимаемых решений и, может быть, акцептировать эти решения, потому что у него более широкий контекст. Но в целом, говоря о концепции, я бы не ограничивался вот этой частью. 

S01 [01:44:27]  : В смысле, правилами имеется в виду? 

S03 [01:44:29]  : Правилами, да. Человек может быть источником, а может и не быть. Вот кто-то сегодня говорил, собака видит в инфракрасном свете, потому что человек не видит. Как он может говорить? Как он может быть принимающим решения в том пространстве признаков, в котором он не способен ничего видеть? 

S01 [01:44:50]  : может если мы найдем систему перекодировки этих сигналов доступную человеческому мозгу если у нас есть система инфракрасного видения которая перекодирует сигналы инфракрасного какого-то спектра в понятный нашему глазу спектр тогда мы можем принимать решение на основе того что мы восполнили этот дефект И в этом случае у нас расширяется область способности там быть арбитром предметной. 

S03 [01:45:18]  : Это правильно. Это супер правильно, потому что это помогает вообще говоря человеку обучаться. Это вот другая история как раз. Мы способны действительно, но я сейчас на память не помню кто автор как называется статья. Была где-то статья по-моему 17 года. на тему, почему объяснимый искусственный интеллект – это так сложно. И там было очень простое сформулированное правило. Машина может находить в данных признаки 10 тысяч измерений, вот вектора. Человек способен что-то воспринимать в трех, максимум четырех измерениях. Несводимо. Правила нет. То есть, количество вариантов свертки настолько большое, что просто нечеловекоразмерно. 

S02 [01:46:10]  : А можно, Кирилл, здесь еще один вопрос на эту тему от Владимира Фролова. Ваше мнение, для полноценного общения агентов необходима ли общность функционирования интеллекта хотя бы в области, касаемой обмениваемой информацией? 

S03 [01:46:29]  : Слово общность непонятно. Общность структуры нет. Общность контекста какая-то – ну да, потому что у них в восприятии должны присутствовать символы, которые ссылаются на те же самые процессы или объекты реального мира, неважно в каком измерении они их видят. 

S00 [01:46:53]  : Можно я поясню вопрос? Во-первых, спасибо за доклад. На протяжении сколько часа я сидел, не отрываясь, слушал. Я бы хотел пояснить свой вопрос. У меня сложилось впечатление, что когда мы говорим с субъектом, мы как бы залезаем в мозг не с самого нижнего уровня, а куда-то вглубь залезаем. Когда человек что-то наблюдает, это на самом низшем уровне идет информация, она потом образуется, обрабатывается нам более и более высшим. Если мы что-то говорим, такое впечатление, что мы практически влезаем в мозг человека и обладаем прямым доступом к более высоким областям мозга. Но если мы говорим какие-то объекты, первый, второй, третий, все часто не сводится, что первый стоит около второго, а третий рядом находится. Очень часто нам приходится говорить какие-то термины обработки информации, как мы получили это, что. В общем, касаемо обработки информации. Обработка информации – это уже функционирование мозга. Конечно, это будет легче восприниматься, если у субъекта, о котором мы говорим, такая структура уже есть. Это будет как родная воспринимация. Если такой нет, что делают лекторы, они делают надстройку, чтобы у слушателей появилась какая-то область, которая более-менее правильно функционирует, как у лектора. Тогда последующая информация очень легко воспринимается. Так вот вопрос, чтобы субъекты достаточно хорошо себя понимали, у них должна быть какая-то общность структуры хотя бы в общих чертах, и тогда информация очень легко переходит одного на другого. Если же этого нет, такое впечатление, что мы будем очень много биться, пока субъект сам не обучится. 

S03 [01:49:04]  : Смотрите, что я об этом думаю. Я думаю следующее. Давайте разделим на два уровня. Давайте разделим на уровень языка просто. Вот вы привели студенты и так далее. Возьмем самый тяжелый случай. Я встретил китайца. на необитаемом острове. Я не знаю ни одного слова на китайском, он не знает ни одного слова на русском. Ну и других языков мы тоже не знаем. Но нам надо есть. Мы видим пальму, и там банан висит, который каждый из нас не может достать. Но если друг на друга сесть, возникает язык. Но язык возникает вокруг чего? Язык возникает вокруг ситуации, вокруг объектов, которые мы можем как бы то ни было смоделировать в своей голове. И если матч происходит, матчинг некоторых объектов, то мы можем дальше договориться. 

S00 [01:50:05]  : А моделирование должно быть близкое, чтобы мы поняли друг друга? 

S03 [01:50:09]  : Неважно. Начальное моделирование – это очень простое. Сейчас ночь или день, мы оба это распознаем. Модель состоит из одного бита. А дальше можно ее усложнять. Язык же возникает ровно для того, чтобы обмениваться моделями. эти модели это же просто проекции мира проекции явлений которые там есть ну проекции в конкретный мозг поэтому когда говорим про общность это я сейчас говорю про агентов которые могут создавать язык вот если говорить про другие биологические объекты ну не знаю там которые вообще в разных модальностях существует но если вообще в разных я не знаю как ну например не знаю там вот летучие мыши слышат что-то, что не слышит человек, а человек видит то, что не видят летучие мыши. Но если происходит какая-то вспышка условно, что-то упало и заискрило, то они в разных модальностях видят одно и то же событие. И по этому поводу может возникнуть общий символ. А дальше они могут его развивать. 

S00 [01:51:20]  : Да, вот легко ли человеку, если бы он, скажем, сделать его летучей мышью, чтобы ему летучая мышь объяснила, что и к чему. Наверное, что-то должно достроиться в мозгу, какие-то понятия, чтобы он мог общаться с мышью. Ну, предположим, если бы они общались между собой. 

S03 [01:51:36]  : Смотрите, должен быть... протокол соразвития, то есть родители с детьми выстраивают протокол соразвития, сначала там показывают или там владельцы кошек выстраивают протокол соразвития, что вот здесь вот лоток, а там вот еда. И вот есть некие правила, но если у человека есть достаточно мотивации обучить мышь, наверное, что-то можно такое сделать. Но у мыши тоже должна быть мотивация чему-то научиться. Это интересный вопрос. 

S00 [01:52:11]  : Должны ли быть общие методы обработки информации у субъектов? 

S03 [01:52:14]  : Это не про обработку информации, это про коэволюцию на самом деле. 

S00 [01:52:20]  : Субъекты – это слишком просто. А вот обработка информации – это уже более высокий уровень и легче понять этот вопрос. что если кто-то не обрабатывает информацию определенным образом, ты ему не объяснишь на высоком уровне, что тебе нужно. 

S03 [01:52:37]  : Правильно. Выразительная мощность общего языка определяет общий интеллект, условно говоря. Вот это соразвитие. Если язык зафиксировать на каком-то уровне, он может три термина, три символа передавать, то все. Вот в три символа уложится вот это, если он не развивается. 

S02 [01:53:00]  : Коллеги, здесь вот у Владимира Смолина давно рука поднята, может быть, он тоже участвует. 

S00 [01:53:07]  : Спасибо за ответ. 

S02 [01:53:09]  : Владимир Фролов, спасибо. Владимир Смолин, пожалуйста. 

S04 [01:53:13]  : Хорошо. По просьбе Антона я начну с положительного, что мне очень понравилось, что здесь все рассказывают о том, как замечательно работает GPT, как по словам рисуют картинки. Это действительно большие успехи. И с чем я согласен с докладчиком, что действительно эти системы хорошо работают только в контакте с человеком. Человек выделяет понятия, а система находит между ними корреляции. И это, как бы сказать, самое основное место в докладе, с которым я согласен. Остальным, конечно, у меня там много противоречий. Но, значит, собственно, хотелось бы задать, то есть там, по постановке, ну, собственно, мое-то отношение, что, как бы, может и система сама выделять понятия, и цели может сама ставить, а я так думаю, с точки зрения докладчика, нет. Ну, или, по крайней мере, никто не знает. Соответственно вопрос в том, что никто из нас здесь присутствующих и вообще наверное в мире не планирует вернуться в каменный век или наоборот создать такую систему, которая уничтожит всех людей. То есть, в любом случае, все планы, которые осуществляются всеми разработчиками, они так или иначе направлены по эволюции. То есть, будет и интеллект, и искусственный интеллект, сильный искусственный интеллект. И они, естественно, будут коэволюционировать. И вся эволюция до этого тоже шла как по эволюции, то есть, никакой там вид по отдельности не развивался. Чем, собственно, ваши работы отличаются от работы остальных? Поподробнее отвертите, потому что, в принципе, коэволюцией так или иначе все занимаются. 

S03 [01:54:46]  : Ну, смотрите, вопрос, да, неоднократно мы его слышали и отвечали. Значит, история заключается в чем? Коэволюция часто осуществляется как бы случайно, либо в узких областях. Кто-то приводил землекопа с лопатой-экскаватором, вот есть узкая часть, которая, понятно, что есть целевая функция копать траншею, и есть инструмент, человек с его силой и так далее. Это и техника, и все такое. Но скорость этой эволюции, у меня слайд про это был, зависит от того, насколько мы имеем формализованное описание когнитивных функций и насколько технологизирована передача знаний, допустим, с искусственной стороны на естественную и наоборот. То есть мы говорим о чем? Все существует, все это и есть эволюция. Все это и есть коэволюция. Человек строит свою техническую реальность, исходя из своих интересов и ограничений. Если мы фокусируемся на том, чтобы создать инструменты создания именно когнитивных систем, то есть таких, в кавычках я скажу неаккуратно, интеллектов под задачи, если мы технологизируем эту коэволюцию, то, собственно, вот это и есть наш основной пойнт. 

S04 [01:56:22]  : Так, можно еще один вопрос? Значит, вот по поводу объяснимых систем, которые важный вопрос. Ситуация какая? Считается, что человек легко объясняет свои действия, а в системе это, дескать, сложно. Но ситуация какая? Вот даже перед тем, как мне дать микрофон, Антон Германович мне написал отдельно, что я думал, что я буду говорить. И это на самом деле относится ко всем. То есть мы, особенно в нашей стране, не говорим, что мы думаем, а мы очень думаем, что мы говорим, а только потом начинаем говорить. И, собственно, то, что я рассказываю о том, что я думаю, совсем не соответствует тому, что я на самом деле думаю. И, как бы сказать, это очень распространено. Скорее всего, можно найти какие-то исключения из этого правила. Почему вы считаете, что с человеком все просто, а с искусственным интеллектом все очень сложно? Хотя, в принципе, прекрасная система учится объяснять, почему она так ответила, резонировать, еще что-то. 

S02 [01:57:20]  : Чад ГПТ бы, Владимир, вас не понял. 

S03 [01:57:23]  : Во-первых, я не говорил, что с человеком все просто, а с искусственным интеллектом сложно. Я, простите, этого не говорил. Я говорил о том, что не существует способа создания такой коммуникации, достаточно удобного. Человек привык думать по-своему, говорить по-своему. машины ну тоже как-то там работают свои логики и возможно если это ну я персонально считаю что эксплейна была это такая же маркетинговая такое же маркетинговое название как искусственный интеллект значит простите я буду говорить то что думаю а не думать то что говорю вот то есть я не сказал что это так Я сказал, что существует сложность, которая мешает развиваться. То есть мы можем создать очень обученную на всех данных мира систему, которая будет генерировать ответы правильные, но мы не сможем ни проверить адекватность этих ответов, ни проследить причинно-следственные связи. То есть эти ответы в принципе бесполезны. Потому что они никак не отвечают нам на вопрос, как я продвинусь в цели полаганий, ну вот в движении по своим целям, если я этот ответ получу. Вот я так считаю. 

S04 [01:58:44]  : Владимир Иванович. Ну, я сказал, что я бы мог на эту тему долго дискутировать, но мы слушаем докладчиков, поэтому я не буду. 

S02 [01:58:51]  : Хорошо. Спасибо. Спасибо, Владимир. Спасибо, Кирилл. Вот еще есть два вопроса практических от Андрея, по-моему. Андрей, если это ваши, то про онтологию... Да, пожалуйста. Вы сами их зададите или мне зачитать? Зачитайте. Зачитайте. Значит, первый вопрос. Как представляются знания в онтологии гибридного интеллекта? Можете ли вы привести пример такой онтологии? Каким образом формируют элементы онтологии искусственный интеллект? Как разрешаются противоречия? Уточнение вопроса. Каким образом ИИ формирует элементы онтологии? Как разрешаются противоречия? 

S03 [01:59:36]  : Давайте так, я сознательно несколько раз это произнес, говорю, что мой доклад не касается представления знаний, поэтому я бы не стал на этот вопрос отвечать. Почему? Потому что это отдельная тема, и как бы я не ответил, останется очень много незакрытых мной областей в этом. Потому что мы начнем историю с определения знания, что такое знание, потом начнем разбираться в контекстах, в которых эти определения работают или не работают. Поэтому я скажу, что я не знаю, как ответить на ваш вопрос, но я считаю, что это очень важный вопрос. Прокомментирую хорошо, чтобы не быть невежливым. Понятно, что в зависимости от типов моделей, которые мы строим, человек или человек автоматизированный, у нас есть разные контексты. И в этих контекстах есть разные способы представления понятий или фактов, и вывода по этим фактам, и разрешение конфликтов, и матчинга онтологии, и всего вот этого дела. И понятно, что если мы говорим про алгоритмы какие-то, например, построение обобщенной модели знаний или обобщенной онтологии в смысле онтологии хранения или представления знаний, то тогда это, ну, это просто тема некоторая, ну, немножко выходящая за уровень нашего разговора, там очень много людей наделали. Все они применимы, то есть я вот как бы не хотел бы, чтобы создалось впечатление, что мы как-то отменяем то, что существует сейчас, ну, как в технологиях, так и в концепциях, да, и что-то на смену Тут такое вот странное представляем. Нет, наоборот, мне бы хотелось, чтобы создалось впечатление, что… Есть такой взгляд, такая точка зрения, к которой мы придерживаемся, которая позволяет использовать все наработки, там был слайд, я уже не буду открывать, все наработки, которые сейчас есть. Там есть модели знаний, вот на слайде у меня были там и антологический вывод, все вот это есть. 

S02 [02:01:59]  : Если можно, уточнение. Да, пожалуйста, Андрей. Прежде чем уточнения, Кирилл, вы же пришлете ссылку на вашу презентацию? Я пришлю презентацию, да. Да, Андрей, пожалуйста. 

S03 [02:02:14]  : Вот сейчас в прототипе вы используете какую-либо антологию? Сейчас в прототипе чего? Смотрите. В любом прототипе гибридного интеллекта. То, что мы сейчас прототипируем, касается биологической обратной связи и сбора данных о человеке. Мы сейчас не работаем над представлением знаний в онтологиях, мы решаем задачу вот этого контура, сначала интерфейса человек-компьютер. Вот, если говорить про вот эту систему с голограммами, то следующий наш шаг, вот сейчас у нас есть просто датасет, есть какой-то там обученный алгоритм, который позволяет выявлять особенности. И после того, как у нас будет модель врача, который это делает, который ставит конкретные диагнозы, мы будем строить гибридную модель между моделью, построенной на данных, и набором правил. Такие работы есть. То есть это не наша область. Есть куча работ, которые связывают машинное обучение, модели машинного обучения с антологиями. Более того, извлекают из данных эти факты и автоматически строят эти антологии. Это не наша поляна, но мы умеем это пользоваться. Мы об этом знаем. Но это не то, что мы представляем здесь. Сейчас ответ мы не используем ничего. Мы модели дознаний не используем сейчас. Нам это просто сейчас не требуется. 

S02 [02:03:57]  : Хорошо, спасибо. Спасибо. Ольга, пожалуйста. 

S01 [02:04:06]  : На самом деле я просто хотела согласовать возникшее понимание с автором. То есть я правильно понимаю, что здесь просто, когда речь идет о вашем в текущем нашем обсуждении про онтологию, это некий способ действия в определенном контексте для решения определенной задачи. Это не некая система знаний, разрозненных, связанных и так далее, а это именно эталон способа действия. 

S03 [02:04:30]  : Способ интерпретации контекста к действию. 

S01 [02:04:37]  : Тогда понятно, тогда все вопросы с представлением знаний, с пониманием онтологии в вашем текущем докладе у меня разрешились. 

S02 [02:04:49]  : Хорошо. Коллеги, большое всем спасибо. Кирилл, Юлия, огромное спасибо за ваше участие, за ваш доклад. Спасибо всем, кто сказал, что думал, и за то, что думали, что говорили при этом. Ну и до новых встреч и, как говорится, за Новый год и за интеллект с человеческими целями. Спасибо. Всего хорошего. Спасибо. До свидания. Всего доброго. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
