## 8 июня 2023 - FractalGPT - Захар Понимаш — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/ZgGR5ypaJ0I/hqdefault.jpg)](https://youtu.be/ZgGR5ypaJ0I)

Суммаризация семинара:

Семинар AGI провел обсуждение актуальных вопросов в области искусственного интеллекта. В частности, были затронуты темы разработки новых подходов к искусственному интеллекту, включая проект FractalGPT, представленный участниками проекта. В докладе подчеркивалась новизна системы, которая оснащена эмоциями и целеполаганием. Однако критика была высказана в отношении упрощения модели мира до статистических вероятностей и отсутствия прорывов в области искусственного интеллекта.

Кроме того, обсуждалась конкуренция с OpenAI, при этом подчеркивалось, что OpenAI не предприняла ничего сверхъестественного. В контексте кода и работы с ним были высказаны критические замечания в отношении качества и эффективности кода системы OpenAI. Вместо этого были упомянуты проекты, стремящиеся создать логические движки и уходящие от статистических методов.

В ходе семинара были заданы вопросы по различным аспектам системы, включая механизмы целеполагания, использование нечеткой логики и представление знаний о предметной области. Также обсуждалась возможность доступа к демо-версии системы и ее текущее состояние в плане эксплуатации и контроля за генерацией текста.

Семинар также включал в себя информацию о предстоящих событиях, таких как конференция по сильному искусственному интеллекту AGI 2023 в Стокгольме и семинар по интерпретируемой обработке естественного языка, где планировалось обсуждение темы ChatGPT и ее применение в системных технологиях.

В заключение, семинар предоставил платформу для обсуждения инновационных подходов к разработке искусственного интеллекта и выявления проблем, стоящих перед современными ИИ системами.







S06 [00:00:02]  : Коллеги, всем добрый вечер. Напоминаю, что на следующей неделе у нас будет, точнее, не будет семинара, но будет проходить очередная конференция по сильному искусственному интеллекту AGI 2023 в Стокгольме с возможностью удаленного участия. зарегистрироваться можно на сайте конференции, а 19-го числа у нас там будет семинар по интерпретируемой обработке естественного языка, где в том числе я буду своим докладом выступать, Захар будет с Виктором Носко тоже выступать с докладом по своей работе. Вот также там будет, мне кажется, интересный доклад разработчиков системы аксиматического вывода НАРС о том, как они то ли поженили, то ли пытаются поженить НАРС и ЖПТ-3. Ну и еще будет доклад от Бена Герцеля. По продолжению проекта по интерпретируемому обучению по строению языковых моделей, которые мы с ним начинали в 2017 году и будет еще выступать Николай Михайловский из Москвы. Ну а сегодня у нас Захар Понимаш по работе совместно с Виктором Носко и он расскажет нам про Фрактал-ГПТ или самообучающаяся мультиагентная ИИ на базе больших языковых моделей и логического вывода. Захар, пожалуйста. 

S07 [00:01:30]  : Здравствуйте. Я представляю проект Фрактал-ГПТ. Это самообучающаяся мультиагентная система. Она не слежит как большей языковой модели, так и модулогического вывода и собственной многогетной системы. Мы ее разрабатываем командой четырех человек. У нас команда и специалистов с опытом работы. более 50 лет. Также у нас есть множество завершенных проектов. Мы делали объявление о своих намерениях разработать фронтальную GPT еще в январе, и у нас Были также анонсы 14 марта, потом переписанные из Вордовского документа. Там мы писали, что сейчас есть такие подходы, как ToolFormer, которые позволяют внедрять инструменты внутрь больших языковых моделей. Рестракция pre-train – это метод, который позволяет дать на вход нейронным сетям типа GPT какие-то данные, которые могут использоваться для уменьшения галлюцинации. Использование обучения споскопления на базе отклика людей, то есть на базе реакции людей, а также NARTS как Система Логического Вывода. И мы когда в своем узоре писали, мы писали, что у нас будет некая синергия похожих подходов. Единственное, что это все-таки такая LM-центричная история, когда используется в качестве некого мозга большая языковая модель. Мы отходим от такой LM-центричности к тому, что У нас в качестве основного высочего ядра используется модуль фрактал, который внутри себя объединяет и многоагентную систему, и модуль логического вывода. Наша цель проекта – это создать небольшой АГИ, то есть как бы прототип сильного искусственного интеллекта. И в плане коммерции это преобразовать в компанию, которая была бы по своим объемам больше, чем OpenAI, стоимостью более 20 миллиардов долларов. Так, структурная схема проекта Fortage, где приведена схема, мы разрабатываем мультимодальную систему, внутри которой есть многоагентная система, это вот многомасштабный децентрализованный, то есть у нас здесь находится многоагентная система, агенты могут быть как наши облачи, так и подключаемые сервисы пользователей. Также у нас есть блок логического вывода, о котором я расскажу чуть позже. И сам вот этот вот интерфейс взаимодействия с многогетной системой и с системой логического вывода. Интерфейс работает на базе больших языковых моделей, и также там есть методы обработки нетекстовых данных. То есть это фотографии, видео, звук нетекстовый, ну и текстовые данные, которые обрабатываются внутри этого модуля. В модуле Fractal Имеется система многомасштабная логического вывода с целью полагания, и также многомасштабный децентрализованный И, который по сути является многогенной системой. Если посмотреть на этот слайд, то вот этот блок сейчас рассмотрим более подробно. он представлен на этом слайде, то есть у нас здесь есть естественно языковой интерфейс, по входу один поступают запросы пользователей, делается их предобработка, это различные системы вроде Toxic, которые позволяют убрать токсичные высказывания. Это различные неры, которые позволяют вычленить именованные сущности и заменить их на специализированные токены для дальнейшей обработки. Далее идет языковая модель, либо на базе GPT-подобных моделей, либо на базе BART. Мы экспериментируем и с теми моделями, и с теми. И далее у нас идет модуль постобработки, причем постобработка может возвращать из языковой модели какие-то данные и возникает что-то вроде педали обратной связи, за счет которой возможно, например, решение тех же задач, когда нам нужно сделать несколько шагов. То есть, языковая модель генерирует какой-то шаг, после обработки говорит, что ответ не получен и возвращает его назад. И языковая модель, учитывая этот шаг, генерирует следующий. И вот таким образом может быть взаимодействие языковой модели и после обработки. После обработки используется вот здесь вот по поду 4 это некая база знаний, которая может подставить на место неров, которые были помечены языковой моделью как какие-то существа, подставляются уже конкретные существа. То есть, например, если языковая модель сгенерировала, что Если какой-то человек живет в Bus City, то отсюда подставляется город, в котором живет этот человек, на местность слова city. Ну, так как оно может быть несогласовано и так далее, то есть у нас также опять идет обратная языковая модель отправки этого результата, и мы получаем уже согласованный ответ, подставленный этим нером. и возвращаем ответ вот с выхода 5. Также мы решили не использовать какой-то один промпт, а генерировать промпты, что называется, на лету, то есть у нас есть какая-то задача, и мы под нее генерируем специальный промпт. И в этот промпт, эту подсказку, мы включаем также данные агента. Вот по входу 2 сюда подключаются данные агента, данные системы логического вывода. Также у нас имеется обработка нетекстовых данных, это различные системы аннотации изображений, ACR, транскрибации, аудио, видео и так далее. Здесь представлена ядрологическая вывода. По сути, я с похожей системой выступал здесь примерно год назад. Она называлась iDoc. Мы ее доработали. Как работает это ядро? У нас есть вход. Вот эта часть, кстати, если по этой линии идти, то она в точности такая же, как в iDoc была. То есть у нас есть вход, здесь стоят нормализаторы данных, они позволяют, по сути, избавиться от нестационарности данных от ожидания дисперсии по каждому каналу. Далее у нас идёт модуль выделения состояний, и вот эти вот состояния, они передаются в модуль логического рода, который обучается прогнозировать следующее состояние, к тому же состояния, которые он учится прогнозировать, они подкрепляются моделями эмоций. По сути, модели эмоций – это что-то вроде реварда, но более такое мощный ревард в том плане, что у нас не одной перемена представлена, а в данной работе представлен четырьмя переменными, которые позволяют нам регулировать не только было подкрепление или нет, но еще позволяют нам давать информацию о том, насколько изменить скорость обучения различных систем и тому подобное. То есть мы настраиваем системы, исходя еще из трех переменных, кроме реварда. Вот он, механизм работы с эмоциями. Также есть механизм планирования действий. Это механизм как раз-таки модуль целеполагания, который напрямую работает с модулем логического вывода и ассоциативной памяти. Что он позволяет делать? Он позволяет нам создать, получается, набор действий, которые нас приведут в конечном счете к тому состоянию, сейчас это уже не граф, но изначально это был граф, к тому состоянию в этом графе, которому споставляется наибольший ревард. у нас ревард по сути представляет эмоции удовольствия, ну вот если говорить в терминах обычного обучения с потреблением, то вот это как раз таки ревард. Далее у нас есть механизм выбора действий, вот здесь вот, которые также работают, механизм планирования действий, механизм планирования действий еще отслеживает то, насколько мы точно следуем стратегии, если мы начинаем от нее отклоняться, она переставляет стратегию. Ну и также у нас есть модуль, который мы назвали модуль интуиции, по факту это модифицированная LSTM-сеть, которая изучает наилучшие стратегии, то есть здесь мы можем генерировать стратегии и потом эта сеть будет их изучать и она выдается свои действия, то есть она по сути не проходит весь этот путь, она просто говорит, что вот такие действия нужно принять. И вот в этом модуле он работает, по большому счету, примерно так, как работают мои. То есть у нас есть здесь, получается, действия. Вот набор действий выдает нейронка, которая похожа на LSTM в некотором плане. Набор действий выдает логический модуль, и далее Вот эта нейронка решает, как нам вот эти вероятности, как нам создать смесь этих вероятностей. В какой ситуации больше прислушаться, скажем, к модели интуиции, в каком случае лучше прислушаться к модели логического вывода. В итоге выбирается метано-нуклеарцельный подход действия и возвращается сюда. Также действие идет обратно на вот этот вход, чтобы учесть, что было произведено какое-то действие, и это тоже является довольно весомой информацией для того, чтобы планировать действия далее, ну и для того, чтобы поддерживать выполнение стратегии в этом модуле целеполагания. К тому же здесь используются две эмоции на вход, это как раз таки По сути, тот же ревард, только для отрицательных эмоций сделан как бы тут двумерный вектор, то есть отдельно отрицательный, отдельно положительный учитывается. Это сделано для того, что если мы используем ревард обычный, то когда у нас высокая положительная эмоция, скажем, и высокая отрицательная, Прямо одинаковые. Мы говорим, что просто у нас ничего не происходит, но здесь мы можем учесть, что, во-первых, действительно, их средняя около муля, но вот внутреннее напряжение всей системы довольно высокое, и что действия сопряжены с неким большим риском. То есть для учета этого было введено с данного входа две эмоции, но здесь, как я говорю, что внутри системы их вообще-то четыре. Мы их можем получить наружу, например, выдать языковую модель, и языковая модель может проявлять в разговоре вот эти вот эмоции, которые были выданы из вот этой системы. И вот так же действует то, что система должна делать. Ассоциативное обучение я пытался моделировать и довольно успешно. работу Павлова. Так как проект iDot, мы за основу брали именно поведение собак. У нас здесь довольно много всего награждено. Но идея в следующем, что у нас есть некоторые реакции, которые мы получили, например, во время обучения Наша логическая мода, либо задали эти правила вручную, они у нас есть, но они активируются вместе с другими правилами, которые мы не задавали. как должна себя вести сеть, она должна выучить новые стимулы. И здесь я, в общем, реализовал модель суммации. То есть суммация – это когда у нас в нейроне происходит накопление ионов кальция. Тут видно, что при многократном повторении стимула возникает связь, и в целом это был поставлен эксперимент по тому же принципу, как его ставил Павлов, и результат его примерно похож на тот, который получал Павлов. Там были другие графики, может быть, если будет интересно, я их потом покажу, где именно накопление самих этих ионов кальция моделировались и вот это вот слюноотделение моделировалось здесь показано по сути тоже самое но здесь еще здесь еще применен получается алгоритм который моделирует называемую долговременную потенциацию, за счет которой сигнал в системе может какое-то время циркулировать. И здесь что показано? Здесь показано, что при небольшом подкреплении, причем подкрепление идет запоздание, у нас даже при предъявлении одного стимула возникновения подкрепления появляется реакция, то есть достаточно предъявления одного стимула. На этом графике показана работа с эмоциональным движком, то есть мы из четырех эмоций получали значение подкрепления, это вполне такой классический ревард. А вот этот вот график – это возбуждение системы, то есть оно может быть даже очень высоким при практически на любом подкреплении. Это то, что отличает эту систему во многом от обычай подкрепления. С какими проблемами вообще сталкиваются системы на базе больших генетических моделей? Это в первую очередь проблемы галлюцинации. То есть это когда нейросеть изучила стилистику правильного ответа, но фактология довольно сильно страдает. В итоге она вводит в заблуждение людей, говоря, что ответ, по сути, ну, ответ, он кажется, правильный, но, по сути, он является ложью. И вот это есть галлюцинация ЛЛН. Мы предлагаем решать проблему галлюцинации при помощи многоагентной системы. В GPT, кстати, тоже увидели эту проблему, вот в чат GPT, и ее решают с помощью плагинов. Но вот здесь есть большое отличие между многоагентной системой и плагинами. Дело в том, что плагины, вот, например, у нас если будет там десяток плагинов, то мы по факту можем решать десяток проблем. Когда у нас есть около 10 агентов, мы можем решать куда большее количество задач за счет того, что они могут самоорганизовываться. Это вот то, что здесь под пунктом 1 называется автосборка. То есть они самоорганизовались для решения конкретной задачи. Появилась новая задача, они, те же самые агенты, организуются для решения другой задачи. Это вот дальше на сайтах будет видно. И вот за счет этого можно, в принципе, обозримым числом агентов, тысячей где-то, сделать так, что система будет решать практически любую задачу. Причем решать она будет ее с помощью вот таких вот экспертных систем, по сути, то есть практически без галлюцинации. то есть вот в интерфейс передавать уже результаты решения задач еще одна особенность одинов то что они автономные и они у нас постоянно обучаются причем вот в отличие от многих которые сейчас строятся, что они дают GPT какую-то задачу, говорят, декомпозируй ее на какие-то блоки, а потом под эти блоки ищут агентов, и они решают задачу. Вот здесь знания о конкретной области. Мы не думаем, что GPT будет иметь знания о конкретной области. Мы все знания об этой области перекладываем уже на агентов. И то есть мы можем добавлять нового агента, который, общаясь с другими агентами, может сказать, что у него есть знания для решения этой проблемы и решить эту проблему. Общается он на своем внутреннем языке, а не на русском языке, например. Это тоже я видел такие работы, что используют агентов, которые общаются на английском языке, например. с помощью больших языковых моделей. И вот так же выясняется, что они могут сделать, и там тоже возникает искажение. Тут внутренний язык, который не требует больших учредительных затрат на то, чтобы сконфигурировать вот этих агентов. То есть у нас время сборки на наших тестах иногда достигало одной 10-тысячная секунда, вот мы делали там 100 сборок подряд, потом делили на 100 время сборки, получали там порядка одной, точнее 100 тысяч сборок делали, потом делили на время сборки, получали порядка одной 10-тысячной секунды на сборку. Что понятно для систем, которые внутри себя, чтобы их агенты просто пересылали информацию, содержат, скажем, LLM, оно-то в принципе невозможно, к тому же у нас учитывается огромное количество параметров, так как мир у нас в принципе динамический, то какой-то агент может быть занят, какой-то агент может задачу решать чуть позже и так далее, что в принципе GPD с помощью промзов его вообще не может учесть, либо учитывать очень плохо. Поэтому мы всегда можем построить такую квази-оптимальную сборку, которая потом будет использована для решения внутренней задачи. И к тому же каждый агент может во время общения с другими принять решение, что он может решить задачу или не может решить задачу. За счет чего Мы агентами не беремся решать задачи, которые они не могут. Например, как происходит вызов API в различных системах, которые довучены. Есть Lama, которая вызывает API конкретного сервиса. Там получается такая проблема, что у нас есть, скажем, API, которая может преобразовать текст изображения. И это может сделать куча разных способов. Но она не имеет возможности посмотреть на это изображение и сказать, что вот конкретное API это сделает чуть хуже, чем другое API. Нужно вызывать его, а не это. То есть вот этого там не происходит. 

S00 [00:24:10]  : У нас это есть. 

S07 [00:24:16]  : Ну здесь у нас показана первая демо, мы его в принципе демонстрировали еще в самом начале, когда создали группу. Тут по факту имеется только один агент, который умеет решать примеры. На самом деле их два, но здесь не показана работа второго. То есть второй мог посмотреть время в разных городах. Но тут также используется наш ноу-хау, про который я рассказывал в плане создания подсказок, предобработки и постобработки в естественно-языковом интерфейсе. и мы получаем более фактологичный ответ за счет этого. Модель использовали, вот именно в этом демо, на 7 миллиардов параметров, но также экспериментировали с моделями на 1 миллиард параметров и на 700 миллионов параметров. В принципе результаты примерно такие же, Мы знания храним не внутри, получается, GPT, а мы их храним вовне и просто обращаемся к ним и выдаем уже под запрос пользователя. Более мощная наша система, которая способна выдавать знания, скажем, из документов какие-то, это система фрактального синтеза. она опубликована вот здесь вот на хабр. Это получается своего рода один из видов агентов, который мы используем, то есть это как бы его ядро, что он делает, но к тому же у него есть оболочка, которая по сути его оптимизирует, принимает решение о вызове и так далее. Как это все работает? У нас есть Некий вопрос. Есть документ. Мы формируем граф документа. Причем делаем это следующим образом. У нас для предложений, сниппетов, по сниппетам мы понимаем в данном случае 4 или 3 одинаковых, ну 4 или 3 предложения. То есть для предложений, для сниппетов, для блоков сниппетов и для документов в целом мы создаем графы их взаимодействия. Причем на этих вершинах тут не один параметр, тут их два параметра. И эти параметры одинаковые что для предложений, что для сниппетов, что для блоков сниппетов. что для слов, если бы мы по словам строили, по сути это является вот такой вот фрактальной структурой, потому что принцип построения, он один и тот же. Просто мы увеличиваем масштабы и получаем похожую структуру на новых и новых масштабах. Работается в следующем образом. Мы формируем граф документа, Вот по этому принципу, какой я сейчас озвучил. После этого производим расчет важности структурных элементов. Далее мы синтезируем ответ на предложение. То есть у нас есть вот такая вот структура. Мы говорим, что вот это предложение связано... Для того, чтобы получить какой-то ответ, мы можем посмотреть, что это предложение довольно сильно связано, например, вот с этим. а это сеттинг. И тогда, ну это интерактивно происходит, но тогда у нас получается, что вот это, это и это предложения попадают в ответ из разных блоков. Ну либо они могут быть внутри одного блока попадать, но у нас в основном из разных блоков попадали, вот на практике. То есть мы синтезируем ответ, причем ответ уже является в принципе, читаемым, то есть, несмотря на то, что на этом участке еще не используется никакая LLM, ответы, в принципе, читаемые, они нормально структурированы, но чтобы учесть также некие, получается, особенности вопроса и контекста мы используем LLM, то есть это лингвистическая модель. То есть что мы делаем? Мы говорим, что вот у нас есть, если мы используем LLM, то мы говорим, что у нас есть контекст, мы его добавляем и генерируем ответ с использованием контекста, с использованием синтезированного ответа и используем вопрос, который был задан. Результирующий ответ у нас идет на выход. Если мы не используем, что дальше будет показано, какие ответы синтезируются, то мы просто тот синтезируемый ответ по этому графу уже выдаем пользователю. Ну, пример того, как мы загрузили гражданский кодекс и задавали вопросы. Здесь получается вот в этих ответах, не используясь OLM, мы из разных участков, из разных абзацев находили с помощью фактального синтеза предложения, выстраивали их в такой последовательности, чтобы не нарушалось прорисование, и, по сути, вот это выдается на выход системы. Также, как я уже говорил, при использовании LLM это будет задаваться не пользователям, это будет задаваться внутри LLM, она будет учитывать предыдущие вопросы, уже отвечать на вопрос пользователя. Следующий вариант, три вопроса задавал по гражданскому кодексу. В принципе, ответы все фактичные получились. нормальное читаемое, то есть нет такого, как, например, когда по векторной базе находятся сниппеты, что ответы какие-то рваные, то есть получается, что кусок отсюда, кусок отсюда, кусок отсюда, и дальше как хочет LM так их и забирает. То есть здесь мы делаем большую часть работы за языковую модель. И чем меньше работы остается на языковой модели, тем меньше вариантов галлюцинации. Поэтому вот этот подход позволяет уменьшить количество галлюцинаций. Также мы... используя многоагентную систему, про которую я говорил раньше. Здесь показано, как она работает. У нас есть агент, который может принять на вход снимок. В данном случае это агент, который может детектировать, вообще он может сегментировать рак поджелудочной железы, именно в этой демке не была, скажем, показана сама сегментация, но в целом он сегментирует, и вот здесь вот видно, что вот тут такое серое пятно, как раз тут и область где есть рак. И вот он, я ему скинул это изображение, спросил, есть ли рак. Он сказал, что на снимке, скорее всего, рак по желудочной. Выдал ту вероятность, которую дает агент. Потом сказал, какой размер обухоли. свою рекомендацию. Он всегда будет давать рекомендацию обратиться к врачу, поскольку даже если мы полностью уверены в качестве медицинской системы, что это экспертная система, она прошла все тесты, вообще отличная, но Даже в этом случае мы не можем давать каких-то медицинских рекомендаций, это просто по закону. Поэтому всегда будет рекомендация обратиться к врачу в случае любого ответа, даже если он скажет, что рака нет, что рака есть, потому что такая система не может брать на себя ответственность и давать какие-то рекомендации, так как ответственность должна себя брать врач, то есть человек. Ну, здесь пример, когда нет рака. И тут есть пример, когда... Это, кстати, вот у нас в группе есть парень, вот он. Виталий зовут, мы делали. Получается... открытое тестирование системы, он скинул такую картинку и попросил сказать, в чем смысл шутки, ну и в итоге система прочитала все, что есть на картинке, то есть она поняла, что это нужно отдать, что это не нужно отдавать агентам, это нужно внутри ядра применить там OCR, прочитать и результат, ну вот результат ответа на вопрос пользователя, то есть покинуть какие-то данные о произведениях George Orwell, какие-то данные о произведениях Franz Kafka и вот сгенерировать ответ. Также здесь показан еще тот старый пример, про который я уже говорил, что у нас есть агент, который решает математические задачи, то есть это уже моему скинули задачу он ее вот решил ну то вот продолжение что когда мы отправляем снимок получается он его описывает То есть можно спросить, что здесь, и он тогда понимает, что ему не нужна там CR-сканер, что ему нужно включить модуль аннотации изображений, и он будет туда описывать изображение. Но вот эти все примеры, они пока слабо показывают преимущество многогенной систем перед плагинами. Вот эти примеры показывают более явно это преимущество. И, кстати, здесь, как происходит сборка агентов. То есть мы говорим, что мы хотим вычислить. Важно, что этой формулы нет. У нас каждая формула записана в виде отдельного агента. Они договариваются между собой, кому какие данные нужно передать, чтобы произошло вычисление. результата, после чего самоорганизуются эти формулы, ну и представляются в виде той формулы, которой раньше не было, и подставляется значение, которое было вот здесь вот сказано, и происходит вычисление. Ну тут то же самое, что это вот такой формулы тоже не было, она тоже синтезирована, она синтезирована правильно, И мы также получаем результат вычислений. Ну и здесь опять то же самое. Как вообще работает наша система многоагентная? У нас есть задачи на естественном языке. То есть, по сути, на английском языке у нас есть задача. У нас есть блок устранения неоднозначной стартовки задачи. То есть это блок, который... Вот, например, когда мы говорим радиус, мы можем говорить там не только о круге, но и о цилиндре, о конусе и так далее. или вообще говорить не о геометрии. То есть вот в подобных задачах устанавливается неоднозначность. Если надо систему переспрашивать, опять-таки сюда интегрирован модуль логического вывода, который принимает решение, переспросить или не переспросить, или если нужно переспросить, то что переспросить. Далее переводится на внутренний язык многогетной системы. который обладает однозначностью карта. То есть нельзя там сказать, что вот это значит не это, а вот это. То есть там всегда получается радиус, и мы решили, что это радиус круга, то это будет именно радиус круга, а не какой-то другой радиус и так далее. Далее у нас идет синтез сборки агентов. То есть, например, в этом примере у нас каждая формула была отдельным агентом. И во время синтеза создается новая формула. После чего эта сборка запускается, получается некий ответ. Ответ передается большую языковую модель, вместе с контекстом диалога. И дальше результат вот этой большой языковой модели отдаётся в модуль агрегации результатов. И сюда же отдаётся, если, например, нам нужно выдать какое-то изображение, которое создал агент, либо график, либо ещё что-то, что сборка создала. какое-то там изображение графика или еще что-то, это выдается сюда же и, например, вот этот модуль агрегации результата может сказать, что вот это вот какое-то описание в подписи графика, но сами графики взять вот отсюда. И вот это вот весь результат вам дается на выход в систему. Ну и тут как раз-таки, если посмотреть, Примерно это и показано, что у нас есть, мы отправили изображение, мы получили ответ многоагентной системы, потом мы взяли вот эти значения. которые здесь есть, и отдали их LLM. Понятно, что вам агент отдает записание с некоторым, но уже LLM, основываясь на вот этом тексте вопроса, на контексте диалога, генерирует текст ответа. например, здесь агент также отдал что меньше 3,3% и что скорее всего рака нет, но так как был вопрос, что делать дальше, он все-таки объяснил, что делать дальше, опять-таки используя политику агента, что нужно в любом случае общаться с врачами и проходить какие-то обследования мимо врачей. И к тому же здесь можно отметить, что агент говорит про МРТ, так как он рассказал, что данные стримов являются не МРТ-снимком, а КТ-снимком. Здесь немного другой пример. Точнее, это та же самая задача с синтеза формулы. Здесь показана другая ее часть, что у нас есть какие-то простые формулы, они синтезируются, и вот агенты договариваются. То есть, в принципе, можно получить эту формулу практически сразу, но вот мы видим, что стоимость этого решения была бы 1,8, но агенты проводили несколько раундов переговоров, а именно четыре раунда в результате каждого. Здесь не было снижения стоимости, но вот здесь, получается, тоже не было. То есть у нас было два снижения стоимости, благодаря чему у нас 1.8 стоимость стала единичной. То есть мы, в принципе, эту формулу могли бы получить и сразу, но во время этих переговоров между агентами мы получили более дешевое решение. Здесь показана другая задача, когда мы загружаем данные. Например, в первом случае это был звук, и я просил систему отдать мне спектр. Тут в качестве агента выступают уже не формулы, а функции, написанные в C-Sharp. И он говорит, что уже последовательно вызвать получается преобразование из звука вектор, потом вызвать преобразование Fourier и получить модуль преобразования Fourier. Вот в таком случае мы получим спектр. Вот мы видим спектр. Потом я просил из изображения сделать текстур. Изображение было в формате PNV, поэтому порядок вызова был следующий. Загрузить изображение в формате PNV, преобразовать изображение в матрицу. преобразовать матрицу в вектор, выполнить преобразование в фурье, выполнить модуль найти этого преобразования, выполнить преобразование в фурье от спектра и найти модуль этого преобразования. Стоит кстати сказать, что здесь не показано, но в принципе это есть, это то, что здесь также мы просили вводить одномерный график, то есть если мы попросили матрицу, то у нас бы считался бы двумерный, то есть если мы просили делать двумерное преобразование, то у нас бы считалось бы именно двумерное преобразование фолье, но так мы просили везде вводить вектор, чтобы его можно было выражать на графике у нас, и здесь считается одномерным. И можно выбирать различные преобразования, которые знает система, выбирать различные типы данных, которые знает система, и она будет автоматически генерировать решение. Ключевые параметры продукта – это фактология, наличие логического вывода, Система плагинов. Ну, у нас не совсем система плагинов, у нас это многоагентная система. Автономность и целеполагание. Здесь каждый агент является автономным, и в нем есть система, которая iDoc, и она имеет внутри себя много целеполагания. И также мы предоставляем приватные API. заказчика в том плане что мы вот если отчасти до самого начала вот что у нас в принципе могут быть сервисы пользователей использованные, то есть когда работа агентов производится на их железе и к тому же вот здесь вот просто показано с одним ядром, но также вот это ядро тоже может быть где-нибудь на другом сервере находиться, то есть Мы пока не готовы передавать именно заказчикам на их сервера, но в целом есть там требования, чтобы языковая модель и все данные находились на территории Российской Федерации, на сертифицированном сервере, то, в принципе, эта требование выполнима, то есть вот это меню может быть туда загружено, и также к нему могут подключаться все эти агенты, либо какие-то выбранные агенты заказчиков, тогда информация и другие агенты просто уходить не будут. И, наверное, я сразу отвечу на другой вопрос, при чем здесь фрактальность, потому что это вопрос очень часто спрашивают. Вообще идея в том, что у нас есть различные конвертеры данных, многогенной системы, и все дело в том, что у нас может быть вот большая многогенной система, являться одним конвертером, то есть мы можем взять один конвертер, внутри него большая многоагентная система, внутри этих агентов тоже большие многоагентные системы, вот в таком плане покидывает взаимодействие и по всему это получается очень сильно напоминает фрактал. ну почему агенты вообще выбрали именно такое направление потому что во-первых они самоорганизуются то есть нужно создать больше получается сервисов чем У нас есть плагины, то есть у нас есть, скажем, ну как я уже говорил, 10 плагинов, и если мы считаем их как плагины, то у нас решаются 10 задач. Если мы считаем их как агенты, то они могут самоорганизовываться, что в принципе было показано ранее на слайдах. Следующее – это способность решать сложные многошаговые задачи. Ну, кстати, оно то, о чем я и говорю сейчас. За счет самоорганизации возможно решать многошаговые задачи, но также возможно учитывать некую динамику окрывающей среды, что у нас может какой-то агент отвалиться, какой-то агент просто быть на данный момент сильно загруженным. И если он загружен, то цена его вызова увеличивается. Если он отвалился, то понятно, что нужно искать другого агента, хоть этот мог бы и лучше решить задачу, что, в принципе, на базе промпов, как сейчас это реализовано, довольно сложно реализовать. Очень хорошая лекция про мультиагентные системы, которая мне очень понравилась. Это Петра Скобелева. Надеюсь, правильно сказал фамилию. Называется «Мультиагентные технологии». Всем советую посмотреть. Очень хорошая лекция, на самом деле. Ну, типы агентов, которые мы сейчас разрабатываем – это агент для поиска в интернете, поисковик ошибок в коде, парсер PDF. Ну, опять-таки, парсер PDF – это, по сути, тот же агент с фронтальной синтезом. Логический вывод с неполными данными – это вот то, что про IDOC я рассказывал. Поиск и недостроительность данных для данной задачи. Вот это как раз-таки модуль внутри каждого агента, который может быть представлен тоже многоагентной системой, про который я говорил, что это модуль, который не назначиваясь трактовки, решает агент, создающий цепочку решения, и агент, который исправляет ошибки описания. Вот, подключение агентов в Fractal GPT, то есть у нас есть некие скиллы, которые по сути являются агентами. Мы можем подключать нейросеть, то есть если вам нужны мощности Fractal GPT, вы можете его подключить через API. Можно создавать агента прямо на нашей платформе, можно создать агента на своей платформе, предоставить нам API, и мы за использование чужого агента, учтав перераспределение средств идет, что часть денег, которые дает юзер, мы отдаем автору агента, если его агент был вызван во время решения той или иной задачи. Здесь представлены некоторые области применения Frontal GPT. Это система синтеза новых идей из научной статьи, но опять-таки на базе своего фронтального синтеза происходит что-то вроде прочтения научной статьи, а имея модели мира, которые строятся в системе iDoc, мы можем синтезировать новые знания. Рассуждение системы намного более надёжное, чем текущая лента. Система консолирования и описания задач. Опять-таки, мы можем создать некий план, рассмотреть риски, например, мы можем создать систему многоагентов, но самих агентов не писать, тогда эта система будет просто говорить, в каком порядке их нужно вызвать, но она, по факту, будет составлять планы и считать риски. Вопрос в ответ на систему для бизнеса. Система автоматического доказательства TRM, система поиска недооцененные информации, недооцененные публикации. Система контролируемого диалога, образовательные системы с контролем, траектория обучения на базе мировых студентов и система описания умных городов на базе научных исследований, а также сервисы автоматизации студийной системы, экспедиенции и так далее. Существует такой проект, как Lama Index, но там используется опять-таки векторная база. Мы пытаемся уменьшить количество галлюцинаций, которые присущи Lama Index как раз таки за счет параллельного синтеза, о котором я рассказывал ранее, что мы не просто отдаем какие-то вырезанные куски разных частей текста, а мы структурированный текст отдаем уже. И нейросеть максимум, что делает, она поправляет стилистику, но мы на нее не перекладываем задачу генерировать полностью текст. Ну, также вопрос ответа. Сеттинги можно использовать вместо объяснения ошибок в коде, почему они возникли. причем искать мы можем информацию в различных системах и помогает, она пока не заточена на то, чтобы написать код, но она может его объяснить, найти ошибки и помочь отдебажить код. Также мы планируем встроить в нашу систему в качестве агента Сабин, как модули. То есть, если во время общения с нашей системой вдруг понадобится, по мнению нашей системы, эмпатичный ответ, то как раз таки будет вызван модуль Сабина, который сможет дать более эмпатичный ответ. Также может быть использованная в системах антифуд для Telegram, то есть может собираться динамически группа агентов, причем каждый агент может представлять какой-то чат и так далее для того, чтобы Выбрать только важную информацию для человека, либо информацию по его запросу, а не, получается, все подряд. Наши основные конкуренты — это OpenAI, Antrofica, Huggins OS с их системой Huggins GPT. Ну и вот AI21, Stability AI и Charter AI. Рынок для нашей системы – это медицина, маркетинг, право и наука. То есть медицина для системы может анализировать документы, в том числе, как было показано со снимками медицинских. В принципе, в качестве агента можно любую спецсистему встроить и взять медицинскую, поэтому может работать и в юриспруденции, может искать научные статьи. анализировать их и выдавать некую суммаризацию, это очень может помочь людям, которые занимаются наукой, также может искать статьи, которые являются половиной... у которых мало новой информации, то есть очень часто в статьях, например, пишут большое количество воды и совсем чуть-чуть реально какой-то новой информации. Нам нужно наконить именно эту новую информацию, чтобы люди не перечитывали все эти статьи и не суморезнили за счет этого проектального синтеза. Получаются ответы. На это все. 

S06 [00:54:21]  : Захар, спасибо. Виктор, тоже спасибо, поскольку доклад ваш совместный, как я понимаю, коллеги. Какие есть вопросы? Давайте пойдем по тому, что у нас написали в чате. Во-первых, вопрос от Константина Утолина. Может ли ваша система обработать набор конструкторской документации и создать на его основе базовую онтологию предметной области конструирования? 

S07 [00:54:50]  : ну вот именно фантазировать я думаю, что не стоит, поэтому я скажу так, что мы именно эту задачу не тестировали, у меня есть предположение, что сможет, но опять-таки не застегивай. 

S06 [00:55:04]  : Спасибо. Следующий вопрос от Константина Утолина. Как вы определили интуицию? Ведь чтобы некоторое качество или свойство тренировать, надо сначала понять, что это такое. 

S07 [00:55:18]  : Да, ну, мы исходили вообще из того, что у нас есть решение, которое принимается на базе некоторого логического вывода, то есть врезаются бочки размышлений, а есть решение, которое мы принимаем, скажем, сходом. И вот то, что мы принимаем сходу, без всяких логических рассуждений, это очень похоже на то, как работают нейронные сети. Поэтому по интуиции мы просто понимаем, LSTM-сеть. Сейчас. Здесь LSTM-сеть, которая... Вот тут у нас происходит многошаговый вот этот технологический уровень, то есть постоянно идет цикл разнушения, результаты которого отправляются в некий буфер, и во время так называемого, в общем, мы это разделили как на фазу сна, что вот у нас есть бодрство, есть сон, и во время этого сна просто мы обучаем LSTM-сети вот это вот название интуиции. То есть вот сеть, которая не может интерпретировать свое решение, как вот мы интуиции не можем интерпретировать, которая работает быстрее, и которая работает иногда очень точно, а иногда, когда недостаточно опыта, опять-таки как с обучающих данных, не достаточно обучающих данных, работает довольно плохо. То есть вот здесь не совсем LSTM, тут модификация, которая позволила очень сильно сократить количество параметров, но в целом можно почти не считать, что это LSTM-сеть. 

S06 [00:56:58]  : Спасибо. Следующий комментарий от Владимира Смолина, который я позволю себе проинтерпретировать как вопрос. Можете ли Вы прокомментировать про ионы кальция и собак Павлова? Видимо, для Владимира Смолина эта ассоциация не очень понятна была. 

S07 [00:57:18]  : А, хорошо. в общем, если говорить так, вот как работают у нас нейроны, то у нас есть по сути так называемый эффект, когда нейрон возбуждается и это происходит во многом благодаря ионам кальция, которые уходят в этот нейрон. То есть, внутри нейрона также есть кальциевые насосы, которые откачивают эти ионы. И вот, что я моделировал, что при активации происходит быстрое проникновение этих ионов внутрь нейрона. Ну, вот здесь, кстати, показано. при отсутствии какой-то стимула, оно откачивается, и эффект суммации, он возникает из-за того, что скорость, с которой откачиваются вот эти вот ионы кальция, она меньше скорости, с которой они проникают в случае какой-то активации, то есть при небольшом воздействии мы чуть-чуть добавляем сюда этих ионов, но у нас вот этот вот порог не пройден, то есть там порог порядка 70 милливольт, он не пройден, то у нас не происходит срабатывание. И как только мы перестали подавать какую-то стимулу, у нас включаются вот эти вот калиевые насосы, белковая структура, которые откачивают мы потом подаем снова импульс, но оно не успело откачать, здесь вот видно, что он чуть-чуть пошел вниз, но не успело откачать, и мы подали еще чуть-чуть, опять они включаются, но опять не успели откачать, и подаем еще чуть-чуть, и вот здесь мы проходим получается вот этот вот порог возбуждения, у нас нейрон активируется, вызывает вот здесь потенциалы действия, вот он смотрит потенциалы действия, и они запускают реакцию. 

S06 [00:59:30]  : Спасибо, но вопрос, видимо, был связан с тем, причем здесь собаки, но, видимо, собаки здесь были просто упомянуты вскользь, да? 

S07 [00:59:38]  : А, причем здесь собаки, потому что я пытался создать ассоциативное обучение такое же, как биологическое, и реальных графиков я не нашел, таких вот, хороших, скажу, графиков, я не нашел нигде, кроме работ Павлова. Ну и там все эксперименты проводились на собаках. Он реально измерял количество капель слюны при воздействии потенциалов и вообще, по-моему, является основополовником ассоциативного обучения. 

S06 [01:00:11]  : Хорошо, спасибо. Дальше здесь вот было несколько вопросов, связанных с тем демо, которое вы показывали. И здесь вот вопрос, а эта демо в доступе есть для желающих? 

S07 [01:00:25]  : У нас есть статья в доступе, а сама нейронка, мы ее запускали ненадолго в чате. Ну, кстати, вот там вот как раз-таки Виталий, один из тех, кто тестировал, был. Мы здесь показывали, что вот мы у себя в общем в чате запускали эту нейронку, он скидывал. картинку и получали ответы. Почему мы ее не запустили на постоянной основе? Здесь есть две причины, на самом деле. Первая причина, она заключается в том, что для того, чтобы работали все эти системы, нам нужны видеокарты. Сейчас я про их дело посудим. на свои деньги и вот покупать надолго скажем сервера с видеокартами это дорого причем видеокарты должны быть хорошие от t4 выше вот вторая причина почему мы так не делали это вот здесь вот я рассказывал про предобработку у нас предобработки должны быть модули детекции токсичных высказываний, его сейчас нет и бесконтрольно запустить его могут быть проблемы связанные с тем, что люди начнут писать всякую ерунду, я имею ввиду какие-то противозаконные вещи начнут писать, противоправные, система может начать отвечать, потому что этого модуля сейчас нет. Он должен быть здесь и здесь. Поэтому сейчас этого нет, но в конце июня мы запустим, когда уже демо, эти модули будут добавлены, они уже разработаны, так что вот в конце июня. 

S06 [01:02:10]  : Окей, кстати, насчет демо, значит, вы, может быть, обратили внимание, я там в группе по интерпретируемой обработке естественного языка дал анонс на последнее расписание воркшопа, который у нас будет в Стокгольме онлайн 19 июня, на котором вы тоже выступаете. И там, в частности, коллеги из группы НАРС, они будут по своей работе скрещивания НАРСа с ЖПТ, будут показывать демо. Поэтому, может быть, вы успеете за недельку быстренько собраться? 

S07 [01:02:49]  : Если показать контролируемое демо, то да, конечно, успеем. Единственная проблема Я повторюсь в том, что запустить ненадолго это не по финансам, не по тому, что там будут какие-то токсичные фразы. Это не проблема. Так что если ненадолго запустить, то это, я думаю, будет возможно. Проблема вот как раз таки в том, что Если так остать, скажем, уйти, не контролировать, что там происходит, то могут быть неприятности из-за того, что люди будут писать какие-то противоправные вещи. Пока модуль до конца не оттестирован, запускать полноценную дему, я думаю, не стоит. А там показать примеры работы, то есть, например, включить инсталляцию экрана, написать что-то в систему, получить ответ, показать, как она работает, я думаю, с этим проблем не будет. 

S06 [01:03:44]  : В общем, имейте в виду, там сейчас у вас стоит полчаса на доклад с вопросами и ответами. Соответственно, если нужно, можно попытаться это время чуть-чуть увеличить, чтобы именно дему пришлось время. Напишите тогда в личке, потом отдельно. Дальше идем по вопросам в чате. Евгений ненароков спрашивает ряд у него вопросов. Давайте их все сначала задам. В каком виде система предоставляет ответ? Это всегда будет текст или существует возможность расширить до других форматов? Также есть вопрос по агентам. Это генерируемый продукт системы или их нужно писать лапками? 

S07 [01:04:31]  : Это два вопроса, да? Сейчас отвечу по порядку. Ну да, по сути, два вопроса. Получается, вот здесь показано, как это работает система в целом. То есть, у нас есть LLM, которая дает текст. Но также у нас есть и вот здесь, в сборке агентов, как мы видим, вот из, например, этого скриншота, Агенты выдают, например, здесь графики. То есть вполне может быть заменен текст, описывающий графики. Агентами будет собрана, например, такая сборка, и клавиатура будет прикреплена к графику. То есть вот здесь как раз таки есть агрегация результатов, то есть у нас есть синтез сборки агентов и одних результатов, а одних результатов это график, по сути. Но LLM также генерирует описание, и все вместе это может быть отправлено в виде документа, может быть отправлено в чат. В демо я этого не делал, просто из-за того, что хотел туда приклеить симуляцию, но потом решил, что слать, в общем, людям Огромные ответы, они не скинули одного снимка, они присылали огромные ответы, с кучей графиков и всего остального, различные признаки, выдеятельности и прочее, которое для врачей довольно существенно. Я решил, что неправильно, потому что там только текст был. Но по факту, даже тот агент, которого я показывал, он может генерировать небольшой отчет, Этот отчет потом, с помощью LLM, может расшириться и уже содержать внутри себя ответы на вопросы юзеров. И, может быть, неправильным, например, подряд документом, либо какими-то РТФ-командами. Так, это на первый вопрос. 

S06 [01:06:21]  : А второй вопрос, повторяю, значит, по агентам, это генерируемый продукт системы или их нужно писать лапками? 

S07 [01:06:28]  : На данный момент они, сами агенты, пишутся лапками. выразился тот, кто спрашивал. Но при наличии агента, который может писать код, вполне может быть генерируемый продукт системы. Есть какие-то стартапы, которые говорят, вот мы напишем... Правда, они не агенты, они инструменты пишут, то есть агенты, в отличие от инструментов, это не инструменты, но задачи. Они, например, делают вызов GPT-4, они пишут код, потом запускать по интерпретаторе выполняют но здесь вот у меня категорическое отношение к этому я сейчас на это не готов делать потому что у нас нет никаких скажем оснований доверять тому коду который напишут GPT-4, так как, например, вчера я пытался решить несколько задач, я просил GPT написать хотя бы просто каркас для кода, но из всех запросов ни один не венчался успехом. То есть, как бы, код есть, он как-то работает, а вывод — полная чушь. То есть, если Это у нас какая-то очень простая задача, типа сортировки, визуализации данных из Pandas и прочее. Да, GPT напишет код, его можно запустить, и это будет генерируемый агент. Но если задача какая-нибудь посложнее, например, взятие какой-нибудь FSK-моделированного сигнала и из него извлечь биты, Но уже все, в 2004 году такое не напишут, она будет писать код, он даже будет собираться, он даже будет работать, но только он будет выдавать полную чушь. 

S06 [01:08:12]  : Спасибо. Следующий вопрос, а вот даже дальше вопрос от Вадея Егоршева. На каком принципе базируется самоорганизация агентов в многоагентной системе? Задайте первый вопрос. На каком принципе базируется самоорганизация агентов? Второй вопрос. Как строится вывод, что они должны самоорганизовываться? 

S07 [01:08:43]  : Я на этот вопрос отвечу только в общих словах, потому что конкретный принцип – это наш ноу-хау, так как это именно мы придумали, и не хочется это раскрывать. Если отвечать в общих словах, то у нас есть задача, выраженная на мудром языке модельной системы, так как у нас используется система логического вывода. а и док, то у нас этот язык называется DocLink, вот на котором устроятся все эти запросы. Далее агенты просто общаются друг с другом на тему того, могут ли они решить эту задачу. То есть вот задача есть и какой-то агент говорит, я могу ее решить, но он ее, например, не решает, он ее раздевает на 10 подзадач. Потом он отдает эти 10 подзадач, и какие-то агенты говорят, я могу. Другой говорит, я могу. Ну, кстати, вот здесь непохожая вещь. Один агент разбил много подзадач, а потом другие агенты, договариваясь, решили, что вот здесь вот ненужная задача, и вот здесь вот ненужная задача, которую тот агент, который разбил, изначально выиграл. И оптимизировалось решение, ну, почти в два раза. То есть они за счет переговоров в качестве языка коммуникации используют наш язык доклэнг, но более подробно о том, как устраняется эта неназначность и прочее, мы не хотим пока раскрывать, потому что это наш новый хаос. 

S06 [01:10:11]  : Антон, а можно на суд забрать? Конечно, конечно, пожалуйста. Здравствуйте, Владимир Петрович. 

S08 [01:10:18]  : Я просто хотел уточнить, на самом деле не ответ, Я не понимаю, кто их заставляет вместе решать задачи. Например, людей заставить – это очень трудно сделать. Люди ругаются, ссорятся. Что мотивирует решать задачи? Это совместно хитрое вознаграждение, я не учу. 

S07 [01:10:47]  : За решение задачи награждает награда. Каждый один хочет увеличить... А то, что он совместно решил дополнительный наград, то есть он может один решить? Если он может один решить, то он получит всю стоимость задачи себе. 

S08 [01:11:07]  : Их должно разнести в клочья, потому что они как раз сразу лакомятся. Я спросил про самоорганизацию, именно что их держит вместе. Мне вот это вот интересно. 

S07 [01:11:18]  : Смотрите, есть один агент, который может решить задачу, и он это сделает, скажем, дешево. то он ее решит, и это будет оптимальный вариант. 

S08 [01:11:29]  : А кто решает, что это оптимальный вариант? Извините, я не буду продолжать, потому что эта социология занимается очень тяжелой политикой. Просто ответ простого, если он есть какой-то критерий, может быть... Да, есть. 

S07 [01:11:47]  : Ну вот я сейчас пытаюсь объяснить. Что у нас, например, когда мы решаем... Вот, предположим, у нас есть какой-то агент, который решает задачу, предположим, с ошибкой, с вероятностью, точнее, правильного решения до 99. И мы берем 5 таких агентов. То, что не лишат задачи, это 99,5 степени, то есть у нас цепочка. Если же мы говорим, что у нас один агент может решить задачу, то вероятность того, что он правильно решит, это просто 99. Вот такой вот пример. И мы можем сказать, что если он может решить ее один, то пускай и при этом дает такое качество, то он может взять такое вознаграждение. 

S08 [01:12:37]  : А кто определяет, в какой момент они определяют? 

S07 [01:12:41]  : У нас система автоматически в режиме, в непрерывном режиме тестирует агентов, на их загруженность, на их качество решения и так далее. 

S06 [01:13:00]  : Хорошо, спасибо. Дальше у нас подоспели вопросы из YouTube. Первый вопрос от Александра Литуновского. По каким алгоритмам согласовывается переход от двух частей графа в единый? 

S07 [01:13:20]  : Ну это вот как раз таки на базе ортологического ввода строится. 

S06 [01:13:28]  : Вот. А тогда следующий вопрос. Как реализован логический вывод? Вопрос от Виктора Сенкевича. 

S07 [01:13:35]  : Ну, я расскажу в общих словах опять-таки, потому что именно эту часть мы не хотим разглашать. В общих словах у нас есть вот здесь модуль выделения состояний. По сути, что он делает? Он преобразует некий вектор, или несколько векторов, если у нас несколько датчиков, в одно значение. Это значение, то есть мы записываем сюда, получается, как в районе единицы. Следующее у нас получается значение, например, в следующий такт времени у нас значение получилось 3. Мы говорим, что у нас появился переход от 1 в 3. Ну, на самом деле, там чуть посложнее это все, но смысл вот именно в этом. И мы говорим, что вероятность перехода из 1 в 3 такая, а вероятность перехода из 3 в 1 такая, а вероятность перехода из 1 в 2 следующая. И когда мы говорим, что мы в состоянии 1, мы можем сказать, что, во-первых, у нас есть некая приоритетная вероятность, что мы перейдем в состояние 3, но также у нас есть вероятность того, что мы перейдем в состояние 3 при условии, выполнение некоторого действия. Почему была именно такая стратегия обучения? Потому что она может работать без учителя. То есть мы делаем случайные действия, никакого подкрепления у нас нет, но мы просто собираем статистику, что мы так переходим, мы в другом состоянии вместо какой-то вероятности, если у нас выполнено какое-то действие, мы переходим с большей вероятностью или с меньшей вероятностью. и потом мы можем, когда у нас появляется подкрепление, достаточно нескольких вот этих вот векторов эмоций, чтобы сказать, что, например, на состоянии 3 у нас вот были такие-то эмоции и мы дальше их можем распространить по графу и сказать, что если у нас вероятность перехода из этого состояния в это такое-то, то мы с такой вероятностью получим такое-то подкрепление с такой, либо можно пройти вот такой путь, либо из этого вот так можно пройти. То есть мы говорим, что мы хотим перейти вот в это состояние, а как мы его перейдем? Чтобы максимизировать вероятность перехода в это состояние, нам нужно выполнить какое-то конкретное действие. И отсюда появляется, вот из этого рассуждения появляется то, что мы здесь должны выполнить какое-то действие. но также у нас есть и вот этот модуль, который тоже говорит, что просто вот этот модуль, он не оперирует этим логическим выводом, он просто говорит, что если мы получили такое-то действие на вход, вот если у нас был такой-то вектор на вход, то нам нужно выполнить такое-то действие, то есть они как-то не интерпретируют ничего, и модули выбора есть, у нас здесь есть одно дискретное сместораспределение, а точнее одно дискретное распределение полосы вероятности, другая дискретная полоса вероятности, потом нужно создать смесь такую, чтобы потом неким симулированием мы бы выбрали наилучшее действие, то есть вот в этом идея. 

S06 [01:16:53]  : Спасибо. Следующий вопрос от Виктора Зинкевича. Что в системе фрактального? Я уже, кстати, отвечал на этот вопрос. Он, видимо, поздно присоединился, но, если можно, еще раз поясните. 

S07 [01:17:07]  : Хорошо. Во-первых, у нас есть система фрактального синтеза-ответа. Почему мы ее называем фрактальной? у нас есть, получается, различные предложения, они объединяются в сниппеты, сниппеты объединяются в блоки сниппетов, эти блоки сниппетов могут быть более крупными, еще более крупными, еще более крупными, но самое главное, что вот эти взаимоотношения, они строятся по одному и тому же алгоритму, то есть это не то, что вот мы сейчас таким алгоритмом построили эти взаимоотношения, потом таким, потом таким, потом таким, нет, у нас один и тот же алгоритм, и мы можем сказать, что мы сейчас хотим масштабе у нас будут какие-то значения. Если мы пойдем на другой более мелкий масштаб, на еще более мелкий масштаб и так далее, мы будем видеть примерно ту же самую структуру, ту же самую организацию. То есть мы можем брать разные масштабы, вот как фрактали, но на каждом масштабе мы увидим одну и ту же структуру организации. То же самое касается многодетной системы. У нас может быть один агент представлен большой многоагентной системой. Внутри него каждый агент тоже представлен многоагентной системой. И мы можем вот так вот спускаясь по... Мы сейчас работаем на самом верхнем уровне абстракции, то есть с определенными агентами. Но потом мы можем спуститься ниже, ниже, ниже. У нас будут такие же точные системы. Имеется ввиду, за Киев точно, в том плане, что, конечно, ядро системы будет другое, а вот, в принципе, взаимодействие, в принципе, организация будет точно таким же. 

S06 [01:18:39]  : Спасибо. Следующий вопрос от Александра Летуновского. Как система понимает, что в дело должен уступить именно тот агент, который отсылает к врачу? 

S07 [01:18:52]  : У нас есть, опять-таки, там оболочки системы. В оболочке агента есть система, которая, основываясь на статистике вызовов агента, на статистике ревардов и прочее, может сказать, что эта задача относится к этому агенту, а это не относится. И когда мы получаем задачу, По сути как DQM эта штука может сказать, что если я возьму эту задачу, я получу какой-то ревард. Если он ниже порога, значит она не берет эту задачу. А если он выше порога, то берет. 

S06 [01:19:31]  : Спасибо. Следующий вопрос от Константина Утолина. Вы упомянули Петра Скобелева. Сравнивали ли вы свою систему с теми, которые предлагает с описаниями сам Скобелев? 

S07 [01:19:46]  : да, конечно, сравнивал, и мне очень нравятся его работы, но его системы, они больше на логистику нацелены, и даже он в своих работах, ну, не работах, а в докладе он говорил, что он не занимается, ну, по крайней мере, на тот год, когда был доклад, он 17-й год, если я помню. он говорил что он занимается именно интеллектуальным агентом то есть это я помню его доклад про систему про группы спутников вот очень мне понравился и также вот его рассказ про оптимизацию логистики но у нас немного другая специфика в том плане что мы работаем именно с получается, с индивидуальными агентами. Но в целом, действительно, его доклад, его статьи я читал, и не только его, но и там его был руководителем. То есть смотрел, искал, две статьи читал и сравнивал. Но вот у нас немного разные типы агентов и разные решаемые задачи. 

S06 [01:21:01]  : Спасибо. Здесь Валерий Егоршев возвращается к вопросу про самоорганизацию агентов. Следующий вопрос. Если качество ответа агентов определяется снаружи от группы агентов, то получается есть один суперагент, который решает правоту для всех. А раз так, то чем эта система отличается от одноагентной, только уже теперь на уровне выше на один? 

S07 [01:21:29]  : А можно пояснить вопрос? 

S06 [01:21:31]  : Давайте я своими словами поясню ответ. Смотрите, если есть агент, который решает какой из агентов должен вступить в дело, то есть вопрос о том, кто должен направиться к врачу или к слесарю, Это же кто-то решает. Соответственно, есть некоторый суперагент, диспетчер, который осуществляет вычисления по поводу того, куда все-таки пациенту отправляться. И тогда получается, что все-таки система не мультиагентная, по-честному, а все-таки у нас система децентрализованная, что есть множество агентов, которые все-таки… То есть это получается не пир-то-пир, а все-таки звезда, в центре которой находятся супервизоры. 

S07 [01:22:23]  : Архитектурно это больше похоже на звезду, потому что у нас есть модуль, который по факту назначает задачи. Но что касается того, кто должен выполнять задачи, нет. Если бы у нас был один агент, который назначал бы задачи, то наша система была бы менее гибкой, в том плане, что мы бы не могли ее бесконечно расширять. А бесконечно расширяемая наша система, ну и вообще система, как я лично считаю, это одна из основных, вообще один из основных принципов АДИФ, что система сельского искусственного интеллекта должна быть бесконечно расширяемой и желательно даже самообучаемой, то есть она должна создавать сама агентов, Мы до этого пока не дошли, но вот идем в эту сторону. То есть, конечное решение, будет ли решена та или иная задача, принимает агент. Другое дело, что само устройство агента, оно довольно сложное. То есть, не только вот сам какой-то решатель, который решатель перед задачей используется есть, но также есть еще оболочка, которая представляется менеджером, но не менеджером всей системы, а менеджером конкретного агента. Вот эта штука и может сказать, что вот, скажем, вы хотите, чтобы я решил эту задачу, а вот я три раза подряд пытался решить эту задачу, и у меня ничего не получилось. Я, наверное, не буду ее решать. То есть вот... Или наоборот. Да, я там 10 раз уже решал эту задачу, и я ее решил отлично. Давайте я ее решу. 

S06 [01:24:02]  : Спасибо. Дальше. Здесь вот Константин Утолин прокомментировал, что Скобелев сейчас, Петр Скобелев, сейчас разрабатывает концепцию так называемого emergent intellect, и у него появились материалы на эту тему. Рекомендую ознакомиться. Я хочу сказать, что у нас действительно был доклад, у нас был семинар весной по коллективному и общему искусственному интеллекту, и там я считаю лучший доклад из тех, что присутствовали, был как раз доклад не самого Скобелева, а его сотрудницы, его коллеги, по поводу того, как они действительно построили систему, так сказать, честного. В том смысле, как это имеет в виду Валерий Егоршев, эмержентного мультиагентного интеллекта. И с помощью этого интеллекта они промоделировали развитие растений в предлогных задачах моделирования развития сельскохозяйственных структур. А там действительно, вроде как, у них все без супервизора. Но с другой стороны, действительно, они решают задачи именно мультиагентного поведения на более примитивных агентах, то есть агентах, которые пытаются что-то говорить на естественном языке. Таких задач у группы Скобелева не стоит, по крайней мере, он про них не рассказывал. Вот, а дальше тут еще из YouTube подоспели вопросы и комментарии. Александр Лютуновский пишет. Вы, значит, пока не поняли суть работы антифлуда? Если нужна идея на миллиард, обращайтесь. Вы реализовали часть моего задуманного сервиса контекстно-паттерной модели. Вот, так что вот смиритесь с Александром Лютуновским. Значит, у вас есть… он вам даст идею на миллиард, так что вы еще капитализацию поднимите свою, и ОПАН, и я, и вообще будет нервно курить в сторонке. А дальше два вопроса от Виктора Сенкевича. Судя по объяснению, логический вывод у вас вероятный стоит. На тексте нет примера, как делается вывод? Или в системе просто отсутствует логический вывод на текст? 

S07 [01:26:03]  : Примеров именно как скриншоты нет, но вот работали над этой темой и сейчас работаем. Одна из задач — это прогнозировать реакции пользователей, прогнозировать, получается, создавать модель мира, то есть получили какой-то текст, но не просто его, как положит сейчас JPG, рассматривать какой-то атомарный текст, просто вот, ну как контейнер довольно большой, но просто атомарный, который нигде не закреплен, а вот мы строим модель мира и можем перейти, например, при вопросе, какие были причины, мы можем перейти и посмотреть, какие при вопросе, что будет дальше, нужно перейти посмотреть, что будет дальше и так далее. То есть вот такая система у нас есть, работаем над ней. Единственное, что у нас, скорее всего, в июне еще не будет этого, но вот в конце июля ее добавим. 

S06 [01:27:01]  : Спасибо. Коллеги, есть еще у кого-то вопросы, комментарии? Александр, пожалуйста. 

S02 [01:27:08]  : Здравствуйте. Добрый день. Большое спасибо, Захар. 

S06 [01:27:13]  : Мне не очень понятно... Александр, Вас плохо слышно. Можно чуть поглумче попробовать сделать? 

S07 [01:27:17]  : так сейчас сейчас попробую так вроде у меня сейчас лучше слышно нет чуть-чуть но не намного и нам нет разобрать можно так если вы с компьютером против ищи предусиление микрофона если это видос то там нужно до 30 децибел покрутить прогрессии да да да да только какой 

S02 [01:27:36]  : Настройки микрофона. Александр, на самом деле слышно. Слышно. Хорошо. Говори прямо в микрофон. Обычно все было в порядке. Мне понравилась последняя фраза Антона про поводу OpenAI. Что конкуренция. Так я вот не вижу вообще в принципе какая конкуренция с вашей стороны OpenAI. Можете уточнить это? 

S07 [01:28:01]  : Ну тут скорее идея в том, что они делают по сути синий искусственный директ, и мы делаем синий искусственный директ. Они говорят, что их система, будучи там например, также GPT-5 и прочее, будут нацелены на решение большого класса задач. И мы говорим и делаем систему… Смотрите, хорошо. 

S02 [01:28:21]  : Здесь вообще, в принципе, так, что вот, скажем, если бы вы этот доклад делали год назад, он бы звучал точно так же, как сегодня. Вы также упомянули бы BERT, там GPT-3 поставили бы вместо своей машины, и ничего бы не изменилось. То есть совершенно ничего принципиально не изменилось бы в вашем докладе, который прозвучал бы год назад. Но мир сейчас совершенно другой. Через год. Есть GPT-4. И вы как бы все преимущества, которые дает GPT-4, которые поставила на уши мир, вы игнорируете. Вы просто как бы это не упоминаете про это. То есть, мол, есть там какая-то модель, которая преобразует текст, какие-то сниппеты, какие-то запросы, промпты в язык человеческий. То есть вот только для этого используете языковую модель. Поэтому мне, вот с моей стороны, я сейчас много читаю текстов о том, как и мультиагентные, и многоэтапные цепочки выводов, и использование векторных баз данных, и всего чего угодно. Это обвязка GPT-4. То есть для того, чтобы применить огромное количество всяких приспособлений, это и плагины, и агенты. Плагины же это все-таки не OpenAI, это просто отдельно сделанное решение, какое-то такое маленькое решение сбоку бантика. Это не принципиальное решение, будет ли агент или будет плагин, потому что центральным является сам GPT-4. И на него можно навешивать и плагины, и агентов, и чего угодно. А по сути ваше решение, оно, ну как бы да, то есть вы можете поставить GPT-4 в виде языковой модели, и она будет составлять как бы ту агишность. А вся обвязка – это не агишня, это просто устранение каких-то проблем, которые связаны с языковыми моделями. 

S07 [01:30:26]  : Хорошо, да, я отвечу на этот вопрос. Дело в том, что действительно сейчас такой тренд идет, что мы берем какую-то модель G53, G54, сейчас G53, G54, и на нее все это навешиваем. Вот сейчас такой тренд идет. Поэтому я и говорил в самом начале доклада, что Основной тренд сейчас идет LLM-центричный. То есть вот когда у нас в центре находится некая большая языковая модель, мы на нее какие-то примочки навесили, она ими управляет, она является тем мозгом, который этим управляет. В ней содержится почти все знания этой модели. Мы будем к ютубазу еще обратиться, но все знания, все содержится внутри этой модели. вот за счет этого строится решение. вот тут идет вразрез с тем, что мы делаем. потому что мы говорим, что мы не будем использовать нейросети, то есть языковые модели, для хранения данных, ну то есть как бы для хранения знаний. Мы не будем использовать нейросети для синтеза решений. Мы используем свои алгоритмы, тот же IDOC, который я начинал, кстати, вот вы говорите, если я в прошлом году докладывался, я в прошлом году как раз по нему и докладывался. Просто возникло много проблем, которые я где-то год еще решал. То есть вот у нас есть логический вывод, у нас есть 

S00 [01:31:59]  : многолетней системы. 

S07 [01:32:00]  : У нас, в принципе, это все может работать вообще без зло. То есть, как с тем уже показано, у нас берутся знания из каких-то баз, мы Их нашим методом синтезируют. 

S02 [01:32:12]  : Вы рассказывали, я все это понимаю, но вопрос в том, что вау-эффект и разговор про АГИ возник именно осенью прошлого года с появлением GPC 3.5, а сейчас GPC 4 это совсем бум. Вопрос не в обвязке, а в самой модели, которая перешла на новый принципиальный уровень. 

S07 [01:32:39]  : Если честно, я не увидел нового принципиального уровня в этих GPT-4. Я с ними работал. писал код с помощью D4. И получается, вот Бахин говорил... Ну, естественно, проблемы есть. 

S02 [01:33:00]  : Александр, Александр, ну давайте договорить. Нет, дело в том, что Захар повторяет одно и то же. То есть он то, что говорил, он повторяет. Поэтому мне хотелось бы что-нибудь новое услышать. А что вы конкретно хотите услышать? Вот сейчас он сказал действительно новое. То, что он не удовлетворен уровнем GPT-4. Он считает, что ничего нового не появилось. Но весь мир, в отличие от Захара, считает, что появилось принципиально новое. И в данном случае, кто здесь прав? Захар, который нам предложит сейчас обвязку для Берта. Или весь мир, который сейчас подписан на GPT-4? 

S07 [01:33:39]  : Хорошо, я могу ответить на этот вопрос. Дело в том, что весь мир по факту не состоит из специалистов. Дело в том, что мы с GPT-моделями работаем очень давно. То есть, да, она чуть лучше сейчас генерирует, да, более качественный текст, но вот принципиально нового. 

S02 [01:34:02]  : Мой прогноз, что вы даже близко не подойдете к конкуренции с OpenAI. 

S06 [01:34:13]  : Хорошо. У нас тут появилось еще несколько вопросов, но Евгений Ненароков хочет вступиться за автора доклада. Евгений, пожалуйста. А потом еще несколько вопросов у нас останется время. 

S04 [01:34:25]  : Да, тут есть огромное количество вещей, которые можно отметить. Для начала по поводу того, почему подход больших языковых моделей несостоятелен в принципе. Они ограничены набором поступающих данных и выводят все свои выводы, какие-то закономерности и так далее, как статистические. Статистическое в процессе человеческого мышления, для начала, Это попытка увязать вещи, которые, как сказать, разделяются гранью между абсолютно невозможными и точно случившимися. В природе не существует точно невозможных вещей. Это наша попытка упростить модель внешнего мира для того, чтобы пытаться ее осознавать. Тут получается, что люди берут модельку, вырывают из всего контекста особенностей когнитивной машины человеческого ума одну единственную модельку к упрощению мира до статистических вероятностей и пытаются на этом куда-то выехать. Но это абсурдно. Насчет конкуренции, я думаю, тут дело просто в маркетинге. Чем будет лучше маркетинг, тем будет больше возможностей конкурировать с OpenAI. Ничего сверхъестественного OpenAI не сделал. Насчет кода скажу. Кода, напишет, отвратительно. Я по своей профессии разработчик, я пишу код в бизнес-сфере, в плане не какие-то научные исследования или искусственный интеллект, а прям прикладной рабочий код. С задачами своими она не справляется. Ни про какие прорывы, говорят же, 5.4 говорить нельзя. Система плоха. И я очень рад, что существуют проекты, где пытаются делать логические движки, вместо того, чтобы пытаться увязать все под статистику и вероятность. Спасибо. 

S06 [01:36:32]  : Да, коллеги, спасибо. Дискуссия интересная. Я всех тогда уже приглашаю на доклад, собственно, оппонента, спикеру Александра Балдачева, который будет в том числе рассказывать про свой опыт. Чат ГПТ семинар состоится через две недели. Это, получается, у нас будет 29 июня. Вот, а сейчас давайте еще дадим слово Виктору Носко и потом ответим на несколько вопросов. 

S01 [01:37:05]  : Виктор, пожалуйста. Да, здравствуйте. На самом деле, тот вопрос, который Александр задает, это тот вопрос, который мы обсуждаем часами. Мы его часами обсуждаем, и я, как участник проекта FocalGT, такой ярый критик на самом деле множества различных подходов. Конечно же, я пробовал, игрался в GT4 и в 3.5. Но первое, да, по поводу новизны. Все-таки у нас в докладе новизна есть, то есть мы заявили о том, что у нас есть эмоции, целеполагания. Да, конечно, сейчас это раскрыто пока. недостаточно глубоко по причинам того, что у нас очень серьезная конкуренция. Мы сознательно не раскрываем многие вещи, но я могу сказать так, что я видел формулы, я видел выкладки, я видел теорию. Конечно, кроме команды эту теорию никто не видел, но вот я видел. Поэтому я могу сказать, что здесь новизна есть. Во-вторых, я, конечно же, в восторге. Мне GPT-шки нравятся очень. Я их рекламировал еще с 2020 года, когда мы создавали наши продукты, чат-боты. И так далее. Да, конечно же, мы с самого начала понимали их фундаментальные недостатки. Действительно, прорыв определенный произошел, но я согласен с Захаром, что он не фундаментальный. Прорыв не фундаментальный. И OpenAI пишет об этом в своей статье, собственно, ну OpenAI, да, то есть люди, которые разбирали эту статью, sparks, искры сильного искусственного интеллекта, обзор GT4, они там, собственно, и подчеркивают, и мы здесь, на семинаре Agile Russia, мы также разбирали и говорили о том, что цепочка логических выводов членов социума, то есть она недостаточно круто работает, и что с этим делать совершенно непонятно. Различные подходы, они все являются кустарными. То есть делать фидбэк на каждый шаг логического вывода. Есть такой подход. Прикручивать туда экшены, прикручивать тот же самый rlhf. Это все, ну можно сказать, что это припарки. То есть есть такая поговорка по поводу припарок. В общем, это все припарки. То есть это то, что не модифицирует архитектуру GPT. И вот, отвечая Александру, я могу сказать, что этот вопрос, который вы задаете, он задавался в самом популярном комментарии на DTF, когда мы анонсировали проект. Вот самый популярный комментарий, который-то есть, который набрал максимум лайков, штук 60 лайков, да. Это был вопрос о том, что у вас же моделей нет, и нет денег на то, чтобы их обучить, поэтому у вас как бы ничего не получится. Я, отвечая на этот комментарий и видя, что он приковывает значительное внимание аудитории, во-первых, отвечал, что нам на текущий момент обучать свои модели не нужно. И существуют методы и подходы, в частности мультиагентный подход, который позволяет добиваться сопоставимого качества на моделях, которые обладают гораздо меньшим количеством параметров, вот этих миллиардов параметров. Вот это первое. А второе, я отвечал, что мы планируем обучать свои модели, мы планируем обучать свои модели другой архитектуры, то есть мы думаем, что действительно нужно развивать GPT, ну, как все, на самом деле, понимают, в сторону того, что мы должны туда добавлять логику как-то внутрь. Как это будет делаться, да? Ну, а пока что об этом рано говорить, но, в общем, действительно, на самом деле архитектура новая, она нужна, и есть подтвердение, есть пруфы того, что мы Ну вот, в общем, мы писали о том, что мы позже просто будем это делать. То есть, соответственно, получается, Александр, что у нас есть часть, которая касается и многоагентной, как know-how, и мы понимаем, что и GPT нужно тоже применять на крутое и полезное для взаимодействия с человеком. Естественно, языковой интерфейс, это взаимодействие с человеком. Как человек-то будет ставить в системе задачи, это реально важно. поэтому как бы вопрос, я думаю, про новизну, мне кажется, он должен быть снят. 

S06 [01:41:30]  : Хорошо, спасибо. У нас еще есть несколько вопросов и еще хочет Владимир Потапов высказаться. Вопросы появились сейчас, давайте я вернусь. Владимир Потапов, собственно, и спрашивает, как реализуются целеполагания? 

S07 [01:41:50]  : Ну, конкретно, уже я и Виктор говорили, что конкретно мы не будем разглашать, а общую структуру расскажу. Идея заключается в том, что у нас есть, например, какая-то точка в графе, то есть вершина, у которой высокий уровень реварда. Нам нужно до нее дойти. Мы можем построить путь до этой точки, но опять-таки, во-вторых, сейчас у нас не граф, а более сложная структура, но пока предположим, что это граф, и вот мы можем найти точку, построить путь и выбрать тот путь, который наиболее вероятно мы сможем пройти, выполняя определенные действия. И вот список этих действий, которые нам нужны для того, чтобы пройти этот путь до точки с максимальным ревардом, это и есть, по сути, наша цель – получить этот ревард, а план – это выполнить набор этих действий. И мы создаем довольно большой план, причем мы его создаем на основном уровне абстракции, мы создаем на верхнем уровне абстракции глобальные планы, и чем ниже, тем планы более детализированы. 

S06 [01:43:07]  : Спасибо. Следующий вопрос. А система логики у вас жесткая? В плане законы логики вы вписали в ядро как факт или в процессе обучения ядро их естественно выводит? 

S07 [01:43:21]  : Закон логики в том смысле, как мы получаем, например, если у нас пришел код, который мы знаем, например, что это кошка на значение, что у этого животного, например, есть хвост, лапы и тому подобное, что эта кошка тогда вот с такой-то вероятностью, вот сам метод учёт таких вероятностей, конечно, он жёстко вписан, но атрибуты, они уточняются во время обучения, они могут исчезнуть, могут исчезнуть, может появиться новое правило, я год назад запускал эту систему вообще без правил и не обученную она сама обучила вот систему выделения состояний и сама же в итоге начала обучать логический модуль то есть изначально я запускал вообще без с необученной системы выделения состояний и с полностью последовательным логическим выводом в итоге Эта система обучилась и предсказывала мои действия с вероятностью 98 процентов. Когда я водил мышкой по кругу, то есть координаты мышки предсказывались с вероятностью 98 процентов. Когда я начинал тягать в разные стороны, то вероятность до 40 падала. Но к конкретному движению, к конкретным векторам, система адаптируется довольно быстро. Если данные перестали быть актуальными, то они, вот так же, как и у живых существ, постепенно, вот эти связи пропадают, и появляются новые связи, которые отвечают новой картине мира. И вот этот процесс, он не прерывен, он идет постоянно. 

S06 [01:45:05]  : Спасибо. Следующий вопрос от Алексея Целих. В каком модуле у Вас используется нечеткая логика позади? Где-то, видимо, показалось автору, что упоминалась нечёткая логика позади. 

S09 [01:45:25]  : Ну, по-моему, вот на втором слайде у вас нечёткая логика была названа, а потом она нигде не прозвучала. Буквально в самом начале. Вот, вот, нечёткая логика уже работает. Третий слайд. Вот, последнее слово. 

S07 [01:45:43]  : нос используется именно вере носогубников. 

S09 [01:45:48]  : Все, тогда это поправка. 

S06 [01:45:50]  : Это все-таки нечетко. Да-да-да. То есть, это имеет смысл. Вы посмотрите в Википедии, чем нечеткая логика отличается от вероятности. Там есть определенные... То есть, нужно по крайней мере понять, какие слова нужно произносить. То есть, если на слайде должна быть вероятностная логика, то так и пишите вероятность. Вот отпечатка просто. Да, чтобы там не попасть. Следующий вопрос появился от Андрея Яршова. Как в системе представлены знания о предметной области? Веса ЕНС, вероятность перехода в граф, алгоритм решения задач, прописанные в агентах или еще что-то? 

S07 [01:46:30]  : А предметная область, если мы имеем в виду узкие домены, то да, это агенты. То есть агенты являются по сути экспертными системами. Агент может быть реализован практически на любой технологии. Единственное, что в оболочке агента находится наша система обучения с предупреждением и система iDoc, она в оболочке находится, а внутри агента может быть реализация абсолютно любая. 

S06 [01:47:02]  : Вы воспроизвели архитектуру Бена Герцеля, которую он пытался реализовать с 1997 года, а потом 25 лет спустя от нее отказался. Тогда каждый агент может быть реализован на своей системе. Ну ладно, интересно. вопрос, да, еще уточнение от Андрея Иршова по поводу правил. Значит, под правилами подразумевается «если то». Да. Окей. Так, ну и у нас кончились вопросы и хотел высказаться Владимир Потапов. Владимир, пожалуйста. 

S03 [01:47:41]  : Коллеги, спасибо за очень интересный доклад. То есть это что-то похожее на когнитивную архитектуру в вашей интерпретации. С другой стороны, опять же в пользу подобных исследований скажу то, что примерно месяц назад было видео от OpenAI, где генеральный директор OpenAI сказал, что языковые модели себя исчерпали. новые прорывы возможны в новых архитектурах». Естественно, он не сказал, какие именно архитектуры, но я думаю, что поскольку GPT 3.5 и 4 они задумывали года три назад, реализовывали… если посмотреть историю, то 22-й год они тестировали только чат GPT, но 21-й они его реализовывали, в 20-м, ну, я думаю, что задумал. Поэтому то, что они сейчас делают и то, что там выкатят через пару лет, это какая-то новая архитектура, и она у них, скорее всего, уже в головах есть, просто мы про это не знаем. И чтобы идти в ногу со временем, естественно, нужно и пытаться сделать что-то большее, не пытаться угнаться за западными разработками, нужно, конечно, придумывать свои. Что из них выстрелит, на самом деле, не знает никто. Это в определенном смысле, не знаю, там, коммерческая, это на грани коммерческой разработки и научного исследования, и там, и там бывают фейлы. там и там бывают победы. но, что называется, нужно пробовать. с точки зрения именно самой архитектуры, вот мне кажется, что если вы делаете логический вывод на неких графах, фрактальных структурах, и у них есть какие-то точки, которые активируются, у которых есть веса и так далее. это тоже очень похоже на какую-то нейронную сеть, только какой-то структурированной. я думаю, что надо совмещать подходы. Какой-то контролируемый рост фрактальной нейросети по каким-то правилам. 

S07 [01:50:10]  : Может быть, это будет решение. Я отвечу на этот вопрос. Видите, направо это очень похоже на нейронную сеть, потому что вдохновлялся я именно теменной ассоциативной корой животных. Вот почему, кстати, проект называется Айдок. Потому что почти все, ну не все, конечно, многие алгоритмы, можно так сказать, многие алгоритмы базируются на исследованиях собак. То есть исследования Павлова и прочих. Ну не только собак, но и собаки. Вот на их исследовании это базируется, в том числе и исследование теменной ассоциативной коры, которая, по сути, и строит некую модель мира внутри мозга нашего. То есть можно сразу сказать, что вот эта вот часть, она основана на модели темной ассоциативной коры, Вот эта вот часть вдохновлена топическим принципом и латеральным торможением. Вот здесь вот тоже это вдохновено латеральным торможением. И по сути каждый из этих блоков вдохновлен некоторыми отдела мозга, но и исследования, почему я брал собак, и по ним, по данным, которые были получены на собаках, строил эту систему, потому что найти исследования собак очень легко. То есть собаки, мыши, крысы, легко найти исследования какие-то. Есть, конечно, такие, например, Латеральное торможение я делал по статьям изучения атомических ядер именно человека. Статьи про людей, даже про обезьян, их найти практически невозможно. про собак очень легко, поэтому и про это называется айдок, потому что это попытка создать некую модель мозга собаки. 

S03 [01:52:28]  : но это еще, наверное, пока не мозг человека. в мозге человека, видимо, есть какие-то дополнительные механизмы, которых нет у мозга собаки. конечно. И хотелось бы, если есть возможность, Захар, Виктор, можете контакты лично сбросить? Хотелось бы лично пообщаться. 

S07 [01:52:54]  : Нет, не смогу. Да, можете просто зайти в группу. 

S06 [01:53:00]  : Захар, вы можете вывести на слайд с вашими контактами, чтобы люди могли сфотографировать контакты. А во-вторых, в группе можно связаться в Телеграме. 

S07 [01:53:15]  : Да, я бы тоже хотел предложить. 

S05 [01:53:18]  : Можно, конечно, в Zoom бросить, но когда запись кончится, в Zoom пропадет. Поэтому вот либо сейчас фотографируете экран с контактами, либо в Телеграме. 

S07 [01:53:29]  : Я просто скажу, что из своих контактов-то и нет, мы их не указали вроде. 

S05 [01:53:32]  : Ну я предлагаю тогда просто в Телеграме. 

S07 [01:53:35]  : Да, конечно, в Телеграме есть и я, и Виктор. 

S06 [01:53:38]  : Сейчас уже в Телеграме лежит наша трансляция. 

S07 [01:53:40]  : В Телеграме есть и я, Виктор, Марат, в принципе все фоткино-участвователи есть в Телеграме. 

S06 [01:53:48]  : Да, VGI Rush, там можно встретиться. Вот коллеги, всем большое спасибо за доклад. Тема действительно очень дискуссионная. Тема будет обсуждаться у нас как раз 19-го числа. Будет семинар на английском языке по интерпретируемой обработке естественного языка. Там будет, скажем так, четыре доклада, как минимум четыре доклада будут на тему того, можно ли сделать что-то типа ЧАД ЖПТ или лучше ЧАД ЖПТ, но по-другому, с использованием системных технологий или комбинируя ЧАДЖИПТ с символами и технологиями. К сожалению, там не будет выступать Александр Балдачев, но Александр Балдачев будет рассказывать на русском языке свой опыт 29-го числа, то есть ровно через 10 дней после этого семинара. Поэтому, коллеги, всем большое спасибо за участие. Приходите на семинар по интерпретируемой работе естественного языка, приходите на наши следующие семинары. А в следующий четверг, напоминаю, Виктор Ковтуненко, точнее через четверг, Через две недели Виктор Картуненко будет рассказывать про термодинамический подход к моделированию общего искусственного интеллекта. Коллеги, всем еще раз большое спасибо. Захар, Виктор, спасибо за доклад. Всего доброго. До свидания. До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
