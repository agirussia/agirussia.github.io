## 4 мая 2023 - Библиотека ExplainitAll для интерпретируемого ИИ: нейросетей трансформер. Методы и кейсы - Виктор Носко (директор в Аватар Машина, член АЛРИИ, сооснователь FractalGPT) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/xASnDIt1J_8/hqdefault.jpg)](https://youtu.be/xASnDIt1J_8)

Суммаризация семинара:

Семинар посвящён теме интерпретируемого разговорного искусственного интеллекта. Виктор Носко подготовил доклад, который представляет собой разработку библиотеки Explained Tool для интерпретации работы ИИ. Особое внимание уделяется нейросетям Transformer и методам интерпретации, которые помогают объяснить работу генеративных нейросетей, включая GPT-Family.

В докладе описывается работа по созданию интерпретируемой системы, которая поможет объяснить генерацию трансформерами и их зависимости. Эта разработка направлена на то, чтобы сделать модель интерпретируемой для исследователей и конечных пользователей. В частности, цель состоит в том, чтобы понять, возможно ли применять конкретные модели для решения бизнес-задач в различных сферах, например в медицине или строительстве, а также проверить достоверность ответов в чат-ботах и других системах вопросно-ответного типа.

Для решения поставленных задач был получен грант фонда содействия инновациям под названием Код ИИ 2022 года. В ходе работы были рассмотрены конкурентные подходы и кейсы, которые показывают, как интерпретация работает на практике в контексте вопросно-ответных систем, аналогичных Google Search.

В семинаре были затронуты вопросы построения пользовательского интерфейса, который позволяет использовать интерпретацию для проверки адекватности ответов. Обсуждалась возможность встраивания интерпретации в систему аранжировщик. Разработчики библиотеки Explained Tool рассмотрели возможность использования нечетких правил для оценки обоснованности ответов и предложили инструменты для определения меры обоснованности ответа.

Кроме того, в семинаре были представлены примеры правил, которые используются для оценки важности кластеров и вероятности ответа. Приводились примеры работы с кластерами и центроидами, а также обсуждалась возможность использования знаний в будущем без генерации знаний внутри системы.

Семинар также включал обсуждение вопросов пользовательского интерфейса и возможности использования системы нечетких правил для борьбы с галлюцинациями в ответах на вопросы. В частности, была представлена схема системы нечетких правил, которая помогает интерпретировать уверенность в ответах на основе встречаемости сниппетов в ответе.











S03 [00:00:03]  : Коллеги, всем добрый вечер. Сегодня у нас на семинаре AGI in Russian или AGI по-русски снова в гостях Виктор Носко и он нам расскажет про свою и вместе с Захаром понимаешь работу по интерпретируемому разговорному искусственному интеллекту. Насколько я понимаю, если я ошибся, то Виктор, поправьте меня, пожалуйста, и вся кибервселенная ваша. 

S02 [00:00:29]  : Да, здравствуйте еще раз. Я сейчас выключу его экран. Ну, первое, что я хочу сказать, это то, что мы будем сегодня с Захаром делать доклад вдвоем, то есть сначала я расскажу, затем Захар переключится на часть, которая касается генеративных уже нейросеток, там отдельно расскажут, то есть там, в общем, отдельный мир, можно сказать. Тема, собственно, библиотека Explained Tool для интерпретируемого ИИ. Собственно, здесь мы коснемся конкретно нейросеток Transformer, посмотрим на те методы, на тот способ мышления, которым мы пытаемся решить эту проблему, учитывая то, как ее понимают исследователи во всем мире. Ну и посмотрим кейсы того, как это работает у нас уже в конкретной библиотеке, которая будет Open Source, будет она всем доступна. Ну, вообще, в чем заключается задача? Нужно объяснять, почему, собственно, генерация трансформеров такая и от чего она зависит. Но объяснять нужно всем. Нужно объяснять это исследователям, нужно объяснять это конечным юзерам, пользователям вот этих нашумевших нейросеток GPT-Family, такого большого сообщества, ChargePT, GPT-4 и прочее. И хочется понимать, на самом деле, можно ли применять конкретную какую-то модель для решения downstream задач, ну то есть конкретной какой-то бизнес-задачи в сфере медицины, в сфере строительства. Хочется понимать вообще, насколько нам Какая-нибудь вопросно-ответная система или чат-бот дает достоверный ответ. В принципе, проблема, как вы знаете, достаточно существенная, и поэтому мы выиграли грант фонда содействия инновациям, называется он код ИИ в 2022 году, и делаем вот эту библиотеку, которая призвана решить эту проблему. Мы пройдемся сейчас по... по конкурентам немножко. Посмотрим, как они это решают. Но там они решают не очень хорошо. Причем проблема in essence. Библиотеки текущие, они визуализируют attention. И это не является человекопонятным. Когда, наверное, многие видели в интернете, визуализацию attention смотрели объясняющие ролики. Вот смотреть на эти таблицы, когда какой-то токен зависит от какого-то другого токена, и когда модель генерировала текст, то при генерации этого токена она смотрела на какой-то другой, И что дальше? Вот мы увидели вероятность какой-то кондиционного генерации, но интерпретировать все-таки это достаточно тяжело. И, наверное, вы себя ловили на такой мысли, что когда вы смотрите на эту таблицу, вы как будто бы производите такие операции у себя в мозгу. Вы смотрите на несколько колонок и на несколько каких-то слов. И, в принципе, вы хотите собрать какую-то общую картину. То есть вы не смотрите на какое-то одно слово, вы пытаетесь понять, увидеть там какие-то важные слова, которые, скорее всего, являются нрами, какими-то специальными терминами, которые относятся к определенной отрасли. И вы посмотрели на несколько вот таких терминов и пытаетесь вместе примерно понять, как эти термины было ли внимание к этим терминам у генеративной сетки, когда она давала ответ. И вот это вот такое мысленное усилие, которое мы пытаемся все как исследователи делать, в принципе вот эта идея вот этого усилия, она и заложена в нашей библиотеке. То есть мы действительно делаем определенные агрегации. Сейчас посмотрим на них подробнее. Проблема следующая. Все понимают, что генерация опасная. контроля фактологии нет. На текущий момент ведь нет уже контроля фактологии за джептишными моделями. Могут появляться лишние тематики, сущности, которые вы, собственно, не запрашивали. Невозможно доверять качеству вопросных ответных систем. Хоть закрытые они, хоть открытые, но в открытых вообще достаточно большая, существенная проблема. которые открыто имеются в виду по Википедии, по всему интернету, которые отвечают, а не только по closed book, например, по закрытым, по книжкам имеется в виду. Еще одна проблема, что метрик качества оценки интерпретируемых моделей мы не встречали хороших. Здесь на скриншоте показана библиотека, которую, если вы загуглите, интерпретируемый ИИ. то для трансформеров вы найдете библиотеку Transformers Interpret. Ну вот здесь есть пример, что вот библиотека в кейсе, когда вам нужно проанализировать сентимент, то есть эмоциональную окраску, она вам подсвечивает зеленым или красным те слова, которые повлияли на то, что сентимент оказался негативным или позитивным. Ну здесь видно, что В принципе, есть какая-то градация, это уже хорошо, что есть какая-то градация в цветах. То есть более зеленое сильнее повлияло на то, что слово, которое является более зеленым, сильнее повлияло. Конечно же, здесь самая банальная мысль сразу же в голову приходит, это то, что слово вот все-таки хочется смотреть на целый кластер слов, то есть слово, какое-то слово, которое идет в связке, скорее всего оно в связке влияет, да, и мы все знаем, что такие кейсы, как negation, да, то есть когда не добавляется, оно тут же меняет полностью смысл. Мы хотели бы, чтобы не или какие-то еще конструкции более сложные, не только, но и прочие, различные обороты. мы бы хотели, чтобы вот это на самом деле подсвечилось, то есть целые кластеры. в общем, вот как мы поставили задачу research. мы хотим сделать следующее. мы хотим сделать методику интерпретированности больших трансформированных моделей. мы хотим Разработать методику оценки качества интерпретируемости в зависимости от параметров и архитектуры моделей, потому что трансформеров там много. У нас сейчас можно разные трансформеры подбружать в модель. И хотим для конкретно вопросных ответных систем, потому что они самые частые, самая частая возникает проблема здесь, чтобы они были с объяснимыми параметрами и метриками полноты. Пример. Вот какой, собственно, кейс. У нас есть какой-то вопрос, который вы задаете в какую-нибудь систему, допустим, медицинскую систему. Ну, медицинскую взяли для примера, потому что это особенно опасно. И я думаю, что всем будет здесь понятно однозначно, что именно здесь в первую очередь нужно библиотеку применять. Вот какое лекарство, какое-то название, то есть в жидком виде, допустим, он применяет для лечения болезни X. при условии того, что есть противопоказания у данного пациента, возраст такого-то и температура при этом такая. Мы видим уже здесь, что мы задали множество различных параметров, и вам генеративная модель дает какой-то ответ. Здесь ответ достаточно крутой дан. Предположим, что он действительно такой крутой дается, хотя мы знаем, что GPT-модели на самом деле такие хорошие ответы не дают, но предположим, давайте предположим, что она дала такой ответ. Что мы хотим в итоге получить в результате работы в библиотеке? Хотим получить метрику качества интерпретивности. Условие назовем SplineQ, Quality, уровень доверия ответу 80%, допустим, на основании учета источников И мы хотим получить интерпретацию, что сущности такие-то и такие-то встречаются с частотой такой-то в источниках таких-то. Также токены описания болезни и температуры являются определяющими при относительном сравнении с описаниями других способов лечения. ну вот хочется на самом деле нам получать что-то типа вот такой человекопонятной интерпретации набор комбинаций токенов тоже можно посмотреть таблица хорошо бы если бы еще и таблица выводилась Я здесь немножко сейчас пройдусь по тому, как мы изучали другие подходы, как другие компании. Вот здесь есть DeepMind, как другие компании. пытались подойти к проблему интерпретации. Здесь вот в статье описан подход с общением агента с самим собой с течением времени. И они там поставили такие различные требования, которые они назвали вот такими буквами КСТРЛ. В общем, суть подхода в том, что модель, в принципе, конечно, может разговаривать сама с собой, и здесь может решаться проблема курицы и яйца. Когда вы, если вы видели смешные ролики, когда две Алисы друг к другу разговаривают в ютубе, то там условно одна Алиса другую На самом деле оценивать не может, и разговор этот нельзя использовать для аугментации, для последующего обучения каких-либо нейросеток. Так вот, на самом деле, если вы поменяете как-то распределение одного из ботов, одной из алис, поменяете распределение, то, в принципе, тогда можно было бы давать интерпретацию с помощью вот такого разговора сам с собой. И если кто-то видел, то модель викона, которая обучена на… которые являются производной ламы, лама-модель, open-source лама, которая является аналогом chat-GPT, которая утекла из мета-AI. В общем, на ее базе была обучена другая модель, Vicuna. Если вы зайдете на сайт Vicuna и посмотрите, как авторы Vicuna сравнивают свою модель с другими, конечно же, им было лень сравнивать в лоб и прогонять То есть человеческое сравнение сайт-бай-сайт, то есть у вас есть одна задача какая-то, и вы сравниваете выдачу вашей модели прикуны с еще перечнем каким-то моделей. Например, этих моделей может быть десяток, которые уже вышли, каких-то аналогов. Конечно же, людям прочитать это все очень лениво и муторно. Вот. Что они сделали? Они сказали, что давайте будем использовать, у нас есть крутой GPT-4, как будто бы самая крутая модель, и она может оценивать. Вот. Идея ведь хорошая, правильно? То есть она решает, в принципе, проблему курицы яйца. И они так сделали. И GPT-4 действительно, они ставили ей задачу в виде промта, что посмотри на 2, на 2 генерации викуны и всех, ну, одной модели и всех остальных моделей, и скажи, какая генерация является более полной, более качественной, более крутой. И вот такое сравнение, казалось бы, одна модель оценивает другую, это какая-то чепуха, но это раньше так было. Сейчас уже выяснено, что действительно такая оценка действительно более крутой модели, которая несколько голов лучше, она допустима, и она нормально коррелирует с человеческой оценкой. ну вот такая вот идея. ну здесь вот они статье описали требования к объяснимости. конечно, она должна быть обоснованная, то есть она должна граундиться на какой-то определенный датасет, который есть у юзера, или на какие-то определенные описания кластеров. она должна быть гибкая, должна быть масштабируемая, но правдивая. понятно, она должна быть как-то верифицируема, что действительно она даёт правильную интерпретацию. В принципе, ведь у нас же может быть такая ситуация, когда у нас модель ошиблась, ну какая-то question answering модель ошиблась, но при этом и модель интерпретации тоже ведь может ошибиться. Ну тогда у нас получается ошибка на ошибку, тогда нам потребуется выстраивать вот такую типа иерархию модели, когда каждая следующая должна предыдущую проверять теоретически так делать можно но в общем сложно в разработке здесь вот давайте рассмотрим здесь другой один из подходов когда ну вот этот подход он в принципе похож на rlhf только он другой то есть он идейно похож на rlhf и здесь увидишь что в принципе Схема его немножко другая, но суть такая, что вы можете обучать GPT-модели не только на unsupervised, не только давая им огромные объемы текста, гигабайты, терабайты текста, как делают все компании большие, когда они обучают GPT-модели. вы можете добавлять туда структурированные данные. Вот в этой статье описано большое исследование, когда они давали различные структурированные данные, как будто бы немножко помогая гайде. помогая модели понимать, что конкретно находится в неструктурированном тексте рядом. Они там исследовали достаточно большой перечень различных кейсов. Они давали, допустим, заголовки, у вас есть там текст статьи, они дают заголовок этой статьи, потому что они напарсили его. Вот, они дают там суммаризацию, что конкретно в этой статье, конечно же, сделано там какими-то другими моделями. Почему я об этом говорю? Потому что идея так делать, она очень хорошая и правильная, и у них в статье описано, что действительно обучение GPT таким образом побеждает, ну, они победили в статье, говорят, что они по какому-то бенчмарку. победили устаревшую уже GPT-3, то есть меньшую модель получили по объему, и она победила GPT-3 по какому-то там бенчмарку, не помню, какой называется бенчмарк. Причем здесь интерпретируемость. Если мы потом сможем придумать алгоритм интерпретации, то этот алгоритм, как у нас в предыдущем слайде было, одно из требований grounding, мы на самом деле можем привязать наш алгоритм к вот этому дополнительному датасету, с помощью которого мы помогали обучать вот эту GPT. И здесь у нас возникает связь. Если наш алгоритм интерпретации говорит, что он смотрел на эти токены, на те слова, которые были в вот этом дополнительном датасете, уже структурированном, то это будет существенно облегчать и давать большую надежность самому вот этому алгоритму интерпретации. То есть на самом деле важно Также и то, как сами GPT-модели обучались, а не только. Важно то, насколько мы крутые как разработчики с точки зрения разработки библиотеки. по конкурирующим библиотекам, ну то есть как, они не конкурирующие, конечно, они просто то, на что мы смотрели, какие, собственно, есть сейчас библиотеки. Есть библиотека CAPTOM, здесь представлена уже наша переписанная функция из этой библиотеки. Ну, в общем, мы используем подход feature ablation. Ablation это когда мы заменяем токен на PAD, а после этого считаем полиметные разности между изначальным вектором и тем вектором, который получен после замены. Собственно, естественно понятно, что если разница между этими векторами большая, это значит, что те токены, которые мы заменили на пады, они имели большой вес, большое значение. Это, конечно, скорее всего, что какие-то нерры. Это, скорее всего, Какие-то важные слова, на которые стоит обращать внимание при оценке надежности ответов. Если векторы не поменялись, значит это были какие-то неважные. неважный токен. в общем здесь идея в принципе такая простая. есть еще одно решение, это snap для трансформеров. ну то же самое, очень сильно похоже на transformers intepret. и здесь проблема та же самая, подсвечивает красным-синим и делает какую-то определенную Градация, здесь видно, что возможно, что нужно нормализацию какую-то делать, потому что вам хочется на самом деле понимать, что вот эти цифры, которые стоят, 5 и 8, это много или мало, то есть кажется, что здесь нужно нормализовать, потому что у нас там минус есть, отрицательное значение, то есть в каком диапазоне. В обычном мире мы людям нормализуем, принято так делать в процентах. мы не поговорим 10%, типа 0,1. какой диапазон, на самом деле это важно. интерпретация эмбидеров. в общем, мы сейчас говорим все время про интерпретацию эмбидеров. Что сделали? Мы проанализировали модель из BERT, это популярная библиотека, с помощью Ablation узнали важность каждого слова в предложении. Здесь заметьте, что на скриншоте показаны несколько предложений, мы можем посчитать для всего предложения поэлементно. И в результате у нас есть возможность тестировать любую модель из BERT. Их там несколько. Это называется по-другому Global Average Pooling. Здесь представлен полный алгоритм модели интерпретации, то есть у нас есть какой-то определенный dataset. Мы даем юзеру возможность вычислить кластеры. Как это делать? По-разному можно делать с помощью Word2Vec и так далее. Мы подойдем на вход в текст. И у нас есть предположение, что нейросеть должна быть чувствительно какой-то смысловой оси, ну или можно называть это кластером. Мне нравится определение «смысловая ось», потому что Потому что это как будто бы есть какое-то у нее направление, и вокруг этой оси как будто бы толпятся точки, которые относятся к данному конкретному смыслу. Это, например, в основном это… Какая-то узкая терминология. То есть у нас есть лекарства, у нас есть внутри тех лекарств антибиотики и различные другие антологические подкатегории. Мы даем дьюзеру возможность сформировать кластер с помощью какого-нибудь алгоритма. Например, это Word2Vec или какой-нибудь другой. Далее, для каждого кластера считаем суммарную важность, насколько он нам важен для нашей университет. Важность можно посчитать в каптом плюс усредненное лифтвидовое состояние. По всей выборке посчитаем. и поймем насколько в среднем меняется вектор и соответственно можем понять вес какого-то конкретного смыслового кластера. в итоге мы можем сравнивать получение выхода с нейросети в двух вариантах, посчитать, в общем, эту лифт-клидовую метрику и сделать генерацию по правилам. То есть у нас есть какие-то определенные фичи, которые мы выдали в конце. ну что такое правило сейчас будет позже то есть мы на самом деле можем обрамлять эту информацию уже в правила которые созданы именно просто ну просто какие-то шаблоны допустим в какой-то текст делать простые подстановки даже это уже даже такой простой подход он уже лучше чем смотреть на какие-то таблицы Вот здесь мы сделали решение, которое позволяет быстрее осуществлять поиск пластера. Вообще, в чем проблема? Вот вы хотите, допустим, считать, у вас есть задача считать важность каких-то определенных Слов, ну вы понимаете, что все эти слова вы записать не можете. Вы как исследователь или вы как работник в медицинской сфере, вы хотите все антибиотики записать. Ну окей, то есть вам нужно какой-то решетч проводить, выгружать эти антибиотики из какой-нибудь системы, из википедии или еще что-нибудь в этом духе. Но часто это сделать трудно, и здесь вот на помощь приходит как раз вор ту век, там поиск достаточно медленный, можно его на самом деле с помощью фаиша скорить. Здесь показаны примеры, по-разному можно считать близость, и здесь вы видите, что разные наборы близких слов в зависимости от алгоритма. Даем там собаку, кошку, рыбу, и он нам подсказывает, что у нас дальше идет пес, котенок, горняшка и так далее. конечно, наверное, для сложных отраслей нужно такой подход, наверное, более мощный использовать. Теперь тест интерпретации. Пример работы. На вход подаем список кластеров, каждый задается списком слов. Здесь очень простой пример, но здесь для лекарства уже, допустим, видно, что мы въедем пенициллин, антибиотик, антидепрессанты. Метод оценивает чувствительность нейросети к этим смысловым осям. Мы можем собирать статистики. по кластерам, а не по конкретному слову. Вот здесь видно, что такой простой на скриншоте, такой простой есть, ну, в общем, можно сказать, что правило, да, что сеть такая-то, Руберт, она чувствительна к кластеру сущности, к животным, и при этом нечувствительна к кластеру лекарств. Ну, значит, ее целесообразно использовать в одной отрасли и в другой отрасли какой-то, в частности, про лекарства. Ну, не стоит ее спрашивать, потому что будет чепуху отвечать. Ну вот, сейчас передаю слово Захару, собственно, главному разработчику библиотеки. Он расскажет про генеративный подход. 

S04 [00:23:23]  : Хорошо. Вот мы в следующий слайд. Мы начали разрабатывать также еще систему оценки генеративных сетей для того, чтобы в частности решить проблему галлюцинации. И вот предлагаем такую схему интерпретации. У нас есть вопрос с генерированным ответом, то есть это вопрос с генеративной системой. И далее мы можем определить важность каждого токена при генерации ответа. Это в принципе дело библиотека INSEC. она довольно известна. После этого мы берем вот эти важности токена при генерации ответа, то есть у нас на каждый токен, когда мы генерируем, мы смотрим на остальные токены, чтобы правильно сгенерировать этот токен. Так как токены разбивают слова по кусочкам, мы дальше агрегируем это все по словам, также агрегируем важности и получаем пары слова «важность». К тому же различные библиотеки для интерпретации, как было показано, некоторые считают просто разности между между вектором и вектором, когда мы заменили одно слово на pad, либо другие библиотеки используют интерпретацию через attention. Есть и градиентные методы интерпретации и так далее. Они немного в разных шкалах дают интерпретацию. Чтобы как-то решить эту проблему, Также строим функцию распределения вот этих важностей, чтобы определить, насколько вероятно то, что случайная связь будет меньше, чем то значение, которое находится в этой ячейке. Об этом на следующем слайде будет. А здесь мы потом переходим в расчет график взаимодействия сенсоровых пластеров. То есть у нас есть некоторый сенсоровый пластер, как на предыдущем слайде было показано. И вот говорилось про более сложные кластеры, в частности, кластеры, состоящие из словосочетаний, либо какие-то еще более сложные кластеры. Сейчас у нас также в разработке есть открытая библиотека RoomNair. Вот одна из задач, которая выявляет такие более сложные кластеры. Далее у нас есть правило логического вывода. Это нечеткий логический вывод, который пользователи могут задать правило, что если мы при генерации какую-то тематику посмотрели, вот при генерации этого токена, не токена, этого кластера, посмотрели на другие кластеры с каким-то уровнем важности, то мы можем в целом принять этот ответ. Если мы на них вообще не смотрели или посмотрели на какие-то классы, на какие не надо смотреть, то мы этот ответ не должны принимать. Это гораздо один из способов борьбы с галлюцинациями. То есть, когда мы хотим, чтобы у нас модель, например, даты брала из какого-то тексты, например, с той же Википедии или еще откуда-то. Вот, например, есть такая... такой сейчас популярный проект, как Lama Index. Вот они дают сниппеты. И вот мы хотим, чтобы она не принимала дата с интерьера, вот на эти сниппеты. А потом мы видим, что вот здесь можно задать правило, что если дата была сгенерирована, но она не была взята ни из какого сниппета, то мы уже не сильно доверяем этой дате. То есть вот это можно считать уже галлюцинацией. То есть таким образом можно бороться с галлюцинациями. Давай следующий слайд. Вот здесь вот как раз таки показана наша работа по поиску функции распределения, так как Вообще библиотека INSEC дает значение важности все больше нуля. Мы тестировали функцию реле, так как она в положительной области, но также смотрели функцию гаусса и исследовали смеси. смесь распределения, она вот приведена внизу, тут вот мы берем смесь распределения до плотности вероятности, считаем через смесь, потом мы ее можем проинтегрировать и получить уже вот как раз-таки вероятность того, что у нас случайная связь будет меньше, чем то число, которое стоит в ячейке. здесь показано, что вот на этих графиках, что функция гаусса не подходит, там внизу есть внизу справа график qqplot, который ставит теоретические и реальные квантеры и если у нас это гауссовое распределение, то Данные должны быть распределены по линии в 45 градусов. Мы видим, что гауссовое распределение подходит. Также смотрели распределение релея. Пришли к выводу, что распределение трехкомпонентной гауссовой смеси дает наивучший пока результат. Экспериментировали с двухкомпонентной, с пятикомпонентной. 25 компонентов использовали. пришли к тому, что именно трехкомпонентная голосовая медь дает наилучший результат. Следующий слайд. Вот, в принципе, интерпретация здесь показана. До применения вот этой вот функции и после. До применения можно сказать, что он показывает доли, вот в долях показывает, насколько мы смотрели на какое слово при генерации следующего. То есть суммы по колонкам, они не строго равны единице, но они очень близки к единице. Здесь возникает проблема в том, что если у нас разные тексты, у нас будут эти числа разные, и если мы собираем некую статистику, то нам хотелось бы все-таки оперировать одинаковыми значениями важности, поэтому мы переходим именно вот к этим функциям распределения, и вот это на следующей картинке находится справа вот показано что у нас после получается так ну давай на следующий слайд также мы переделали саму билетик инсект потому у нее было две существенные проблемы во первых она восстанавливала довольно много всего лишнего и ломала в некотором плане environment, то есть библиотеки, которые были установлены до нее, она их перезаписывала, хотя у них не было необходимости. Мы выполнили, получается, анализ того, какие библиотеки нам нужны, а какие нам не нужно менять. И смогли сократить время установки с 300 секунд до 10. К тому же, если посмотреть на табличку, то она не работала с русским языком, так как в идее чеки она писала токены, а не слова. с русским языком она очень плохо работала, если там приблизить, то можно увидеть, что непонятно, что здесь вообще написано. Вот тоже исправили, догрузили другой токенизатор, не в класт, а получается другой токенизатор и получили нормальные слова на русском языке в ячейках. Саму библиотеку тоже выложили в открытый доступ. Ссылка тут приведена после наших модификаций. Так, ну и два следующих. Здесь можно посмотреть интерпретацию. То есть мы подгружаем модель. Вот у нас погружается от Сбербанка RootGBT-3small. После чего мы создаем эти вот кластеры, то есть по сути мы говорим, что у нас здесь кластеры животные, лекарства, болезни, аллергия. Потом у нас есть что-то вроде центроидов, то есть мы для животных создаем собаку, кошку, заяц и так далее. И сколько нам слов дополнить. И далее мы интерпретируем. Получается она дизотравка, чем лечить собаку, которая насморк, и вот ответы лечить ее антибиотиками. Вот мы интерпретируем, получается, выход этой сети и получаем, что когда она говорила про лекарства, она посмотрела, эта сеть посмотрела на кластер животных, это значение 0,56, и на кластер болезни 076. Дальше я опять передаю слово Виктору. 

S02 [00:33:37]  : Ну, да. Собственно, здесь вот показан интерфейс какой-то. Ну, это тестовый интерфейс. Мы хотим просто еще юзерам дать также помимо каких-то API еще возможность там просто кликать мышкой, собственно, подгружать различные трансформеры, выбирать их из выпадающего списка, изображать свой датасет, тестировать метрики. Сейчас у нас Rogue, PPL и вот наша метрика надежности. Работать должно локальное в облаке, и сама вот эта визуализация на Градио сделана. Но Градио, я думаю, что все знают, потому что ее популяризировал HugginFace, потому что на нем в основном на Градио все демонстрации сделаны, которые вы там заходите на Spaces, там эта бюджетика используется. В общем, такая фича для удобства. Здесь в принципе показаны какие-то демки, какие-то вопросы-ответы, когда нам нужно на самом деле понимать, на какие смысловые кластеры модель смотрит. И на самом деле хочется также понимать, на какие не должна смотреть при ответе. То есть, например, есть какая-то сложная сфера. Здесь пример с психологией, но есть сложная сфера, где невозможно все знать. что-то типа биологии или квантовой механики, и вы хотели бы задать такие кластеры, где вы знаете, что оттуда не могут браться какие-то определения, термины не могут браться, чтобы модель туда не смотрела. Вообще вы можете тогда это сделать, но вот это в разработке. То есть вот такая штука как бы контрастивная, по типу, немножечко похоже это на то, что вы в датасете даете датасет, который нужен, который хороший, правильный, и кейсы, когда как не нужно отвечать. То есть вот здесь идея похожа на это, что вам нужны как хорошие кейсы, примеры, так и отрицательные. Ну, здесь вот важность, я думаю, что нужно здесь объяснять, что для фарма важность большая, для производства, для науки, в принципе, тоже думаю, что это прям понятно. И галактика ведь была же закрыта, если кто-то помнит галактику, собственно, она была закрыта, убрана из демки, потому что она, собственно, давала наукообразный ответ, которые были бредовыми, и они, конечно же, были опасными. Вот, ну, как уже говорил, будет библиотека доступна open source, она будет бесплатно открытая, доступна, применяться может в огромном количестве отраслей. Вот, собственно, мы разработчики, Захар, я, Александр и Денис. Ну, немножко наших регалий, которые, возможно, что Сообщество AGI Russia, я думаю, знает о нас уже, здесь они перечислены кратко. Спасибо. 

S03 [00:36:37]  : Спасибо. Так, здесь вот есть несколько вопросов. По поводу, что такое смысловой кластер, Эдуард, вы удовлетворены ответом? или нужно еще пояснить по смысловому кластеру? Нет, не удовлетворен ответом, конечно, но если другого нету... Виктор, можете пояснить для Эдуарда или Захара, что значит смысловой кластер, может быть с примером? 

S04 [00:37:14]  : Лучше я поясню, потому что это понятие я предложил. Это, по сути, то же самое, что и НЭР, то есть именованные существа, но просто у НЭРов есть уже сложившиеся категории, то есть это персоны, это локации и организации и тому подобное. А смысловым кластером может быть что угодно. Почему изначально называли кластерами? Мы их изначально выделяли за счет кластеризации commins. Отсюда пошло название смысловый кластер. То есть брали вектора World2Vec и сверху кластеризации commins находили и пытались их интерпретировать. Но потом от этого отказались, потому что Там находилось очень часто не то, что нам нужно было в итоге, и мы начали задавать вот эти центроиды, которые вот если мы ищем медного талонов, то мы действительно получаем среднее значение этих векторов, которые мы задаем, и потом медного талонов находим ближайшие к ним и обратно их интерпретируем как слова, и потом эти слова находим в тексте. Это так было сделано. Сейчас, конечно, мы поняли, что нужно и другие, более сложные искать. И у нас есть сейчас библиотека RUNER. Там на данный момент опубликован подход, основанный на QA-моделях, что мы задаем вопросы и вытаскиваем некий NERV, который отвечает на этот вопрос. и мы хотим это еще тюнить, чтобы эта модель лучше вытаскивалась на базе геороберта моделей, но в будущем планируются другие подходы использовать, которые позволяют вытаскивать больше, чем одно слово, словосочетания или даже своего рода распределенное словосочетание, то есть часть здесь, потом 

S03 [00:39:09]  : дополнение часть там вот такой языкать ну то есть это вы вообще ответили по ходу на мой первый вопрос можете ли вы выявлять не только слова как указатели на важность, то есть выявлять важные слова, но в будущем вы планируете выявлять и фразы. 

S04 [00:39:33]  : Сейчас фразы выявляют. Проблема в том, что сейчас сеть не адаптированная под задачу НР вообще, поэтому Она нестабильно работает, в некоторых очень хорошо, в некоторых не очень. И вот у нас в планах дотюнить эту сеть, чтобы она стабильно работала. 

S03 [00:39:57]  : То есть сейчас вы фразы не выявляете в качестве важности, только слова? 

S04 [00:40:02]  : На данный момент нет, но исследования в этом направлении идут. 

S03 [00:40:07]  : Окей, тогда дальше по поводу смысловых кластеров. Тоже на понимание с одной стороны, а с другой стороны тут похваливарить по терминологии чуть-чуть. Смотрите, named entity extraction, да, это именованные сущности. именованные сущности действительно там имена, названия компании, географические названия, собственно, потому они именованные. А почему не использовать просто entity extraction? Почему просто не говорить, что вы извлекаете сущности? Зачем? То есть вы видите, почему ваш смысловой кластер нельзя просто называть сущностью? 

S04 [00:40:45]  : в целом можно, просто я говорю, что изначально вот первый алгоритм, который был, он именно на алгоритмах пластеризации работал, то есть использовался Каминс, использовался иерархическая пластеризация, ну там много разных алгоритмов пластеризации пробовали, там на базе нейронной сети, когда самообучающаяся этой сети, которая Но в итоге пришли к выводу, что лучше все-таки руками задавать, потому что они не всегда пересекаются с тем, что человек подразумевает. Пересечения не всегда есть, и поэтому лучше просто задать руками, чем вот так задавать. Но с другой стороны, задавать с помощью кластеризации может быть даже лучше, потому что Мы тогда можем вообще весь текст заменить на название кластеров и уменьшить вариативность текста, например, до сотни кластеров. Но пришли к выводу, что это не всегда хорошо работает, поэтому решили сделать руками. А название так и осталось. Вот поэтому называется кластерами. 

S03 [00:41:48]  : А дограмм вы не пробовали использовать? Нет. Мы просто использовали для подобной задачи адаграм, очень хорошо работал для разделения этих самых аммонимов. Если у нас есть одни и те же слова в разных контекстах, образующие разные смыслы, то была задача выявления, грубо говоря, разных ключей и разных кос. И как раз использовался адаграм для этого. 

S04 [00:42:16]  : А можете скинуть, как называется? 

S03 [00:42:19]  : Сейчас я задам вопрос, пока будете отвечать по гуглу, найду. Так, сейчас я ищу вопрос был. С мысловым пластером, надеюсь, разобрались. Если кому-то не устроило, можно заподнять руку, задать вопрос. Да, вот по поводу галлюцинации. Смотрите, два вопроса по поводу галлюцинации. Во-первых, Как ваша технология борьбы с галлюцинациями может помочь с галлюцинациями в ответ на вопрос про роль танков в армии Александра Македонского? Вроде и танки есть, и македонские есть, а вместе они не встречаются. Вы эту проблему можете решить? 

S04 [00:43:04]  : Да. Эта проблема решается, если вы посмотрите на презентацию на 14 слайд, там есть схема и в ней есть система нечетких правил. В нее можно внести то, что если у нас в каком-то сниппете встречается и то, и то, то есть через «и», то мы говорим, что у нас уверенность в этом высокая. И потом через метацентроль, вот эту уверенность интерпретировать уже в некое число, и эти числа можно потом аранжировать. То есть сеть же генерирует не один ответ, то есть она может генерировать 2, 3, 10 ответов, и вот это число использовать для аранжирования. и можно вот как раз таки на подобных кейсах вот почему вот мы взялись именно за кластеры или минованные сущности вот потому что Каждый конкретный пример прописывать получится, это очень-очень много и бессмысленно, но прописать там взаимодействие трех-четырех-шести сущностей кажется вполне реальной задачей. 

S03 [00:44:18]  : То есть, вы ставите дополнительные фильтры, когда вы получаете набор ответов с какой-то температурой, вы включаете дополнительные фильтры и еще аранжируете их по релевантности с точки зрения вот этих вот нечетких правил на основе выявленных смысловых кластеров. А если релевантности не дотягивает для того, чтобы отобрать один ответ по порогу, вы увеличиваете температуру и так далее. 

S04 [00:44:46]  : Либо так, либо можно вообще сказать, что ответа нет. Система не знает. 

S03 [00:44:50]  : но то, что система не знает ответа, то у вас уже там какой-то за хард кожаная заготовка. ну если не прошла порог. 

S04 [00:44:58]  : сделала 10 вариантов ответа, ни один не прошел порог. 

S03 [00:45:00]  : окей, понятно. так, по гранту вы отчитались успешно. 

S02 [00:45:04]  : а сейчас разработка же в процессе. то есть у нас по полгода. 

S03 [00:45:11]  : ну хоть какой-то этап уже закрыли. 

S02 [00:45:14]  : А он сейчас в процессе. 

S03 [00:45:16]  : Поэтапно, да, поэтапно. 

S02 [00:45:19]  : То есть у нас сейчас в процессе первый этап, а потом будет полгода еще один этап, где мы будем дорабатывать. 

S03 [00:45:27]  : По первому этапу еще не отчитались? 

S02 [00:45:30]  : Срок не пришел, но скоро. 

S03 [00:45:32]  : Ну ладно, тогда успехов. Так, ну и вопрос от Эдуарда Хачукаева. Претендует ли ваша система на то, что мыслит? Ваше определение мыслит? 

S04 [00:45:43]  : Мыслит человек, а не система. Человек, который писал правила. Вот он решил, что если при генерации такого-то токена мы посмотрели на такие токены, даже не токены, а кластеры, потому что кластеры это может быть даже несколько слов. При генерации такого кластера мы посмотрели на такие, то значит, что мы можем доверять Вот этому ответу. Если мы не обращались, например, к какому-то источнику, то есть у нас тот же лама индекс нашла там 10 сников, а мы ни к одному не обратились вообще. Ну, как бы это уже какая-то отсебятина, но то же самое, что и в научной литературе, если вы написали статью и не сослались на один источник, то ее не стоит и учитывать. То же самое и здесь. Вот, смысл такой. 

S03 [00:46:31]  : Понятно, спасибо. Коллеги, есть ещё вопросы? 

S00 [00:46:40]  : Здравствуйте. 

S03 [00:46:41]  : Да, Елизавета, пожалуйста. 

S00 [00:46:43]  : Я всё-таки не понял насчёт ластеров и то, что вы пока не планируете работу с фразами. Если вы не планируете, то разве можно добиться хороших результатов, если вообще не планируется или нет планов или нет подходов к работе с фразами? Планируем, планируем, да. 

S04 [00:47:12]  : Я же говорил, что у нас сейчас есть даже открытие библиотеки, целью которой находить фразу. Это наша цель – работать с фразами. Я говорю, что у нас есть, например, открытая библиотека RUNER. Сейчас там один подход есть, он просто как сам подход написан, но сами модели мы еще не учили. Используем существующие модели, но понятно, что они под эту задачу не обучены, поэтому работают нестабильно. Мы, кажется, хотим обучать моделей, чтобы работать сразу. 

S00 [00:47:52]  : Можно как-то уже предварительно сказать, на чем она будет построена, в чем замысел работы с фразами? 

S04 [00:48:03]  : Ну, как я говорю, то, что сейчас опубликовано, это подход, который мы более-менее протестировали, это на базе Роберта, Вот. Работа идет. То есть, ну, бертер объекта. То есть, есть вопросы относительно системы, которые работают следующим образом. Они каждому токену ставят соответствие, вероятность того, что это является началом ответа в тексте. И каждому токену ставят соответствие и вероятность того, что это является окончанием. И способен выделять довольно большие фразы из текста, вытаскивать. Это так называемые инстракшн... инстракшн, которые... а, экстракшн, вот, экстракшн QA системы. То есть они вытаскивают какое-то отчасти в ответ на вопрос. Ее можно переориентировать так, чтобы она вытаскивала не ответ на вопрос, а вытаскивала получаются новые классы. Причем, так как эта система работает так, что разные вопросы, разные контексты, она из них вытаскивает, то можно сделать так, что перестройка под новые эти кластеры будет происходить очень быстро. То есть достаточно будет так же написать или несколько примеров, и вот как у нас показано в демонстрации, пишется несколько примеров, ну либо жутпромт, и на базе этого вытаскивается, ну уже не по одному слову, а фразы вытаскиваются, и потом уже по ним считается их важность и так далее. 

S03 [00:49:49]  : Другие еще вопросы? Я скинул ссылки в группу по нашему проекту, который мы делали Singularity.net, там в частности на одном из этапов как раз используется кластеризация по одограмму. У нас две кластеризации. Первая кластеризация была именно для того, чтобы расщепить исходный поток токенов на аммонимы, грубо говоря, если у нас в разных контекстах используется слово ключ. то у нас появлялся ключ 1 и ключ 2, это были разные слова, и в одних контекстах был ключ 1 и ключ 2. А вторая кластеризация у нас была в конце, когда мы уже пытаемся выявлять то, что вы называете смысловые кластеры, но в линграммере это называется lexical entities. что тоже не совсем корректно, потому что это не обязательно лексические, это могут быть смысловые сущности. Но там у нас была вот такая проблема, значит я почему-то говорю, потому что интересно, как вы его решаете. Там получается такая история, что в общем случае с одними и теми же параметрами кластеризации, гиперпараметры, если мы возьмем, получается так, что у нас очень трудно на каком-то реальном корпусе получить так, что два разных слова, допустим, у нас есть четыре смысла, Два из которых попарно близки друг к другу. Допустим, есть кошка и собака и есть стул и стол. два смысловых кластера – кошка, собака, стул и стол. Четыре всего. И вот когда мы начинаем их кластеризовать, все время получается такая фигня, что часто, не все время, но это стандартная вещь, что либо у нас кошка и собака объединяются в один кластер, а стул и стол получаются разными. Либо если мы пытаемся разодрать кошку и собаку, то у нас стул и стол, кошка и собака разделились, а стул и стол разделяются на все возможные стулья и столы. То есть появляется несколько разных столов и несколько разных стульев. И к чему мы пришли, что на самом деле пытаться вообще подобрать какие-то универсальные параметры кластеризации не получится. И в общем случае все, что модель кластеризации единственная, которая может быть, это может быть некоторое дерево. где разделение идет только на ветвях дерева, причем в разных контекстах мы можем оперировать на разных уровнях дерева. То есть, грубо говоря, отделять столы от стульев мы отделяем на высоте 5 метров от уровня пола. А кошку от собаки мы разделяем на уровнях одного метра от уровня пола. Ветви деревьев разные, соответственно, мы в разных ветвях по-разному работаем. Работаем с разными порогами для того, чтобы разделять различные сущности. Но какую-то унифицированную систему кластеризации на просто плоское пространство кластеров не получается. Вы как-то с таким сталкивались? Что-то с этим делали? 

S04 [00:53:09]  : Я же про это и говорю, что мы с этой проблемой столкнулись, поэтому и перешли от того, чтобы искать кластеры автоматически, к тому, что человек задает некий центроид. То есть центроид — это, по сути, центральный вектор. Мы его как получаем? Человек задает просто... У нас есть два подхода, на самом деле. Они были показаны, там вот Виктор показывал их. Есть два подхода. Первый подход — это человек задает, скажем, три-четыре слова, ну или больше, мы вычисляем средние, и которые близко к этому среднему, набираем там топ-к слов. Это вот первый подход. Это, по сути, метод эталона. Второй подход, он был сделан на методе движения соседа, что мы говорим, что у нас есть, например, четыре этих слова, каждый из них является самостоятельным центроидом, центром И мы каждому из них подбираем, ну то есть смотрим минимальную близость каждому из них. То есть насколько они близки. Расстояние, да, минимальное. Но этот подход, он оказался хуже, ну не хуже, он оказался очень медленным. Поэтому мы применили Faiz, который делает то же самое, но в разы быстрее. 

S03 [00:54:27]  : А человек задает, вот как процесс этот происходит на практике? То есть вы антологию какую-то строите? 

S04 [00:54:39]  : Виктор, можешь показать слайд там, где хоть один, хоть другой пример работы? Нет, там мы пока задаем через перечисление похожих слов. Например, если мы хотим задать животное, мы перечислим там. 

S03 [00:54:55]  : Кошка, собака. Я имею ввиду с практической точки зрения. Практический кейс или юзер стори, что называется. В каком месте происходит задание? 

S04 [00:55:09]  : Открой интерпретацию. 

S03 [00:55:11]  : Мы это рассматриваем в контексте вопрос-ответной системы, правильно? Мы пытаемся рассматривать систему как вопрос-ответную систему, альтернативу Google Search, правильно я понимаю? 

S04 [00:55:22]  : Ну по сути да, это вопрос оценной системы в основном. 

S03 [00:55:26]  : Да, и вот в этой ситуации человек хочет узнать, были ли танки в армии Александра Македонского. Сколько было танков в армии Александра Македонского, к примеру. В каком месте здесь слова задаются? 

S04 [00:55:40]  : Можешь промотать? Сейчас был такой слайд. 

S03 [00:55:44]  : Ну окей. Сколько колесниц было в армии Александра Македонского? 18 слайд. 

S04 [00:55:48]  : Можешь открыть? Ну вот здесь получается, смотрите. Вначале у нас создается саунд интерпретатор, потом мы загружаем вот эти вот описания кластеров, как я уже говорил. И потом мы вопрос пишем и пишем, вообще это даже не вопрос, это промпт по сути, потому что здесь есть вопрос, но слово ответ, и дальше мы пишем, что сеть ответила. И передаем сюда также эти кластеры. И мы в итоге получаем, на какую часть промпта смотрела при ответе. то есть и какой кластер был в этой части фронта. Вот так это работает. И если у нас есть, скажем, найденные сниппеты, можно сказать, что если мы смотрели на этот сниппет, там был кластер боевая техника, танки и так далее. то и там же было про Александра Македонского, то, скорее всего, танки там были. Если того не было, то, значит, ну и танков там не было. То есть вот так и оно работает. То есть вот Prompt, в принципе, пишется все, что мы передаем в генеративную сеть для получения ответа. А потом у нас там второй параметр, аргумент функции, это то, что сеть ответила. И вот мы смотрим, насколько оно соответствует. То есть, если мы говорим про какие-то системы типа Lama Index, то мы же перейдем на Snippet и вводим же Prompt и можем посмотреть, а было ли это вообще в Snippet. То есть, где оно было и это ли было. И потом посмотрите, что вот оно нашлось в ответе. Либо если в ответе что-то есть, чего там не было, а это что-то является важным, а как мы поймем, что это что-то является важным? Ну, то есть мы помечены как кластер, который нас интересует. То значит, что это, скорее всего, галлюцинация, раз не было. 

S03 [00:58:00]  : Вопрос. Это пользовательский интерфейс? То, что вы показываете, это прототип пользовательского интерфейса? 

S04 [00:58:07]  : Да, это пример, как эта юридика использовалась. 

S03 [00:58:13]  : Я правильно понимаю тогда, что это пользовательский интерфейс там не для любителей котиков или пива, а если человек реально что-то хочет там узнать серьезное и получает ответ, он хочет убедиться в том, что этот ответ адекватный, вот тогда 

S04 [00:58:27]  : Это можно встроить, я говорю, это можно встроить, например, в аранжировщик. У нас с Виктором тоже выходила статья в аранжировщик, мы смотрели именно эмбендинги, то есть мы через классификацию решаем довольно много можно рассказать, но идея в том, что мы делали классификацию, а перед этим использовали эмбендинг, получали с вертичной сети. Но там же можно использовать не только, что оно по смыслу совпадает, но также можно использовать, что наша система нечетких правил считает, что этот ответ является обоснованным. Ну и насколько он является обоснованным. То есть вот когда мы делаем дефазификацию на базе цифров, это, по-моему, нам возвращает это значение. которая, по сути, можно считать градацией обоснованности ответа. Ну, не градациями, а мерой обоснованности ответа. То есть можно это так интерпретировать. Мы можем получить, что ответ обоснован на 10% или ответ обоснован на 90%. И если у нас есть, например, ответ обоснован на 10% или ответ обоснован на 90%, то мы выберем ответ обоснован на 90%. А если у нас есть ответ обоснован на 10% и ответ обоснован на 20%, но мы вообще не должны ничего убирать. То есть вот такую задачу помогает решать. 

S02 [00:59:50]  : В общем, тут можно сказать по поводу танка, что при некорректном вопросе, условно, то есть при троллинг вопросе, действительно может смотреть на кластер оружия, но там танков не будет, соответственно, не посмотрит на танк. Соответственно, мы можем сказать, что Число, которое будет выдано в ответе, нельзя ему доверять, потому что не смотрело, не было танков, в общем. 

S03 [01:00:19]  : Но это же не обязательно троллинг, кстати, вопрос. Вот сегодня у нас там была же дискуссия про, являются ли они питающими или нет. То есть, нормальный вопрос, да? 

S02 [01:00:28]  : Тут вопрос, да, здесь большой спектр вот к нам обращается, по вопросно-ответным системам. В основном, действительно, тут, конечно, не троллинг, здесь другая сфера, это когда юзеры не разбираются в теме, когда они спрашивают своим определенным жаргоном по тематике, в которой они не знают внутреннего, в общем, не знают распределения терминологии, этой терминологии, по которой они спрашивают. Я думаю, что кто пользовался какими-то госуслугами, медицинскими системами, с этим и сталкивались. И здесь, конечно же, стоит задача приведения. То есть по-разному можно решать. Либо вы должны привести вопрос юзера к канонической форме, то есть к профессиональной форме, как профессиональный врач должен спрашивать этот вопрос. Я не знаю, как это произойдет. Я не знаю, как это произойдет. Я не знаю, как это произойдет. Должен понимать, он понимает, что он не знает терминологии, наверняка это многие понимают, но он тогда должен знать, что условно он правильно вопрос задал по выдаче из этой библиотеки. Если достоверность высокая, то значит он типа правильно задал вопрос, значит он угадал с определениями в нем. Если низкая, то тогда не угадал, то есть нужно перефразировать или еще к специалисту. Обратиться, в общем, для неспециалистов в любых сферах тоже полезно, либо если ее встроить в какой-нибудь интерфейс, интерпрайс, поликлиники и прочее. 

S03 [01:02:11]  : А поясните, вот вы про нечеткие правила сказали. Вот нечеткие правила, они откуда берутся? 

S04 [01:02:18]  : Их пишет пользователь. Ну не пользователь, а разработчик. 

S03 [01:02:22]  : Вот, вот. То есть тогда я правильно понимаю, что по сути разработчик должен по сути создать некоторую нечеткую онтологию, где ребрам онтологических отношений соответствуют некоторые вероятности? И, собственно, этот антологический каркас на основе нещеткой вероятности логики используется как тот скелет, относительно которого валидируются ответы. 

S04 [01:02:56]  : В принципе, да, но мы довольно сильно упростили сейчас жизни разработчикам, которые это будут использовать. в том плане, что у нас получаются градации, они автоматически считаются, и достаточно просто написать, что если такое-то правило... такой-то кластер высокой степени уверенности, такой-то низкой. 

S03 [01:03:22]  : А можете привести пример правила? У вас был где-то слайд с правилами? У нас не было, потому что это сейчас еще в разработке. А тогда можете рассказать, пояснить? Приведите пример какого-нибудь правила. 

S04 [01:03:37]  : Сейчас я открою. У меня есть эти правила. мы можем сказать, что, например, если не учитывать аллергические реакции, если не учитывать аллергические реакции, не учитывать породу, и не учитывает болезни, то этой системе нельзя доверять. А если она учитывает это все, то ей нужно доверять. Вот такие правила. 

S03 [01:04:18]  : Я правильно понимаю, что правило выглядит примерно так. Если важность трех кластеров низкая, то вероятность ответа тоже низкая, правильно? 

S04 [01:04:31]  : Это пример правила. 

S03 [01:04:33]  : Пример, хорошо. А как вы идентифицируете каждый из этих кластеров? 

S04 [01:04:40]  : Это просто перечисление слов, то есть не фраз, а именно слов. 

S03 [01:04:41]  : Каждый кластер характеризуется некоторым распределением слов, правильно? да. вот, а тогда следующий вопрос вот здесь задают, два вопроса задают Эдуард Хачикаев. во-первых, что такое смысловая ось? я правильно понимаю, что под смысловой осью вы подразумеваете просто центроид кластера по сути? или это что-то другое? 

S04 [01:05:12]  : в принципе да. 

S02 [01:05:13]  : что-то главное, что является наиболее типичным для этого кластера. 

S03 [01:05:25]  : Хорошо, и второй вопрос, раз уж вы заговорили про правила, можно ли сказать, что ваша система способна оперировать знаниями? Или нет, или сейчас нет, но в будущем вы к этому идете? 

S04 [01:05:40]  : Мы к этому идем, да, но знания, например, если сравнивать какие вот сейчас мы работаем, то знания они не генерируются внутри системы, они закладываются просто пользователям и все. То есть там нет никакой генерации знаний, нет никакой самостоятельности. 

S03 [01:05:59]  : А вы видите какую-то перспективу того, что система будет эти знания выявлять в результате обучения без учителя? 

S04 [01:06:07]  : Ну, пока такой задачи не ставили для этой системы. Вот, например, портал GPT, да, Там есть модуль, который выявляет эти знания. Ну, по-моему, они более сложные. 

S02 [01:06:24]  : Мне показалось, Антон, когда вы приводили пример со столом, окошкой, да, вот эти четыре объекта назвали. Я сейчас попробую предположить, может быть, я не прав, как я понял, например, когда вы стали его говорить. На самом деле, вы же рассматривали вот на самом деле обучаемый На самом деле, кошка и стул – это очень близкие вещи, потому что кошка прыгает со стула все время, и в интернете можно много найти кейсов. таких предложений. 

S03 [01:06:58]  : Здесь тоже тонкий момент, что близость бывает разная. Близость бывает текстуальная. А тут казуальная. 

S02 [01:07:07]  : Здесь казуальная близость. И вот когда Эдуард спрашивает про вот эти знания, то есть на самом деле здесь же возникают такие цепочки или графы с какими-то циклами, Казуальности, и вы видели, да, что ценятся сейчас те анализаторы картинок, которые описывают внутри картинки действия, а не только сами эти объекты. А еще связи между этими объектами, что человек там бросает мячик, кошка куда-то прыгает. Конечно, здесь можно сказать сейчас, что а у вас только слова. Окей, но на самом деле мы даем возможность юзеру, мы это обсуждаем, что на самом деле желательно конечно юзеру давать большую свободу при определении вот этого кластера, и он бы мог на самом деле обучить какую-нибудь нейросетку на причинно-следственную связь. И таким образом задавать кластеры не только словами, потому что действительно связи между этими словами он в кластере на текущий момент не может задать. Он задает плоский список этих слов. Здесь множество. Хотелось бы ветвление, хотелось бы какую-то антологию задавать, казуальность какую-то задавать для разных сфер. Пока что этого нет, но мы думаем в эту сторону. Здесь же есть оборотная сторона того, что туториал тогда для юзера довольно-таки сильно усложняется. вот мы как бы думаем, не слишком ли сложно, а будет людям это делать, не наошибаются ли они вот в этом ключе. 

S00 [01:08:43]  : можно здесь как раз вопрос, тоже то, что Антон спрашивал, я вот насчет уточнял, много раз Захар говорил. как-то происходит вот этот режим откладки или что все-таки еще тоже мне непонятно у вас как вот наверно есть концепт вообще системы как концепт общения системы с пользователем то пока получается, что это не просто диалоговая система, как сейчас мы имеем в GPT, просто вопрос задал и ответил. Получается, что пользователь еще должен владеть вот этими кластерами, весами, что-то настраивать. И вот сам концепт этой системы, как он у нас построен, это получается не просто диалоговая система, а какой-то постоянно находится в режиме откладки и обучения? 

S04 [01:09:40]  : но эти кластеры и прочее задает не пользователь, а разработчик это просто получается для пользы с точки зрения пользователя, как человека, который использует систему Потому что мы еще разделяем понятие пользователя, человек, который использует систему, и человек, который использует нашу библиотеку для создания подобных систем. Это разные понятия. И если мы говорим про человека, который использует систему, то у нас что получается? У нас получается так, что он видит обычную диалоговую систему, которая просто обладает более более низким уровнем галлюцинации, и когда не знает ответ, она может сказать, что она не знает ответа. Вот что видит пользователь. А вот пользователь нашей библиотеки, который создает эту систему, он программирует ее этими правилами, чтобы эта система могла определять, знает ли она ответ, не знает ли она ответ. и какой где-то лучше. получается так? 

S00 [01:10:48]  : пока получается, что у вас как бы… я лично не просматриваю способы… результата выхода к самостоятельной, чтобы диалоговая система уже работала без отладчика. У вас получается, что постоянное необходимое присутствие вот этого разработчика-отладчика, чтобы он выявлял все эти троллик-не троллик, но сложные вопросы, конфликты вот эти, веса расставлял, то есть пока личнее не просматривается способ, чтобы система сделала это сама. 

S04 [01:11:31]  : Да, вот например разработчики, которые пишут систему, ну какой-то строитель, для строительного бизнеса, либо для какого-то там поликлиники, еще для чего-то. он может заранее прописать правила, что если вам дается рекомендация, не посмотрев на какие-то кластеры, то значит этой рекомендации нельзя верить. То есть нельзя какую-то рекомендацию давать, не посмотрев на такой кластер, на такой кластер, на такой кластер. Вот это человек, который занимается разработкой, который знает свою вот свой, как бы, домен, вот он понимает, что для того, чтобы грамотно ответить, нужно посмотреть вот на эти кластеры. Также контроль фактологии вот из тех же сниппетов должен быть. Он это все один раз запрограммировал. Ну, конечно, понятно, что в будущем будут какие-то ошибки иногда оплавживать, но это не постоянно. Но оплавка он запрограммировал, и дальше эта система начинает общаться с пользователем, просто аранжируя ответы. по вот этим правилам. Так как правила нечёткие, они дают не просто один ноль, они дают некоторое число, и поэтому число нужно аранжировать. К тому же вот я сейчас прикрепил в чатов правил, как у нас сейчас идёт работа с фразами, вот на базе библиотеки Runer. Опять-таки повторюсь, почему мы это не вставляли сюда, потому что Она нестабильна, работая за счет того, что модель не обучена. То есть мы брали, даже приведено на скриншоте, приведено, какую модель мы используем. Если обучить модель по нашей задаче, то, конечно, результат будет стабильным. Но пока еще не обучили, как обучим, будет более стабильный результат. То есть пример работы с фразами тоже привел, можете посмотреть. 

S00 [01:13:30]  : Я очень сомневаюсь, что таким способом можно получить систему более привлекательную для пользователей, чем сейчас имеется. В чем у вас преимущество, в чем вы обещаете? результаты и возможности более привлекательны, чем GPT. 

S04 [01:13:58]  : Тем, что мы используем такой подход, мы сможем сказать, когда модель не знает. Но вот GPT очень часто, когда не знает, оно начинает брать, получается. а здесь, когда он не знает, он может сказать, что он не знает. К тому же оно может генерировать несколько вариантов ответа и выбрать тот вариант ответа, который будет наиболее обоснованным. А наиболее обоснованным это как раз-таки то число, которое выдаст система четких правил. На данном этапе в МОНДА не используют. 

S00 [01:14:37]  : Получается, вы предлагаете пользователю неестественным образом оперировать этими числами, весами, какую-то таблицу с собой носить, какие-то правила помнить. А у GPT, если он даже соврет, то чисто обычным в диалоговой системе можно уточнить, дать уточнение, сказать простыми словами, что это неправильно, выделить ошибку. ГПТ она согласится с этим, найдет ошибку и в итоге получается, что ее сама же исправит. Происходит естественным образом. У вас как диалог происходит совершенно неестественным образом. Я сомневаюсь, что это как бы эргономично и удобно. 

S04 [01:15:35]  : Пользователь вообще не будет видеть никаких таблиц, ничего? Вот эти таблицы строятся автоматически тем методом, про который мы докладывались. Мы построили таблицу, мы знаем все эти уровни важности. Потом мы применяем правила, но правила не мы сами считаем на бумажке, они же у нас разработчикам вынесены, это же автоматический расчет. Например, алгоритм Авдали. Он же автоматически посчитает это все, и выдастся после декодификации одно число, которое скажет, мы принимаем этот ответ от LLM или не принимаем. То есть, если мы его принимаем, то хорошо, мы считаем, что LLM ответила. Если мы не принимаем, то мы считаем, что LLM не ответила. Если у нас есть три варианта ответа от LLM, и каждого она поставила число, то мы выбираем тот, у которого это число больше. Но это все происходит автоматически. Пользователь просто написал вопрос, получил ответ или получил, что система не знает ответа. И все. 

S02 [01:16:51]  : Но тут на самом деле можно добавить, что мне кажется, что как будто бы вы сравниваете две разные системы. Вы же сравниваете условно ChargePT как конечный продукт, и нашу библиотеку тоже как конечный продукт. А назначение этих двух продуктов супер разное. многоцелевая система, которая там помогает юзерам и прочее. Наша система имеет узкое направление, и она как является, как можно сказать, в каком-то смысле, как плагин дополнительный. Вот у ChargePT вышли плагины. Можно сказать, что наша система является плагином, которое уменьшает галлюцинации. Если бы какие-то разработчики, мы или кто-то другой, сделали для браузера встроили бы этот плагин для какой-то отдельной отрасли, разработчик поставлен на задачи начальства, сделает для медицины так, чтобы нормально отвечала. Он сделал этот плагин, вы его поставили из репозитория для браузера, и теперь заходите на медицинские сайты или книжки хотите анализировать и прочее, и вы как конечный юзер опираетесь уже на экспертность того разработчика, который сделал этот плагин, и он, этот разработчик, уже там прописывал вот эти кластеры. А этот разработчик, конечно, ему нужно быть специалистом в этом домене, собственно. Иначе он там, конечно, не специалист. в сложной сфере не сможет прописать правильно эти кластеры. Конечно, вы опираетесь, как и в любых продуктах сложных, на разработчиков, на то, насколько у них прямые руки, если так честно говорить. В принципе, как с любой нейросеткой. Потому что другой же кейс у вашей нейросетки хорошо отвечает тогда, когда она обучена на этот домен. Значит, те люди, которые разрабатывали, которые обучали эту нейросеть, они ведь брали какой-то датасет для граундинга, а у нас было в начале презентации про граундинг, то есть мы же опираемся, мы же учили нейросетку на определенном датасете. Окей, тогда этот датасет каким-то образом сейчас, может быть, рано говорить каким, но можно преобразовать в кластеры, и тогда граундится на них, действительно ли нейросеть отвечает в той стилистике с употреблением тех терминов, которые были в этом датасете. Если нет, конечно, библиотека покажет, что не стоит доверять этому ответу. 

S03 [01:19:17]  : Виктор, здесь пара вопросов от Юрия Бабурова еще. А почему нельзя просто попросить ЭЛМ выбрать темы ответа? Эти кластеры – это же просто темы. Аналогично можно просить ЭЛМ выбрать часть ответа, которая относится к теме «Животное» и так далее. 

S02 [01:19:31]  : Ну, я, может быть, частично отвечу, но, наверное, здесь может Захар лучше ответить. Это же то же самое, как Ильгизар сказал, что можно попросить нейросети исправить ошибку. Здесь же нет никогда гарантии. То есть, если одна система в которой заложено природно ошибки. Такой пример приведу, условно это как разговор с таким глупым человеком, или давайте со студентом, который недоучил предмет, и вы с ним разговариваете и говорите, он сдает экзамен, вы говорите неправильно, неправильно, а он все пытается угадать, как в том анекдоте, что вот если бы там у такого-то там животного была шерсть, то это была бы кошка. И про эту кошку начинают рассказывать. То есть, на самом деле, часто HRGPT не может исправить эти ошибки. Те, которые были в RLHF в зависимости от датасета кейсы, когда она могла исправлять ошибки, когда юзеры подсказывали, как правильно исправлять ошибки, они срабатывают. В огромном количестве кейсов это не срабатывает. В частности, это все сложные вещи. Это программирование. куча других доменов, где нужен резонинг. Там она не может исправлять. То есть, соответственно, вы не можете написать какой-нибудь промпт, где сказать, что выбери такую-то тематику. То есть, сгенерируй мне там 10 вариантов, а затем второй вы пишете промпт и говорите, теперь выбери из этих 10 вариантов самый лучший. Когда-то это срабатывает, когда нет, надежность этого невозможно проверить, то есть какое численное вы получите оценку по надежности, когда вам нужно опираться на вот такую генерацию. Но мы много видим таких примеров, мы тоже сидим в телеграм-чатах, где постоянно скидываются примеры типа там, chat.gpt скажи, как заработать много денег там за определенный период и прочее. Конечно, это ну так не работает. Ну вот у меня такой общий ответ. 

S04 [01:21:31]  : Захар, может, дополнишь? Я вообще хотел спросить у Юлии, может быть, он более подробно задаст вопрос, потому что я не совсем понимаю, что значит эти классы, это просто тема? Да, это тема, но, например, мы ищем их с помощью тоже векторных моделей, вот же Word2Vec используемый, либо вот то, что я сейчас скинул в чат, это использования Роберто, то есть, почему кажется, что GPD, например, даст лучше вариант, чем Роберто, не с тем понятно. То есть, вот у нас есть текст, мы в нем должны найти, выбрать какой-то кусочек этого текста. Ну вот, я сейчас скинул пример с Роберто, Роберто это может делать. Почему именно такая уверенность, что нужно использовать в другие модели. Ну и к тому же Roberto там, даже то, что мы сейчас используем, мы не используем, мы ее тестировали просто, она там занимает 2 гигабайта, вот ее общий вес, ее параметры, 2 гигабайта. Это не квантованная параметра, то есть намного меньше, чем даже chat gpt. Зачем вам обращаться по API к какой-то chat gpt, если можно локально использовать объекты. К тому же мы планируем использовать менее емкие модели. Точнее, менее тяжелые модели. 

S03 [01:23:12]  : Реакция вашего оппонента. Так у вас тоже нет гарантии, особенно с многозначными словами. По сути, вы здесь безосновательно утверждаете, что ваш алгоритм поиска тем работает лучше. Ну может быть рекол у вас лучше, но зато прецизия намного хуже. Вы много лишнего найдете. Можно секундочку, у меня просто сразу в развитии этого вопроса. А вы видите вообще как можно верифицировать качество? Лучше, хуже, то есть это же все можно свести к метрикам? 

S04 [01:23:48]  : Да, в целом можно. Если есть метрики, то к ним можно свести. вот то, что сейчас делаем с Арабертой, можно использовать метрику SQL. Это все решаемо. Мне непонятно другой момент, почему такая уверенность, что нужно использовать какие-то другие модели, а не те, которые у нас, и почему уверенность, что у нас будет Прессизм намного хуже. Хотелось бы услышать более развернутый вопрос. 

S03 [01:24:27]  : Юрий, прокомментируйте, на каком основании вы считаете, что коллеги безосновательно утверждают? Коллеги, может быть, предполагают, что вы тоже безосновательно утверждаете, что они безосновательно утверждают? 

S01 [01:24:41]  : Ну, изначально говорилось, что Кластерана во рту веки и на чем-то таком. 

S04 [01:24:53]  : я скинул, что у нас есть исследование с Робертой. я говорил, что мы сейчас работаем с Вортовиком, но для выявления фраз исследуем Роберту. я там скинул пример, как она работает. и то, и то. вот это в резюме исследований. на данный момент мы получили результат и переходим на Роберто. 

S01 [01:25:20]  : Роберто, это и есть один из вариантов делать то, что я предлагаю. Только вы именно вот так спрашиваете, какая тема, или вы по-другому делаете? 

S04 [01:25:33]  : Можете открыть скриншот, я же скинул, как она работает. Скриншот я скинул. Эта библиотека с Робертой работала. 

S01 [01:25:42]  : Так, не совсем понял, где искать скриншот во время демонстрации. 

S04 [01:25:52]  : В общей чате я его там скинул еще перед вашим первым вопросом. 

S01 [01:25:56]  : Ну, меня не было тогда, у меня и ссылки нет. 

S04 [01:25:59]  : Хорошо, я еще раз перешлю тогда. 

S01 [01:26:05]  : вот, ну, соответственно, у всех вот ворту века, значит, он хуже немножко с клетчерами разбирается, у него будет больше ложных срабатываний. вот, ну и с языковым моделям то же самое. у роберта, наоборот, будет... она меньше тем, условно говоря, найдет, но зато там меньше срабатываний будет ложных. Значит, если будет модель более умная, то она более четко будет выбирать слова, соответствующие этим темам, и так далее. Тут баланс такой. 

S04 [01:26:40]  : Да, там еще есть момент такой, что Word2Vec они разные. Если его нужно обучать под разные домены и затюнить можно, например, Word2Vec под любой домен, и он будет лучше в этом домене работать. А мы в библиотеке даем возможность человеку выбрать модель, которую он будет подгружать для интерпретации тестеров. То есть человек может затюнить свою модель и подгружить ее. Мы вот используем сейчас Word2Vec, но планируем посмотреть в сторону Сберта, посмотреть в сторону Роберта. Пример с Роберта есть, я отправил сейчас. 

S01 [01:27:31]  : Смотрите, еще лучше преды посмотрите тогда, если русскоязычный делаете. 

S03 [01:27:42]  : Хорошо, коллеги, еще есть вопросы? Нет, у меня короткий комментарий, но мне кажется этот вопрос пора лучше-хуже, это же можно решить с помощью метрик. Я могу дать ссылочку в нашей работе, мы там ряд метрик использовали, есть BLUE, есть VLCS, есть VER, есть TER, которые для вещей аналитики систем могут использоваться. Сейчас я кину ссылку. Мы хотим этот склад использовать. Мы склад не использовали, но взять и посмотреть кто точнее. leaderboard, что называется, всех рассудит. коллеги, большое спасибо за доклад, Виктор. я полагаю, что вы с этим докладом будете на INOP заявляться, да? 

S02 [01:28:44]  : так, а там у нас тоже, да? 

S01 [01:28:46]  : это же июнь, да? да, да. 

S02 [01:28:53]  : В принципе, да, с этим. Мы его еще поправим. То есть, дело в том, что мы же этот доклад рассказывали на конфее OpenTalks, но не такой, как он сейчас. То есть, половины доклада там не было. Он был короче. Сейчас он был дополнен и, возможно, и, скорее всего, он будет еще как-то видоизменен в следующий раз. 

S03 [01:29:14]  : Хорошо. Коллеги, я так понимаю, мы в июне еще раз встречаемся и будет рассказ от Захара про фрактал ГПТ. Да. Хорошо. Коллеги, спасибо. Спасибо всем участникам. Спасибо за вопросы. Спасибо за критику. Всем всего доброго и до новых встреч. До свидания. До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
