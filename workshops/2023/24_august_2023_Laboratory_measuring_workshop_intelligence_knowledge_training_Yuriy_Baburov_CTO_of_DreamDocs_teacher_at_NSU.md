## 24 августа 2023 - Лабораторный измерительный практикум: интеллект = знания + обучаемость? - Юрий Бабуров (CTO компании DreamDocs, преподаватель НГУ) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/NYDY6xwTvOA/hqdefault.jpg)](https://youtu.be/NYDY6xwTvOA)

Суммаризация семинара:

На семинаре русскоязычного сообщества разработчиков искусственного интеллекта Юрий Бабуров представил лабораторно-измерительную практику "Интеллект равняется знания плюс обучаемость". Сессия затронула темы измерения интеллекта моделей, их обучаемости и качества знаний. Особое внимание было уделено сверхсложным задачам и перспективам развития AGI.

## Измерение интеллекта моделей

В начале семинара были рассмотрены простые модели и попытки измерения их интеллекта на задаче распознавания цифр из изображений NIST. Было показано, как простые модели, такие как линейная регрессия и персептрон, могут достигать высоких результатов в задаче распознавания цифр.

## Обучаемость моделей

Далее, Юрий обсудил идею обучаемости моделей, указывая на то, что даже без использования лоссов (поправок на обучение), модели могут быть доучены с помощью нескольких примеров. Этот процесс может занять всего несколько секунд и позволяет моделям адаптироваться к новым условиям.

## Сверхсложные задачи

Александр выразил интерес к формализации методов оценки обучаемости моделей и предложил использовать формулы-эфмеры или акьюроси для сопоставления моделей. Юрий предложил учесть качество знаний и уровень интеллекта в понятии качества модели.

## Примеры сверхсложных задач

Юрий выделил несколько примеров сверхсложных задач, включая создание технических заданий и программного кода на основе текстовых описаний задач, что требует от модели способности к реверс-инжинирингу и пониманию контекста.

## Футурология событийной семантики

Семинар затронул тему будущего развития процессоров, которые будут ближе к бизнес-логике, чем к вычислениям. Были обсуждены идеи событийной семантики и возможности автоматизации бизнес-процессов с помощью сильного искусственного интеллекта.

## Визуальные модели и размеры параметров

В заключительной части семинара были обсуждены размеры и параметры моделей, включая сверхбольшие модели с миллиардами параметров. Было отмечено, что большие модели могут достигать высокой точности, но при этом могут быть сложными в обучении и использовании.

## Заключение

Семинар подчеркнул важность обучаемости и качества знаний в искусственном интеллекте, а также потребность в разработке новых методов оценки и сравнения моделей. Был затронут вопрос перехода от интерпретации к компилируемым программам и возможности использования сильного искусственного интеллекта для автоматизации сложных бизнес-процессов.






S01 [00:00:01]  : Начинаем очередной семинар русскоязычного сообщества разработчиков сильного или общего искусственного интеллекта. И сегодня Юрий Бабуров расскажет, даст нам лабораторно-измерительную практику «Интеллект равняется знания плюс обучаемость». Выпросительный знак. Юрий, пожалуйста. 

S03 [00:00:21]  : Всем добрый день. Себе включать пока не буду, пока буду только презентацию с экрана показывать. Итак, давайте возьмем стандартный датасет и рассмотрим на нем стандартную задачу, которая называется NIST. Все мы знаем, многие знают эту задачу. На ней можно показать на самом деле очень многое. Начнем мы с того, что построим несколько достаточно простых моделек. вот так вот выглядят картинки из миста. видим, что они на черном фоне, светленькие картинки. и попробуем измерить интеллект на достаточно простой такой задаче. будем модели называть умными, глупыми, в общем, по-всяким кидаться обвинениями. первый тренировочный пример будет связан с тем, что мы возьмем этот датасет просто как он есть. в его особенности все цифры центрированы, то есть расположены около центра картинки, все достаточно большого размера, 28 на 28 пикселей. и попробуем посмотрим как три разных модельки, но тут две похожих, линейные регрессии ridge и персептрон, как они эту задачку решат. могу запустить преваз, чтобы мы еще посмотрели. в общем-то она запустилась, просто вначале она кричала. 

S04 [00:02:37]  : я запустил портал розыгрыш текст сначала причем считай все бесплатно 

S03 [00:03:02]  : первый эксперимент. берем датасет, учимся на нем. первые модельки достаточно глупые и учатся усредненно, учатся на тренировочной датасете 26%, на тестовой датасете 25%. то есть распознает 2 цифры угадывает из 10, 2,5. Третья модель у нас умнее. Несмотря на то, что она линейная, она у нас распознает 86% датасета. Это, кстати, получше, чем показывают многие модели другие, линейные-нелинейные. спайковые, не знаю, еще какие-то. после этого попробуем дать сети немножко другую задачу. возьмем, перевернем наши картинки таким образом по цветам, чтобы черный цвет на фоне стал белым, а белый соответственно черным, ну и промежуточные цвета тоже. Посмотрим. Ну, конечно же, ничего тут необычного нету. Нейросетки учатся примерно так же на этих задачах. Правда персифтрон чуть ниже показал результат, на 1%. Ну, бывает. А вот теперь посмотрим, задачу более сложную. Но для человека казалось бы очевидным, что если мы умеем распознавать черные цифры, то мы должны на черном фоне белые цифры, то мы должны уметь распознавать и наоборот белые цифры, черные на белом, белые на черном фоне. То есть делаем тренировочный датасет, из белых цифр на черном фоне, тестовый датасет наоборот, из черных цифр на белом фоне. Смотрим, что у нас показывают модели. Как вы думаете, что эти модели покажут? 

S01 [00:05:39]  : Юрий, уточните, то есть, мы тренируем на, грубо говоря, негативе, а тестируем на позитиве, да? Да. По идее, должен быть бред. 

S03 [00:05:53]  : должен быть бред да так давайте я буду смотреть чат может быть попробуем добавить к этому чат если кто хочет еще предложить какие-то варианты у всех бред не у всех бред в целом что что вы ожидаете от данной задачи пишите в чат Виктор считает, что выучат инварианты, бреда не будет. Смотрите, здесь у нас инварианты для сети. но обратные картинки не являются инвариантами для обычных картинок. то есть они сильно отличаются. там, где подавался в линейной модели на сеть плюс, теперь будет подаваться минус вместо плюса. наоборот. в линейной модели качество падает. конечно же. То есть даже те цифры, которые сеть угадывала, она начинает не угадывать, потому что она среди этого ищет. ищет беленьким, то есть, например, она может подумать, что здесь вот так вот в верхней части, давайте попробую нарисовать еще, что здесь в верхней части, например, вот так вот этот нолик, или что-нибудь такое, или вот здесь вот что нолик, например, может пытаться найти. Да, если более сложную архитектуру взять, это в принципе, в какой-то ситуации может быть и выправится, но для этого нам как раз и надо будет думать над постановкой задач. Сейчас мы к этому всему перейдем, не ко всему, но в общем затронемся. Будем немножко это дело усложнять. усложним следующим образом. попробуем сделать полный датасет из белых и из черных элементов. теперь, как вы думаете, снова такой же вопрос, что будет у линейной модели на выходе? то есть эти все три модели, они по сути линейные. там можно сказать пару слоев, по сути они все линейные. первая модель вообще была линейной регрессией, она училась интуитивно догадываться по сумме цветов элементов больше это похоже на тройку или на пятерку. вторая модель в этом плане уже бинарная, уже есть нейрончики. слой, но все же линейная. один слой, а тут линейное преобразование. бинарный на каждый слой уже. так, ну что-то никто не пишет, даже нет доказать. ну, собственно, вариантов тут два. Варианты тут два. Или будет работать, или не будет работать. Или будет работать так же, потому что датасет похож на прошлый, или не будет работать. 

S04 [00:10:08]  : Смотрите, что получается. 

S03 [00:10:25]  : первая модель. 10% случайное угадывание. вторая модель. 10% случайное угадывание. третья модель. Чуть лучше случайного угадывания, но чему-то она могла бы научиться. Какие-то общие начальные закономерности она вывела. О чем это говорит эксперимент? То, что линейные модели плохо разделяют нелинейные сложные данные. То есть вниз все-таки слишком простой датасет, и его можно разделить линейными моделями. Но, тем не менее, и с transfer learning он всегда сложный. итого, какие мы сделали выводы по данной системе моделей. первая модель у нас всегда плохо обучается, просто сама модель глупая. неправильная архитектура, что-то идет плохо. а второе, значит третья модель на простом датасете все же хорошо обучается, но просто вот этот full NIST датасет он был уже сложный для нее. но на простом датасете она хорошо обучается, то есть она умная, но такая вот, не знаю как сказать, как насекомая. интеллект обучится там под нужную ситуацию, достаточно быстро обучится. За 30 секунд амнистия будет что-то там на нем показывать результат. Заметим, что более умная модель учится дольше. Даже на таком маленьком простом примере нам это видно. Значит дальше. Первые выводы мы сделали. Значит, давайте сделаем теперь более сложные выводы. Начнем вот эту ситуацию экстраполировать. Значит, по презентации снизу. Модели умные до тех пор, пока не сменился датасет. И для нового датасета их надо переобучать. скорость переобучения, соответственно, зависит от размера модели, большие модели переобучаются дольше. то есть вот на небольших моделях ситуация именно такая, что на небольших моделях нам нужно переобучать модель под новую задачу, то есть мы выкидываем старую задачу, обучаемся новую задачу и у нас все все в целом хорошо, как-то задача моделью решается. при условии, что задача достаточно простая. давайте, если какие-то вопросы по этому эксперименту, по этому небольшому практику, и потом пойдем дальше. 

S04 [00:13:58]  : все понятно? 

S01 [00:14:03]  : вроде понятно. тезисы вроде не вызывают сложные задачи. 

S03 [00:14:08]  : на небольших моделях всегда такая логика. теперь дальше. Если мы сделаем нелинейную модель, то более сложную задачу она уже выучит. У нас уже будет все хорошо, но тут встает вопрос, что делаем дальше. Соответственно. три способа обойти ограничение. здесь на самом деле не три способа обойти это ограничение еще написано, а скорее первый способ обойти это ограничение. во-первых, можно взять модель намного больше. в этом случае очень большая модель. Если ее обучить на большом датасете, у нее не будет такого доменного ограничения, она сможет работать сразу с несколькими доменами, сразу с несколькими поддоменами. И если всякие разные цифры и такие сети ей подавать, то она уже с ними будет справляться. Подобным образом сделали на картинках несколько, даже много раз получили модели. В прошлый раз я показывал модель Дина. показали также, ну сейчас делаются фундаментальные модели для картинок и в общем-то на них все работает. Но тогда возникает у нас проблема с этим способом. Теперь нам дообучение становится невозможно делать, потому что модель очень большая и дообучается она долго. Соответственно, вот это ограничение дает нам несколько путей выхода из кризиса. Для начала давайте вернемся, сверимся в первый раз с нашим тезисом. Показал ли я вам главный тезис на этом небольшом примере? что нельзя интеллект мерить как меру просто знаний на конкретном датасете, потому что важна еще обучаемость, иначе на другом датасете у нас будет результат нулевой. То есть первое, вот эти модели, если судить их по знаниям на конкретном датасете, они вроде бы все, то есть эти плохие, вот эта модель вроде бы хорошая. То есть мы ее обучили, она хорошо обучилась, решает задачу, все хорошо. Значит, она у нас интеллектуальная, хорошая, или она у нас слабенькая. Я утверждаю то, что оба эти компонента важны, оба эти компонента нужно измерять. Как измерять знания я показал. как измерять обучаемость, соответственно, мы ставим системе другую задачу и требуем от системы, чтобы эта система эту задачу решила. окей? 

S01 [00:18:15]  : у меня окей. 

S03 [00:18:20]  : Так, ну, в силу там лета и прочих фунтов, посещаемость у нас там низкая. Я думал, хотя бы кто-нибудь вопрос задаст. Например, на каких задачах можем посмотреть обучаемость? Как нам выбрать такую задачу, в которой будет хорошая обучаемость? 

S01 [00:18:49]  : На самом деле у меня возникает вопрос, который, очевидно, будет в остальной части вашего доклада. Как мы можем мерить, формализовать меру обучаемости? То есть, знания, как я понимаю, здесь вы предлагаете мерить либо через Акуроси, либо через Эвскор, правильно? Вы утверждаете, что знание – это F-score или accuracy на тестовом сети, так? Так. Окей, хорошо. Тогда возникает практически вопрос, какую метрику мы можем сформулировать для формирования обучаемости и как различные алгоритмы могут по этой метрике себя показать. на тех же самых стандартных дейтасетах, и сразу же возникает вопрос, неужели никто такую, казалось бы, очевидную вещь не делал? 

S03 [00:19:48]  : Ситуация здесь следующая. Обучаемость для маленьких моделей мы можем переобучить полностью. Соответственно, для маленькой модели 

S01 [00:20:00]  : но при этом переобучить, она перестанет работать на предыдущих сетах, правильно? 

S03 [00:20:08]  : да, она перестанет или станет хуже работать на прошлых сетах. но для маленьких моделей это является в целом мерой обучаемости и обучаемость считается за получаемость считается вот эта метрика. то есть получается алгоритм, который можно соблюдать. берем задачу 1, берем задачу 2. Учим на задаче 1. Измеряем качество. Это получается, это мера знаний. Учим на задаче 2. Измеряем качество, первое качество. И измеряем время. это получаем меру обучаемости. Соответственно, для обучаемости у нас два параметра. Вызвано это тем, почему на первой задаче у нас измерялось только качество, потому что в большинстве случаев модели приходят нам готовые. Модели к нам приходят готовые, мы не можем посмотреть, сколько времени занимало их обучение, или же нам не нужно было их обучать, эти модели, или же мы можем перед использованием эту модель обучить. И для узкого искусственного интеллекта нам вполне достаточно первого кейса. Учим на задаче, измеряем качество. Качество хорошее, берем модель и ее начинаем использовать. А вот для более сложных кейсов у нас возникает проблема, что измерение качества на первом датасете нам совершенно не показывает то, насколько в будущем эта модель нам будет полезна. Поэтому у нас встает задача приспособить модель под использование на новые задачи. сейчас это модным словом называют transfer learning. и для простых моделей в роли transfer learning будет просто переобучение. его вполне достаточно, потому что маленькая модель все равно не может запомнить все. ее все равно нельзя заставить учить все. до 2020 года в NLP была ровно та же ситуация. мы не могли учить NLP-шную модель всему, просто не могли. она начинала, если начинать ее учить на новые задачи, она будет ухудшать качество на старых задачах. соответственно, в первой эпохе маленьких моделей у нас решение по обучаемости была ситуация такая, что переобучали на новую задачу. и из этого возникала проблема, что нам требуется датасет для второй задачи тренировочной, потому что без тренировочного датасета результаты будут ужасными. то есть это вот такая была первая эпоха. и, соответственно, почему был вопрос про дообучение. тогда дообучение с большой модели будет... сейчас мы попробуем на этот вопрос ответить. так, ну что, критерии. Как вы считаете, можно ли считать критерием интеллектуальности именно, то есть отличием общего интеллекта, возможность суммы имеющихся навыков и возможности приспособления к новым знаниям, навыкам и так далее? 

S01 [00:25:10]  : После ремарки Тельхова на позапрошлом семинаре я теперь везде хочу увидеть формулу. То есть, как бы на пальцах вроде как понятно, но вот как F-score считается известно, что мы на что делим, на что умножаем. А вот как бы это теперь загнать в формулу? Говоря и задач, где количество задач изменяется от единицы до K большое, ну и так далее. 

S03 [00:25:50]  : Да, хорошо. 

S01 [00:25:51]  : Причем время на самом деле тут, наверное, все еще усложняет. То есть, хотя бы без времени. Хорошо. 

S03 [00:26:02]  : время будем считать ограничить вариант. итого, у нас теперь три эпохи моделей. 

S04 [00:26:14]  : первая эпоха, небольшие. 

S03 [00:26:28]  : небольшие модели. давайте их охарактеризуем по этим параметрам. пока что без формулы, пока что просто вот эти три параметра зафиксируем. и нам придется еще ситуацию удвоить. потому что у нас бывают задачи простые, бывают сложные, как я показал на этом примере. Простые задачи. Задача один, качество. Хорошая. Хорошая. значит, время обучения небольшое, хорошее. качество, значит, обучение под новую задачу хорошее. то есть на простых задачах... давайте... давайте просто в каком порядке лучше делать таблицы. давайте сложные загадочные. время хорошее, но результат плохой. То есть мы понимаем, что небольшими моделями хорошие задачи можно решить, это замечательно, простые задачи можно решить, это замечательно, но этого мало. Но, к счастью... 2010 года... Значит, вторая эпоха 2018-2020 годов. Значит, простые задачи. На простых задачах большие модели теперь решают... ну, в общем-то, не имеет смысла. Хотя есть нюанс. время переобучения у нас плохое, но качество у нас хорошее, потому что модель большая, учится дольше. Значит, что происходит со сложными задачами? Качество на сложных задачах стало хорошим. Со временем все плохо. Качество на новых задачах хорошее. Просто потому что мы не можем сменить задачу быстро. хотя средние на самом деле немножко можно, потому что переиспользовать. смотрите, о чем я говорю. здесь для примера сложной задачи вполне можно взять какой-нибудь условный matchnet и сделать на нем модель, которая неплохо будет работать. неплохо будет выделять базовые примитивы для зрения и до обучения под новую задачу будет занимать ну 10% времени от того, что было потрачено на старую задачу. Это намного больше, чем маленькая модель, но тем не менее это не 100%. То есть мы научились немного переиспользовать переиспользовать данные, то есть 90% мы учимся какому-то там фаундейшну, потом мы доучиваемся, доучиваемся конкретную задачу под конкретный датасет. Теперь переходим к третьей, современной. Сверх... не знаю, вы просто назвайте, сверхмодели. Сверхбольшие модели. 2019 плюс, эта эпоха сейчас как раз идет. Что у них происходит на простых задачах? На простых задачах у них все хорошо, здесь ужасно, здесь все хорошо. сложные задачи. хорошо, ужасно, хорошо. казалось бы, и вот эта штука нам мешает использовать эти модели в том режиме, в котором мы использовали простые модели. то есть у нас возникает фундаментальная проблема, мы больше не можем доучивать модели. К счастью, к этому нашли три обходных пути. Первый обходной путь называется метрика у нас сменилась приемлемо. и здесь сменилась приемлемо. то есть, заметьте, Дальше более умные модели идут по пути… Ну, казалось бы, сделали уже сверхбольшие модели, что нам еще надо? Идут по пути уменьшения времени для обучения, потому что все еще качество нас не удовлетворяет для новой задачи. поэтому вот еще раз говорю вот это время поэтому имеет значение. без этого времени мы для сверхбольшой модели говорим ну не знаю взять там другой язык или там плохо складывает там не знаю там gpt4 мы говорим переучить всю gpt4 добавив датасет или убрав другие задачи, добавив задачи на сложение. Пусть она переобучается и научится складывать. Нет, такой просто невозможно сделать. Но возможно добавить адаптер. Это как раз похоже на вот этот способ. Когда мы уменьшили время обучения, мы оставили каркас от модели и добавили к ней нашлёпку, которую уже дообучаем. То же самое делается с верхмоделями. Вот эта нашлёпка как раз называется лора, она нам позволяет уменьшать время обучения в кучу раз. вот такие же нашлепки были и для модели поменьше всякие разными то есть способов миллион теперь и есть еще случайно обнаружилась случайно обнаружилось, что у сверхмоделей есть еще один способ. способ заставить доучить сложную модель, способ, который на больших моделях почти не работает. то есть работал, но очень слабенько и тем более не работал на маленьких моделях. как вы думаете, что это за способ? 

S01 [00:36:00]  : мужики задумались. 

S03 [00:36:12]  : этот способ называется learning или prompt. и еще плюс, плюс prompt сюда допишу. оба компонента важны и оказывается, что этот способ Позволяет простые задачи, почти все типичные задачи простые, прям сверхбыстро на них доучиваться. Как выяснилось? что выяснилось, что во few-shot ситуации нейросеть с трансформером делает что-то очень похожее на backpropagation и что-то очень похожее на собственное обучение. То есть на самом деле это вообще... очень вообще странно, что данный способ работает, что я хочу сказать. Но данный способ работает. Соответственно, few-shot – это один способ. Когда мы показываем нейросети, что она должна отвечать, и нейросеть в реальном времени, по сути, как будто бы у нас на эти несколько примеров доучивается. Простые задачи. 

S04 [00:38:15]  : Простые задачи. 

S03 [00:38:25]  : И здесь. Ну, возможно, уже не так хорошо. Недостаток этого метода в том, что итоговое качество может быть хуже, чем у сверхмаленьких моделей. Сверхмаленькая модель иногда может обучиться намного лучше. Сложные задачи. Здесь ситуация такая, что если она решала задачу хорошо, то мы добавляем уход, получаем приемлемый результат. Причем нейросети можно скармливать, здесь большой нейросети можно скармливать вплоть даже до бинарной информации в виде слов, закодировав в виде слов и так далее. Это фьюшот, может быть, обучение любого вида. Большая нейросеть внутри как будто бы внутри себя воспроизводит маленькую нейросеть, которую на этих примерах учат. но тем не менее качество приемлемо, потому что few-shot, примеров мало. 

S04 [00:40:04]  : для сложной задач нам просто недостаточно примеров. 

S03 [00:40:14]  : и кроме этого альтернативный способ является сверхмодель то есть когда мы в промпте просто объясняем новую задачу соответственно у нас теперь промпт выступает в качестве как замена датасета, то есть это совсем другая штука, его надо как-то писать, его можно также программно как-то вычислить, но с помощью этого результат, результат приемлемый. Соответственно, у нас происходит, то есть по метрике качества, небольшое ухудшение, но, впрочем, оно сильно зависит от задачи. Зато по скорости мы, наконец-то, научились быстро адаптироваться к новым задачам. То есть мера интеллекта, можно сказать, что все-таки так, ну что, есть согласие с тезисами? обосновал ли я выбор такой меры интеллекта? То есть вот оно наше как раз адаптивное поведение мы как раз свели к тому, что у нас есть задача 2. То есть неадаптивное поведение, мера в целом, мера сложного, то, что система демонстрирует сложное поведение, это как раз она способна учиться на задачи 1. А мера того, что система способна адаптироваться, это задача 2. Это качество и время обучения на задачу 2. Если время бесконечное, то неважно то, что качество задачи 2 можно получить высокое, мы считаем, что система не адаптируется. Скорость адаптации имеет значение. пользователь не будет ждать неделю, пока там... ну, в некоторых случаях будет, но в большинстве случаев не будет ждать неделю, пока нейросеть обучится на его задачу. Что думаете? Годный критерий? 

S01 [00:43:20]  : Вроде годный. 

S03 [00:43:24]  : Ну вот теперь, на вопрос, меряет ли кто-нибудь данный критерий, ответ смешанный. Ответ смешанный, потому что... для маленьких задач это измерение это по сути вот я механизм показал измерение для маленьких сеток для первых моделей значит для более сложных моделей Эту процедуру именно, доучивание, все производят отдельно, но иногда эта процедура все же проводится. и учитывается в тестах. То есть рез нет, мы выбираем не по его качеству, не из-за того, что он на одной задаче, на ImageNet показывает хорошие качества, а то, что его легко доучить практически до любой задачи, связанной с картинками. модель семейства резьб нет. ну и соответственно все их не выписали. мобайл нет. ну какие-то могу выписать. какие модели относятся сюда. рез нет. мобайл нет. всякий рез нет. для классификации. для детекции там чуть-чуть другое. там всякие efficient нет там нет как там она там другая там детектрон семейство детектрон детектрон 2 ела всякие и так далее. то есть у них зачастую есть выбор какую верхнюю часть брать и у них есть вторая часть, которую тоже можно адаптировать под задачу. решений, соответственно, для более сложных заданий. соответственно, там есть то же самое для задачи генерации. для задачи генерации тут, соответственно, у нас BERT. и, соответственно, также BERT используется в качестве базы. это уже трансформерная модель. И к ней там докручивается какой-то вариант, уже там адаптер для конкретной задачи. Показывает хороший результат для того же MLP. Ну, соответственно. 

S04 [00:46:36]  : Вот. 

S03 [00:46:39]  : Соответственно, вот в таком виде это мы не используем. Мы, соответственно, выбираем один из нескольких способов современных доучиваний. Или LoRa, или QShot, или ZeroShot. Соответственно, Системы стали ближе к человеческому, потому что ему надо рассказать, что новая задача заключается, словами описать, что вообще делать-то надо. Ну и мы даем несколько примеров, сколько можем, сколько засунется примеров того, как задачи делаются. И тогда результат получается неплохим. я в дополнительных материалах. сегодня я не успею все дело сделать и показать. я в дополнительных материалах, поэтому потом пришлю. текстовая задача, подобный анализ и сразу с несколькими поколениями моделей. на простой задаче, а потом уже отдельно будем делать на более сложной задаче. чего я хочу на выходе? я хочу сделать вот эти штуки у меня, это платформа. платформа, на которой самому можно программировать эти задачки, в плане что брать готовые задачки и их упаковывать, и на котором можно измерять. то есть для измерения сверх больших моделей на самом деле их в общем-то так и измеряют. им дают им дают или фьюшот плюс промпт или промпт и сравнивают их качество работы на ответы на вопрос, сонаризации, посчитать сколько там равно 1 плюс 123 плюс 4 36 и так далее. тут вы сами наверное все пользуетесь уже chat gpt поэтому здесь здесь все понятно и соответственно здесь измерение уже стало естественным форматом для текста. а вот с картинками Здесь работа еще только с картинками или с видео. Эта работа только стартует, мы еще только дошли до сверхмоделей. И поэтому еще таких вот способов выбрать хорошую сверхмодель. или большую модель для задач пока что нет. есть какие-то, но не систематизированные. 

S04 [00:50:01]  : разделилось все на области. 

S03 [00:50:09]  : теперь давайте вопросы. и в области reinforcement learning Все примерно то же самое. То есть только под Reinforcement Learning идет вместо Supervised Learning доучивание на основе обратной связи. И да, действительно, можно в JPT загонять описание сцены, которую видит робот. Робот попытался сделать действие, у него не получилось. Робот попытался сделать действие по ответу чаджиопеки. Чаджиопеки говорит, как ему там сделать, кофейный тест проходить. Говорит, ну вот найди, ты там нашел Нашел кружку, значит, на картинке, отлично, тогда возьми кружку. Робот говорит, поделитесь еще на этапы. Первый этап – робот. Роботу говорит, подойди к кружке. Робот выполняет. Потом говорит роботу, возьми кружку. Робот говорит, кружку взял. Система смотрит на результат, говорит, так, теперь выполни следующее действие. Пойди, значит, в чайник с кружкой в руке. Робот говорит, я не могу, я застрял. Значит, ChatGPT ему говорит, То есть вот это получается уже начинается обучение ситуации. Вот как раз в U-Shot вот это добавляется. Вот эти примеры добавляются в описание ситуации. Получается обучение на ситуации, что генерируется новый ответ. Что делать в новой ситуации? Это замена для reinforcement learning. И этот способ работает в чем-то быстрее, чем все методы. Лучше и быстрее, чем все методы, которые пробовали до этого. То есть пробовали и алгоритмически, пробовали делать кучу простых моделей, которые делают отдельные действия. Такой метод оказывается. выгоднее в перспективе. так что я в октябре хочу попробовать таким методом. таких попыток уже на самом деле много. я хочу попробовать этим методом решать общие задачи. в октябре вам доложится, что получается. вот как пример такой штуки. есть много-много кодеров, которые которые таким образом адаптивно программируют, переходят в разные файлы, в файлах что-то в разных пишут. есть еще такая штука под названием метод GPT. вот этот вот репозиторий. когда говорят, что у нас у нас компания из таких-то разных ролей, и не одного делают робота-агента, а делают сразу много роботов-агентов, каждый вправляется своим промптом и по очереди их запускают, они друг с другом коллаборируются и решают более какую-то сложную задачу. Можно сказать, что написать программу сложную, и они, соответственно, напишут и документацию, и спецификацию, и программу самую, и оттестируют эту программу, и в результате будет код. То есть используется ровно этот же подход, и оно как-то работает. другими подходами это не получалось сделать. так что пока что не видно какого-то еще способа, которым мы можем решать такие вот задачи на самом деле, хотя и качество иногда, иногда это страдает. Покажете. может, мы архитектуру не очень правильно строим, и поэтому получается, что робот предпочитает соврать или еще что-то сделать, но не решить задачу, неправильно решить задачу. возможно, мы неправильную метрику оптимизируем, мы среднее качество оптимизируем на задаче. если мы посмотрим какой-нибудь суперглумп, который измеряет данные критерии, то мы увидим, что по каждой задаче на самом деле берется средний, потом от всех задач еще берется средний. В этом есть своя проблема. Мы не штрафуем робота. за то, что он, когда он наврал, не говорит, что я не знаю. Мы измеряем здесь просто по среднему качеству. То есть он предпочитает брать, но с вероятностью угадать. То есть как студент на ответе типа ЕГЭ, где несколько вариантов ответа, если он ничего не знает, он будет угадывать. здесь, соответственно, будет выдавать наиболее вероятный ответ. возможно, из-за этого у нас и получается сделать систему, которая работает качественно. но системы, которые в целом неплохо работают, у нас делать таким образом получилось. эти системы решают задачи на самом деле хорошо и самое главное сверхбыстро доучиваются, сверхбыстро решают новые задачи, которых до этого ни разу не стояло. на самом деле мы могли бы еще вот здесь добавить сверхсложные задачи, но ни одна из этих систем сверхсложные задачи напрямую не решает. И вот наша задача как раз найти способ, которым сверхсложные задачи можно было бы решать с небольшим временем переобучения под новую сверхсложную задачу. Потому что когда все ученые и искусственный интеллект научатся одно открытие одинаково совершать, это нам не тот критерий, они должны все открытия в мире совершать. Условно. Или в любой другой отрасли у нас тоже должно быть. Какую бы задачу ни попросили, мы должны ее решать хорошо. и быстро адаптироваться, чтобы он не приходил за нас. Ну вот, соответственно, наверное, так и можно отличить сейчас слабый искусственный интеллект от сильного по искусственному интеллекту, по уровню интеллекта. То есть сильный интеллект просто будет тот, у кого эти параметры будут прокачаны уже на максимум. он будет и хорошо задачи решать, и быстро адаптироваться к новой задаче. Ну, я думаю, я свою задачу на сегодня выполнил, критерий изложил, критерий в целом критерий в целом обосновал. 

S01 [00:59:00]  : Главное – это правильно поставленная задача. Да. Уцелевшие коллеги, есть какие-то вопросы или комментарии? 

S00 [00:59:22]  : Добрый день, Юрий, большое спасибо, с удовольствием послушал. Но если бы, скажем, выкинуть из этого всего рассказа слово «интеллект», то как бы ничего не пострадало бы. То есть мы имеем список задач разной сложности, только хорошо бы более точно определить, как мы отделяем сложную задачу от несложной задачи. И, скажем, здесь есть такая тонкость. Для больших языковых моделей оказывается сложно математические задачи. А для калькулятора это простые задачи. Калькулятор не решит ни одной задачи из LNP и LNU, а языковые модели щелкают их. Поэтому здесь, наверное, нужно задачи не столько разделять по сложности, сколько по специфичности. То есть, скажем, какие-то задачи, те же математические задачи до появления калькуляторов были предельно сложные, а стали простыми. И, скажем, Антон подтвердит, скажем, та же токенизация и поиск поминованных сущностей была сложной задачей, с появлением языковых моделей стала простой задачей. Поэтому здесь два момента. С одной стороны, является ли решение каких-то задач показателем интеллектуальности, то есть, скажем, до появления калькулятора мы бы счет считали интеллектуальным, после появления калькулятора это неинтеллектуальная задача. И также можно сказать, что поиск каких-то закономерностей в тексте, понимания текста, суммаризация текста была предельно сложной задачей для компьютера. Сейчас это простая задача. Но скажем ли мы, что BERT или CHAT GPT это интеллектуальные системы? Ну нет, можно сказать, что интеллектуальные. Конечно, все интеллектуальные. Кальвадор тоже интеллектуальная система. И сеточка, которая решает, циферки определяет, мы тоже называем интеллектуальной системой. Поэтому вот либо мы должны где-то провести границу, а вот это интеллектуальные, а это не интеллектуальные, либо вообще выкинуть это слово. Потому что оно ни о чем не говорит. Вообще ни о чем. Вот, наверное, вот такие две моменты. Классификация задач по сложности – это довольно сомнительная классификация. И используем слово «интеллект». Тогда у нас получается, что знание обучаем, то есть мы меряем этими тестами, меряем с помощью этой классификации знание и обучаемость. Да, действительно, мы меряем знание и обучаемость. А называть ли это знание обучаемой словом интеллект? Ну, может, может и нет. Как бы ничего не прибавляет. Вот такой, наверное, мой комментарий. 

S03 [01:02:48]  : Хорошо. Спасибо. 

S00 [01:02:52]  : Это теоретические задачи, которые нужно как бы более точно ставить в начале исследования, не то что исследования, а в начале как бы чисто терминологически подбирать. И действительно, если бы мы разделили задачи как-то более, ну, по большему количеству критериев, чем по сложности, может быть, какие-то нюансы открылись другие. 

S03 [01:03:19]  : Хорошо. Мне хотелось, чтобы измеряемая мера приблизилась максимально к тому понятию интеллекта, которое все-таки используют люди. Если мы считаем, что что-то здесь не хватает, давайте думать, чего не хватает. 

S00 [01:03:37]  : Люди очень по-разному используют слово интеллект. То есть если смотреть, что люди называют, используют слово интеллект, скажем, интеллектуальная профессия, интеллектуал. То есть это значит, если исходить из этого, то интеллектуальные профессии это все связанные с обработкой какой-то информации, скажем так, абстрактной, то есть это инженеры. математики, физики, ученые. Вот интеллектуальные профессии. А продавщица, дворник – не интеллектуальные профессии. Но при этом продавщица прекрасно считает, распознает цифры, лица и все прочее. Поэтому тут, что люди называют интеллектуальным и словом интеллект, очень размыто. Еще нужно учитывать то, что до, скажем, 60-х, 50-х годов, то, что люди называли словом интеллект, и после, очень тоже разнится. То есть и, скажем, уровень требований к интеллекту с развитием искусственного интеллекта очень сильно падал. Тес Тюринга у нас определял однозначно, что интеллект и обладает, обладатель интеллекта имеет язык, умеет говорить, понимает текст, читает и может объяснять. Тес Тюринга, да? А уже как бы к середине, к концу 20 века мы интеллектуально называли называли распознавание картинок и вот много-много-много чего называли, что не имеет отношения к языку и пониманию сложных каких-то интеллектуальных проблем, интеллектуальных задач. Это тоже очень расплывчиво. 

S03 [01:05:24]  : Так, ну мне хотелось тот интеллект взять, который все же ближе к нашей группе, который сильный искусственный интеллект, да, то есть меру сил, силы, что ли, искусственного интеллекта. 

S00 [01:05:38]  : Ну тогда, наверное, нужно было говорить не про интеллект, а про вычислительные способности или способность решения задач. Вот можем ли мы отожествить способность решения задач с интеллектом? В какой-то степени – да. 

S03 [01:05:57]  : способность решения задач вот я здесь назвал знание способность решения задач если можно там посмотреть насколько сложные задачи там система решает насколько простые решает то есть если она не решает сложные решает только простые то эта система глупая. Если система решает более сложные задачи, то у нее более высокий интеллект. Но при этом, если эта система не способна адаптироваться к новым задачам, то это слабый, узкий искусственный интеллект, И не приближение, наверное, даже вообще к сильному искусственному типу. 

S00 [01:06:45]  : Тут тоже подводные камни с сознанием. То есть, скажем, у нас есть, скажем, человек, который решает очень сложные задачи. тот же Перельман, да, вот он решил одну из сложнейших задач математических. Можно ли назвать этого человека интеллектуальным в общечеловеческом плане, и можно ли себе представить, что Перельмана можно научить каким-то другим задачам решать, какие-то другие задачи? Ну, условно, условно, да? Или, скажем, условный, кто у нас там? знаток, интеллектуал, который может обладать огромным количеством знаний, может ответить на огромное количество вопросов, но не обучаем. То есть, скажем так, человек может решать сложные задачи, но при этом мы можем назовем его интеллектуалом, но он не обучаем. Вполне возможно такая ситуация. Очень много разных здесь градаций. Высокая обучаемость, но не способности. Малые знания и, наоборот, большие знания, но маленькая обучаемость. И кого мы назовем интеллектуалом? Интеллектуальным агентом, скажем. Для каких-то заданий, для решения каких-то задач нам нужно огромное количество знаний, а для каких-то – быстрая обучаемость. Ну, скажем, спецназовец, у него малое количество знаний, но он легко адаптируется, он быстро обучается, он приспосабливается. гораздо сильнее решает какие-то задачки, вот мелкие, текущие здесь и сейчас, чем профессор. Профессор тут же в лужу сядет. 

S01 [01:08:43]  : Александр, я позволю себе встрять, что я как раз в своем последнем докладе, там у меня был слайдик, где показано было в системе двух координат в рамках той модели Когнитивные способности могут соответствовать различным типам личности. С точки зрения эволюции в разные периоды и в разных ситуациях важны разные люди и, наверное, не случайно в социуме соответствующие гены предполагают появление людей с различными обучаемостями и переобучаемостями, и способностью к катастрофическому забыванию, либо наоборот к катастрофическому вспоминанию. И социум как раз подбирает комбинации этих людей и призывает Те способности, которые нужны в данный момент в соответствующей стадии развития социума. 

S00 [01:10:04]  : Да, я смотрел. Это правильно. Что мы верим? Интеллект, знание, преобучаемость. Имея в виду, что у людей такой большой разгруз, И такой большой разброс задач. Мы, скажем, возьмем какое-то устройство, потестируем на какой-то сложных задачах, сделаем вывод, но оно будет совершенно неадекватно действовать в другой ситуации, с другими задачами и с другими принципами обучения. Здесь нет единой шкалы и единой какой-то градации, единой такой линейной, что вот здесь низкая интеллектуальность, здесь высокая интеллектуальность. 

S01 [01:10:59]  : Александр, а можно, извините, по поводу шкалы и градации? Вот там вопросы, я прозывал в ютубе, были на понимание от Вадима Шевчука. Во-первых, попросил уточнить архитектуру универсальной модели. А во-вторых, вот вы говорите, большая, маленькая. А есть вообще какой-то способ провести границы? То есть, где у нас кончается большая модель, где у нас… точнее, где у нас кончается маленькая, где начинается большая? И где начинается сверхбольшая? И кто за этим стоит? 

S00 [01:11:37]  : Это Юрий вопрос, да? 

S03 [01:11:38]  : Да, конечно, Юрий, это вопрос. Давайте вначале, да, по поводу первого момента все же я прокомментирую, по поводу вот этой вот прошлой дискуссии. Да, безусловно, и знания, и обучаемость сами по себе могут быть нужны и важны. Но в первом случае, если у нас присутствуют знания без малейшей обучаемости, то несмотря на то, что людей таких мы называем интеллектуальными, мы это явление называем специализацией. И специальный искусственный интеллект – это узкий искусственный интеллект как раз. То есть это ровно оно и есть. Мы научили на какой-то определенной задаче, и эта штука у нас работает на этой задаче. Да, безусловно, русские искусственные интеллекты нужны. Нам на сканере не нужно систему, которая посчитает 5 плюс 7. Нам нужна система на сканере, которая лица людей распознает, чтобы они входили на предприятие. а чужих не пропускали. Но небольшая обучаемость для этой системы, минимальная все же нужна в том плане, что должна быть возможность одного человека или двух новых сотрудников туда добавить. Какая-то небольшая обучаемость нужна. Но, соответственно, полная широта задач не нужна. Да, такие системы есть, такие системы используются, такие системы хорошо, но тогда, может быть, нам и не нужно вообще сильного искусственного интеллекта, может, мы узкими интеллектами обойдемся. И давайте в другую сторону смотреть. Если нам не нужна, значит, нужна только обучаемость, но нам не нужно накопление знаний и какие-то там уже накопленные знания в системе, то тогда у нас страдает другой фактор. Система у нас быстро что-то делает в конкретной ситуации, но сложных поведения, которые требуют знаний и всего прочего, требует какой-то сложной когнитивной модели, нам не получить. Вторая ситуация – это как раз то, что мы получаем с ChargePT. У нее какие-то знания есть. Знания о мире такой моделью сравнимы по измерениям со средним человеком. Но сверхчеловеческого уровня по знаниям она не показывает и не покажет, потому что у этого модели не вшить все просто знания. Ее можно какие-то знания вшить. А все остальное у нее... добавляется от обучаемости в мире. Поэтому обучаемость важна для агента, которому мы сможем научить конкретные наши новые задачи и действовать в новом окружении, при этом Интересно как раз скомбинировать эти два явления, чтобы система не вела себя глупым образом в каждой новой ситуации. То есть да, обе грани имеют значение, но комбинация нам важнее, потому что мы сейчас получили оба варианта системы по отдельности. 

S04 [01:15:42]  : Нас это не устраивает. Все еще не устраивает. 

S03 [01:15:47]  : Но при этом для каких-то применений нас это вполне подойдет. вот так теперь по поводу размера модели для разных доменов для разных предметных областей размеры модели различаются но вот примерно поколение примерно определяют определяют примерно до 2010 года несколько слоев нейросети, до трех-четырех слоев. С единственным исключением было... Визуальные модели чуть-чуть по-другому устроены, но в общем это несколько слоев здесь. и, соответственно, небольшая ширина. Ширина модели примерно определяет то, насколько хорошо она учит знания разные. А глубина скорее отвечает за сложность поведения. И небольшие модели, они были не сильно широкие, не сильно глубокие, глубокие просто не умели делать модели, ну и вычислительной мощности не хватало. по ширине эти модели были небольшими, потому что сложные задачи они все равно не решали, а для простых задач ширины было обычно небольшой достаточно. то есть запомнила она основные там части, из которых там картинки вместе складываются, и все, и отлично. Соответственно, большие модели, это модели до где-то там 20 слоев, до 1000, ну где-то можно по параметрам оценить там 10 где-то порядка там от 10 там до 100 миллионов параметров 1.20 небольшие модели здесь соответственно меньше значит но сверх большие модели вы сами знаете какого они размера это 1 но это билет билет миллиард больше одного миллиарда параметров. диапазон около сотни, вот здесь промежуточный оказался относительно невыгодным. он не намного лучше результаты показывает, чем большие модели, но он медленнее. То есть улучшение качества уже там несущественное, там единицы процентов от увеличения размера в разы, а качество не сильно поднимается. Поэтому вот примерно... Ну, не знаю, можно и более, чем сказать, от 1 до 100 миллиардов параметров. 

S04 [01:19:52]  : вот здесь скорее там будет 1 100 млн. если 1 100 было миллионом. 

S03 [01:20:10]  : и здесь будет соответственно где-нибудь там 10 тысяч, 100 тысяч весов. потом для больших моделей в конце тоже лора, кстати, добавили. и, соответственно, сейчас присутствует вариант сверхбыстрого доучивания больших моделей, но и даже без лора есть вариант. когда мы доучиваем на конкретных 10-100 примерах большую модель, это занимает единицы секунд на самом деле. то есть сравнимо со сверх большими моделями, но при этом такие модели проще держать где-то в памяти, еще где-то им применить в некоторых задачах. Соответственно, знания у нас пришли в модель, приходят раньше, они приходят уже с большими моделями, большие модели уже достаточно, а вот для обучаемости, потребовалось делать сверхбольшие модели. 

S01 [01:21:32]  : Коллеги, еще вопросы или комментарии? Сейчас посмотрим, что у нас в ютубе. 

S03 [01:21:47]  : На самом деле тема достаточно узкая. Мы очень много времени на нее потратили. Если вопросов нету… Да, хорошо. 

S01 [01:22:03]  : Юрий, на самом деле было бы интересно, если бы в дополнение к результатам, которые вы будете рассказывать через пару месяцев, как-то формализовать на уровне формулы-эфмеры или акьюроси, чтобы можно было понять как, грубо говоря, можно это дело загнать в ноутбук и сопоставлять модели по метрике обучаемости. Хорошо. Спасибо, Юрий, за доклад. Александр, спасибо за комментарии, за критику. 

S03 [01:22:48]  : Соответственно, чем хочется заняться на самом деле, то есть сверхсложными задачами и, соответственно, добавить, как-то учесть их. Как минимум, их можно учесть вот здесь, в понятии качества, уровень знаний. 

S01 [01:23:09]  : А вы можете сформулировать хотя бы три сверхсложные задачи? 

S03 [01:23:13]  : Сверхсложная задача – это любая задача, которая одновременно требует 

S01 [01:23:20]  : Не любая, а практическая. То есть, практические задачи, за которые гипотетически хотя бы кто-то мог заплатить деньги. За решение которых гипотетически кто-то мог заплатить деньги, скажем так. 

S03 [01:23:33]  : Вот, пожалуйста, целый класс сверхсложных задач. Это вот напишите мне программный код для решения задач. То есть это не разовое действие. По тексту. По тексту, да. То есть мы текстом говорим, что система должна делать. Техническое задание даем. Система должна написать эту программу вместе с тестами, всем прочим. Оно все должно работать. Пример сверхсложной задачи. 

S01 [01:24:11]  : Есть еще более сложная задача, которую я, например, сейчас имею дело, это напишите мне код, но когда нет технического задания. 

S03 [01:24:21]  : Соответственно, первым делом напишите техническое задание. 

S01 [01:24:24]  : Да, то есть первое, напишите техническое задание. Вопрос, как системе написать техническое задание, если исходными данными являются разрозненные эксперты, разрозненная документация, разрозненные программные обеспечения. доставшееся в тяжелое наследство. Тут действительно нужен мультимодальный AGI, который в состоянии делать реверс инжиниринг кода, изучать техническую документацию, противоречивую, интервьюировать пользователей. 

S00 [01:25:06]  : Мне кажется, что здесь, наверное, будет по-другому. Потому что, скажем, кофейный тест можно попросить написать программу. Это очень сложная программа будет. И поставить ТЗ, и всё. Но если кто-то умеет это делать, он всё делает и без кода. То есть, скажем, если система интеллектуальная, так скажем, модель какая-то, сможет сделать, поставить задачу, сформулировать технические требования, техническую задачу написать и управлять группой программистов или сама писать этот код, то, скорее всего, этот код уже не нужен будет. Она сама это сможет сделать. Промежуточный артефакт в виде кода. 

S01 [01:25:54]  : Промежуточное задание не надо, не нужно сразу код. Даже и кода не нужно, а сама система является интерфейсом. 

S04 [01:26:17]  : То есть она сама может быть графическим координателем. 

S01 [01:26:22]  : То есть нам не нужно… Хорошо, Александр, тогда получается, что… Хорошо, тогда я разовью ваш тезис. Вот возьмем вашу субъективную семантику. Вы с помощью субъективной семантики решаете какие-то задачи в тех проектах, где вы работаете системным архитектором. Вопрос, если вы используете чат GPT для того, чтобы она помогала вам строить модели субъективной семантики, то зачем эти модели нужны? Потому что сама часть ГПТ может просто решать те задачи, которые вы хотите автоматизировать с помощью субъективной семантики. Зачем нужна субъективная семантика? 

S00 [01:27:04]  : Хорошо, поясняю. У меня есть два примера и два ответа. Первый ответ я возьму пораньше. Люди, занимаясь NLP, долго-долго писали программы и коды различные на разных языках для того, чтобы проанализировать текст. Сейчас эта большая языковая модель делает без программирования. То есть, если я напишу ей, выдели, пожалуйста, токены, она выделит, выдели мне, пожалуйста, поименованные сущности, она мне их выделит, и это не требует промежуточного этапа создания кода, который будет интерпретировать текст. Теперь отвечаю по поводу событийной семантики. Здесь есть два момента. Модель событийной семантики исполняется на движке. Вот сейчас я сижу, пишу ТЗ для модернизации движка, добавления функций движка. Это сложное техническое устройство, некое приложение, написанное на языке программирования. И это устройство интерпретирует довольно простые модели в несколько строчек, на которых описывается бизнес-логика. Так вот, проверено уже, что вот эти простые модели, которые можно выразить словами, я могу не закладывать движок на языке программирования, а сразу сказать chat.jpg. И он сразу их исполнит. Он их исполнит без наличия внутри кода этого движка. А зачем нужны сами модели? Потому что если мы не формализируем бизнес-процесс, не формализируем, мы его не проверим. Поэтому модели нужны, простые семантические модели, для проверки результата. То есть я задаю, скажем так, я словами говорю, нужно сделать то-то, то-то, то-то, то-то. Он мне пишет код на семантическом языке, читаемый. Я говорю, да, все правильно. Еще, скажем, даю тест. Проверь вот этот код. симпатически, другой модель проверила, все хорошо. И дальше, когда сам языковая модель будет исполнять этот код, выполнять бизнес-процесс сам, без программирования, он будет просто поэтапно это выполнять, другая модель будет по этому коду контролировать, правильно он все сделал. Это нужно для контроля, именно для того, чтобы избежать галлюцинаций. Язык написания спецификаций, который понятен человеку и понятен множество устройств, которые могут проконтролировать точность. Нужен язык для именно контроля и тестирования. 

S01 [01:29:50]  : Александр, а сразу, значит, да, вот я полностью поддержу, что вы сказали, я был приятно удивлен, что вы это сказали, хотя, наверное, мне не следовало удивляться. Может быть, я должен извиниться даже перед вами за то, что я удивился, но неважно. Вопрос. Вот если мы можем, используя вот эти большие вычислительные затраты и ресурсы, которые потребляет часть ГПТ для того, чтобы написать формальную спецификацию, получили формальную спецификацию, которую проверили, и она верна. Зачем нам еще раз или каждый раз, когда нужно отрабатывать конкретный бизнес-кейс или бизнес-ситуацию или технологический процесс по этой формальной спецификации, зачем нам использовать эти сочетательные мощности, когда мы можем ее использовать на дешевом субъективном движке или в каком-то другом интерпретаторе, если эта формальная спецификация не вашей субъективной семантики, а там чего-то другого. 

S00 [01:30:51]  : Понятно, то есть это совершенно законный вопрос, на который я ломаю тоже голову и сам себе задаю. Дело в том, что очень часто приходится вносить мелкие поправки. Очень часто в задаче какое-то нужно что-то добавить. И, скажем, я сейчас пишу какой-то бизнес-процесс, вот мне не хватает чего-то. Я стучу программисту, программист пиши мне вот еще одну функцию, которая мне будет вот это делать. Если это исполняет языковую модель, то я ей скажу, а вот здесь ты еще вот это учти. И, скажем, новый элемент спецификации вводится на лету. Вот если что-то нужно, а нам нужно, мне не хватает вот этого. Да, хорошо, вводим это, вводим это в контроль, все это исполняется. И момент, здесь действительно вы еще затронули, это момент вычислительных ресурсов. Ну, мы видим, что первые компьютеры обладали, конечно, очень минимальными ресурсами, а сейчас мы располагаем большими ресурсами, и я думаю, что если мы освободим все компьютеры, ныне существующие, от вычисления всех программ, которые сейчас написаны, все эти ворды, Все приложения, которые там миллионы, крутятся, и вместо этих приложений запустим единую модель, которая будет взаимодействовать между узлами, то эти ресурсы будут использованы для того, чтобы работала эта модель индивидуальная, скажем так, а не локальные приложения, которые устаревают через каждые полгода, год, и нужно заменять новыми, еще программистов привлекать. 

S01 [01:32:35]  : Александр, я все-таки немножко другое имею в виду. Забыли ворды, вот у вас есть конкретные бизнес-процессы, которые автоматизируется с помощью субъективной семантики. Вы попросили большую LLM-ку написать вам по вашим требованиям Неважно, как они выражены, некоторую субъективную программу, если это правильно… Субъективную модель. Субъективную модель, да. Вы, значит, ее проверили, она правильная. Потом в какой-то момент вы выяснили, что она где-то что-то не хватает, попросили ее улучшить, вам ее улучшили, но исполнять эту модель, так сказать, в продакшене, зачем вам для этого LLM? 

S00 [01:33:27]  : Нет, смотрите, Антон, я как бы, отвечая, немножко как бы перескочил, что сейчас, вот на данный момент, на данный момент, естественно, это будет программный клиент, то есть какой-то это будет движок, и он исполняет, и использовать модель не нужно. Но я говорю о будущем. Но в будущем, в будущем, я думаю, что этот вот движок, он не нужен будет. 

S01 [01:33:51]  : То есть, в будущем... То есть, смотрите, Александр, правильно ли я понимаю, значит, что в будущем это может выглядеть так? Значит, вы говорите в программе, значит, ну, я не знаю, так сказать, я хочу, чтобы ты сделала мне ремонт в квартире. Скажи мне, что ты будешь делать? Программа говорит, сначала я обдеру старые обои, потом наклею новые. То есть, вы убеждаетесь, что она не будет клеить новые обои поверх старых, что она сперва берет старые, и вы говорите, окей, делай. То есть, вы не загружаете программу содрать обои, наклеить новые в робота, в событийный движок по производству ремонта, а вы вот этой вот программе по производству ремонта, которая имеет вам То есть, вам рассказать то, что она будет делать, как живой ремонтник, которого вы, прежде чем нанять, спрашиваете о том, как он будет делать, и если вы понимаете, что он неадекватен, вы его не подряжаете. Вы ей тогда доверяете и даете ей карт-бланш, правильно? 

S00 [01:35:02]  : Ну да, есть спецификация конкретная, по которой она мне выдает алгоритм своего действия. Я могу зарядить тестовую модель, которая будет контролировать это все пошагово, и я буду уверен, что она выполнит все правильно. Сейчас нам нужен еще движок программный, но, скорее всего, в будущем этот программный движок нам не нужен будет. Как мы, скажем, вот мы уже представить себе программу, конкретную программу на компьютер, загружаемую для перевода текста, уже бессмысленно. Уже нет таких программ, их не будет скоро. Или, скажем, еще есть программы спеллчекеры, но их тоже скоро не будет. И куча многих программ, они будут все уходить постепенно в большую модель, которая их будет выполнять. Но единственное, что нам нужно – систему контроля. То есть систему ввода. язык все равно человеческий будет ввода, но все равно после того, как я про языком проговорил, она мне должна выдать что-то проверяемое не на человеческом языке, но приближенном к человеческому языку. И действительно, если вот мой движок сейчас, я прекрасно представляю, что какие-то семантические примитивы я туда еще не ввел. Я говорю, вот программист, мне нужно еще что-то добавить, еще что-то добавить. Если это будет модель большая, то она на лету будет добавлять. Она говорит, о, хорошо, я добавил такое отношение. Я говорю, хорошо, протестирую, как оно действует. Да, вот так вот действует, правильно. В таких моментах она будет говорить, да, вот так, все, хорошо, мы закрепили. Дальше, когда я говорю, вот это сделай, ты будешь делать вот это по такой-то схеме, и вот такая-то другая тестирующая модель будет проверять, правильно ли ты все сделала. И тогда сложная задача. То есть мы, решая сложную задачу программирования, мы ее же и убили решением, получив большие модели. Сама задача программирования уходит как сложная. 

S03 [01:37:09]  : Я бы так это сформулировал. То есть вот был у нас язык ТЗ. он был приближе к человеческому. вот у нас наша шкала и этот язык уже приближенный к коду. значит здесь был код у нас. вместо этого вы предлагаете сделать единый язык 

S01 [01:37:43]  : Вы язык описания семантики, как я понял, просто для примера взяли? 

S00 [01:37:51]  : Да, язык описания деятельности. 

S01 [01:37:57]  : Я говорил про событийную семантику, здесь чисто для того, чтобы проще было общаться с Александром в контексте его деятельности. Например, сейчас, в контексте моей деятельности, чем я сейчас занимаюсь. Это написание программного обеспечения для автоматизации технологических процессов на специальных языках линейки стандартов EC61131, там 5 языков всяких разных. И они исполняются программными либо аппаратными контроллерами. Соответственно, возникает гипотеза, что мы, если мы, да и соответственно эти программы пишут программисты. Соответственно, на первом шаге мы можем попросить эти программы писать чат GPT, большую модель по исходным данным. характеристикам технологического оборудования, которым нужно управлять, верифицировать эти программы, а потом эти верифицированные программы загружать в эти же самые промышленные контроллеры. А в какой-то момент, когда стоимость LLM будет сопоставима со стоимостью вот этих вот контроллеров, которые сейчас исполняют технологические программы, Мы сможем сделать следующее. Мы сможем просто сказать, генерить эти программы не для загрузки в контроллер, а только для верификации того, что та логика, которую будет исполнять языковая модель, она адекватна тех условиям и поставленным задачам, а управлением будут заниматься не контроллеры, а сама LLM на соответствующем оборудовании. То есть для управления мы будем брать не контроллеры для исполнения этих спецификаций, на которых пишется программа для СУТПА, оборудование с соответствующим набором видеокарт, чтобы там вместилась эта лелемка, которая будет решать те же самые задачи. А мы время от времени будем спрашивать у нее, правильно ли она понимает поставленную задачу. Александр, я правильно выразился? 

S00 [01:40:03]  : Да, здесь можно привести пример еще такой. Смотрите, вот у нас сейчас мобильник в руке, там десятки приложений. Десятки специализированных приложений, а то и сотни написанных разными разработчиками. Но мы прекрасно понимаем, что уже часть из них мы можем передать на исполнение большой модели. И, скажем, через лет 5-10 у нас пропадут отдельные приложения, а все, там, скажем, написать письмо, отправить что-то, получить какие-то данные, проиграть какую-то музыку, все это может выполнять, управлять одна моделька. Она может быть не локальной, может быть распределенной, но именно как программирование, конкретное пошаговое программирование функции, оно отпадет. Мне так кажется, по логике развития. Вот у нас сейчас есть два примера больших моделей. Это языковые и графические герметичные модели. Они по сути собой сейчас заменили целые классы программных продуктов. То есть графических редакторов и различных программ обработки текста и работы с текстом. Они заменили собой полностью. И это будет происходить все с большим количеством задач, которые будут формулироваться языком, пониматься языком, писаться на каком-то формальном языке для контроля, потому что полностью отдать сложно в такой вот модели, и контролироваться исполнением. Этот язык, описание деятельности какой-то вполне возможно без программирования уже обойтись. программирования, уйдет самый-самый глубокий слой существования этих моделей. но код такой вот видимый, он скорее всего пропадет. 

S03 [01:42:01]  : смотрите, тут есть нюанс с этой схемой. я ее чуть-чуть усложню. вот и здесь и здесь тоже есть какой-то код. но вот на этом уровне код управляющий код на этом уровне код уже там устройства конкретного, код исполнительного устройства, который этот код выполняет. То есть это язык высокого уровня, а здесь приближенный к устройству код низкого уровня. Так вот, дело в том, что если мы Даем возможности по транслятору. Штука, которая переводит из одного языка в другой, будем называть ее транслятором. Можно компилятором называть. Это интерпретатор. Интерпретатор – это вид транслятора. Транслятор пишет в начале низкоуровневые инструкции. а потом исполнитель их исполняет, а интерпретатор – это система, которая эти инструкции без промежуточного кода сразу выполняет. Проблема в чем? Все сходятся к мысли, что интерпретаторы медленные, интерпретаторы требуют много ресурсов. Трансляторы в этом плане лучше. И вот если люди делают бизнес, то происходит та же самая ситуация. Они нанимают десяток сверхумных людей в пиццерии, чтобы они там сами разобрались, что там делать и как клиентов лучше обслужить. И платят каждому по миллиону рублей в месяц. Вместо этого они нанимают людей на специальную работу, на специальные должности, дают им конкретные инструкции. Соответственно, люди просто как исполнители максимально не гибкие. Чуть-чуть гибкости нужно, чтобы адаптироваться к условиям труда, но гибкости мало. Эта система, она экономнее с точки зрения расхода ресурсов. Именно поэтому эта система используется. Поэтому эти системы никуда не денутся, этот способ в принципе более выгоден. Поэтому почти всегда выгодно таким образом действовать. 

S00 [01:44:42]  : Есть один момент, я сейчас буду говорить именно про свою систему, но скорее всего она перекладывается и на различные другие языки, другие возможности описания деятельности. Вот сейчас, скажем, есть событийная семантика, в которой событие описывается вполне конкретным форматом, вполне конкретными полями. И дальше вступает сначала программа высокого уровня, которая пытается интерпретировать, а еще низкий уровень, очень низкий уровень, который интерпретирует эту программу, о чем Юрий говорил. Тратишь огромное количество ресурсов, вместо того, чтобы просто учесть, вот это событие есть, значит выполняю это событие. Если событие есть, то выполняю это событие. Если вот эти события и эти условия выполнять, то выполняю это событие. То есть совершенно элементарные операции, совершенно элементарные операции требуют огромной нагрузки компьютера. почислительных мощностей для того, чтобы перевести это сначала в ассемблер, потом перевести на уровень кодов процессором. И я предполагаю, что в ближайшем будущем вот этот разрыв будет ликвидирован. Процессоры станут приближены не к вычислениям, а к бизнес-логике. То есть процессор будет унифицирован для выполнения именно того кода, той семантики, той спецификации, с которой мы будем общаться с машиной. 

S01 [01:46:22]  : Александр, извините, но тут я слышу противоречия. Только что вы говорили, что мы заменим интерпретацию семантики, интерпретацию лемок, и тогда нам нужно будет оптимизировать процессоры не под семантику, а под параллельные вычисления. А сейчас вы говорите, что все-таки нужно оптимизировать под событийную семантику. И я, честно говоря, склонен согласиться все-таки с последним вашим тезисом. Почему? Потому что, к примеру, в том проекте, которым я сейчас занимаюсь, мы там говорим о том, что Для того, чтобы удовлетворять требованиям производительности, нам действительно нужно уходить от интерпретации к компилируемым программам, как один вариант. А если мы будем то же самое делать с помощью LLM, то производительность будет еще ниже. То есть, как сказал Юрий, вопрос времени и скорости реакции в бизнесе важен. И если стоимость обработки одного запроса с помощью интерпретатора будет стоить 1 цент, с помощью откомпилированного кода будет стоить 0,1 цент, а с помощью лилемки будет стоить доллар, то очевидно выбор будет не в сторону лилемы. 

S00 [01:47:58]  : Понятно. Я не приснёс последнюю фразу, что речь, скорее всего, и должна идти о переводе и больших моделей на какую-то другую специфику, более приближенную к спайковым моделям, когда сами процессоры будут выполнять... И на этих процессорах можно будет построить очень большие модели, которые будут выполнять то, что современные модели делают, но без тензорного пересчета, без пересчета этой большой математики. И тогда как бы настыкуется и верхний уровень семантические описания бизнес-процессов, и нижний уровень просчета реализации интеллектуальных моделей, которые будут интерпретировать эту семантику. 

S03 [01:49:00]  : Это называется избавление от горлышка фон Неймана. Да, именно это я имею ввиду. 

S00 [01:49:06]  : Это флоу-архитектура и уход от фон Нейманской архитектуры. 

S03 [01:49:14]  : Оборудования хорошего для ухода от фан-мейновской архитектуры нет, хотя есть попытки к чипу добавлять сбоку элементик обучаемый, который будет событийный. То есть, у Intel есть такие эксперименты. 

S00 [01:49:34]  : Тут мы как бы специализированный чип добавляем в процессы. 

S01 [01:49:40]  : Коллеги, я предлагаю на этой позитивной ноте завершить сегодняшний семинар. Тем более, что через две недели тема субъективности, тема семантики будет Александром продолжена. Было бы здорово, если бы то, про что мы сейчас говорили, было бы там затронуто, если это будет местно. Юрий, спасибо большое, Александр, спасибо за дискуссию, Владимир, Елизар, спасибо за участие. Всем до свидания, всего доброго, до новых встреч. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
