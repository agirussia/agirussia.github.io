## 13 июля 2023 - Основные направления развития фундаментальных моделей машинного обучения на пути к AGI - Сергей Марков (директор Управления экспериментальных систем машинного обучения SberDevices) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/XOlMOBZsF24/hqdefault.jpg)](https://youtu.be/XOlMOBZsF24)

Суммаризация семинара:

Семинар был посвящен обсуждению актуальных направлений в развитии фундаментальных моделей машинного обучения. В частности, говорилось о мультимодальности и перспективах её развития. Участники семинара поделились опытом работы с глубокими нейросетями, а также обсудили проблемы, связанные с ограниченной фактологической точностью моделей, что может привести к генерации галлюцинаций.

В вопросах, касающихся сознания и его возможного возникновения в искусственном интеллекте, участники акцентировали внимание на мультиагентной среде обучения как на пути к созданию систем с рефлективной психикой. Однако было подчеркнуто, что современные фундаментальные модели машинного обучения далеки от человеческого сознания и что вопрос сознания у ИИ ещё требует глубокого изучения.

Кроме того, были затронуты темы интеграции новых модальностей, интерпретируемости моделей, а также вопросы обработки текста и возможности создания иерархической суммаризации больших литературных произведений. Участники также обсудили перспективы развития host AI, где вычислительные ресурсы будут распределены между кластерами и клиентскими устройствами.

Семинар завершился приглашением на будущие мероприятия, включая круглый стол по блокчейну, и обсуждением последних исследований и разработок в области машинного обучения и искусственного интеллекта.







S01 [00:00:04]  : Коллеги, всем добрый вечер. У нас сегодня снова в гостях после долгого перерыва Сергей Марков, который, как никто в Сбербанке, хорошо и много знает о глубоких нейросетях и о том, как они могут нас привести к HI. Если могут, то как. И, Сергей, я с удовольствием предоставляю вам слово. Пожалуйста. 

S00 [00:00:27]  : Всем привет. Спасибо, Антон. Но я, надо сказать это, все-таки, наверное, не самый главный специалист Бирбанки по глубоким сетям. У нас достаточно много специалистов, продвинутых в этой области. Я, честно говоря, в большей мере являюсь таким не исследователем сейчас, а скорее таким менеджером от науки, то есть я руковожу большим исследовательским подразделением, в котором сейчас около 150 человек работает и занимается глубокими нейросетями. Я, в общем-то, сам там до сих пор что-то делаю руками, но все-таки по большей мере занимаюсь сейчас представительской и административной работой, но тем не менее, в общем-то, я в курсе того, что происходит в этой сфере, вот я сегодня вам расскажу как раз о том, что у нас происходит в таком мейнстримном русле коннекционизма, вот, и начну я, конечно, с того, что, ну, краткое введение в слоноведение в двух томах, вот, но не в двух томах, конечно, в паре слайдов, но просто чтобы но как мы все понимали в какой мы сейчас ситуации оказались еще последние 10 лет часто называют новой весной искусственного интеллекта есть вообще такая вот забавная схема о том, что якобы в области искусственного интеллекта существуют какие-то зимы, потом весны, потом снова зимы и так далее. На самом деле это, конечно, довольно далеко от действительности, все это гораздо сложнее. И если уж говорить о весне, то, наверное, пора бы уже говорить о том, что наступило лето, потому что сегодня модели машинного обучения являются частью огромного количества продуктов и сервисов, которые стали частью нашей жизни. Каждый раз, когда вы делаете фотографию при помощи своего мобильного телефона, Она обрабатывается тоже при помощи глубокой нейросети, которая работает прямо там на вашем устройстве. Каждый раз, когда вы сталкиваетесь с современными системами распознавания или синтеза речи, например, или компьютерного зрения, чаще всего подлежащими моделями являются как раз глубокие нейросети. опять же, мы говорим глубокие нейросети, ну и у некоторых людей может создаться впечатление, что это какой-то такой ноу-хау, которое появилось в начале десятых годов, и раньше такого не было, на что там кто-нибудь Юрген Шмидтхубер выйдет на сцену и скажет, что у Ивахненко шесть слоев в нейросетях было еще 60-е годы, поэтому с чего бы-то мы решили, что у нас глубокие нейросети только сейчас появились. Но на самом деле, конечно, здесь мы имеем дело с таким эффектом, и технологическим, и медийным. Медийным в том плане, что многие эффектные демонстрации возможностей глубоких нейросетевых моделей, они привлекли к себе внимание общественности, внимание прессы, внимание инвесторов, внимание, естественно, большого количества исследователей. Но это эффект не чисто медийный, потому что подлежащие успехи действительно есть. Очень многие задачи, которые на протяжении полстолетия мы не умели эффективно решать при помощи методов машинного обучения, искусственного интеллекта вообще, они оказались за последние 10 лет решены на человеческом или даже сверхчеловеческом уровне. И если коротко, то причиной этого, причиной такой вот плотности успехов, наверное, начиная с начала десятых годов, является то, что соединилось действие сразу трех очень важных факторов. Первый фактор – это действительно новые модели, но мы говорим глубокие нейросети, на самом деле речь идет скорее о Ну, таких... локально связанных сетях, которые мы умеем собирать из единообразных кирпичиков, из параметризованных слоев, потому что глубокие сети с большим числом слоев действительно были еще в 60-е, локально связанные сети как концепция довольно подробно описанного Розенблата, например, в его принципах нейродинамики. К началу 10-х годов сформировалась концепция нейросеток, которые мы собираем из параметризованных слоев, это в первую очередь сверточные нейросети на тот момент, но некоторые строительные кирпичики были изобретены тогда помимо сверточных сетей, например, долгая краткосрочная память Шмидтхубера, сама вот эта вот идея добавления вентилей неких, модель была серьезным шагом вперед по сравнению с сетями Элвана и Джордана. ванильными так называемыми рекуррентными сетями. Опять же, к началу десятых годов появились идеи skip connections, идеи как правильно инициализировать сети с большим числом слоев, и это на самом деле немаловажная вещь. Словом, с точки зрения алгоритмов и методов действительно появилась целая большая плеяда методов, которые стали одним из трех китов, которые были факторами наступления этой самой новой весны искусственного интеллекта. Второе – это, конечно, объемы данных цифровых, которые человечество накопило, и понятно, что Для того, чтобы обучать глубокие нейросети, нужно много данных. Это модели, которые обладают большим аппетитом к данным. И в 70-е, скажем, практически исследователям приходилось вручную заниматься этой оцифровкой. Розенблат пихал в рецептивное поле перцептрона руками фотографии мужчин и женщин для того, чтобы научить сетку отличать мужские фотографии от женских. Ну а сейчас, в общем-то, благодаря развитию интернета, благодаря развитию социальных сетей, благодаря, в принципе, развитию технологии оптического распознавания, благодаря промышленной автоматизации, которая формирует большие промышленные базы данных. Мы получили действительно внушительные объемы данных, которые мы теперь можем использовать для обучения нейростей. И вообще говоря, количество данных цифровых, которыми человечество обладает, растет экспоненциальными пока что темпами, по крайней мере, как показывают исследования. Каждые два года примерно объем нашего цифрового следа удваивается. В общем, это действительно внушительные объемы, которые нам тут очень пригодились. Ну и третье, но не менее важное, это, конечно, рост вычислительных мощностей. Причем здесь, опять же, мы находимся на этапе такого роста, напоминающего экспоненциальный участок до сих пор. Вот, но здесь дело даже не только в поступательном росте вычислительных мощностей человечества, но дело и в появлении архитектур, которые больше подходят для коннекционистских моделей, и появление тензорных процессоров, конечно, и в виде доступных тензорных процессоров типа видеокарт пользовательских. Вот, это все позволило существенно расширить узкое горлышко фон Неймана и таким образом получить дополнительный буст при обучении глубоких сетей. Вот эти три фактора, они в принципе привели к тому, к чему привели. Там можно называть разные события, которые стали спусковым крючком вот этой новой коннекционистской весны искусственного интеллекта. Ну, часто говорят, что вот AlexNet, дескать, на конкурсе по распознаванию изображений из ImageNet победила. Но если мы посмотрим на AlexNet, которая, кстати, не называлась так, когда она была создана, она называлась Supervision, Она в общем-то не была чем-то революционным сама по себе, то есть это не была первая сетка, которую учили на GPU, это не была первая, тем более глубокая нейросетка. Это даже не была первая нейросетка, которая продемонстрировала экстремально высокое качество распознавания изображений, потому что еще в 2011 году Аспирант Шмидтхубера Черешан победил в соревнованиях по распознанию дорожных знаков тоже с глубокосверточной сеткой, причем там был сверхчеловеческий уровень достигнут еще в 2011 году. Ну там картинки маленького разрешения были достаточно, но вот тем не менее учили это тоже при помощи GPU. То есть самой по себе какой-то такой радикальной новизны в AlexNet не было, но это была демонстрация зрелой технологии, плюс это были действительно масштабные соревнования, наверное, не сопоставимые со всеми теми соревнованиями по распознаванию образов, которые существовали до того времени. Вот. Ну, так или иначе, эта история привлекла большое внимание, и здесь одновременно произошли технологические прорывы в других областях, в области обработки естественного языка, благодаря развитию вот этого стека с векторными представлениями word-to-vec в голове и так далее, и так далее, векторные имбеддинги. Опять же, Word2Vec не была отнюдь первой системой, которая сопоставила словам какие-то векторные представления на основе статистической лингвистики. Такие модели в группе Benjo разрабатывались еще в начале нулевых годов, и в 2003 году была опубликована фундаментальная работа, где идея таких векторных вложений была проанализировано и были первые удачные эксперименты поставлены. Но опять же, так или иначе, World2Vec стало такой популярной, удобной утилитой для того, чтобы построить мостик между миром символьным и миром коннекционистским. Ну и вот за эти 10 лет, которые там минули с 2013 года или там 2011 уже с 2012, на самом деле было предложено много новых интересных моделей и методов. То есть понятно, что с одной стороны шло масштабирование моделей, увеличения вот но на самом деле были предложены и довольно интересные новые подходы архитектуры вот ну и самое наверное важное событие последнего десятилетия это появление архитектуры под названием трансформер в семнадцатом году но опять же не на ровном месте эта архитектура появляется это развитие идеи механизма внимания предложенного в четырнадцатом году еще богдановым для рекуррентных сетей. Ну вот в 2017 году появляется эта революционная идея, что давайте мы механизм внимания будем использовать в отрыве от рекуррентной сетки, давайте построим такие многослойные сети из блоков внимания, внимание над вниманием, над вниманием, над вниманием. ну и в чем было конечно преимущество большой этой модели это то что она тоже развязала одно важное узкое горлышко теперь при обработке длинных последовательности мы стали обрабатывать по сути все элементы последовательности параллельно вот что позволило нам извлечь пользу из масштабного параллелизма появление трансформеров, в общем-то, привело к той гонке гигантских нейросетей, насчитывающих сегодня уже сотни миллиардов и триллионы параметров. Это и такой неожиданный ренессанс больших машин, суперкомпьютеров, потому что сегодня снова мы оказались в парадигме, напоминающей времена мейнфреймов, когда Час вычислений на суперкомпьютере стоит гораздо дороже, чем время людей, которые работают с этой машиной. Словом, вот такое интересное действие – законное отрицание и отрицание. Ну и с 2017 года на основе вот этого самого блока появляется много разных архитектур, много популярных сетей, каждая из которых там была целым большим событием в начале в мире обработки естественного языка, потом и в других отраслях искусственного интеллекта. Ну и вот там все, наверное, слышали про BERT, про GPT-2, про GPT-3 и так далее. Вот. И опять же, те же самые подходы, они легли в основу таких громких проектов уже 20-х годов. DALI, CLIP, GLIDE, T5, Perceiver, WUDAO, ну и много-много разных других сеток, включая chat-GPT, про который мы сегодня немножко тоже поговорим. Что еще можно здесь отметить из важных тенденций, которые влияют вообще на развитие современного коннекционистского мейнстрима? Про эффективный параллелизм трансформеров и горизонтальное масштабирование я здесь уже несколько слов сказал. Но здесь нужно несколько моментов отметить, принципиально важных. Во-первых, на протяжении нескольких лет во многих презентациях часто нам рисовали график с экспоненциальным ростом числа параметров нейросетей. И в какой-то мере эта тенденция давлела над всем конъюнкционистским мером. миром, и было такое мнение, что вот сетки-то у нас масштабируются экспоненциально. Но на самом деле там был такой момент определенного головокружения от успехов, связанный с тем, что Ну хорошо, количество параметров в сетке мы увеличиваем, а как должно изменяться количество данных для обучения этой сети, и как должно количество компьютеров, да, количество вычислений при обучении этой сетки меняться. И, в общем-то, ориентиром была работа 2020 года, написанная специалистами из OpenAI. А первый автор там Каплан, по-моему, если мне память не изменяет. И вот это была первая такая, наверное, большая серьезная экспериментальная попытка установить закон о масштабировании этих сеток и понять, каким образом мы должны увеличивать количество данных, количество шагов обучения. Но оказалось, что По всей видимости, выводы были поспешны. В этой статье, сделанной в 1922 году, в мае появляется исследование коллег из DeepMind. Это работа, посвященная такой популярной теперь нейросетке под названием «Шиншилла». Собственно говоря, на этой архитектуре и ставились опыты. И что было принципиально важным выводом авторов этой работы, то что на самом деле количество компьютера, количество шагов обучения, ну и соответственно данных используемых при обучении, на сетке растет нелинейное количество параметров. Вот эта нелинейность, она в общем, ну понятное дело, что при маленьких размерах сетки ее труднее заметить, но чем дальше, тем вот этот нелинейный член больше вклад дает. Авторы работы пришли к выводу, что топовые модели по числу параметров на тот момент, это GPT-3 со 175 миллиардами параметров и Turing NLG с 540 миллиардами параметров, это сетки недоученные, их нужно было учить дольше, чем они проучились. Ну и в качестве такого доказательства правильности своих выводов они обучили сетку под названием Shinshila с 79 миллиардами параметров, которая на подавляющем большинстве тестов продемонстрировала свое превосходство на GPT-3 со 175 миллиардами параметров. Поэтому экспоненциально растет на самом деле не число параметров в сети, экспоненциально растет количество вычислений, вычислительных затрат на обучение этих сетей. И это тогда понятным образом коррелирует у нас с ростом вычислительных мощностей, которые тоже растут примерно такими же темпами. Здесь все понятно. Сетки увеличиваются, затраты на их обучение просто потому, что в рамках одного и того же бюджета количество вычислений удваивается каждые два года примерно. Это интересный такой результат. На самом деле с тех пор появилось много сеток, которые чуть меньше, чем GPT-3, но лучше. Опять же, что еще интересного про масштабирование? Пока что очень важная работа вышедшая в 2022 году, посвященная набору тестов, который сейчас известен под названием Big Bench. Биг – это, собственно говоря, не только большой, но и акроним Beyond the Imitation Game, то есть сверх, так сказать, превосходя, следуя, вслед за игрой в имитацию Тюринговской. На самом деле это очень большой набор тестов, почти Около 300 научных коллективов туда, собственно говоря, свои наработки отправили. И это на сегодняшний день такая самая большая коллекция всяких разных тестов для языковых моделей, которые позволяют неплохо оценить их способности, в том числе в сравнении с людьми. Ну и увидеть, что, конечно, С одной стороны, прогресс действительно очень большой, с другой стороны, по среднему уровню до людей они не дотягивают пока что. Есть некоторые классы задач, которые эти модели решают заметно хуже, чем средние люди. Но есть и задачи, которые они решают лучше людей, справедливости ради. Значит, что интересно, то, что метрики, в общем-то, растут пропорционально логарифму от компьютера, затраченного на обучение моделей. Ну и, в общем-то, вот это масштабирование, оно не демонстрирует пока что каких-то признаков уменьшающейся отдачи. IQ, условно говоря, сетки, она растет как в случае трансформерных архитектур, таких наиболее распространенных. Оно ведет себя таким образом. Причем, что интересно, очень мало зависит от конкретной архитектуры трансформерной сети. Самый основной, самый сильный фактор – это compute. архитектурные ухищрения каких-то существенных в плане в пределах порядка не дают все-таки преимущество. Или дают, но тест недостаточно чувствительный, чтобы их выявить. Еще про большие сетки. Помимо монолитных сеток, появились сетки, реализующие подход Mixture of Experts, но я сегодня про них немножко скажу отдельно. Здесь я единственное что хочу зафиксировать, что вот сетки типа Switch C нельзя сравнивать по с монолитными сетками просто по числу параметров. Нельзя сказать, что SWITCH-C это тоже такая же сетка, как GPT-3, но просто у нее 1,6 триллиона параметров. На самом деле нет. Про это сегодня поговорим отдельно. При этом наши представления пока что таковы, пока что сетки, ну и, соответственно, машины, которые используются для их обучения инференса, они человеческому мозгу пока что уступают. Вот, то есть, если прикинуть, посмотреть на человеческий мозг как на вычислительное устройство, то там примерно оценочное количество там двоичных логических операций, которые происходят внутри биологической нейросети, превышает 10-21 степени в секунду. И это важный момент. В принципе, это говорит нам, что если наши вычислительные мощности будут расти с такой же скоростью, как росли до сих пор, то где-то там к концу 20-х годов у нас железки будут, которые по брутто-производительности будут с человеческим мозгом сравнимы. Но есть нюансы. Есть нюанс, заключающийся все в том же пресловутом бутылочном горлышке Хонеймана. И при симуляции биологических сетей мы сейчас из-за проблем вот этого бутылочного горлышка на нынешних архитектурах получаем замедление тысячекратное примерно. Поэтому здесь вопрос, сможем ли мы к тому моменту создать архитектуру, которая развяжет это пуское место. И понятно, что по энергопотреблению человеческий мозг пока совершенно недостижим, там всего 20 ватт. Вот здесь есть вот эта оценка на самом деле, количество бинарных операций в секунду, которые мозг осуществляет. Довольно приблизительная, но она основана на современных представлениях о том, с какой точностью нам нужно моделировать биологическую систему для того, чтобы в ней те же самые макроскопические эффекты проявились и те же самые психические феномены были продемонстрированы. Если детали интересуют этих расчетов, то потом отдельно можем обсудить, могут показать. Что еще интересного? Революция произошла изначально в области обработки естественного языка, но строго говоря, Этого достаточно для того, чтобы с формальной точки зрения сделать AGI. Если у вас есть очень умная сетка или модель какая-то, которая умеет продолжать текстовую последовательность, еще любую эффективно вычислимую задачу, И тем более любую интеллектуальную задачу можно представить в виде задачи продолжения последовательности символа. Как это доказать? Формально, например, таким образом, что если вы можете при помощи естественного языка объяснить, что такое лямбда-счисление или что такое машина Тьюринга, можете, очевидно. Таким образом, дальше вы можете использовать этот формализм для того, чтобы описать условия любой интеллектуальной задачи, любой вообще эффективно вычислимой задачи. Вот, ну то есть если вы хотите там, не знаю, машинный перевод выполнять, то вы просите продолжить текст там яблоко-эппл-стол-тейбл-груша- и если ваша модель этот текст сможет продолжить, то она выполнит задачу перевода. Если вы хотите, не знаю, шахматы, ну значит вот вы словами естественного языка описываете позицию, там дана шахматная позиция, двоеточие, ладья А1, конь В1 и так далее, точка с запятой, наилучший ход в этой позиции, двоеточие. Ну и если моделька сможет этот текст продолжить, то в зависимости от того, насколько хорошо она это сделает, настолько хорошо она играет в шахматы. Понятно, что не всегда, не со всеми модальностями удобно работать таким образом. Например, для картинки вам придется как-то цвета каждого пикселя, видимо, описывать или еще какой-то способ кодирования использовать. Но это все не всегда удобно просто. То есть формально это работает, но не всегда удобно. Поэтому плоды революции в обработке естественного языка, они в первую очередь распространились на те отрасли искусственного интеллекта, которые связаны с обработкой чего-то, что на текст похоже. То есть обработка программного кода, биоинформатика, в которой есть ДНК, РНК, последовательности и так далее, химия, в которой есть структурные формулы, музыка, в которой есть нотная грамота, ну и так далее. Все, что хорошо описывается чем-то прям похожим на текст в своей структуре. Сегодня трансформеры пришли, наверное, уже практически во все отрасли. искусственного интеллекта, то есть и изображения тоже обрабатываются трансформерными моделями, иногда используются какие-то подсети энкодер и декодер, но тем не менее ядром является именно трансформер. В связи с трансформерной революцией произошел определенный такой сдвиг парадигмы в машинном обучении. Какие здесь основные сдвиги парадигмы? Во-первых, мы перешли от создания узкоспециализированных моделей, которые обучались строго под решение какой-то одной интеллектуальной задачи, перешли к моделям фундаментальным. Что такое фундаментальная модель? Фундаментальная модель – это модель, которая в начале, на стадии предобучения выучивает какие-то представления, И затем может уже дообучаться или непосредственно использоваться для решения широкого спектра интеллектуальных задач. Ну вот в случае такого самого простого примера, модели семейства GPT, например, GPT-2 или GPT-3, в чем основная идея? Мы берем много-много текстов, собранных в интернете, просто сканируем все сайты подряд, мы при желании подкладываем что-то еще руками туда, Википедию, я не знаю, то, что мы хотим, чтобы там точно оказалось. Дальше мы учим модельку, разбиваем эти тексты на токены при помощи код-токенизатора. Это какой-то символьный алгоритм, который составляет нам словарь токенов. Для простоты давайте считать, что слова. вот все эти тексты разбиваются на слова условно говоря и мы учим сетку предсказывать следующее слово по предыдущим вот там gpt3 длина рецептивного поля 2048 токенов 2047 предыдущих токенов, мы 2048 токен пытаемся предсказать, то есть получаем распределение вероятностей для каждого токена из словаря того, что этот токен будет являться продолжением нашей последовательности. Благодаря тому, что данные очень разнообразные, которые мы используем в обучении, а сетка очень большая, Значит, она выучит какие-то внутренние представления для того, чтобы наиболее эффективно решать вот эту задачу. И затем оказывается, что эти внутренние представления, они очень хороши для того, чтобы значит, решать другие задачи в зависимости от обработки естественного языка. Это могут быть и задачи классификации текстовых последовательностей, это могут быть и задачи просто генерации, ну и так далее. Сентимент-анализ, интент-анализ и так далее. Машинный перевод, все что угодно. Вот. Вот эта парадигма, она получила название самообучение, self-supervised learning, потому что мы на самом деле как бы вручную не размечаем эти данные для обучения, мы фильтруем их при помощи автоматических алгоритмов, просто чтобы избавиться от мусора. И дальше мы используем саму внутреннюю структуру данных как некую псевдоразметку. То есть вот у нас каждый прецедент обучающей выборке, значение факторов – это предшествующие слова, значение целевой. Предсказываемые переменные – это следующее слово, которое мы предсказываем. Мы вручную как бы не сажали разметчиков и не заставляли их писать правильные ответы для модельки. Мы просто использовали вот эту структуру текста для того, чтобы автоматически получить значение факторов и значение свободной переменной, которую мы предсказываем. Опять же, сдвиг парадигмы от однозадачных моделек к моделькам многозадачным и от одноязычных моделек к моделькам многоязычным. Еще важная тенденция – это развитие направления мультимодальных мы, конечно, хотим, чтобы наша моделька могла не только с текстом работать, но и с другими модальностями, желательно как минимум с изображениями, а в идеале еще и со звуком. При обучении модели, опять же, мы вынуждены здесь переходить от старой парадигмы с параллелизмом только в данных, когда у нас есть просто много-много мини-батчей, и мы, значит, там параллельно на узлах суперкомпьютера, ну или там чего у нас есть, обрабатываем эти мини-батчи, потом усредняем как-то градиенты, да, эти градиенты пробрасываем опять на узлы усредненные. Вот, а здесь у нас уже в случае больших моделей оказывается, что и сами модели не вмещаются в память одного тензорного вычислительного устройства, мы вынуждены саму модель разбивать между разными узлами, а вот в случае моделек с сотнями миллиардов параметров у нас получается, что и в память одного узла не вмещается, то есть не только в память одной карты, но и в память целого узла dgx модель не вмещается, то есть мы вынуждены слои модели раскидывать, по сути, между разными узлами, то есть это, конечно, более сложный формат параллелизма, ну и венцом творения здесь являются современные воплощения подхода mixture of experts с слоями разреженной активации, где мы вообще можем какие-то в теории даже гетерогенные использовать кластеры, потому что градиенты, значит, носят очень разреженный характер, и мы можем пробрасывать часть градиентов в разные подсети, которые расположены на разных узлах. Важная штука, про которую спорят последний год, это эмержентность. Есть она или нет. Под эмержентностью, напомню, понимают такое явление, когда при увеличении количество параметров моделей или, если желаете, преувеличение числа компьютера на обучение модели. До какого-то порога наши модельки не умеют хорошо решать какие-то задачи. Потом, при превышении некоторого порога, происходит такой фазовый переход, и модельки очень быстро начинают решать эти задачки на сверхчеловеческом уровне. вот ну на самом деле здесь вопрос ну там типа как может быть можно перенормировать пространство да и эффект пропадает да и начинает казаться что все-таки нету там скачка такого резкого но есть на эту тему споры есть работы отстаивающие одну и другую позицию Но тут, наверное, важным является то, что в принципе в процессе такого быстрого увеличения размера моделек у нас скопилось довольно много задач, которых буквально за последние несколько лет мы действительно пробежали очень быстро путь от random guess уровня до каких-то там околочеловеческих или сверхчеловеческих метрик. Вот, ну и важный еще сдвиг парадигмы происходит в разработке программного обеспечения, про это много достаточно говорят, про, там, Copilot, и о том, как ChatGPT хорошо код пишет и так далее, вот, но понятное дело, что здесь мы имеем дело с такой очередной революцией, уже множество их разработки программного обеспечения происходило. Когда-то программисты в 40-е и 50-е годы самостоятельно дырочки в перфокартах пробивали, потом появилось программирование в машинных кодах, потом Assembler, потом языки высокого уровня, потом появились переиспользуемые библиотеки, произошла такая социализация процесса разработки, когда появилось большое количество сниппетов кода в открытом доступе и средства эффективного поиска по ним, появились Stack Overflow, GitHub и так далее, которые позволили там все меньше программистам держать в своей голове конкретных паттернов, конкретных решений, и все больше доверяться какому-то социальному процессу разработки. Но вот сейчас у нас появляются ML-модельки, которые значит, изрядную долю вот этой черновой работы по переиспользованию программных паттернов могут завалить на себя, и тем самым еще в большей мере освободить руки программистов и еще больше повысить производительность труда. Естественно, это вряд ли приведет к замене программистов, точно так же, как, не знаю, появление языка Assembler, хотя и сделало производительность программистов гораздо выше не привела к тому, что программистов поувольняли, да, привело это к ровно противоположному эффекту, тому что порог применения программной инженерии снизился, да, и программная инженерия стала еще более широко применяться, еще в большем количестве областей, чем раньше, и в итоге программистов потребовалось еще больше в конечном счете. Немножко про Чаджи Пити. Хороший вопрос это, а вот Чаджи Пити это все-таки хайп или не хайп? В том плане, что эффект очень такой мощный, медийный. Огромное количество людей вообще впервые узнало о каких-то там успехах в области искусственного интеллекта. Благодаря ЧАДЖПТ. То есть, медийный эффект, социальный эффект, эффект на инвестиционную область отрицать трудно. А есть ли научная новизна какая-то? Есть ли какой-то действительно революционный прорыв технологический, который действительно в этой модели есть? Ответ на этот вопрос несколько затрудняется в связи с тем, что компания OpenAI превратилась в Lost AI со всеми вытекающими последствиями. Мы не знаем многих деталей. Некоторые утечки по поводу GPT или GPT-4, которые мы видим, мы даже не знаем, насколько им можно доверять, потому что они выглядят… Где-то правдоподобно, а где-то ты начинаешь задумываться, что если ты бы хотел над публикой подшутить, чтобы ты бы написал в утечке про то, как устроена очередная большая сетка, вот, может быть, и написал бы туда примерно то же самое. вот поэтому ну давайте признаем что мы не знаем всех подробностей да но мы знаем примерно что происходит с конкурентами и мы видим куда в принципе думает комьюнити какие решения предлагает Но сперва, в чем же такая новизна от GPT? На самом деле, на мой взгляд, две очень правильных и смелых вещи коллегам удалось сделать. Во-первых, они пересмотрели, перепридумали в некотором роде диалоговые модели, потому что развитие диалоговых моделей в NLP на протяжении многих десятилетий, да и, в общем-то, практически от их появления в 60-е и 70-е годы, оно устроилось в парадигме, что мы ведем такую просто беседу в режиме чата моделью вот там или за какая-нибудь да или там какая-нибудь современная модель лежащая в основе виртуальных ассистентов они в этом плане мало отличаются они отвечают достаточно короткими репликами вам вот в основном цель создателей моделей ставилась в том чтобы ну поддерживать такой непринужденный разговор, да, непринужденную беседу. Ну и еще прицел такой сразу шел на голосовой домен, потому что когда, значит, произошел быстрый прогресс в области речевых технологий, то, конечно, давайте скорее делать говорящего ассистента. Ну а если вы общаетесь в звуковом канале, понятно, что Вы не хотите такую модель, которая будет отвечать вам тремя абзацами текста. Быстро очень наскучит своим занудством. И в этом плане таким важным, наверное, шагом... продуктовым во многом стало то, что коллеги из OpenAI сделали принципиально другой диалоговый датасет, не такой, как делали все до них. Они сделали датасет для инструктивной диалоговой генерации, когда Вопросы пользователя — это инструкции для решения разных интеллектуальных задач. И ответы модели, наоборот, должны быть наиболее полными, подробными. Ничего страшного, если они будут занимать полстраницы или страницу текста. Исследователи из OpenAI понимали, что современные модели, они дозрели до того уровня, чтобы давать действительно хорошие, большие, развернутые ответы, а не просто «ага», «угу» и вот это вот всё. Первый важный момент. Второй важный момент, конечно, это смелость, связанная с публичным релизом такой модели. Они потратили и тратят до сих пор очень много денег на инференс. Какого бы размера там сетка ни была, но она точно не меньше десятка миллиардов параметров, и это дорого. При том количестве пользователей, которые есть во всем мире. Ну а последствия, вы сами понимаете, было много всяких разных историй. Когда там Бот Тэй от Майкрософт начал какие-то российские высказывания говорить, и все стали шеймить Майкрософт. Ну, в общем, Чаджи Пити тоже может вполне вам что-нибудь такое сказануть, да, и там написать вам показания к ампутации головы для пациента и что-нибудь эдакое сказать вам совсем не политкорректное, особенно если вы специально стремитесь к нее этого добиться. Вот, ну и несмотря на то, что разработчики, конечно, вложили много усилий для того, чтобы как-то сделать безопасными ответы модельке, но без скандалов не обошлось, вот, и поэтому тут, конечно, с их стороны была такая большая смелость. Про технологии, что мы знаем? Мы знаем, что есть статья про InstructGPT, есть несколько еще важных технических статей от OpenAI, которые выходили незадолго до появления ChatGPT. Например, статья про Fill in the Middle. Вот о том, как тоже можно заставить просто декодерную модельку решать задачу denoising на этапе предобучения. Статьи по инстракт-GPT мы знаем про обучение с подкреплением, с обратной связью от людей. Надо сказать, что на протяжении, наверное, десятилетия это было одним из, ну, таких малых священных граалей обработки естественного языка, как нам обработку естественного языка скрестить с РЭЛи. с обучением, с подкреплением. И много было попыток, много было всяких разной степени хороших результатов, но в целом работало это не очень хорошо. Почему? Потому что сигналы от людей шумные. Как-то в этой людской разметке найти сигнал, Использовать его в чистом виде, как обратную связь, ну мало, да, то есть дорого очень получается эти данные получать, но понятно, что вы не можете там сопоставимое с размером предобучения количество данных разметить. Вот, ну а здесь на помощь пришел подход, который называется Proximity Policy Optimization, то есть когда мы учим, используем как бы ответы людей, оценки людей не в явном виде, мы вначале делаем такую вот proxy модель или модель reward модель да как ее называют учим ее на оценках людей предсказывать вот эти самые оценки людей вот и потом уже вот эта модель она становится источником обратной связи для генеративной сетки вот таким образом мы как бы решаем проблему дороговизна и сравнительно низкого качества и малого количества данных в RL. И, значит, насколько это важно, насколько Reinforcement Human Feedback докидывает качество chat-GPT. В случае Instruct-GPT они, значит, 70-30 побеждали в сайт-бай-сайт сравнении свою свою же модельку без реинфорсмента, ну то есть это заметный прирост, но это не вот не такой прирост, чтобы прям вот тотальное доминирование, да, то есть чтобы вы понимали, это это важный результат, то есть InstractGP стало важным научным результатом, но это не дало вот, не знаю, там какого-то кратного превосходства. Но вот уже после появления ChatGPT, по мере ее дальнейшего развития, по мере покупки Microsoft, лицензии, встраивания моделей в Bing, появления Bing Chat и так далее, какие вот важные тенденции мы здесь обнаруживаем. Но в целом все то же самое. Многозадачность, рост уровня интеллекта моделей. ChatGPT, BingChat – это модели еще более многозадачные, чем те, которые у нас были раньше. То есть они могут решать еще более широкий спектр интеллектуальных задач, и это делает одна моделька… по модельке на каждую задачу. причем она умеет решать и те задачи, которых не было в дата-сети FineTune. это тоже принципиально важный момент, в том числе задачи, которым вроде бы специально не учили модель. Мультиязычность. Ну, здесь понятно, чат GPT довольно успешно общается, не только на английском языке, но и на многих других языках. Мультимодальность. Ну, мультимодальность, это здесь прежде всего, конечно, про Bing chat и GPT-4, которая может с вами картинки обсуждать. про обучение с подкреплением я рассказал ну и вообще в целом такая вот социализация моделей как только модели начинают использоваться экстремально большим количеством пользователей вы так или иначе можете собирать информацию ее как-то использовать значительно для дальнейшего улучшения моделей, усиления возможностей. Ну и тенденция к интеграции моделей с поисковыми системами. Мы про эту историю сейчас поговорим еще, про синтез генеративных и экстрактивных моделей. как-то более системно, но в целом это тоже важный момент. Но мы, кстати, в Сбере тоже, естественно, не могли пройти мимо истории с инструктивной генерацией. Наша платформа называется GigaChat. Мы сразу сделали ставку уже на этапе первой версии на мультимодальность. мы умеем генерировать картинки в скором времени значит мы там сможем не только генерировать обсуждать картинки но и работать со звуками с другими модальностями вот ну маленький коротенький ролик просто покажу с демкой вот так у меня сегодня цели нету вам уж подробно рассказывать про наше решение вот но примерно чтобы понимали о чем Ну, в общем, такая штука. Кстати, музыка, которая в процессе звучала, это тоже музыка, написанная Сергой. Теперь давайте поговорим про ограничения этих моделей. Вроде все так классно и замечательно, и все побеждающие, но на самом деле да, но нет. проблемы выявились, точнее не то, что выявились, социалисты были известны хорошо и раньше, но тем не менее, проблемы, которые присущи таким моделям. Первое – это ограниченная фактологическая точность. Но модели нередко ошибаются в фактах и могут откровенно эти самые факты выдумывать в сравнительно правдоподобным образом. И сейчас это модно называть термином галлюцинации моделей. На самом деле, раньше существовал такой термин, как фактоиды, то есть нечто похожее на факты, но фактами не являющееся. В этом смысле модели похожи на такого студента, которого преподаватель припер к стенке своим вопросом на экзамене. не знал ответа, да еще и забыл. И вот он начинает знать, что молчать нельзя. Он начинает что-то такое фантазировать, пытаться из своих каких-то остаточных знаний и внутренних аналогий что-то такое правдоподобное сгенерировать. Ну и надо сказать, что эта стратегия тогда, в общем, нередко на экзамене спасает. У сетки, соответственно, проблема в том, что выборки для fine-tuning. Недостаточно примеров было, когда модель честно отвечает, что не знает ответа на тот или иной вопрос. Поэтому она пытается что-то генерировать. Что, в общем, нехорошо, если мы вдруг собираемся всерьез доверять ее ответам. Знания модели без дообучения устаревают. Это тоже понятная история. Если у вас основой является претрейн, какая-то сетка на сотни миллиардов параметров, даже на десятки миллиардов, обучение ее это довольно долгий процесс. Сбор данных для нее тоже довольно долгий процесс. Поэтому с момента того, как сетка обучена, все ее знания в окружающем мире фиксировано, все, что она знает, это то, что было в ее датасетах. И отчасти понятно, что у вас есть инструктивный датасет, который вы можете постепенно дополнять, в том числе и фактами из окружающего мира, но все равно даже переобучение, очередной fine-tune, который вы делаете, все равно у вас пара суток будет уходить скорее всего да ну может быть и быстрее но там все равно релизный цикл туда-сюда то есть как бы быстро обновлять знания модели не получится да и ну типа встает вопрос а как вы должны Ну, если вы хотите регулярно дообучать, это дорого, плюс вам нужны какие-то механизмы, которые будут новую информацию собирать и докидывать. А инструктивный датасет его все-таки люди пишут, да, обычно, ну, чтобы там данные были качественными. В общем, эта проблема не то что неразрешимая, но понятно, что для решения всех этих проблем, про которые я сейчас говорю, уже придумано много всяких остроумных способов, и мы сегодня тоже поговорим про некоторые из них. Но, тем не менее, это важное ограничение трансформеров больших. А дальше. Большие модели склонны заучивать клише. Это довольно интересный эффект. Есть некоторые задачи. которые большие модели решают хуже, чем маленькие. Ну, например, вы просите модельку повторить за вами фразу, и дальше пишете какую-то фразу, ну, очень популярную, очень популярную, которая у всех на слуху, да, но вносите в нее намеренно ошибочку, да, заменяете там, не знаю, какую-нибудь одну буквку на другую. Чем модель больше, тем в большей мере она склонна ответить вам оригинальной фразой, без тех изменений, которые вы в нее внесли. Она много раз видела в обучающей выборке, она запомнила эту фразу, ей хочется ее сказать безошибочно, а не так, как вы от нее хотите. Это лишь один из примеров такого поведения. Фиксированное число шагов рассуждения. Что я здесь под этим понимаю? Вообще многослойные трансформеры, классические декодерные архитектуры типа GPT, это фидфорвард сети, это не рекуррентные сети. Что это значит? Сколько бы много параметров у этой сетки не было, у нее сигнал активации всегда распространяется в первых от первых слоев к последующим. У вас никогда активации не текут в обратную сторону, у вас нет никаких циклов внутри сети. Что это значит? Это значит, что, условно говоря, обдумывая ответ на ваш вопрос, сеть лимитирована количеством вычислений, которое она производит. Сколько бы в ней параметров не было, количество вычислений будет фиксировано. Поэтому, если вы возьмете какие-то задачи, которые при увеличении размерности задачи требуют большего количества шагов рассуждения, условно говоря, то, начиная с какой-то размерности этой задачи, трансформерная сетка, какой бы большой она ни была, она эту задачу решить не сможет. Попробуйте заставить чаджи-пяти переворачивать длинные строки, а еще лучше сортировать списки чисел. Начиная с какой-то длины списка чисел, сетка не отсортирует вам список, потому что число шагов рассуждений кончилось. Ну и, соответственно, вы еще можете взять какой-нибудь алгоритм, который имеет сложность не полиномиальную, а вообще экспоненциальную, я не знаю, задачку попросите решить вам GPT, да, и вы увидите, что, начиная с очень небольшой размерности этой задачи, она перестанет справляться с этим. И это легкий способ, кстати, как в ходе процедуры в духе теста тьюринга вы можете человека такую сетку отличить. Просто возьмите какую-нибудь такую задачу, которая будет требовать много шагов рассуждения, и все. Дальше в некоторых задачах, надо сказать во многих, в специализированной модели все еще лучше. то есть даже, например, задачи машинного перевода, специализированные модели машинного перевода работают лучше, чем вот та же chat.gpt. А вот, или код лучше пишет кодекс пока что, или, не знаю, в шахматы лучше играет пока что стокфиш. Лейла Чес, чем Чаджи Пити, который, в общем, не особо умеет шахмат играть, хотя даже пытается какие-то ходы делать. Можете попробовать. Ну и последнее, но вот этого слона тоже в посудной лавке мы не можем не заметить. Это, естественно, много вычислительных ресурсов, которые нам требуются, причем не только на этапе обучения, но и на этапе выполнения этих сетей. Ну и, в общем, да. стоит некий такой набор вызовов перед разработчиками фундаментальных моделей, которые нужно решить по дороге к AGI. Про галлюцинации я уже сказал. Вопрос интеграции новых модальностей. Вопрос интерпретируемости, я к нему так отношусь своеобразным образом, но в некоторых задачах нам нужна модель, которая будет какой-то нарратив генерировать по поводу того, как она принимает решение. Насколько этот нарратив в случае людей, например, соотносится с тем, как они на самом деле решают или интеллектуальные задачи, он открытый, в некоторых случаях нам объяснимость нужна. Высокие требования к веч ресурсам, неактуальность данных, квази-недоторминируемость, на самом деле это вопрос о повторимости экспериментов. Генерация ответов содержит стахастический элемент, стахастический семплинг, поэтому если вы получили какой-то ответ, в него вносит свой вклад генератор псевдослучайных чисел. Некоторые ограничения режима чата, мы тоже хотим все-таки решать какие-то задачи не только в режиме чата, нам неудобно часто это делать в режиме чата. С этими ограничениями напрямую связана проблема multi-embodiment. Может быть, мы хотим какими-то агентами управлять при помощи таких моделей, какими-то устройствами физического мира или виртуального. Как-то мы должны решить эту проблему. Трансформеры по-прежнему хуже, в том числе и некоторых символьных моделей решают некоторые задачи. Ограничение длины контекста модели связано с квадратичной сложностью модуля самовнимания. Есть, кстати, хорошая статья, написанная, по-моему, в этом году уже, где математики строго анализируют операции, лежащие в основе. self-attention и показывают, что субквадратичную сложность можно получить только жертвуя чем-то, жертвуя точностью. То есть полное внимание мы не можем субквадратичной точностью вычислить. В связи с этим интересный вопрос. Сейчас очередной такой хайп своеобразный научно журналистский, строит очередные экспоненты, где показывают, как удлиняется длина рецептивного поля моделей. Что вот Microsoft выпустила на той неделе работу, что значит у них там сколько, я не помню, миллиард токенов длина рецептивного поля модели. Но эти все заявления, они напоминают Историю с секретаршей, когда ее спрашивают на собеседовании, с какой скоростью она печатает, она говорит, что печатает со скоростью 3000 символов в минуту. В ответ на удивленные взгляды говорит, такая, правда, фигня получается. Поэтому вопрос не только и не столько в длине рецептивного поля модели, но и в том, что именно она способна различить внутри этого рецептивного поля. Отсутствие Turing полноты, сетка нерекурентная, значит Turing полноты нет, значит нужно искать какие-то способы chain of thought или рекуррентность добавляется, тоже немножко поговорим об этом. Ну и хороший тоже вопрос о том, как вся эта штука должна стыковаться с имеющейся нашей программно-аппаратной инфраструктурой, как это все должно встраиваться в промышленные решения, производственные и так далее. Теперь о фронтире исследований, как на эти вызовы мы собираемся отвечать и какие эксперименты здесь существуют. Существует такое поле исследований, которое мы для себя называем мультиэкспертностью. Вот термин сам по себе не устоявшийся еще, но значит совершенно очевидно, что вот есть определенное исследовательское поле, которое надо как-то обозвать. Мы вот так его определяем, что к области мультиэкспертности относятся какие-то решения, которые предполагают усиление возможности фундаментальных нейросетевых моделей за счет создания механизмов и взаимодействия с другими моделями, системами, сервисами, в том числе акторами и аппаратными устройствами. Ну и здесь вот есть три таких больших направления взаимодополняющих. Это смеси экспертов, это каскадные модели, в том числе нейросети дополненной памятью Memory Augmented Neural Networks и синтетические экстрактивно-генеративные сети. Ну и также еще модульные модели. Сейчас немножко расскажу про все эти направления. Смеси экспертов. Сама концепция стара как мир. В 1991 году в Neural Computation вышла статья наших корифеев Хинтона, Майкла Джордана, Якобса и Нолана, посвященная вот этой концепции смеси экспертов. Ну и развитие этого подхода им активно занимались исследователи из Google Brain. Это все воплотилось в сетке вначале Jshard, затем switch-трансформеры, так называемые. В чем здесь идея основная? Давайте мы сделаем сетку, которая будет состоять из каких-то подсетей, которые мы можем отдельно предобучать, например. А дальше мы эти сетки будем объединять при помощи такого специального слоя, который называется слоем разреженной активации. Иногда его там роутером называют, маршрутизатором. Но идея заключается в том, что это слой, который отбирает, в какую из подсетей передать активацию, или в какие несколько подсетей передать активацию. Допустим, есть у нас 20-30-100 подсетей. Слой этот наш генерирует просто разреженную маску, где 1, 2, 3, единички, все остальное – нолики. И мы в эти подсетки отправляем градиенты, а остальные – нули, ничего не идет. И, соответственно, с такой сеткой ее довольно удобно попилить еще в плане подлежащего железу. То есть разные подсети будем располагать на разных вычислительных узлах. Ну и вообще таких слоев может быть не один. То есть мы можем еще какую-то иерархию построить. Вот, значит, ну и понятно, что поскольку мы такую сетку не учим, значит, пропуская градиенты через все подсети сразу, да, у нас число вычислений падает сильно при обучении сети, вот, ну и как следствие, как следствие мы можем сделать сетку больше. Вот, пожалуйста, там полтора триллиона параметров у таких сеток стало, когда там GPT-3 было 175 миллиардов, у самой большой монолитной сетки. Значит, понятно, что сравнивать с монолитными сетями не совсем корректно, потому что сквозным образом градиенты не проходят через все слои. сети, то есть только через фрагменты слоев получается. Ну и последнее, так сказать, События, которые привлекли внимание к этому подходу, это вот эти самые утечки про GPT-4, что вот, дескать, GPT-4 это mixture of experts модель, в чем разные параметры назывались, две были утечки, одна, ну, в общем, тоже можно-нельзя верить, вопрос открытый. Но почему нет? В целом это не противоречит не противоречит нашим представлениям об окружающей действительности ну и в мире есть несколько центров разработки таких Микчерфэкспортсеток, вот, это китайцы с их сеткой в Удао и, соответственно, пожалуйста, СВИЧСИ в Гугле, но почему бы в OpenAI тоже исследователям этим не заниматься, да? Вот. Но, значит, когда, конечно, СВИЧСИ появилось, то это выглядело вот так примерно, да, что полтора триллиона параметров. Следующее интересное направление – сетки до полной памяти. Ну вот смотрите, человек-то, когда чего-то хочет запомнить, он часто использует блокнотик или что-нибудь еще, какое-то средство для сохранения информации. Может быть, нам нужно сетку дополнить каким-то инструментом, который будет ей позволять что-то тоже записывать, в том числе, может быть, и в явном виде. Почему бы не приделать к трансформеру хранилище памяти? Дальше не научить его генерировать команды по сохранению чего-то в память и команды по чтению чего-то из этой самой памяти. Это можно сделать очень разными способами. И сама эта идея, опять же, стара как мир. В 2014 году еще появилась статья про нейронные машины Тьюринга. Вот, ну и в целом этот подход, он там много раз в разных своих инкарнациях появлялся, да, вслед за нейронными машинами Тюринга появились там дифференциальные нейронные компьютеры и, значит, вот с Мишей Бурцевым мы там занимались memory-трансформерами активно, последние годы, значит, в many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-many-m заставить в ответах генерировать, значит, команды по укладыванию чего-то в память, причем вот прямо на естественном языке или в виде каких-то динамических блоков. А дальше, значит, каждый раз, когда моделька должна будет ответить на вопрос, мы будем из памяти наиболее релевантные ключи извлекать и подкладывать куда-то в контекст, подобно тому, как механика с плагинами работает. Память – это средство, во-первых, обработки длинных контекстов, потому что, обрабатывая длинную последовательность, вы можете сгенерировать команды по укладыванию чего-то там из этих длинных контекстов важного в память, того, что потом при генерации ответа вы будете использовать. Если важная для вашего ответа информация хранилась где-то в начале, очень длинной последовательности у нее все равно шансы есть дожить до момента подготовки ответа в этой самой памяти. Во-вторых, память – это, конечно, средство борьбы с тюнинг неполнотой. Потому что, опять же, вы можете какие-то операции в этой памяти производить. Ну, вот к вопросу о длине контекста. Еще в 2011 году появилась такая интересная модель под названием KenLM, и этот подход уже в трансформерные времена в Google развивался в рамках проекта Realm. точнее проект Retro DeepMind, ну и Realm в гугле. В чем здесь идея? Ну вот смотрите, у нас есть, условно говоря, какой-нибудь поисковый индекс всего интернета, ну или там какая-то база знаний, где содержатся какие-то фактические данные, которые хорошо было бы Особенно тогда, когда мы сталкиваемся с какими-то фактологическими вопросами. Ну вот вас кто-то спросит, я не знаю, кто был там чемпионом, первым чемпионом мира по, не знаю, по шашкам, да, вот вы сходу не знаете, да, что вы делаете, вы идете в гугл, идете в гугл, пишете запрос, получаете ответ, читаете поисковую выдачу, да, и потом уже можете дать фактологически точный ответ человеку. Ну, это гораздо более фактологически точно, чем если вы попытаетесь из головы что-то придумать. Почему бы нам не научить нейронку делать то же самое? Возьмем слепок всего интернета, порежем его на какие-то фрагментики, возьмем сетку энкодер, посчитаем имбединги для каждого из этих фрагментиков, сложим все это в векторное хранилище большое. Ну и дальше каждый раз, когда мы будем получать вопрос от пользователя, мы будем что делать? вычислять имбединг, опять же, какой-то, идти в это векторное хранилище, извлекать ближайшие к этому вектору по значению ключа фрагментики текста. И дальше мы просто подложим это в контекст генеративной модели, напишем ей примерно следующее. Используя следующую информацию, двоеточие, наши фрагментики, которые мы извлекли, Дай ответ на следующий вопрос. Ну и тот вопрос, который задал пользователь. То есть мы на самом деле при помощи такого retrieval механизма извлекаем из огромного поискового индекса предположительно релевантную информацию и дальше генеративка уже обладает информацией, глядишь и даст фактологически правильный ответ. Ну и, значит, приятная вишенка на торте – это то, что мы вообще для нашего поискового индекса, для документов, которые мы туда включаем, мы вполне можем хранить источник, то есть откуда мы это взяли. И можем научить сетку генерировать ответы со ссылками на источники, которые она использовала, отвечая на наш вопрос. Вот, эта штука работает. Эта штука работает довольно хорошо. У нее тоже есть сейчас несколько разных имплементаций разной степени точности. Ну и в принципе, чем это не сетка с очень длинным контекстом, да? Ведь эту операцию по извлечению релевантной информации из поискового индекса, ее можно применить и к вашему супердлинному контексту. И тогда у вас получится как бы некий аналог блока внимания, который имеет вообще сублинейную сложность, скорее всего. Если вы в векторном хранилище по-умному умеете искать, вы там логарифмическую какую-то имеете, скорее всего, сложность при поиске информации. Вам ее надо проиндексировать, правда, в начале, но индексирование не страшно, линейно. Вот почему я не люблю разговоры о супердлинных контекстах моделей, потому что подход как в ретро, вы можете хоть сейчас сказать, что это подход, который вам позволяет работать с контекстами в триллион токенов, и формально вы будете правы. Но чем, конечно, этот подход еще хорош, то что вы можете использовать какие-нибудь корпоративные базы знаний, например, при создании модельки для корпоративных применений, ну и так далее. То есть вы даете в руки генеративке, по сути, свой Google. модульной модели. Ну вообще вот встает вопрос, если мы понимаем, что есть какие-то инструменты, которые те или иные интеллектуальные задачи решают лучше, чем сама моделька, давайте мы дадим ей эти инструменты в руки, давайте позволим моделькам общаться каким-то образом друг с другом. Вот эта идея, она впервые была так вот немножко может быть вычурно, но сформулировано в работе по модельке ламбда, и вот само название ламбда, естественно, нас отсылает к лямбда-исчислению. И здесь идея в том, что мы делаем много моделей, которые практически составляют такой функциональный фреймворк. То есть модельки вызывают модельки, вызывают модельки и так далее, как в функциональном программировании. Будем учить модель генерировать вызовы других моделей систем. В такой более простой и доступной форме. Эта же идея изложена в статье про Toolformer. В Toolformer используется такая аналогия, что у человека есть инструменты, если ему надо посчитать, он берет калькулятор. Нужно найти информацию, он берет Google и так далее. Есть разные инструменты усиления человеческого интеллекта инструментальные. Давайте мы эти инструменты дадим и модельки тоже. Человек тоже в голове не очень умеет хорошо в аюфметику. Длинные числа перемножить уже беда. вот значит ну что же мы хотим от трансформера того же самого да он тоже не очень умеет но давайте дадим ему калькулятор вот Ну и сейчас мы видим в той же chat.gpt идея плагинов, она тоже воплощает этот же подход. У нас есть мощные символьные движки, давайте мы вручим в руки chat.gpt вольфрам, и пусть он к этому вольфраму ходит за символьными всякими трюками хитрыми. Ну, отдельная тема мультимодальность. Я на самом деле вам сегодня не буду про нее подробно рассказывать. Я лучше вам посоветую, может быть, на один из следующих вечеров человека, который про это расскажет гораздо более подробно, чем я. Андрей Кузнецов с этой тематикой активно занимается. Я пока просто скажу вообще про понятие модальность как таковое. Оно тоже налево и направо сейчас используется в МЛ мире. Но на самом деле, как и многие другие понятия, машинное обучение, оно пришло из биологии, психологии, зоологии, из наук о людях и о живых организмах. Изначально понятие – это модальность раздражителей или сенсорная модальность. И здесь идея изначально заключалась в том, что все стимулы, которые мы получаем, они относятся всегда к определенной сенсорной системе, типа зрительные символы, вонятельные, осязательные, слуховые и так далее. И поэтому, когда стали появляться модельки, которые могли, например, преобразовывать текст в картинку, или так или иначе работать с информацией, которая у нас с вами с определенными модальностями ассоциируется, ну вот этот термин его заимствовали и стали говорить, ну вот у нас есть зрительная модальность, да, визуальная, есть текстовая модальность, ну и тут встает вопрос, ну а вообще-то текстовая модальность это ересь, да, потому что у человека нет отдельной сенсорной системы для восприятия текста, да, мы текст воспринимаем либо через зрительную систему, либо через слуховую. То есть это понятие текста и вообще символы семиотики, оно уже как бы оторвано от конкретной сенсорной системы часто. И здесь произошло такое смешение. Смешение существовавшего термина представления данных, data representation, с понятием модальности. И сейчас уже вы найдете научные работы, в которых пишут о кодовой модальности, что программа на языке программирования — это тоже как бы отдельная модальность. На самом деле, С одной стороны, можно сказать, что машина не обязана обладать тем же набором сенсорных систем, что и человек. Может быть, мы как раз и можем сказать текстовая модальность в отношении глубокой нейросетки, потому что у нее есть векторные вложения, есть словарик. Это можно рассматривать как суррогат сенсорной системы, превращает символное представление текстовое в активации в сетке. Точно так же, как наша зрительная система превращает визуальные стимулы в электрический импульс. Ну, вопрос большой о корректности этой терминологии, но во многом тут уже, конечно, фарш обратно не прокрутишь, потому что написаны уже сотни работ, где под мультимодальностью и под модальностями понимаются просто разные представления данных, и часто эти представления смешиваются с модальностями сенсорных. Так или иначе, все здесь сводится к тому, что нам нужно создавать часто для работы с модальностями какие-то подсети или модели символьные, нейросимвольные, которые информацию, принадлежащую к определенному представлению, к определенной сенсорной модальности, умеют преобразовать в тензор, который мы можем скормить в трансформерную нейросетку. А как это может делаться? Это целая большая наука. Андрей, я думаю, расскажет как раз про основные работы в этой области, расскажет и про то, что мы делаем. Вот. Примеры того, что мы делаем в плане мультиэкспертности. значит, сейчас уже наша моделька умеет генерировать картинки и об этих картинках рассуждать. у нас есть первый прототип символьной системы, но пока это просто калькулятор, то есть если вы чья-то спросите какое-нибудь арифметическое выражение посчитать, то на самом деле генеративный трансформер сгенерирует вызов калькулятора, да, и вы получите результат вычисления. Вот, значит, retrieval механизмы, то есть соединение экстрактивных генеративных моделей, ну и в целом поиск. Мы, скорее всего, скоро будем уметь генерировать музыку и звуки, вот, тоже в таком режиме мультимодального диалога. Ну и дальше, значит, синтез распознавания речи, понятно. Система сообщений, интерпретаторы, компиляторы кода, ну вот как сейчас gpt умеет исполнять фрагмент кода, который генерирует за счет вызова интерпретатора. Это разные акторы для разных поверхностей, но это отдельная у нас тут область экспериментов. Понятно, что мы как банк разные механизмы с финансовыми и с банковскими системами обмена данными создаем. Отдельно это персонализированная память. Мы используем подход с так называемыми генеративными ключами, по сути дела поручая модели самостоятельно генерировать онтологию, генерировать, по сути дела, придумывать под какими ключами, какую информацию она считает нужным уложить в свою записанную книжку. И затем специальная такая тоже ретро-подобная механика, наиболее релевантные записи при подготовке ответа умеет из этой кивелью памяти извлекать и использовать в ответ. Но это тоже хорошо работает, и генеративная сетка, когда вы ей в SFDataSet даете много примеров того, как вы в ходе диалога записываете те или иные факты под разными значениями ключей, Она довольно хорошо учится это обобщать и начинает придумывать вот эти вот новые значения ключей для сохранения в памяти тех или иных фактов. Ну и, в общем-то, всё. Это всё, что я хотел сегодня рассказать. Я надеюсь, у нас есть немножко времени, чтобы поотвечать на вопросы, которые у вас наверняка возникли. Вот. Ну, здесь вот на слайдике ссылка на мой каналчик в Телеге и на, соответственно, каналчик Салют.Ай. И большое спасибо вам, что выслушали, потому что я, как всегда, не могу коротко Поэтому лучше извините немножко, что утомил. 

S01 [01:24:27]  : Сергей, спасибо огромное за фундаментальный доклад про фундаментальные модели. И начать вопросы хочется с вопроса по поводу того, о чем вы не хотите говорить. И предоставляете это Кузнецову. Значит, мы Кузнецова с удовольствием послушаем. Буду очень признателен за контакт. Но вот вопрос такой. Вы говорили достаточно много про мультимодальность и перспективы с этим связанные. А я сейчас припоминаю две вещи. Во-первых, на первом мероприятии Open Talks, я и в Москве, по-моему, чуть ли не лет пять назад, была встреча, заключительный, по-моему, был там круглый стол или, в общем, Анохин с Черниговской. выступали совместно. В общем, они пришли к такому тезису, что проблему сознания Вообще и проблему сознания у искусственного интеллекта в частности нужно изучать для того, чтобы понять, что такое сознание, и чтобы ни в коем случае не допустить возникновения сознания у искусственного интеллекта. Это вот одна часть вопроса-комментария. А вторая часть вопроса-комментария. Три года назад на заре нашего сообщества русскоязычного, точнее на заре его онлайн составляющей, был тоже большой круглый стол, где тема сознания всесторонняя осмыслялась. И в общем пришли к тому, что сознание как раз возникает из мультимодальности. И, соответственно, вопрос такой к вам, если можно, в рамках оставшегося времени, давая, так сказать, подачу Андрею Кузнецову. Как вы видите проблему сознания вообще и в связи с мультимодальностью в частности? с одной стороны, и с другой стороны, как вы видите перспективу возникновения сознания у существующих систем и тому, во что они выйдут с точки зрения EGI, и что нам с этим делать и надо ли что-то делать. Спасибо. 

S00 [01:26:44]  : Спасибо за вопрос. Первым делом тут вопрос такой. У человека и вообще у живых существ, да, у них есть эти самые сенсорные системы, которые все стимулы от окружающего мира в конечном счете превращают в электрохимические сигналы в мозге, да, в нервной системе. Ну и наоборот, любые как бы все наши акторы, которые у нас есть, мышцы, да, они тоже под влиянием электрических импульсов сокращаются. У нас есть какой-то уровень абстракции, который на самом деле все разнообразие модальностей, все разнообразие стимулов окружающего нас мира в конечном счете приводит к некому общему знаменателю. И тут встает вопрос, ну типа, а где проходит граница-то, граница области искусственного интеллекта, да? Вот Тьюринг, например, в своем тесте Тьюринга, по сути дела, через этот Тьюринг давая определение той самой области исследований, которой он предлагал заниматься, Он сознательно абстрагируется от вопроса с модальностями, сенсорикой. Он говорит, что есть телетайп, через него будем общаться. Что там за ширмой? Человек, машина? Каким образом он активирует этот телетайп? Щупальцем он нажимает на кнопки? Или электромоторчиком? Или пальцем? Неважно. оставить это за ширмой. Мы хотим оценить именно интеллектуальную функцию и отделить ее от функции сенсорной. Значит ли это, что сенсорика не важна? Важна, потому что мы в реальном мире существуем и наши интеллектуальные агенты тоже в этом реальном мире существуют. Но вопрос является ли это предметом исследования или нет. Важно это или не важно. В силу того, что мы решаем прикладные задачи, неизбежно это становится частью нашей активности. Но вот с точки зрения формального наличия или отсутствия интеллекта или каких-то свойств компьютерного или человеческого разума, в том числе таких, как сознание. Но значит ли это, что мы, общаясь с человеком сквозь ширму, условно говоря, абстрагируясь от модальностей, не сможем для него сказать, есть у него сознание или нет. Вот принципиально. Но можно тоже на такую позицию встать. В конце концов, мы знаем всю эту историю с Китайской комнатой, знаем, что там. Как говорится, вся вот эта проблематика о том, что считать за настоящий интеллект, что не считать, проблема квали и т.д. и т.п., может быть, нам нужен, значит, всякий там супер-супер тест Тюринга, который требует вообще молекулярной неразличимости для объекта, тестируемого с, значит, объектом-кандидатом. Ну а кто-то вообще в мире селепсизма проживает и считает, что его сознание вообще единственное, а остальные все вокруг него философские зомби. Ну, я бы, честно говоря, оставил все-таки эти вопросы философам, вот. С инженерной точки зрения они, кажется, большого значения не имеют. Если же говорить о сознании, то я тут, честно говоря, как бы, как представитель, не знаю, там, мейнстримного направления науки, а мейнстримным направлением наукой и вопросами сознания занимается, там, Эволюционная биология сознания. Я что хочу сказать. У нас есть какая-то грубая картина о том, как сознание появлялось эволюционно. Появились социальные организмы. Для приспособления к среде стало нужно предсказывать поведение других представителей твоего рода, которые с тобой составляют какую-то социальную общность. Появилась модель другого, психическая модель другого для предсказания этого поведения. Ну и в какой-то момент она на себя оказалась замкнута. Появилось представление о себе как о другом. И вот это сознание, рефлективная часть психики, которая что-то там у нас отражает и которая вот так прекрасна, как бесконечная галерея зеркал, отражающих друг друга. Ну вот, кажется, для того, чтобы нам создать или, наоборот, не создать системы, в которых есть то же самое, ну, чтобы создать нужно что? Нужна, видимо, какая-то мультиагентная среда обучения. Значит, нужно, чтобы в этой среде присутствовали агенты того же рода. Какое должно быть обучение с подкреплением, вот это мультиагентное. Ну и если сетка будет обладать достаточной емкостью, то наверное у нее может в ходе такого эксперимента сознание появиться, почему бы и нет. Но те пайплайны обучения наших self-supervised фундаментальных моделей, они очень далеки от этого. Там нет никакой мультиагентности, там нет тюринг полноты, там нет, в общем-то, какого-то взаимодействия этих объектов, этих агентов друг с другом. Но есть вот, конечно, ППЕ и то самое общение с креплением с обратной связи от людей, но это не то, то есть от этого недостаточного по понятным причинам. Вот, поэтому там психический мир современных фундаментальных моделей, он, конечно, безнадежно далек от человеческого, да, и вот кого-то аналога сознания мы там не найдем, скорее всего, даже близко, да, и рано об этом говорить. Но вот в целом, если нам хочется в какой-то момент такое сделать, ну вот такие у нас есть подсказки от эволюционной биологии, куда-то вот туда нужно идти. Ну, а если не хотим, то, значит, туда идти не нужно. Как-то так. Но целеполаганием тут, как говорится, занимаемся не мы. 

S01 [01:33:21]  : Поэтому такие, наверное, суждения. Сергей, спасибо. Следующий вопрос, он тоже сейчас в последнее время активно обсуждается. Вы сказали про ежегодное, по-моему, удвоение контента, но а как быть с тем, что все больше и больше часть этого удваиваемого контента, оно пишется не людьми, а пишется теми же самыми нейросетями в той или иной степени. Начиная от того, что исследователи пишут свои статьи с помощью Сами мы знаем каких методов, иногда их причёсывают руками, иногда даже не причёсывают, потому что так прокатят. Не говоря уже о маркетологах, которые там написание товаров в интернет-магазине генерят такими способами. То есть не приведёт ли это со временем к прогрессивной деградации качества контента и соответственно всех этих прекрасных моделей, сколько бы их параметров не было. 

S00 [01:34:13]  : Я, знаете, я эту статью тоже читал, вот, честно говоря, не произвела она на меня большого впечатления, да, насчет того вот это, то, что стали СМИ тиражировать, что вот там artificial stupidity, вот это вот все опять началось. Значит, ну, во-первых, да, насчет того, какая там доля контента сейчас там генерируется автоматически. Ну, пока небольшая, скорее всего, но дело даже не в этом. Дело в том, что Значит, есть такие подходы, которые активно используются, это подходы, относящиеся к категории curriculum learning, когда вы на самом деле те данные, на которых вы учитесь, вы все-таки отбираете из них те примеры, на которых учитесь. На самом деле никто вам не мешает из обучающей выборки отсеивать Например, как сейчас отсеиваются дубликаты. На самом деле люди давным-давно используют метод copy and paste и метод перестановки слов в предложениях и так далее, чтобы их диссернат не вычислил. Но диссернат все равно умнеет и постепенно вычисляет. Поэтому вы на самом деле мусор-то можете выфильтровать с довольно нехитрыми способами, например, используя какую-нибудь языковую модель для оценки энтропии последовательности и выбрасывания последовательности с экстремальными значениями энтропии, очень низкими или очень высокими. но как это сейчас делается всеми создателями фундаментальных моделей. Все эти пайплайны фильтрации, они не ценные с точки зрения обучения данных, данные они отфильтровывают. Разный мусор, разные повторяющиеся последовательности, но и точно также какие-то последовательности, которые на самом деле ничего нового не привносят, у них как бы перплексия маленькая, на них и так как бы лосс модели будет маленький, но как бы даже если вы их не отсеиваете, у вас будут просто градиенты ваши меньше по норме своей, то есть если у вас в ваших обучающих данных превалируют данные, которые модель и так предсказывает прекрасно, но у вас будут получаться просто маленькие по модулю градиенты, но не страшно, вы их все равно перенормировываете, если вы используете градиентные методы обучения. Поэтому это все проблема, которая имеет простые инженерные решения, и, кажется, здесь особо бояться нечего. А так, надо сказать, что многие данные, которые генерят машины, наоборот, могут быть очень ценными для обучения моделей. ну какая-нибудь область типа газогидродинамики, да, вот у вас есть симуляторы, да, которые могут какой-то процесс просимулировать, да, и результат его вам выдать. Но это вычислительно дорогая история, да, какой-нибудь вот метод крупных частиц, когда вы там делите вычислительное пространство трехмерное на ячейки, потом, значит, у вас там есть Тейлеров-Лагранжев этапы, вы там долго мучительно это все симулируете, а потом оказывается, что нейронка на этих данных эффективно обобщается и умеет строить какие-то качественные прогнозы, тратя гораздо меньше вычислений. Многие синтетические данные, они как раз хороши и полезны. Последние несколько лет такой серьезный тоже шаг вперед от изначальной идеи в GPT, где мы просто предсказываем следующий токен по предыдущему. Это всякие задачи denoising, когда мы просто берем последовательности текстовые и из них удаляем какие-то случайные фрагменты и учим сетку их восстанавливать. И оказывается, что сетки, которые учатся с такой целевой функцией, Они гораздо в меньшей мере склонны заучивать, во-первых, свою обучающую выборку, во-вторых, они формируют гораздо более робастные представления, более подходящие потом для решения многих задач. Поэтому появление таких методов, как mixture of denoisers или fill-in-the-middle, они очень сильно расслабляют наши требования к данным предобучения. Нам нужно меньше данных сейчас, чем нужно было раньше. Поэтому вот эти апокалиптические предсказания о том, что у нас либо не хватит данных, либо данные как-то замусорятся, У нас сейчас, возможно, нету... немножко мы вот эти границы именно потребности к данным чуть-чуть удалось их расширить, и все-таки самым узким горлышком остается компьютер по-прежнему, а не данные. Ну, может быть, ситуация изменится, но в целом не выглядит... меня не очень пугают вот эти страшилки. 

S01 [01:39:27]  : Спасибо, Сергей. Следующий вопрос про Ваше отношение к интерпретируемости и прозрачности моделей, основанных на глубоких нейросетях. Есть ли это проблема или нет вообще? Если она есть, то решается ли она сейчас или нет? Если решается, то как? 

S00 [01:39:47]  : Ну, есть огромное поле исследований, оно называется Explainable AI, и там придумано очень-очень много разных методов, и, ну, скажем, в случае трансформеров это есть такое направление как дертология, когда мы анализируем матрицы внимания в трансформерных сетях. Есть миллион разных других способов, регуляризация, интерпретабильность, бла-бла-бла. В некотором смысле идея с chain of thought или с генеративной онтологией Они тоже относятся к интерпретируемости, потому что если мы учим сетку генерировать на естественном языке ключ, под которым она укладывает какие-то данные в память, то это вполне интерпретируемая операция или те же самые экстрактивные сетки. Мы видим, на каких данных они опираются, давая свой ответ и так далее. Но проблема как всегда шире. Во-первых, всегда ли нам она нужна? Объяснимость моделей оказывается, что очень часто не нужна. Нам нужна надежность моделей, а не их объяснимость. Поэтому вы садитесь автомобиль к такси да там за рулем сидит человек он вы его первый раз видите да он вам вообще не объясняет какой он прошел долгий жизненный путь и на чем основываются его навыки управления автомобилем и почему он сейчас руль влево повернул а сейчас нажал педаль газа сейчас нажал педаль тормоза вы как-то обходитесь как бы без этих долгих объяснений вот а когда люди начинают еще эти объяснения давать Тут еще встает большой вопрос, как они связаны с действительно теми методами, которые они в принятии решений используют. Потому что классический пример, Михаил Моисеевич Ботвинник полжизни своей потратил, да еще и много времени талантливых программистов, пытаясь сделать шахматную программу, которая будет объяснимыми методами играть. То есть он попытался формализовать те методы, которые были у него в голове, и переложить их в машину. И в конечном счете потерпел фиаско. Почему? Потому что наша способность свои собственные поступки интерпретировать, она тоже очень сильно ограничена. Она ограничена и порог сложности, задачи, которые мы решаем, при превышении этого порога объяснимость становится для людей точно так же невозможной, недоступной, как и для глубоких нейронных сетей. На основе чего вы, не знаю, В ответ на 2 плюс 2 пишите 4. Вы еще можете объяснить худо-бедно? Вот на основе чего вы делаете вывод, что на фотографии кошечка или собачка изображена? Или почему вы тот или иной шахматный ход выбрали в позиции? Тут уже с объяснением сложности возникает. Ну и это довольно ожидаемая штука, потому что биологическая нейросеть, она тоже очень большая и сложная. И наше сознание является отражает лишь небольшую часть психических процессов, которые происходят. Мы не осознаем все те операции, которые совершает наша сетчатка, зрительная кора и так далее, хотя это огромный объем, условно говоря, вычислений, которые там происходят. Мы просто не осознаем, что там происходит и почему у нас активировался вот такой-то нейрон с таким-то признаком, а почему не активировался с другим. Ну и еще, наверное, важный момент. Часто говоря об объяснимости в искусском интеллекте, имеют в виду немножко другую задачу. Имеют в виду задачу переноса знаний между агентами. Имеют в виду, что вот как бы нам у сетки научиться принимать те же решения, которые она принимает. И вот, допустим, если речь идет о людях, то, допустим, я хочу своему другу объяснить, как выглядит тигр. И я при этом знаю, что тигра не видел никогда, но я ему могу сказать, что тигр – это такая большая кошка с черными и желтыми полосками. И я вроде придумал очень компактное объяснение, которое уложил в небольшое количество слов естественного языка. Почему это работает? Потому что я предполагаю, что он знает, что такое кошка, что такое большая кошка или маленькая кошка, что такое черный, что такое желтый, что такое полоска. Наша общность общественной практики, которая существует, то, что мы живем в одном обществе, приводит к тому, что у разных людей есть выровненные до некоторой степени представления. На самом деле, понятно, что мои представления – это какие-то спатиотемпоральные карты активации в моей жизни. биологической нейронной сети. Его представление, это его какие-то паральные карты активации. У нас в мозге может быть разное число нейронов, абсолютно разные карты связей, очень сильно разнящиеся, разная топология сетей. Но тем не менее из-за того, что мы воспитаны одним и тем же обществом, мы до некоторой степени можем полагаться на то, Моё представление о чёрном, или о полоске, или о кошке, оно не очень сильно отличается от его. И на самом деле мы что делаем? У нас как бы есть такой энкодер, который пакует наши внутренние представления в форму естественного языка, например, или какой-то символьной системы, если говорить шире. И декодер, который из этой символьной системы, принятой в нашем обществе, обратно умеет это распаковывать в наши внутренние танки. с патиотемпоральной картой активации. И тут вопрос стоит такой, а что, вот как нам сделать так, чтобы наши модели, которые мы обучаем, они тоже могли бы свои вот эти внутренние, значит, представления упаковывать каким-то образом в такие формы символьные, да, и обратно распаковывать. Ну, можно это сделать, да, то есть для этого нужно что сделать? Для этого, значит, нужно произвести какое-то, значит, выравнивание активации с понятиями из естественного языка. И, в принципе, сетку можно заставить генерировать какой-то текст, который описывает те активации, которые у нее происходят, если вы это выравнивание произвели. То есть, в принципе, этим занимаются люди. То есть, в рамках такой продвинутой бертологии, Сама вот эта идея, запаковать карты активации сетки в высказывания на естественном языке, такие эксперименты есть, но они там как-то работают, пока, наверное, не супер круто, но уже лучше, чем ничего. Я думаю, что со временем в тех областях, в которых это действительно будет важно, это будет происходить. До некоторой степени тоже Чаджи-Пти можно попросить объяснить, почему она пришла к тем или иным выводам. Иногда ее объяснения выглядят правдоподобно. Так же, как и у людей. Их объяснения иногда выглядят правдоподобно. Ну и в целом, да, то есть мы пакуем свои представления в этот условный челобайт понимания, из которого потом можно обратно распаковать, из которого другой человек может обратно распаковать. Ничто не мешает нам те же подходы развивать в наших фундаментальных моделях и этим заниматься. 

S01 [01:47:53]  : Спасибо. Следующие два вопроса связаны. Один вопрос – это какие проблемы НЛУ еще предстоит решить? А второй вопрос – это какие препятствия еще есть на пути к AGI и какие перспективы их решения с вашей точки зрения? 

S00 [01:48:18]  : В NLP, в NLU, ну вы можете пойти и посмотреть просто в Superglue или в BigBench, посмотреть какие задачки модели пока решают хуже. В целом классические наборы тестов, ну вот долгое время там вот эта вот схема винограда была сложной задачей, но сейчас самые топовые сетки они там. На человеческом, примерно, уровне решают. Но в целом, даже мне трудно назвать какой-то класс задач конкретной в области NLP и NLU, в котором фундаментально все было бы плохо. Скорее сложности больше с ризнингом, с построением каких-то длинных логических цепочек рассуждений, ну и с арифметикой какой-нибудь тоже по той же самой причине, потому что там нужно выстроить ну, много шагов рассуждения, чтобы правильный ответ получить, да, и вот здесь плоховато, да, у трансформеров это получается. Но все равно не совсем как бы фатально плохо. Вот. Поэтому в целом вот если вы задаете на естественном языке какую-нибудь там задачку, которая требует много шагов рассуждения, то там проблемы могут быть. Вот. А что стоит на пути к AGI у нас? Кажется, нам нужно решить проблему бутылочного горлышка фон Неймана, и нам нужны более эффективные вычислительные архитектуры, потому что даже Даже если все будет хорошо, мы по мере приближения к физическим лимитам вычислимости не начнем сильного замедления ощущать до конца 20-х годов. Даже если этого замедления не будет, у нас там вот этот вот нехороший штраф в тысячу раз за счет бутылочного горлышка фонеймена, нам нужны более эффективные архитектуры для больших искусственных нейронов. Второй момент, и как говорится, у нас нету консенсуса по вопросу о том, можно ли создать AGI, опираясь только на цифровой след человечества, не имея никаких механизмов активного обучения, взаимодействия с окружающим миром. Почему это важный вопрос? Вообще, наверное, лет 10, 15, 20 назад большинство исследователей сказало бы точно, что нельзя, что цифрового следа не хватит. Нельзя быть таким Жаком Паганелем, который возьмет все книги о географии и станет действительно классным географом. Жильвер осмеивает, по сути, эту идею. Но, с другой стороны, цифровой след растет очень быстро, а цифровой след – это есть слепок общественной практики очень-очень многих людей. Люди живут в реальном мире, они с этим реальным миром взаимодействуют, и результаты этого взаимодействия откладываются в цифровом следе. Может быть, там уже есть все, что нужно. И вот у нас есть YouTube, TikTok, там есть видео. Видео описывают кучу всяких явлений окружающего мира. Из этих видео точно можно вывести законы физики какие-нибудь, механики. И в общем-то есть куча обучающих видео и обучающих текстов, которые рассказывают нам о закономерностях окружающего мира. Есть огромное количество. логов каких-то, не знаю, систем, которые в реальном времени взаимодействуют с окружающим миром. Вот, то есть информации много, информация разнородная, да, поэтому, ну, типа, может быть, ее достаточно. А может быть, нет. То есть, если нет, тогда нам нужны какие-то схемы активного обучения, то есть нам нужно, чтобы эти агенты там взаимодействовали. хотя бы с людьми, может быть и вообще как бы непосредственно через какие-то другие системы, через каких-то механических акторов с окружающим миром для того, чтобы вот эту важную информацию собирать. И тут, как говорится, не попробуешь – не узнаешь. У нас сейчас Как мне кажется, основная проблема, знаете, часто дилетанты говорят, что ученые до сих пор не знают, как работает мозг. Как бы абстрагируясь от вопроса того, что понимать под пониманием того, что работает мозг, у нас вообще очень много теорий. У нас очень много моделей всяких, начиная от иерархической жепы Лекуна, заканчивая… Чем только нет. И на самом деле, что нам мешает? Нам мешает как раз невозможность провести достаточное количество экспериментов, чтобы отсеять неправильные представления, неправильные гипотезы. Так же, как в свое время за нейрофизиологов в 1933 году Эдриан сказал на получении Нобелевской премии, что прогресс нейрофизиологии определялся главным образом прогрессом в области измерительных приборов. Точно так же можно и сейчас сказать, что у нас во многом, очень во многом прогресс в области коннекционизма, он заключается в доступных нам вычислительных ресурсах проведение экспериментов, потому что именно эти эксперименты позволяют нам зерна плевелов, так сказать, каким-то образом отсеивать. Поэтому мне кажется, что самое узкое горлышко, оно вот там, потому что вот если у нас появится возможность ставить учредительные эксперименты, мы всякие завиральные теории, концепции сможем быстро отсеивать и смотреть на практике, что работает, что нет. И в том числе и ответ найти на тему цифрового следа. Получится EJ сделать только на нем или не получится. 

S01 [01:54:40]  : Спасибо. Вопрос следующий. Вы говорили про успехи ЧАД ЖПТ и говорили про компанию OpenAI, которая становится ClosedAI, при этом являясь лидером этой области. Насколько возможно импортозамещение? в этой части, да, силами Сбербанка или, может быть, каких-то других компаний, или мы всегда будем в обозримой перспективе на полшага позади? 

S00 [01:55:13]  : Ну, тут смотря что импорта замечать, да, то есть... Если говорить о архитектурах сетей, которые мы разрабатываем, что мы, что наши коллеги из Яндекса или передовых исследовательских центров академических, здесь уровень науки во всем мире примерно сходный. Лучшие исследователи в разных странах хорошо понимают, как устроена современная архитектура, существуют нюансы, вызовы и так далее. Ну и наша там вот RootGPT4, которая сейчас учится, она там себе тоже ряд инноваций разных реализует, отчасти каких-то наших собственных, отчасти открытых комьюнити, которые мы там перепроверяли в ходе своих вычислительных экспериментов. С точки зрения архитектуры самих моделей, кажется, какого-то отставания здесь нету существенного. Но в этом стеке что еще есть? В этом стеке есть железо тензорное, которое тут, сами понимаете, У нас в стране не производятся современные микросхемы. Проблема заключается в том, что всего-то заводов по производству современных микросхем во всем мире раз-два и общался, а заводов, которые делают фотолитографическое оборудование, только голландцы и делают. И дальше решают, кому разрешать пользоваться, кому не разрешать. Поэтому в плане электроники нужны очень большие инвестиции, гигантские колоссальные инвестиции и много лет, чтобы сократить разрыв в отставании микроэлектроники. В Союзе в 1991 годах мы отставали на полтора года от Запада, например. Сейчас это десятилетие. То есть, здесь не ждите, что какое-то будет импортозамещение в ближайшее время. Правда, может, конечно, произойти чудо в виде смены вычислительного субстрата. что мы завтра будем не на привычной нам электронике что-то считать, да, там какая-нибудь там нанофотоника, вексилоника взлетит, какие-то там, не знаю, мемристеры из никелатов-перовскитов, еще какая-нибудь шляпа, да. И внезапно окажется, что мы сможем что-то с нуля сделать и на повороте кого-то обойти. Такой сценарий исключать нельзя, но на него нельзя и полагаться. Активный поиск разных вычислительных субстратов идет в Science&Nature за последние пять лет. Три десятка статей на эту тему. Вдруг, будем надеяться на лучшее. Есть уровень in the middle. Наши нейронки при помощи каких-то фреймворков, языков программирования реализуются. Пайторч, Дипспид, Питон, Плюсы, Куда и так далее. Но это решение в основном опенсорсное, и необходимости делать свои аналоги в общем-то нет. Пока мы используем то же оборудование, что и во всем мире используется, использовать, ну, писать свой питон, это кажется просто глупо, на это тратить и так скудные ресурсы. Вот. Поэтому в целом карты импортозамещения выглядят вот так. То есть вот зелененькая там, где архитектуры сеток, их обучение, подходы, алгоритмы и так далее. Желтенькая там, где фреймворки и прочее. И красненькая там, где железки, которые, ну вот, все как есть. 

S01 [01:59:14]  : Спасибо. Еще есть вопрос по теме, про которую вы вообще не говорили, но она на протяжении последних пяти лет периодически выскакивает. Сейчас вот снова по нее стали писать. Это тема искусственного интеллекта и блокчейна. Ну или того, что подразумевается под блокчейном, а на самом деле несколько шире. У вас есть какое-то отношение к этому? 

S00 [01:59:39]  : Конкретно моя лаборатория не занимается этим всем. В Сберид, конечно, есть лаборатория блокчейна, которая эту проблематику активно исследуют вот но здесь смотрите да если говорить о блокчейне но и более широко вообще всяких распределенных хранилищах машинном обучение значит с ним связана непосредственно такая отрасль которая называется федеративный обучение вот то есть это собственно такое федеративное обучение когда вот у нас есть много каких-то агентов у которых есть там какие-то свои данные, например, которыми они не могут делиться, да, и нам нужно, значит, какие-то распределенные строить схемы для этого. Вот, ну, в целом мы в последнее время этим не занимаемся, то есть, конечно, там как специалисты мы там что-то понимаем в Federated Learning, вот, но вот специально сейчас как отдельные большие направления исследований, такого у нас нет. С другой стороны, в каких-то финансовых применениях блокчейна, там есть место для... использования методов машинного обучения. Например, какой-нибудь аудит смарт-контрактов. Аудит смарт-контрактов сейчас, как и большинство задач, связанных с поиском уязвимостей в программном ходе, решается в том числе при помощи трансформерных моделей. И вот искать какие-нибудь дырки в вашем коде на Solidity наши там сетки умеют. Это непрямая связь с блокчейном, но, в принципе, некая зона соединения этих миров. Вот как-то так. 

S01 [02:01:24]  : Спасибо. Кстати, я приглашаю всех на семинар, который у нас пройдет тоже с участием лаборатории Сбербанка по блокчейну. Это планируется в сентябре. У нас будет круглый стол. Но следующий вопрос как раз связан отчасти с мультиагентными системами и federated learning, и распределенными сетями. Как вы видите перспективу соотношения или соотношение развития того, что мы можем назвать host AI, когда у нас вычислительные ресурсы расположена на кластере Google или на кластере OpenAI или на Кристофаре с одной стороны, а с другой стороны на тех сетках, которые на каждом телефоне участвуют в обработке изображений, снимаемых каждым телефоном и всеми теми вычислительными мощностями и средствами, которые размещаются на клиентских устройствах. 

S00 [02:02:26]  : ну, здесь как бы всегда рациональный подход должен присутствовать. где-то вам важно иметь очень низкие задержки, низкое latency и, допустим, гарантированно быструю работу в условиях нестабильных каналов связи. это место, где edge вычисления хороши. Вам гораздо проще распознать ключевое слово, которое вы говорите с умным устройством на самом устройстве, чем куда-то пытаться отправить этот аудиопоток, его проанализировать, вернуть результаты. рациональным решением будет здесь edge вычисления. Понятно, что в случае мультиэкспертности, опять же, там, где вам latency позволяет, где у вас синхронность есть или что-то еще, здесь вот эти мультиэкспертные подходы, они тоже вполне могут взлететь, ну и в принципе взлетают, потому что Ну, скажем, в нашем Гигачате, когда вы просите нарисовать картинку, да, Гигачат на самом деле генерирует вызов Кандинского, да, Кандинский там. работает на другом пуле серверов, да, ну то есть это на самом деле два, можно сказать, разных облака, да, обслуживают ваш запрос, вот, и чем дальше, тем разветвлением будут становиться такие взаимодействия, вот, но в целом при этом вы должны понимать, что У вас вот этот канал связи, который существует между клиентскими устройствами и облачными, он, конечно, очень узенький по сравнению с, не знаю, шиной, которая типа инфинибенда какого-нибудь, который связывает в суперкомпьютере между собой узлы вычислительные. И, конечно, это вот то самое узкое бутылочное горлышко, да, то есть вы там будете получать задержки большие и при обучении при federated learning штраф колоссальный за вот этот тонкий канал и при инференсе тоже. Поэтому в каждом конкретном случае нужно смотреть какая должна быть архитектура, насколько она позволяет вам делать что-то на edge стороне или на серверной стороне. каким-то образом между собой это компенсировать. А вот на уровне самого облака, там гетерогенные вполне себе могут быть какие-то истории, и они уже сейчас возникают и развиваются. 

S01 [02:05:13]  : Спасибо. Еще вопрос от Виктора Носко, развернутый. Какой тренд и какие топ-разработки есть в синергии трансформеров и логического ризнинга, в том числе математического? Сейчас есть ToolFormer, LongChain для цепочек-промптов, но все эти попытки эмулировать логику с помощью Chain of Thoughts, Tree of Thoughts – это все кустарные поделки, костыли к трансформерам. А есть ли архитектурное решение? Перспективны ли они? В чате у нас споры большие на эту тему. Одни пишут, что правила устарели и не стоит их смешивать с нейросессиями, а другие, что наоборот нужна генерация по понятиям, а не по токенам и имбедингам. Что вы думаете по этому поводу? 

S00 [02:05:59]  : На мой взгляд, как раз наиболее структурный подход, это тот подход, о котором Исследователи из Гугла говорили, да, с их изначальными идеями, которые в Ламбде были предложены. Какое они там сейчас развитие получили, мы, как говорит, всех подробностей не знаем. Вот. Ну, вообще, как бы, ризнинг в явном виде. Ну, вот люди его используют, да. То есть вот у нас есть такая мощная коннекционистская модель, как наша биологическая нейросеть, да, и наш мозг, на котором она работает. Но мы при этом не все задачи интуитивно, так сказать, решаем. Нам иногда нужны эти самые последовательности рассуждений. Мы изобрели эту самую символную логику, начали с симбиотику, потом всякие символные вычисления. Значит, они как-то позволяют нам усиливать нашу интеллектуальную мощь. Да, самые ранние какие-то решения на эту тему, они напоминают костыли, потому что если у нас есть уже какая-то предобученная сетка большая, то дешевые эксперименты это попробовать вот ее знание использовать азиз для того, чтобы симулировать вот этот самый логический резин. если мы умеем генерировать текст, давайте попробуем просто путем трюков с промпами каким-то образом эти проблемы решать и специфическими датасетами. но если посмотреть на эту проблему более широко, то здесь конечно в голову приходит какой-то такое нейрофункциональное программирование, то есть что у нас выполнение, один шаг инференса большой сетки – это на самом деле выполнение какой-то функции, у которой есть вход текстовый и результат генерации какой-то. Результаты генерации могут в себе содержать в свою очередь вызовы. Вызовы других систем или сетки самой себя. И таким образом у нас получается такое нейрофункциональное дерево выполнения. У Microsoft, например, они эту штуку реализуют при помощи своего LLM Kernel, если вы посмотрите на их сайте. Идея в чем? У нас должен быть какой-то асинхронный фреймворк, который в себя включает операции как бы одного шага вычисления, оркестрации, механизмов ретривола и памяти. И дальше ответом может быть ответ, который включает все динамические блоки, вычисление которых может приводить в свою очередь к вызовам самой же фундаментальной модели, либо каких-то символьных моделей внешних инструментов, whatever. Вот есть такой большой синхронный фреймворк, который строит не цепь рассуждения, а который строит полноценный такой, если хотите, граф. Ну и понятно, что все это понимают, потому что все Good Old Fashioned Artificial Intelligence тоже изучали, и на ЛИСПе, и прологи писали, вот. И, значит, вот эти вот механики для резининга, они хорошо простроены, вот. Ну, давайте скрещивать с LLM-ками, скрещивать в, значит, какую-то действительно стройную архитектуру. Но мы тоже этим занимаемся. Этим занимаются, наверное, все. Наверное, не сразу эти результаты будут опубликованы. кустарные модельки, маленькие эксперименты, вот вы видите в публикациях, которые сейчас выходят. Но то, что сейчас выходит в публикациях Google или OpenAI или там, не знаю, Stanford и так далее, ну вот прикиньте, что они там сами на год-полтора вперед ушли от того, что в этих публикациях есть, скорее всего. Ну вот попробуйте домыслить теперь. 

S01 [02:10:28]  : А вы можете сравнить гига-чат и чат-жпт с точки зрения галлюцинации? 

S00 [02:10:34]  : Ну, конечно. У нас есть большие сайт-бай-сайт сравнения на корзинах, там из трех с чем-то тысяч запросов. И эта корзина, она взвешена по типам задач и по топикам. Ну и среди типов задач там есть QA, ODQA. И в ODQA мы чуть-чуть уступаем ChagGPT, но несущественно. Это как раз та область, где большой разницы нет между нами и ChagGPT. У нас есть некоторые типы задач, которые мы пока заметно хуже решаем. В целом, вот если в среднем по этой корзине посмотреть, у нас сейчас 33,67 получается результат сравнения с ЧА-ГТ, но это вот средняя такая температура по больнице. В конкретной ОДК и галлюцинации там почти паритет. Ну, наверное, там 45-55. Но это все сильно изменится, когда в августе доедет ретривол механика. И когда мы будем отвечать, опираясь на фактологические знания из индекса, я думаю, что там будет картина скорее в нашу пользу уже, ну, судя по тем первым экспериментам, которые у нас есть. 

S01 [02:11:59]  : Спасибо. А еще вопрос от Виктора Носко по этому поводу. Делаются ли в Сбери решения на сетке RWQA? 

S00 [02:12:09]  : Есть эксперименты с этой архитектурой, но пока игрушечных достаточно. Спасибо. Почти все крупные работы, то что вы видите, там RWK, всякие там RMT и прочее, это все и всякие синтезы с KGPA, и всякие ретро-разновидности и прочее. Это все мы пробуем, но просто не все эти работы хорошо воспроизводятся и не все их результаты потом попадают в мейнстримную модель. 

S01 [02:12:45]  : Спасибо. Следующий вопрос от Владимира Смолина. Можно ли привязать имеющиеся в Сбери модели к обработке текста, например, заслушанного нами доклада? Насколько хороша будет грамотность, а может быть и литературность после обработки текста? Есть ли средства по тексту подобрать ссылки, подтверждающие или опровергающие высказанные утверждения? 

S00 [02:13:08]  : Ну, пока как лабораторные инструменты насчет ссылок, да. ну то есть retrieval механики есть, пока они еще мега тщательно заведены. насчет там суммаризации какой-нибудь или перефразирования, но это работает неплохо. в целом, кстати, рерайтинг и суммаризацию мы умеем делать на очень хорошем уровне. Другое дело, что та моделька, которая в продакшене, это моделька с длиной контекста 4096 токенов. Контекст модели получается, умножьте на четыре с половиной или на пять, 20 тысяч символов примерно, то есть получается 10 страниц текста примерно. Это в контекст модели влезет, такой текст она вам сможет суммаризировать или переписать или что-то еще. Если длиннее, то пока нет. Ну, скоро сможем тоже. Понятно. 

S01 [02:14:07]  : То есть, краткое изложение «Войны и мир» сделать не получится. 

S00 [02:14:11]  : Ну, вы можете побить на главы, можете на абзац побить. Сделать иерархическую суммаризацию – тоже не грешно. 

S01 [02:14:19]  : Спасибо. Еще несколько вопросов из YouTube от пользователя Яф Яф. Первый вопрос. В Ваших продуктах возникает emergent behavior? Есть гипотеза о механизме emergent abilities или это мираж? 

S00 [02:14:34]  : Ну, смотрите, я думаю, что как бы вот что считать за секс. в целом мы видим то, что в нашей сетке 13b сетка по сравнению с сеткой 1.3b многие задачи умеют решать прям сильно лучше и можно это считать за эмержентное по идее, но это тогда нужно брать каждую отдельную задачу и простраивать вот по ней там типа кривые метрик для моделей разного размера, там вот у нас допустим gpt там есть 760 миллионов, 1.3 миллиарда, 13 миллиардов, сейчас вот еще там побольше одна сеточка заканчивает тренироваться, но вот мы не делали специально таких оценок, вот прям вот чтобы мы взяли вот какие-то типы задачи, по ним посчитали вот эти кривые и посмотрели есть ли там какой-то фазовый переход внутри них. я не скажу сейчас, есть или нет. но в целом идея эмержентности примерно понятна, на чем основана. вот у вас увеличивается количество слоев модельки, значит она может, так сказать, еще один, так сказать, коэффициент свободы у нее добавляется, да, еще один нелинейный член. Вот какие-то у вас задачки связаны с определенным числом шагов рассуждений для того, чтобы найти ответ, да. Вот определенное число условных операций, которые может сделать один блок трансформера, Вот. Ну и дальше что? Ну понятно, что если в вашей задаче шагов рассуждения оказывается больше, чем слоев у вашего трансформера, то типа он ее решить не может совсем. А когда нужный слой добавляется, опа, значит, он уже может ее решать очень хорошо. То есть этот фазовый переход связан просто с неким добавлением порядка, аппроксимирующий кривой, если так рассуждать. Какие-то типы экспериментальных данных у вас линейный аппроксиматор не может хорошо прогнозировать, а квадратичный может. Вот вам и эмержентное поведение. Чем вам не эмержентное поведение? Поэтому мне, честно говоря, это проблема. Я не очень понимаю, почему. про неё так много стали спорить и так далее, ну то есть это, кажется, какая-то скучная штука, ну типа вполне ожидаемая, вот. А то, что вы можете перенормировать пространство и превратить ваш, так сказать, резкий скачок в сегмоиду, можете превратить в прямую, перенормировав пространство? Ну да, можете, и чё? я поэтому правда не люблю вот эти разговоры и не очень интересно, но в целом, наверное, у меня такой взгляд. 

S01 [02:17:45]  : Спасибо. Следующий вопрос от того же пользователя. Какой из подходов реализации пошагового процесса ответа на запрос с «давай подумаем шаг за шагом» модели вы считаете предпочтительным? В чем преимущество по сравнению с другими подходами? 

S00 [02:18:03]  : Понимаете, не проводили мы пока масштабных экспериментов по сравнению этих подходов, поэтому я, честно говоря, воздержусь здесь от какого-то квалифицированного мнения. Когда будут результаты, расскажем. 

S01 [02:18:19]  : Спасибо. О ваших продуктах улучшение качества ответа при пошаговом ответе возникает? 

S00 [02:18:27]  : Ну да, да, как и у всех. 

S01 [02:18:32]  : Хорошо. Сергей, огромное спасибо за Ваш доклад. У меня, правда, остался вопрос про войну и мир. То есть, я видел, что статьи суммаризуются сейчас достаточно хорошо, а вот интересно, насколько действительно та же самая иерархическая суммаризация позволяет суммаризовать большие литературные произведения. Вы не видели таких работ? Есть эксперименты на эту тему? 

S00 [02:18:57]  : Я знаю, что есть такие работы, но я сейчас не вспомню ни их названия, ни метрики, которые там были получены, потому что, как всегда, вопрос все в метриках. Как говорится, суммаризовать-то можно, может, фигня получается. А насколько фигня не фигня, нужно смотреть конкретные работы и метрики. Но в целом, кажется, должно легко гуглиться. 

S01 [02:19:19]  : Хорошо. Сергей, огромное Вам спасибо, что пришли. За Вас интересный и фундаментальный доклад про фундаментальные модели и их настоящее, прошлое, настоящее будущее. Буду рад за приглашение вашего коллеги поговорить про трудную проблему сознания и всё, что с этим связано. Спасибо всем участникам и до новых встреч. 

S00 [02:19:44]  : Спасибо вам. Спасибо, что говорили. До свидания. До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
