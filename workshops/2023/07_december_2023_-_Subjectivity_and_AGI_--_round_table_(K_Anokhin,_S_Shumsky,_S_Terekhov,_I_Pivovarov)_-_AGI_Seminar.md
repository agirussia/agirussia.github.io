## 07 декабря 2023 - Субъектность и AGI — круглый стол (К. Анохин, С. Шумский, С. Терехов, И. Пивоваров) — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/w20aF0eFeig/hqdefault.jpg)](https://youtu.be/w20aF0eFeig)






А. КОЛОНИН [00:00:02]  : Коллеги, всем добрый вечер. Мы начинаем наш очередной семинар русскоязычного сообщества разработчиков сильного или общего искусственного интеллекта. Сегодня мы снова будем говорить о сознании, о субъектности и связи этого с ЭДЖИ. Сегодня у нас в гостях Константин Анохин, Сергей Шумский, Сергей Терехов. И ведет круглый стол Игорь Пивоваров. Игорь, пожалуйста. 

И. ПИВОВАРОВ [00:00:32]  : Отлично, Антон, спасибо. Коллеги, всем добрый вечер. Я рад всех видеть и в особенности рад видеть наших участников Константину Владимировича, Сергея Александровича и Сергея Александровича. два Сергея Александровича, но я буду, к сожалению, еще по фамилии иногда обращаться. Мы в ответ будем тебе говорить Пивоваров. У меня идентификатор проще, все уникальны в данной компании. Отлично. У нас сегодня тема снова про сознание. Я покажу вводные слайды, как я обычно это делаю. на сценариях, которые модерирую, и дам маленькую коротенькую предысторию. Последнее время, мне кажется, что тема осознания у искусственного интеллекта, она стала прямо очень активная и обсуждаемая тема сознания и в частности сознания у системы искусственного интеллекта и наверное в первую очередь связано с этими большими моделями которые появились языковые которые для многих людей на многих людей производят впечатление о том, что они сознательны. И за последнее время, в частности этой осенью, было несколько событий, несколько мероприятий, на которых были выступления, обсуждения. В частности, было как минимум два или даже три доклада по статье Владимировича. И у нас было в нашем семинаре было интересное обсуждение про осознание искусственного интеллекта. Которая, к моему удивлению, закончилась тем, что два из четырех участников этих семинаров, у нас было четыре участника, я напомню. и я моделировал, 2.4 пришло для себя к выводу, что действительно у современных систем искусственного интеллекта с точки зрения определений, которые они сами дали в начале и их подходов, этих участников, как минимум у некоторых больших моделей есть уже какие-то зачатки сознания или скажем так какие-то элементы сознания. И я, честно говоря, был даже озадачен этим фактом, и мы вот это обсуждали. И уже в вопросах, когда была дискуссия после основного обсуждения с Сергеем Тереховым, мы там зацепились за субъектность. и в частности про то, что такое субъектность, и есть ли она у систем искусственного интеллекта. И мы решили сделать следующий семинар, а дальше, когда мы разговаривали с Константином Владимировичем Анухиным, он предложил сделать это шире, и мы обсудим сегодня совершенно замечательную статью, которая вышла. и в ней где-то вот красной линией отдельно я бы предложил выделить вот этот элемент про субъектность я сейчас про него скажу значит собственно статья которую мы сегодня будем обсуждать на мой взгляд ну совершенно обязательно к прочтению всем кто интересуется этой темой это достаточно большой подробный обзор с чем-то можно поспорить мы сегодня просто сделаем и обсудить там какие есть за и против. Это примерно 88 страниц в этой статье. Да, почти 90. Там 10 страниц ссылок, мне кажется. Основные тезисы статьи, я надеюсь, что все прочитали, чтобы сделать какое-то введение к этой дискуссии. Мы обсуждаем, я уже представил Константина Владимировича Анохина, Сергея Александровича Шумского и Сергея Александровича Тихова. Я хочу начать со слайда, который был в одном из докладов последних у Константина Владимировича Анохина. про то что сознание это несколько разных отдельных как бы аспектов и в частности вот последний пункт про самосознание у нас регулярно тоже всплывал в обсуждениях я понял что Слово субъектность, которое я использую для себя, что, во-первых, оно, видимо, не очень... Я убедился, что оно не присутствует в англоязычной дискуссии, там используются несколько другие слова. И, кроме того, оно, видимо, разделяется еще на две части, судя по всему. И когда мы говорили субъектность в прошлый раз, то под этим подразумевалось с одной стороны, что это некто, кто себя осознает. Вот это вот самоосознание. Но помимо этого, это еще и некий актор, который действует. Вот для меня, по крайней мере, вот еще один пласт. Еще один актор, который действует и достигает каких-то целей. И вот это видимо то, что в этой статье, которую мы сейчас перейдем, называется Intentional Agency. И у меня ощущение, что вот даже они в одном месте даже прям специально написали, что они как бы пропускают intention как таковой и не хотят касаться его в этой статье. Intentional agency как таковой они все-таки пообсуждали как некое свойство. но интересно, что вот этот пласт постановки целей, он мне показался немножко исключен, но может быть это только мое ощущение. Основные тезисы этой статьи такие, что если стоять на позициях вычислительного функционализма. Другими словами, не придавать какого-то мистического значения сознанию и считать, что оно в принципе воплотимо в вычислительных процессах, Не все теории с этим согласны, но большинство согласны. Это первый пункт, что если мы стоим на такой позиции, что сознание в принципе воплотимо в вычистительных процессах, то второй пункт, у нас есть некоторое количество существующих теорий, известных, которые уже достаточно состоятельные с точки зрения своей аргументации, у них есть подтверждения определенные, у них есть за и против. И можно базироваться на этих теориях. Собственно, пункт 3. Можно базироваться на этих теориях для того, чтобы понять, что является сущностными признаками сознания и посмотреть, есть ли такие признаки у системы искусственного интеллекта. Очень подробным образом обосновываются эти тезисы. Мне лично кажется, что это все очень сделано основательно и качественно. И дальше коллеги выделяют, подробно рассматривают разные теории. Из каждой теории выделяют некоторые отдельные индикаторы сознания, которые суммированы здесь в этой табличке. которые они дальше рассматривают у нескольких моделей искусственного интеллекта и приходят к некоторым выводам для себя. Я специально не стал писать выводы, а просто дошел исключительно до этой таблички. и другими словами мы рассматриваем некоторый набор признаков и пытаемся дальше понять по этим признакам что можем сказать про модели искусственного интеллекта базируясь на вот этих признаков причем на эти признаки очень там подробно расписанное, и это очень хорошо нам выглядит, что дан такой большой контекст для всего этого понятия. Ну и собственно, вот они приходят к выводу, что с одной стороны, а нет, не буду говорить выводы. не буду мы лучше выводы дальше с каждым из участников обсудим ну вот собственно статья которая подводит разные теоретические основы по понятию возможного проявления сознания у системы искусственного интеллекта. И мы сегодня хотим поговорить про эту статью. У меня нет какого-то специального порядка Но может быть я бы предложил сначала у Константина Владимировича высказаться как инициатору этой идеи со статьей. 

К. АНОХИН [00:10:23]  : Если я выскажусь, то может быть будет неинтересно дальше обсуждать. 

И. ПИВОВАРОВ [00:10:28]  : Давайте я в конце. Хорошо, давайте так. Тогда Сергей Александрович. Сергей Александрович, кто из вас готов начать? 

К. АНОХИН [00:10:40]  : Игорь, ну можно я предложу? Давайте. Статья, мне кажется, повод. То есть я предлагаю высказываться безусловно в контексте статьи, но не ограничиваться ею, а использовать ее как канву. То есть можно и просто про статью, а можно в связи с темой статьи. 

С. ТЕРЕХОВ [00:11:18]  : Константин Владимирович, а вот можно вас попросить все-таки какое-нибудь проблемное место в этой статье озвучить? Ну как некое, знаете, зародовые уши. Спонтанное нарушение симметрии, да? И тогда мы вот, опираясь на эту точку, уже можем дальше, так сказать, структурировать наши позиции. 

К. АНОХИН [00:11:40]  : Ну вот что-то такое... Проблемное место, на мой взгляд, состоит в том, что Авторы говорят, что вся статья у нас написана исходя из трёх предпосылок, на которых мы твёрдо стоим. И без них мы другие вещи не готовы обсуждать. Первое – это вычислительный функционализм. Второе – это существование научных теорий для осознания и третье, ну, теоретически насыщенный подход, скажем так. Дальше они определяют каждый из пунктов своих позиций в конце следует вычислительный функционализм. Функционализм в отношении сознания это известная позиция, она особенно развилась в 50-е и 60-е годы прошлого века и строится на том, что сознание Это процесс имеющий определенную функциональную организацию. Причинные отношения, которые происходят при этом. Это часто связывают с информацией. и идеи того, что функция может кодироваться на разных материальных субстратах, то есть являются независимые от субстрата. А вычислительный функционализм, то что авторы пропагандируют и берут на вооружение, это версия функционализма, которая утверждает, что Функции, которые и функциональная организация у сознания, она имеет вычислительную природу. То есть, осуществляется через определенные алгоритмы. Проблемное место, на мой взгляд, в этой части самое острое. И про другие две вещи можно сказать, но я не думаю, что мы можем сегодня достаточно уверенно исходить из позиции, что сознание является вычислительным процессом. 

С. ТЕРЕХОВ [00:14:23]  : Если это не так, то 

К. АНОХИН [00:14:28]  : Их база от этого просто растворяется. Насколько? Это другой вопрос. Может быть они ошибаются в своей позиции, но теории, которые они приводят, не обязательно следуют этой позиции. То есть это неучислительные теории. Тем не менее самое проблемное место я в статье вижу в этом. Я могу объяснить, почему я так думаю, если нужно. 

И. ПИВОВАРОВ [00:14:58]  : Можно я уточню вопрос? Я прочитал, читая эту статью, я понимаю, что computational functionalism, то, что они используют, не как вычисление в смысле алгоритма. 

С. ТЕРЕХОВ [00:15:15]  : Вот это и был вопрос, да. 

И. ПИВОВАРОВ [00:15:18]  : верно а как а как воплощение в как бы в компьютерных вычислениях просто ну как бы компьютинг это термин такой широкий в английском языке и я я понимаю их тезис в том что если мы принципиально не согласны с тем что сознание вообще можно так или иначе воплотить в компьютере, который, грубо говоря, считает, он там просто пересылает нули единицы, складывает, вычитает и делает всякие операции с ними, то тогда вообще не имеет смысла говорить о том, что у искусственного интеллекта может быть хоть какое-либо сознание. А вы сейчас говорите именно про алгоритмы? Я цитирую их. 

К. АНОХИН [00:16:13]  : Вот их фраза. Системы, которые выполняют компьютации, процессируют информацию имплементируя алгоритмы. Компьютерный функционализм заявляет, что это достаточно для того, чтобы государство было осознательным, что это играет роль в этого рода имплементации правильного рода алгоритма. То есть они связывают это жестко. 

С. ТЕРЕХОВ [00:16:46]  : Ну, Игорь, можно я еще тогда свой вопрос задам? Да, конечно. Я прошу прощения, что я это самое, как это... немножко вклинился сразу. Я, собственно, вот этот момент-то хотел немножко тоже так вот проговорить. Вот смотрите, я намеренно упрощаю, но у меня, наверное, такая функция в последнее время, максимально все упрощать для того, чтобы там вот не было никаких сомнений, что вся аудитория воспринимает. Вот смотрите, некто, далекий довольно от точных наук и так далее, проводит такие какие-то для себя вычисления. так 2 плюс 4 и пока он там их суммировал он решил что нет наверное надо умножить то есть он поменял операцию на 2 умножить на 4 так там 2 так далее если у него спросить а какой же получился ответ он скажет не хватит то есть он решал какую-то задачу проводя нечто напоминающая очень отдаленно понятие вычисления по алгоритму и так далее. Его вычисления неповторяемы, то есть если он в следующий раз попадет в аналогичные условия или вы просите, запросто может быть дан другой ответ. Более того, этот ответ будет не... То есть этот вот output, так сказать, вот эта вот реакция, она совершенно не обязательно будет именно на вычисление иных результат. Она может быть сопряжена с каким-то контекстом использования, полезности и так далее, которая очень расплывчатая и так далее. И поэтому, когда говорят слово вычисление или слово алгоритм, то вот тут возникает такой вопрос. Насколько это вообще... Во-первых, что имеется в виду? То есть алгоритм, повторяемые какие-то вычисления или там, скажем, вероятность алгоритма, у него принципиально неповторяемые результаты, у него встроена в сам алгоритм неповторяемость результатов. Алгоритм, который обязательно заканчивается, останавливается, ну и так далее. Это много свойств для того, чтобы что-то можно было назвать вычислениями. Ну вот мы как инженеры, как математики будем подходить. Вот с вашей точки зрения, что имели ввиду авторы статьи или может быть что принято считать вычислениями? 

К. АНОХИН [00:18:54]  : Ну, первое, я не эксперт в этом. Второе, это идёт от Лейбницы, и могу процитировать, если дадите мне время, что, как определяется вычисление исторически, начиная со времён Лейбницы. Третье, мне кажется, что Опять-таки, чтобы формулировать наши позиции догматически, в целях полной ясности, я бы не отходил от понимания алгоритма как операции, которая гарантированно, выполняясь, приносит определенные результаты. Если начинать плавать сама операция, или результат. Я не стал бы релаксировать понятие алгоритма до таких случаев. 

С. ТЕРЕХОВ [00:19:55]  : Ну вот это вот очень важный момент, потому что вы же хорошо знаете, что, например, такие модели, даже классические модели, как модель Хопфилда, модель ассоциативной памяти, там нужны довольно жесткие такие условия для того, чтобы те вычисления, которые там проходят, сходились с каким-то стационарным состоянием и так далее. Как только можно, как только уклоняетесь от этих требований, сразу там не гарантируется не то, что алгоритм остановится, И тогда если восстановить в произвольный момент времени, то что считать результатным? Потому что восстановить можно было бы в другой момент времени, там был бы другой результат. И так далее, и так далее. Меня вот этот момент очень смущает, потому что по-видимому речь здесь идет о каких-то кибернетических основах. что это так сказать стимулы реакция и вот она вот он стимул он закончился или так сказать он уже отработал вот она реакция она достигла состояния когда мы можем зафиксировать и в этот момент признать что вот эта реакция есть результат вычисления алгоритм то есть вот Нет ли здесь, на самом деле, такой удобной позиции у авторов, которая говорит следующее. Ну, любой момент, когда нам не понравится или что-то там с чем-то не совпадет или не построится в какую-то структуру, мы просто уточним понятие вычисления, мы его либо расширим, либо сузим, либо как-то контрастируем, либо там, ну, в общем, что-то с ним сделаем. И тогда... Спасибо. 

К. АНОХИН [00:21:22]  : Я бы здесь добавил, это принципиальный вопрос в том смысле, что насколько сознание может воединиться в конечном счете в моделях, которые работают на компьютерах. Кроме функционализма есть же вот жесткая позиция, которая, не знаю как перевести на русский язык, computationalism, который утверждает, что если две системы функционально неразличимы, то делают одно и то же. то они и ментально неразличимы, то есть они обладают одними и теми же ментальными состояниями. Это другая сторона вычислительного функционализма. И это не очевидная вещь. И есть теории, которые подвергают это очень серьезной критике. Одна из таких теорий, Это теория интегрированной информации, которая говорит, что выполнение операций, то есть функциональные вещи, совершенно не гарантирует сопровождение их какими-то субъективными состояниями. И поэтому, дальше продолжает теория, Любые операции, которые осуществляются моделями на основе работы компьютера, не способны привести к возникновению субъективных состояний и сознания. Поэтому эту теорию, сильную теорию сознания, если Делать рейтинг теории сознания научных, то может она стоит на первом месте. Авторы не включают в рассмотрение в своей статье. И они пишут об этом вначале, что мы не включили теорию интегрированной информации. Но не раскрывают почему. А вот я раскрываю почему. Потому что теория интегрированной информации говорит, что все вещи, которые написаны в статье, вообще нерелевантны. То сознание на компьютере смоделировать нельзя. Для этого нужна физическая структура, нейроморфные архитектуры процессора, которые Имеет физические основы согласно теории интегрированной информации. Есть статьи Кохе и Таноне на эту тему. В принципе могут развить сознание, а вычислительные модели нет. 

И. ПИВОВАРОВ [00:24:32]  : Мне кажется, что они прямо так и пишут в начале, в преамбуле, что они именно поэтому не включают действительно ИИТ в свое рассмотрение, эту теорию, потому что она противоречит computational functionalism. И это факт. и но в каком-то плане вот тут методологически то кажется вот у меня у меня есть понимание у меня ощущение что они так делают это металлогически не делают правильно Потому что если мы в принципе говорим о возникновении возможного сознания у системы искусственного интеллекта, которая в принципе существует исключительно в компьютере, в формате вычислений компьютера, нельзя рассматривать для этого металлогическую теорию, которая отрицает эту возможность. Тогда нужно сразу сказать, что с точки зрения теории сознание невозможно. и появление сознания невозможно. Они рассматривают именно возможности какие-то. 

К. АНОХИН [00:25:38]  : Нет, это все так. Они эксплицитно на самом деле это не разбирают. Они не разбирают ААИТ вообще, кроме вот этого асажа, где они ее не включают. А позиция ААИТ заключается в следующем, что сознание Это внутренняя причинно-следственная сила у определённой системы, обладающей определёнными свойствами. Авторы называют её физической системой, это пускай будет на их совести, но смысл их утверждения, что физическая причинно-следственная сила у физических систем, таких как мозги, Она не может быть ни вычислена, ни симулирована. Она должна быть встроена в физику системы. 

И. ПИВОВАРОВ [00:26:37]  : У нас в сообществе было обсуждение. Было мнение, что это фактически теория, развивающая пансихизм. И в некотором смысле она базируется даже на панцирхизме, хотя есть один постулат исключения, который вроде как пытается исключить, но тем не менее. И именно это фактически не дает никак… Если стоять на позиции панцирхизма, то безусловно вычислительно это сделать нельзя, просто по определению. Вы что думаете на эту тему? 

К. АНОХИН [00:27:22]  : Я бы разделил, хотя это не делают эксплицитно авторы, особенно Кох, я бы разделил здесь метафизику, как предлагают, кстати, авторы разбираемой нами статьи, от научного содержания. К метафизике они относятся в частности к позиции панпсихизма, дуализма, иллюзионизма и так далее. И рассматривал бы только научную сторону разных теорий, в том числе теории интегрированной информации. На мой взгляд, теория интегрированной информации совершенно не обязательно должна быть сцеплена с панпсихизмом. Если кому-то хочется, он может это увидеть. Вообще она способна жить и существовать, и я думаю, ее эффективное научное содержание находится в этой зоне. без каких-то экстраполяций на глобальные космические сущности. Да, есть в теории идея, что сознание это фундаментальная сущность, не редуцируемая. Ну а дальше всё дело в том, что это западные авторы, и как без исключения у всех западных авторов, они строят всю свою научную картину миру на физикализме. И поэтому следующим шагом является, что раз сознание нередуцируемо, фундаментально, значит надо опустить его на самый низкий уровень, на уровень физических систем, не биологических, не химических, а именно физических. И отсюда возникает панпсихизм. Но в действительности это просто тупик западной философии и мне кажется его легко отбросить и серьезно рассматривать теорию интегрированной информации по ее научному содержанию. Научное содержание говорит, что необходим определенный уровень интеграции работы элементов, материальных элементов который создает новый причинно-следственный потенциал у целой системы. Мы такие системы, которые обладают таким потенциалом, знаем пока только в биологии, но потенциально, теоретически, можно рассматривать и другие физические системы. которые будут обладать таким потенциалом. Да хоть инопланетян, о которых мы еще не знаем, но теория говорит, что если они способны создавать интегрированную информацию и можно просчитать ее нередуцируемое максимальное содержание файл, то значит эти системы сознательны. Ну и все. А панпсихизм? Это просто гримаса на лице теории, ее можно стереть. 

И. ПИВОВАРОВ [00:30:58]  : Хорошо, спасибо. У меня есть еще тот тезис, но Сергей Александрович Шумский, ты хочешь высказаться? 

С. ШУМСКИЙ [00:31:10]  : Да, хочу. Ну, у меня просто есть несколько слайдов, которые иллюстрируют мои мысли. Давай. Если я поделюсь. Ну, отлично. Я думаю, что, собственно, вот То, что по большей мере всех волнует, это то, что мы уже почти вплотную подошли к созданию общего искусственного интеллекта, особенно если вы видели последний ролик от Гогла с его Джиммини иллюстрациями. И всех волнует, в общем-то, будет ли сознание у искусственных агентов. те самые, будут ли они там мечтать об электронных чем-то. Вот. И моя точка зрения, что да, и что сознание – это просто необходимый атрибут интеллекта, я просто хотел ее обосновать буквально там несколькими штрихами. Потому что я рассматриваю интеллект как некое природное явление. Мы все-таки должны понять, как он возник даже в живом. И интеллект, он связан с понятием регуляция. Больше всего со мной близкие тут это понятие регулятора, потому что это способ держать, удерживать системы вдали от термодинамического равновесия. То есть держать их в квазистационарном состоянии, но оно неустойчивое. А раз оно неустойчивое, то оно требует неких активных действий. И эти, собственно, активные действия – это и есть интеллектуальные действия, то есть разумные действия, те действия, которые удерживают систему от распада или от сваливания куда-то, от потери устойчивости. Ну а раз есть регулятор, то есть в принципе разные типы регуляторов. Ну и вот нас интересует то, что называется хорошие регуляторы. То есть это не простые какие-то. термостаты, которые тупо реагируют на какие-то изменения, следуя за событиями, а те, которые предупреждают возможные угрозы и активно удерживают систему в состоянии равновесия. А дальше есть просто математическая теорема, которая говорит, что у любого хорошего регулятора системы должна быть модель той системы, которая не регулирует. Потому что без этого невозможно что-то предсказывать, невозможно совершать действия, которые предугадывают что-то, смотрят в будущее, а это и есть, собственно, то, что мы называем интеллектуальное поведение. Ну а раз так, то отсюда возникает понимание того, что мозг – это просто хороший регулятор, то есть некий компьютер. Регулятор – компьютер в том смысле, что он, я отвечаю на вопрос о вычислительном, что он выполняет некую функцию, несет. Эта функция, кстати, она не должна заканчиваться как какой-то алгоритм, который нашел результат. Эта функция – это балансирование. Балансирование на краю небытия. Как только ты закончил эту функцию, ты как бы закончил с интеллектом со своим. И как любой хороший регулятор, он должен выполнять эту функцию, и способ выполнения этой функции – алгоритм. Это и есть интеллект. Ну, а раз он хороший, то он создает модели реальности. И вот я тут специально пометил для Константина Владимировича, что вот это вот и есть то, как я понимаю, его теорию когнитума. И сознание – это есть просто текущее состояние этой модели. Сознание – это наше настоящее, которое мы воспринимаем, а воспринимаем мы только вот картину мира. То есть вот здесь вот на этой картинке мозг, да, вот он шире, чем вот эта модель мира, да, то есть это психика, и большая часть этой психики, ну, большая-меньшая, там вот уже это… как определять, как мерить, но часть этой психики, она нами не осознается. Это бессознательное, там вся мотивационная, там лежит реинфорсмент ленинг, но часть этой психики нами осознается, осознается как внешний мир, хотя на самом деле к внешнему миру мы имеем дело Ну, мы имеем доступ только очень опосредственный, через такие низкоуровневые сенсорные функции, но мы их потом обобщаем и превращаем вот в ту модель мира, которая уже сознается, то есть на уровне первичных Мы не осознаем мир, мир осознается на уровне уже осмысленном, крупнозернистая картина мира. И эта модель мира, она в каком-то смысле изоморфна реальной динамике мира. Но реальный мир гораздо-гораздо сложнее, чем та картина, которая есть у нас в голове. И к реальному миру, конечно, мы не имеем никакого доступа. Это те вещи в себе. Но мы имеем доступ к некоторой грубой картине этого мира, которая достаточна для того, чтобы чтобы наши действия были синхронны с реальной динамикой мира, и чтобы мы могли как бы вот это балансировать, удерживать в настоящем вот то самое равновесие. Ну вот, а наилучшей метафорой сознания для меня – это компьютерная симуляция, то есть Так же, как в игре создается, есть движок игры, который мы не знаем и не видим, но мы видим на экране модель мира, и это то, что мы видим на нашем внутреннем экране, и у каждого из нас это свой экран. То есть понятно, что какие-то вещи мы понимаем, наверное, одинаково, Ну, или более-менее. Но какие-то вещи более абстрактные, конечно, у нас у каждого свои, и мы живем каждый в своем мире. Внимание – это как раз выбор наиболее важных параметров, которые нужны для решения вот этой вот задачи управления. А мышление – это тот движок, который, собственно, управляет вниманием, который в каждый момент времени находит наилучшее наилучшая матч с картиной мира. Вот сознание таким образом – это текущее содержание внимания, видимая часть мышления, и она обеспечивает понимание в том смысле, что мы в нашей модели понимаем, где мы находимся в этом пространстве мысленном. Ну и дальше там в зависимости от того, насколько с абстрактными вещами мы сейчас оперируем, мы можем оперировать и с более абстрактными, и с менее абстрактными. Вот эта буковка «М» довольно-таки сложная, но сейчас не об этом суть. То, что это какой-то вычислительный процесс, да, в принципе вот эта вот теория Фристона дает очень такое ясное понимание, как задача управления решается. Если у нас есть некоторое априорное распределение наших внутренних параметров организма, где мы хотим его удерживать, то есть то самое состояние вдали от термодинамического равновесия, то мы должны максимизировать нахождение в этой области априорной вероятности, каким образом мы делаем, управляя актуаторами, которые зависят от нашего мысленного состояния. И если вот эту меру хорошести управления, со знаком минуса – это, собственно, страдания, мы испытываем страдания, когда мы выходим за рамки узкого интервала внутренних параметров организма. которые мы бы хотели удерживать в этих пределах. И можно написать функцию, которая всегда больше, чем это, и минимизируя эту функцию подгоночным параметром, мы минимизируем страдания. И тем самым решаем задачу управления. В некотором смысле это и есть какой-то алгоритм. который реализован у нас в мозгу, который решает основную задачу, поставленную перед нами фактически эволюцией. Ну, а теперь чуть поближе к статье. Для меня, например, вот все теории сознания делятся на две большие категории. Да, это те, которые говорят, что ощущения свойственны особым динамическим системам. То есть, это свойство hardware. И в этом смысле вот туда вот IIT относится, конечно же. И в этом смысле, раз это особое свойство хардвера, то да, понятно, что наше биологическое хардверо кардинально отличается от компьютерного. И в этом смысле тогда, если мы находимся в этой области теории, мы говорим, что да, пожалуй, у роботов не может быть сознания, потому что у них нет того самого хардвера, который есть у нас. А вот то, точка зрения которой придерживалась я и вот который в этой статье, да, это то, что сознание, это ощущение свойственно особым вычислительным процессам, то есть это свойство софтвер, и не зависит от хардвера, на каком бы хардвер это софтвер не стояло, то есть есть Хороший регулятор, который регулирует очень сложную систему, сравнимую с нами, и делает это своим образом, каким-то своим вычислительным процессом. то он вполне себе может обладать сознанием, потому что у него будет модель, которая дает ему понимание картины мира, и в этом смысле он будет обладать сознанием. Ну и последний слайд здесь – это будет ли у агентов искусственных понимание текущей ситуации. Допустим, оно будет. Действительно, оно будет. Мы просто действительно видим. что вот эти вот последние модели реально понимают, когда их спрашивают что-то про картинку, про видео, про задачу. Они просто разговаривают так, как будто они понимают, они знают, как ее решать, они знают, где ошибка. То есть там есть понимание, поскольку понимание можно функционально просто измерять, то там есть это понимание. Ну, что нас, наверное, сильнее всего, значит, будет волновать – это их сознание, насколько близко оно нашему будет. И понятно, что раз у них другой hardware, то у них будет другой тип сознания, потому что эмоции – это свойство градиента этой функции, которую мы оптимизируем. Как только мы отклоняемся, вот отклонение это испытывается нами как эмоция. В разных направлениях отклоняемся от равновесия, это разные эмоции. И понятно, что раз тело устроено по-другому, то и регуляция этого тела будет устроена по-другому. Но вот в чем могут совпадать наши модели реальности – это в социальной сфере. Потому что если мы все будем… ведь человек испытывает не только физические страдания, но и моральные страдания. То есть для него ценности – это не только физические ценности. Типа здоровье, состояние здоровья. Это моральное состояние, понимание того, что такое хорошо, что такое плохо, как себя вести в социальном плане. И вот здесь, поскольку агенты искусственные будут работать в той же среде, что и естественные, участвовать в той же самой социальной жизни, И будут у нас брать наши моральные ценности. Эти ценности у них, хочешь не хочешь, будут человеческие. И вот в этом смысле у нас, скорее всего, будет понимание друг друга. В физическом смысле, в том, что относится к hardware, конечно, понимания такого не будет. Ну, хотя бы потому, что они будут бессмертны, поскольку они могут легко быть… Цифровые модели, они как бы бессмертны. Их можно записать, а потом воспроизвести без ошибок. не почувствует вот это вот небытие, которое было. Мы же смертные, и у нас есть запаянные страхи, связанные вот с этим. того, что у них не будет. У нас есть разные прайеры, связанные с тем, что мы обезьяны, и у нас есть стремление доминировать, которое у них не будет, поскольку они не обезьяны. И в этом смысле, конечно, сознание у нас будет отличаться, но в чем-то в том, где мы будем действовать, сообщая, я думаю, что мы сможем друг друга понимать. Наверное, это все, что я хотел сказать. 

И. ПИВОВАРОВ [00:46:29]  : Спасибо огромное. Прежде чем я Константину Владимировичу слово передам, у меня два вопроса к тебе. Во-первых, с точки зрения даже предыдущего семинара, Ты сейчас сделал еще больший шаг с точки зрения твоего определения сознания, как условно некоторые видимые части или той части картины мира, на которой фокусируется текущее внимание. Вообще у очень многих моделей сегодняшнего ИИ, даже не только обязательно у ИИ, даже у некоторых очень хороших регуляторов, уже как бы сознание в этом твоем понимании есть. Да, я правильно понял тебя. 

С. ШУМСКИЙ [00:47:08]  : Да, я думаю, что, грубо говоря, вот эти большие фундаментальные модели, как их называют, это есть модели одного акта сознания. То есть они могут предсказывать нечто на один шаг вперед. Этого мало для регуляции, этого мало для субъектности, но понятно, что мы уже где-то рядом, потому что по сложности эти модели уже соперничают и даже где-то в чем-то сверхчеловеческом. 

И. ПИВОВАРОВ [00:47:35]  : Окей, хорошо. Тогда второй вопрос. У меня ощущение, что ты используешь все-таки слово «сознание» сейчас, вот в этом разговоре, не так, как оно используется в этой статье, про которую мы начинали говорить. Потому что в статье речь идет про феноменологическое, как сознание, как феноменологический опыт. нечто явно отличающиеся от интеллекта как способности там предсказывать регулировать это некоторое ну как бы то что мы знаем там некоторые субъективное состояние ты ты как бы ты ты в этом смысле используешь или или или Или ты не согласен вообще с этим определением про фенологический опыт? 

С. ШУМСКИЙ [00:48:19]  : Статья не показалась особенно в чем-то меня продвигающей. Да, она слишком аналитическая. Они стремятся расщепить что-то на отдельные составляющие, потом их отдельно померить. Мне это такое мышление чуждо, мне как раз больше нравится холистический взгляд на сознание, как на некоторую функцию. И тогда эту функцию я вот так определяю. С этой точки зрения у меня как раз претензии к Таноне, к теории интегрированной информации, что там нет вот этой самой функции. Там есть феноменология. Они говорят, если у вас есть система физическая с такой связностью, который можно посчитать, то она обладает сознанием. А для чего тогда это сознание? Они не говорят. Тогда как вот когда мы подходим с точки зрения регуляторов, а мы понимаем, что это эффект выжившего. То есть мы плод очень длинной эволюции регуляторов. И мы в этом смысле самые лучшие регуляторы, которых можно пока придумать. И просто потому что природа выбирала, и выбирала, и совершенствовала вот эту главную функцию. И сознание возникло именно как вследствие того, что оно необходимо для вот этого осуществления главной функции. Вот оно не нет у этого. Зачем? У него есть просто как это устроено. И в этом смысле мне больше нравится подход с точки зрения функции. 

И. ПИВОВАРОВ [00:50:14]  : Константин Владимирович, у вас есть что прокомментировать? 

К. АНОХИН [00:50:22]  : Есть много что. Могу начать с конца. Сознание как функция и отсутствие такой функции в теории интегрированной информации. Нет, это не так. Танони не пишет отдельные статьи про это, но в его концепции и об общающих статьях Например, статья 2012 года, которая такая обобщающая манифест. Он выделяет это в раздельную главу. Как феноменальное сознание может быть функционально. Это у него носят название в соответствии, matching с внешним миром. И этот matching, появляющийся у этих феноменальных состояний, даёт адаптивное преимущество. У них с Кохом и Крисом Адами была серия из трёх статей, где они в 2011, 2012, 2013 году, где они брали аниматы и моделировали интегрированную информацию в условиях поведения и отбора аниматов, и показывали, что Появление интеграции информации в аниматы даёт им преимущество по сравнению с аниматами не имеющими интегрированной информации. То есть нет, нельзя сказать, что первая теория интегрированной информации игнорирует вопрос функции сознания, что она равнодушна. и что она ничего об этом не говорит. Нет, это не так. В отношении того, что Сергей Александрович сказал касательно статьи, у меня очень схожие с ним ощущения и отношение к статье. что она написана группой авторов. Ну не хочу ничего сказать плохого про них, но там много философов, которые занимаются теориями сознания, и часть из них, собственно, и писали. И когда люди, так сказать, ну не теме буквального мяса какой-то проблемы, они начинают разлагать ее так, как это им подсказывает определенные логические алгоритмы. Получается такая аналитика. Вот мы возьмем такие-то компоненты из одной теории, такие-то компоненты из другой. Игорь, вы показывали эту таблицу. Я согласен с Сергеем Александровичем, что мне кажется компилятивно нельзя составить такую вещь, что вот давайте посмотрим и сложим. Если все компоненты всех теорий присутствуют у модели, то значит она, наверное, обладает сознанием. Так это не работает. Должна быть одна фундаментальная теория, которая берёт эту проблему за горло, то есть адекватная. А не так, что равновесные теории, от каждой возьмём её главные критерии и получим. Ну, это так же, как у Сергея Александровича моё личное интуитивное ощущение, как с этой проблемой работать. Что я вижу в качестве проблемы в том, что говорил Сергей Александрович? То же самое, что Игорь сказал. То сегодня, и это не относится только к авторам статьи, я вот в этих двух докладах посвятил этому некоторое время. Это некоторый консенсус в мировых исследованиях, как научных, так и философских. Под сознанием стали понимать феноменальное состояние. Я не говорю, что это не сдвинется через 20-30 лет и не вернётся к другим определениям, которые были в середине прошлого века, но мы имеем дело вот с этой ситуацией. Она просто отражена в данной статье, но на самом деле она в состоянии дел в мире. И соответственно вопрос, который эта ситуация создает, есть ли субъективные ощущения, переживания у кого-то, кому мы приписываем сознание. Если есть, значит сознание присутствует. Именно субъективные переживания. В этом смысле то, что говорил Сергей Александрович. В функции не есть субъективные состояния. Они могут сопроводаться с субъективными состояниями, но не обязаны. Например, внимание это функция. Но есть ли у систем, обладающих функцией внимания, которые ясно как выполнять и фокусировать и так далее, при этом Субъективные ощущения, сопровождающие функцию внимания, не факт и между ними вряд ли можно уверенно ставить знак равенства. Раз мы смоделировали внимание, то, что находится в фокусе внимания у модели, можно считать основаемым. Не обязательно. У меня было два в связи с этим вопроса к Сергею Александровичу. Если смотреть на сознание таким образом и задавать вопрос, ощущает ли что-то компьютер, выполняющий данный функционал. Первый вопрос такой. Вы сказали, я записал, что сознание – это текущее состояние модели, просто текущее состояние модели. А потом показали на схеме, что модели могут быть в состоянии сознательной и несознательной. Буквально хотел уже спросить, а как же процессы и состояние модели, которые не сопровождаются сознательным ощущением? Ну вы сами сказали. Но тогда, если есть эта модель, она когнитивная, вы использовали там термин когнитон, и в ней текут эти динамические процессы, которые вы там образно изобразили, то Мы знаем, что они могут течь без сознания, во сне, в скрытых видах мышления. И я перед этим говорил, что если извлечь эти процессы на уровень, который моделируется как внимание у модели, то не факт, что Это равнозначно субъективному ощущению. Значит, вот первый вопрос, всё-таки что такое сознание? Это текущее состояние модели или особый вид состояний, которые отличаются от состояний модели несознательных Тем-то, тем-то и тем-то. Второй вопрос. Во всех этих выкладках и обсуждениях, кто такие мы? Вы говорите, вот мы видим на экране модели, там происходящее то-то, то-то и то-то. Кто видит? Это, видимо, относится к поднятой вообще теме субъектности, как я понимаю, которая возникла у вас на прошлом обсуждении, и Игорь в введении об этом сказал. Я пока не высказываю своих мнений, задаю вопросы, но в этом месте могу сказать. Пока мы не будем иметь фундаментальную теорию субъекта или self, или мы, или кто, кто видит. Мы не расшифруем понятие сознания, оно в двух местах как минимум приклёпано намертво к мы. 

С. ШУМСКИЙ [01:00:56]  : Ну, по порядку тогда, да? Ну да, и для меня действительно понятие психики шире, чем понятие сознания. То есть, сознание – это часть психики, собственно, видимая часть психики, так её все и определяют, за которой стоит много чего, но это часть психики, которая необходима. 

К. АНОХИН [01:01:16]  : Серёж, а можно вот сразу же к этому? То есть, я смешиваю этапы обсуждения, которые перечислял, но видимое опять кем? 

С. ШУМСКИЙ [01:01:27]  : Кем? Хорошо. Я – это тоже часть модели мира, как у меня было нарисовано, потому что мы же регулируем отношения мира и себя, то есть себя в мире. Но понятие себя, оно тоже появляется не сразу у ребенка, оно начинается… он начинает себя от мира, значит, сепарировать, ну, по-видимому, как наиболее предсказуемую часть мира. То есть вот у него есть сенсорный опыт, но какой-то из них, что-то он может предсказать абсолютно точно. И это он контролирует. И он потихонечку вот это вот, Эта часть модели мира становится частью, моделью себя. 

К. АНОХИН [01:02:23]  : Сереж, а можем мы, я не знаю, я прошу прощения, порядок обсуждения, но могли бы мы говорить здесь, я помню всю схему вопросов и логику, но может быть можно еще добавить диалоговый какой-то, вот обмен сразу же. Вот в этом месте. Потом можем дальше продвигаться. Есть проблема. Она заключается в том, что ты говоришь, что у ребенка не сразу возникает модель себя, а связываешь модель себя с ответом на вопрос, кто видит или испытывает. Но ребенок, как показывают многие исследования, уже с момента рождения испытывает ощущения боль, голод, холод и так далее. не имея достаточно итеративно ложившийся, многократно развившийся в его отношениях с миром модели себя. 

С. ШУМСКИЙ [01:03:53]  : Да, конечно. Психика же у него есть. Психика есть, и у этой психики есть видимая часть. Просто в этой видимой части у него нет модели себя, то есть самосознание. А сознание это есть. 

К. АНОХИН [01:04:14]  : Мы разделяем ведь правда самосознание и сознание. 

С. ШУМСКИЙ [01:04:19]  : Да, да. То есть вот эта структура модели, реальность, ну или структура сознания, если хочешь. Но понятно, что она усложняется. И, в общем-то, это на рисунке легко нарисовать облачко. А так, в принципе, это очень сложная функция. Мы видим, что она там состоит. у современных моделей из триллионов параметров. Это сумасшедшая сложная вещь, которая еще развивается в процессе, растет. То есть и самосознание возникает, психика развивается, усложняется, дифференцируется. Появляется понимание того, что есть объекты, а есть субъекты. Появляется понимание того, что ты такой же субъект, как другие. Появляется теория ума. Но это все процессы, которые расписаны там и выгодским пиажетом, они проходят все свои стадии. Так что вот эта вот модель и структура сознания, она, конечно, усложняется. И она не равна. У только что родившегося ребенка и у взрослого человека совершенно разные разные сознания. Хотя природа. Природа одна и та же, и тот и другой испытывает вот тот самый дискомфорт, о котором ты говоришь, да, это врожденная вещь, которая поступает. Но тем не менее, вот опять, если говорить про кто испытывает, для меня всё-таки это испытывает софтвер. От хардвера у него идёт сигнал… Но я это не понимаю. 

К. АНОХИН [01:06:24]  : Можно другими словами? 

С. ШУМСКИЙ [01:06:27]  : Я – это вычислительный процесс, у которого есть вот эта вот самая функция. Я – часть этой функции. Сознательный я – это часть функции регулирования моего организма. Просто потому что у нас так сложно устроено общество, и вообще мы животные очень высокоорганизованные, то у нас более сложная функция управления. И ощущаем мы ее более сложно, и наше субъективное ощущение Они обладают той степенью сложности, что мы считаем, что у компьютеров никак не может быть там. 

К. АНОХИН [01:07:29]  : Сереж, мне кажется, я, во-первых, не могу понять, но мне кажется, какая-то путаница, потому что ты говоришь, что это функция, а потом ты говоришь, ощущаем мы ее, эту функцию, значит мы это уже Раз мы эту функцию ощущаем, то мы это другое, чем эта функция. Я и про функцию не понял, а уж как мы ощущаем, кто такие мы, если это не функция сама, я уже совсем запутался. 

С. ШУМСКИЙ [01:08:01]  : Ну смотри, вот давай вот по тому, по той метафоре, о которой говорил. Вот есть компьютер, на нем игра. Я или не я, потому что там всегда есть мода, когда искусственный интеллект играет игроком. А ты можешь просто смотреть, что там происходит. Мы смотрим сейчас вот эту моду. И там есть движок, который нам не виден, который есть все равно программа. Но то, что ощущается в сознании, это видимая часть этой программы, это то, что выводится на PZS-матрицу, на графическую память. Это видимая часть сознания. И в этом смысле… там есть игрок, который играет от первого лица, у него есть руки-ноги, и ты в этом смысле можешь сказать, что я – это игрок в этой игре. Но мы понимаем, что за игроком стоит сложный игровой движок, и можем сказать, что на самом-то деле я – это вот этот движок. В зависимости от того, что мы имеем в виду, у нас просто слово «я» одно, а понятий под ним можно подвести несколько, как невидимый движок, так и видимое на экране изображение тебя как первого лица, которое, собственно, играет. в эту игру, он все понимает про эту игру, что он видит, как устроен мир, что в нем меняется. У него даже есть внутренние состояния, которые там высвечиваются слева. Это эмоции его, его здоровье, очки какие-то, которые он там набирает. Это эмоциональная часть, которая ему передается из движка. Но вот в этой метафоре видно, что да, там легко запутаться, но вот просто вот эта метафора помогает распутаться, выпутаться. 

К. АНОХИН [01:10:22]  : Если мы воспримем это не как метафору, а как буквальное описание, операциональное, то мы же согласимся с тобой, что движок не обладает сознанием. Чем тогда функционально движок агента в компьютере, выполняющий активные действия, имеющие эмоции, операционально отличается от биологического агента, который это все выполняет, но обладает сознанием? где та демаркация, которая вот этот софт, как ты говоришь, сознание в одном случае присутствует у биологической системы, а в другом случае в симметричной функциональной метафоре отсутствует. Что отсутствует? 

С. ШУМСКИЙ [01:11:33]  : Я думаю, что возможно… Ну, это, собственно, тот вопрос, который меня волнует, и я не могу дать на него четкий ответ. Но мне кажется, что можно исходить из того, что какое-то примитивное сознание есть у этого игрового движка, Но просто оно измеряется в каких-то там миллитононии, а у нас они, скажем, килотононии или мегатононии. Потому что ведь у него же тоже ты измеряешь сознание, это есть некая функция, которая, в общем-то, у простейших систем, которые они рассматривают, тоже есть. 

К. АНОХИН [01:12:29]  : Там я видел, Игорь написал ядовитое замечание в чат про нас тут, как философов. Я должен сказать, я его не принимаю. 

И. ПИВОВАРОВ [01:12:41]  : Не ядовитое, просто Борис Новиков философ как раз. 

К. АНОХИН [01:12:46]  : Нет, я вот к чему. Я чувствую одним из своих недостатков в обсуждении этих вещей, что я, поскольку физиолог, я мыслю, наоборот, слишком приземлённый и всё время хочу найти для обсуждения чисто механистическую базу. Не факт, что вообще механика здесь правильный язык, но Тем не менее, я все время хочу заимолить на структуры, протекающие в них процессы, материальные элементы этих структур, откуда возникают взаимодействия. и так далее. И в этом смысле моя теория сознания, гиперсетевая, она очень механистична, наоборот, не философская совсем. 

И. ПИВОВАРОВ [01:13:46]  : А в этом смысле теория сознания, которую, допустим, Сергей Шумский сейчас рассказывает, она у него предельно вычислительна. в ней все возникает но в вычислительной области и в том числе вот этот самый я этот субъект он значит там получается как бы возникает но неизбежно с развитием сложности с развитием регуляции я так понимаю сейчас что ну вот если это если этот тезис перефразировать часто что сергей сам говорил Получается, что у тебя этот субъект, сознание развивается, он неизбежно со временем разовьется как функция некая вычислительная у сознания, которое эволюционирует, в особенности если есть другие сознания вокруг. 

К. АНОХИН [01:14:40]  : Сергей Александрович, это правильно? 

С. ШУМСКИЙ [01:14:45]  : Я так и понимал теорию когнитома, что есть когнитом, это физика. Это физические связи, которые можно физикой исследовать. А когнитом – это, собственно, вычислительная структура, которая построена на вот этих связях. Одно другому не противоречит. не противоречит программа движка игры, но физике процессора. Это просто взгляд на одно и то же явление с двух точек зрения, где в одной ты концентрируешься на каких-то там мелочах, как конкретно текут электроны, если при таких-то граничных условиях, в таких-то транзисторах. А в другом случае ты концентрируешься на функции, которые вот этот мозг выполняет. И с этой точки зрения вот эти коги, они и есть элементы сознания, необходимые для того, чтобы ориентироваться в этом мире и чтобы адекватно реагировать на на любые изменения в мире, то есть выполнять ту самую функцию балансирования на краю небытия. 

К. АНОХИН [01:16:12]  : Есть важное отличие того, что ты говоришь от того, что у меня в теории. Коги возникают в результате определенного процесса. Могу говорить о нем. Но когда они возникли и как листья на ветвях дерева висят в когнитуме, их активность может быть осознаваема, а может неосознаваема быть. Они являются непременным элементом неосознаваемых психических процессов тоже, которые без этого и не способны без этих когов дробить, воспринимать и взаимодействовать с внешним миром, который, я с тобой согласен, ты правильно, ну, на мой взгляд, солидарен, нам не дан прямых ощущений. Это модель. Модель состоит из этих когов, но они, эта модель используется и без сознания. Поэтому в теории стоит отдельный вопрос. Какое дополнительное действие, какая дополнительная операция критически необходима для того, чтобы активность этих же когов перешла в осознаваемое. 

С. ШУМСКИЙ [01:17:41]  : Ну, хорошо. Можно и так. В этом смысле тогда коги – это часть программы психики, фактически. То есть, это вот тот самый движок софтверный, который движется. нашу психику, а какая-то часть этих когов, которые нами осознается, является частью сознания, она выполняет роль вот этого мэппинга внешнего мира, то есть создания карты, по которой мы ориентируемся, когда мы пробуем предвидеть будущее и действовать в соответствии с этим предвидением. 

К. АНОХИН [01:18:26]  : Ну это да. А то, что Игорь сказал и ты подтвердил, тут просто есть линия важная. Сознание, по мнению Игоря, на твой взгляд, возникает с увеличением сложности системы, с усложнением. Ты так думаешь? 

С. ШУМСКИЙ [01:18:50]  : Просто это точка зрения. 

С. ШУМСКИЙ [01:18:54]  : Есть простые регуляторы, которые не требуют картины мира. Ну, те же самые, там, терморегулятор какой-нибудь. Он, конечно, будет держать температуру постоянную, но он не будет знать, хозяин вообще дома или он уехал в отпуск, надо ли вообще держать это. Он такой тупой. И, конечно же, в живых организмах много и таких регуляторов. Но мозг, собственно, и дан животным, для того, чтобы все-таки строить предсказательные модели. Вернее так, со временем он приобрел такую способность, особенно с корой, то есть специальный слой мозга разрастался, потому что именно в нем копились модели мира. И это было выгодно, и было давление от гора, чтобы у людей вот эта часть мозга сильно разрослась, и модели, наши модели мира стали настолько сложными, что мы, в общем, себя считаем центром вселенной. 

К. АНОХИН [01:20:14]  : Я задал этот вопрос, потому что Эта же тема, которая на протяжении последних нескольких лет развивалась, она прямую связана с тематикой нашего обсуждения. Что нужно для возникновения сознания в системах искусственного интеллекта? И одна точка зрения, которые я придерживался всегда и продолжаю придерживаться, что нужны определенные архитектуры и структуры, в которых должен протекать свойственный только этим структурам процесс. А другая точка зрения, развивавшаяся на протяжении последних нескольких лет и над которой Многие из нас иронизировали или фыркали на неё. Принадлежала Суцкеверу. И его идея с 2017 года, по крайней мере, я помню, там 2018, что сознание самостоятельно возникнет в системе, при увеличении её сложности, что для того, чтобы система стала обладать сознанием, нужно наращивать первое, количество параметров в системе, количество глубоких слоев, то есть сделать её очень сложной с большим количеством очень глубоких слоев и параметров. А второе, насыщать её большим количеством данных. Многие из нас говорили на эти слова до прошлого года, что это просто дикий такой механицизм. Больше, больше, больше вдруг возникнет новое качество. И вдруг становится ясным, что если не сознание, то путём такого масштабирования появляется огромное количество, ну то есть десятки и сотни уже сейчас эмержентных свойств. И Сускевер пишет в посте год назад, что Машинное обучение это физика эмерженции. Появляются неожиданные функции у этих систем, оценивающие в частности эмоциональные отношения, которым их не учили. и так далее и это сейчас же вызывает тревогу и может быть может быть я не прав насчет специальных архитектур но там количество глубоких слоев увеличивается это часть моих представлений того что необходимо но может быть Чем больше будут моделей и больше данных, тем непонятным, но требующим понимания от нас образом будут возникать эмержентные вещи, в том числе и субъективные состояния, субъективные отношения. Чисто внутри я подчеркну как раз вычислительную парадигму. 

И. ПИВОВАРОВ [01:24:01]  : Я тут должен уточнить, вот смотрите, я Сергея Александровича вопрос был с подвохом, конечно, но все-таки он был немножко другой. Я его тогда спросил, и он ответил, и он подтвердил, что когда уже есть сознание у системы некой, и она развивается, то у нее последовательно при развитии сознания возникает субъектность то есть возникает этот я и собственно сергей говорил отвечал на это и на мой взгляд далеко не у любого мы же не говорили про усложнение мы говорили про развитие сознания у системы этому объекту агента который активизирует свое поведение, занимается прогнозированием и так далее, для того, чтобы достигать своих целей. И вот тут у него точно будет это развиваться. А вот что касается вообще любой сложности, что мы просто берем систему, как-то ее усложняем, вообще любым образом, или там эта система усложняется даже намеренно, например, не занимается решением своих целей. Я не думаю, что Сергей Александрович это имел в виду, когда говорил, что там сознание возникнет, в особенности как филологический опыт. Сергей Александрович, я правильно сейчас говорю? 

С. ШУМСКИЙ [01:25:37]  : На самом деле вопрос-то очень интересный, вот эта суцкеверская парадигма, которая с таким триумфом прошла. Но я напомню, что просто когда они переходили от GPT-1, GPT-2, GPT-3, Там у них не появлялось волшебства, вернее так, появлялась возможность у системы продолжать что-то, какую-то фразу, которую мы начали, очень правдоподобным образом. 

К. АНОХИН [01:26:13]  : Серёжа, я не согласен. Извини, пожалуйста, Сергей Александрович. Это всё началось с первой работы с трансформером, которую сделал Сузкевер. Как только они появились в шестнадцатом году, они в семнадцатом году начали их использовать для предсказания следующих символов в тексте. И у них получилось то, что они в своей статье 17-го года, уже 17-го года, и в материале, выпущенном OpenAI, обозначили вывод surprise. тому, что у этой простой модели, ну на то время простой, да, 17-го года, появилось эмержентное свойство. И какое? Они назвали это Sentiment Neuron, то есть нейрон чувств или отношений. На что они не учили, там, они большое количество текстов, рецензии из Амазона скормили, Но уж никак не учили модель расценивать хорошее или плохое отношение внутри этих лицензий. То есть нет. Это появилось на простых и рано. 

С. ШУМСКИЙ [01:27:39]  : Я согласен, что вот эти вещи появлялись. Но просто до GPT-3 не было вот этого вау-эффекта. На GPT-3 он появился, но прошло там еще три года. Прежде чем GPT-3, это 19-е годы, 17-18-19-е. По году у них шло GPT-1, GPT-2, GPT-3. А потом три года прошло, прежде чем они в 22-м выпустили чат GPT, который произвел революцию. Почему? Потому что с ней стало возможно разговаривать, как она приобрела свойства психики. Для этого они изменили схему ее обучения и ввели туда reinforcement learning. Они нанимали людей, которые ранжировали ее ответы, учили ее, воспитывали, что надо не просто продолжать фразу, как GPT раз-два-три, а надо генерировать совсем по-другому. И научили все-таки, да, что она начала понимать, что от нее хотят. И благодаря тому, что все-таки у нее была вот эта вот модель, реальность, то есть оказалось, что в языке Очень дофига всего содержится, очень много. Схема нашего мышления. Особенно, кстати, продвинуло ее то, что она изучала кроме обычных языков еще и машинные языки. Это очень сильно продвинуло ее аналитические способности. А последние модели, вот Gemini, они там ее обучали еще и видео, а это значит уже физика фактически бытовая. И звуки. Это уже такая мультимодальная модель мира. И эта модель мира уже обладает способностью понимания. И остается-то еще чуть-чуть добавить вот этот вот движок самости, чтобы она от себя… Сейчас-то они что, просто вход на выход пускают? И как бы из-за вот этой обратной связи, что у тебя движется, следующая мысль связана с предыдущей, и получается вот такой цепочки мыслей, и в общем-то они вполне себе вполне себе впечатляет. Но это слишком простая архитектура, когда вход на выход допускаешь. А в принципе, если ты это дело усложнишь, как хочешь. Мне больше нравится подход Лекона, особенно его последнее выступление, летнее выступление, где он говорил, как переходить от больших моделей от машин-леарнинга к автономным агентам, что именно надо новшество на уровне архитектуры. То есть надо запаять туда вот это вот стремление оптимизировать некую глобальную цель. То самое reinforcement learning минимизирует свое страдание, и тогда у модели появится понятие страдания и эмоций, потому что она будет вести себя эмоционально, она будет выбирать. те состояния модели мира, которые причиняют ей наименьшее. 

И. ПИВОВАРОВ [01:31:17]  : Сергей Александрович, ты слушай сейчас в энтузиазме не предлагаешь в общем путь. Я даже боюсь, куда сказать. В никуда. Если мы модели будем делать, так сказать, модели страдания, и она будет искать способы, чтобы она меньше страдала, то есть тем самым мы будем то, что в нее некую мотивацию будем закладывать, то не обернется ли это совершенно... Нету своей стороной. 

С. ШУМСКИЙ [01:31:47]  : Субъектность — это и есть мотивация. 

И. ПИВОВАРОВ [01:31:50]  : мотивация такой субъектность еще до конца непонятно я бы сказал я бы тут поспорил с разными тезисами но просто сижу молчу можно у меня по введению предложения 

К. АНОХИН [01:32:04]  : слишком долго говорим вдвоём. И ясно, что мы можем это продолжать ещё дольше. Может быть, надо нам замолчать и дать время, во-первых, другим участникам семинара поговорить, а во-вторых, я вижу, там очень много в чате всего, а мы игнорируем это. 

И. ПИВОВАРОВ [01:32:25]  : Мы не игнорируем, но мы тут с Сергеем Тереховым переписывались, мы вас слушаем, мы тут какие-то для себя тоже комментарии делаем. В этом плане вы разговариваете вполне интересно, очень даже. Сергей Александрович, Терехов, ты хочешь сейчас что-нибудь добавить? 

С. ТЕРЕХОВ [01:32:44]  : Спасибо, Игорь. Коллеги, я Сегодня студент, внимательно слушаю. Поэтому у меня, соответственно, вопросы студента. Можно и Константин, и Сергей. Первый вопрос вот какой. Мне на зачет один билет учить или три? Три билета такие это сознание, психика и интеллект. Отдельные билеты и надо по ним сдавать будет. Или все-таки мне надо какой-то один билет такой учить называется сознание в скобках психика или там через запятую там как бы интеллект. Потому что у Сережи интеллект и сознание на слайдах возникают в определенных любых последовательностях. Некоторые функции, которые там в состоянии чего, они без интеллекта вообще не могут быть как бы осмыслены. Соответственно, есть состояния там наблюдаемые, их должен кто-то наблюсти. то есть вот состояние, которое в системе есть, значит, должна быть какая-то функция, которая должна что-то делать. Короче, получается вопрос про вот это вот фундаментальное определение как бы сознания. Это вот первый такой вопрос, да. На самом деле у меня их много, но вот второе я сразу задам, чтобы не забыть. Я вот когда читал эту статью замечательную, ну я только давайте тоже опять я все упрощаю, ну она на 95 процентов, конечно, 97 процентов. Она, конечно, коммерческая. Она написана таким образом, чтобы та тенденция развития, которая намечается сегодня, была продаваемой. Продаваемой имеется в виду продаваемой обществу. Вот вы, например, знаете, наверное, что буквально там на днях или вчера, там чуть ли не позавчера заключен огромный, так сказать, контракт там 50 участников, но среди лидеров это IBM и компания Мета, которая является у нас признанной экстремистской организацией и запрещена. Они заключили огромный контракт на сумму там 50 миллионов долларов и 80. и 80 миллионов, и ожидают участия в этой активности около миллиона людей и так далее. Общественное восприятие достигает сейчас таких масштабов. Не создаётся ли впечатление, что вот эта статья, она обязательно должна быть устроена так, чтобы можно было вот это общественное восприятие потом подкармливать, достигать инкрементального роста какого-то. Вот эту функцию мы уже выполнили так, вот это на следующий год переносим, это мы включаем в техническое задание этого года, это мы немножко подстроим там и так далее. То есть она содержит, условно говоря, продаваемо, проверяемые такие действия, потому что если по-другому, то надо схватиться за голову. И вот в этой связи я просто взял вот эту табличку, которую я очень огромно благодарен, если бы не ваше упоминание этой статьи, я бы, конечно, на нее не наткнулся, потому что публикации в последнее время я отношу, как правило, уже к таким, ну, они у меня уже в папочку научных не попадают, они уже попадают мне в другую там отдельную папочку. что у них подоплека другая. Так вот я взял эту табличку и попробовал применить ее к электрической системе, электрической, так сказать, плану Уэлл-Ро. И вот система, так сказать, электрификация, так сказать, на уровне страны. И попробовал посмотреть, есть ли какие-то составляющие вот этих систем управления, контроллеров, которые принимают решение о том, что эта информация, которая к ним поступила, это именно про него, про этого, про меня, про контроллер, потому что она отделена от шума. Она по времени соотносится с тем, что я сейчас действую, то есть это актуальный сигнал. Она пространственная, потому что это не какие-то там шумовые сигналы. Она очищена от какого-то внешнего и так далее. То есть это, вообще так говоря, осознание этим контроллером того, что эта информация его. И после этого, на основе этой информации, он принимает решение о выработке управляющего сигнала. В основном, как вы понимаете, что контроллеры, вот контроллеры Фристона, они же не реалистичны совсем. Они там чуть ли не каждый день непрерывно там работают. И если спросить у Сергея Александровича Шумского, что такое функция в его понимании, то у него функция это какая-то такая административная функция. Скажем, лаборатория выполняет административную функцию. Какую функцию? Ну вот она проводит исследование. Вот это функция. Но это, конечно, не в математическом смысле функция. Так вот, в основном контроллер, конечно, ничего не делает. В 99% случаев с большими процентами он пользуется простейшими моделями мира, то есть шаговыми какими-то там моделями мира. И лишь изредка на более высоких уровнях эти модели начинают работать. Одна система подавляет другую и так далее. То есть это целая иерархия моделей, которые далеко не всегда, на самом деле, отражают мир. Теорема Эшби, она на самом деле звучит немножко по-другому, но сейчас не будем отвечать. Так вот, я вернусь. Я взял вот эту табличку и попробовал применить ее позиции отдельные к вот этой энергетической системе. И вы знаете, я нигде не нашел противоречия. То есть по каждому из пунктов вот этих вот действий, которые на табличке записаны, можно при правильном взгляде на хорошо устроенную техническую сложную систему, такую развивающуюся и так далее, и так далее, увидеть, что она действительно следует этим функциям. Возможно, господа философы просто, которые писали эту статью, они не в курсе о том, что существуют технические системы. И они просто, условно говоря, там заново придумали вот то колесо. про которое неизвестно какого цвета, поэтому непонятно как его придумать. А в действительности, на самом деле, так устроена система управления, реальная, так инженеры и мыслят. Вот у меня, собственно, два вопроса. Итак, учителям не три билета или один. И второй вопрос, как быть с тем, что есть система, работающая, технически созданная людьми и так далее, которая, вообще-то говоря, на 100% отвечает тому списку. Вот такой у меня Два из более широкого списка вопросов студенческих, но давайте пока про них. Спасибо большое, коллеги. 

К. АНОХИН [01:39:01]  : Сергей Александрович или я? Сереж, давай ты. 

С. ШУМСКИЙ [01:39:06]  : Давай. Значит, учить билеты вообще бессмысленно. Я считаю, что понимание – это и есть построение модели. И в этой модели ты… вот мы сейчас строим некую модель искусственной психики, Адамом назвали. И мы там просто все коги Костины, мы просто их пальцами чувствуем, мы их знаем, когда они рождаются, когда они применяются, на каком уровне, как они общаются друг с другом. И только так можно это все понять вместе. В рамках некой модели можно уже говорить о каких-то понятиях, которые получают смысл только в рамках модели. А учить три билета – учи, потом сдашь и забудешь. 

С. ТЕРЕХОВ [01:40:02]  : Но если бы ты строил модель не когов, а модели вот этих электрических элементов, ты бы реально так же делал? 

С. ШУМСКИЙ [01:40:09]  : Сейчас к этому перейду, да, потому что это меня вопрос очень волнует на самом деле. Мечтает ли общество об электроопции? То есть коллективное сознание, есть ли сознание у коллектива людей, коллективность. То есть мы понимаем, что мышление – это все равно оно коллективное. То есть понятно, что субъективные ощущения у каждого из нас свои, и мы там являемся субъектами и чувствующими, и мыслящими, но мысли-то, которые мы мыслим, они оформляются не у нас в голове, они оформляются между людьми. в процессе взаимодействия людей и выполняет некие другие функции, именно управление обществом. Только такие мысли и имеют смысл, только наука, она рождает все вот эти системы, формальные свои системы, только как некий коллективный эффект, когда множество людей разных поколений работают для того, чтобы у общества была модель реальности. Та модель, которую мы своими чувствами, например, не воспринимаем, Мы не воспринимаем атомы, мы не можем их увидеть, почувствовать, пощупать. Но мы знаем, что это общество. Общество знает в целом, что есть атомы, как они выглядят и как их рассчитывать, благодаря вот такой подсистеме, как ученые. Но каждый конкретный ученый, Он, если подумать, то он всю эту систему, конечно же, сам не мог вродить никогда. Вот он воспринял ее, вложил общество в него, он чуть-чуть что-то добавил от себя и выдал. Выполнил какую-то очень небольшую часть, какую-то функцию, не математическую. Но мышление как таковое тогда, если мы хотим понять, то мы должны понять, как устроено общество, как мыслит общество. И, например, тогда возникает действительно вопрос, а есть ли понятие осознания общества? Сознание в мозгу – это понятно, что оно может быть организовано некой физикой, когда когерентные какие-то явления в мозгу объединяют множество областей мозга в некую когерентную мысль, которая рождает ощущение понимания у человека. А есть ли аналог у общества такого? Может быть и есть, но я считаю, что в принципе теория машинного обучения, теория сознания, ну или теория интеллекта, она, конечно же, распространится на коллективное мышление. Более того, Фристон там уже вот издал со своими коллегами некий даже манифест о том, что, значит, что они создали институт изучения коллективного сознания, когда коллективы агентов Ну, управляют какими-то сообществами. Ну, вот, наверное, так бы я ответил на два вопроса твоих. 

С. ТЕРЕХОВ [01:43:48]  : То есть, четыре билета получить надо, я понял. 

И. ПИВОВАРОВ [01:43:50]  : Константин Владимирович. 

К. АНОХИН [01:43:53]  : Я считаю, что только три из трех названных. позиция по первому вопросу что однозначно и твердо это три разные вещи и нужно понимать каждую что сознание это процесс в когнитивной системе, системе обладающей знаниями, определенного качества. В ней текут и многие другие процессы, которые являются когнитивными, но являются психикой, в смысле не обязательно осознаются. Есть некоторая пороговая функция, определяющее возникновение состояния сознания внутри системы, обладающей психикой и когнитивными элементами. Это процесс или способность, возможность, потенциал присущей когнитивной системе, но есть масса примеров интеллектуальных действий, не требующих сознание механизированных автоматизированных уже если мы будем говорить про обучение еще одну вещь в ряду этих билетов там сложнее обучение в интеллектуальной системе ну зависит от сознания. Во многих случаях, во всех или нет, не знаю. Но, короче говоря, я разделяю. Сознание как процесс от других ментальных процессов, которые не осознаются. Для меня в момент осознания происходит специфическая вещь. И интеллект как способность от психики в зависимости либо процесса, либо структуры. Сергей Александрович, я понятным образом отвечал? 

С. ТЕРЕХОВ [01:46:57]  : Да, абсолютно понятно, только единственное, что это действительно слайд в отношении того, что сонарный, эффекторный, когнитивный и сенсорный уровни. И вот у меня только маленький комментарий, а можно ли, если это относится к сознанию, вот этот когнитивный уровень, то есть условно говоря, решил действовать. понимать следующим образом, что на самом деле решил действовать, это означает, что на самом деле всегда хочу действовать при рождении, при создании системы генетически. А в этот момент я просто позволил себе это свое желание реализовать. Ну, то есть, либо внешние условия сложились, либо, так сказать, картинка какая-то отпечаталась, либо, так сказать, энергетики хватает. И вот эта агентинность, она на самом деле происходит от того, что, ну, как бы некое позволение у системы возникает. То есть, можно ли это действительно, и оно, и оно вообще-то говоря, ну, с моей точки зрения, неделимо от интеллекта. То есть, по большому счёту, войти в состояние осознания, если не касаться при этом какого-то смысла интеллектуального осмысления вот этого состояния, невозможно. Я понял, да. 

К. АНОХИН [01:48:14]  : Для меня в этом списке различных форм, где проявляется сознание, агентивность и принятие решения является, может быть, самым сложным для моего понимания. Я не уверен, что здесь найдены все правильные слова. Потому что принятие решения может осуществляться и агентом без сознания. Многие вещи, как нейрофизиологи мы знаем, которые проявляются в поведении, и если была альтернатива из энного количества вариантов выполнения этого действия, а берется одно, то мы должны сказать, что был момент принятия решения. Но мы знаем, что на нейрофизиологическом, поведенческом, ментальном уровне это был неосознаваемый акт. То есть нельзя сказать то есть полный знак равенства между принятием решения и выбором действия, и принятием решения к действию и сознанием. Просто есть моменты сознательных принятий действия, и вот как определить принятие решения к действию, как определить тонкий вклад сознательного принятия решения к действию по сравнению со многими вариантами несознательных, Мне кажется, это сложный момент. Давайте я скажу еще вот, может быть, здесь по-другому на языке, который мне больше знаком и, может быть, вам тоже в терминах теории функциональных систем. Я в 2010 году, когда собрал ребят на зимний семинар и сказал, давайте мы попробуем заняться сознанием, потому что, кажется, появились биологические способы это сделать, инструменты. Я предложил такую модель, что вот если мы посмотрим на схему функциональной системы, то там есть афферентный синтез, который объединяет очень много компонентов. Мотивацию, память, обстановочную афферентацию, пусковые стимулы. И это всё варится. И Пётр Кузьмич Анохин писал, что вот в этот момент через реверберации и прокручивание этого всего и включается фактор сознания, который заканчивается афферентной синтез моментом принятия решения и формированием уже конкретной программы действия и акцептора результатов действия под этот конкретный результат и эту программу действия. Я предложил в десятом году, что Вот в этой схеме, может быть, не прописано, что такое сознание в полной мере, что оно может осуществляться вот так, как я её описал, и без сознания. И разница, на мой взгляд, заключается в следующем, что У Анохина это было УПК таким образом, что существующая у агента мотивация вытягивает из прошлого опыта все способы, которые были когда-то связаны с удовлетворением этой мотивации или получением результата необходимого агентам. С учётом обстановки пусковых стимулов происходит селекция и выбор наиболее адекватного этой обстановки и условия способа достижения результата, который в принятии решения и манифестируется. Отличие, мне кажется, такого поведения, которое может быть даже без сознания, от сознательного, что в момент сознания происходит глобальный доступ ко всему опыту, не тому, который был связан с данной целью, задачей, мотивацией, потребностью агента в данный момент. То есть, например, удовлетворение пищевой потребности и все вещи, где я нахожусь сейчас, рядом ли находится холодильник или магазин или ресторан, какое время дня, что может быть закрыто, как я раньше Не только это, а вообще всё из опыта и самых разных других функциональных систем. И вот когда есть такой глобальный доступ, то происходит некое воспламенение и момент осознания. Может быть это другие слова для того, что мне трудно сформулировать в этом пункте, про который вы сказали, что когда сознательный агент, то есть я как целое со многими функциональными системами моего прошлого опыта принимает участие в принятии решения, а не автоматизированная часть модуля меня, которая связана с данной потребностью и специализированными способами ее удовлетворения. Понимаете разницу, да? Я, как все функциональные системы, которые когда-либо были у меня с их способами получения результата, их опытом и так далее, как целые, принимаю участие в решении, вкладывая в него или вытягивая из этого опыта все, что может быть нужно. По сравнению с достаточно локальным афферентным синтезом, который использует некоторые ветви очень сложного дерева когнитома и по ним может вывести на действие без рефлексии на всех остальных ветвях этого опыта и моего я. 

И. ПИВОВАРОВ [01:54:52]  : Константин Владимирович, вот только тут я для понимания хочу... Сергей Александрович, у меня просьба, давай мы, у нас осталось полчаса времени. Извините, коллеги, я прошу прощения, я настолько в состоянии студента, что... У нас есть еще большая аудитория, давайте мы все-таки дадим тоже возможность еще всем по камере... Давайте я помолчу, я не буду отвечать. А там будут некоторые вопросы вам. Смотрите, тут люди пишут обычно вопрос ко всем докладчикам. Я буду адресовать вопрос конкретному человеку, потому что он скорее будет больше понятен. Вопрос от Виктора Казариного. Это будет Сергею Шумскому вопрос. Считаете ли вы, что количество... Ты говорил про то, что эмерджентно там будет возникать и как бы он будет дальше развиваться. Считаешь ли ты, что количество может перейти в качество только на основе одного уровня структур, например трансформеров, или для достижения сознательной функциональности нужен как минимум еще один более общий уровень в конструкции интеллектуальных систем? Проще говоря, из трансформеров или других модулей требуется создать какую-то более высокоорганизованную структуру для достижения полноценного, а не примитивного сознания. 

С. ШУМСКИЙ [01:56:07]  : Да, я так считаю, что трансформеры, если они будут в конце концов использоваться, это есть одна из подсистем, один из блоков системы искусственной личности. Но понятно, что чем они больше, чем они богаче, Чем больше эмерджетных качеств возникло, тем богаче будет это сознание. 

И. ПИВОВАРОВ [01:56:38]  : Вопрос от Владимира Смолина. Важно не может ли возникнуть сознание у искусственного интеллекта, а в чем польза возникновения такого сознания. Зачем нам это нужно? 

С. ШУМСКИЙ [01:56:53]  : Для меня это понятно, потому что я считаю, что человечество довольно-таки долго развивалось на На очень ограниченном ресурсе, ведь мы же за сто тысяч лет, у нас мозг не изменился, и его возможности, которые развелись в саванне для решения одних каких-то вопросов, А сейчас человечество поставлено перед совсем другими вопросами и просто банально коллективного коллективного вычислительного ресурса всего человечества перестало хватать для того, чтобы человечество развивалось дальше. Надо пополнить наше сообщество еще миллиардами искусственных личностей, чтобы это развитие продолжалось. Вот для чего. 

И. ПИВОВАРОВ [01:57:56]  : Окей. Я, честно говоря, думаю, что проблема человеческого сообщества не в том, что ума не хватает, а потому что не те люди, занимаются принятием решений, но... А у других не хватает ума, чтобы это изменить. Видимо, да, видимо. Но тут есть один вопрос, как раз ровно противоположный, и я его, кстати, Владимировичу адресую. Это был тезис, который тут люди вспомнили, что еще на первом OpenToxic, когда вы на первой конференции, когда вы делали свой доклад про сознание, то вы закончили тогда это парадоксальные некие фразы. Тогда, я помню, аудитория там вся была Мы должны изучать это, чтобы понять, как предотвратить появление сознания и искусственного интеллекта, потому что нам это не нужно. Как предотвратить появление в первую очередь спонтанно в системах искусственного интеллекта сознания и субъектности без существенного ухудшения карьеры. И в частности, как ограничить саморазвитие, формирование целей, потребление ресурсов, способность к репликации, кооперации. Вы по-прежнему придерживаетесь этого тезиса? И если да, то мы можем это сделать? 

К. АНОХИН [01:59:10]  : Да, меня это по-прежнему тревожит. И если на первой конференции меня тревожила эта абстрактная возможность, то сейчас она вполне материализованная. Я слежу внимательно за работами по эмергенции и всё, что происходит. Эмерженции новых свойств и качеств систем. И поскольку я не понимаю пока как они работают, то есть что там происходит внутри, но вижу эффекты эмерженции и меня очень интересует визуализация элементов, которые за это отвечают. У Сускевера в этой статье в OpenAI была еще очень важная вещь. Они написали, что в отличие от других моделей, вот то, что мы обнаружили, визуализировали, они нашли народ конкретно, то есть функцию. У нас появляется возможность управлять этими эмержентными функциями, которые возникают, локализуя их в соответствующих нейронах, отключая или включая эти функции. Я понимаю, что будет видимо движение в этом направлении но для этого нужно сделать то что я давно очень хочу я называл это прозрачный искусственный интеллект потом через некоторое время появился термин интерпретируемый я пока его не понимаю как мозг и не могу сказать Да, у меня есть это опасение, что возникнут непредсказуемые эмержентные свойства. И я думаю о том, как можно было бы предотвратить, предотвратить, когда это не в наших вообще руках обучение моделей. Или как можно управлять, по крайней мере. Мысль, которая у меня была тогда и она остаётся, что я бы ограничил, если бы можно было это делать обучением, сознание и персоналити в этих моделях где-то на уровне домашних животных. Но поскольку это стали большие языковые модели, которые пользуются человеческим языком, концептами и так далее, то мы уже прошли эту стадию и их на уровень домашних животных уже не опустишь. Тогда единственный вариант которые я вижу, иметь возможность, по крайней мере, делать эти модели более-менее прозрачными, с точки зрения понимания, какие слои, какие нейроны, какие функции в модели отвечают за те или иные качества, и иметь возможность включать и отключать их. Но это тоже не оптимальное решение, не знаю вообще. 

И. ПИВОВАРОВ [02:03:03]  : Я, кстати, подписывал письмо на полгода, которое ничем, конечно, не закончилось. 

К. АНОХИН [02:03:15]  : Призыв обратить внимание, скорее, чем реалистичный расчет, что это сделано. 

И. ПИВОВАРОВ [02:03:19]  : Это правда. К вам еще вопрос, кстати, Владимир Владимирович, от Виктора Казариного. Так как вы говорили, что сознание невозможно реализовывать на вычислительных структурах, то он упоминает, что есть такой известный мысленный эксперимент, когда у человека постепенно заменяют настоящие нейроны на искусственные, которые точно повторяют функционал. И вот если мы такой эксперимент делаем, и постепенно все заменяется на искусственные, то есть ли где-то граница, в которой сознание и черты личности перестают существовать? Или такой границы нет? 

К. АНОХИН [02:03:55]  : Я не думаю, что этот мысленный эксперимент имеет отношение к реальности. Что значит заменять на искусственные нейроны? Я говорил о том, что моё требование к сознанию это наличие определённой архитектуры. Если эту архитектуру вы сохраните, и каждый из нейронов будет выполнять ровно то же самое, что он делал биологически, сохраняя сеть, гиперсеть, кооперативные группы клеток в этой гиперсети, структуру и веса связей, избирательные активации. Но теперь будет это делать искусственно. На мой взгляд, собственно, биохимия, если она выполняется и заменяется чем-то другим, не является определяющим. Определяющим является архитектура. Архитектура, которая наполнена опытом соотношения агента с внешним миром, опытом, который специализирует группы элементов в этой архитектуре и создаёт, протаривает совершенно другие, причём не сетевые, а гиперсетевые, то есть там рёбра, связи. Если она есть, то там текут процессы соотношения агента с внешним миром. Искусственные эти элементы или нет, мне кажется, неважно. 

И. ПИВОВАРОВ [02:05:36]  : Ну, значит, у нас нет противоречий все-таки, потому что то, что вы сейчас говорите, это условно информационные процессы какие-то идут. Я думаю, что Сергей Александрович, когда говорит про вычислительные процессы, речь ровно про это же. В этом смысле вы согласны с тем, что на вычислительных процессах можно смоделировать сознание, но только в правильной архитектуре. 

К. АНОХИН [02:06:06]  : Я не уверен. Понимаете, у меня есть теория того, как устроен мозг когнитивного агента и дальше как в нем возникают необычный феномен сознания. И в этой теории есть, например, такие вещи, как кротовые норы, которые пронизывают системы нейронов, носящих опыт агента в разные времена, за счёт наличия у них общих элементов. И это тогда получается нелинейный процесс. В этих кротовых норах нет вычислений, там не течёт время, вообще не течёт время, потому что проваливание в эту кротовую нору, то есть активация этого нейрона извлекает ассоциативно из когнитома события и элементы опыта, которые были квази случайно связаны с этим нейроном в совершенно разные времена существования системы и все это извлекается одновременно. Как вы это вычислительно смоделируете? 

И. ПИВОВАРОВ [02:07:24]  : Все можно смоделировать вычислительно. 

К. АНОХИН [02:07:27]  : Может быть, может быть, но... То есть если мы это сможем спланировать, я просто не понимаю как. 

И. ПИВОВАРОВ [02:07:35]  : Окей, окей, но мы уже как бы, это уже более такая позиция. Хорошо. Сергей Александрович, к тебе вопрос от Виктора Казариного. Как могут быть ощущения? Ощущения свойственны особо вычислительным процессам. Это, видимо, цитата из тебя. Я, кстати, не очень понимаю, как ощущения могут быть. Допустим, не совсем понятен этот тезис применения к виртуальным мирам и виртуальным телам. Или вы считаете, что никакого интерфейса к любому виду миров необязательно убить? не очень понял вопрос я его тоже не до конца понял вопрос но ты считаешь что вот эти вычислительные процессы создают некоторые ощущения у как бы ну там вот у агента ощущение тоже по сути вычислительный процесс ну да если будет виртуальное тело в виртуальном мире то там тоже будут некие ощущения вот эти виртуальные 

С. ШУМСКИЙ [02:08:44]  : Ну да, модель будет. Будет модель взаимодействия с реальным миром. Ну да, да. 

И. ПИВОВАРОВ [02:08:54]  : Окей, ограничимся этим. По-моему сплошь вопросы от Виктора Казариного. Ну ладно, раз они есть, вот тут хороший вопрос я зачитаю. И можно ко всем. Когда начинается зарождение сознания у ребенка? Когда ребенок ударяет тебя по пальцу молотком, или видит себя в зеркале, или начинает проявлять сочувствие, или сознание включается в ребенка гораздо раньше? Когда, в какой момент? 

С. ШУМСКИЙ [02:09:22]  : Наверное, Константин Владимирович. Константин Владимирович. 

К. АНОХИН [02:09:28]  : Я думаю, что на многие вопросы такого рода мы сможем уверенно ответить, когда у нас будет хорошая научная фундаментальная теория сознания. Эти вещи должны выводиться из теории. Теория говорит, что это происходит тогда-то и тогда-то, и этот процесс такой-то и такой-то его можно увидеть а с точки зрения многочисленных психологических и эмпирических вещей которым не очень можно доверять я одна из вещей с которой общаюсь я работаю с группой перинатологов которые вынашивают выхаживают недоношенных детей. Они делают это с 25 недели эмбрионального развития. Это маленькие совершенно существа, по 400 с лишним грамм. И если смотреть на них лежащих в капсуле, то они демонстрируют за месяцы до рождения эмоциональные на маленьком личике признаки реакции, которые связаны с тем, что у них почти нет кожи и любые там прикосновения могут обжигать их. Но в общем есть масса оснований думать, что это возникает сознание как феноменальные ощущения в том числе боль так далее достаточно рано вопрос что и как это делает мозг и кто это я для меня центральный вопрос вообще во всей теории я считаю что теория сознания должна ответить на три вопроса которые мне четко и теории по Гнитому прописаны. Первое, что для появления сознания должен быть кто, который генерирует некоторое состояние. Второе, что это состояние должно быть квалиативным, то есть должна активироваться группа квалонов, которые образуют единое целое, квалон интегрированной информации. Пока когнитон не созрел и у него нет этих элементов, просто физиологическая активность нейронов, которые не несут этой качественной информации отношения субъекта к окружающему миру, и они формируются частью эмбрионально, а частью в результате опыта. Состояние сознания не возникнет, оно есть это. И третий очень важный момент, Эти квалоны, вот мы с Сергеем Александровичем это говорили, могут генерироваться когнитомом и без осознания. Третий момент это ignition, это воспламенение, что этот хаом должен достать обратно до всего кто, до всего когнитома. И я считаю, что это вот кусок, про который я говорил, глобальный офферентный синтез, глобальный доступ. что когнитом это все я, которые я когда-либо как агент испытывал в соотношении с внешним миром. То есть все функциональные системы, которые когда-то меня соотносили и они все живут как частицы опыта во мне. Сознание возникает в тот момент, когда этот холлон, состоящий из множества валонов как целого, получает доступ ко всем, начинает шевелить все элементы моего опыта с детства до сегодняшнего дня, как целого. Три части. Должно быть кто, потому что это структура, в которой текут эти процессы. Пока эта структура не сложилась, мой мозг это просто ведро макарон, физиологическая болтанка. Второе, что эта структура должна генерировать состояние из элементов, которые имеют качество и отношение к этому качеству, которое сложилось в ходе формирования этой структуры. отдельные коги. И третье, что мало того, что они должны все активироваться и какая-то сцена, она должна достать обратно до всего кто. Три части. Кто, что, назад, доступ к кто. 

И. ПИВОВАРОВ [02:15:04]  : Отлично, спасибо. Так, у нас вот есть одна поднятая рука, Андрей. Я потом еще один вопрос задам, который, по-моему, для всего сообщества нашего будет очень важен. Я думаю, что, честно, на этом у нас время закончится. Андрей. 

АНДРЕЙ [02:15:20]  : Добрый день. Я бы сказать, в первую очередь, спасибо за уровень дискуссии нашим спикерам. А мой вопрос Сергею Александровичу Шумскому. Вы говорили, что эмоции, как состояние плохо, хорошо ожидаются относительно функций баланса. Вы упомянули о том, что баланс, как я понял, является функцией противопоставления себя термодинамическому равновесию. противодействия антропии. И вы сказали о том, что человек в нашем случае является высшей ступенью эволюции в рамках регулирование равновесия этой функции. Смотрите, есть некоторые живые организмы, которые справляются с этим гораздо лучше, чем мы. То есть живут дольше, банально. Есть такие организмы, которые просто не умирают. То есть такой вопрос, что это за функция? Баланс вокруг чего происходит? Спасибо, Сергей Александрович. 

С. ШУМСКИЙ [02:16:56]  : Ну да, может быть живот дольше. Бактерии бессмертны, допустим. Но они решают эту задачу на своем уровне. Мы пошли по другому пути, решаем на своем более сложном пути, скажем так. И я думаю, что в эволюции нет понятия, кто хуже, кто лучше. Раз мы все выжили, все мы потомки одного предка, значит, мы одинаково приспособлены в каком-то смысле. Но просто на нашем пути мы пошли по пути усложнения и усложнения моделей мира. усложнения соответственно всех субъективных ощущений, которые связаны с этим моделированием. Это наш путь, лучше он или не лучше, для нас лучше. 

И. ПИВОВАРОВ [02:18:10]  : Спасибо. Константин Владимирович, пользуюсь случаем, что вы у нас тут в сообществе. Вот тут есть один вопрос, который на самом деле, сейчас я его разобью, он очень многих людей волнует. Вопрос такой из телеграмма. Какую роль играет внутренний голос в регуляции когнитома и насколько язык сознания включает в себя знаковую эмоциональную регуляцию? Метаязык когнитома формален или естественен? Я в этого дополню, что у нас регулярно возникают обсуждения того, а является ли сознание, сознание это языковой уровень или до языковой уровень. Есть люди, которые считают, что вот как бы для сознания обязательный язык. А есть те, кто считает, что сознание вообще возникает еще до языка. И в этом смысле особенно интересно становится ответ на этот вопрос, учитывая, что современные эти большие языковые модели, они языковые. Вы что думаете? 

К. АНОХИН [02:19:09]  : Я правильно понимаю, что когда речь идет о внутреннем голосе, то это буквальная формулировка языкового проговаривания каких-то вещей, то есть оперирования с помощью языка. 

И. ПИВОВАРОВ [02:19:28]  : Да, да. 

К. АНОХИН [02:19:32]  : Общий ответ на этот вопрос, которым я просто присоединяюсь, что сознание не требует языка. сознание не требует языка. 

И. ПИВОВАРОВ [02:19:49]  : Прекрасный ответ, спасибо. 

К. АНОХИН [02:19:51]  : Я проводил в мае этого года конференцию по сознанию животных и я собрал туда специалистов из 14 стран ведущих и один день был посвящен, я специально посвятил панораме сознание в животном мире начиная от растений это был мой маргинальный уровень для того чтобы понять где-то что-то возникает я считал что нужно четко понимать где этого нет и растений я взял как этот пример но в действительности есть серьезные группы и вот был из Испании руководитель такой группы из Plant Intelligence Laboratory, руководитель такой лаборатории, который считает, что есть. Но я думаю, что нет. Дальше идут гидры, и у меня был доклад по гидрам и оптическому имиджингу, и тому, как у них возникает самоорганизующаяся ритмическая активность во время поведения. И дальше шли членистоногие, моллюски, рыбы, птицы, приматы и в конечном счете человек. Был, например, фантастический доклад о том, как рыбы узнают себя в зеркало. Было много вещей, которые связаны с болью, самостимуляцией, удовольствием у моллюсков. Но я могу добавить к этому Эйнштейна, это так, в шутке ради, который говорил, что его мысли вначале имеют не языковую к природу, когда он решает какие-то новые проблемные задачи и только потом эти образы доходят до языкового оформления. То есть нет, не требует языка субъективный опыт. 

И. ПИВОВАРОВ [02:22:05]  : Здорово, спасибо огромное. 

К. АНОХИН [02:22:06]  : А в отношении языковых моделей это сложная штука. Да, у нас вчера семинар был про агентов на основе языковых моделей. Да, так они пошли развиваться, но я не исключаю, я несколько раз уже говорил про эмержентные свойства. Авторы статьи 1922 года, которая вызвала там наибольший шум про эмерженцию, они потом сделали анализ и выделили 137 эмержентных свойств, которые на данный момент, на тот момент были выделены. Я не уверен, что все из них, которые возникают языковой модели, я подчеркиваю, на основе анализа языковых вещей, эти свойства и категории имеют языковую форму и языковое выражение. То есть эти качества могут уже быть не языковыми. и даже не эксплицируемые языком. Типа вот отношения. Нравится, не нравится. 

И. ПИВОВАРОВ [02:23:23]  : Спасибо огромное. Но я думаю, что это действительно так и есть, потому что над языком там же создаются огромные векторные пространства. Вот в этих векторных пространствах там идут совершенно не языковые вещества. И вот вопрос от Антон Толоколонина. Даже два вопроса. Возможен ли прозрачный ИИ, если даже человеческий интеллект не прозрачен? И не связана ли прозрачность с осознанностью и сознанием? И нет ли тут противоречия? Мы хотим, чтобы он был прозрачным, а с другой стороны, нам не желаем ему сознания одновременно. 

К. АНОХИН [02:24:01]  : Прозрачный – это значит идеал ученого. Вот Дарвин вывел законы естественного отбора борьбы за существование, но как она осуществляется? Это же происходит здесь и сейчас в конкретных актах соотношения агента-животного с окружающим миром. И если бы можно было заглянуть внутрь и посмотреть что происходит в работе организма, миллиардов клеток, которые соотносят, то мы поняли бы законы этого процесса, потому что отбираются-то организмы по результатам актов, но на самом деле отбираются эти функциональные системы. Нейрофизиология 20 века шаг за шагом шла к тому, чтобы сделать процессы внутри интеллектуального агента, ведущего себя каким-то интересным, разумным образом, прозрачным, увидеть каким образом они осуществляются. И это сегодня в случае простых систем допустимо. Сейчас вышли несколько работ по C. elegans, которые буквально это делают. Прозрачная активность всех нейронов и синапсов нематоды, когда она выполняет те или иные виды поведения. И это можно декодировать. Да, 300 нейронов просто, но в более сложных вещах мы, по крайней мере, знаем какие-то принципы, как формируются эти специализированные группы клеток и нейронов, даже если мы не можем их пересчитать все и узнать все связи, как у C. elegans. Я думаю, что это же движение. Я в 2015-м пришел, когда в МГУ предложил проект прозрачный интеллект, искусственный интеллект. Но нет людей у нас, которые на нужном уровни, как Исинский, там вот работа первая вышла в шестнадцатом году, делали бы визуализацию нейронов разных слоев искусственных нейронных сетей. Сейчас это делают с языковыми моделями, мне не нравится как это делается, потому что выдергиваются отдельные нейроны с их функциями, нет сети, то есть как нейрофизиолог я бы делал это по-другому, но нет ребят, которые занялись бы этой визуализацией. Если ее делать, я думаю, что возможен прозрачный искусственный интеллект. Прозрачный, может быть, не во всех миллиардах элементов. но понимаемые по принципам все равно. Откуда берутся эти эмержентные нейроны, такие как у судской веры с отношением Sentiment Neuron, или откуда берутся У Ясинского была работа еще раньше, до Судской веры, 16-го года, когда они учили сеть распознавать лица людей, самих себя там. А сеть научилась распознавать текст в книгах на корешки, которых стояли на полках. Совершенно другое эмержентное свойство. Оно не подкреплялось и никак на выходе не фигурировало. Это можно изучать. Я думаю, что тот факт, что то ли разные по архитектуре и принципам обучения сети, как искусственная нейронная сеть и естественная нейронная сеть, демонстрируют возникновение в глубоких слоях специализированных элементов эмержентного качества крайне схожих Говорит, что, первое, мы не понимаем что-то очень фундаментальное, математическое, которое выше, абстрактнее всех различий между искусственной и естественной сетью. И второе, что оно понимаемо, оно должно быть точно понимаемо. Это на разных биологических нервных сетях это видно с разными устройствами и на разных искусственных нейронных сетях, начиная с простых, с одними механизмами reinforcement learning, кончая сложными трансформерами. 

И. ПИВОВАРОВ [02:28:59]  : Спасибо огромное. Так, Сергей Санчетерихов, у тебя там еще был прям короткий вопрос в конце. Давайте прям один маленький вопрос. 

С. ТЕРЕХОВ [02:29:07]  : Он вопрос-предложение. Константин Владимирович, вот я хотел на самом деле такую вещь сказать. Сейчас идет очень активная, так сказать, такая, ну, мейнстрим такой. Если обсуждаются какие-то социальные последствия какой-то технологии, то они крутятся вокруг социальных последствий искусственного интеллекта. Вот здесь вот, да? А не возникает ли такая ситуация, что в связи с работами и с потребностью в создании единой теории сознания, которая возможно все-таки, если ее строить естественно научным образом, а это хотелось бы получить, затронет элементы возможной психики и интеллекта и так далее, Так вот, не возникает ли на повестке дня такой вопрос о социальных последствиях того, что на планете может наступить, если такая естественная научная теория сознания, которая объясняет гетерогенность людей, распределение Не буду даже продолжать, чтобы там страшилок не рассказывать. Из нее будут следовать такие следствия, за которые лишение Нобелевской премии создателю теории ДНК, это покажется детским лепетом. То есть не возникает ли новая потребность? 

И. ПИВОВАРОВ [02:30:22]  : Спасибо. 

К. АНОХИН [02:30:24]  : Да, возникает. Я постоянно об этом думаю. Дэнот сказал когда-то, что когда мы поймем сознание, сознание у людей изменится. Но я не знаю, так сказать, операционального преодоление этой проблемы или этого опасения. А что, не работать? Вот отказаться от движения в эту сторону? Но люди будут все равно работать. Это то же самое, как вот на шесть месяцев заморозить разработку G5. 

С. ТЕРЕХОВ [02:31:07]  : Сейчас задача ставится так, чтобы достигнуть консенсуса. А это теория фундаментальности со-научной, это далеко не консенсус. 

К. АНОХИН [02:31:16]  : Не консенсус, нет-нет-нет, конечно, но это более серьезная и глубокая вещь. 

И. ПИВОВАРОВ [02:31:24]  : Это ты поднял прям такую тему гигантскую, на которой можно отдельно разговаривать. я как минимум видел одну дискуссию про это где вот там был ликун еще бенжио еще там макс тегмарк еще там не помню мелани там какая-то вот они как раз опасность да ничего опасно безопасность и еще бенжио написал по прекрасный пост недавно вот про это я читал как раз про свои внутренние переживания что он тоже осознал там что в этом может быть там какая-то какие-то риски он тут начинает делить свое время между разными вещами но это это гигантская тема может мы еще когда-нибудь обсудим отдельно я предлагаю заканчивать мы уже два с половиной часа честно отработали и я получил гигантское интеллектуальное удовольствие и предлагаю всем Высказать огромное спасибо нашим замечательным участникам. Кстати, Владимир Владимирович, спасибо огромное, что присоединились к нам. Нам было очень приятно с вами. Сергей Александрович Шумский, Сергей Александрович Терехов. 

С. ТЕРЕХОВ [02:32:25]  : Пошел учить билеты. 

И. ПИВОВАРОВ [02:32:27]  : Мое личное огромное спасибо всем вам. Коллеги, если хотите, прямо три слова в конце сказать, попрощаться, будет здорово. 

К. АНОХИН [02:32:38]  : Я хочу поблагодарить всех за два с половиной часа. Это непросто. И должен сказать, что тема эта, конечно, я недоволен многими вещами, которые я говорил. Их можно говорить короче, она порождает многословие. Но, в общем, как получилось, так получилось. 

И. ПИВОВАРОВ [02:33:04]  : Но мы сделали хороший подход, я думаю. 

С. ШУМСКИЙ [02:33:07]  : Большое спасибо за очень интересный семинар. Маленький вопрос. Чат будет доступен участникам и в записи? 

И. ПИВОВАРОВ [02:33:16]  : Чат, как обычно, да. Сделаем, да. Спасибо. 

С. ШУМСКИЙ [02:33:18]  : Сергей Александрович? 

И. ПИВОВАРОВ [02:33:20]  : Сергей Александрович? 

С. ШУМСКИЙ [02:33:23]  : Хочу сказать, что я лишний раз убедился, что мышление рождается между людьми. И у меня просто родились очень интересные мысли, как можно моделировать сознание в нашем подходе. Кстати, Владимир Владимирович в этом смысле очень сильно помог. То есть, как сделать вот этот... Халон. Мне кажется, это все возможно. 

И. ПИВОВАРОВ [02:33:59]  : Отлично. Спасибо. 

С. ТЕРЕХОВ [02:34:03]  : Сергей Александрович Терехов, ты еще финально... Коллеги, я очень благодарю за совершенно потрясающее обсуждение и за очень фундаментальную базу, которая была построена. И мне нравится, что мы, в общем-то, достаточно открыто говорили, хотя, конечно, темы могут быть еще более, там, такие жаркие дискуссии вызывать. И будет здорово, если, Константин Владимирович, мы вас очень попросим находить время к нам присоединяться, потому что вот эта фундаментальная составляющая, она очень нужна этому семинару, и вообще людям нужна. Спасибо огромное. И Сергей Александрович, конечно, тебе тоже. 

И. ПИВОВАРОВ [02:34:42]  : Я от себя говорю всем еще огромное спасибо. Было очень интересно. И Антону передаю слово закрыть наш семинар. 

А. КОЛОНИН [02:34:51]  : Коллеги, мне нечего добавить. Всем огромное спасибо, что пришел. Константин Владимирович, спасибо. Сергей и Сергей. Спасибо за участие, спасибо всем участникам, кто задал вопросы, и Игорю, который провел этот замечательный семинар. До новых встреч и приятного вечера. Всем счастливо. 

С. ШУМСКИЙ [02:35:10]  : Спасибо. Спасибо, до свидания. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
