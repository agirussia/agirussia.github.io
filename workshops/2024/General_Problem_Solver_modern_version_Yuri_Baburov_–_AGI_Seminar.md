## 26 сентября 2024 - General Problem Solver, современная версия - Юрий Бабуров — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/10Q-lZ7ym2A/hqdefault.jpg)](https://youtu.be/10Q-lZ7ym2A)
- [Видео в ВК](https://vk.com/video/@agirussia?z=video-210968399_456239196)

Суммаризация доклада:

1. Введение и исторический контекст:
   Юрий Бабуров представляет современную версию обобщенного решателя проблем, начиная с обзора исторических попыток создания автоматических систем решения задач. Он упоминает General Problem Solver (GPS) 1950-60-х годов как важную веху в этой области. GPS использовал принципы начального состояния, целевого состояния и набора операторов для перехода между состояниями. Докладчик подчеркивает, что хотя эти ранние попытки были ограничены вычислительными мощностями и могли решать только простые задачи, они заложили фундамент для современных подходов.

2. Современные проблемы и подходы:
   Бабуров обсуждает текущие сложности в создании универсальных программ, способных работать в непредсказуемых условиях. Он подчеркивает необходимость иерархического подхода к решению сложных задач и описывает метод A* (A-звездочка) как пример эвристического алгоритма поиска. Докладчик также рассматривает современные подходы, включая использование машинного обучения для оценки качества решений и применение больших языковых моделей в качестве "компьютерных экспертов". Однако он отмечает, что эти методы сталкиваются с проблемами масштабируемости и требуют значительных вычислительных ресурсов.

3. Предлагаемый подход и его демонстрация:
   Юрий представляет свой подход к созданию обобщенного решателя задач. Ключевые аспекты включают: создание локального окружения для тестирования, использование естественного языка для формулировки задач, и иерархическое планирование с возможностью разбиения на подзадачи. Он демонстрирует пример решения задачи в "мире кубиков", показывая, как система пытается генерировать и выполнять последовательность действий. Бабуров честно признает текущие ограничения подхода, включая неточности в решениях и необходимость дальнейшей доработки алгоритмов.

4. Роль Reinforcement Learning и будущие перспективы:
   Докладчик подчеркивает необходимость применения обучения с подкреплением (Reinforcement Learning) для улучшения качества решений. Он сравнивает свой подход с методами, используемыми OpenAI и другими компаниями, отмечая потенциал для значительного улучшения при использовании больших объемов данных и вычислительных ресурсов. Бабуров обсуждает перспективы и вызовы, стоящие перед областью, включая необходимость увеличения вычислительных мощностей, проблемы с созданием и разметкой больших датасетов, и вопросы эффективности разбиения задач на подзадачи в сравнении с использованием единых систем.

5. Дискуссия и критика:
   Доклад вызвал оживленную дискуссию среди участников семинара. Обсуждались различия между задачами обучения и задачами рассуждений, вопросы о формализации понятия "задача" и критериях решенности. Некоторые участники выразили скептицизм относительно подхода, основанного исключительно на увеличении вычислительных мощностей, предлагая вместо этого сосредоточиться на улучшении структур для организации знаний о простых объектах и явлениях. Дебаты также затронули роль человека в постановке задач и выделении объектов, а также перспективы создания сильного искусственного интеллекта в ближайшем будущем. Несмотря на разногласия, участники согласились с тем, что область быстро развивается и имеет потенциал для значительных прорывов в ближайшие годы.






S03 [00:00:01]  : Коллеги, всем добрый вечер. Мы начинаем очередной семинар русскоязычного сообщества разработчиков сильного и общего искусственного интеллекта. И сегодня у нас в гостях Юрий Бабуров. И он нам расскажет современную версию обобщенного решателя проблем. Юрий, пожалуйста. 

S01 [00:00:20]  : Добрый день. Сегодня хотелось бы поговорить про… Общие решательные задачи, как способ приблизиться к искусственному интеллекту, может быть, очень замечательный способ, а может быть и нет, сейчас узнаем. Ну, давайте поговорим в целом об автоматическом планировании и автоматическом решении задач. Мы хотим построить систему, которая работает автономно, в каких-то условиях, мы заранее не знаем каких, ну или может немного знаем в каких условиях. В некоторых случаях мы даже очень хорошо знаем, какие условия есть, но системы достаточно сложные, или там может быть сложности с железом, могут быть сложности с соседними программами рядом, могут быть сложности с людьми, которые всякие странные штуки вводят в вашу программу. Но в итоге получается, что программа не работает. Соответственно, программы мы в итоге делаем конкретно под задачу, но все равно они плохо работают. О том, чтобы сделать универсальную программу, казалось бы, вовсе не идет и речи в таких условиях. Тем не менее, в каком-то виде понятно, что сложную задачу нужно решать иерархически. То есть мы как-то разбиваем задачу на подзадачи. Можно рисовать эти задачи-подзадачи у себя где-нибудь в блокнотике со стрелочками между ними, и после этого полученные Решение задачи становится планом выполнения задачи, и мы его реализуем в виде компьютерного алгоритма. Тем не менее, напрямую иерархическое планирование, оно не адаптивно. Вот у нас есть четкий план действий, мы его придерживаемся. Мы не можем цернуть влево-вправо, но можем какие-то условия написать, но тем не менее к новой среде мы таким образом не адаптируемся. Метод Азвёздочка является методом поиска, который позволяет как-то немножко улучшить ситуацию. Например, представим ситуацию, что нам нужно приехать из города С в город Е, и мы хотели бы теперь понять, каким путём двигаться. Видно мышку у меня на слайдах? 

S03 [00:03:24]  : Мышку видно, да. 

S01 [00:03:26]  : Отлично. Значит, мы начинаем со стартовой точки S и теперь думаем, в какую бы сторону двигаться. Например, S-A, потом S-X, X-E. Оцениваем, путь получился длиной 1 плюс 4 плюс 2 длиной 7. А могли бы пойти там в другую сторону. S, B, D, E. А у нас получился длины 15. Значит, как же нам понять, каким путем лучше двигаться? Давайте решать, делить задачу как-то на подзадачи. Например, мы можем попробовать оценить из текущей ситуации, сколько нам осталось двигаться. Для этого мы можем посчитать примерно расстояние на графе. Просто какое примерно расстояние у нас здесь есть до точки. И потом после этого мы берем Берем и говорим, что в случае... Вот здесь маленькие цифры в конце, значит, расстояние будет небольшое. И здесь вот у нас достаточно компактный маршрут, небольшой. То есть мы двинемся вот в эту сторону, дальше видим, что здесь мы ближе к цели. А далеким маршрутом не пойдем, потому что от него мы удаляемся от цели. В этом идея алгоритма «Отзвездочка». Более подробно можно посмотреть на Википедии или где-нибудь еще. Я прям сильно в детали опускаться, думаю, не буду. В общем, к чему это приводит? Что у нас появляется эвристика, какой-то способ оценить расстояние промежуточное из каждой точки, потом уже дальше делать действие. Значит, чем это нам поможет? Расскажу вначале, что такое General Problem Solver. Давным-давно был разработан компьютерный алгоритм, который бы можно было внести в произвольную программу, и он ее пытался решить. Больше всего это было похоже на пролог. Но у нас идея не в этом, а в том, что мы пытались, по сути, иерархически строить программу с учетом каких-то там условий и добавляя какие-то условия, которых у нас не было при попытке решения задачи. Также у нас было начальное состояние, целевое состояние набора операторов для перехода. Уже был эвристический поиск для нахождения пути решения. То, что вот, например, в алгоритме звездочка. И мы, двигаясь по пути решения, как-то... Сейчас, секундочку. Мы как-то в общем решали задачу. Но дело в том, что хотя и в общем получилось унифицировать задачи разные, но Все равно, во-первых, компьютеры были маленькие, задачи были простенькие, во-вторых, даже там сразу столкнулись с ограничениями разными, вычислительными, и столкнулись с тем, что программу надо писать каждый раз. Ну, вообще говоря, из этого сформировался, можно сказать, что из этого сформировался heurистический метод. Давайте спросим человека, как он поступил, потом запрограммируем это в виде алгоритма. И хорошо, если получится еще и оценить близость цели по мере приближения, например, получилось нам сделать шаг или не получилось, или, например, поменялось ли что-то в окружении или не поменялось. Таким образом алгоритм получал сделать более адаптивным. Но, собственно, проблемы аваристического метода понятны, потому что человек дорогой, каждый раз привыкать к человеческому эксперту для решения задач достаточно сложно. Поэтому всё плохо. И долгое время было, и есть до сих пор по большей части плохо. То есть, нам каждый раз всё равно что-то не работает. А в нашем алгоритме человек приходит, смотрит, ага, так у вас вот здесь не то-то, не винт, а болт. Ну, давайте, не болт, а шуруп. Вам надо немножко по-другому было написать алгоритм сборки конструкции. И переписываем алгоритм, после этого новую версию программы ставим, и она работает. А потом снова падает с какой-нибудь ошибкой из-за непредсказуемости окружения. Также есть попытки написать алгоритмы с помощью компьютера. И они в чем-то даже работают. То есть простые олимпиадные задачи компьютер уже научился решать и очень даже хорошо решает на уровне лучше среднего, наверное, на уровне лучше уже среднего программиста. Что компьютер не решает? Компьютер не решает сложные алгоритмы. Он их не может писать, потому что ему надо обследовать хорошенько задачу, ему надо сформулировать это в виде технического задания. И сложно алгоритм ему разбить на такие стадии, которые можно было бы... Которым можно было бы частично, в каждой стадии частично решать задачу. С разбиением на подзадачу тоже у компьютера есть проблемы. Что еще подумали? Давайте мы подробно опишем наш мир. Например, скажем, что в мире можно… что у машины четыре колеса, тогда может быть алгоритм для машины компьютер будет составлять более правильно. Также вторая идея то, что мы можем использовать машинное обучение для оценки качества тем или иным образом. Например, мы можем какую-то подзадачу описать в виде алгоритма машинного обучения или же можем оценивать, что мы там приближаемся к цели. Тоже какой-то оценкой с помощью машинного обучения. Я не углубляюсь, сейчас детали рассказываю в общем виде, но я думаю, может быть такое обобщение как раз будет полезным сейчас. Ну и соответственно, какие еще мысли возникли? Что человек дорогой, давайте дорогого человека мы будем эмулировать с помощью компьютера, с помощью большой языковой модели, и спрашивать у компьютера, что бы человек нам сказал, как решать задачу. Таким образом, у нас появился компьютерный эксперт по решению задач. И, ну, заметим, что сложные задачи компьютер спланировать все равно не может, ну, ввиду того, что и окружение у нас сложное, и И сложные у нас задачи. Но, тем не менее, может как-то он может делать следующий шаг, мы станем ближе к цели, потом снова попросим компьютер что-то еще сделать, станем еще ближе к цели. Ну и в таком виде оно как-то уже потихоньку начинает работать. Ну, соответственно, вот давайте спрашивать компьютер не один раз, а часто. Компьютер при этом должен быть достаточно умный, чтобы текущее состояние оценивать и каждый раз генерировать нам алгоритм в следующих ближайших действий. Ну и у него есть недостаток, что требуется или локальная видеокарта или видеокарта какие-то мощности для мощного современного компьютера с большими языковыми моделями, или же оно всё будет расположено в интернете, и мы будем то же самое грузить из интернета. Ну, как-то этим люди пользуются, но пока что оно работает плохо. Значит, поэтому есть мысль такая, не до... как раз давать компьютеру генерировать не только ответ, но и последовательность промежуточных шагов. И, во-вторых, это не сильно помогает. В целом, нужно всё равно использовать до обучения, чтобы этот подход действовал. То есть, для этого нам нужно понимать, какие из шагов не сработали. Здесь мы возвращаемся как раз к идеям reinforcement learning. то, что мы должны выделить те шаги, из-за которых мы совершили ошибку, и научить потом компьютера эти шаги не совершить. Так сейчас работают последние модели OpenAI. И до сих пор они дообучаются. То есть они какое-то время уже дообучались, но теперь их можно самих оставить дообучаться, и они будут работать. Теперь давайте попробуем сами как-то сделать что-то подобное, но немножко на другой базе. Попробуем подумать, как бы это всё могло работать, не находясь на серверах OpenAI, а если мы это будем учить сами. Есть ли вопросы по первой части? После этого перейду ко второй части. 

S03 [00:14:42]  : Коллеги, есть вопросы к Юрию? Окей, давай тогда дальше. 

S01 [00:14:52]  : Вторая часть у нас будет демонстрационная. Сейчас вот пока что скрою. Значит, чтобы локально с этим всем работать, нам требуется такая штука, как окружение. То есть мы хотим локально воспроизвести воспроизвести какое-то окружение, и в этом окружении заставить компьютер выполнять какие-то действия. Ну, например, в случае, если у нас окружение — это компьютерная папка, мы можем с этой папкой делать какие-то действия. Загружать файл, сохранять файлы, туда создавать вот каталог. удалять файл каталоги. Или, например, у нас есть стандартный для 60-х годов мир кубиков, в котором у нас есть следующая операция. Мы можем взять, ну, есть линейное пространство, в котором какие-нибудь есть палочки или какое-то пространство, на которое мы можем ставить блоки. Значит, вот это позиция номер 1 для установки блока, это позиция номер 2, это позиция для установки 3. Вот мы, например, поставили блок A, блок B под ним, а под ним блок C. И теперь представим, что у нас есть рука, и эта рука может брать в себя какой-нибудь предмет с этой позиции. Например, мы взяли предмет с позиции А и положили его в руку. Вот он оттуда ушел. Сюда он добавился. А потом мы из А поставили его в позицию, например, 2. Вот сюда вниз он поставился. Потом какой-нибудь другой блок взяли в руку. И поставили его в позицию 3. Вот у нас есть состояние нашего мира. Вот у нас есть с этим миром, соответственно, операции, какие-то действия. И у нас есть методы ещё, которые могут понять состояние этого мира. Теперь мы в этом мире можем теперь решать какие-то задачи. Для этого нам нужен судья. Судья – это такая штука, который запускает в мире на выполнение какую-то задачку, например, у нас был блок, в котором на первой позиции были блоки ABC, а в остальных позициях блоков не было. И после этого мы формулируем задачу, например, задачу Хановьских башен, что требуется переместить блоки из позиции 1, вот здесь, в позицию 2, причем это в определенном порядке. Запускаем, инициализируем наш мир, отправляем судью Вначале запустить решение, а потом посчитать, оценку качества дать. Оценка качества производится следующим образом. У нас есть критерии какие-то для выполнения. И мы считаем, какие критерии выполнены в каком количестве. Так мы понимаем, насколько задача решена. Частично, не частично, вообще хоть как-то решена или нет. Ну и соответственно нам требуется решатель задач. Так может в такой системе выглядеть решатель задач. Решатель задач в такой системе это следующая конструкция. Представим, что у нас есть какой-то способ задать компьютерный алгоритм в следующем виде. что мы можем или делать какие-то действия, выполнять какие-то действия в этом мире, или выполнять какие-то программистские действия переменно и присвоить значение 0, например. Или же мы можем какие-то условия выполнить. Но главное, мы можем взять и вместо задачи естественным языком сформулировать какую-то подзадачу, И компьютер, поглядев на наше состояние, на наше описание мира, возьмет с помощью ГПТ также последовательность действий для этой подзадачи нам скажет. Значит, таким образом можно решать достаточно сложные задачи. Ну вот, покажу, как может выглядеть провод в такой системе. То есть, мы говорим, что у нас есть task. И, соответственно, пишет последовательность действий, выдая нам на выходе для решения этой задачи. Соответственно, компьютер нам генерирует последовательность действий. Мы эту последовательность действия выполняем. Если встречается какая-то подзадача, мы ее снова отправляем к компьютеру на анализ. Это наше приближение к объекту. И потом снова отправляемся выполнять задачу. И такой подход даже частично работает, ну, точнее, работал бы, и работал бы хорошо, если бы компьютер был бы хорошо обучен в таком виде действий. Но работает он далеко не всегда. Например, покажу пример лога эпичного. Значит, что компьютер в таком случае может сгенерировать? Значит, мы можем сказать, Значит, решив, значит, данную задачу, он нам сделал 9 действий. Значит, первое действие, он считает, что нужно блок А с позиции 1 в позицию 2 выдвинуть. Для этого он, значит, смотрит, что сейчас происходит, и снова генерирует подзадачу. Под задачу он сгенерировал, также говорит оцени критерии, что сделать. Ну ладно, там пооценивал, как-то вроде понял, что ему делать. Теперь говорит, значит, сделай, возьми там в руку что-то. и проверить, что у тебя в руке получилось. И в данном случае, например, ломается. Говорю, что он плохо понял условия. При разных запусках на самом деле можно получить очень разные состояния. В каких-то запусках он частично или почти полностью решает задачу, но задача достаточно объемная получается, если ее разбивать. Где-то он уходит даже в бесконечный цикл. Где-то он из задач выполняет первые несколько шагов, потом спотыкается. На самом деле, сложность тут в том, что мир надо специфицировать лучше, более подробно ему описывать, что есть. Но даже это не важно. Важно то, что он плохо умеет работать, в принципе, с такими действиями, когда нужно вызвать какие-то действия. Но это тоже не проблема, ведь мы можем каль сделать. Если компьютер где-то ошибся, мы сбрасываем текущий алгоритм и снова его запускаем от того состояния, в котором он попал. Заодно и говорят, что в прошлый твой запуск ты споткнулся, была такая ошибка. И всё было плохо, но теперь надеюсь, ты исправишься, зная эту ошибку, а сгенерируешь новый план и снова действуй. Таким образом, компьютер в целом более-менее с задачей не сильно сложно исправится, но возникает та же самая проблема, что без заранее иерархического планирования каких-то подзадач, каких-то описаний, что нужно делать, ему достаточно тяжело, то есть надо еще больше усложнять коммуникацию. В этом плане, Решение от Стробери, было сделано следующим трюком. То, что мы компьютеру говорим не только задачи и не только текущее состояние, мы ему говорим всю последовательность действий, которые он совершал сначала. И таким образом, хоть и получается очень медленно, но тем не менее компьютер может действительно исследовать пространство действий, пробовать разные действия и решать сложные задачи. То есть если мы посмотрим разницу между классическим GPT-4 и действиями O1 Preview, во многих ситуациях то как раз видим, что различаются действия в том случае, когда задачи достаточно сложные, Причем он настолько сложный, что с наскоку их не решить. И требуется генерировать какие-то гипотезы, проверять эти гипотезы. Но тем не менее, безусловно, тут еще играет роль дообучение, reinforcement learning. В случае этого дообучения Компьютер понимает, что, во-первых, не надо повторять, делать повторные саптаски, например. Значит, вместо этого нужно делать действия. Также он гораздо более разнообразно исследует ситуации и гораздо более хорошо начинает разбираться в собственных ошибках. Потому что вот обычная версия, она очень плохо, здесь всего 4 мини. Ну, в общем, тем не менее, на классическом алгоритме без reinforcement learning данная штука, ну, едва-едва работает, но для сложных задач тоже не работает. И даже на маленьком таком примере много таких нюансов видно, почему оно не работает. Безусловно, доделать его нужно, тем не менее работать оно толком не будет. Увы, это текущее состояние вещей, то есть мы знаем способ это исправить. Нам нужно обучение, нам нужно reinforcement learning. OpenAI как раз лидеры в том, что они двигаются в этом направлении. Более того, результаты данного обучения можно использовать еще и при обучении классических вариантов, уже без reinforcement learning. Ну, в общем-то, по основному материалу у меня всё. Единственное, сразу хочу сказать, что я призываю вас вместе вот эти вот примеры добить и попробовать сделать всё-таки, чтобы эта штука работала. Вначале без дообучения, потом с дообучением. То есть можно взять Google Collab, например, для того же самого. Очень хочется иметь локального конкурента для OpenAI и научиться решать сложные задачи. Я не упомянул еще один подход, еще одну модификацию. Это рулевую модель. Здесь у нас все равно, хоть и с обтаски есть, у нас только одна роль. Ролевая модель действительно тоже это еще один способ улучшить качество, но тем не менее он опять же фундаментально качество не улучшает, поэтому вот сразу если кто-то хочет спросить, что может сделать, чтобы там было несколько ролей, там был бы там какой-нибудь критик, какой-нибудь там анализатор и вот разные там действия выполняли бы, выполнял бы компьютер от разных ролей. Но вот сильно бы лучше не стало. Иногда получается, и в принципе есть проекты типа BabyAGI и прочие, которые говорят, что давайте, вот у нас будет Project Manager, у нас будет тестер, у нас будет программист. И мы будем двигаться решать эту задачу, при этом составлять еще, писать баги, потом эти баги программист будет исправлять, Project Manager будет руководить, а тестер — находить новые баги. В общем, подход в целом работает по-прежнему плоховато, требуется дообучение. Возможно, с дообучением эта система хорошо зайдет. У меня по основной части на этом всё. Давайте, пожалуйста, задавать вопросы. 

S03 [00:30:03]  : Дмитрий Иванович, у Вас вопрос? Да, я слышу. Так что, задавать его или читать? Ладно, давайте я прочитаю. Вопрос от Дмитрия Ивановича Свериденко. Знает ли докладчик что-либо о задачном подходе, семантическом моделировании и его важном разделе логико-вероятностный подход к решению задач? 

S01 [00:30:32]  : Я про онтологию упомянул. То есть, онтология для описания мира помогает лучше. лучше представлять пространство. Собственно, сами по себе вот эти задачи, они ничем не отличаются от задачных подходов и многих всяких других способов. Я показал, что еще в 60-е был аналог задачного подхода, в 50-е. Тем не менее, этого всего недостаточно. Логиковероятностный подход, он замечательный, пока задача маленькая, но тоже возникает проблема в том, что мы не можем задачу достаточно точно, достаточно хорошо описать логиковероятностным образом. И, соответственно, из-за этого мы все равно не можем решить задачу. То есть в данном случае мы не смогли описать компьютеру Как мы попытались компьютеру сказать. Компьютер, решай задачи с помощью задач. Задача вот в таком виде. Решение задавай в таком виде. Задача вот тебе в таком виде. И компьютер нам периодически с этим подходом не справляется. То есть, чтобы задачный подход работал, у нас исполнитель должен быть достаточно умный. достаточно умный исполнитель, и нам его еще предстоит получить. То есть, когда у нас будет достаточно умный заменитель человека, задачный подход заработает, как и в общем-то и все остальные подходы, основанные на эротическом планировании. Пока у нас вот этого умного исполнителя нету, у нас моделирование реальности получается плохо. 

S04 [00:32:18]  : Я понял, что докладчик не понял моего вопроса. Он работает в Новосибирском университете. Вообще-то в Новосибирском университете задачный подход в Институте математики Сибирского отделения развивается с конца 70-х годов. И его вероятность подхода и семантическое моделирование показали свое. В общем, из ответа видно, что чего-то незнакомо о том, о чем я спрашиваю. Потому что в задачном подходе основная идея это все так называемая оракулярная вычисленность. Именно она позволяет, скажем, различные технологии соединять в единое целое, то есть говорить о гибридном искусственном интеллекте. Когда у вас в качестве одного оракула выступает не консимвульная программа, скажем так, а в качестве другого оракула выступает, скажем так, искусственная нейронная сеть. 

S01 [00:33:17]  : Скажите, работает ли подход на практике, на больших задачах? Более чем. Например, приведите пример большой задачи. Программу напишут на подобии этой? 

S04 [00:33:33]  : Смотрите, я бы не хотел сядь на этой площадке и спорить. Вы же в университете работаете, я так понял, да? Мы доступны Середенко, Витяев, Гончаров, Нечесов. Я в курсе ваших работ. Да, я семинар. Подходите, мы поговорим. 

S01 [00:33:52]  : Да, я даже в группе есть. Пока что я не вижу, чтобы это все работало. То есть, в теории оно замечательно. На практике я не вижу, чтобы достаточно большую задачу можно было решить подобным подходом. На практике. Используя только компьютер, не используя человека в качестве эксперта. 

S04 [00:34:12]  : Послушайте до конца, не спорьте. Значит, есть три больших платформы – Reveno, Resel. который сделал Гумиров. Есть бета-систем, который сделал Мансавада Гарпуцкий. Есть Discovery, который сделал Витя. Есть их комбинации, на которых решено огромное количество задач. Мне жалко, что вы не в курсе дела. Спасибо большое. 

S01 [00:34:32]  : Смотрите еще раз. Подождите, вы, наверное, путаете. Приходится ли вам самим описывать задачи в качестве спецификации на каком-то формальном языке? Или вы задаете задачу на естественном языке, и ее компьютер вам решает? 

S04 [00:34:54]  : В этом смысле вы правы. Да, мы фактически остаемся на уровне полуформального описания спецификации задачи. Но, скажем, та же PetaSystem позволяет работать уже на почти естественном языке. То есть на самом деле, когда вы имеете дело с некой проблемной областью, то речь не важна, так сказать, что только естественный язык. На этом формальном, на этом уровне, когда вы говорите об отраслевых задачах, там достаточно полуформального языка, который достаточно просто переводится в ту же предикатную форму. 

S01 [00:35:29]  : Ну, извините, предикатный подход в пролог решал еще давным-давно. 

S04 [00:35:34]  : Послушайте, я говорю не о прологе, а о так называемой дельта-ноль в языке. 

S01 [00:35:41]  : Это более... Ну, хорошо, немножко более сложная логика, хорошо. Но еще раз, ограничения формальных... Подход в основных на формальных методах заключается не в том, что они не работают, они работают, но в теории. Они работают на маленьких задачах, они не работают на больших задачах, потому что у вас компьютерные графы становятся огромными, у вас пространство решений становится огромными, восточных оракулов невозможно построить. 

S04 [00:36:08]  : Почему вы берете на смелость на тебя утверждать это? 

S03 [00:36:10]  : Вы не знакомы с этим подходом, а утверждаете... Дмитрий Иванович, можно я встряну, поскольку я хорошо понимаю ситуацию, мне кажется. И мне кажется, проблема заключается в следующем. Во-первых, естественно, речь идет не о прологе, потому что пролог – это четкая логика. То, чем занимается Евгений Евгеньевич, с которым мы вместе работали, и доклады были у нас совместные с Евгением Евгеньевичем, и на этой площадке Евгений Евгеньевич рассказывал. Речь идет о вероятности логики, или о нечеткой логике, или о том, что Пиванг называет неаксиматическая логика. И, конечно, это никакого отношения к прологу не имеет. вот но единственное что эти там и там есть некоторая логика вот но только в тех системах про которые мы говорим дисковые нарц значит это логика вероятность вот проблем не видится в другом да и речь не в размерах графов да то есть на самом деле и глубокая что нейросеть это очень большой граф и вероятность на логике тоже можно построить достаточно большие графы. мне кажется проблема заключается в следующем, что если взять пресловутые черноящичные глубокие нейросетевые модели, то можно найти сотни тысяч статей, публикации с открытым кодом, скачать и натренировать скачанный код на решение любых задач. скачать уже построенные модели и получить результаты на построенных моделях. А ни с одной из перечисленных систем, за исключением в какой-то степени NARSA, Это сделать нельзя. Во-первых, вы не можете скачать Discovery или скачать систему манцеводы и натренировать ее, допустим, на корпусе естественного языка и делать предсказания или решать какие-то прикладные задачи. Более того, даже в работах, которые, скажем так, доступны, нет пока, к сожалению, чего-то убедительного масштаба того, что нам предъявляют глубокие нейросетевые модели. Я сразу могу сказать некоторое оправдание. Если бы у Евгения Евгеньевича или с Discovery или у Пи Вонга с Нарсом, точнее у Патрика Хаммера, он сейчас Нарсом занимается, были бы такие вычислительные мощности, то, может быть, что-то бы и получилось. Но ни у нас, ни у вас, ни у кого этого нет. Но проблема заключается в том, что именно продемонстрировать в реальной жизни, что мы можем делать что-то более сложное, чем вот то, что обычно демонстрируется этими системами. Вот именно вот эта невозможность показать эффективность вот этих вот систем. И главная проблема, значит, показать не просто с точки зрения, значит, вот масштабности результатов типа того что нам всякие чат жпты показывают но вот именно решение проблемы обучения да то есть inference мы еще можем делать вот а как построить самообучающийся модель которая бы училась на неразмеченных корпусах и опять-таки продемонстрировать То есть да, там есть пример с нематодой, есть пример с мышами, есть пример, который опять-таки мы с Евгением Евгеньевичем делали доклад тоже с классификацией объектов, лишних субъектов. в данных социальных сетях или решение каких-то классификаций медицинских задач, но с точки зрения масштабности и разносторонности, к сожалению, в публичном пространстве мы ничего предъявить не можем сопоставимого с тем, что демонстрируется бесчисленными американскими стартапами и их российскими последователями от Яндекса и Избири. 

S04 [00:40:46]  : Спасибо за комментарий. Единственное, я хочу заметить следующее. Классы задач, решаемых человеком и которые мы пытаемся промоделировать их решение с помощью компьютера, они естественно распадаются на два больших класса. Классы задач обучения, здесь я не возражаю. Методы машинного обучения, тем более больших языковых моделей, блестящей технологии, никто этого не использует. Но есть еще задачи рассудительные, рассуждения. логические задачи. И то, что, так сказать, их надо сочетать в виде гибридных моделей, конечно же, именно об этом я и говорю. Именно об этом. Ну, та же самая система Вольфа, да, так сказать. Ведь хороший результат получен, прекрасный результат. Но он опять в своем, так сказать, итоговом заключении сказал именно то, о чем мы уже еще в 70-х годах говорили. Что надо сочетать Различные системы предусмотрены для разных классов задач. Кто-то решает математические задачи, кто-то решает перевод естественного языка. И надо научиться, так сказать, соединять. И здесь возникает проблема. Какая должна в основе лежать модель по численности? Вот о чем я говорю. И второй вопрос по отношению к докладчику. Что такое задача с его точки зрения? 

S01 [00:42:07]  : Смотрите, проблема объединения безусловно важна, но без того, чтобы... То есть в данном подходе, типа моего, всё выворачивается наизнанку. То есть мы можем, так же как мы задаем environment в данной среде, так же мы можем задавать внутренние дополнительные решатели задач. То есть мы в environment или куда-то еще можем говорить, вот у тебя есть способ для модели логики описать задачу. То есть, ты можешь вместо того, чтобы выполнять действие, сделать вот здесь, написать, там, пятое, написать solve, значит, и здесь description, или там какая у вас там логика, какая-то там d, d или s0, не помню, как называется. Вот. Написать здесь комментарий о том, как это все устроено, эта логика, он сгенерирует вам метод для решения задач на этой логике и попробует решить ее этим способом. То есть это альтернативный метод. В большинстве случаев формально никакой точности Это было убедительно. Ленардо показан для ЦИКа 30 или 40 лет назад еще. Вы не сможете просто точно специфицировать задачу, даже вероятностно. Дождь идёт через день, это означает, что он действительно идёт каждый чётный день. Или дождь идёт через день, означает, что дождь идёт в среднем 50% времени. Или же комбинации того и другого какая-то. То есть 50% суток он идёт, или часов 50% он идёт. Как это всё устроено? А тем не менее люди при этом описывают задачи именно в таком недоспецифицированном виде. И важно решать задачи именно в таком недоспецифицированном виде. То, что её можно переделать на формальный язык, оклоформальный на нём решить, это замечательно. Но вот большинство задач нельзя просто переделать на формальный язык. Или же получается что-то прямо невообразимо огромное, в котором решатели потом вырваются и не справляются. 

S04 [00:44:49]  : — Это весьма голословное утверждение, на самом деле. Я еще раз сказал, что каждый раздел вашего солдата должен решать свои задачи, понимаете? А мой вопрос был такой, что вы понимаете по задаче? Что вы понимаете по задаче как некой сущности? 

S01 [00:45:04]  : — Нет, это был комментарий еще на прошлый вопрос. Значит, комментарий на этот вопрос, что я понимаю под задачей как сущностью. Задача – это нечто, которое вот в данной формулировке, это значит… какое-то название и какое-то описание. И компьютер сам должен из этого описания себе сформулировать критерии решения, если он хочет ее решать методом типа «а звездочка», чтобы оценивал приближение по этим критериям потом к цели. Также он должен себе какую-то подробную формальную или какую-то спецификацию на своем псевдоязыке сделать. Но задача должна быть явно представлена на естественном языке. Это ключевое отличие моих задач от многих теоретиков. 

S04 [00:45:55]  : Я бы вам посоветовал аккуратнее делать такого сорта утверждения. И самое важное, вы же хотите, так сказать, научно заниматься деятельностью. Все-таки сравнительный анализ очень важен. 

S01 [00:46:05]  : Нет, я не хотел бы заниматься сейчас научной деятельностью. Я хотел бы решать практические задачи. Это важнее в данном случае. 

S04 [00:46:14]  : Тогда ещё раз повторяю, нельзя каждую задачу свести к задаче обучения, чем выполнять. Это неверно. Просто принцип. 

S01 [00:46:21]  : Задача какой обучения? Расскажите подробнее, пожалуйста, раз у нас время есть. 

S02 [00:46:27]  : Что за задача обучения? 

S03 [00:46:38]  : Раз, раз, раз. Дмитрий Иванович, не слышно вас. Дмитрий Иванович, у вас микрофон отключен. Дмитрий Иванович, вас не слышно. 

S04 [00:46:59]  : Алло, алло, алло. 

S03 [00:47:00]  : Да, да, теперь слышно. 

S04 [00:47:04]  : Еще раз повторяю. Если серьезно заниматься классификацией задач, то их, естественно, на самом деле это более сложная классификация. И понятие, формализованное понятие задач, оно требует для того, чтобы провести правильную классификацию. Поэтому ваш ответ на то, что такое задача, мне не устраивает, потому что это не ответ. Так вот задачи делятся на самом деле на задачи рассуждений. и задачи обучения. У каждого класса задач есть, так сказать, своя та математическая основа, которая лежит в основе. Скажем, в основе задач обучения в основном лежат, значит, это математическая статистика, в которой задача решается на том, что обрабатывается большое число данных, ищется закономерности какие-то, хотя ищется на данных корреляции, но объявляется закономерности, вы используете закономерности, задача решается. Задача рассуждения – это прямые задачи, когда у вас есть некоторое представление знаний, есть некоторое представление этих правил работы с этим знанием, и вы напрямую делаете решение. При этом понятие задачи обязательно требует наличия критерий ее решенности. Нет критерий – это хотелка. Просто хотелка. Потому что все, что вы мне предложите в качестве решения на такой хотелке, можно объявить решением. 

S01 [00:48:23]  : Хорошо. То есть я не вижу, почему задача рассуждения не является подзадачей для задачи обучения? под видом задачи учения, во-первых. Поэтому я не вижу, зачем ее выделять отдельно. А во-вторых, к какому виду тогда относятся задачи, которые требуют решения, которые задаются не в виде точной спецификации, а задаются на естественном языке. На самом деле, мы умеем с помощью программистов решать задачи, которые задаются с помощью спецификаций. Нам хотелось бы с помощью компьютера научиться решать задачи, которые задаются на естественном языке. 

S03 [00:49:08]  : Опять микрофон, похоже, отвалился. Так, сейчас смотрим. Дмитрий Иванович, снова звук пропал. Да. Дмитрий Иванович, вас не слышно. Дмитрий Иванович. Да, вот сейчас пропадает что-то, вот сейчас что-то прорывается. 

S04 [00:49:52]  : Я бы пригласил молодого человека прийти на семинары, мы бы там поспорили. 

S01 [00:49:58]  : Как раз понимаете, хотелось бы публично это все больше обсуждать, потому что вот когда звучит вопрос в виде, знают ли доктор что-либо о задачном подходе, то как раз очень хочется поговорить публично о том, какие задачи на естественном языке решает задачный подход. А не о том, какой подкласс задач можно придумать, который бы решать логически вероятностными методами. 

S02 [00:50:35]  : Спасибо. 

S03 [00:50:38]  : Хорошо, коллеги, еще есть вопросы докладчику у нас сегодня? Коллеги? 

S00 [00:50:54]  : Если меня слышно. 

S02 [00:50:58]  : Да. 

S00 [00:51:00]  : Я бы еще с более, как тут принято говорить, голословными вопросами обратился и докладчиком, причем к обоим дискуссантам. Значит, я с высоким уважением отношусь к тому, что люди делают системы, которые работают, и это прекрасно. Но, значит, когда они называют общими решателями задачи, Надо добавлять, как правильно спрашивали докладчик, каких задач? Задач, поставленных человеком, с параметрами, которые выделил человек, с предметами, с объектами, которые выделил человек. Это немножко сужает круг задач. Или вы считаете, что ничего не надо человеку делать? 

S01 [00:51:42]  : И да, и нет. То есть, здесь результаты современные есть, и результаты современные неплохие, они в целом говорят о том, что компьютер может... Нет, нейронические, конечно, дают какие-то эффекты в этом направлении, я с этим не спорю. Да, то, что компьютер может выделять те же самые объекты самостоятельно, Но, опять же, ценностный тот вопрос. Нас вполне устроит, если мы будем решать задачи про объекты, которые там создал человек, и словами, которые на человеческом языке. 

S00 [00:52:17]  : А не те задачи, которые мог бы компьютер… Нет, общий решатель задач – это исключительно ссылка на General Problem Solver. Вообще наивные ребята, 70-е годы. На них можно сослаться, можно и на Зинона сослаться. 

S01 [00:52:40]  : Я в этом плане этой наивностью как раз немножко и делюсь. Наивный подход почему-то до сих пор не работает. На новый лад. Но есть мысль все-таки. Есть попытки его все-таки доделать, и он вполне может заработать в наше время. 

S00 [00:53:01]  : То есть, что вы предлагаете доделать? Чего не хватает? Наконец-то он заработал. 

S01 [00:53:09]  : Может, я невнятно проговорил. Давайте проговорю еще раз. Чего, на мой взгляд, не хватает? Не хватает здесь... Не хватает здесь reinforcement learning. То есть мы берем, у нас куча разных окружений, у нас куча разных задач, причем и задачи окружения, в общем-то, может генерировать компьютер на основе того, что он узнал о человеческом мире. И он может эти задачи учиться решать по шагам, также иерархически планируя эти задачи и используя, то есть, временами, посматривая, что происходит, собственно, в этом окружающем мире. И, соответственно, что этому методу требуется? Этому методу требуется, во-первых, Доделать текущую реализацию и расширительство планирования, добавить сюда историю задач, добавить сюда описание, там родители, там и другие задачи. Во-первых, немножко увеличивает качество. Но, во-вторых, этого всего всё равно будет недостаточно. Добавить до обучения. Это уже не такая простая задача. И дообучать компьютер в разных мирах, решать разные задачи методом reinforcement learning. Поэтапно так же, примерно так же, как это делает OpenAI Stronger и много других похожих подходов, то есть Chain of Thoughts применяется многими компаниями и во многих ситуациях просто может быть так масштабно только OpenAI пока что. Но, тем не менее, есть такой способ решения задачи и хотелось бы его развить. и хотя бы, как минимум, научиться его применять для решения задач типа производства кода, но производство кода уже не в масштабах одной-двух страниц кода, а в масштабах уже производства программ до миллиона строк, скажем так, чтобы подход устойчиво работал. На мой взгляд, этого будет достаточно для того, чтобы мы могли генерировать достаточно сложные программы и алгоритмы и отправлять их уже, ну, заменить ими современные многие задачи. Ну, как-то их разбив на части, на куски, на подзадачи. Сделать более совершенные пользовательские интерфейсы, ну и потом частично заместить тоже логику всех алгоритмов машинного обучения на такие, возможно, такие куски задач. 

S00 [00:56:08]  : Я, как вы понимаете, не против Рейнспорта Маслененко, всячески его поддерживаю. Но в конце вы сказали такие, на мой взгляд, правильные слова, что надо разбивать сложные задачи на пользу задачи, поскольку мир наш сложный, и каждый день мы проживаем по-разному. И все задачи сложные, они тоже накосторяются. Поэтому мы их все, скажем так, заранее промоделировать не можем. А подзадачи более или менее простые мы можем разносторонне промоделировать. Вот как-нибудь считаете ли вы важным обращать внимание на структурирование знаний про простые задачи и явления, и, соответственно, как это входит в вашу модель? 

S01 [00:56:52]  : Вот здесь большой вопрос, но вопрос эффективности. То есть оба эти подхода, и разбиение на простые задачи, и на обучение одного универсального решателя, они имеют смысл? Но в машинном обучении есть одна традиционная проблема. Когда мы разбиваем задачи на подзадачи с одной стороны, подзадачи у нас становятся проще, их проще обучить. Требуется маленькая нейросеть или там вообще алгоритм, соединяется алгоритм. Но, тем не менее, многие задачи недостаточно хорошо специфицированы, и вот в детали в точки недоспецифицирования попадает часть кейсов реальных, и в итоге вот эта вот программа, собранная из кусочков, работает не так хорошо, как работала бы единая система, которая, конечно же, желала бы намного больше ресурсов, но была бы единой. Сейчас это так, потому что эти системы неадаптивны, то есть вот эти кусочки друг другу неадаптивны, Но, во-вторых, это и сложно, потому что мы работаем с человеком или с естественным языком, или с естественной классификацией предметов, который тоже не является зачастую логичным и простым. И чего только стоят интернет-печеньки, которые не являются печеньками, как мы знаем. Системы цельные традиционно показывают более хорошие результаты, чем разбиение на простые задачи. Но, тем не менее, для многих случаев достаточное разбиение на подзадачи достаточно хорошее. И есть некоторые наметки о том, как мы могли бы еще более хорошо делить на подзадачи с помощью машинного обучения уже. Но тем не менее, опять же, для того, чтобы эти подзадачи хорошо решать, требуются большие датасеты. Больших датасетов напрямую открытых нету, их не существует в природе. Их надо как-то размечать. Размечать может сейчас только человек. Мы снова упираемся в то, что до любого машинного обучения у нас есть слабое звено человека. Опять же, если компьютер более умный может как-то эту разметку делать, то есть опять же надежда, что мы сможем делать более простые модели и развивать как-то на подзадачи за счет того, что компьютер, который большой, но умеет решать задачу общую, будет нам делать, будет нам создавать решение более простых подзадач, и это все будет достаточно хорошо. И, соответственно, мы сможем… ну, будет это оптимизированная версия модели, по сути, как будто бы, которая будет уже задачу неплохо решать на практике. 

S00 [01:00:08]  : Но при этом будет очень… Тоже на это надеемся. Вопрос в том, какой путь вы видите конкретное решение, задачу восприятия реального мира и разведения его на простые объекты и явления, и, соответственно, представление знаний об этих простых объектах и явлениях. Насколько, какими путями вы сейчас представляете себе путь по оптимизации, в смысле по автоматизации этого процесса, исключения человека из этого процесса? 

S01 [01:00:38]  : В каком виде? Ну, смотрите, современная гипотеза такая, что при росте вычислительной мощности происходит Скачок. Происходят скачки уровня интеллекта. Просто рост уровня интеллекта некий. При наличии, конечно, или обучающих данных, или искусственных миров с данными. Причем даже искусственных миров зачастую в какой-то степени хватает. Моделирование, по сути. За счет этого мы можем делать какую-то уже или разметку, или какие-то уже можем делать искусственные схемы, семантические какие-то модели, какие-то антологические модели общего вида. Делать с помощью компьютера какие-то уже задачи, которые похожи на программистские. Опять же, ну и также там разметку или тесты делать. Да, это требует много ресурсов. И поэтому на практике пока что почему-то получается так, что вот эти маленькие модели, они хоть и более экономны, но пока мы их сделаем, нам придется затратить намного больше ресурсов. чем если бы работала просто большая модель в каждом конкретном случае. Из-за этого барьер потенциальный создается. Ну, а второе – это качество. Мало решать задачи быстро и хорошо. Вот у нас был в школе один ученик, он каждую задачу мог решить за минуту. Только где-то две трети задач решал неправильно с первой попытки. Но ему давалась вторая и третья попытки. Вторая попытка у него была через несколько минут. Со второй попытки решение зачастую было уже более правильным. А с третьей попытки так вообще было замечательно. И вот современные большие языковые модели сейчас выйдут по этому пути. Пока мы максимизируем точность у стандартных моделей, они склонны как раз преувеличивать и давать нам неправильное решение. который в каких-то случаях работает, но в общем случае не работает. А нам бы хотелось вместо этого, чтобы компьютер давал нам более точные решения. И вот это нам не позволяет сейчас создавать легко датасеты. Потому что у нас процент ошибок достаточно большой. 

S00 [01:03:13]  : Через две недели, надеюсь, мне удастся выставить здесь со своим докладом. Я не поддерживаю идею, что простым увеличением мощности мы достигнем повышения разумности хотя бы до уровня человека. Поскольку Скажем так, сложность задач растет экспоненциально, а экспоненциально у нас, конечно, есть закон МУРа. Но даже чтобы решать задачу ГО силовым путем, то есть полным перебором, значит по закону МУРа потребуется 750 лет, когда мы достигнем таких мощностей. А поскольку окружающий нас мир немножко сложнее, чем ситуация на доске гор, то там потребуется миллионы и миллиарды лет, чтобы достигнуть вот такой вычислительной мощности. Конечно, никто не будет достигать решения никаких задач полным перебором, но смысл такой, что чтобы уйти в большей степени от полного перебора, надо не ждать, что это там эмержентно возникнет за счет увеличения мощности, а строить структуры, которые будут организовывать выделение знаний про простые объекты явления и, собственно, использовать их в построении планов действий. Ну, собственно, эти действия могут заключаться в решении задач, а могут, значит, в выполнении каких-то заданий. Что, в принципе, как вы понимаете, одно в другое переводится. Вот. Ну, в целом, было интересно вас послушать. Спасибо. 

S03 [01:04:39]  : Владимир, не могу удержаться от вопроса. Вы же говорили, что AGI то ли через год, то ли через три построят китайцы, а сейчас говорите, что простым увеличением ничего не получится. Можете расшифровать противоречие? 

S00 [01:04:54]  : Могу расшифровать противоречие. Помните, в 2012 году обещали конец света? Так. Очередной раз. Кто-то говорит, что он не состоялся, а кто-то говорит, что нет, он просто начался и сейчас идет. То же самое, в принципе, уже... Кто-то говорит, что уже построили сильный искусственный интеллект. Я не буду совсем с этим согласен, поскольку сам процесс этот займет еще некоторое время, чтобы как бы... Серьезным критерием этот сильный искусственный интеллект удовлетворял. Но для неспециалистов вполне себе, о чем сегодня рассказывали два человека, которые обсуждали, что есть уже система, которая решает много задач, и они вполне себе в какой-то степени могут быть сравнены с человеком. И вот уже за последние 

S03 [01:05:58]  : Так, что-то у нас сегодня морно оппонентов вырубает. Коллеги, к сожалению, Владимир Смолин от нас отвалился. Ещё у кого-нибудь есть вопросы или комментарии по сегодняшнему докладу? Владимир, вас не слышно. Мы рады вас снова видеть, но вас не слышно. Не слышно по-прежнему. 

S00 [01:06:25]  : Сейчас включилось? 

S03 [01:06:26]  : Да, сейчас включилось. 

S00 [01:06:28]  : То есть, в следующем году будет еще больше рывок в эту сторону. Повторюсь, что абсолютной истины никто никогда не достигнет. Насколько эти системы будут действительно сильным искусственным метеоритом, это также будет дискуссионный вопрос. Но, надеюсь, вы не будете спорить с тем, что за последние два года в этом направлении уже сделаны большие достижения, и в следующем году они будут еще больше. С этим особо никто не спорит. Ставить гидроцерту, она, конечно, очень ориентировочна. Я ее ставлю в 1925 году. у нас прогресс будет еще сильнее, чем за последние два года. Вот, собственно, о чем я. Давно уже говорю, что примерно тогда это произойдет. 

S01 [01:07:17]  : Начало конца света. 

S00 [01:07:19]  : Постоящее. Ну, начало конца света в 2012 году произошло, когда началась нарастевая революция машинного обучения. Как предсказывают? Ну, я, конечно, не номеролог, я к этому достаточно иронично отношусь, но в целом тенденция такая. 

S03 [01:07:39]  : Владимир, а все-таки уточните, то есть я понял, что он будет, по вашей точке зрения, создан на год раньше, чем предрек Леопольд Эшенбренер, вот, или даже на два года раньше, чем он предрек. Он обещал через три, а вы говорите через год. Но уточните, он будет создан в результате увеличения мощностей или не в результате увеличения мощности, а в результате каких-то других прорывов? 

S00 [01:08:03]  : Ну, мощности, конечно, тоже важны. То есть, на калькуляторе, конечно, не будет сильного искусственного интеллекта. А, конечно, будут улучшаться алгоритмы. С этим, я не думаю, что кто-то будет спорить. То есть, прогресс, ну и, в принципе, все вот эти жпт, поколения жпт, они же не просто идут увеличением. мощности серверов, которые для этого используются. Каждый следующий жптл немножко там улучшается. Я считаю, что в ближайшие год-два будут более серьезные алгоритмические улучшения, которые дадут значительно более интересные результаты. Ну и сам факт, что в этой области много народу работает, много денег вкладывается, они как бы создают для этого условия. 

S03 [01:08:53]  : Спасибо. Коллеги, есть еще какие-то вопросы к докладчику, уважаемым оппонентам и к уважаемому докладчику? Нет? Тогда спасибо. Как раз через неделю Евгений Евгеньевич Витяев будет рассказывать о своей работе. Он будет рассказывать про информационные теории сознания. Поэтому будет возможность еще раз покритиковать символьный логико-вороятностный подход и все, что с этим связано. Юрий, большое спасибо за доклад и за его прикладные аспекты. Спасибо всем за критику и всем спасибо за участие. До свидания и до новых встреч. 






https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
