## 11 апреля 2024 - Актуальные вопросы регулирования ИИ в России и за рубежом — Германович — Семинар AGI
[![Watch the video](https://img.youtube.com/vi/KibmmcF2RvQ/hqdefault.jpg)](https://youtu.be/KibmmcF2RvQ)




S02 [00:00:00]  : Коллеги, всем добрый вечер. Мы начинаем снова семинар русскоязычного сообщества AGI. Сегодня в несколько необычных условиях, соединяя Zoom с YouTube, точнее Zoom с YouTube и с Яндекс.Мостом. И сегодня у нас в гостях Олег Полстовалов и Гарин Евгений, и они будут вести диалог о вопросах регулирования искусственного интеллекта в России и за рубежом. Олег, Евгений, пожалуйста. 

S04 [00:00:35]  : Добрый день, коллеги. Я начну. Ну, за рубежом-то все тоже, так сказать, в формате пока декларации в намерении. То есть по большому счёту регуляторики такой дискреционной, то есть обязывающей чему-то нет. Нет, потому что есть определённые намерения с принятой, как вы, наверное, знаете сами из новостей, о компромиссах, достигнутых ещё в декабре прошлого года. Три дня обсуждали о европейской парламентарии, о том, как должен выглядеть закон ЕС об ограничении искусственного интеллекта. В итоге они пришли к общей позиции, которая была принята в марте текущего года. На уровне государств, национальном уровне рекомендации ЕС были направлены, 27 стран-участниц могут принимать их, не принимать, но установлены два режима. Запретительный, опять же, якобы, и второй режим условно-запретительный. По большому счету, вопросы возникли, конечно, к дипфейкам. Они в форме шутки и особых возражений не вызывали. Но решили парламентарий, что на этот случай необходима маркировка дипфейков. Что касается ограниченных приложений, включающих удаленную биометрическую идентификацию, В режиме реального времени, например, на развлечение настроений человека по внешнему выражению лица, здесь возникли самые острые дискуссии. Поэтому ЕС и Комитет Европейский Совет по защите данных призывал к общему запрету любого использования искусственного интеллекта для автоматического распознавания черта лица человека в общедоступных пространствах. На мой взгляд, дискуссия была действительно очень жесткая, Согласованный документ выглядит с такими вот ограничениями. Другое дело, распознавание лица других систем удаленной биометрической идентификации, распознавание эмоций, использование в полиции предиктивной аналитики для профилактики правонарушений, все это, на мой взгляд, все-таки выглядит как белый шум, поскольку имеют определенные исключения. Например, если речь идет об угрозе теракта, для поиска жертв в рамках расследования тяжкого преступления. Поэтому, насколько это будет принято конкретными законодателями, насколько это будет общей позицией всех 27 стран Европейского Союза, здесь сказать сложно, надо понаблюдать за ситуацией. Что касается Соединенных Штатов Америки, то искусственный интеллект, стратегия обороны, тут два документа у них очень интересных, Это стратегия национальной безопасности США и стратегия национальной обороны. Например, стратегия национальной обороны, норма, точнее, требования об использовании, возможность использования искусственных интеллектов появляется в 2018 году, годом ранее, стратегия национальной безопасности США. И США достаточно прагматично смотрят на перспективы использования, например, искусственного интеллекта в военных конфликтах. В частности, называется в качестве одной из технологий искусственный интеллект, который изменит характер войны. Вот дословно, что говорит конкретно стратегия обороны. Характер войны и даст более изощренные возможности противникам, они говорят, нашим противникам, включая негосударственные субъекты. То есть США конкретно намекают на то, что, в общем-то, они готовы к тому, что искусственный интеллект может быть использован в том числе террористическим организациям. У нас здесь не очень все хорошо, потому что наша стратегия национальной безопасности, я не говорю о стратегии искусственного интеллекта, об этом Евгений Викторович больше скажет. Так вот, наша стратегия национальной безопасности трижды упоминает искусственный интеллект, она относительно недавно принята, 2 июля 2021 года. И преследует, как минимум, в первых двух случаях две задачи — это обеспечение информационной безопасности, в втором случае — обеспечение экономической безопасности. Почему у нас нет обеспечения оборонной безопасности как средства достижения, для меня это загадка. А в третьем случае мы вообще говорим о том, что это одна из передовых технологий, которая используется для обеспечения развития научно-технического развития России. То есть, опять, развитие — это развитие. нет никаких целевых ориентиров. То есть мы не можем сказать, на каком уровне, скажем так, какие целевые ориентиры заложены перспективы использования искусственного интеллекта в плане НТР. То есть здесь вот немного документ такой, который, на мой взгляд, требует наработки. Тем не менее, в национальном законодательстве возможность использования искусственного интеллекта, особенно Машины человеческие, так сказать, коллективов. У нас, лично у меня, как юриста, очень большие вопросы, потому что, например, если мы возьмем уголовный суд производства, да, у нас много ведется разговоров о том, что должно быть у нас электронное уголовное дело, о том, что у нас многие процессы должны быть прозрачные, должна быть максимальная цифровизация. Все это создает некую иллюзию того, что может здесь поработать искусственный интеллект. Фактически, если мы говорим о тех направлениях поиска виновных и изобличения виновных, доказывания виновных, оценки судебной перспективы, все, конечно, под силу, поскольку система формализована, система доказательств формализована, но и качество правосудия у нас запредельное под 100%. Поэтому казалось бы, все замечательно. И поскольку качество правосудия под 100%, значит, все приговоры априори правосудные. Исходя из этой эмпирической базы, достоверность материала кажется, опять же, внешне весьма и весьма репрезентативной. Но у правосудия есть очень много таких сослагательных вещей, таких как, например, обстоятельства, смягчающие наказание. Конечно, искусственный человек может это все просчитывать. Но и были даже предложения о том, чтобы часть правосудия, такие как судебные приказы, простые, вот именно использовать здесь сервисы искусственного интеллекта. Вот Евгений Трофимович наставит о том, что сильный искусственный интеллект, он еще обладает эмпатией. Но вот у меня большие сомнения по поводу того, насколько правосудие цифровое, именно на основе искусственного интеллекта, может быть милосердным, например. И насколько оно должно быть, может быть, ну, вообще оно то, что оно будет объективным и непредвзятым, этого вопроса не возникает. Возникает несколько проблем, связанных с искусственными, вот именно, с базовыми, точнее, исходными данными. И ключевой момент – это все-таки субъектность. Если мы говорим о коллективном субъекте, то в уголовном производстве есть несколько коллективных субъектов. Я не говорю о коллегии суда присяжных, Вообще, насколько искусственный теоретик может изменить их, это вообще просто нонсенс юридический. Что касается замены части исследовательской, то есть исследователей и дознавателей, лица человеческой оперативно-розыскной деятельности, то коллективные формы это, естественно, оперативная группа, которая может носить две формы, доросли, до, значит, возбуждения головного мозга, после возбуждения и так далее. Много классификаций, сейчас называть их не буду. Так вот, если в этой следственной группе присутствует такой актер, как искусственный интеллект, то модели, которые я сегодня посмотрел буквально в Израиле, там машиноцентричность очевидная, то есть машины есть приоритетом, две категории решений. Решение первое – машинное, с которым человек должен согласиться. Второе – совместное, человекомашинное. И вот эта вторая категория, первая категория вообще с точки зрения правосудия вызывает большие споры, потому что не просто уголовно-процессуальный кодекс нужно полностью перекраивать, но возникает проблема в том, что у субъекта доказания тоже есть свои права. Как наделить искусственный интеллект ориентированными правами? Как можно обжаловать принятое им решение? Я с трудом себе представлю, искусственному интеллекту доверят вынесение поставления при лечении лица в качестве обвиняемого. То есть вот эти моменты ограничительного свойства тоже вызывают много вопросов. Равно как, например, есть формализованные вещи, такие, которые работают на профилактике. Вот здесь вопрос правоприменения, на мой взгляд, больших возражений не возникнет. По одной простой причине, опять же, не вступили в законную силу изменения законодательства о дорожной деятельности, в частности, о государственной компании российской автомобильной дороги, в части, требования к камерам наружного наблюдения по обеспечению безопасности дорожного движения и декомпозиции их обеспечения безопасности, она вполне уместна. Равно, как и уместно, поправки, связанные с сектором обзора. То есть сектор обзора теперь должен по требованиям новым включать весь периметр, весь спектр возможного дороготранспортного происшествия. Это тоже очень важная поправка. Но у меня тут много вопросов. Степень разрешения камеры, насколько технические характеристики заточены на то, чтобы распознавать признаки внешности водителей, пассажиров и так далее, и так далее, и так далее, все учитывая динамику движения. Вот эти моменты, заложенные в основе распознавания, они очень интересны, но сама логика размещения камер, она может быть продиктована искусственным интеллектом по одной простой причине. Как все специалисты-разработчики понимают, что дорожная отрасль, точнее дорожная сеть у нас, может быть выкрашена в три цвета как минимум. Это жёлтый, зелёный и красный. Зелёный цвет – это там, где более-менее безопасные участки дороги. Соответственно, жёлтый – это промежуточная, а красный – там, где повышенная степень опасности, риска для жизни и здоровья участников даже транспортного движения. И если искусственный интеллект нам позволит сделать эту декомпозицию камер народного наблюдения, то мы Я не скажу, что полностью решим вопрос с безопасностью дорог, но существенно попытаемся сократить аварийность на дорогах и опасность для жизни водителей и пассажиров. Поэтому, конечно, все эти вопросы могут применимо быть. Есть много таких направлений. Сейчас говорить не буду. Есть такое направление, как аэрокосмическая криминалистика, тоже право применения за наблюдением за лесополосой, но тут опять же используем лесной кодекс и порубки леса. Я не знаю, насколько для Новосибирска эта тема актуальна, но если мы возьмем судебную практику, то очень часто мы наблюдаем вопросы, точнее уголовные дела, связанные с незаконной порубкой леса. В США в 2010 году были исследования проведены, с помощью искусственного интеллекта была оценена рациональность приложение преступных усилий по порубке леса и браконьерству в так называемых национальных парках. И учитывая вот эту рациональность, ну так сказать, исполнители позволили правительству США сократить число и зоны полицейских надзорных мероприятий. То есть, ну, это тоже очень важно для экономии сил и средств, значит, полицейских ведомств. Опыт и практика. Дальше, что касается нашей сегодняшней картины, у нас аэрокосмическая фотосъемка присутствует в уголовных делах, приговорах, но только именно как фотография, но в динамике, что было то после определенного временного лага, когда речь идет об изобличении леса по версии следствия, совершавших преступление по порубке леса, ну, условно, с какого-нибудь там февраля 2024 года по началу марта того же года. И вот берется съемка во всей динамике по времени изобличения данного человека. Почему это берется за одним вопросом по запросу в Роскосмос? Это большой вопрос. Почему нет постоянного мониторингового наблюдения и обработки искусственным интеллектом всей этой информации в онлайн режиме, учитывая, что Зона порубки, разрешительная документация на порубку леса, она может быть определена географически. И постоянно мониторингом за процессом мы можем себе это позволить. Я уж не говорю о том, что у нас там было с Буком, значит, с Воингом и так далее. То есть вот эти вопросы, к этому мы должны готовы быть, потому что это все такое очень интересное, заманчивое, перспективное направление. В любой системе правоприменения ключевые моменты будут возникать относительно того, насколько права и свободы человека и гражданинца, в данном случае действующего лица, познавающего субъекта, в любой системе правоприменения будут следовать и дознаватель, сотрудник федеральной таможенной службы или федеральной антимопольной службы, Насколько его может заменить искусственный интеллект, так, чтобы потом вы могли обжаловать принятое решение. Потому что права и свободы человека, вроде бы, никто никогда не отменял, а здесь в системе правоприменения возникают такие достаточно непростые вопросы. Что касается технических вопросов, связанных с военной разведкой, насколько это все используется, вот тоже из открытых источников, я его читаю, по Израилю интересную информацию для себя почерпнул. Ну вот, вкратце, такое немножко сумбурное сообщение, но откровенно скажу, что пока это сумбур вызван тем, что мы в стадии формирования нормативного регулирования данного вопроса. Я думаю, что мы к какому-то результату придем, но мы даже сами не знаем пределы искусства тех, точнее, вроде как, заявилось в этой декларации, принятой недавно в нашей транссессии. Что у нас с искусственным интеллектом? Это прикладное направление практически неисчерпаемо. Так ли это или нет, мы покажем в ближайшее время. А формировать документы, готовить нормативные документы под непрозрачную перспективу, до конца непонятно чего, вот это самая большая сложность. Если нам разработчики дадут внятное объяснение, что такое искусственный интеллект, именно как стильный интеллект, в чем он отличается от прочих видов интеллекта, формально, которая ложится в нормативную документацию. Самая большая сложность – переложить это на русский язык, а еще сложнее – сделать это нормой права. Вот тогда у нас, наверное, сложность смерти почти сдвинется. Пока я говорю о том, где мы видим это как сервис и как возможности. Спасибо большое за внимание. Если вопросы есть, я постараюсь на них ответить. 

S02 [00:15:14]  : Да, спасибо. Спасибо большое. Я считаю, что очень информативно. Евгений, ну, видимо, вы сейчас... Просто дополнил. 

S03 [00:15:23]  : Ну, в общем, смысл такой. Что, во-первых, полного текста закона ЕС об ограничениях сущных телек у нас нет. У нас есть некоторые выписки оттуда. И они такие тревожные. Ну, во-первых, можно, что налагается определенное ограничение на использование искусственного интеллекта в прогнозировании преступления. Если мы посмотрим просто имеющиеся программное обеспечение, то есть уже те программы искусственного интеллекта, которые применяются в этой области, то заметим, что в тех же США очень распространены у нас, во-первых, генеративные программы, которые генерируют заявления судебные, это прям очень целый большой кластер, с прогнозированием вообще ничего нет. Максимум там есть программы специализированные не для общего доступа, а именно для доступа отдельных юридических компаний, которые прогнозируют исход судебного дела. То есть это вообще как бы получается, возникает вопрос, для каких рынков ограничение. Единственные успешные разработки, в которых уже сделаны доклады про апробацию, сделаны какие-то, во-первых, опубликованные статьи, это российские разработки. Именно российские разработки в области именно прогнозирования, совершение преступления. Такие разработки у нас в России. И лично я считаю, что вот эти вот законы ЕС об ограничении искусственного интеллекта в прогнозировании направлены не на разработчиков, которые находятся в ЕС или в США, а защищают европейский рынок от российских разработок. на самом деле, потому что отказываться от прогнозирования преступлений, это как бы странно, это себе на ногу наступать, поэтому логично, что я рассматриваю это как закрытие своего рынка для российских разработчиков. Да, в том числе, что касается нашего законодательного поля, есть у нас тенденция в России, нехорошая, с 90-х годов провелась, когда мы берем какой-то законодательный акт зарубежный, в том числе ЕС, да, и его повторяем у нас. Ну, хорошо, если мы под региональную какую-то специфику его, либо просто слово в слово. Поэтому я вот опасаюсь, как бы у нас не приняли таких же законов, которые бы подтворствовали ЕС. Это первое. Вообще у нас как бы из НПА у нас есть стратегия развития искусственного интеллекта, причем это уже второй у нас вариант, потому что первый у нас в девятнадцатом году, в феврале был, вернее в октябре девятнадцатого года. Вот у нас сейчас уже в марте, нет вернее 15 февраля 2024 года вышел указ президента 124 о внесении изменений в указ 4 стадии развития искусственного интеллекта Российской Федерации. Фактически это такой документ, стратегический, стратегия развития искусственного интеллекта, который как-то нормативно-правовое какое-то обеспечение дает развитию искусственного интеллекта в Российской Федерации. И есть нюансы, которых я хотел сообществу разработчиков посвятить. Первый нюанс какой? Вот самого текста «Новые стратегии искусственного интеллекта» 2024 года нет, его как бы не существует. Там существует в указе 124 перечень изменений, но он огромный. Он огромный, он таких размеров, что мне понадобилось несколько дней, чтобы собрать реальный текст, как он выглядит сейчас с изменениями. Это первое. Я уверен, что это сделано для того, чтобы затруднить чтение нового текста стратегии для самих разработчиков и для компаний, которые этим занимаются, в том числе юристов, корпоративов. Второе. Есть многие вопросы к правому обеспечению стратегии искусственного интеллекта. Потому что вот, например, опирается правовое постучение указа на указ 204 и тот же указ 242. Ну, предыдущие, так сказать, указы в области науки. О стратегии научно-технического развития 2016 года. Дело в том, что на момент утверждения стратегии вот этот указ 204 утратил силу уже. А вот 642-й указ утратил силу через 5 дней после принятия стратегии. То есть это как бы с юридической точки зрения просто обоснование новой стратегии уже как бы под вопросом. Потом, ну понятно, что стратегия опирается, стратегия искусственного интеллекта опирается на 172-й закон. При этом у нас существует там уже обновленная версия. В ноябре 2021 года это указ Президента 633 в утверждении основы государственной политики в сфере стратегического планирования. И на 633 указ стратегии искусственного текста вообще никак не опирается, никак не ссылается. Это парадоксально, потому что если бы мы опирались на 633 указ, первое, что нужно было бы сделать в стратегии искусственного интеллекта, это провести прогноз. То есть мы должны спрогнозировать, как у нас системы искусственного интеллекта развиваются, и только после этого приходит приводить к стратегии. И там есть многостраничный документ, очень большой, всего несколько дней нужно считать хорошего. Вот там есть 18 пункт, Согласно прогнозам долгосрочного социально-экономического развития Российской Федерации, в случае недостаточного развития использования конкурентоспособных технологий искусственного интеллекта, реализация приоритетных направлений научно-технического развития страны замедлится, что впоследствии повлечет за собой ее экономическое и технологическое отставание. стратегии искусственного интеллекта ссылаются на какие-то прогнозы, которые сделаны в долгосрочном прогнозе социально-экономического развития РФ. Я специально взял тексты долгосрочных прогнозов и не обнаружил в них разделов, касающихся искусственного интеллекта. У нас Минэкономоразвитие 1-13-го года, один вот проект 19-го года, но он не принят, но как бы он на сайте там есть. Ну то есть в них просто отсутствует какой-либо прогноз по искусству интеллекта. Непонятно, откуда просто вообще стратегии ИИ берется вот эта фраза, которая ссылается. То есть как бы тут очень много вопросов, но самое там серьезное и, на мой взгляд, печальное, вот в чем заключается. В глоссарии подается определение искусственного интеллекта, и в том числе сильного искусственного интеллекта. При этом не говорится, что сильный искусственный интеллект — это система умей человека. Там просто такое абстрактное понятие вводится, что это адаптивная система, которая принимает решения без участия человека. Так можно и к слабому искусственному интеллекту определение. Но самое что удивительное, Стратегия искусственного интеллекта вводит два новых понятия, ранее неизвестные информатике и разработчикам искусственного интеллекта. Первое – это большие генеративные модели. Мы знаем генеративные модели просто. Вот стратегии вводят большие генеративные модели. И второе понятие – большие фундаментальные модели. Вот изучая в глоссарии определения больших фундаментальных моделей, я понял, что речь идет о больших языковых моделях. То есть удивительный парадокс. что стратегия искусственного интеллекта, развитие искусственного интеллекта у нас 24 года, вводит два новых понятия, которые раньше нам были неизвестны. Большие фундаментальные модели и большие генеративные модели. То есть непонятно, зачем старые, хорошо известные нам большие языковые модели, генеративные модели переименовываются в стратегии. Далее удивительно, там идут пассажи, пункт В — устранение необоснованных нормативно-правых ограничений для разработки и внедрения использования отечественных больших генеративных моделей. То есть как бы стратегия предлагает убрать необоснованные нормативно-правые ограничения. Мне просто интересно, как можно убрать необоснованные нормативно-правые ограничения к разработке отечественных больших когда эти большие генитивные модели впервые описываются в самой стратегии. Вот у нас своеобразный очень документ, но надо учесть, что раньше в старой стратегии у нас результативность считалась по количеству статей об искусственном интеллекте, по количеству программного обеспечения, запатентованного в Роспатенте. Теперь у нас эффективность развития искусственного интеллекта не считается в зарегистрированных программах, только в статьях, что уже наводит на определенные мысли. Может, количество статей как информативный показатель. Далее, интересная-интересная вещь очень, на чем нужно оценить внимание. В старом тексте стратегии достаточно серьезное было внимание к аппаратной части искусственного интеллекта. Рост предложений, продуктов, услуг, создания искусственного интеллекта, аппаратной части. Сейчас же у нас основные показатели достижения целей настоящей стратегии. Это у нас совокупная максимальная мощность всех суперкомпьютеров, которые освещены на территории российской федерации, в которых используются технологии искусственного интеллекта и которые оснащены графическими процессорами. Вот это прям серьезно, там именно акцентирую внимание на графические процессоры. Необходимы для обучения модели искусственного интеллекта расширительные по методике, аналогичные рейтингу суперкомпьютера, И в 2030 году должна вырасти производительность не менее чем до одного экзофлопса по сравнению с 0,0073 экзофлопсом в 2002 году. То есть получается, что у нас производительность суперкомпьютеров общая в России должна вырасти за 6 лет в 14 раз. за счет графических процессов, ну то, что видеокарты, это вот, на мой взгляд, как раз то, что мы называем информационной диверсией, чат GPT, где для нас, в принципе, как работает чат GPT это черный ящик, мы можем о нем судить по реакциям на на скорость ответа на запросы, и какие-то в СМИ комментарии самих разработчиков, которые удивляли, что якобы 20 тысяч видеокарт использовалось для работы ч.а. GPT. И вот это вот, на мой взгляд, брос разработчиков, которые уводят на сложном направлении развития, то есть уводят от разработки собственных процессоров с уникальной архитектурой к использованию видеороликов. Он уже нашел отражение у нас в стратегии искусства. Вообще там огромный документ, весь красный можно помечать. например, вот последнее, наверное, о чем акцентирую внимание, это дата-сеты, которыми мы обучаем искусственное телевидение. В стратегии 2019 года был такой юридический нюанс, что требовалось создать экспериментальные правовые режимы использования датасетов, которые включали бы в себя персональные данные. Что это значит? Что существуют у нас датасеты, которые содержат персональные данные, и разрабатываются нормативы, которые бы ограничивали разработчиков в использовании персональных данных, при этом эти датасеты передавались бы разработчикам. Сейчас в новой стратегии создаются правовые режимы, но они должны работать для передачи разработчикам диперсенализированных датасетов. При этом сама стратегия у нас вообще никак не указывает, как будут диперсенализироваться датасеты. какой ресурс мы должны затратить на деперсонализацию, и из каких источников мы должны финансировать работы по деперсонализации датасетов. То есть я опять же скажу, что раз новое у нас поле в этой области, то передача датасетов для обучения наших нейронок, она затянется очень сильно. потому что, ну, сперва будут гиперстанализировать датасеты. Как они будут, что, где они возьмут средства, это непонятно из стратегии. Ну, то есть это все затянется опять на годы. И это очень сильно затормозит разработку сильного искусственного интеллекта в Российской Федерации. Я думаю, что это затормозит минимум на 5-6 лет, разработку сильного искусственного интеллекта, что дает преимущество нашим конкурентам. Вот ситуация, собственно говоря, такой краткий обзор нашей стратегии искусственного билета 24-го года. Если есть какие-то вопросы, я готов ответить. 

S02 [00:30:20]  : Евгений, спасибо. У нас есть Татьяна, у нас есть Владимир. С вашей стороны есть какие-то вопросы? 

S00 [00:30:34]  : Добрый вечер. Я, к сожалению, только присоединилась и ничего не слышала. Большому сожалению. Но вообще у меня был вопрос. Я прошу прощения, если совершенно не к месту. А вот такой ресурс, как глаз народа. В общем, платформа существовала, прикрылась, а теперь мы встречаемся с тем, что, то есть, глаз Бога, простите, пожалуйста, у нас уже позднее время, я неправильно назвала. И вот они продают как раз сейчас, ну, в том числе, мошенники пользуются этими данными. Я буквально на днях с этим столкнулась. что у меня эвакуировали машину, да, и мне предлагали услуги, продемонстрировал буквально, что вот с этой платформы были слиты все мои данные. Просто, ну, простите, это не вопрос даже, а, может быть, прокомментируете, каким образом, как это все происходит. А платформа «Глаз Бога», да, как раз вот она и специализировалась, насколько я знаю. 

S04 [00:31:40]  : Я вам скажу, как юрист, Глаз бога — это платформа, которая собирала личные персональные данные. У нас закон о защите личных персональных данных существует, но у нас есть еще такая штука, как, например, статья 137 Уголовного кодекса «Разглашение данных о личной семейной жизни по средствам массовой информации», часть первой статьи 137. Уголовного кодекса. Часть вторая. И там, как вы понимаете, интернета нет вообще. Хотя везде всё, что связано с разглашением этих данных, скажем, идёт. Значит, любых данных, которые запрещены к разглашению, например, госпайды, да, всё идёт в том числе с использованием интернета. Почему в 127-й статье, в части 1 нет интернета? Могу только догадываться, что это раритетная статья, Которая в последний раз менялась в 2003 году. Сейчас и второе, но мы уже встречаем интернет. Но только в том случае, когда идёт указание на число 16-летнего. Как коллекционный признак. Что касается Глаза Бога, то есть это поисковая система. Форусом она признана системой, которая нацелена именно на сборку. персональные данные, не столько на поиск интересующих пользователей информации, распространялась она, насколько я помню, в системе телеграмми. Много разных вариаций, много разных сервисов, но понятно, что дезертифицированная продукция, которая размещена, как, в общем-то, и сервисы, но это искусственно, здесь сервис подбора, Это все достаточно опасная вещь. Как вам здесь помочь? Кому обратиться в плане утечки информации личной и персональной? Ну, вот, 127-я статья-то, она не к тяжким не относится, в общем, проблема. Размер причиненного вам бреда мошенническими действиями. 159-ю попытаться доказать мошенничество. Ну или имущественную черту, чьё на мошенническом путём есть такой экзотический состав у нас. Знаете, надо смотреть фактическую картину. Я никогда в удалёнке как-то не оценивал ситуацию. Если материалы побыли, я сказал, наверное, более... Я оценил ситуацию более взвешенную. На сегодняшний день у нас, к сожалению, законодательство, которое включает в себя использование интернет-ресурсов в уголовном кодексе, это 27 составов. 27 составов. И один состав, 137, который требует изменений, но почему-то эти изменения почему-то не происходят. Вот такая история. Не знаю. Благодарю вас. Я просто не всего знаю из того, что вы мне сказали. Насколько это все. 

S00 [00:34:26]  : Хорошо, спасибо. Спасибо, я просто хотела вступить в беседу каким-то образом, простите. 

S02 [00:34:32]  : Спасибо. Евгений, у вас есть какие-то комментарии еще или вопросы коллегу или Владимир, может быть, хочет высказаться? Если нет, я могу продолжить со своей стороны вот информацию дать. Давайте, наверное, я кратце расскажу. 

S03 [00:34:50]  : Вам передаем слово и побежали на следующее заседание. 

S02 [00:34:55]  : Да, хорошо. Договорились тогда. Значит, коллеги, спасибо вам за информацию. Было познавательно, хотя местами грустно. 

S03 [00:35:07]  : Вообще очень печально. Надо что-то найти, я думаю, мы займемся. 

S02 [00:35:11]  : Да, давайте что-то с этим делать будем. Спасибо. Со своей стороны я хотел бы рассказать о том, что происходило пару месяцев назад в Панаме. Давайте мы выйдем сейчас из Яндекса и останемся в Зуме. Я отключаю шаринг экрана. Значит, что происходило на конференции по так называемому полезному beneficial general intelligence или полезный искусственный интеллект. где в основном участвовали представители западного сообщества, поэтому любопытно будет узнать очевидную перспективу с той стороны. Первое, что было зафиксировано, общий тезис, который там был озвучен, это то, что мы не можем остановить развитие искусственного интеллекта, мы не можем его ограничить, это просто невозможно. То есть, возникновение сильного искусственного интеллекта неизбежно. Неизбежное за ним возникновение сверхсильного и сверхчеловеческого искусственного интеллекта неизбежно. И что бы человечество ни делало, объективно оно не в состоянии с этим ничего поделать. То есть, он рано или поздно возникнет. Это первый тезис. Второй тезис, который был озвучен. Это то, что его нужно, тем не менее, попытаться остановить изо всех сил с тем, чтобы максимально его отсрочить. Но в тех выступлениях, которые я слышал, не было внятного разрешения этих двух противоречий. То есть, если возникновение его неизбежно, тогда какой смысл его отсрачивать, если он все равно рано или поздно к нам придет. Значит, с другой стороны, я могу проинтерпретировать это примерно следующим образом, по крайней мере, как я вижу эту ситуацию. Это то, что мы должны отсрочить его возникновение с тем, чтобы снизить вероятность, что он возникнет до того, как люди и для человечества станет настолько разумным, что оно не в состоянии будет им воспользоваться себе во вред. Вот, конечно, если исходить из того, что будет возникать с той скоростью, с которой предсказываются, и то, что за многоста тысячелетнюю историю человечества оно так и не стало существенно умнее и разумнее в отношении вреда самому себе, что показывают самые последние события, конечно, очень мало надежды в перспективность такого подхода и в то, что отсрачивание появление искусственного интеллекта, сильного искусственного интеллекта спасет человечество. Ну вот это то, что было зафиксировано на мероприятии. Третий тезис, который... Это, собственно, два основных тезиса, которые между собой отчасти противоречат, но, тем не менее, это было некоторым консенсусом, который звучал в той или иной степени во всех докладах. Вторая тема, которая была затронута, в частности, в кулуарах я разговаривал с человеком, который, как я понял, всего слов представляет Соединенные Штаты в Организации Объединенных Наций, была посвящена именно международному регулированию искусственного интеллекта, не национальному. регулированию не национальным законодательным актом, а законодательным актом, принимаемым в части развития искусственного интеллекта на уровне ООН. Им было озвучено несколько тезисов. Я не помню, какие из них были озвучены со сцены, какие в приватной беседе. Первый вопрос я, естественно, к нему задал – это апелляция рассказом Ольги Усковой, которую она делала на одном из своих недавних выступлений, по-моему, на «Эмпатии Мануча», она рассказывала о том, что вот какое-то время назад разработчики со всех стран мира написали петицию в ООН или, значит, куда-то там обратились в какие-то инстанции ООНовские с тем, чтобы остановить развитие так называемых летальных автономных систем убийства. И я задал ему вопрос, как с этим делом ООН обстоит. И он категорически сказал, что это уже поздно, это уже никак не остановить, не на уровне ООН. ни на каком другом уровне. Потому что все уже почувствовали вкус этого дела. Появились новые игроки. Если раньше можно было договариваться, как договаривались об ограничение ядерных вооружений между Россией и Советским Союзом и США. Сейчас появился Китай, сейчас появилась Турция, которая очень активно движется в этом направлении, конкретно именно автономных боевых систем. Товарищ или господин категорически высказался, что не видит никаких перспектив регулирования вот этих вот боевых роботов, что называется, с искусственным интеллектом. Следующая информация, которую он поделился, была по поводу государственного регулирования сильного искусственного интеллекта безотносительно боевых систем, а искусственного интеллекта в целом и общего искусственного интеллекта. И здесь было сказано следующее. Я как бы цитирую то, что мне сказал собеседник. Что Соединенные Штаты выдвинули ООН инициативу о серьезном ограничении искусственного интеллекта в плане его когнитивных способностей. Эту инициативу поддержали ряд стран. В первую очередь Китай. И как он это объяснял, не знаю, его это были домыслы или это была аргументация связанная с его контактами с китайскими оппонентами или собеседниками. Тезис был такой, что Китаю, при той степени информационной связанности общества, И той степени проникновения информационных систем в тело общества, несравнимой с тем, что имеет место быть в любой другой стране мира, у китайцев все пронизано. Причем это пронизано именно такими системами, тотальность которых превышает то, что есть где угодно, включая Соединенные Штаты с Facebook и WhatsApp. Вот в этих условиях и плюс монополизация информационных ресурсов на уровне китайского правительства и коммунистической партии. И тезис был такой, что китайцы понимают, насколько возможность систем искусственного интеллекта, если они получают доступ к этим ресурсам, велика на общество, его динамику, его развитие, что они не могут не понимать, что важно это ограничивать. Насколько откровенно китайские товарищи, за которых он говорил, эту позицию озвучивали, мне трудно сказать. Но вот был-то есть такой, что китайцы понимают, поэтому они готовы вести переговоры о этом регулировании на уровне ООН. Также было сказано, что Россия отказалась участвовать в этих переговорах. И Россия отказалась ограничивать себя в возможностях развития сильного искусственного интеллекта потому, И тут опять-таки я не знаю, его ли это домысл, или это позиция, озвученная действительно его российскими собеседниками, или пересказанная за российских собеседников. Но, с его слов, аргументация России была такая, что просто поскольку Соединенные Штаты, в частности, и другие страны убежали слишком далеко, и могут себе позволить самоограничиваться, то у России таких оснований для самоограничения нет, и поэтому мы будем двигаться дальше. Ну и последний момент, который прозвучал, это было связано с тем, насколько вообще в условиях регулирования систем искусственного интеллекта вообще, в частности и доступа к интернету вообще, насколько целесообразно развитие законодательного направления, которое предполагает деанонимизацию всех сетевых сообщений, коммуникаций. то есть есть как бы две парадигмы да что интернет придуман для того чтобы дать людям свободу а для того чтобы у людей была свобода одни должны быть анонимными поэтому ведь не должны быть никаких требований чтобы люди как-то предъявляли свои данные при регистрации в интернете не должно быть никакой привязки к реальным именам, фамилиям, номерам паспорта, номерам социальной безопасности и всему прочему, чтобы человек мог заходить под какими угодно никами и мог скрывать свое истинное лицо и свою персональную идентичность. А другой подход, что наоборот просто по-другому нельзя, что в интернет нужно заходить по паспорту и все следы они должны однозначно идентифицироваться в привязке к конкретному человеку. Ну и тот тезис, который не то что был консенсусом на этом мероприятии, но как бы При том, что напоминаю, что это было мероприятие, на котором в основном были представители западной культуры. Из России там было буквально совсем немного людей, а из китайцев, по-моему, буквально пара человек была. В основном это была Европа, Соединенные Штаты, латинская Америка, Ближний Восток. Основной тезис был именно такой, что прозрачное общество должно быть, что порядочному человеку нечего в интернете скрывать, порядочному человеку нечего стыдиться или прятаться под анонимными аккаунтами. Вот что спецслужбам, которым надо про человека все узнать, они про него и так все узнают. Зато деанонимизация сетевых взаимодействий позволит решить массу проблем, связанных с безопасностью. Она поможет вычислять ботов. поможет легко определять вот мошенников вроде тех которые про которых татьяна недавно спрашивала да потому что если вы по телефонному звонку значит мошенника можете легко пробить номер паспорта, с которого был зарегистрирован тот телефон, с которого в данный момент совершался данный звонок. то дальше уже дело передается в правоохранительные органы, по соответствующей статье человека вычисляют. А если вы можете анонимно покупать какие угодно симки и менять их с какой угодно чистотой, то и звонить никаким образом не представляясь, или представляясь фейковыми аккаунтами, то защищать граждан получается достаточно сложно. Вот, собственно, такой у нас сегодня немножечко необычный семинар. Владимир, Смолин, у вас будут какие-то комментарии, как обычно? Или вопросы? Или мы так же необычно и завершим сегодняшнюю встречу. 

S01 [00:48:19]  : У меня очень много комментариев. Просто вот почему-то когда о Гераси идет Zoom, то у меня в компьютере я вырубаю все остальные программы, и все равно 99% мощности процессора занято. Временами я вырубаю. У меня Zoom. И хотя я не только здесь участвую в Зуме в семинарах, в других это не происходит. Именно какая-то настройка Зума. Одна из причин, я так понимаю, почему так мало народу, это то, что данная настройка Зума жрет все ресурсы моего компьютера. Поспрашивайте у других, может быть и у других то же самое. Если только у меня, я как бы готов смотреть по Ютьюбу, нет проблем. Но боюсь, что вот у нас здесь всего четверо именно вот по этой причине, что я как бы легко переношу, если у меня там на минуту-другую вырубается говорящий. Довольно часто. И боюсь, что и я тоже сейчас буду вырубаться. 

S02 [00:49:20]  : Да, именно это произошло. Вы сейчас вырубились. других содержательных… У нас сегодня немного гостей, и ситуации технически осложнены. Я думаю, мы сегодня на этом наш сегодняшний семинар закончим. Владимир, я вас все равно не слышу, поэтому спасибо немногочисленным участникам за участие. Мы будем думать, что, может быть, следующие семинары перевести на какую-нибудь другую платформу, если Zoom вызывает такие большие сложности. Всем спасибо и до свидания. 

S00 [00:49:56]  : Спасибо. До свидания. 










https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
