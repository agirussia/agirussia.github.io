


S02 [00:00:02]  : Коллеги, всем добрый вечер. К нам обратилась Елена Покатаева из редакции журнала BizJournal с вопросами, связанными с существующим уровнем развития искусственного интеллекта вообще и общего интеллекта в частности. Ее вопросы показались настолько хорошо продуманными, интересными и развернутыми, что Я с удовольствием согласился поговорить с Еленой на эту тему. Поэтому, Елена, здравствуйте. Здравствуйте. Даю вам слово. 

S00 [00:00:34]  : Да, здравствуйте ещё раз, Антон и все, кто к нам присоединились и кто нас слушает. Действительно, я обратилась к Антону с предложением побеседовать на тему, причём она достаточно объёмная. поговорить о том, что представляет сейчас собой, желательно на практическом уровне, вот это движение в сторону общего искусственного интеллекта, то есть это All Artificial Intelligence, AGI, пресловутый, который всех интересует. Вопросов у меня достаточно много, поэтому мы с Антоном приготовились к достаточно длительной беседе, но будем стараться её провести достаточно динамично, не затягивая, потому что бэкграунд на самом деле у людей достаточно большой, и здесь, на мой взгляд, требуется только лишь немножко придать некую системность вот этим представлениям. Ну, предлагаю начать. Начнём тогда вот с некого вводящего, вводного вопроса. Ведь если мы говорим о аббревиатуре Эйджай, то она имеет самые различные толкования. Ну, не самые, но, по крайней мере, есть две трактовки, которые друг от друга сильно отличаются. То есть, во-первых, можно, говоря об этом феномене, об этом научном направлении, исследовать моделирование процессов мышления человека, то есть уходить в некую академическую сферу. А можно пытаться максимально автоматизировать интеллектуальную деятельность человека, пытаясь заменить вот эту интеллектуальную работу человеческого мозга неким умным прикладным обеспечением. Вот, Антон, первый вопрос такой к вам. Вы вообще согласны с таким делением? стратегических направлений движения искусственного интеллекта в сторону его общего варианта. Или, может быть, вот этот общий искусственный интеллект – это вообще какая-то новая сущность, которая, как и человек, может выполнять какие-то и творческие, и научно-исследовательские, и даже практические бизнес-задачи на основе вот какой-то технологической платформы, которая реализует некую инфраструктуру, что ли, его интеллекта. Желательно при этом, конечно, не скатываться в некие вульгарные толкования, типа восстания машин, всяких вариантов наделения искусственного интеллекта субъектностью, свободной волей. Конечно, мы в это скатываться не будем, но какую-то границу все-таки хотелось провести. Расскажите свой взгляд. 

S02 [00:03:28]  : Спасибо. Этот вопрос очень простой, с одной стороны. С другой стороны, очень сложный. Очень простой он, по крайней мере, для меня, поскольку вот этот вот термин AGI, его примерно одновременно придумали три человека. С двумя из них я работал в одной компании 25 лет назад. Это Бен Герцель и Шейн Лек. Шейн Лек – это один из основателей DeepMind. Бен Герцель – это руководитель проекта «Сингулярный тенец», с которым я сотрудничаю по сей день. А третий человек это Питер Восс, тоже известный человек в сфере разработки искусственного интеллекта, и я с ним тоже лично знаком, правда не лично, не визуально, а по переписке. У нас с ним очень похожие проекты в области персональных ассистентов. И они этот термин, придумывая, они заложили в него совершенно конкретную вещь. что они под термином общий искусственный интеллект предполагали развитие искусственного интеллекта на его состоянии 20 лет назад когда к моменту 20 лет назад сложилась такая ситуация что даже это было уже больше это уже наверно 20 почти практически 23 года назад да если быть точным когда под искусственным интеллектом подразумевалось то, что сейчас называется машинное обучение, либо системы, основанные на правилах. То есть, примерно 25 лет назад сложилась примерно следующая ситуация, что было два направления искусственного интеллекта. Одно – это так называемая символьная. когда на основе некоторых предикатов или графов, или графовых обознаний, или систем логического вывода строились системы, основанные на правилах, или экспертные системы для решения определенных конкретных задач. Это так называемый символьный искусственный интеллект, или символический искусственный интеллект, как его некоторые называют. Другое направление заключалось в том, что мы для решения конкретных задач, допустим, распознавания номеров автомобиля, или распознавания пола человека, или предсказания траектории движения чего-нибудь, тренируем специально настроенные, сконструированные нейронные сети, или не обязательно нейронные сети. Это могут быть просто полиноминальные системы, аппроксимирующие функции. И эти системы тоже мы тренируем на определенных наборах данных, под определенный набор сенсоров. или датчиков, или измерений для решения совершенно конкретных задач. То есть, обе системы, несмотря на то, что они были совершенно разные, они и та, и другая решали узкие задачи. И после того, как мы натренировали систему на распознавание номеров автомобиля, мы ее на распознавание отпечатков пальцев уже не можем переобучить, Или после того, как мы сконструировали систему, основанную на правилах для предсказания, допустим, возвратности кредитов, мы не можем эту же систему переобучить, допустим, на предсказание пола ребенка, к примеру. При этом эти системы стали внедряться, они стали решать конкретные задачи. Они решали конкретные задачи уже 25 лет назад. в узких своих сферах. Но было некоторое неудовлетворение, что, так сказать, священный грааль мы не нашли. Воспроизведение того, как человек учится, развивается, самообразуется. Взаимодействие с окружающим миром и своими друзьями, товарищами, родственниками, некими и близкими мы это воспроизвести не могли, поэтому нужно было придумать какой-то термин, какую же задачу мы все-таки решим, которая не является вот этим банальным искусственным интеллектом. И было одно направление терминологической войны заключалось в том, что люди решили называть тот искусственный интеллект, который был 25 лет назад слабым искусственным интеллектом, а тот, который мы еще не придумали, называть сильным искусственным интеллектом. Проблема в том, что слабый и сильный – это вещи такие эмоциональные немножечко. Где слабый, где сильный, где границы между ними. И поэтому три упомянутых коллеги – Петервоз, Бенгерцель и Шенлек – они примерно одинаково, независимо пришли к термину «общий искусственный интеллект» или «искусственный интеллект общий». Artificial intelligence, artificial – искусственный общий интеллект. Основной принцип которого, что система должна иметь возможность обучаться на любые задачи. То есть, мы деконструируем принцип следующий, что мы делаем некоторую систему, которая может научиться чему угодно. Человек может научиться лодкой управлять, может научиться самолетом управлять, может научиться в шахматы играть, может научиться в ГО играть. То есть, человек адаптивно способен настраиваться на любые правила в течение всей своей жизни там плохуда или бедна он способен приобретать новые навыки значит адаптировать это новые навыки погружаться осваивать новые профессии и поэтому вот этот вот искусственный интеллект он стал называться общим При этом определение, можно опять-таки там сейчас, если интересно будет погрузиться в детали, но математическое определение было дано таким образом, что масштаб этого интеллекта он на самом деле не важен да то есть с точки зрения вот математической формы давайте так значит формально формула этого определения искусственного интеллекта например на следующую это способность достигать сложных целей в сложных условиях. Ну, в общем-то, да. Там есть некоторые вариации этого определения. Каноническое определение Бена-Гёрцеля – это способность достигать сложных целей в сложных условиях. Пи-Ванг еще дополнил это определение. значит необходимостью адаптации к ограниченным ресурсам вот то есть таким образом что мы не просто сложных целях достигаем сложных средах но мы еще и значит адаптируем ресурсопотребление таким образом чтобы не Получилось, что мы систему, которая просто методом перебора, пожирая всю энергию, находящуюся в космосе, решает любую задачу. Нет. Все-таки ресурсы ограничены. Система должна как-то оптимизировать их потребление. В общем, получается, что У нас, если система имеет более чем одну цель, формально, математически, и если сложность среды включает в себя более чем один параметр, то есть два – это уже много по сравнению с одним, то мы эту систему можем назвать системой, обладающей общим искусственным интеллектом в каком-то количестве. То есть, получается интересная вещь, что математически общий искусственный интеллект – это не какое-то фиксированное свойство или фиксированное количество интеллекта, а это способность именно адаптивно развиваться в любых условиях, какие бы системе ни были бы предъявлены. Насколько коротко я сказал про определение, дальше теперь вариации на эту тему. Вариации на эту тему есть, во-первых, что такое общий искусственный интеллект. Общий искусственный интеллект – это тот, который позволяет сделать две вещи. Первое – это так называемый Human-Level Artificial Intelligence. Это устоявшаяся аббревиатура. Проводятся периодически отдельные конференции по теме Human-Level Artificial Intelligence, то есть искусственный интеллект человеческого уровня. Обращаем внимание, что это не общий искусственный интеллект. Потому что общий искусственный интеллект – это способность к активному развитию и обучению различных навыков в различных условиях вообще. А human level artificial intelligence – это конкретно интеллект человеческого уровня. И мы можем их соединить. То есть, если мы создаем систему, которая в какой-то момент может быть с уровнем интеллекта кролика или мышки, или младенца, то она автоматически, получается, может по мере своего развития достичь Human-Level Artificial Intelligence. А дальше возникает следующее понятие – Super-Human, или Super-Intelligence, или Super-Human-Level Artificial Intelligence. Это про что история? Это про то, что если мы создали систему, которая может доразвиться самостоятельно до человеческого уровня, до Human-Level Intelligence, Если она сохраняет возможность развиваться дальше, она очень быстро может превысить уровень человеческих возможностей. Или если мы сконструировали систему с таким количеством памяти, которая позволяет обучиться до human level intelligence, то добавив быстродействие или добавив количество памяти, мы просто автоматически получаем super human intelligence. Это как раз одна из важных вещей, которую надо понимать. Если мы делаем систему, которая достигает human level intelligence, то super human level intelligence получается автоматически, тупо добавлением дополнительного числа ресурсов или времени обучения. 

S00 [00:13:07]  : Очень хороший ответ, Антон. Вы знаете, вот если вспомнить, как Вы предложили, то, что было там 20 лет назад, система, основанная на правилах и машинное обучение в самом начале своего развития, как два направления, и они всегда были на конференциях по искусственному интеллекту, всегда вместе шли. И пока не будем говорить о том, когда интеллект человеческого уровня перейдёт на уровень суперчеловеческого, потому что это пока всё в категории «если», это возможно. А вот что сейчас у нас происходит? А сейчас мы видим очень большой хайп, на тему больших языковых моделей, про которые вот уже в сознании такого обывателя есть чёткое представление. Вот это уже тот самый большой, общий, кто-то говорит, что уже даже сильный искусственный интеллект, потому что большая языковая модель знает всё. Вот там все знания мира уже лежат, модель знает всё, но Конечно, это не так. Вот покажите, пожалуйста, вот эти большие языковые модели, вот какое у них роли и место вот в этой эволюции. То есть, может быть, у меня Была вот такая некая мысль, что вот вначале был логический искусственный интеллект, с точки зрения самой формализации происходящего, требуется точное описание всех сущностей, всех взаимодействий, вся система предикатов должна быть выстроена и работает чёткий совершенно логический вывод, если без всяких вероятностей. Глубокое машинное обучение — это уже действительно другой подход к накоплению вот тех знаний, в кавычках можем взять, знаний автоматизированной системы. Потому что, вообще говоря, уже не требуется заранее вносить все точные данные, не нужна даже разметка исходных данных, обучающих в ДТС, как в первых вариантах машинного обучения. А на уровне больших языковых моделей вот тут вообще уже всё замечательно. То есть вообще не надо никак готовить никакие обучающие выборки. Вот где-то в облаке есть всё. То есть тот контекст, который необходим для работы самых разных интеллектуальных навыков, то есть фактически о чём вы и говорили. То есть можно ставить к одной и той же большой языковой модели, можно ставить много задач, фактически много разных целей. Будет много параметров и будет много ответов. Или всё-таки вот роли места всех этих больших языковых моделей, и конкретно XGPT и прочих, XGPT, как-то оно по-другому выглядит? 

S02 [00:16:26]  : Смотрите, давайте я попробую ответить. Прежде всего я сделаю оговорку, что я выскажу свою точку зрения. Потому что как и 20, и 30, и 40 лет назад люди стояли насмерть, одни говорили, что мы за нейросетевые методы, а мы за символические методы. И только маленькая горска людей говорила, а давайте будем не выкидывать и то, и другое. Возникло такое направление, как нейросимвольная интеграция или гибридные системы, которые сочетают в себе нейросетевые и символные методы. И как до последнего момента люди спорили о том, что же все-таки кое-AGI. Одни говорят, что AGI это уровень уровень человеческого интеллекта. Другие, что AGI это про то, про что я сказал. Это про способность к системе саморазвития. Третьи говорили, что нет AGI. Это то, что другие называют superhuman level intelligence. То есть у всех людей точки зрения разные, исследователи разные. Исследователи точки разные. До последнего момента, когда писалась книжка известная под эгидой Эсбера, Сильный искусственный интеллект, пусть сверхсразум, в написании которой мы с коллегами участвовали, там обсуждалось распределение на состояние пять лет назад. И, в общем, там распределение по вопросам различных исследователей было, когда наступит пресловутый Разброс был начиная от нескольких лет и кончая сотнями лет вперед. На сегодняшний день консенсус несколько сменяется. Это распределение по поводу того, когда он наступит, постепенно меняется в сторону того, что То, что люди называют сильным искусственным интеллектом, это, кстати, вот тоже вопрос, что они называют. Но то, что они называют сильным или общим искусственным интеллектом, оно случится скорее раньше, чем позже. И точно так же консенсус немножечко распадается между теми людьми, которые Говорят, что нейросети – это не про HDI, и теми, которые говорят, что нейросети – это уже почти HDI современная. Буквально 5 лет назад больше людей говорили, что нейросети – это совсем не HDI. что-то большее, нам пока неизвестное. Сейчас больше людей склоняется в сторону того, что нейросети приближают нас существенно туда, потому что просто те факты, которые постепенно нам демонстрируются, экспериментальные, что мы можем построить систему, которая будет до какого-то момента, значит, трудно отличима от человека, значит, этих фактов становится все больше. То есть, на самом деле, значит, история же такая, что пресловутый тест Юринга, который долгое время считался мивилом искусственного интеллекта, он в какой-то момент, по-моему, в 2014 году был формально пройден. Но он был формально пройден программой, которую даже символьным искусственным интеллектом нельзя было назвать. Он был просто создан программой, которая была запрограммирована на прохождение Тюринг-теста. И тем самым то, что вот эта программа, запрограммированная на прохождение Тюринг-теста, прошла Тюринг-тест, сам этот факт послужил основанием для большого числа исследователей сказать, что Тюринг-тест вообще не применим. Буквально 2-1,5 года назад можно сказать, что формально Тьюринг-тест был пройден. Потому что вот эти нейронные сети до тех пор, пока не ловишь их на пресловутых галлюцинациях, когда они пытаются с умным видом рассуждать о том, чего не знают, трудно подловить на том, что они действительно являются не людьми. При этом, с точки зрения математики, если мы возьмем математику, которая за ними находится, мы увидим, что эти сети строятся по методу аппроксимации. То есть, мы берем большое количество данных. максимальное количество данных, которое покрывает либо там всю конкретную предметную область, либо всю совокупность предметных областей. И мы видим, и мы можем этими сетями аппроксимировать все эти данные. выраженные в текстовом виде, выраженные в аудио виде, чтобы генерировать максимально правдоподобные, воспроизводить максимально правдоподобные паттерны, вписывающиеся в ту картину данных, которые этим сетям были выданы. Вопрос. Становятся ли эти системы системами общего искусственного интеллекта? С точки зрения того самого формального определения, которое мы сформулировали в начале. Мой ответ, что строго говоря, нет. Почему? Потому что, если вы взяли весь объем литературы, накопленной человечеством, и долго и мучительно тренировали эту сеть на этом объеме литературы, то система усвоит этот объем литературы. Но если вы захотите расширить знания этой системы на, допустим, объем литературы жителей другой планеты, то вам придется тренировать систему заново. То есть вам придется ее рожать заново, тратить все эти вычислительные ресурсы, которые потребуются для тренировки, но уже на большем корпусе. То есть система не способна приобретать новое знание. Она способна адаптироваться к новым условиям. То есть мы можем сочинить какой-то промпт, так называемый. Мы можем создать в системе некоторый контекст. в котором она будет открывать, раскрывать выученную ей информацию, возможно, в каких-то аспектах, которые мы не могли себе вообразить. И в этом смысле даже можно сказать, что система будет способна к творчеству, потому что она будет синтезировать что-то в каком-то новом контексте, с которым она никогда раньше не сталкивалась, но она возьмёт из каких-то прошлых опытов, что-то соединит, соединит горькое с зелёным или фиолетовое со сладким, и получится что-то фиолетово-сладкое. И это, возможно, будет какой-то эврикой. Но это все равно будет в рамках того жизненного опыта, который она через вот эту многократную итеративную подборку, многократный итеративный подгон коэффициентов на что она была натаскана. Она не способна будет инкрементально, динамически впитывать в себя новую информацию и обучаться новым навыкам без дополнительного набора тренировочных данных и новые итерации перетренировки. 

S00 [00:24:02]  : А вот, скажем, когда-то ещё совсем недавно были отдельно текстовые, большие языковые модели, они как-то указывают на их текстовое, символьное происхождение. развивались отдельно модели трансформера для изображения. А сегодня вот мы уже видим время мультимодальных систем. Там и голос, и видео, и изображение, и тексты. Вот может быть прорыв происходит вот на этом пути сейчас, на пути объединения модальностей. 

S02 [00:24:40]  : Прорыв происходит во многих аспектах. Мы начнем с того, что прорыв случился в тот момент, когда оказалось, что количество прирастает в качество. Был подтвержден известный тезис, что, оказывается, количество может прирасти в качество. В какой-то момент нейросети, которая, казалось бы, не способна обучиться решению какой-нибудь интеллектуальной задач. Оказалось, что если сделать достаточное количество слоев и достаточное количество параметров, то она может вести себя так, как она ведёт себя сейчас. А потом выяснилось, что мы ещё можем соединять вместо разметки, вместо ручной разметки данных, вместо того, чтобы размечать, что вот здесь у тебя глагол, вот здесь у тебя существительное, показывать, совмещать аудио с видео или текст с картинками, и система автоматически находит корреляционные связи между предъявленным визуальным Рядом идет визуальная структура и предъявленным текстом, и тем самым возникает… По сути, другими словами, мультимодальность на больших данных, она по сути является неявной разметкой. То есть мы можем разметить вручную малое количество данных и разметить их точно. А мы можем взять огромное количество данных и разметить их не точно. Но это огромное количество данных, размеченных не точно, окажется настолько огромнее маленького количества данных, размеченных точно, что просто за счет объема мы проблему разметки решим. Причем, чем больше этих модальностей, тем получается точнее разметка. Потому что мы размечаем данные одновременно в нескольких аспектах. 

S00 [00:26:46]  : А вот как Вы очень хорошо сказали, когда рассказывали о самой математике вот этих нейросетевых моделей, о том, что идет поиск максимально правдоподобных данных. А вот что является здесь метрикой и как происходит такая унификация вот этих метрик правдоподобности в разных модельностях? 

S02 [00:27:18]  : Стандартная история на самом деле по поводу того, Как решаются все эти задачи? Она имеет свои корни в области, которая когда-то никакого отношения к искусственному интеллекту не имела. Это алгебра, это решение системы уравнений, когда у нас есть много неизвестных и много уравнений. и система недопределена или переопределена, и нам нужно найти приближенные решения этой системы уравнений. И решение решается итерационным методом, то есть мы как-то начинаем подбирать вот это вот множество значений таким образом чтобы эти правые части они минимально расходились с тем что у нас задано в системе да то есть мы просто постепенно подбираем все более и более точное значение коэффициентов чтобы то, что мы ожидаем получить на выходе, оно минимально отличалось от того, что мы получаем. То есть, неважно, что мы пытаемся предсказать. Пытаемся мы или предсказать тональность звука, который выходит, или мы пытаемся предсказать символ, который выходит, или мы пытаемся предсказать значение пиксела в зависимости от предыдущих пикселов или сопряженных пикселов. Все равно мы пытаемся построить систему коэффициентов, которая, имея некоторый набор чего-то с одной стороны, предсказывает значение на краю. И если мы получаем ошибку этого предсказания, мы каким-то образом изменяем значение этих коэффициентов так, чтобы эта ошибка уменьшилась. И, повторяя это многократно, мы можем получить какое-то оптимальное решение. Вот. И математически совершенно неважно. Соответственно… Ну, а дальше ситуация такая. Чем больше у нас вот этих самых уравнений, тем статистически более точно… Если все эти уравнения описывают некоторый реальный мир… Да, здесь важный момент. Потому что мы можем случайным образом нагенерить такое количество уравнений, которые не будут иметь решения, потому что они не описывают реальный мир. Но если мы соберем такие уравнения, которые описывают реальный мир, неважно, будет этот мир описывать видеопоток или аудиопоток, или какой-то гибридный смешанный аудиомультимодальный поток, то тогда, чем больше этих данных, тем точнее статистически получится наше решение. 

S00 [00:30:05]  : Да, понятно. То есть для задачи распознавания нам нужно минимизировать эту ошибку, а обратная задача, можно её немножко увеличить, и тогда мы получим букет генеративных возможностей. 

S02 [00:30:22]  : А дальше мы получаем следующее. После того, как мы научились предсказывать, мы помещаем систему в то состояние, в котором она раньше не была, и она пытается придумать, а что могло бы быть после. И возникает то, что на самом деле в одних ситуациях называют галлюцинациями, а в других случаях называют эврикой. Я на самом деле в глубине души всегда обижаюсь за глубокие нейронные сети, когда их обвиняют в галлюцинациях, потому что на самом деле Любой выдающийся ученый, который делает открытия, он беспрерывно галлюцинирует. Некоторые галлюцинации подтверждаются экспериментально, и тогда они становятся открытиями. А те галлюцинации, которые не подтверждаются, Открытиями не становится. Они не проходят проверку реальности. Поэтому, на самом деле, я не могу сказать, что наличие галлюцинаций у нейронных сетей характеризует об их низких когнитивных способностях. Когнитивные способности как раз нормальные. Тот факт, что мы достигнем такого уровня в области глубоких нейросетевых моделей, говорит о том, что материалистическая картина мира становится все более доказуемой. что если мы сумели с помощью систем коэффициентов создать нечто, что настолько похоже на человека по поведению, то, наверное, то, что человеческий мозг состоит из конечного числа нейронов и синапсов, наверное, имеет право объяснять его поведение на том уровне интеллекта, на котором мы его наблюдаем сейчас. То есть проблема ключевая именно в том, что то, как это устроено сейчас, оно предполагает именно долговременное обучение на конкретном и консистентном наборе данных. И нет возможности изменить это поведение на основе новых данных. с тем, чтобы это поведение запомнилось. То есть, мы можем помещать систему в новые контексты, мы можем динамически эти контексты менять, но это не будет менять саму претренированную модель. 

S00 [00:32:56]  : Понятно. Опять же интересную мысль высказали о том, что уже вроде бы есть некое приближение к этому human level, к человеческому уровню искусственного интеллекта. Вот недавно прошли такие большие конференции мировые, и в OpenAI, и в Google были разные анонсы. Наверняка вы за ними следили, за этими событиями. Можете сказать, какие-то практические примеры привести? Вот что-то в работе, какие-то новинки, научно-технические какие-то новости, которые проходили в последнее время, Какие из них характеризуют наивысший уровень развития тех интеллектуальных возможностей, тех систем, к которым мы все стремимся? 

S02 [00:33:55]  : Смотрите, первое, что нужно сказать, что по факту человеческий же интеллект на самом деле очень многогранный. То есть, человек и огромное количество энергии, которую человеческий мозг потребляет, он потребляет на то, что называется неинтеллектуальная деятельность. Это моторная деятельность, сенсорная деятельность, это двигательная активность. А то, что связано с обработкой текстов, вот это в общем только какая-то составляющая часть вот и то что мы видим ну и просто то есть я что хочу сказать что основные успехи которые сейчас демонстрируется это успехи демонстрируется прежде всего именно в работе с текстовой и аудио, и в последнее время с видеоинформацией. И это не настолько связано с… именно с моторными навыками. Я что имею ввиду? Вот есть, допустим, чат GPT, и вы можете с этим чат GPT долгое время говорить на любые совершенно темы. Начиная от того, как телефон починить, и кончая тем, как в теннис играть или как пиццу приготовить. Но никакого из существующих роботов вы не можете научить сперва кататься на велосипеде, а потом научить его играть в хоккей, потом научить его играть в футбол. То есть, с точки зрения именно двигательных функций, мы еще очень далеки от этого общего искусственного интеллекта. С одной стороны. С другой стороны, как буквально, по-моему, сегодня утром кто-то у нас в сообществе пошутил в одном из наших чатов. Наверное, тут надо сказать, что мы с вами находимся сейчас на площадке русскоязычного сообщества общего искусственного интеллекта, которое существует уже Или почти 10 лет, или больше 10 лет, я сейчас точно не помню. В общем, порядка 10 лет существует в Фейсбуке, во Вконтакте, в Телеграме, на Ютьюбе. По электронной подписке в сообществе Телеграм сейчас порядка 1100 пользователей, на Ютьюбе порядка 1500 подписчиков. И мы уже последние, по-моему, примерно четвертый год еженедельно на наших вечерних онлайн семинарах обсуждаем различные аспекты общего искусственного интеллекта, его развития, создания возможностей, перспектив и всего с этим связанного. И вот как раз сегодня в одном из наших каналов на Телеграме Было высказано такое саркастическое высказывание, что мы думали, что искусственный интеллект заменит нам дворников, таксистов и посудомоек, а мы сконцентрируемся на интеллектуальных и творческих функциях. А получилось точно наоборот. Почему? Потому что искусственный интеллект прекрасно галлюцинирует, прекрасно может сейчас, еще не прекрасно, но все лучше и лучше может рисовать картины. новая, которая… причем микшируя различные стили, генерируя новые стили. Мы же галлюцинировать умеем. Мы можем взять стиль Ван Гога и стиль Рубенса и изобрести Рубенса-Ван Гог. Микшированием стилей. Это будет нечто совершенно… невиданное. И в этом стиле рисовать любые картины, которые мы забьем туда-пром. С определенными оговорками, но, я думаю, технология будет развиваться. Генерация музыкальных произведений уже идет. Генерации текстов – пожалуйста. Мы можем где-то находить там косяки, можем где-то находить шесть пальцев вместо пяти, но люди работают с тем, чтобы ограничить вот эти лишние пальцы. А вот с палатёрами превратить робота-палатёра в робота, допустим, стекломойщика или робота-посудомойщика, не получается, придётся людям делать. Поэтому тут такая интересная ситуация. Но важный момент, что всё-таки на сегодняшний момент мы имеем следующее, что система может заниматься аппроксимацией и так сказать и интерполяции и даже экстраполяции в областях которые хорошо протоптаны да то есть если там нам нужно написать допустим алгоритм допустим разбора текста на какие-то слова, токенизации последовательности символов. Мы можем попросить алгоритм это сделать. Он нам напишет, потому что на GitHub можно найти тысячи и сотни тысяч, значит, реализации этого алгоритма токенизации, вот, и эта система на этом алгоритме, значит, обучалась, значит, в большой, сотни тысяч, сотни тысяч итераций, она все это умеет делать, но если ей нужно решить какую-то сложную задачу, с которой она никогда не справлялась, и такую, что подобной задачи или подобные задачи в интернете, в тренировочном наборе представлено не было? Она ее не сможет решить. Это просто экспериментальный факт. У меня многие коллеги пользуются вот этими чат-GPT и копилотом для программирования. И да, если нужно какую-то рудиментарную операцию сделать, вроде как автокомплит автоматически продолжит последовательность символов, это пожалуйста. А вот если нужно конкретную задачу решить, все равно надо уже думать. 

S00 [00:40:13]  : Если попытаться сравнить, ну вот ваше мнение интересует. Есть глобальная модель, о них очень много новостей всегда выходит. Есть наши российские. Есть большие гранды, есть меньшие компании. Вот с вашей точки зрения, как выглядят наши разработки? 

S02 [00:40:43]  : Здесь есть два момента. Основной момент – если мы говорим про большие языковые модели, то мы находимся в фарваторе, мы занимаемся воспроизведением. чужого опыта вот то есть то что изобретено за рубежом в большинстве случаев области больших языковых моделей значит у нас копируется и соответственно то что у них в кавычках есть сейчас это то что у нас в кавычках будет через через год говорю, ну или через месяц, через какое-то время. При этом надо понимать, тут опять-таки я не буду никого спекулировать, мы не знаем, что происходит за закрытыми дверьми, мы не знаем, что происходит за закрытыми дверьми у нас, а как мы знаем из некоторого опыта, что часто у нас за закрытыми дверьми происходит, о чем мы даже не предполагали и не только мы оказываемся этому удивлены, но наши зарубежные коллеги, партнеры или оппоненты, как их называть. Но никто не гарантирует, что у них за закрытыми дверьми не происходит чего-то такого, о котором мы не предполагаем. Но если говорить о том, что происходит за открытыми дверьми у нас и у них, то мы идем, так сказать, на шаг-полшага позади и американцев, и китайцев. Это первое. Второе, что для того, чтобы в этой парадигме больших языковых моделей что-то делать, нужны вычислительные мощности. С точки зрения вычислительных мощностей, мы идем не на шаг и не на полшага, а на 10 шагов позади. Потому что тех вычислительных мощностей на том железе, которое есть у них сейчас, Мы не можем себе часто позволить. Потому что и санкции, и деньги. Американцы и во вторую очередь китайцы могут делать это быстрее, лучше, дешевле. Чисто по той причине, что у них есть железо. Тут мы находимся в ситуации догоняющих на сегодняшний день, если говорить о том, что происходит в публичном пространстве. Хотя, несмотря на это, утверждается, я сам не пробовал, на всё время не хватает, но утверждается, что как в своё время поиск Яндекса на русском был лучше, чем поиск Гугла на английском, утверждается, что Сберовский гигачат по-русски говорит лучше, чем чат GPT, но я не проверял. 

S00 [00:43:33]  : Понятно. Если мы идём в фарватере, в позиции догоняющего, то можно ли сказать, что это не просто движение всех в каком-то направлении разных стран, а есть ли при этом какая-то конкуренция? 

S02 [00:43:52]  : Основная конкуренция сейчас, опять-таки, если мы говорим большие языковые модели, здесь между Китаем и США. То есть, китайцы пытаются по обоим позициям обеспечить, если не лидерство, то хотя бы в ровень идти на уровне исследований. И там сумасшедшие деньги вливаются университетов, образования, конфирмирования исследовательского сообщества. Причем интересный тренд. Я не очень внимательно за этим слежу. Но вот в моей области я недавно наткнулся на статью которая оказалась есть только на китайском. То есть, вот там определенная тематика в области обработки текстов на естественном языке мне ближе. Одна статья года 2-3 назад вышла Она на английском языке опубликована. А вот самая последняя статья, я ее обнаружил, она есть только на китайском. И даже не я ее нашел, у меня есть студент-китаец. Вот он мне эту статью выложил, в своей работе он ее использовал. Меня это насторожило, что я подумал, что, может быть, китайцы сейчас уже потихонечку начинают публиковать, откалываться от англоязычного сообщества. Не знаю, может быть, просто эта статья так сложилась, что вышла, может быть, потом она и на английском выйдет. Но вот китайцы свою собственную экосистему пытаются создать научную. 

S00 [00:45:30]  : А если поставить вопрос так, наши разработки, исследования в области генеративного интеллекта, Это поле для такого вольного развития академической науки для тех, кому нравится заниматься наукой? Или нужно создавать вот это направление, развивать, вкладывать усилия? То есть нужна ли нам импортно-независимая генеративный искусственный интеллект. Вот если так вопрос поставить. 

S02 [00:46:10]  : Тут, значит, сразу несколько выкопнули очень спорных, так сказать, и противоречивых вещей. Во-первых, сказали слово «академическая наука» и в моем понимании то, что подразумевалось под академической наукой 30 лет назад, она вообще никакого отношения к искусственному интеллекту современному и тем более генеративным моделям не имеет, потому что никаких, ни малейших намеков на наличие хоть каких-нибудь ресурсов, необходимых для работы с генеративными сетями ни у каких-либо академических институтов и сообществ На сегодняшний день нет. То есть, всё, что в этой области делается, это всё делается в лабораториях крупных компаний уровня Сбер, МТС и Яндекс. Там может быть каких-то ещё других. Вот я там не очень внимательно за этим слежу, ВК мырую и так далее. Можно говорить, что это академическое, но только в том смысле, что этим занимаются не академики Российской Академии Наук, а дата-сайентисты российских корпораций. Научные исследования. Это с одной стороны. С другой стороны, опять-таки, я, может быть, выскажу не очень оптимистическую точку зрения. Я с другой стороны зайду. Вот смотрите. Я сейчас, допустим, работаю в ОСУТП. Это автоматизация технологических процессов. На семинаре на последнем у нас выступал Тимур Сайдеков. Он из атомной промышленности. Это области критической инфраструктуры. В областях критической инфраструктуры невозможно доверить принятие решения системе, которая будет принимать решения на основании какой-то модели, которая на чем-то выучена. Упаси Боже, она выучена на чем-то в интернете. То есть, эта система, во-первых, должна быть основана на понятных правилах, которые человек, который отвечает за принятие решения этой системы, может верифицировать. И вот здесь мы подходим к важной теме так называемого прозрачного, доверенного или интерпретируемого искусственного интеллекта. где предполагается, что мы, во-первых, понимаем, на основании чего система принимает те или иные решения. То есть, мы можем ее открыть и посмотреть. Тут она вот это знает, а тут она это не знает. Более того, что если система дает какую-то рекомендацию, она способна пояснить, а почему она эту рекомендацию сделала. То есть, если система говорит, что у человека там рак, и его нужно срочно на операционный стол, она должна объяснить, а почему она так считает, чтобы человек мог принять ответственно информированные решения о том, что это действительно делать или не делать. Потому что отвечать в конечном итоге все равно будет человек. И в этом смысле, возвращаясь к тому, куда нас привели нейросети и где они нас заменяют, они нас заменяют как раз в тех областях, которые мы думали оставим для себя. Художники, музыканты, композиторы – вот там, где ответственности нет, там, где не нужно подписываться своей должностью и жизнью под принятием какого-то решения – там, пожалуйста. А там, где нужно принимать какие-то решения, во-первых, в Евросоюзе уже несколько лет назад принято соответствующее законодательство, что даже в бизнесе и не только в медицине принятие решений должно быть интерпретируемым. То есть система, неважно какую нейросеть ты использовал, ты должен по запросу пользователя, которому предписали пройти какую-то медицинскую процедуру, или отказано в кредите, ты должен ему объяснять, почему ты это сделал. В других странах, очевидно, это тоже будет развиваться. И поэтому именно применимости вот этих вот систем, она ограничена, скажем так, юридическими рамками, где человек может отказаться от от ответственности за принятие решений системой или там, где эта ответственность некритична. Например, допустим, мы сейчас с вами поговорим, будет расшифровка. Вы готовы будете, допустим, не прочитав эту расшифровку, опубликовать ее у себя в журнале? Может быть, нет. И тогда вы вам все равно придется вычитывать текст и принимать решение. А может быть, да. Но тогда есть вероятность, что случится так, как с многими онлайн-книжками. Часто скачиваешь какую-нибудь онлайн-книжку, начинаешь её читать и понимаешь, что дальше, чем пять страниц, ты прочитать не можешь, потому что там ошибки распознавания идут в каждом абзаце. И ты просто не можешь перебороть отторжение от того, что такое количество ошибок Просто глаз отказывается воспринимать. 

S00 [00:52:02]  : Ну вот так. Кстати говоря, критическая информационная инфраструктура, понятно, что там особые требования. 

S02 [00:52:12]  : Не только информационная, и не только информационная, то есть это и военная, любая критическая информация. Военная, информационная, медицинская, энергетическая. 

S00 [00:52:26]  : Да, а информационное пространство у нас никаким критическим вроде как не является. Но важно ли при этом какой модели ставят свои запросы наши вот обычные люди, школьники, студенты, те самые маркетологи, которых призывают время пользоваться, да? То ли они чат GPT ставят свои запросы, то ли гигачату. Это важно? 

S02 [00:52:55]  : Совершенно верно. И вот, значит, я тоже периодически про это напоминаю. Вот есть два человека, значит, где-то разные, где-то похожие. Значит, один американский, другой наш. Американского человека зовут Илон Маск, российского человека зовут Игорь Ашманов. И они в прошлом году высказали примерно один и тот же тезис. что основная угроза... Сейчас переходим к теме про роботов, которые уничтожат человечество. Ужас и искусственный интеллект. Мы сейчас подошли к ней вплотную. Основные риски, которые оба человека независимо высказали в отношении развития современного искусственного интеллекта, как есть, Это возможность использования вот этих вот больших языковых моделей для массированного информационного воздействия на аудиторию в онлайн-пространстве. Для достижения маркетинговых целей, для достижения политических целей, ну, собственно, вот две основные цели, да, так сказать, маркетинговые и политические. То есть, заработать больше денег, значит, либо на уровне бизнеса, либо на уровне межгосударственного противостояния. 

S00 [00:54:22]  : Да, понятно. Если у конкретной модели есть конкретный владелец, можно сделать какие-то выводы о воздействии, о том, каким образом содержимое этой модели, этот контент может использоваться. 

S02 [00:54:37]  : воздействовать на неокрепшую конечно конечно собственно вот то есть это-то понятно собственно истоки всех разговоров про значит фаерволы да так сказать великий китайский фаервол а давайте построим значит по примеру великого китайского фейерволла в великий российский фейерволл вот или давайте не будем строить это вот все из этой же истории вот и тут видите тут тоже как бы эти есть очень большая поляризация вот как мы про значит ученых заговорили да какой что ученые думают по этому поводу да тут ведь тоже поляризация то есть одни ученые да Считают, что наука как была самая международная, она и должна оставаться международной, что не нужны никакие границы. И все знание должно быть общим достоянием. А другие фиксируют то, что эти границы возникают, к сожалению, не с нашей стороны. И с этим что-то нужно делать. И одна из проблем, которая тоже подчёркивается, причём не только у нас, то есть есть люди, которые на Западе выступают по этому поводу как среди исследователей, так и из бизнеса, это так называемая проблема элаймента или проблемы выравнивания. Она заключается в том, что когда мы тренируем вот эту большую языковую модель, мы ее тестируем на некотором наборе данных, которые предполагают наличие некоторых ценностей или некоторых, так сказать, этических норм, которые, скажем так, стейкхолдеры, да, или, так сказать, владельцы, условно говоря, вот этой системы предполагают. Вот. И если вот этот вот набор этих данных содержит какие-то определенные ценности и императивы, и клише несовместимое с ценностями и императивами какой-то другой, части человечества или какой-то другой популяции, то очевидно, что те ответы, которые находят или те контексты, или те смыслы, которые несет взаимодействие с этой языковой моделью, они будут неприемлемы для вот этой другой части общества. общество в большом смысле планетарного населения вот и если мы и как раз вот голоса раздаются на тему того что значит должна быть некоторая демократизация в этом плане да ну должна быть откуда она возьмется непонятно да потому что у кого больше ресурсов и больше возможности платить зарплату ученым в области науки о данных, дата-сайентистам, у того и больше возможностей. Но идея, голоса идут за то, что каким-то образом должны быть разные языковые модели. Должна быть какая-то пресловутая многополярность. Должен быть не только многополярный мир с точки зрения политических факторов, Но должен быть многополярный мир также с точки зрения этих языковых моделей. Должно быть не только равенство полов или цветов кожи, но должно быть и равенство точек зрения и этических норм, выражаемых различными языковыми моделями как это достичь непонятно да потому что вот тоже значит самое как проводили недавно значит сравнительные исследования оказалось что Все модели языковые, включая изберовский, они на некоторые вопросы такого политического характера дают ответы, скажем так, не совсем ожиданное и не совсем совместимое с повесткой существенной части российского населения. Вот. То есть, условно говоря, они все являются более прозападными. Вот. В меньшей или большей степени. Вот. Но это то, что есть. Это такая реальность. 

S00 [00:59:27]  : Да, вот модели тоже, как вы говорите, могут отражать многополярность нашего мира, а при этом есть ещё модели с открытым кодом. Они вроде как ничьи. Ну там есть какие-то номинальные владельцы, но в общем-то это всегда продукт деятельности сообщества. А вот с ними как? И они причём разбиваются это очень интенсивно и активно. Может быть у них тоже такое же влияние будет на все наши информационные системы. Примерно такое же, как Open Source оказал на корпоративные приложения. То есть просто такое мощное. движение, и так что даже нашим регулирующим органам пришлось как-то пытаться тормозить специальным образом, вопросы безопасности изучать. Вот что-то вы подобное ожидаете в плане моделей, генеративных моделей с открытым кодом? 

S02 [01:00:30]  : Ну, хотелось бы верить в такую возможность демократизации, но на практике, значит, если взять, к примеру, ситуацию с тем же самым программным обеспечением, вот сколько инсталляций Microsoft с закрытым кодом и сколько инсталляций Linux с открытым кодом – вот это вещи совершенно не посопоставимы, прежде всего в силу того, что есть маркетинг, есть законы рынка, по которым хорошо продается не то, что лучше, а то, что больше продвигается. Я знаю массу людей, которые пользуются копилотом, но не знаю ни одного, который пользовался какими-то, условно говоря, опенсорсными демократическими решениями. ну потому что как бы зачем но если у человека есть возможность пользоваться тут как бы знаете это искать история про пресловутая значит блокчейн и криптовалюта значит тоже периодически возникают эти разговоры. Ситуация очень простая. Если вы используете недемократическую визу или мастер-карт, недоступную у нас в России, или недемократичный мир, который доступен у вас в России, у вас одна транзакция стоит, грубо говоря, одну копейку. А если вы используете демократичный биткоин или блокчейн, у вас транзакция стоит рубль. Ну, соответственно, а дальше вопрос простой. Вы, так сказать, как гражданины, как простой пользователь, вы хотите за транзакцию рубль платить или одну копейку? Естественно, вы будете платить одну копейку, вы пойдете к недемократичному Гигачату или Визе или Миру и будете там проводить дешевые транзакции. Зачем вам эти дорогие транзакции на каком-то там биткоине или блокчейне? 

S00 [01:02:37]  : Понятно, понятно. Вот если опять немножко вернуться к нашим замечательным большим языковым моделям и немножко ещё вспомнить о различных языках. Понятно, что есть страна происхождения, есть язык, который изначально лучше всего поддерживает данную конкретную модель. Но ведь если говорить о знаниях, а мы всё время как-то пытаемся... Сейчас вот разговор у нас идёт о знаниях, о знаниях модели, знаниях человека. то многоязычность это всегда считается достоинством человеческого интеллекта. То есть человек может получать информацию на разных языках. Вот как вы думаете, может быть к большим моделям Тоже применимо вот это правило, что лучше для меня, как для пользователя, не та модель, которая хорошо поддерживает мой язык, который я знаю с рождения, а та, которая поддерживает много языков на хорошем уровне. И вот это мне поможет как раз решать большее количество задач и на новом уровне. 

S02 [01:03:52]  : тут все гораздо веселее потому что собственно вот существующий взлет в этой области он как раз многоязычности начался вот потому что все началось насколько я помню с того что в гугле когда значит стали пытаться, когда занимались нейросетевыми системами перевода на основе глубокого обучения, они обнаружили, что если систему обучают на большом количестве языков, то она гораздо лучше формирует некоторые внутренние представления о каких-то смыслах, чем если делать это на малом количестве языков. И это как раз происходит за счет феномена пресловутой многомодальности. То есть, грубо говоря, если вы рассуждение о том, что мама мыла раму дадите системе только на английском языке, она сформирует какое-то одно представление. Но если вы дадите ей информацию о том, что мама мыла раму на 100 языках, то это представление будет гораздо богаче. И как раз за счет этого обогащения возникла гипотеза, что увеличение количеством мультимодальных данных в сочетании с технологией трансформеров, которая позволяет эффективно предсказывать последовательности в различных контекстах, она как раз оттуда Значит, эта история и пошла. И с практической точки зрения все, опять-таки, зависит от задачи. Реально, если у меня нет задачи решать какие-то проблемы на разных языках, то зачем мне эти разные языки? То есть все-таки математически здесь дело в мультимодальности. Чем больше модальности система может переварить и соединить, тем ниже потребность вручную разметки. Потому что эти различные модальности сами друг другу себя размечают в том случае если мы можем иметь дело с заведомо избыточными и повторяю не просто из избыточными наборами данных но консистентно избыточными да то есть просто большое количество мусора если мы возьмем то ничего не получится. А если вот эти вот все переводы одних и тех же текстов на все языки, они действительно будут соответствовать друг другу, то мы как раз можем получить вот это вот адекватное внутреннее представление о картине мира, которое будет инвариантно уже к конкретному языку. 

S00 [01:06:28]  : Да, всё верно. Но с другой стороны, вот вы сказали, всё зависит от задачи. Если мы говорим о практической жизни корпоративного сектора, то есть о наших компаниях, которые работают в различных отраслях экономики, в различных сферах деятельности, то они вообще решают бизнес-задачи. И им, вообще говоря, вот эти вот знания универсальных моделей обо всём, вообще говоря, не нужны. То есть это нужны. Какой-то болталки, да? 

S02 [01:07:07]  : Смотрите, здесь ситуация следующая. То, что называются большими языковыми моделями, это понятие достаточно условное, потому что мы в качестве данных можем затолкать все, что угодно. То есть, с помощью больших языковых моделей мы поняли, что действительно, взяв достаточно большое количество слоев, достаточно большое количество параметров и получив достаточно большое число вычислительных ресурсов с достаточно высокой производительностью, мы можем даже такую сложную вещь, как человеческий язык, аппроксимировать настолько хорошо, что создадим поведение, которое с какой-то точностью будет воспроизводить человеческое. Дальше. Если у нас возникает задача предсказания транспортного потока, или предсказания поведения плазмы в реакторе, или предсказания, допустим, поведения крупного рогатого скота на какой-то территории. Если мы можем получить достаточно большой набор консистентных данных, и правильно токенизировать, побить эти данные на некоторые обучающие выборки, то, в принципе, мы сможем сделать систему, которая будет предсказывать всё, что угодно. Транспортный поток, состояние плазмы, поведение стад крупного рогатого скота. То есть, в принципе, мы можем, стараясь, строить предсказательные модели на всём, на чём угодно. Вопрос только в том, первое, являются ли эти модели интерпретируемыми. То есть, можем ли мы, получив некоторую модель, убедиться, что мы закрыли все возможные сценарии и что у нас нет ситуации, когда система начнет галлюцинировать. А мы заранее не знаем, что вот в этой ситуации она начнет эволюционировать. То есть, если нам нужна система, бизнес-система, которая не будет там открывать и что-то изобретать. Эврики какие-то делать. А данная, которая должна просто управлять, допустим, температурой котла на электростанции или скоростью турбины на гидроэлектростанции. Там изобретение не нужно. Надо, чтобы там турбину не сорвало направляющих. Если в этой ситуации мы не знаем, в каких ситуациях система удержит турбину под контролем, а в каких нет, мы не можем ей доверить управление. То есть, мы должны, во-первых, иметь возможность, если мы обучили эту систему узнать у неё, как ты выучила, какие правила, какие формулы. Расскажи нам, пожалуйста, те формулы, по которым ты будешь описывать поведение этой турбины. Если система может написать формулы, Окей, все, человек подмахивает подпись, все, СМС сдается в работу. То есть, если бы система могла вывести, написать программу или вывести закон, с помощью которого нужно управлять конкретной ситуацией на производстве, она, наверное, могла бы действительно дать ценность бизнесу, потому что она бы просто сэкономила затраты на получение вот этой формулы и этой управляющей программы. Если система может предложить только какую-то модель, которую мы можем экспериментировать, верифицировать только экспериментально, то во многих случаях мы не можем пойти на этот эксперимент. Просто никто не положит голову на плаху под этим экспериментом. Это первое. чем хорошо обучение на видеорядах, на текстовых рядах, на аудиопотоке, тем, что очень много данных. которое не нужно генерить. Если мы хотим опять-таки строить управление технологическими процессами, например, или какими-то бизнес-процессами, то у нас не всегда достаточно обучающего материала на конкретные важные ситуации. Но опять-таки, если мы строим систему для предотвращения технологических катастроф, у нас нету данных, допустим, тысячи катастроф, на то, чтобы мы могли зафронтюнить систему на срабатывание технологических защит, направленных на предотвращение этой катастрофы. И мы не можем себе позволить такое количество данных сгенерить. И поэтому возникает ограничение ограничения наших возможностей по тренировке этих моделей. Вот для предсказания климата, наверное, да. То есть, наверное, чем больше у нас будет спутников летать и наблюдать за нашей планетой, чем больше у нас будет данных накапливаться, а по всем параметрам начинает солнечные активности. магнитных бурь и температурных данных, тем точнее будут наши модели предсказания климата. То есть, опять-таки, это зависит от того, насколько мы можем собрать данные в конкретной предметной области и насколько модель может эти данные сформировать в виде предсказуемой модели. А с формированием предсказуемых моделей как раз все на сегодняшний день достаточно плохо. То есть, по сути, все технологии ЛЛМ, которые есть сейчас, они являются неинтерпретируемыми. То есть, у нас символьный искусственный интеллект остался далеко позади нейронных сетей с точки зрения точности и возможности обучения. Но с точки зрения интерпретируемости, вот системы, основанные на правилах, они остались в таком же хорошем выигрышном положении, где и были. И нейронные сети тут ничего, к сожалению, не предлагают на сегодняшний день. 

S00 [01:13:28]  : То есть вот идея того, что можно для какой-то конкретно типа задач достаточно быстро построить обучающую выборку, она вам не кажется пока вот такой вот хорошо работоспособной. Вот откуда эта идея-то у меня появилась? Есть у нас большие языковые модели, у них много сведений, они содержатся в своей голове, которая в кавычках. И есть направление виртуальных консультантов. Понятно, что всегда были претензии к ним и до сих пор остаются о том, что они достаточно туповаты. Но просто им всегда не хватает контекста для поддержания разговора. То есть контекст они берут обычно либо из информационных систем корпоративных, и тогда могут что-то пользователю рассказать, что-то дельное. Либо из какой-то корпоративной базы знаний они берут конкретные сведения и дают уже какие-то осмысленные, хорошие ответы человеку. И получается, что если есть инструменты для создания таких моделей, небольших, неогромных, меньшего размера, но те, которые содержат именно детальное, хорошее, выверенное знание об этом куске бизнес-процессов. 

S02 [01:15:06]  : Ну, смотрите, раз уж вы сказали про консультантов, я просто свой личный опыт дам. Я впервые столкнулся с голосовыми консультантами в Соединенных Штатах как раз 25 лет назад, они тогда только начали внедряться. Вот. И я был в общем в ужасе от того, что если раньше ты мог позвонить по телефону и с любым человеком, который тебе рано или поздно ответит, решить любой вопрос, то тут ты просто потерял возможность решить любой вопрос, потому что ты бродишь по голосовому меню, которое ничего не понимает. Вот. Ну и я констатирую тот факт, что за 25 лет назад прогресс нулевой да то есть вот буквально я пытался решить там проблему с голосовым ассистентом там новосибирско-наргосбыта вот и я отчаялся да ну то есть от того что и от того что они значит стали говорить приятным голосом а не металлическим понимать то что ты им говоришь они лучше не стали И, казалось бы, почему бы все эти замечательные достижения не использовать, но мы здесь как раз попадаем на этот разрыв между тем, что одно дело – натренироваться на в каком-то большом объеме каких-то данных, которые описывает весь жизненный опыт, весь исторический опыт человечества и мировой литературы. А другое дело – решить совершенно точную, совершенно конкретную задачу, связанную с конкретным аккаунтом, у которого есть определенный баланс, у которого есть определенная проблема. То есть прогресс нулевой в моем понимании. И как это соединять? Опять-таки Питер Восс, один из авторов термина AGI, он считает, что именно по той причине, что Глубокие нейронные сети являются просто аппроксиматорами чудовищной мощности, не способными точно понять именно суть проблемы в совершенно точном контексте, сведенном до конкретных позиций, конкретных номеров счетов, конкретных балансов и конкретных действий, которые могут быть выполнены по этому счету. Они, значит, бесполезны за рамками, так сказать, просто среды развлечений. Можно, так сказать, генерировать какие угодно прекрасные образы, которые будут радовать глаз, или генерировать какие угодно прекрасные тексты, которые будут тебя развлекать. Но решить конкретную задачу можно только, когда Система может быть сведена к конкретному набору символов отношений, которые описывают совершенно конкретную проблему. В данном случае речь идет о интеграции нейросетевых моделей с символьными моделями. Мы, допустим, можем использовать нейросетевую модель для распознавания текста, но этот аудиосигнал или видеосигнал, если идет взаимодействие на языке Глухонемых, извиняюсь. Но в конечном итоге все равно это должно сводиться к конкретным записям в базе данных, конкретным транзакциям, которые должны быть символьными, которые должны быть вещественными, которые должны быть конкретными. 

S00 [01:18:57]  : абсолютно согласна с вами, и тогда вот насколько справедливо будет следующий тезис, что вот этот нынешний хайп, когда нам всё время предлагают воспользоваться бесплатным семинаром, где нам расскажут, как правильно создавать промпты и решать все свои задачи, Правда, почему-то при ближайшем рассмотрении оказывается, что все эти семинары проводят компании, которые занимаются SMM-маркетингом. Ну, как-то так вот, почему-то. И вот вопрос у меня такой. Может быть то, что мы наблюдаем, это всего лишь навсего тестирование новых технологических механизмов на большой аудитории? И на самом деле сейчас вот все эти большие языковые модели в разном виде, в том числе и мультимодальные, они сами по себе реальные пользы для клиентов, для частных клиентов, тем более для бизнеса, не несут. Это всего лишь этап совершенствования вот той самой технологической базы, которая нужно пройти, чтобы вот потом уже на этой новой базе будут возникать какие-то новые конструкции. Конструкция уже интеллектуальная. Как вы думаете? Вопрос сложный. 

S02 [01:20:22]  : Давайте несколько перспектив. Первая перспектива она конспирологическая. В свое время конспирологическая перспектива заключается в том, что как в свое время все большие продавцы памяти зарабатывали на продаже памяти за счет того, что от символьных терминалов перешли к графическим, И для этого потребовалось больше памяти, соответственно, потребовалось производить больше чипов, и на этом можно было зарабатывать. Точно так же можно спекулировать о том, что производители видеокарт для обработки обсчета нейросетей зарабатывают на продаже графических карт. Я надеюсь, что это теория конспирологическая, хотя не знаю вот с практической точки с другой точки зрения все-таки да ну и опять таки сказать если посчитать некоторых экономистов которые следят за тем что происходит в экономике они сравнивают то что сейчас происходит с нейросетями с тем что 25 лет назад происходило с интернетом да то есть это накачка рынка денег инвестиционного рынка деньгами с последующим схлопыванием пузыря, и как в 2001 году схлопнулся интернет-пузырь, рано или поздно схлопнется пузырь нейросетевой, с другой стороны. С третьей стороны, все-таки, несмотря на то, что пузырь интернета схлопнулся, интернет никуда не делся, и, очевидно, те нейросетевые технологии, которые Сейчас, даже если они находятся в стадии пузыря, они, скорее всего, останутся. И практическую пользу они уже приводят. Как я уже сказал, есть люди, которым просто… Я просто знаю людей, которые просто экономически считают для себя целесообразно использование ЧАД-ГПТ для решения совершенно практических задач. для написания кода. Допустим, если им понятно на какую тему писать код, они пишут общую описание проблемы, получают некоторый шаблон, а потом его дальше дорабатывают. Или, допустим, перевод текста. Я сам свой пример приведу. Если мне нужно перевести статью русского на английский, я без зазрения совести перевожу ее в Google Translate, а потом вычитываю глазами. И получаю результат быстрее чем если я бы всё это делал вручную. То есть, экономическое качество этого перевода становится всё лучше и лучше и лучше с каждым годом на протяжении последних пяти лет. Где-то пять лет, значит, конкретно то, что я сказал, стало возможным. Поэтому Экономический эффект, очевидно, есть. Вопрос в том, насколько быстро это будет приобретать, вот если мы говорим про общий искусственный интеллект, да, действительно, которому можно будет доверить все, что угодно. Насколько быстро это будет происходить? Здесь опять-таки вопрос такой возникает. У нас в сообществе эта тема периодически муссируется. Надо ли нам, чтобы искусственный интеллект заменял нас в области программирования и графического дизайна? вместо того, что мы думали, что он заменит нас в качестве таксистов и уборщиц. Потому что получается, что даже если таксистам искусственный интеллект не очень хорошо справляется, потому что там нужно выходить колеса менять от времени, бензин заливать в бак, а тут нужны все-таки руки. 

S00 [01:24:41]  : Вполне сложная модульная операция. Я бы еще добавила, в плане такого массового пользования, в кавычках можно массовое сказать, это вообще киберпреступность, которая, по-моему, активнее всех этим пользуется. 

S02 [01:24:58]  : Да, это вторая. После того, что сказали Маск и Ашманов обозначили как проблему номер один, это массовое воздействие со стороны корпораций и государств, друг в друг в отношении друга вот вторая это безусловно значит история с кибер преступностью потому что вот у себя в сообществе значит примерно в неделю удаляется несколько десятков фейковых аккаунтов Вот, значит, по телефону, значит, звонки идут беспрерывно, да, и когда бабушкам начинают звонить не просто там, не просто писать СМСки, значит, сама там мама, значит, кинь мне значит, на телефон 20 рублей, а начинают звонить там голосом твоего сына и говорить, мама, я лежу в больнице, переведи денег на искусственную почку срочно, а то я умру, то никакая бабушка, конечно, не сможет ничего с этим сделать. 

S00 [01:26:06]  : Но всё-таки уровень реализации вот таких дефейков, он всё-таки достаточно сложен. И такие атаки, они всё-таки единичные пока, как мне кажется, да? 

S02 [01:26:17]  : Пока да. Пока да, но технология стремительно развивается. Уже сейчас нужно не просто... Есть случаи, когда для того, чтобы пройти авторизацию, нужно не просто в камеру включить, нужно еще и головой помотать. 

S01 [01:26:39]  : Да, да, да. 

S00 [01:26:42]  : Живое видео, да. Вот к вопросу о творческих способностях. Вот тут недавно была новость о том, что модель альфа-фолд 3, она там какую-то структуру белка предсказала и вот крик пошел, что вот в очередной раз всё пропало А теперь машина уже научные открытия совершает. И даже вот я цитату себе выписала. Метод машинного обучения выигрывает у физически обоснованных методов точного предсказания мира. То есть все законы гидродинамики, молекулярной динамики, ядерной физики окажутся неинтерпретируемыми. машинным, моделями машинного обучения и вот, ну вот опять мир рушится. То есть объяснить ничего невозможно, модели что-то придумали, что-то там работает. Но ведь создание новых лекарственных соединений – это, собственно, не интеллектуальная задача ведь, это же всегда была чисто вычислительная задача, которую использовала перебор. И вот, насколько я помню, для квантовых компьютеров как раз одна из сфер их применения в силу их высокой производительности – это как раз фармакология, анализ вот этих молекулярных соединений вот с вашей точки зрения все-таки тут есть интеллектуальное научное творчество или инженерное творчество или это все-таки перебор? ну смотрите 

S02 [01:28:37]  : Здесь, что мы называем творчеством? Помните, мы про галлюцинации говорили? Научные открытия, скажем так. В моем понимании, строго говоря, научные открытия – это как раз та самая галлюцинация. То есть, научные открытия – это экспериментально подтвержденная галлюцинация. То есть, если ты галлюцинировал, но ни одна твоя галлюцинация не подтвердилась, то ты неудачник. А если ты нагаллюцинировал правильно, то тебе, так сказать, повезло. И как раз великие ученые способны не только к богатству, у них не только богатство воображения, но у них еще достаточно большая размерность того пространства, в котором они галлюцинируют, что они могут в этом большом пространстве отбирать действительно те решения, которые вписываются в ту фактологию, на которой они свои галлюцинации, условно говоря, строят. То есть, я не вижу, вообще говоря, еще раз, проблемы галлюцинации как таковых, поскольку они, в моем понимании, отражают как раз творчество. 

S00 [01:29:55]  : Условно говоря. 

S02 [01:29:55]  : Да, в человеческом понимании. И на самом деле, что такое перебор? Есть такая поговорка, не буду утверждать, что гений – это 1% гениальности и 90% пота или тяжелая работа. Тяжелая работа – это как раз перебор. то есть я должен обладать возможностью не только не просто там родить одну гениальную идею и случайно угадать что вот именно она гениальная да или мне должно повести что вот первая же идея которую угадал она стала она она попала в точку а гениальность это про то что я могу генерировать там сотни тысячи неадекватных идей, но методом, так сказать, собственной тяжелой работы проверять их все одна за другой, да? И вот, наконец-то, тысяча первая идея, которую я нагуляционировал и тяжелым трудом проверил, она оказалась верной. Это вот как раз про это. И в этом смысле тоже как бы в переборе нет ничего плохого, да? Напоминаю, что, собственно, вот механизм обучение вот этих вот глубоких моделей он по сути как раз связан на том что мы последовательным последовательным перебором итеративным постепенно находим вот этот вот глобальный минимум пространстве коэффициентов который позволяет некоторым оптимальным образом аппроксимировать ту картину миру которую мы воспринимаем через множество там датчиков или каналов информации То есть это тоже тяжелая работа. Мы не исследуем все пространство параметров. Мы используем так называемый градиентный спуск, когда мы находим некоторый локальный минимум. При этом мы понимаем, что может быть этот минимум не глобальный может быть он локальный да может быть у нас данных недостаточно много вот и мы поскольку у нас данных недостаточно много находим какую-то неоптимальную конфигурацию этих параметров которая будет описывать не весь мир а только какую-то его часть и именно поэтому успех вот этих вот больших моделей оказался в том, что они способны оказались с теми вычислительными ресурсами, при которых они оказались возможными, с теми объемами памяти, по которым они оказались возможны, они оказались способны вместить в себя вот такое избыточное количество параметров, что полученные модели в итоге оказались сопоставимыми с тем, которыми обладает человек. И является ли это перебором по сути? С одной стороны – да, потому что мы все равно перебираем все эти данные, и мы пытаемся, когда мы делаем вывод, мы пытаемся задействовать всю совокупность входов относительно всей базы данных, всех ситуаций, которые у нас накоплены. но мы Но это не полный перебор, потому что мы используем некоторую оптимальную модель, которая оптимальным образом аппроксимирует весь тестовый набор. И в этой оптимальной пространстве, и в этой оптимальной модели мы находим некоторый максимум, который откликается на набор полученных параметров. Мы говорим, что вот это единственная ситуация, которую мы сейчас имеем предсказать. 

S00 [01:33:34]  : Если продолжить аналогию с человеческим мышлением и посмотреть на вот эту большую модель, чего ей не хватает по отношению к человеку? Некого воспитания, в кавычках, образования. А вот можно ли дать ей вот это образование, в кавычках, ну, за счёт некой систематизации, что ли, знания, да? Может быть, какую-то внутреннюю структуру вот этих знаний, да? Ну, не знаю, может быть, антологические какие-то модели, да? Вот какие-то... Вариант Semantic Web существует же, да? То есть мы вводим туда... некое семантическое структурирование да вот может быть вот на этом пути удастся преодолеть вот это принципиальная неинтерпретируемость больших моделей но тут есть два аспекта во первых тут все примерно так опять-таки 

S02 [01:34:40]  : Точки зрения разные. Есть точка зрения, что то, что вы называете семантик ВЕП, он уже давно умер, и нечего... С одной стороны. С другой стороны есть два направления. Одно направление – это обогащение нейросетевых моделей семантическими представлениями. И вот коллега в Новосибирском университете, Иван Вондаренко, Как раз сейчас с этим последние несколько лет занимается, и у него есть достаточно хорошие результаты. Он у нас на семинаре делал доклад недавно. Он как раз показал, что с помощью ограничения структурирования вывода нейросетевой модели вот этой вот некоторой семантической структурой позволяет существенно повысить качество предсказаний или классификации решений и предъявленных задач. Это вот одна сторона. Но остается вопрос, откуда эти семантические модели взять. Вот человек, он в состоянии погрузившись в какую-то предметную область, он в состоянии не просто научиться правильно рефлексировать в этом контексте, он в состоянии еще каким-то образом выявить смыслы. Он может сказать – ага, вот эти все люди, они мужчины, вот это женщины, между ними есть определенные отношения. эти отношения проявляются в каких-то обстоятельствах, и после этого он в состоянии уже с этими объектами или сущностями оперировать на уровне понятий, причем существенно экономя вычислительные ресурсы. И вот здесь мы как раз подходим еще к одному важному аспекту определения общеискусственного интеллекта, который был в самом начале разговора, что общеискусственный интеллект – это не только про то, что мы можем, имея бесконечное количество ресурсов, адаптироваться к бесконечному количеству задач и на бесконечном количестве параметров, а то, что мы можем еще это сделать при ограниченных ресурсах. То есть, имея ограниченное время на реакцию и имея ограниченное количество памяти, мы все равно в состоянии решать поставленные задачи. Чем меньше ресурсов, тем меньше точность, но мы их можем решать. И тут как раз возникает история про то, что если мы можем выделить из какой-то ситуации самое элементарное понятие, свести, допустим, одного бегущего оленя к точке, в которую нам надо целиться, то мы существенно экономим ресурсы мозга, потому что нам не нужно думать о всех точках, составляющих бегущего оленя, а нам достаточно думать об одной точке, в которую нам надо присядется – это где-то геометрический центр того оленя. И на сегодняшний день, к сожалению, нет сосложившейся технологии, которая бы показала, что можно вот эти структурированные знания из модели узнать. То есть, если вы натренируете модель на большом количестве видео и текстов, где слова будут совпадать с какими-то животными, она сможет, допустим, при предъявлении медведя говорить, что это медведь, а при предъявлении оленя говорить, что это олень. Но она не сможет вам рассказать о том, что такое олень, если в текстах не было описаний оленя. То есть, она не сможет, глядя на оленя, разобрать его, не имея текста, разобрать его на составляющие. Человек это может делать. То есть, человек, допустим, если он даже Маугли, да? И он вырос в лесу, он не умеет говорить, он без языка понимает, как охотиться, понимает, где опасные животные, где не опасные животные, от кого нужно убегать, кого нужно ловить. Он может структурировать окружающую реальность. Поэтому задача обогащения нейросетевых моделей символями решена. Задача извлеключения символьных моделей из нейросетевых – задача, которая требует решения. Сделаю оговорку. Я сейчас вспомнил, что, в принципе, есть попытки решения вот этой задачи. извлечения смысловых моделей из нейросетевых, но это делается через, опять-таки, перевод. То есть, мы пытаемся представить себе семантику или семантическое описание какой-то картины мира как некоторую языковую модель, как некоторый язык, и, переводя текстовые описания в семантические, мы пытаемся с этой семантикой оперировать. Может быть, это тоже одно из направлений. То есть, может быть, мы сможем прийти к тому, что глубокая языковая модель сможет научиться оперировать с мыслями, более компактными, чем распределенное текстовое представление, но это будет сделано опять-таки через текст. Но это вот над чем сейчас работают. 

S00 [01:40:27]  : Понятно. Но ведь если мы, опять же, посмотрим на бизнес-системы, на применение вот этих моделей для решения бизнес-задач, есть огромный диапазон вот таких бизнес-приложений, где без логических конструкций, наверное, вообще невозможно двигаться. Это вот в первую очередь управление процессами и всякая поддержка принятия решения. Любая аналитика. Как вы считаете, можно без добавления каких-то символьных технологий, логических конструкций? 

S02 [01:41:12]  : Здесь, опять-таки, поддержка смотря каких принятий решений. Насколько я понимаю, допустим, принятие решения о выдаче и невыдаче кредита легко готовы были бы товарищи из финансовой сферы отдать нейросетям, если их законодательно бы не обязали объяснять эти решения. Причем, я просто знаю, делался доклад на одной из конференций в году, в 2018-м я был, где коллеги рассказывали о системе интерпретируемого искусственного интеллекта, по-моему, чуть ли не для банка. где устроено все было примерно так, что вот у них есть нейросеть, которая принимает решение выдавать или не выдавать кредит, а сбоку стоит система, которая пытается эти решения объяснять, исходя из символьной логики. При этом они заведомо знают, что статистическая точность системы, основанной на символьной логике, ниже, и поэтому для принятия фактических решений они используют нейросетевую модель, необъяснимую. Но если к ним приходит человек и говорит, а почему мне не выдали кредит, они включают, значит, стряхивают пыль с этой символьной машинки, получают объяснение. Если объяснение совпадает с объяснением нейросетевой модели, значит, они его, значит, отдают, вот на вот тебе объяснение. Если оно не совпадает, то уже приходится подключиться, что называется, к кожаному мешку. и он должен что-то там сочинять и объяснять человеку, почему ему отказали в кредите. Вот такое бизнес-решение. Вот так вот выкрутились. Поэтому, если в бизнесе реально, законодательно не требуется объяснение, то Я думаю, все владельцы бизнеса будут счастливы отдать это на откуп машине, если у них есть на чем эту машину натренировать для того, чтобы экономическая стоимость была бы сопоставима. Я просто приведу примеры своего опыта. Мы в какой-то момент занимались классификацией системой распознавания каталогов магазинных. Идёт текст, описание того, что в накладной входит. И нужно понять сколько, чего, какого цвета, какого размера, какой материал. И мы долгое время переживали, что у нас точность низкая. Вот. А потом мы стали разбираться в тренировочных наборах. Вот. И обнаружили... Ну, то есть мы видим, думая, почему у нас там точность такая низкая. Вот. И стали сопоставлять по позициям. Вот здесь вот у нас тестовый набор, где человек разметил, как должно быть. А у нас не совпадение. И мы обнаружили, что там... грубо говоря, в половине случаев, либо в тестовом наборе сам человек сделал ошибку, то есть мы предсказали правильно, а у человека неправильно. Либо у нас неправильно, но потом мы идем и смотрим в том, на чем мы тренировались, а у нас как раз была интерпретируемая модель, где можно было от модели уйти к тестовым данным и заглянуть в тестовые данные, и мы в тренировочные данные. И мы в тренировочных данных видим, что косяк в тренировочных данных был. То есть мы увидели, что мы в какой-то момент, что да, у нас точность низкая, но наша точность, она примерно сопоставима с человеческой точностью. А дальше вопрос такой, что если мы можем обеспечить человеческую точность с существенно низшим, более низким низкими вычислительными затратами, да, или существенно большей производительностью по решению этой задачи, то тогда зачем нам люди? Вот, поэтому если, скажем так, точность устраивает, как это, цена-производительность, да, или там цена-точность производительности, вот если вот сочетание этих факторов делает применение системы искусственного интеллекта нейросетевой или какой другой угодно более производительной, то бизнес, очевидно, на это пойдет. Если есть законодательные ограничения, очевидно, бизнес будет смотреть, какова цена вопроса удовлетворения этих законодательных ограничений. Поэтому, допустим, в той сфере, которой я занимаюсь, допустим, сейчас, там ограничения очень жесткие, потому что там не может система, в принципе, не может по стандартам отрасли не может использоваться система, основанная не на конкретной логике, причём описываемой совершенно конкретными стандартами. Дальше возникает вопрос, что если мы можем сделать систему, которая в результате какого угодно машинного обучения, на чём угодно, если мы эти тестовые данные наберём, она сможет составить программу с учётом этого стандарта, где мы эту программу сможем верифицировать, то, пожалуйста, давайте эту систему запускать в производство. Но, к сожалению, пока таких систем нет. 

S00 [01:46:35]  : Понятно. То есть вообще получается так, что ресурсы-юмкость, то есть требования к ресурсам, они таковы, что всё-таки облачный вариант, наверное, для какого-то массового пользования, он получается более предпочтительным, потому что не могут предприятия, особенно среднего уровня, допустим, наше промышленное, среднего масштаба предприятия, да, какие бы там вагоностроительные, вагоноремонтные депо, например, да, себе позволить какие-то эти модели, наверное, это должно быть облако, да, причем, а в нем должна быть какая-то проверенная такая универсальная модель, которая будет уметь настраиваться на конкретные запросы заказчиков из разных предприятий. То есть это вот совсем далеко от реальности такая идея. 

S02 [01:47:31]  : Ну, смотрите, тут несколько аспектов. Во-первых, в среднем, естественно, если брать экономику, то в разумной экономике, естественно, централизованное всегда дешевле. Другое дело, что если централизованный сервис становится монополистом, то он может в какой-то момент начать выкручивать себе маржу до такого состояния, что у какого-то конкурента может оказаться дешевле или дешевле будет оказываться развернуть свое собственное внутреннее облако, если ты достаточно большая организация. Второй момент, он связан с безопасностью. Если вы в своем облаке собираетесь хранить секретные данные, или если вы, не доверяя, хотите, чтобы в случае каких-либо претурбаций с чужим облаком которая может быть либо там находиться за границей которая может там какой любой момент объявить санкции или если находится это облако у предприятий которые у какого-то предприятия которое может быть перекуплена допустим конкурентом твоим да или аффилировано своим конкурентом и таки тоже возникает вопрос значит сохранности твоих данных вот в этой ситуации Компании из соображений безопасности просто делают свои облака. Другое дело, что есть некоторый порог, начиная с которого свое облако может оказаться экономически целесообразным. И даже если свое облако может оказаться целесообразным для каких-то одних задач, для каких-то других задач, Своего облака может оказаться недостаточно. Простой пример. Вы можете развернуть свое облако, допустим, для хранения файлов, но для решения задач LLM у вас нет достаточно числа сервировок с графическими картами, чтобы собрать свой собственный нейросетевой кластер. Поэтому файлообменные сервера, ресурсов для файлового хранения у вас достаточно, а графических карт недостаточно. С одной стороны, если мы говорим чисто про вычислительные, с точки зрения универсального Ну, все-таки это вот разные вещи, да. Одно дело мы говорим про вычислительных ресурсах, а другое дело про специализации. То есть, если... Здесь же видите, для того, чтобы забить разные, так сказать, срезы окружающего пространства в одну и ту же модель. нужны соответствующие объемы памяти. Допустим, для того, чтобы поддерживать одновременно 10 языков, к примеру, нужно столько памяти. Для того, чтобы одновременно поддерживать 20 языков, нужно уже вот столько памяти. Потому что, если вы пытаетесь 20 языков затолкать вот в такое количество памяти, у вас они могут туда не упихаться, у вас не хватит размерности. И у вас 20 языков туда упихаются, но они будут обрабатываться с качеством меньшим, чем если бы было вот такое количество памяти. Соответственно, если вы хотите к этим языкам запихать в эту же модель предсказание погоды, может оказаться, что вам памяти надо еще в 10 раз больше или в 5 раз больше. Если вы хотите добавить туда еще музыку, вам нужно еще больше памяти. И поэтому, чем больше модальность вашей модели, чем больше число параметров, в этой модели, в каждой модальности, естественно, вам нужно все больше и больше памяти. Соответственно, куда сейчас это все идет? В индустрии планетарного масштаба, чтобы я, и Google, и китайцы, они делают все больше и больше моделей, то есть, не модели, они делают все больше и больше более-более производительные вычислительные кластера, чтобы затолкать туда все больше и больше модальности. Вот. И поэтому вот здесь вот проблема. Проблема из трех составляющих. Во-первых, вычислительные ресурсы. Во-вторых, то количество модальности, которое мы хотим затолкать. И в-третьих, соображение как политической, так и экономической безопасности. И вот сочетание этих трех факторов определяет… Да, ну и последнее уже на то, что вообще, в принципе, требование к интерпретируемости ваших моделей, которое, в принципе, может позволить либо не позволить вам использовать подобные системы для предсказания. Вот четыре этих фактора определяют применимость соответствующих современных ЛЛМ для бизнеса. И еще раз подчеркну, это не обязательно про текст, это может быть про все, что угодно. Это про любые цифровые данные. Смехом ради скажу, что понятие «большие данные» в неявном виде оно возникло... впервые я его услышал в 80-м каком-то там году. Я по первому образованию геофизик, изучал сейсморазведку в институте. Нам там говорили, что Все данные, которые мы имеем с вами при цифровой обработке сейсмических данных для поисков нефти и газа, они на порядке превышают все данные, которые на сегодняшний момент имеет человечество в цифровом виде. Это было 50 чем-то. 45-50 лет назад. Сейчас всё изменилось и количество цифрованных данных... Сейчас большие данные совсем другие. Они как раз именно про поведение людей, про те тексты, которые люди пишут, про то видео, которое они загружают, про то аудио, которое они загружают. Это, конечно, уже превышает любые геофизические данные. 

S00 [01:54:17]  : Понятно. Антон, а как тогда вот можно провести, как очертить потолок, что ли, вот этих вот реальных возможностей современных больших моделей, ну вот в сравнении с теми мифами, которыми нас, ну не нас, а так, публику путчают? То есть вот вы четыре этих пункта описали, да? То есть вот я для себя так определила, что уровень модельности человека, он несопоставимо выше, чем сегодняшняя модель, которая... Жутко прожорливая. 

S02 [01:55:00]  : Уровень модальности человека в физическом мире. Модальность самая вещь тонкая. Я вам приведу простой пример. Не хочу быть политически или социально неполиткорректным. Вот, но и опять-таки эта вот мысль, она вот недавно где-то у нас в сообществе прозвучала, что там не будем спекулировать на процентах, но скажем так, что интеллектуальный уровень любой современной Элли Лемке интеллектуальной с точки зрения текстового восприятия мира. То есть, если мы смотрим на мир через компризму научной и художественной литературы, то уровень любой из нескольких известных топовых эллилемок он культурный уровень, то он превышает уровень, скажем так, существенной части человечества. То есть, ни один из существующих, даже скажем конкретно, ни один из людей, живущих ныне на Земле, не обладает такой энциклопедической, такой энциклопедичностью знаний, которой обладает любая, любая, опять-таки, значит, из нескольких топовых элелемок. Понимаете, да, о чем я говорю? С другой стороны, если мы возьмем, так сказать, бытовой и бытовой, так сказать, интеллект и способность к поведению в физическом мире, то ситуация ровно наоборот. Грубо говоря, мы возьмем эту элелемку и поставим весь этот кластер на необитаемом острове, и что он там будет делать? человек там может быть и выживет и научится научится морских ежей ловить там и росу собирать значит в ямку а вот лемка не сможет потому что у нее ни рук ни ног нету вот это конечно не честно так говорить да потому что ну скажут что вы же не вы бы приделали руки ноги И она бы вас заткнула за полость, но пока что руки-ноги никто не смог придумать, все эти роботы ходят очень неустойчиво, неуверенно, поэтому всё-таки полноценный мультимодальный интеллект в физическом мире – это вещь гораздо более реальная, чем способность манипулировать с текстом, звуком и картинками. Чисто по причине физического ограничения. 

S00 [01:57:49]  : То есть у меня получилось так. Энциклопедические знания о модели, которые человек вряд ли достигнет, но эти знания плохо применимы на практике. 

S02 [01:58:00]  : знает много но что что с ними делать опять-таки все это зависит от контекста да то есть если вот нужно программисту помогать подсказывать вот конкретная задача то пожалуйста если нужно там справочную информацию выдавать, то пожалуйста. Я просто еще раз скажу, я знаю людей, которые перестают пользоваться гуглом, потому что если гуглом пользуешься, то нужно еще по выдаче ходить и искать, где правильный ответ. самому а тут значит вот тебе уже все значит единственное что проверять надо да потому что значит может быть галлюцинация вот но тут опять-таки если допустим ты берешь первый раз проверил все правильно второй раз проверил проверил все правильно третий раз проверил все правильно то там на сотый раз тоже перестанешь проверять Вот. Но и тут ты попадаешь в засаду, потому что на сто первый раз, на сотом разе ты перестал проверять, а на сто первом может оказаться галлюцинация. Вот. Но на самом деле, опять-таки, положа руку на сердце, ведь и люди тоже способны к галлюцинациям. Более того, люди, они могут заведомо давать, так сказать, ложные рекомендации по той причине, потому что они там потому что им выгодно тебя склонить к неправильному решению или потому что им важно получить с тебя деньги за консультацию, а то, что консультация, или совет, или решение было неправильным, значит, это их не волнует. То есть, в этом смысле, значит, можно искусственные системы, если у них, как бы, процент ошибок фактически меньше, С точки зрения бизнеса они не так уж плохи, хотя бы потому, что они не врут. Пока у них не возникла какая-то совсем высшая психическая деятельность и не стало возникать то, что мы у людей называем плохим или хорошим настроением. По крайней мере, можно предположить, что они будут вести себя относительно объективно. 

S00 [02:00:15]  : Понятно. Антон, вообще, разговаривать можно бесконечно, по-моему, на эту тему, но мне кажется, нужно иметь совесть и вас отпустить. А если следующие вопросы... Что-то осталось у нас за... Ещё мы не обсудили, а может быть, тогда вот перенести? 

S02 [02:00:35]  : Да, то есть я предлагаю тогда подвести черту, вот если возникнут какие-то вопросы и желание продолжить беседу, можно будет еще раз в этом же месте в другое время встретиться. 

S00 [02:00:47]  : Да, давайте так. Спасибо вам огромное за этот замечательный разговор. 

S02 [02:00:52]  : Большое спасибо, Елена, и тогда до новых встреч. Всем спасибо, кто нас слушал. До свидания. 

S01 [02:00:57]  : Спасибо. Тогда мы еще... сейчас я закончу запись всего заканчиваю запись 












https://agirussia.org/
Мы ведем группы и организуем семинары русскоязычного сообщества разработчиков систем AGI (Artificial General Intelligence или Общий Искусственный Интеллект) или Strong AI (Сильный Искусственный Интеллект), а также - являющийся их частным случаем HLAI (Human-Level Artificial Intelligence или Искусственный Интеллект Человеческого Уровня).

Группы:
https://t.me/agirussianews (новостной канал)
https://t.me/agirussia (основная)
https://t.me/agiterms (вопросы терминологии)
https://t.me/agibots (разговорный интеллект)
https://t.me/agifintech (финансовые технологии)
https://t.me/collectivei (коллективный интеллект)
https://vk.com/agirussia
https://www.facebook.com/groups/agirussia (основная)
https://www.facebook.com/groups/socialintelligence (коллективный интеллект)
https://groups.google.com/g/agirussia

Онлайн-семинары идут по четвергам, в 18:00 по Московскому времени. Продолжительность два часа, обычно это либо доклад на один-полтора часа и последующее обсуждение на полчаса-час либо круглый стол с регламентом на усмотрение модератора дискуссии. Технические средства проведения, регламент и модерацию обычно обеспечивает инициатор конкретного семинара либо спикер и его коллеги.

Регистрация на семинары (внизу страницы):
https://aigents.timepad.ru/event/1412596

Программа следующих семинаров:
https://agirussia.org/workshops.html
